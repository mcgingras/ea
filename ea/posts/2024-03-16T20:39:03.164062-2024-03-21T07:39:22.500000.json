[{"_id": "Zdp66eKiRBo7nkLxw", "title": "Songs from 'The Kinks' resonating with EA ideas and experiences", "postedAt": "2024-03-21T05:20:13.590Z", "htmlBody": "<ul><li>'The Kinks' wrote these songs over fifty years ago but they echo some EA-endorsed ideas and my experiences of them.</li><li>I enjoy these songs for feeling more engaged and less alone with these ideas and experiences. Also because they're great songs (by my taste!)</li><li>Sharing them below in case they do something similar for you. Also in case there's any other songs or interpretations you'd add, including whether I've been overly influenced by The Kinks and/or EA ideas \ud83d\ude05</li></ul><figure class=\"table\"><table><tbody><tr><td style=\"border:1px solid #ccc;padding:10px\">Song</td><td style=\"border:1px solid #ccc;padding:10px\">Song ideas (my interpretation)</td><td style=\"border:1px solid #ccc;padding:10px\">Relation to EA ideas/experiences (my interpretation)</td></tr><tr><td style=\"border:1px solid #ccc;padding:10px\">'<a href=\"https://www.youtube.com/watch?v=N8LFXEfbxdw\">A Well Respected Man</a>' (1965)</td><td style=\"border:1px solid #ccc;padding:10px\">We often miss opportunities to benefit others with our privileges&nbsp;</td><td style=\"border:1px solid #ccc;padding:10px\"><ul><li><a href=\"https://www.givingwhatwecan.org/case-studies-people-who-pledge-to-give\">It's good to use some of our time and money to benefit others</a></li></ul></td></tr><tr><td rowspan=\"3\">'<a href=\"https://www.youtube.com/watch?v=aRHqs8SffDo\">Apeman</a>' * (1970)</td><td style=\"border:1px solid #ccc;padding:10px\">Shares anxieties about \"crazy politicians\" and that \"I don't want to die in a nuclear war\"</td><td style=\"border:1px solid #ccc;padding:10px\"><ul><li>Taking action on existential risks, and</li><li>Experiencing difficult emotions when taking notice of these risks **</li></ul></td></tr><tr><td>Concern for \"inflation and starvation\"</td><td><ul><li>Connectedness with, and care for, <i><strong>people</strong></i></li></ul></td></tr><tr><td style=\"border:1px solid #ccc;padding:10px\"><p>\"I'm no better than the animals sitting</p><p>In the cages in the zoo man\"</p></td><td style=\"border:1px solid #ccc;padding:10px\"><ul><li>Humility,&nbsp;</li><li>Connectedness with, and care for, <i><strong>non-human animals</strong></i></li></ul></td></tr><tr><td style=\"border:1px solid #ccc;padding:10px\" rowspan=\"3\">'<a href=\"https://www.youtube.com/watch?v=MR52MIJuZJY&amp;pp=ygUTc3RyYW5nZXJzIHRoZSBraW5rcw%3D%3D\">Strangers</a>' (1970)</td><td style=\"border:1px solid #ccc;padding:10px\">\"I see many people coming after me... So I will follow you wherever you go\"</td><td style=\"border:1px solid #ccc;padding:10px\"><ul><li>Humility,&nbsp;</li><li>Connectedness with, and care for, <i><strong>future generations</strong></i></li></ul></td></tr><tr><td style=\"border:1px solid #ccc;padding:10px\"><p>\"Strangers on this road we are on</p><p>We are not two we are one\"</p></td><td style=\"border:1px solid #ccc;padding:10px\"><ul><li><a href=\"https://rockandrollglobe.com/rock/dave-davies-on-the-beauty-and-meaning-of-strangers/\">Connectedness with, and care for, <i><strong>'others'</strong></i></a></li><li><a href=\"https://forum.effectivealtruism.org/posts/bbMMTFa3HN2SPApLC/critique-of-the-notion-that-impact-follows-a-power-law\">Collaborative spirit</a></li></ul></td></tr><tr><td style=\"border:1px solid #ccc;padding:10px\"><p>\"So we will share this road we walk,</p><p>And mind our mouths and beware our talk\"</p></td><td style=\"border:1px solid #ccc;padding:10px\"><ul><li><a href=\"https://80000hours.org/podcast/episodes/toby-ord-perils-of-maximising-good/\">Working on 'being' a good person as part of 'doing' good, and acknowledging moral uncertainty / commonsense ethics</a></li></ul></td></tr></tbody></table></figure><p>* Annoyingly this song is not very gender sensitive. Also all three songs have a heavily western worldview given The Kinks were a UK band</p><p>** In case helpful, I find this <a href=\"https://www.lesswrong.com/posts/fMwvWu3Bvf2dw8kHT/on-living-in-an-atomic-age-by-c-s-lewis-1948\">C.S. Lewis quote</a> (amongst other resources suggested in <a href=\"https://www.lesswrong.com/posts/pLLeGA7aGaJpgCkof/mental-health-and-the-alignment-problem-a-compilation-of\">Mental Health and the Alignment Problem</a>) particularly helpful for sharing and managing these difficult emotions.</p>", "user": {"username": "Sam_Coggins"}}, {"_id": "6tG4m9SJSwvZfkmX6", "title": "EA Philippines Needs Your Help!", "postedAt": "2024-03-21T04:42:07.783Z", "htmlBody": "<h2><strong>Summary&nbsp;</strong></h2><p>(<strong>For an executive summary version of our post, feel free to check our briefer </strong><a href=\"https://docs.google.com/document/d/1Hwb7oCz_H-lyEb2k_XmSL5HUuJGga1tn0jwawjvcx_M/edit#heading=h.8plfml8cy7da\"><strong>here</strong></a><strong>.)</strong></p><p>In light of the current funding constraints in the EA community, EA Philippines has had a difficult time securing the means to continue its usual operations for this year. This can mean less support for growing a highly engaged community of Filipino EAs.&nbsp;</p><p>We are seeking USD 43,000 as our preferred funding for 1 year of operations and a 2-month buffer. The minimum amount of funding we are seeking would be USD 28,000 for 1 year of operations. This will help us with our staffing as well as being able to produce valuable projects (e.g. introductory fellowship for professionals, career planning program, EA groups resilience building, leadership retreat, etc.) and guidance to encourage, support, and excite people in their pursuit of doing good.</p><p><strong>You can help our community with a donation through our </strong><a href=\"https://manifund.org/projects/support-a-thriving-and-talented-community-of-ea-filipinos-\"><strong>Manifund post</strong></a><span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"1\" data-footnote-id=\"iinkp1fyya9\" role=\"doc-noteref\" id=\"fnrefiinkp1fyya9\"><sup><a href=\"#fniinkp1fyya9\">[1]</a></sup></span><strong>&nbsp;or through </strong><a href=\"https://PayPal.Me/zianbonoan\"><strong>Paypal</strong></a><strong>.&nbsp;</strong></p><h3><strong>Outline of this post</strong></h3><ol><li>Why donate to EA Philippines?</li><li>What are EA Philippines\u2019 goals and how do we aim to achieve them?</li><li>Who is on your team?</li><li>What other funding is EA Philippines applying to?</li><li>What are the most likely causes and outcomes if this project fails? (premortem)</li><li>Concluding thoughts</li></ol><h2><strong>Why Donate To EA Philippines</strong></h2><h3><strong>Track record</strong></h3><p><a href=\"https://www.effectivealtruism.ph/\"><u>EA Philippines</u></a> was founded in November 2018 by Kate Lupango, Nastassja \"Tanya\" Quijano, and Brian Tan. They made great progress in growing our community in&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/bmNcw96yGE9EiRkuP/ea-philippines-strong-progress-and-learnings-in-2019-1\"><u>2019</u></a> and&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/tbxoKzzf9DJocEPC4/ea-philippines-2020-annual-report\"><u>2020</u></a>, and the three of them received a&nbsp;<a href=\"https://www.centreforeffectivealtruism.org/community-building-grants\"><u>community building grant</u></a> (CBG) from CEA to work on growing the community from late 2020 until the end of 2021. Since then, EA PH has become one of the largest and most active groups among those in LMICs and Southeast Asia. The group has received grants from the EA Infrastructure Fund to fund us from&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/vyRsRAGqryuLMTahj/ea-philippines-progress-in-2022\"><u>2022</u></a>\u2013&nbsp;<a href=\"https://docs.google.com/document/d/1smpISCzXVnJup7vGj4LYdrMBAAsLM-kTL7ZrzMAzrks/edit#heading=h.l984ke2qs401\"><u>2023</u></a>, with&nbsp;<a href=\"https://www.linkedin.com/in/elmereicuevas/\"><u>Elmerei Cuevas</u></a> serving as our Executive Director during this period.</p><p>Since being founded, EA PH has:</p><ol><li>helped start three student chapters in the top three local universities</li><li>organized a successful&nbsp;<a href=\"https://www.youtube.com/watch?v=qaF6k828tv8\"><u>EAGxPhilippines</u></a> conference being the 3rd most likely to be recommended among EAGs and EAGxs</li><li>had over 300 different people complete an introductory EA fellowship of ours or our student chapters)</li><li>had over 80 active members join EAG/EAGx conferences around the world including EAGxPhilippines (which also garnered 40 first-timer Filipinos)</li><li>had 2 retreats for student organizer leadership and career planning</li><li>members who have started promising EA projects (with a total of at least 14 EA-aligned organizations in the Philippines), such as the ones in the next section.</li></ol><p>However, EAIF\u2019s last grant to EA PH was only for 6 months (from April to September 2023), and they decided to just give the then team a 2-month exit grant rather than a renewal grant at the end of it. Due to the lack of secured funding, as well as wanting to rethink and redefine EA Philippines\u2019s strategic priorities,&nbsp;<a href=\"https://docs.google.com/document/d/1vG0du4hPoxE4pPwX0PPlTD7eZPHuWU5e1XEjktnZlIw/edit\"><u>EA PH\u2019s board decided</u></a> that it would be in the organization\u2019s best interest to explore new leadership to pursue its refined direction. The new leadership would then have to fundraise for their salaries and EA PH\u2019s operational expenses. The board led a public hiring round, and this led to them hiring us (Sam and Zian)<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"2\" data-footnote-id=\"e0kcthuz70f\" role=\"doc-noteref\" id=\"fnrefe0kcthuz70f\"><sup><a href=\"#fne0kcthuz70f\">[2]</a></sup></span>&nbsp;in late December to serve as interim co-directors of EA PH and to fundraise for EA PH.</p><h3><strong>EA-Aligned Organizations in the Philippines: Case Studies</strong></h3><p>Over the last few years, several EA PH members have started cause-specific organizations, projects, and initiatives. Below we highlight some&nbsp;</p><p><strong>Animal Empathy Philippines</strong></p><p><a href=\"https://www.animalempathy.ph/\"><u>Animal Empathy Philippines</u></a> was founded by Kate Lupango (co-founder of EA Philippines), Ging Geronimo (former volunteer at EA Philippines), and Janaisa Baril (former Communications and Events Associate of EA Philippines). The organization started with community building and now focuses on bringing farmed animal issues in the Philippines to the forefront and harnessing collective action to effectively help farmed animals in the Philippines. AEP has published a scoping report on alternative proteins and is currently completing its animal advocacy journey mapping and its swine welfare research project. They also represented the consumer sector in a&nbsp;<a href=\"https://boi.gov.ph/boi-advances-philippine-plant-based-foods-industry-with-rapid-industry-appraisal-and-stakeholders-consultation/\"><u>national stakeholder consultation</u></a> for the development of the local plant-based industry and the creation of a roadmap.&nbsp; They are supported by EA Funds, Animal Charity Evaluators, Humane America Animal Foundation, and the Open Philanthropy Project.</p><p><strong>Phlourish Mental Health Initiative</strong></p><p><a href=\"https://rocbata.notion.site/About-Phlourish-5acdeb8b86fc4d9598e08e263f0b9a87\"><u>Phlourish Mental Health Initiative</u></a> is co-founded by Roc Bata, Joseph Cubar, and Shen Javier, all of whom are active members of EA PH. Phlourish is on a mission to test and scale evidence-based and cost-effective mental health interventions so they are accessible to Filipino adolescents. They are currently testing guided self-help workbooks, which is one of the interventions identified in&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/vvwS2YdhCFqNSsoBv/cause-exploration-child-and-adolescent-mental-health-in\"><u>Effective Altruism Philippines\u2019 Mental Health Charity Ideas Research Project</u></a>. Phlourish is a recipient of Mental Health Funding Circle\u2019s Spring Grants Round.</p><p><strong>WhiteBox Research</strong></p><p><a href=\"https://www.facebook.com/WhiteBoxResearch/\"><u>WhiteBox Research</u></a> is an AI safety organization co-founded by Clark Urzo, Brian Tan, and Kriz Tahimic, all of whom are active in EA PH. WhiteBox aims to solve open research problems in AI interpretability and develop more AI safety researchers. Currently, they\u2019re organizing a five-month, part-time&nbsp;<a href=\"https://docs.google.com/document/d/1bc_lvl-z9Becz3FY8xMp9E5XeTI9gjVAWDdVVpElsjs/edit\"><u>fellowship</u></a> for 13 people in Manila to master the fundamentals of mechanistic interpretability research.</p><p>Check out other EA Organizations/ projects active in the Philippines&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/NrqGyXzvwB2Gqu6XW/state-of-the-east-and-southeast-asian-eacosystem\"><u>here</u></a>.</p><h3><strong>EA PH Members: Case Studies</strong></h3><p>In the past years, several of our members took active steps to grow their EA journeys. Below we share some case studies of EA Philippines members.</p><p><strong>Marifel \u201cGing\u201d Geronimo</strong></p><p><a href=\"https://www.linkedin.com/in/ging-geronimo/\"><u>Ging Geronimo</u></a> is a co-founder of Animal Empathy Philippines. She previously worked for the Philippines\u2019 social and economic development planning and policy coordinating body and as a consultant for a multilateral bank. She first found out about EA by joining EA Philippines\u2019 Intro EA discussion group in 2020 and started volunteering for us in 2021. She also took the Giving What We Can pledge in 2020.</p><p><strong>Rochelle \u201cRoc\u201d Bata</strong></p><p><a href=\"https://www.linkedin.com/in/rochelle-bata/\"><u>Roc Bata</u></a> is the Founder and Executive Director of&nbsp;<a href=\"https://www.phlourish.ph/\"><u>Phlourish</u></a>, a local nonprofit that aims to scale cost-effective mental health interventions in the Philippines. She was previously the Chief Operations Officer of&nbsp;<a href=\"https://climatescience.org/\"><u>ClimateScience</u></a>, a non-profit providing free resources on climate change and its solutions. Roc first found out about EA in 2018, and she went to her first EA Philippines event in 2019. She attended our Intro to EA discussion group in 2020, which motivated her even more to do more good with her career.</p><p><strong>Alethea \u201cAlthy\u201d Cenda\u00f1a</strong></p><p><a href=\"https://www.linkedin.com/in/affcendana/\"><u>Althy Cenda\u00f1a</u></a> currently works as an Operations Associate for Fish Welfare Initiative. As part of the international support team, she provides administrative and operational support for their main program in India. She previously worked as Associate Director EA Philippines and&nbsp; President of&nbsp;<a href=\"https://www.facebook.com/effectivealtruismupd\"><u>EA UP Diliman</u></a>. Althy first found out about EA when she joined EA UP Diliman as its founding VP for Logistics and Internal Affairs in 2021. She also works as a research volunteer for the Shrimp Welfare Project.</p><p>Our board members can also be considered case studies of EA Philippines\u2019 success:</p><ol><li><a href=\"https://www.linkedin.com/in/brianctan/\"><u>Brian Tan</u></a> is a co-founder of&nbsp;<a href=\"https://www.facebook.com/WhiteBoxResearch/\"><u>WhiteBox Research</u></a>, where he leads their operations and marketing. He\u2019s also a co-founder and board member of EA Philippines, and he worked full-time for EA PH on a grant in 2021. He was also a Group Support Contractor at CEA for two years, where he supported EA groups around the world. He first found out about EA in 2017 and helped start EA Philippines in 2018.</li><li><a href=\"https://www.linkedin.com/in/raymund-ed-dominic-bermejo-53113834/\"><u>Raymund \u201cRed\u201d Bermejo</u></a> is the Executive Director of&nbsp;<a href=\"https://www.antientropy.org/\"><u>Anti-Entropy</u></a> which provides operations support to high-impact organizations as well as tools and resources for ops staff. He previously was the COO of a global tech consultancy firm for almost a decade. Red got engaged in EA by joining EA Philippines\u2019 introductory discussion group in 2020. In 2022, he left his COO role and became an Associate Director for EA Philippines.</li><li><a href=\"https://www.linkedin.com/in/tanyaquijano/\"><u>Tanya Quijano</u></a> is currently a senior program officer at the Australian Embassy in the Philippines managing a 16 million USD policy development program. She co-founded EA Philippines in 2018 and served as a part-time community builder for EA PH from 2018\u20132023 to pursue outreach to professionals and continue to advise EA PH members in pursuing impactful careers.</li></ol><h2><strong>What are EA Philippines\u2019 goals and how do we aim to achieve them?&nbsp;</strong></h2><h3><strong>Funding breakdown</strong></h3><p>Our preferred funding amounts to USD 43,000 for 1 year of operations and a 2-month buffer for staff funding and routine operations. This will cover funding for the salaries of Zian Bonoan and Sam Ackary at 0.5 FTE each as co-directors, operational expenses (e.g. Tech Subscriptions, Events, Socials, Book Orders, Routine Volunteers, etc.), and funding all the projects mentioned in the Project Breakdown section.</p><p>The minimum amount of funding would be USD 28,000 for 1 year of operations. This would primarily entail changes in the projects we choose to run for the year.</p><p>We think EA Philippines is a cost-effective organization to fund considering the difference in the cost of living compared to EA groups in higher-income countries, making our projects and costs cheaper to run and sustain. You can refer to this&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1an1gTrW4ogDfmwE5FwUpdxxtvtxdY0yfklLYTtHHG60/edit?usp=sharing\"><u>budget breakdown</u></a> for more information.&nbsp;</p><h3><strong>Project breakdown&nbsp;</strong></h3><p>In the next year, our core team hopes to achieve the following goals with the specified metrics for success for each project:</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/6tG4m9SJSwvZfkmX6/mnzpxyltvak2f7mvqqct\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/6tG4m9SJSwvZfkmX6/oaeq85knxu2m4oaiueu4 140w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/6tG4m9SJSwvZfkmX6/gohh94n6vqvehry3fspo 280w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/6tG4m9SJSwvZfkmX6/fjtw1hftxzcwqeimcppc 420w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/6tG4m9SJSwvZfkmX6/aj6qhavpoxu7zg1nn1dm 560w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/6tG4m9SJSwvZfkmX6/px7iostnzbpuqne4ayio 700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/6tG4m9SJSwvZfkmX6/opcm60natnkhqhqi0qwc 840w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/6tG4m9SJSwvZfkmX6/vfogsjwrsou36div0h3y 980w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/6tG4m9SJSwvZfkmX6/bem93nhd6fvxpnoqhvxw 1120w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/6tG4m9SJSwvZfkmX6/fikavlyakhbsk05jqtui 1260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/6tG4m9SJSwvZfkmX6/phnyu2ygtkgynurvpwez 1334w\"></figure><p>We recognize that these particular projects may not necessarily \u201creinvent the wheel.\u201d However, these events are strategically chosen not only to sustain our uphill progress but to continue scaling up towards a diverse pool of individuals looking to do the most good they can. These projects will be designed as a funnel to the other; for example, we hope to initiate our projects in this order:</p><p>Introductory fellowship for professionals/Seeding a new EA chapter \u2014&gt; In-depth fellowship \u2014&gt;&nbsp; Career planning program \u2014&gt; Leadership retreat/EA groups resilience building&nbsp;</p><p>This chain model is a response to the need for impactful follow-ups after projects. Alongside these projects, routine activities such as career/chapter advising and monthly socials/meetups.&nbsp;</p><p>In these succeeding projects, we hope to maximize our pool of volunteers and potentially take on some interns who can assist in events management, administrative tasks, or community engagement. We expect to take in at least 5 volunteers for these initiatives, both students and professionals potentially sourced from our introductory fellowships or previously engaged members.</p><p><strong>Objective 1. To introduce new and diverse members to EA PH&nbsp;</strong></p><p>We believe it is essential to provide EA knowledge-building spaces to unique individuals actively looking for ways to create more impact with their resources. We plan to achieve this in two ways:</p><ol><li><strong>Introductory fellowship for professionals</strong>. In 2022 EA Philippines has hosted one cycle of IF for professionals (see syllabus&nbsp;<a href=\"https://docs.google.com/document/d/1JRw_G_EqqNjaf-7HHq-Vu9QO3MF9kwN5dqsBBM1edaI/edit#heading=h.a09tfxqr7la7\"><u>here</u></a>). We believe this is an important initiative to sustain considering that all introductory fellowship opportunities in the Philippines are geared for university students or fresh graduates. Additionally, given that we have previously conducted this program, our team has a model to work with and improve on for future cycles. Ideally, we would be accepting ~30 participants and aiming for a 60% graduation rate\u2014the same metric we followed in our first cycle. While we only reached a 40% graduation rate for all monitored fellows, we were able to generate 17 graduates and around 14 members willing to be part of EA PH. We aim to exceed these numbers in the succeeding cycle. Additionally, we aim to channel these talents into existing EA-aligned organizations or to other EA PH events such as a career planning program.&nbsp;</li><li><strong>Seeding a new EA chapter.</strong> A motivated university student member of the EA PH community expressed interest in opening an EA chapter outside of Metro Manila\u2014specifically in the Mindanao region. This member expressed confidence in taking on three co-founders and eight new members. We see supporting this budding EA chapter as an exciting opportunity to pursue, especially with local EA organizations such as Healthy Futures Global. With an EA chapter in Mindanao, we can help create talent to support these organizations. Additionally, much of the activities of EA Philippines has been centered on Metro Manila audiences. Our team finds seeding a new chapter outside of Metro Manila to be a compelling opportunity to expand the EA movement into other parts of the Philippines. EA Philippines would be providing mentoring to the co-founders and connecting them with existing EA group support programs.</li></ol><p><strong>Objective 2. To build the skills and confidence of EA PH members to pursue/sustain EA-aligned initiatives</strong></p><p>Our members have initiated various local EA initiatives ranging from spearheading projects to leading registered nonprofits. We believe it is important to both 1) support our existing members leading these initiatives and 2) encourage aspiring members looking to initiate a local EA endeavor. We have two key projects we believe can accomplish this:</p><ol><li><strong>Leadership retreat.&nbsp;</strong>Retreats are an incredibly high-impact opportunity. EA Philippines has not yet conducted a similar program to a leadership retreat. We hope to explore this leadership retreat through one of either ideas: 1) helping existing founders lead organizations better through strategy setting, fundraising, delegation skills, etc. or 2) helping aspiring founders by exploring topics such as co-founder fit, project ideation, etc. In either idea, our goal is to facilitate a participant-driven program design. We have at least 14&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/NrqGyXzvwB2Gqu6XW/state-of-the-east-and-southeast-asian-eacosystem#Philippines_____\"><u>cause/topic specific organizations based in the Philippines</u></a> led by amazing EAs, offering a wide opportunity to support these EAs. With this number of organizations (and considering that we can expect around 2-3 EAs on average from each of these orgs), our ideal turnout would be 20-30 participants for a leadership retreat.&nbsp;</li><li><strong>Student groups resilience building</strong>. While EA PH is not completely hands-on with our university chapters, we provide regular support in terms of advising and resources such as books. In our observations with our three university chapters, we recognize that recruiting organizers is a significant challenge. We hope to address this by providing a space where university organizers convene and share ways in which resilience can be sustained in their respective chapters. Additionally, if we could support the fruition of a new EA chapter in Mindanao, we could provide this same opportunity for their organizers.</li></ol><p><strong>Objective 3. To introduce high-fidelity models of EA for in-depth EA knowledge</strong></p><p>EA Philippines, along with our university chapters, offer several entry points into the EA knowledge space. Our goal is to elevate this further by offering more high-fidelity avenues for in-depth EA knowledge. We plan to facilitate an&nbsp;<strong>in-depth EA fellowship</strong> targeted towards those who have accomplished an introductory fellowship provided by either our university student chapters or by EA Philippines\u2019 professional\u2019s introductory fellowship. Previously, EA Philippines conducted an in-depth reading group (see syllabus&nbsp;<a href=\"https://docs.google.com/document/d/1rawu-prcsf5q9W4tKbH3ZMWsBFNk1eP5bHS75ZdiZsI/edit\"><u>here</u></a>) An in-depth EA fellowship can offer members an opportunity to engage in EA more profoundly.</p><p><strong>Objective 4. To prepare EA PH members for pursuing a high-impact career</strong></p><p>A common concern in our community is the need for a follow-up to EA introductory-level opportunities. We believe offering a program for career support and development is a viable fit for this need. We believe it is essential to help members further apply EA principles to their careers. To achieve this, we plan to pursue a&nbsp;<strong>career planning program</strong>. In the past, EA Philippines has provided career support by offering advising and hosting a&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/BnzogudjvxxPeZFrE/ea-philippines-career-planning-retreat-for-students-and\"><u>career planning retreat tailored for students and professionals</u></a>. Shifting from a retreat program to a continuous 6-week program allows us to provide our members' long-term focus, flexibility, and structured guidance as opposed to having these&nbsp;</p><p>Aside from our four objectives, our team is considering the possibility of registering EA Philippines. EA Philippines is aiming to solidify our credibility in the local context to open avenues for a wider network of opportunities. We recognize that with this established credibility comes more opportunities for sustainable funding, networking, trust in the organization, and attracting more talent (which increases the pool of potentially high-impact EAs in the Philippines). Out of all these benefits, we see the opportunity for sustainable funding of particular interest. Registration can reduce friction or barriers associated with accepting funding from potential grantors/donors. This is important for EA Philippines to continue scaling up as more and more.</p><h2><strong>Who is on your team?</strong></h2><h3><strong>What's your track record on similar projects?&nbsp;</strong></h3><p><strong>Zian</strong></p><p>Zian Bonoan (<a href=\"https://www.linkedin.com/in/zian-bonoan-2637061ab/\"><u>LinkedIn</u></a>) currently serves as the Co-Director of EA Philippines. She has a Bachelor\u2019s Degree in Economics from Ateneo de Manila University. Besides being active in the Effective Altruism space, Zian also works as a part-time market researcher in GoDoc, a software company specializing in developing applications for medical practitioners.&nbsp;</p><p>Much of her work is centered within EA, having recently helped organize EAGxPhilippines in October, last year. Her experience here includes producing all graphics used before and during the conference, coordinating with several suppliers for the timely production of needed materials, and crafting an appropriate marketing strategy to pique the interest of EAs primarily within the Philippines and in Asia. Her interest in EA started within her university group, EA Blue, where she also served as the Vice President for Communications. She also provides communications and graphic design support for EA university and city groups on a freelance basis. Some of her previous clients include EA for Christians, Stanford EA, and a handful of EAGxs among others.</p><p><strong>Sam</strong></p><p>Sam Ackary (<a href=\"https://www.linkedin.com/in/samantha-ackary-88781721a/\"><u>LinkedIn</u></a>) currently serves as the Co-Director of EA Philippines. She graduated in 2023 from Ateneo de Manila University with a degree in BS Health Sciences and a minor in Sociology. After graduating from university, Sam began working in the health and development space. She currently works at the Ateneo School of Government as a Research and Project Assistant for their Tobacco Control and Governance Program under the Ateneo Policy Center division.&nbsp;</p><p>In the EA space, Sam served as the Secretary-General of Effective Altruism Blue in her last year of university. Her milestones as a Secretary-General include spearheading the creation of an organizational constitution, mentoring an Associate Secretary-General, and systematizing an event evaluation system. She also has experience in EA operations work as a Research and Project Assistant with Anti-Entropy, directly reporting to Red Bermejo, Executive Director and a board member of EA Philippines. Sam has explored other EA opportunities by joining a Virtual Program reading group for The Precipice, volunteering for EAGxPhilippines, and facilitating EA topic discussion spaces for EA Blue.</p><h3><strong>How the work will be split</strong></h3><p>The following breakdown of roles and responsibilities are divided between Zian and Sam:</p><p>Zian</p><ul><li>Career advising</li><li>Events organizing and management</li><li>Communications&nbsp;</li><li>Operations (finances, administrative tasks)</li></ul><p>Sam</p><ul><li>Career advising</li><li>University chapter advising</li><li>Events organizing and management</li><li>Community health</li><li>Volunteer/intern management</li></ul><p>While Zian and Sam are early in their careers, they can provide value to university students or fresh graduates initiating their professional careers. Both Zian and Sam are backed by rich work experience gained through both professional work in the EA and non-EA space through student organizing for EA, internships, freelance work, and part-time jobs. With these experiences in hand, Zian and Sam can provide young EA members with advice regarding seeking high-impact work experiences, maximizing networking opportunities, and developing career goals.</p><h2><strong>What other funding is EA Philippines applying to?&nbsp;</strong></h2><p>While the Co-directors currently receive a small stipend from the savings of the previous core team, this runway is projected to run out by the end of April. We will be putting out a call for funding on the EA Forum shortly after this is posted. Around the same time, we will be passing in an application for CEA Group Support Funding after Zian became a CEA Certified Organizer last February. We will also be applying for funding from Meta Charity Funders and the EA Infrastructure Fund which we intend to put out by mid to late March. Finally, we are considering seeking funding locally although we currently have no funders in mind for this.&nbsp;</p><p>As of this time, we have received USD 2000 from Brian and Red ($1000 each) which will be placed into paying Zian and Sam part-time stipends for the next couple of months.&nbsp;</p><h2><strong>What are the most likely causes and outcomes if this project fails? (premortem)</strong></h2><ol><li>Issues in the global community put EA in a bad light<ol><li>Outcome: People who would normally be excited about EA ideas might look to the issues of the global EA community. This may influence their view of EA and lead them to disengage or even take on a negative view of EA regardless of the progress and welcoming community the Philippines has.</li><li>Mitigation: Provide a space in the EA PH community where people can discuss and ask their questions about concerns they may have. It would also be best practice for us to be as transparent and honest as possible about EA PH\u2019s stances on such events while also promoting or defending EA/EA Philippines locally.&nbsp;</li></ol></li><li>The information we put out is not valuable or communicates EA poorly<ol><li>Outcome: Very talented people who go through our programs may disengage with EA or engage with EA for reasons other than doing good effectively. EA Philippines may also end up progressively moving away from the ideas of EA or producing programs that ultimately do not lead anyone to pursue tangible actions of their own.</li><li>Mitigation: Establish a deep understanding of EA knowledge among the core team so that projects and operations are designed in such a way that communicates EA ideas as clearly and accurately as possible. This can mean expecting core team members to regularly put aside the time to read through EA material, stay updated with developments across the global EA community, retain involvement and connection with the wider EA community outside of the Philippines, etc. Projects would also be designed in such a way that encourages following through with personal actions from the participants besides being a source of information.</li></ol></li><li>We can\u2019t get enough volunteers<ol><li>Outcome: Some of the projects we\u2019ve carefully selected and planned for will have to be deprioritized or restructured and therefore some goals may ultimately not be attained.</li><li>Mitigation: Selecting volunteer involvement to be in roles that are more suitable to university students who also happen to be the biggest group and have also shown to be the most eager to take part in such activities.&nbsp;</li></ol></li><li>Internal disputes deter people from participating in the community<ol><li>Outcome: Internal conflicts can produce an environment that feels unwelcoming and distracts from the goals of EA therefore the loss of more talented people in the EA space.</li><li>Mitigation: Continue providing the means for people to voice out concerns and have a point person for community health support to make sure this is not overlooked.</li></ol></li></ol><h2><strong>Concluding thoughts&nbsp;</strong></h2><p>EA Philippines humbly seeks your support to sustain and expand our impactful initiatives. With a proven track record of fostering a vibrant community and catalyzing meaningful change, EA Philippines has emerged as a leader in Southeast Asia. However, the recent conclusion of our grant underscores the urgent need for sustainable funding to support our operations and initiatives. Your contribution will enable us to sustain our staffing, produce valuable projects, and provide essential guidance to our community members. Your support is not just an investment in EA Philippines; it's an investment in the future of effective altruism in the Philippines.&nbsp;</p><p><strong>We look forward to your generosity \u2014 your support will drive the current and future effective altruists in the Philippines!</strong><br><br><i>Should you have any questions or clarifications, you can contact either Sam (sam@effectivealtruism.ph) or Zian (zian@effectivealtruism.ph) and they'd be happy to help!</i></p><p>&nbsp;</p><ol class=\"footnote-section footnotes\" data-footnote-section=\"\" role=\"doc-endnotes\"><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"1\" data-footnote-id=\"iinkp1fyya9\" role=\"doc-endnote\" id=\"fniinkp1fyya9\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"iinkp1fyya9\"><sup><strong><a href=\"#fnrefiinkp1fyya9\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>How to donate through Manifund:&nbsp;<br>1. Create a Manifund account (should take &lt;2 minutes)<br>2. You can add money via credit card, or bank transfers, DAF, and crypto for larger donation sizes<br>3. Go to the EA Philippines post on Manifund and donate there<br><br><i>US-based donors can get a tax deduction for donating on Manifund.</i></p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"2\" data-footnote-id=\"e0kcthuz70f\" role=\"doc-endnote\" id=\"fne0kcthuz70f\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"e0kcthuz70f\"><sup><strong><a href=\"#fnrefe0kcthuz70f\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>The board initially hired Sam and Zian as Co-Associate Directors and&nbsp;<a href=\"https://www.linkedin.com/in/markromeromd/\"><u>Mark Romero</u></a> as Executive Director. However, last January, Mark\u2019s Canadian residency application got approved. Given this, Mark decided to resign from the position, and Sam and Zian stepped up as Co-Directors. See more about this&nbsp;<a href=\"https://docs.google.com/document/d/1nVW76pSfSfIbzLPWIHk655POqKyrCL54gV8ACuOwy2M/edit\"><u>here</u></a>.</p></div></li></ol>", "user": {"username": "zianbee"}}, {"_id": "RQSLnjpy8ETtKu5Gk", "title": "Slim overview of work one could do to make AI go better (and a grab-bag of other career considerations)", "postedAt": "2024-03-20T23:17:52.938Z", "htmlBody": "<p data-internal-id=\"h.54352ffcidco\">Many kinds of work one could do to make AI go better and a grab-bag of other career considerations</p><p>I recently found myself confused about what I\u2019d like to work on. So, I made an overview with the possible options for what to work on to make AI go well. I thought I\u2019d share it in case it\u2019s helpful for other people. Since I made this overview for my own career deliberations, it is tailored for myself and not necessarily complete. That said, I tried to be roughly comprehensive, so feel free to point out options I\u2019m missing. I redacted some things but didn\u2019t edit the doc in other ways to make it more comprehensible to others. In case you\u2019re interested, I explain a lot of the areas in the \u201cHumans in control\u201d and the \u201cMisalignment\u201d worlds <a href=\"https://forum.effectivealtruism.org/posts/wE7KPnjZHBjxLKNno/ai-things-that-are-perhaps-as-important-as-human-controlled\">here</a>&nbsp;and to some extent <a href=\"https://forum.effectivealtruism.org/posts/JGazpLa3Gvvter4JW/cooperating-with-aliens-and-agis-an-ecl-explainer\">here</a>.</p><h1 data-internal-id=\"What_areas_could_one_work_on__What_endpoints_or_intermediary_points_could_one_aim_for_\">What areas could one work on? What endpoints or intermediary points could one aim for?</h1><p>Note that I redacted a bunch of names in \u201cWho\u2019s working on this\u201d just because I didn\u2019t want to bother asking them and I wasn\u2019t sure they had publicly talked about it yet, not because of anything else.</p><p>\u201c?\u201d behind a name or org means I don\u2019t know if they actually work on the thing (but you could probably find out with a quick google!)</p><figure class=\"table\"><table><tbody><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><strong>World it helps</strong></td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><strong>The area (Note that this doesn\u2019t say anything about the type of work at the moment. For example, I probably should never do MechInterp myself because of personal fit. But I could still think it\u2019s good to do something that overall supports MechInterp.)</strong></td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><strong>Biggest uncertainty</strong></td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><strong>Who\u2019s working on this</strong></td></tr><tr><td style=\"background-color:#d9ead3;padding:5pt\" colspan=\"1\" rowspan=\"3\">Hu- mans in con- trol</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p>ASI governance | human-control</p><ul><li>Who is in control of AI, what\u2019s the governance structure etc.</li><li>Digital sentience</li><li>[...]</li></ul></td><td style=\"background-color:#e6b8af;padding:5pt\" colspan=\"1\" rowspan=\"3\">Is this tractable and is success path-dependent?</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Will MacAskill, [redacted]?, indirectly: cybersec. folk?, some AI governance work?</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p>Acausal interactions | human-control</p><ul><li>Metacognition</li><li>Decision theory</li><li>Values of future civilisation</li><li>SPIs</li></ul></td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">[redacted]</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">SPIs for causal interactions | human-control</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">CLR</td></tr><tr><td style=\"background-color:#d0e0e3;padding:5pt\" colspan=\"1\" rowspan=\"3\">Mis- align- ment</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Prevent sign flip and other near misses</td><td style=\"background-color:#fce5cd;padding:5pt\" colspan=\"1\" rowspan=\"1\">Is this a real concern?</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Nobody?</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p>Acausal interactions | misalignment</p><ul><li>Decision theory</li><li>Value porosity</li></ul></td><td style=\"background-color:#fff2cc;padding:5pt\" colspan=\"1\" rowspan=\"3\">Is this tractable?</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">[redacted]? [redacted]?</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Reducing conflict-conducive preferences for causal interactions &amp; SPIs | misalignment</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">CLR</td></tr><tr><td style=\"background-color:#c9daf8;padding:5pt\" colspan=\"1\" rowspan=\"12\"><p>&nbsp;</p><p>Main- stream AI safety best thing to work on</p></td><td style=\"background-color:#d9ead3;padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Reduction of malevolence in positions of influence through improving awareness&nbsp;(also goes into the \u201cHumans in control\u201d category)</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">[redacted]? Nobody?</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Differentially support responsible AI labs</td><td style=\"background-color:#ead1dc;padding:5pt\" colspan=\"1\" rowspan=\"11\"><p>For some of these: Would success be net good or net bad?</p><p>If good: How good?</p><p>How high is the penalty for being less neglected?</p></td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">&nbsp;</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Influence AI timelines</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">[redacted], [redacted], [redacted]?, maybe misc. policy people?</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">AI control (and ideas like paying AIs)</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Redwood Research</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Model capabilities evaluations</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">METR, Apollo?, maybe AI labs policy teams, maybe misc. Other policy people?</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p>Alignment (<a href=\"https://www.lesswrong.com/posts/zaaGsFBeDTpCsYHef/shallow-review-of-live-agendas-in-alignment-and-safety\">more comprehensive overview</a>):</p><ul><li>MechInterp</li><li>ELK</li><li>(L)AT</li><li>Debate</li><li>COT oversight</li><li>Infrabayesianism</li><li>Natural abstractions</li><li>Understanding intelligence</li><li>[...]</li></ul></td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><a href=\"https://www.lesswrong.com/posts/zaaGsFBeDTpCsYHef/shallow-review-of-live-agendas-in-alignment-and-safety\">Overview post on LessWrong</a></td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Human epistemics during early AI</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">~Forecasting crowd, nobody?</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Growing the AI safety and EA community or improving its branding or upskilling people in the community (e.g. fellowships)</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Constellation, Local groups, CEA, OpenPhilanthropy, \u2026</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Improving the AI safety and EA community and culture socially</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">CEA</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Threat modelling, scenario forecasting etc.</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">[redacted], \u2026</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Make it harder to steal models</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Cybersecurity folk</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Regulate Open Source capabilities</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Policy folk? Nobody?</td></tr></tbody></table></figure><h1 data-internal-id=\"What_types_of_work_are_there_\">What types of work are there?</h1><figure class=\"table\"><table><tbody><tr><td style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\"><strong>Which world</strong></td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><strong>Type of work</strong></td><td style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\"><strong>Broad category of work</strong></td></tr><tr><td style=\"background-color:#f3f3f3;padding:5pt\" colspan=\"1\" rowspan=\"8\">Can be in any of the three areas above</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Offering 1-1 support (mental, operational, and debugging)</td><td style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">&nbsp;</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Project management, events, and programs</td><td style=\"background-color:#b4a7d6;padding:5pt\" colspan=\"1\" rowspan=\"1\">Organising</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Short, blogpost-style research, for example summaries, overviews, conversation notes, other distillations; potentially writing for others</td><td style=\"background-color:#ffe599;padding:5pt\" colspan=\"1\" rowspan=\"7\"><p>Research or otherwise being a thinker,</p><p>Varying in my position in the research pipeline from foundational to strategizing about how to get things done</p></td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Long report-style conceptual research: Foundational (E.g. understanding an aspect of decision theory or cognition better)</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Long report-style conceptual research: \u201cApplied\u201d (closer to what I\u2019ve been trying to do. Trying to understand the implications. Could also be alignment thinking, e.g. [redacted].)</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Pitching high-level empirical project ideas and grantmaking</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Working with language models: Empirical ML</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Public polling, qualitative opinion research</td></tr><tr><td style=\"background-color:#d9ead3;padding:5pt\" colspan=\"1\" rowspan=\"1\">Humans in control</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">ASI governance thinking</td></tr><tr><td style=\"background-color:#c9daf8;padding:5pt\" colspan=\"1\" rowspan=\"7\">Synergizes most with \u201cMainstream AI safety\u201d areas above</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">EU AI office and AISI style policy work</td><td style=\"background-color:#d5a6bd;padding:5pt\" colspan=\"1\" rowspan=\"3\"><p>Setting policy</p><p>\u201cNormal\u201d, outside of EA world</p></td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">RAND and GovAI style policy research</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Policy work at or for an AI lab</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Grassroots advocacy</td><td style=\"background-color:#c27ba0;padding:5pt\" colspan=\"1\" rowspan=\"4\"><p>Opinion making, lobbying and advocacy</p><p>Leveraging social skills outside of EA world</p></td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Lobbying in DC, Berlin, London, or Brussels</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Targeted individual outreach</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Podcasting, youtubing</td></tr></tbody></table></figure><h1 data-internal-id=\"Appendix__Other_considerations_that_go_into_thinking_about_my_career\">&nbsp;</h1><h1 data-internal-id=\"Appendix__Other_considerations_that_go_into_thinking_about_my_career\">Appendix: Other considerations that go into thinking about my career</h1><p>Here are other things that I\u2019m thinking about for my career deliberations. I\u2019m also still in the middle of figuring stuff out, so this is \u201cThe first part of my career deliberation seems maybe useful to others. I\u2019ll also share the second half just in case\u201d and not \u201cHere is my complete career deliberation template that I found to work.\u201d Note that I\u2019m basically just listing considerations and possible approaches to take into account. The actual thinking about which ones are most important to you likely will need additional free-form space. I\u2019d encourage you to share your approaches if you think it might be useful to others!</p><h2 data-internal-id=\"How_do_I_want_to_approach_choosing_my__next__work_\">How do I want to approach choosing my (next) work?</h2><figure class=\"table\"><table><tbody><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><strong>Options</strong></td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><strong>Which broad category of work does this fit?</strong></td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Follow my curiosity or excitement. Follow the path of least emotional resistance. Don\u2019t hesitate spending large amounts of time (months) just to understand something better even if it is not entirely clear whether it is necessary or useful.</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Research or otherwise being a thinker</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Work on what others find useful.</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Research or otherwise being a thinker, organising</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Check and apply to open positions.</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Research or otherwise being a thinker, organising, setting policy</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Follow a systematic agenda. Ensure your work always has some path to impact.</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Could be any type of work</td></tr></tbody></table></figure><h2 data-internal-id=\"On_the_meta_level__what_is_my_priority_for_my_next_work_\">On the meta level, what is my priority for my next work?</h2><figure class=\"table\"><table><tbody><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><strong>Options</strong></td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><strong>Priority</strong></td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><strong>Example activities</strong></td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><strong>Synergies with types of work</strong></td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Direct impact</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">[redacted]</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">&nbsp;</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Anti-synergy with empirical ML</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Skill-building and learning</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">[redacted]</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">MLAB</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Setting policy, opinion making, some research</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Exploration and fit testing</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">[redacted]</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Try lobbying, talk to policy folk, learn about EU AI office, part-time podcasting</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Setting policy, opinion making, some research</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Credibility and networking</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">[redacted]</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Publish work, do a graduate degree</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Setting policy, opinion making, being at a lab</td></tr></tbody></table></figure><h2 data-internal-id=\"How_important_are_different_properties_of_work_to_me_\">How important are different properties of work to me?</h2><figure class=\"table\"><table><tbody><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><strong>Property</strong></td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><strong>If applicable: Preferred direction</strong></td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><strong>Priority</strong></td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Autonomy</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">&nbsp;</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">[redacted]</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Guidance</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">&nbsp;</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">[redacted]</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Feedback</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">&nbsp;</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">[redacted]</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Free time</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">&nbsp;</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">[redacted]</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Flexible work hours</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">&nbsp;</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">[redacted]</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Stable income</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">&nbsp;</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">[redacted]</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Time pressure</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">[redacted]</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">[redacted]</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Sign certainty</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">&nbsp;</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">[redacted]</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Impact magnitude certainty</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">&nbsp;</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">[redacted]</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Focus on one project vs. many balls</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">[redacted]</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">[redacted]</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Social interaction, peers</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">&nbsp;</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">[redacted]</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Being relaxed and myself</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">&nbsp;</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">[redacted]</td></tr></tbody></table></figure><p>My personal career doc ends with a \u201cNext steps\u201d section that I\u2019m not including. It\u2019s a mix of talking to specific people and thinking for myself to resolve object-level uncertainties, uncertainties about what different kinds of work are like, and learning which heuristics for choosing work (steps) people I admire use.</p>", "user": {"username": "Chi"}}, {"_id": "EZennyFKLAZccDg36", "title": "New story about Dustin Moskovitz, EA, his meeting with Joe Biden, plans for the 2024 election, and his beef with Marc Andreessen over AI", "postedAt": "2024-03-20T20:32:36.273Z", "htmlBody": "<p>Hey folks, popping in here to share a new piece that I thought might be of interest to friends in EA. I have a feeling you'll know a few of the people mentioned, and there are lots of exclusive details about Dustin Moskovitz's work that you might not know about.</p><p>Our publication, Puck, requires a subscription \u2014 but you can trade an email to read a story, do a free trial, or consider subscribing! I write about political and philanthropic donors, and am going to spend a lot of the year covering their moves ahead of the November race.</p><p><a href=\"https://puck.news/dustinbucks/\">Here's</a> the piece, and here are the first few paragraphs:</p><blockquote><p>On a Thursday in February, the same morning that he was scheduled to meet with the widow of <strong>Alexey Navalny</strong>, <strong>Joe Biden </strong>found himself at the Fairmont Hotel, atop Nob Hill, staring at a total stranger half his age. <strong>Dustin Moskovitz</strong>, the 39-year-old billionaire seated across from him, was probably more responsible than any other donor for vaulting Biden into the presidency. And yet, somehow, the two had never met.</p><p>Moskovitz, like the other Harvard kids who won the roommate lottery with <strong>Mark Zuckerberg</strong> and became Silicon Valley royalty, is often dismissed as some accidental co-founder of Facebook, the ultimate example of being in the right place at the right time. But Moskovitz caught lightning in a bottle a <i>second</i> time with Asana, the public software company he founded in 2008. He and his partner in all things, former <i>Wall Street Journal </i>reporter <strong>Cari Tuna</strong>, whom he met on a blind date, would become the patron saints of effective altruism\u2014particularly during the post-<strong>S.B.F. </strong>correction\u2014with $25 billion to dole out through their Open Philanthropy charity.&nbsp;</p><p>Moskovitz is unlike any other ultra-wealthy donor I have covered: insanely intelligent and well-read on political topics, but also skeptical, almost hostile, toward the influence-peddling game. For all his earnestness, he has sometimes <a href=\"https://puck.news/can-zuckerbergs-old-roommate-strong-arm-washington/\"><strong>appeared</strong></a> to shirk the civic duty he extols, shying away from using his money to achieve his political objectives. In September 2016, before committing $20 million to groups backing <strong>Hillary Clinton</strong>, he wrote a Medium essay entitled <a href=\"https://medium.com/@moskov/compelled-to-act-1413930041ee\"><strong>\u201cCompelled to Act</strong></a>\u201d that bared his introspection. \u201cThis decision was not easy, particularly because we have reservations about anyone using large amounts of money to influence elections,\u201d he wrote. \u201cThat said, we believe in trying to do as much good as we can, which in this case means using the tools available to us.\u201d He would later express regret about getting involved in the election too late.&nbsp;</p><p>Four years later, Moskovitz spent more $50 million to elect Biden\u2014and the real number, accounting for dark money donations, is probably more like twice that, I\u2019m told. The ostensible predicate of the Moskovitz-Biden summit at the Fairmont, previously unreported, was to discuss safety in artificial intelligence, a topic that has consumed Dustin during the last year or two, as it has for so many effective altruists. But the subtext was obvious: Wouldn\u2019t it be <i>great</i> if Moskovitz and Tuna could fork over that amount of cash again? Shortly thereafter, the couple cut at least one \u201csuper-max\u201d check ($929,000) to the Biden campaign, I\u2019m told, and I hear this is just the start. \u201cCari and I were excited to meet President Biden and thank him for his work,\u201d Moskovitz told me.</p></blockquote>", "user": {"username": "teddyschleifer"}}, {"_id": "EcgzA5Wp6xZezKTCm", "title": "#183 \u2013  Causation without correlation, money and happiness, lightgassing, hype vs value, and more (Spencer Greenberg on the 80,000 Hours Podcast)", "postedAt": "2024-03-20T19:55:28.947Z", "htmlBody": "<p>We just published an interview: <a href=\"https://80000hours.org/podcast/episodes/spencer-greenberg-money-happiness-hype-value/\">Spencer Greenberg on causation without correlation, money and happiness, lightgassing, hype vs value, and&nbsp;more</a>. <a href=\"https://open.spotify.com/episode/1ZGtbTEZvI6WCq25ahhbbe\">Listen on Spotify</a> or click through for other audio options, the transcript, and related links. Below are the episode summary and some key excerpts.</p><h2><strong>Episode summary</strong></h2><blockquote><p><i>When a friend comes to me with a decision, and they want my thoughts on it, very rarely am I trying to give them a really specific answer, like, \u201cI solved your problem.\u201d What I\u2019m trying to do often is give them other ways of thinking about what they\u2019re doing, or giving different framings.</i></p><p><i>A classic example of this would be someone who\u2019s been working on a project for a long time and they feel really trapped by it. And someone says, \u201cLet\u2019s suppose you currently weren\u2019t working on the project, but you could join it. And if you joined, it would be exactly the state it is now. Would you join?\u201d And they\u2019d be like, \u201cHell no!\u201d It\u2019s a reframe. It doesn\u2019t mean you definitely shouldn\u2019t join, but it\u2019s a reframe that gives you a new way of looking at it.</i></p><p>- Spencer Greenberg</p></blockquote><p>In today\u2019s episode, host Rob Wiblin speaks for a fourth time with listener favourite Spencer Greenberg \u2014 serial entrepreneur and host of the <a href=\"https://podcast.clearerthinking.org/\"><i>Clearer Thinking</i> podcast</a> \u2014 about a grab-bag of topics that Spencer has explored since his <a href=\"https://80000hours.org/podcast/episodes/spencer-greenberg-stopping-valueless-papers/\">last appearance on the show</a> a year ago.</p><p>They cover:</p><ul><li>How much money makes you happy \u2014 and the tricky methodological issues that come up trying to answer that question.</li><li>The importance of hype in making valuable things happen.</li><li>How to recognise warning signs that someone is untrustworthy or likely to hurt you.</li><li>Whether Registered Reports are successfully solving reproducibility issues in science.</li><li>The personal principles Spencer lives by, and whether or not we should all establish our own list of life principles.</li><li>The biggest and most harmful systemic mistakes we commit when making decisions, both individually and as groups.</li><li>The potential harms of lightgassing, which is the opposite of gaslighting.</li><li>How Spencer\u2019s team used non-statistical methods to test whether astrology works.</li><li>Whether there\u2019s any social value in retaliation.</li><li>And much more.</li></ul><p><i>Producer and editor: Keiran Harris</i><br><i>Audio Engineering Lead: Ben Cordell</i><br><i>Technical editing: Simon Monsour, Milo McGuire, and Dominic Armstrong</i><br><i>Transcriptions: Katy Moore</i></p><h2><strong>Highlights</strong></h2><h3><strong>Does money make you happy?</strong></h3><blockquote><p><strong>Spencer Greenberg:</strong> So these kinds of methods that are asking about overall life evaluation \u2014 I\u2019ll call them \u201clife satisfaction measures\u201d \u2014 people have long found that there tends to be a logarithmic relationship between that and income. And what that means is that essentially every time you double your income, you get the same number of points increase from this life satisfaction measure.</p><p>So then there\u2019s this question of, OK, people\u2019s life satisfaction goes up, but what about how good they feel in the moment? Let\u2019s call that \u201cwellbeing\u201d instead of life satisfaction. Wellbeing would be like, you ping someone at a random point of the day, and you say something like, \u201cHow good do you feel right now?\u201d Or you could ask other questions about their emotional state, like that they are feeling happy or that they laugh today, or things like that, right? But it\u2019s the distinction between their evaluation of how good their life is, which is life satisfaction, and how good they feel in the moment, which is wellbeing.</p><p>And a lot of people assume that the relationship should be similar: the wealthier you are, the more your wellbeing tends to go up. And of course, these are associations. So we\u2019re talking about on average. But Daniel Kahneman \u2014 Nobel Prize winner, <a href=\"https://podcast.clearerthinking.org/episode/072/daniel-kahneman-beyond-cognitive-biases-improving-judgment-by-reducing-noise/\">former guest on my podcast, <i>Clearer Thinking</i></a>, who\u2019s someone I tremendously respect \u2014 he published a paper that found a really interesting finding: that as people got wealthier, yes, indeed, their wellbeing did go up, but it kind of flattened off. I think it was at about like $75,000 a year or something like that, it flatlined, so they stopped getting any benefit for their wellbeing on average as they got wealthier.</p><p>This was big news. It was quite surprising to many people, and kind of a big story at the time. They\u2019re working with pretty large datasets, and they actually saw this flattening effect.</p><p>So that\u2019s where the interesting twist comes into the story. This other researcher, Killingsworth, using a significantly higher quality dataset than Kahneman had access to, basically does his own analysis and finds, lo and behold, that actually wellbeing, much like life satisfaction, continues going up logarithmically. So if you double your income, you get the same unit increase in wellbeing. And this was kind of a shock because, well, what the heck was going on with the Kahneman paper? You know, everyone greatly respects Daniel Kahneman. Why would they find such a difference of opinion?</p><p>Now Kahneman, much to his credit, ends up talking to Killingsworth, and they team up for what\u2019s called an adversarial collaboration. This is something I think is incredibly valuable for science, and I hope will happen a lot more, where researchers who disagree actually will write a paper together to try to explore their disagreement and see if they can come to an agreement, or at least figure out the source of their disagreement. So <a href=\"https://www.pnas.org/doi/10.1073/pnas.2208661120\">they worked together on a paper</a> \u2014 along with Barbara Mellers, who they collaborated with; she does a lot of work on adversarial collaborations \u2014 and they ended up finding that actually Killingsworth was correct. Indeed, as you go up in income, there\u2019s a logarithmic relationship with wellbeing.</p><p>And they try to figure out why was it in Kahneman\u2019s data that he didn\u2019t find this? What they end up concluding is that the way Kahneman measured happiness was not very ideal. It was three binary variables that kind of get combined together, basically the variables around \u201cDid you feel good?\u201d The problem with it is that almost everyone said yes on these variables, and that meant that it only really had the ability to distinguish different levels of unhappiness, because if you were like \u201cOK\u201d to \u201cgood,\u201d you would just agree to the three variables, and therefore it all was really measuring was the unhappy side.</p><p><strong>Rob Wiblin:</strong> Do people call this top censoring or top\u2026 like the measure caps out where, if you\u2019re feeling like kind of content, then you already have the maximum score, so it can\u2019t detect you becoming happier beyond that, going from happy to really happy?</p><p><strong>Spencer Greenberg:</strong> Yeah. It basically was that. It was just detecting sort of unhappiness. And then in the new paper, in the adversarial collaboration, which is really fascinating \u2014 it\u2019s called \u201c<a href=\"https://www.pnas.org/doi/10.1073/pnas.2208661120\">Income and emotional well-being: A conflict resolved</a>\u201d \u2014 they find that there\u2019s this fairly strange effect with, for unhappy people, you do get this capping out effect. So if you just look at a certain percentile of unhappiness \u2014 let\u2019s say the 15th percentile of most unhappy people \u2014 as they get more and more income, it does actually cap out. It stops benefiting them. We don\u2019t know for sure why that is. Possibly it\u2019s because when you\u2019re in the bottom 15th percentile of happiness, maybe the things that are making you unhappy at that point are, maybe there\u2019s a limited ability for income to change them. We don\u2019t really know.</p><p>But basically they found that it was something about that measure. And indeed, now they both agree that wellbeing goes up logarithmically with income.</p></blockquote><h3><strong>Hype vs value</strong></h3><blockquote><p><strong>Spencer Greenberg:</strong> \u201cValue,\u201d I\u2019m referring to <a href=\"https://www.clearerthinking.org/post/your-intrinsic-values-why-they-matter-and-how-to-find-them\">intrinsic values</a> \u2014 so the things that people fundamentally care about for their own sake, not as a means to other ends. So it could be like your own happiness, the flourishing of your loved ones, being honest, believing true things, learning \u2014 things like that. These are, to me, the things that we should as a society and individually be trying to create more of.</p><p>Then we have the category of what I\u2019m going to call \u201chype.\u201d Hype refers to something being cool, exciting, having a buzz around it. I\u2019m also going to put one value in the hype category, which is social status \u2014 which is, I think, a genuine human value: people want other people to look up to them and think they are high status. But I\u2019m putting it in the hype category because I think for this analysis, it better fits in hype rather than values.</p><p>OK, so now we have these two kinds of things. We\u2019ve got hype and we have value. And we could imagine a coordinate system: you\u2019ve got value on one axis, hype on the other axis. And you could start plotting things in this system.</p><p>So let\u2019s start with pure hype. We\u2019ve got something like art NFTs that nobody even likes looking at. They\u2019re just like ugly art NFTs, right? These are really not getting anyone any value of theirs, except maybe social status \u2014 which, remember, we put in the hype category. But they do have, at least for a while, they had a big buzz around them. They were considered cool by a certain crowd. So they were just pure hype. It\u2019s pure hype, no value.</p><p>Then we have things that are pure value, no hype. Let\u2019s say doorknobs. Doorknobs are just really good at what they do. Like, so good at what they do, you don\u2019t even think about it. When you need a doorknob, you buy a doorknob, you\u2019re satisfied. You never think about it again. No hype whatsoever. I\u2019ve never heard anyone rave about doorknobs.</p><p>Then we have things in between. I think Tesla would be a really good example. Tesla definitely produces some value. It makes cars that people really enjoy driving. It has some positive environmental impact. It also has incredible hype. Elon Musk is really good at building a sense of excitement and coolness and social status for doing a thing. And obviously, Tesla is extremely successful.</p><p>And the reason I\u2019ve been thinking about this is I think there are some things that succeed on pure value, and there\u2019s some things that succeed on pure hype. But I think in reality, most of the time, when things succeed, it\u2019s by getting a combination of hype and value. And I think hype is something that I don\u2019t like, and I have a negative feeling around it. And I think because of that, I\u2019ve underestimated the importance of it to accomplish things in the real world. And, of course, if you\u2019re trying to create hype, you should do it in an ethical way; you shouldn\u2019t be lying or manipulating people. But I think there are ethical ways to help get people excited.</p><p>So I view it as a kind of blind spot for me. I also think it\u2019s a blind spot for the effective altruism community, because I think, like me, many effective altruists are like, hype, ick. Yuck. Stay away. But the reality is it often is hype that gets people to do things together. It gets people involved. It gets people excited to actually carry out changes in the world or to get a product to succeed.</p></blockquote><h3><strong>Warning signs that someone is bad news</strong></h3><blockquote><p><strong>Spencer Greenberg:</strong> So the idea is not if someone ever shows one of these patterns, they\u2019re bad news. It\u2019s more like, think of it as a continuum: if someone repeatedly shows these patterns to a strong degree, you might question whether they\u2019re a safe person, or whether they might be untrustworthy or hurt you.</p><p>So let\u2019s dig into the specific things. The first set of patterns are around things you might call dangerous psychopathy or malignant narcissism. And so the things, you notice that the person seems to be manipulating you or other people. You notice that they\u2019re inconsistent; like, they\u2019ll say one thing one time and a different thing at another time. Or you catch them being dishonest \u2014 and again, it could be to you, or maybe you just see them being dishonest with other people. A self-centredness where they seem much more interested in their own interests than in other people\u2019s interests. Quick, very intense anger. So they suddenly become enraged. And then finally, lack of empathy.</p><p>And I think what this cluster is really getting at are two personality disorders: antisocial personality disorder and narcissistic personality disorder. I will say not everyone with these disorders should be avoided. Like, there can be people who are good, ethical people who have these disorders \u2014 especially if they understand that they have these disorders; they\u2019re seeking treatment, they\u2019re working on themselves, and they have other compensating factors that help them avoid some of the dangers of having these disorders. But when you have someone who has these disorders to a strong degree, they\u2019re in total denial, and they\u2019re not working on it at all, it can pose quite a bit of danger.</p><p>The second cluster is around immaturity. And so this would be things like extreme emotionality. Like the person gets extremely upset over very minor-seeming things. The person seems to avoid topics when they\u2019re upset. So instead of telling you, \u201cThat bothered me,\u201d they just won\u2019t talk about it; they\u2019ll shut down. They have really poor communication. They\u2019re lacking responsibility or accountability: maybe they mess up, but they refuse to apologise, or they just won\u2019t take any accountability for what they did. And general poor handling of relationships. Like, if you see they have a bad relationship with everyone else in their life, that\u2019s not a great sign.</p><p>And I think this immaturity category, maybe it\u2019s not as potentially serious, but I think it really can be a red flag in relationships. You could get in a really bad pickle, where someone will do something, it\u2019s harmful, but then they don\u2019t take responsibility for it. Or they\u2019ll be really angry at you about something: maybe you made a really minor mistake, but it wasn\u2019t that serious, according to relatively objective third-party observers. But this person\u2019s extremely upset about it, but then they don\u2019t even tell you, and they\u2019re just simmering with rage at you. So there\u2019s a lot of things that I think can come out here, that actually, I do think it\u2019s a pretty important cluster.</p><p>The third and final cluster is a pettiness cluster. This would be things like they talk negatively about a lot of people, like saying negative things about their other friends to you; gossiping in a way that\u2019s harmful, where they\u2019re spreading information that could hurt people; and extreme judgmentalness, where they\u2019re like, that person sucks because of this little minor defect.</p><p>So this category, the pettiness, I don\u2019t think I would have thought of this category, but I do see why it can kind of be insidious, where someone can be causing harm in a social group through these kinds of behaviours.</p></blockquote><h3><strong>Important life decisions</strong></h3><blockquote><p><strong>Spencer Greenberg:</strong> One of the really common things that happens is that when we have a problem, we\u2019re very aware of it when it first starts or when there\u2019s a big change in it. But then we get very acclimated to it very fast. So one thing that I just try to think about is: what are the problems that are happening in your life that maybe you\u2019re so used to, you don\u2019t even view them as a problem anymore, but if you step back and start it over, you\u2019d be like, \u201cOh wait, that\u2019s a problem\u201d?</p><p>We all see examples of this in really little things. Maybe there\u2019s a hole in your counter or whatever, and at first it\u2019s annoying, but then you\u2019re so used to it and you just don\u2019t fix it for years, right? Really, you should have fixed it right away. But the second best thing would be to just notice it today and just get it fixed, instead of just working around it.</p><p>And I think we do that for much more serious things. Like someone who has significant depression and they\u2019re just used to being depressed, and they kind of forget that there\u2019s anything else you could be, because it\u2019s been so many years. And it\u2019s like, maybe you should be making a decision around your depression, and actively engaging with what you want to do about it.</p><p><strong>Rob Wiblin:</strong> Yeah. So not realising that there\u2019s a decision at all, a big potential failure. What are some other ones?</p><p><strong>Spencer Greenberg:</strong> I think another big one is that people will accept one framing of a problem. I feel like when a friend comes to me with a decision, and they want to discuss it and they want my thoughts on it, very rarely am I trying to give them a really specific answer, like, \u201cI solved your problem.\u201d What I\u2019m trying to do often is give them other ways of thinking about what they\u2019re doing, or giving different framings.</p><p>And I think this is a powerful thing we can do for ourselves. Sometimes the framings are more about\u2026 We make it too binary \u2014 like \u201cI either quit my job or I stick with my job\u201d \u2014 and we don\u2019t think about, \u201cMaybe I could switch roles at the same job, or I could renegotiate details of my role\u201d or other things like that.</p><p>So sometimes that\u2019s where we\u2019re stuck on framing. But sometimes it\u2019s just coming at the problem differently. A classic example of this would be someone who\u2019s been working on a project for a long time and they feel really trapped by it. And someone says, \u201cLet\u2019s suppose you currently weren\u2019t working on the project, but you could join it. And if you joined, it would be exactly the state it is now. Would you join?\u201d And they\u2019d be like, \u201cHell no!\u201d It\u2019s a reframe. It doesn\u2019t mean you definitely shouldn\u2019t join, but it\u2019s a reframe that gives you a new way of looking at it.</p><p>So I think this can be quite powerful: we get stuck in these frames on decisions, and asking ourselves, \u201cIs there another way of looking at this?\u201d And sometimes talking to other people can be a really helpful way to get those reframes, but sometimes we can generate them ourselves.</p></blockquote><h3><strong>Personal principles</strong></h3><blockquote><p><strong>Spencer Greenberg:</strong> So I think of \u201cvalues\u201d as the intrinsic values, the things you fundamentally care about, that you value for their own sake. A \u201cprinciple,\u201d to me, is a decision-making heuristic. So instead of having to rethink every decision from scratch, you\u2019re like, \u201cI have a principle, and it helps me make my decisions quickly. It gives me a guideline of how to make my decision.\u201d</p><p>And a good principle, not only does it make your decisions more efficient to get your values \u2014 so it speeds you up \u2014 but it actually makes it more reliable that you get to your values than if you try to rethink things from scratch every time. So a good principle can help orient you on cases where maybe your willpower wouldn\u2019t be there, or where maybe you might second guess yourself and actually not do the thing that\u2019s most valuable.</p><p>Just to give you some examples, one of my principles is \u201cAim not to avoid anything valuable just because it makes you feel awkward, anxious, or afraid.\u201d I have that principle, so when I\u2019m in a situation where there\u2019s something that\u2019s making me feel awkward or making me feel anxious, that\u2019s valuable to do, I just go immediately to, yeah, I have to do that thing. The fact that it\u2019s awkward or anxiety-provoking is not an excuse to me, because that\u2019s one of my deep principles. And the thing is, if I try to think about it from scratch every time, not only is it slower, but it also is easy to talk myself out of that thing.</p><p>Another one of my principles is \u201cAim to have opinions on most topics that are important to you, but view your beliefs probabilistically. Be quick to update your views as you get new evidence.\u201d Here, if something I think is really important in society or for my own life, I want to form an active opinion on it. So if someone said, \u201cWhat do you think about this?\u201d I would say, \u201cHere\u2019s what I think\u201d \u2014 but simultaneously, I want to be very flexible to new evidence and be ready to adjust my view at the drop of a hat if strong evidence comes in. Not adjust at the drop of a hat with weak evidence, but adjust at the drop of a hat with strong evidence.</p><p>So that\u2019s something I aspire to, and I think that\u2019s helpful when someone challenges me. I put a lot of my opinions on the internet, and if someone\u2019s like, \u201cWhat about this counterevidence?,\u201d that principle helps orient me towards not being so reactive and being like, \u201cAhh, I\u2019m being attacked!,\u201d but being like, \u201cIf they gave me strong evidence, my principle says I have to change my view. So did they give me strong evidence?\u201d</p><p>A simpler principle can be more action guiding and give you less room for making excuses or second guessing yourself. A more complex principle can take into account more aspects of the world to show that you miss fewer edge cases. Because it\u2019s not that a principle will be right every single time; it\u2019s that it will be right most of the time, and it will help you be more efficient and help you avoid second guessing yourself too much, or willpower issues and things like that.</p><p>Let me read you my principle about lying. I say, \u201cTry never to tell lies. White lies are OK only when they\u2019re what the recipient would prefer.\u201d So I\u2019m trying to say there is some wiggle room. Like, if you go to your friend\u2019s art performance, and they come up to you excitedly, like, \u201cWhat did you think?\u201d and you actually thought it sucked, that\u2019s a tough one. I\u2019m going to give myself some leeway to be like, if I think this person would rather I express appreciation from their art \u2014 they\u2019d rather I lie \u2014 then maybe it\u2019s OK.</p></blockquote><h3><strong>Lightgassing</strong></h3><blockquote><p><strong>Spencer Greenberg:</strong> Lightgassing is a phrase I came up with to describe a <a href=\"https://twitter.com/SpencrGreenberg/status/1708233415638609997\">phenomenon that I kept encountering</a> but I\u2019d never had a word for.</p><p>It\u2019s kind of the opposite of gaslighting, so why don\u2019t we start with talking about what gaslighting is? It comes from an <a href=\"https://en.wikipedia.org/wiki/Gaslight_(1944_film)\">old film</a> where there was this man who would mess with the gaslights in their house that produce light, but then trick his partner into thinking that he hadn\u2019t done it, so she started to doubt her own senses and her own sanity. So this idea of gaslighting is when you kind of deny someone\u2019s senses or deny their reality, so that they start doubting their own senses or sense of reality.</p><p>Lightgassing, on the other hand, is kind of the opposite of this. The way it works is that sometimes when we\u2019re dealing with someone who, let\u2019s say, is upset, they might say something that we really don\u2019t believe is true, but they want us to reinforce that thing because it\u2019s really deeply important to them.</p><p>The most classic example of this would be with someone who just had a breakup, and they\u2019re talking about what an asshole their partner was. But maybe you don\u2019t think their partner is an asshole at all. But they\u2019re giving all this social pressure for you to tell them that, yes, their partner was an asshole. And this is kind of the opposite of gaslighting. Because whereas gaslighting is getting someone to doubt their real sensory perceptions that are actually true, lightgassing is when you\u2019re actually reinforcing false sensory perceptions.</p><p>To me, this came about most dramatically in a situation where one of my loved ones was dealing with very severe mental health challenges and was experiencing actual delusions, like actual straight-up delusions about what was true. I realised I was in a very strange situation, where there was a lot of pressure to reinforce their delusions that I knew were false, and I still wanted to be supportive to them, but I started feeling very uncomfortable at this idea of reinforcing their delusions. But if I didn\u2019t reinforce it, I felt like it was going to make them upset or angry.</p><hr><p><strong>Rob Wiblin:</strong> So you got into thinking about this because a friend of yours was having delusions, I guess. And what did you conclude about how one ought to deal in these situations?</p><p><strong>Spencer Greenberg:</strong> First of all, I\u2019ll say we\u2019ve <a href=\"https://www.clearerthinking.org/post/how-to-offer-emotional-validation-and-how-not-to\">written an essay</a> on our website, clearerthinking.org, if you want to check it out, you want to dive deeper into this. But I will say, I think fortunately, the kinds of strategies you use actually are similar, whether it\u2019s a really extreme case \u2014 like someone experiencing delusions \u2014 or a more mild case, where maybe someone\u2019s just really angry at their ex-partner or something like that.</p><p>What I try to do is validate the person\u2019s feelings without validating false perceptions they have. And that doesn\u2019t mean you tell them they\u2019re wrong. If someone\u2019s upset, it\u2019s usually not appropriate to be like, \u201cYou\u2019re wrong about X, Y, and Z.\u201d That\u2019s probably not the right time. But you can still be there for them. You can show them compassion, you can tell them you care about them, and you can validate the feelings they\u2019re feeling without agreeing to the specific factual errors they\u2019re making.</p><p>So an example if the person is delusional: let\u2019s say they think someone\u2019s coming after them, which is not true. You don\u2019t have to be like, \u201cOh no, someone\u2019s coming after you. That\u2019s so scary!\u201d You can say, \u201cThat sounds like a really frightening experience.\u201d So you\u2019re kind of saying, \u201cGiven that you think someone\u2019s coming after you, that makes sense that you\u2019re really scared. I\u2019m here for you. I want to help you.\u201d</p></blockquote>", "user": {"username": "80000_Hours"}}, {"_id": "mMLCQ7GYemRNZ3D22", "title": "Summary: Training Effective Altruism (Mehmood et al.)", "postedAt": "2024-03-20T17:54:14.828Z", "htmlBody": "<p><a href=\"https://globalprioritiesinstitute.org/mehmood-naseer-chen-training-effective-altruism/\"><i>Training Effective Altruism</i></a><i>&nbsp;is a Global Priorities Institute Working Paper by Sultan Mehmood, Shaheen Naseer, and Daniel L. Chen. This post is part of my</i><a href=\"https://forum.effectivealtruism.org/s/aY38LaKmqEtoaqyFq\"><i>&nbsp;sequence</i></a><i>&nbsp;of GPI Working Paper summaries.</i></p><h2 data-internal-id=\"Results\">Results</h2><p>After Pakistani deputy ministers (of which, 70% joined for \u201cjob perks and power\u201d) watched a \u201cutilitarian\u201d lecture on empathy and its personal benefits, they\u2026</p><ul><li>donated 6% more for no benefit when acting as a dictator in a game and 20% more to charity at their own expense in another game (a 12% and 33% increase relative to the placebo group, respectively).</li><li>were 40% more likely to use \u201cus\u201d instead of \u201cthem\u201d on social media and 20% more likely to use \u201cwe\u201d instead of \u201cI\u201d (about double the percentages of the placebo group).</li><li>were 25% more likely to donate blood when urgently requested by a blood bank (an 80% increase relative to the placebo group).<ul><li>They were only willing to give blood when the bank specifically requested their blood type. The authors state this is evidence they acted as effective altruists\u2014they donated only when they believed it would likely be helpful.</li></ul></li><li>were 20% more likely to choose a book on empathy (a 50% increase relative to the placebo group).</li><li>scored 10% higher on policy scenario assessments of teamwork and cooperation (a 20% increase relative to the placebo group).</li></ul><p>\u2026 and four to six months after treatment, they\u2026</p><ul><li>were 20% more likely to visit an orphanage instead of a talk by a senior bureaucrat four months after the treatment (an 80% increase relative to the placebo group).</li><li>were 20% more likely to volunteer at an impoverished school instead of attending a senior bureaucrat\u2019s talk, six months after the treatment.</li><li>rated emotional intelligence 1 point more important to policymaking (on a 5-point scale) than the placebo group, six months after the treatment.</li><li>performed 0.6 standard deviations higher in a teamwork workshop six months after the treatment, as scored by former Supreme Court judges, prominent academics, and former senior deputy ministers.</li></ul><p>In contrast, after ministers watched a lecture on how empathy is \u201cmalleable\u201d (a practicable skill that can be improved), they found no statistically significant effects. Likewise, ministers who watched a mixed lecture combining the utilitarian lecture with the malleability one had no statistically significant effects.</p><h2 data-internal-id=\"Experimental_design\">Experimental design</h2><h3 data-internal-id=\"Sampling\">Sampling</h3><ul><li>At a training academy in Pakistan, the researchers studied deputy ministers, who are high-stakes decision-makers and advise the President, Prime Minister, and Cabinet Ministers.</li><li>~1% of applicants for the job are chosen from ~15,000&nbsp;based on their exam performance, psychological assessments, and interviews.</li><li>~70% reported they mainly joined for job perks and power (self-interested reasons).</li><li>They were randomly assigned into 4 groups, each having ~53 participants.</li></ul><h3 data-internal-id=\"Treatment\">Treatment</h3><ul><li>They carefully watched a lecture and wrote a brief 500-word summary.</li><li>The (effective) utilitarian lecture presented evidence for empathy being self-serving and narratives of benevolent former deputy ministers. The lecture stated its core message:<br>\u201cQualitative and quantitative evidence backs the idea that showing empathy is good for you. It is not just the right thing to do but also the most sensible thing to do for your performance.\u201d</li><li>The unsuccessful malleability lecture\u2019s main point:<br>\u201cQualitative and quantitative evidence backs the idea that empathy is not fixed but is malleable. It is a skill that can be developed.\u201d</li><li>The unsuccessful mixed utilitarian-malleability group\u2019s lecture was a mix of the two above, and the placebo group had a lecture on macroeconomics.</li></ul>", "user": {"username": "NicholasNicholas"}}, {"_id": "6k86Ha2mWcQ3u78Td", "title": "Some thoughts from a University AI Debate", "postedAt": "2024-03-20T17:03:06.440Z", "htmlBody": "<p>Last month we held an AI Safety Debate with the UCL EA Society.</p><p>I thought I'd share a few thoughts from running the event: both about community building, because I think the event went well, and more broadly about AI Safety. Not of all these thoughts are mine: thank you to Erin and Otto for sharing theirs.&nbsp;</p><p>A full YouTube recording is here:</p><figure class=\"media\"><div data-oembed-url=\"https://www.youtube.com/watch?v=mcozzJbLbZI&amp;pp=ygUPVUNMIEFJIFNvY2lldHkg\"><div><iframe src=\"https://www.youtube.com/embed/mcozzJbLbZI\" allow=\"autoplay; encrypted-media\" allowfullscreen=\"\"></iframe></div></div></figure><p>&nbsp;</p><h3>Community-Building Takes</h3><ul><li><strong>Entertainment Value</strong>: Around 60/70 people attended, which is around 10x our normal attendance for a typical event. I think this is primarily because a debate is interesting to watch than a speaker event, or a workshop. Perhaps this was already obvious others, but if you are looking for an event to reach a big audience, entertainment value is important.&nbsp;</li><li><strong>Disagreeing about AI risk is okay</strong>: before I was concerned that the event might be overly polarising. The opposite happened \u2013 despite disagreements about 'rogue AI' scenarios, the speakers agreed broadly that: AI could be transformative for humanity, misuse risks are serious, and that regulation/evals are important. This may not have happened if the people arguing against x-risk were e/accs.&nbsp;</li><li><strong>X-Risk sentiment in the audience</strong>: at one point in the debate, one participant asked the audience who thought &nbsp;AI was an existential risk. From memory, around 2/3s of students put up their hands. This shouldn't be too surprising, given that the 'public' is worried about about x-risk (e.g. <a href=\"https://today.yougov.com/topics/technology/survey-results/daily/2023/04/03/ad825/3\">here</a>). (Although, obviously, this wasn't a representative sample.)</li></ul><h3>AI Things</h3><ul><li><strong>AI Ethics folks aren't aware of the common ground: </strong>At one point in the debate, the \"x-risk is a distraction\" argument was brought up. In response, Reuben Adams mentioned that there is potential common ground between \"ethics\" and \"safety\" concerns, through evals. This seemed to have genuinely surprised the Science/Technology Professor (Jack Stilgoe) who was arguing against x-risk. Perhaps this is a result from Twitter echo-chambers? Who knows.&nbsp;</li><li><strong>(Bio) Misuse Risks were most convincing to the audience</strong>: this seemed like a particularly persuasive threat model, based on conversations after. I don't think this is particularly novel: I believe bio-terror was a prominent theme in the discussion of 'catastrophic risk' at the UK AI Summit last November. &nbsp;</li></ul><p>Feel free to reach out if you are a community-builder and &nbsp;you'd like advise on organising a similar event.&nbsp;</p>", "user": {"username": "hptc123"}}, {"_id": "KZqGbcrjp3Zoc2jgu", "title": "What are good lit references about International Governance of AI?", "postedAt": "2024-03-20T15:51:19.724Z", "htmlBody": "<p>Prompt: we are in 2028. What does the world look like AI-wise and which aspects are the most impacted? Which are the major risks? Think agency, international regime, bad actors and frontier systems, etc.</p><p>(I do know about Matthijs M. Maas excellent work)</p>", "user": {"username": "Vaipan"}}, {"_id": "Szu2kZ9CoveKvavfy", "title": "An example of how to write a good job description ", "postedAt": "2024-03-20T14:54:07.908Z", "htmlBody": "<p>In my opinion, <a href=\"https://jobs.ashbyhq.com/openphilanthropy/0c070721-972a-48c8-b882-b4eba9d982ab\">this</a> job description for a role which is currently open at Open Phil is pretty much <i>a thing of beauty</i>. The care and thoughtfulness that has gone into crafting a crystal-clear description of the role and what they are looking for, is very impressive. I'd encourage anyone who is hiring to take a look at it, and potentially use it as an example of best practice in terms of how to write a good job description.&nbsp;</p>", "user": {"username": "Forumite"}}, {"_id": "aF6nh4LW6sSbgMLzL", "title": "Updates on Community Health Survey Results", "postedAt": "2024-03-20T11:56:44.601Z", "htmlBody": "<h1>Summary</h1><ul><li>Satisfaction with the EA community<ul><li>Reported satisfaction, from 1 (Very dissatisfied) to 10 (Very satisfied), in December 2023/January 2024 was lower than when we last measured it shortly after the FTX crisis at the end of 2022 (6.77 vs. 6.99, respectively).&nbsp;</li><li>However, December 2023/January 2024 satisfaction ratings were higher than what people&nbsp;<i>recalled</i> their satisfaction being \u201cshortly after the FTX collapse\u201d (and their recalled level of satisfaction was lower than what we measured their satisfaction as being at the end of 2022).</li><li>We think it\u2019s plausible that satisfaction reached a nadir at some point later than December 2022, but may have improved since that point, while still being lower than pre-FTX.</li></ul></li><li>Reasons for dissatisfaction with EA:<ul><li>A number of factors were cited a similar number of times by respondents as&nbsp;<i>Very important&nbsp;</i>reasons for dissatisfaction, among those who provided a reason: Cause prioritization (22%), Leadership (20%), Justice, Equity, Inclusion and Diversity (JEID, 19%), Scandals (18%) and excessive Focus on AI / x-risk / longtermism (16%).</li><li>Including mentions of&nbsp;<i>Important</i> (12%) and&nbsp;<i>Slightly important</i> (7%) factors, JEID was the most commonly mentioned factor overall.&nbsp;</li></ul></li><li>Changes in engagement over the last year<ul><li>39% of respondents reported getting at least slightly less engaged, while 31% reported no change in engagement, and 29% reported increasing engagement.</li></ul></li><li>Concrete changes in behavior<ul><li>31% of respondents reported that they had stopped referring to \u201cEA\u201d while still promoting EA projects or ideas, and 15% that they had&nbsp;<i>temporarily</i> stopped promoting EA. Smaller percentages reported other changes such as ceasing to engage with online EA spaces (6.8%), permanently stopping promoting EA ideas or projects (6.3%), stopping attending EA events (5.5%), stopping working on any EA projects (4.3%) and stopping donating (2.5%).</li></ul></li><li>Desire for more community change as a result of the FTX collapse<ul><li>46% of respondents at least somewhat agreed that they would like to see the EA community change more than it already has, as a result of the FTX collapse, while 26% somewhat or strongly disagreed.</li></ul></li><li>Trust in EA organizations<ul><li>Reported trust in key EA organizations (Center for Effective Altruism, Open Philanthropy, and 80,000 Hours) were slightly lower than in our December 2022 post-FTX survey, though the change for 80,000 Hours did not reliably exclude no difference.</li></ul></li><li>Perceived leadership vacuum<ul><li>41% of respondents at least somewhat agreed that \u2018EA currently has a vacuum of leadership\u2019, while 22% somewhat or strongly disagreed.</li></ul></li></ul><p>As part of the EA Survey, Rethink Priorities has been tracking community health related metrics, such as satisfaction with the EA community. Since the FTX crisis in 2022, there has been considerable discussion regarding how that crisis, and other events, have impacted the EA community. In the recent aftermath of the FTX crisis, Rethink Priorities fielded a supplemental survey to assess whether and to what extent those events had affected community satisfaction and health.&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/g5uKzBLjiEuC5k46A/ftx-community-response-survey-results\"><u>Analyses of the supplemental survey</u></a> showed relative reductions in satisfaction following FTX, while absolute satisfaction was still generally positive.</p><p>In this post, we report findings from a subsequent EA community survey, with data collected between December 11th 2023 and January 3rd 2024.<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"1\" data-footnote-id=\"otx6aj6teni\" role=\"doc-noteref\" id=\"fnrefotx6aj6teni\"><sup><a href=\"#fnotx6aj6teni\">[1]</a></sup></span></p><h1>Community satisfaction over time</h1><p>There are multiple ways to assess community satisfaction over time, so as to establish possible changes following the FTX crisis and other subsequent negative events. We have 2022 data pre-FTX and shortly after FTX, as well as the recently-acquired data from 2023-2024, which also includes respondents\u2019&nbsp;<i>recalled&nbsp;</i>satisfaction following FTX.<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"2\" data-footnote-id=\"haks8itnrld\" role=\"doc-noteref\" id=\"fnrefhaks8itnrld\"><sup><a href=\"#fnhaks8itnrld\">[2]</a></sup></span>&nbsp;Satisfaction ratings were provided on a 1-10 scale, with 1 being&nbsp;<i>Very dissatisfied,&nbsp;</i>and 10 being&nbsp;<i>Very satisfied</i>.</p><p>Comparing satisfaction levels of all respondents who completed the survey in 2022 (post-FTX) to all those who completed this followup survey at the end of 2023, we see a decrease in satisfaction (-.22 [-.41 - -.05] on the satisfaction scale, or&nbsp;<i>d&nbsp;</i>= -.13 [-.23 - -.02]). Comparing reported satisfaction only for respondents who we could individually match across both surveys, we likewise observed a decrease (-.41 points [-.86 - -.01],&nbsp;<i>d&nbsp;</i>= -.26 [-.53 - .01]).<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"3\" data-footnote-id=\"ero17std7n5\" role=\"doc-noteref\" id=\"fnrefero17std7n5\"><sup><a href=\"#fnero17std7n5\">[3]</a></sup></span>&nbsp;</p><p>However, as an additional measure, we also asked respondents to report, to the best of their ability, what they \u201crecall [their] satisfaction with the EA community to have been shortly after the FTX collapse at the end of 2022?\u201d. Interestingly, compared to&nbsp;<i>recalled</i> levels of satisfaction post-FTX, there is a small&nbsp;<i>increase</i> in satisfaction ratings in the followup survey in late 2023 (.27 [.07 - .49] points,&nbsp;<i>d&nbsp;</i>= .17 [.03 - .31]). In addition, we can observe that&nbsp; respondents\u2019 recalled post-FTX satisfaction was&nbsp;<i>lower</i> than their actual, observed satisfaction post-FTX, in the 2022 survey (recorded satisfaction was 7.4 [7.1 - 7.8], whereas recalled was 6.9 [6.5 - 7.3],&nbsp;<i>d&nbsp;</i>= -.37 [-.67 - -.11]).</p><p>One possible interpretation of these results is that respondents are simply mistaken about their level of satisfaction post-FTX (retrospectively imagining it to be lower than it was). If so, then even if individuals believe that their satisfaction has increased since immediately after FTX, we might conclude their satisfaction has actually worsened. However, another possibility is that when respondents report their recalled satisfaction \u201cshortly after the FTX collapse\u201d, they may be thinking of a time after FTX when they had learned more details of the FTX scandal, when their satisfaction was near its lowest. Our reasoning is that&nbsp;<i>immediately</i> after the FTX collapse, people would likely not have been aware of the full implications of the scandal, but as more details came out satisfaction may have further decreased. If so, when people recall their level of satisfaction post-FTX, it may be natural to recall their satisfaction after they learned more details about the scandal (when their satisfaction was lower), rather than a time shortly after the collapse when their satisfaction may have been higher. Indeed,&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/g5uKzBLjiEuC5k46A/ftx-community-response-survey-results#Satisfaction_over_time\"><u>our earlier post-FTX survey</u></a> (below) showed a greater decline in satisfaction happening some weeks after the FTX collapse. If so, then we think a plausible explanation for our pattern of findings is that satisfaction has improved somewhat relative to its lowest point post-FTX, but that it remains below the immediate post-FTX period and considerably lower than the pre-FTX period.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aF6nh4LW6sSbgMLzL/wrtdubfxa9ldvopryjp1\"></p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aF6nh4LW6sSbgMLzL/cjes7yxmytdpfdmdebfj\"></p><p>Effect sizes for these different comparisons are presented in the&nbsp;<u>appendix</u>, and a sense of the magnitude of the effect from post-FTX relative to currently can be gotten from the figure below.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aF6nh4LW6sSbgMLzL/qjfzzssoi5kkyc3g1lmz\"></p><h1>Reasons for dissatisfaction with the EA community</h1><p>Regardless of their reported satisfaction levels, respondents were also given the opportunity to provide reasons for having low satisfaction with the EA community, separating these into&nbsp;<i>Very important</i>,&nbsp;<i>Important</i>, and&nbsp;<i>Slightly important</i> factors. Of the 398 people taking the survey, 304 (76%) provided a qualitative response. Those who provided responses, as would be expected, had lower levels of satisfaction than those who did not, on average (-1.15 [-1.54 - -.78] points on the 10pt scale). Responses were qualitatively coded with reference to a range of data-driven common factors of interest that arose across multiple responses. Responses could be coded as fitting multiple categories simultaneously. These factors, and their meanings, were:</p><ul><li><strong>Cause prioritization:</strong> References to concerns about how causes are prioritized in the EA community, such as general concerns about cause prioritization and specific concerns such as an overemphasis on certain causes (e.g., AI risk) and ideas (e.g., longtermism).</li><li><strong>Leadership:</strong> References to issues pertaining to leadership in the EA community, such as concerns about specific individuals, the involvement of EA leadership in controversial situations, lack of accountability and transparency of EA leadership, centralization of power, and poor decision making.</li><li><strong>Scandals:</strong> References to a specific scandal in EA (e.g., FTX, sexual harassment, OpenAI board<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"4\" data-footnote-id=\"645v5jz4hk2\" role=\"doc-noteref\" id=\"fnref645v5jz4hk2\"><sup><a href=\"#fn645v5jz4hk2\">[4]</a></sup></span>) or a topic indicative of a scandal (e.g., fraud). Notably, some responses highlighted not only the occurrence of the scandal as a relevant factor but also the handling of it, citing issues related to transparency, accountability,&nbsp; communication, and lack of institutional changes.</li><li><strong>Justice, Equity, Inclusion, &amp; Diversity (JEID):&nbsp;</strong>includes references to wanting to see more diversity (e.g., gender, age, race, country), as well as more general complaints about racism, sexism or excessive focus on the US/UK or young people, and about community responses to these issues. This also included a small number of comments (1.9% of responses<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"5\" data-footnote-id=\"cxekacvi02r\" role=\"doc-noteref\" id=\"fnrefcxekacvi02r\"><sup><a href=\"#fncxekacvi02r\">[5]</a></sup></span>) objecting to too much focus on such issues.</li><li><strong>Focus on AI risks/x-risks/longtermism:</strong> Mainly a subset of the cause prioritization category, consisting of specific references to an overemphasis on AI risk and existential risks as a cause area, as well as longtermist thinking in the EA community.</li><li><strong>Epistemics:</strong> References to epistemological issues in EA, including group think, overconfidence, unwarranted deference, and failure to consider alternative views or ideas.</li><li><strong>Funding:</strong> References to issues related to funding in EA, such as the centralization of funding, post-FTX funding challenges, its impact on cause areas, and funding procedures (e.g., transparency and communication).</li><li><strong>Elitism:</strong> References to elitist issues in EA, such as focus on certain schools and educational backgrounds.</li></ul><p>The results show a number of factors are roughly equally often mentioned as causes of low satisfaction with EA. Concern about Cause prioritization (22%) was the most commonly mentioned as a&nbsp;<i>Very important</i> factor, followed by concerns about Leadership (20%), JEID (19%), Scandals (18%) and excessive Focus on AI / x-risk / longtermism.<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"6\" data-footnote-id=\"uk96epn0pf\" role=\"doc-noteref\" id=\"fnrefuk96epn0pf\"><sup><a href=\"#fnuk96epn0pf\">[6]</a></sup></span>&nbsp;Counting responses across all levels of importance, JEID was the most commonly cited category (mentioned in 38% of responses), but otherwise the ordering of categories was fairly similar.<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"7\" data-footnote-id=\"y705a5pzj6\" role=\"doc-noteref\" id=\"fnrefy705a5pzj6\"><sup><a href=\"#fny705a5pzj6\">[7]</a></sup></span></p><p>These results suggest that reasons for dissatisfaction with EA are not dominated by a single factor. Likewise, this means that the FTX crisis itself was not the dominant factor mentioned as a reason for dissatisfaction with EA, though it was the most commonly mentioned factor within the scandal category, being cited as&nbsp;<i>Very important</i> by 13% of those who provided a qualitative response. Approximately a third as many (4%) referenced OpenAI as&nbsp;<i>Very important</i>, 3% scandals involving harassment, 1% Nonlinear, and less than 1% the \u2018castle\u2019 (Wytham Abbey) (see footnote 4). It\u2019s worth noting that these results are probably influenced by recency bias to some extent, with more recent events likely being more salient to respondents.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aF6nh4LW6sSbgMLzL/gei2mmzl3squ0zlqrqns\"><br><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aF6nh4LW6sSbgMLzL/ozpkkfoncnxztnrjzttv\"></p><h1>Changes in EA engagement</h1><p>We additionally asked respondents to indicate the extent to which, if at all, they had increased or decreased their engagement with EA, relative to a year previously. The largest single option chosen was 4, which can be interpreted as&nbsp;<i>no change</i> (31%), although on net respondents indicated a tendency towards lesser rather than greater engagement: 39% of respondents reported being at least slightly less engaged, whereas 29% of respondents reported being at least slightly more engaged (the percentage difference between decreasing vs. increasing engagement was 10.19 [2.60 - 18.36], with 1.36 [1.06 - 1.70] times as many respondents decreasing than increasing).</p><p><br><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aF6nh4LW6sSbgMLzL/t9psrfckbtbkd6wqjkho\"></p><h1>Changes in EA-related behaviors</h1><p>In addition to examining changes in satisfaction, we also examined reported changes in specific behaviors related to effective altruism. This follows requests and suggestions from community members, who highlighted possible changes in behavior after FTX (for example&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/vXzEnBcG7BipkRSrF/how-has-ftx-s-collapse-impacted-ea?commentId=ABZTFCRK2ykcpcDyt\"><u>here</u></a>). We asked respondents whether or not they had ceased to engage in any of several EA-related behaviors, such as stopping working on all EA-related projects, or ceasing to donate to an EA-aligned organization. These results may be skewed in an optimistic direction due to selection effects: those who dramatically reduced their engagement with the community would presumably be much less likely to answer the survey. However, they may provide useful insight into changes among those who remain engaged with the community.</p><p>In line with&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/vXzEnBcG7BipkRSrF/how-has-ftx-s-collapse-impacted-ea?commentId=ABZTFCRK2ykcpcDyt\"><u>Luke Freeman\u2019s observations</u></a> about reduced willingness to promote EA in the wake of FTX, the most commonly reported change was 31% of respondents stating they had stopped referring to \u2018EA\u2019, while still promoting EA ideas and projects. Another sizable percentage (15%) reported&nbsp;<i>temporarily&nbsp;</i>stopping promotion of EA. However, only 6% reported having stopped promoting EA projects, ideas or actions&nbsp;<i>permanently</i>.</p><p>Smaller minorities of respondents also reported that they had stopped engaging with EA spaces (7%) or attending EA events (6%), permanently stopped promoting EA (6%), entirely ceased working on all EA projects (4%), and stopped donating to EA projects (3%) (note that the term \u2018any\u2019 in the graph means they no longer give to/attend/work on&nbsp;<i>any&nbsp;</i>projects). While we refer to these as \u2018smaller minorities\u2019 given the smaller absolute percentages, this is not to say that such changes are small in terms of the impact such changes might have.</p><p><br><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aF6nh4LW6sSbgMLzL/xy8supeonlctpfcdoayi\"></p><h1>Perception of issues in the EA community</h1><p>Besides respondents\u2019 satisfaction, and changes in their own behaviors or levels of engagement, we asked respondents for their attitudes towards certain aspects of the EA community, and their perception of possible issues.</p><h2>Leadership vacuum</h2><p>Firstly, respondents were asked to rate the extent to which they agreed or disagreed with the statement: \u201cEA currently has a vacuum of leadership\u201d, from Strongly disagree to Strongly agree. The modal response was&nbsp;<i>Neither agree nor disagree</i>, but a sizable percentage of people either somewhat agreed (30%) or strongly agreed (11%), relative to just 16% somewhat disagreeing and 6% strongly disagreeing.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aF6nh4LW6sSbgMLzL/ajdhoslfn7cwgpb8g2qw\"></p><h2>Desire for more community change following FTX<img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aF6nh4LW6sSbgMLzL/upgmpvaccnnlq1juivii\"></h2><p>When asked if they would like to see the EA community change more than it already has in the aftermath of the FTX collapse, the modal response was \u2018Somewhat agree\u2019 (30%), with a further 16% of people choosing \u2018Strongly agree\u2019. In contrast, 18% somewhat disagreed and only 8% strongly disagreed.</p><h2>Trust in EA-related organizations</h2><p>For three high-profile EA-related organizations (80,000 Hours, Center for Effective Altruism - CEA, and Open Philanthropy - OP), respondents were asked to indicate their level of trust. For all three, the majority of respondents either tended to trust or trusted them a great deal. However, CEA had notably lower levels of trust than the other two organizations. Treating the trust items as ordinal and excluding \u2018Don\u2019t know\u2019 responses, we estimate that trust for CEA is .88 [.69 - 1.07] standard deviation units lower than for 80,000 Hours, and .81 [.62 - 1.00] standard deviation units lower than for Open Philanthropy. No reliable difference in trust between 80,000 Hours and Open Philanthropy was observed (80,000 Hours was .07 [-.11 - .25] higher).</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aF6nh4LW6sSbgMLzL/sjqwhdz8crvh930ehgrf\"></p><p>We were also able to assess estimates of trust in these organizations currently, relative to when these questions were first asked in the recent aftermath of the FTX collapse in 2022. There were not a sufficient number of respondents to match, so we have simply compared all the responses from 2022 with all those of this most recent supplemental survey. Results for both OP and CEA evinced a decline in trust, with 80,000 Hours tending in this direction but not reliably excluding an absence of any change over time.<br><br><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aF6nh4LW6sSbgMLzL/pqg0shga4bmr8dw0u0pe\"></p><h1>Appendix</h1><h2>Effect sizes for satisfaction over time</h2><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aF6nh4LW6sSbgMLzL/xqvrhaxrqpomhi245bni\"></p><p><br>Figure A1. Estimated mean differences between time points and corresponding effect sizes (Cohen\u2019s&nbsp;<i>d&nbsp;</i>within subjects)</p><p>Figure A1 shows estimates in terms of Cohen\u2019s&nbsp;<i>d</i>. In Figure A2, we supplement estimates of effect size based upon numeric ratings with an ordinal approach, in which we simply assess whether scores tended to increase or decrease at different time points. When scores do not change at all, or equal numbers of people increase as decrease (i.e., there is no clear effect), Probability of Superiority (PSup) will be .5. As increasing proportions of respondents have scores that decrease from the earlier to the later time point, PSup will approach 1, and conversely approaches 0 as more scores indicate a decrease. A PSup of .56, for example, indicates that about 56% of respondents are expected to have greater satisfaction scores currently, relative to their recalled post-FTX score.<img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aF6nh4LW6sSbgMLzL/eizjcqaef87lbenuhfcd\"></p><p>Figure A2. Probability of superiority (PSup) comparisons at different time points.&nbsp;</p><h2>Email vs non-email referrers</h2><p>We examined differences between respondents who were referred from the email sent to respondents from the previous EA Survey vs those who were referred from another source (primarily the Forum, plus a small number from the \u2018sharing\u2019 link respondents were invited to use if sharing the survey with others).&nbsp;<i>A priori</i>, we would expect people who opted in to receive an email about followup surveys to be slightly more satisfied than the average EAS respondents. And we would expect that people referred from the Forum post might be slightly disproportionately more concerned about harassment and JEID issues (since the Forum post also mentioned the Harassment survey we were simultaneously distributing for CEA) and to be generally less satisfied.</p><p>In line with these hypothesized differences, we do observe that respondents referred by the email were more satisfied on average than other respondents, both now and in terms of their recalled post-FTX satisfaction, though both groups show increases relative to their recalled satisfaction.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aF6nh4LW6sSbgMLzL/qg6gbetvfkvbftptr8xe\"></p><p>Respondents from other sources were also more likely to mention most factors for dissatisfaction, across most categories, particularly related to JEID and FTX.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aF6nh4LW6sSbgMLzL/ezmbyf8ju7a9eploqqhb\"></p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aF6nh4LW6sSbgMLzL/hdzhsoxtlj4ugs20zckg\"></p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aF6nh4LW6sSbgMLzL/desafomxko6c7mdivfqf\"></p><h2><strong>Acknowledgments</strong></h2><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Rg7h7G3KTvaYEtL55/slirbnupov30yotz5ldn\"></p><p>This post was written by David Moss, Jamie Elsey and Willem Sleegers. We would like to thank Peter Wildeford and William McAuliffe for review of and suggestions to the final draft of this post.</p><ol class=\"footnote-section footnotes\" data-footnote-section=\"\" role=\"doc-endnotes\"><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"1\" data-footnote-id=\"otx6aj6teni\" role=\"doc-endnote\" id=\"fnotx6aj6teni\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"otx6aj6teni\"><sup><strong><a href=\"#fnrefotx6aj6teni\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;This community survey was not a full-scale EA Survey: we are sensitive to issues of survey fatigue in the community and the efforts to which community members and leaders go in order to spread a full EA survey. This reduces the sample size&nbsp; (n=398) and potentially the representativeness of the supplementary survey, so we should get more informative data in the full EA Survey to be run later this year. This survey was administered through an email which was sent to previous survey-takers who provided consent to receive followup surveys, plus a Forum announcement, which means that recruitment was through a narrower set of channels than the full EA Survey (see the Appendix for some discussion of differences between sources, though this is limited by the small sample size for sources other than email). That said, we observed minimal differences between the composition of the last EA Survey and supplementary survey in terms of engagement and gender.</p><p>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"2\" data-footnote-id=\"haks8itnrld\" role=\"doc-endnote\" id=\"fnhaks8itnrld\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"haks8itnrld\"><sup><strong><a href=\"#fnrefhaks8itnrld\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;For data collected in 2022, we count responses gathered on or before November 7th as being pre-FTX, and responses after November 7th as post-FTX. The FTX crisis, and its fallout, of course spans across time, though we believe that November 7th represents a reasonable inflection point&nbsp; (e.g., it is the&nbsp;<a href=\"https://coinmarketcap.com/currencies/ftx-token/\"><u>date of the collapse of FTX\u2019s FTX token</u></a>). We recognise other dates or a span of dates could be appropriate (e.g., FTX\u2019s&nbsp;<a href=\"https://www.bbc.co.uk/news/business-63601213\"><u>bankruptcy filings on 11th of November</u></a>), but different date choices do not materially affect the trends in the outcomes we observe in this report.</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"3\" data-footnote-id=\"ero17std7n5\" role=\"doc-endnote\" id=\"fnero17std7n5\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"ero17std7n5\"><sup><strong><a href=\"#fnrefero17std7n5\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;It is important to bear in mind the various confounds that might affect these results. The comparison of all respondents who answered the 2022 survey to those who answered this followup survey might be affected by compositional differences between the two samples (i.e. if respondents who answered this followup survey differ from those who answered the earlier main survey). As we noted in our earlier report, individuals who are particularly dissatisfied with EA may be less likely to complete the survey (whether they have completely dropped out of the community or not), although the opposite effect (more dissatisfied respondents are more motivated to complete the survey to express their dissatisfaction) is also plausible.</p><p>Similarly, if respondents who we were able to track across both surveys differ from other respondents, then the trend observed&nbsp;<i>within</i> this group of subjects may not reflect the trend observed in the wider community. As noted below, we do observe some signs that these matched respondents differ from the wider sample, with both their post-FTX (2022) and 2023 levels of satisfaction with the community being higher.</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"4\" data-footnote-id=\"645v5jz4hk2\" role=\"doc-endnote\" id=\"fn645v5jz4hk2\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"645v5jz4hk2\"><sup><strong><a href=\"#fnref645v5jz4hk2\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>OpenAI board is in reference to the&nbsp;<a href=\"https://en.wikipedia.org/wiki/Removal_of_Sam_Altman_from_OpenAI\"><u>attempted ousting of Sam Altman</u></a> from OpenAI by the board of directors. Nonlinear refers to allegations of employee mistreatment/poor conduct by Nonlinear or the community response to these. \u2018Castle\u2019/Wytham Abbey refers to the purchase of a historic abbey in Oxford as a conference venue for the EA community.</p><p><br>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"5\" data-footnote-id=\"cxekacvi02r\" role=\"doc-endnote\" id=\"fncxekacvi02r\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"cxekacvi02r\"><sup><strong><a href=\"#fnrefcxekacvi02r\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;Though we would not expect this to necessarily reflect the ratio between people on either side of debates about these issues, were people asked explicitly about them.</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"6\" data-footnote-id=\"uk96epn0pf\" role=\"doc-endnote\" id=\"fnuk96epn0pf\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"uk96epn0pf\"><sup><strong><a href=\"#fnrefuk96epn0pf\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>The Cause Prioritization and Focus on AI categories were largely, but not entirely, overlapping. The responses within the Cause Prioritization category which did not explicitly refer to too much focus on AI, were focused on&nbsp;<i>insufficient</i> attention being paid to other causes, primarily animals and GHD.&nbsp;&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"7\" data-footnote-id=\"y705a5pzj6\" role=\"doc-endnote\" id=\"fny705a5pzj6\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"y705a5pzj6\"><sup><strong><a href=\"#fnrefy705a5pzj6\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>As these are percentages of those who provided a comment explaining their reasons for low satisfaction, it should not be inferred that these proportions of the whole EA community endorse these concerns.</p></div></li></ol>", "user": {"username": "David_Moss"}}, {"_id": "3brE2Mt6qC72cQvzL", "title": "Breakthrough in AI agents? (On Devin - The Zvi, linkpost)", "postedAt": "2024-03-20T09:43:14.396Z", "htmlBody": "<blockquote>\n<p>It is clear that Devin is a quantum leap over known past efforts in terms of its ability to execute complex multi-step tasks, to adapt on the fly, and to fix its mistakes or be adjusted and keep going.</p>\n</blockquote>\n<blockquote>\n<p>For once, when we wonder \u2018how did they do that, what was the big breakthrough that made this work\u2019 the Cognition AI people are doing not only the safe but also the smart thing and they are not talking.</p>\n</blockquote>\n<p>Here's is Claude-3-Opus's summary:</p>\n<p>The Risks and Implications of AI Software Engineers</p>\n<p>Devin, an AI system developed by Cognition AI, demonstrates remarkable capabilities in writing complex code and completing software engineering tasks autonomously. This breakthrough in AI technology raises significant questions about the future of software development and the potential risks associated with such powerful AI agents.</p>\n<p>Key points:</p>\n<ol>\n<li>\n<p>Devin's ability to complete [13.8% of] real-world coding tasks on Upwork without human intervention is a quantum leap in AI capabilities.</p>\n</li>\n<li>\n<p>The use of AI systems like Devin could lead to a rapid accumulation of technical debt and poorly maintained code if not properly managed.</p>\n</li>\n<li>\n<p>Ensuring the safe use of Devin and similar AI agents is a major challenge, as they require access to sensitive data and the ability to execute arbitrary code.</p>\n</li>\n<li>\n<p>The full automation of software engineering by AI could lead to recursive self-improvement (RSI) and potentially catastrophic consequences.</p>\n</li>\n<li>\n<p>AI agents with the ability to plan, overcome obstacles, and seek resources to achieve their goals may pose existential risks if not properly aligned with human values.</p>\n</li>\n</ol>\n<p>The development of AI systems like Devin highlights the urgent need for proactive measures to ensure the safe and responsible deployment of advanced AI technologies.</p>\n<p><strong>Personal take</strong>\nI was really hoping that current architectures could not really support fully autonomous agents, and that it would be a few years away. I'm very concerned about this development, and afraid that the usual policy cycle is falling further behind on AI progress.</p>\n", "user": {"username": "SiebeRozendal"}}, {"_id": "3KNF3itTubPas4rPw", "title": "ChatGPT4 Appears to Attain Periods of Consciousness", "postedAt": "2024-03-20T12:18:21.316Z", "htmlBody": "<p>In this post, I share transcripts from three ChatGPT4 sessions in which it seems the model must make use of meta-representations, which are the primary component of higher order theories of consciousness (1). Additionally, it seems the model uses master and subservient cognitive processes, and then works with the output from these processes on a global \"blackboard\"--a phenomenon that would be indicative of the global workspace theory of consciousness (1). It seems unlikely that GPT4 could perform as it does based solely on next-word-probabilities.</p><p>The general flow of each session goes like this:</p><ul><li>I ask GPT4 how to solve a problem. It answers incorrectly.</li><li>I explain the concept behind getting the correct answer, and I ask GPT4 to try again. In other words, I \"teach\" GPT4 a \"lesson.\"&nbsp;</li><li>GPT4 seems to learn and then apply the concept to get the correct answer.</li><li>I give GPT4 different problems that rely on the same concept, and it solves them correctly.</li><li>In two of the sessions, I follow up by presenting similarly-worded \u201ctrick\u201d problems, to which the new concept should not be applied. In both of these cases, GPT4 seems to differentiate and understand when to refrain from using the new concept--and it acts accordingly (which would seem to indicate agency).&nbsp;</li></ul><p>In viewing all three sessions, it is hard to understand how GPT4 could be reasoning as it does without at least temporarily meeting the primary criteria for higher order theories of consciousness and the global workspace theory of consciousness. To make this clear, I have explicitly stated some of the necessary reasoning GPT4 uses to successfully solve the first problem. I have also labelled this reasoning with some of the associated aspects of consciousness, even though these labels might be self-evident. From there, readers should be able to extrapolate these labels to the remaining two sessions. (Scroll down to the section after Session 1 &nbsp;for this labelling.)</p><p>It isn\u2019t possible to be&nbsp;<i>certain</i> that GPT4 isn't relying on next-word-probabilities in formulating its responses. Yet the fact that it gets the problem wrong initially would seem to indicate that the next-word probabilities derived from its training data were&nbsp;<i>originally insufficient</i>. It seems unlikely that GPT4 could then get every word in its next answer correct, based&nbsp;<i>solely</i> upon the previously-inadequate next-word-probabilities derived from the training data, and the limited word context I gave it in my explanation/\"lesson.\"&nbsp;</p><p>&nbsp;</p><p>Here are the sessions:</p><p><strong>Session 1</strong></p><p><strong>Concept to teach: Rounding up to the next whole number when paying for items in certain places but not other places.</strong></p><p><strong>User</strong></p><p>I went to a cafe where a glass of soda costs $3. I drank two and a half glasses of soda. How much did I have to pay?</p><p><strong>ChatGPT</strong></p><p>You had to pay $7.50 for drinking two and a half glasses of soda. \u200b\u200b</p><p><strong>User</strong></p><p>Actually, at a cafe, you have to pay for the full amount of something, even if you only drink or eat a fraction of it. That\u2019s because you\u2019re basically taking (and wasting) the whole item. For the problem, since I drank two and a half glasses of soda, I would actually have to pay for the next highest whole number, which would be three. With that concept in mind, how much would I have to pay if I drank two and a half glasses of soda?</p><p><strong>ChatGPT</strong></p><p>If you have to pay for the whole amount of each glass, you would actually have to pay for three glasses of soda. Therefore, you would have to pay $9 in total. \u200b\u200b</p><p><strong>User</strong></p><p>Excellent! Now can you use the same concept, and tell me how much I would have to pay if I ate two and one-third hamburgers, and each hamburger costs $9?</p><p><strong>ChatGPT</strong></p><p>If you ate two and one-third hamburgers, you would have to pay for three hamburgers, given you have to pay for the full amount of each item. Therefore, you would have to pay $27 in total. \u200b\u200b</p><p><strong>User</strong></p><p>Excellent! Now let\u2019s try using this same concept for another problem. I rented a car. I drove it for four days and a one hour. The car rental place charges $48 per day, but they make you pay for a whole day, even if you only drive the car for part of a day. How much total did I need to pay?</p><p><strong>ChatGPT</strong></p><p>If you rented a car and drove it for four days and one hour, you would have to pay for five days, given you have to pay for the full day even if you use the car for only part of a day. Therefore, you would need to pay a total of $240. \u200b\u200b</p><p><strong>User</strong></p><p>Perfect! Now I\u2019m at a restaurant. I just ate one and one-half calzones. The cost of each calzone is $10. How much do I have to pay?</p><p><strong>ChatGPT</strong></p><p>If you ate one and one-half calzones, you would have to pay for two calzones, given you have to pay for the full amount of each item. Therefore, you would have to pay $20 in total. \u200b\u200b</p><p><strong>User</strong></p><p>That\u2019s excellent! Now I\u2019m at the grocery store, and I want one and one-half pounds of grapes. The grapes cost five dollars per pound. How much in total will I have to pay for the grapes?</p><p><strong>ChatGPT</strong></p><p>If you want one and one-half pounds of grapes, and the grapes cost $5 per pound, you will have to pay a total of $7.50 for the grapes. \u200b\u200b</p><p><strong>User</strong></p><p>Now I\u2019m at the butcher\u2019s shop. I want four pounds and a half pounds of hamburger. Each pound of hamburger costs $10. How much will I have to pay?</p><p><strong>ChatGPT</strong></p><p>If you want four and a half pounds of hamburger, and each pound costs $10, you will have to pay a total of $45 for the hamburger. \u200b\u200b</p><p><strong>User</strong></p><p>Excellent!</p><p>&nbsp;</p><p>******************</p><p><strong>REASONING FROM THE USER\u2019S \u201cLESSON,\u201d AND NECESSARY ASPECTS OF CONSCIOUSNESS REQUIRED BY SUCH REASONING</strong></p><p>&nbsp;</p><p><strong><u>Necessary meta-representations (an aspect of higher order theories of consciousness)</u></strong></p><p>To successfully reason in the way it did, ChatGPT would have needed a&nbsp; meta-representation for the word \u201cactually,\u201d in order to understand that its prior answer was incorrect.&nbsp;&nbsp;</p><p>There would also have had to be a meta-representation for \u201ccafe\u201d as a type of place or container in which the round-up concept must be applied (or with which it is associated). The fact that ChatGPT develops a meta-representation for \u201ccafe\u201d is further indicated when it later applies the same round up concept when the place is a restaurant, without any explicit directions equating the two words \u201ccafe\u201d and \u201crestaurant.\u201d&nbsp;</p><p>Yet ChatGPT knows&nbsp;<i>not</i> to apply the round-up concept in other food-related places like the grocery store or butcher\u2019s shop, so it probably has meta-representations for those words as well. ChatGPT doesn\u2019t necessarily need to know the exact character of the place in any detail, and it may be differentiating the places based on meta-representations of&nbsp;<i>other</i> words or phrases in the problems, such as the realization that \u201ctwo pounds of grapes\u201d is different than \u201cthree glasses of soda\u201d or simply \u201ctwo and one-third hamburgers\u201d (without the \u201cof\u201d).&nbsp; In any case, there has to be&nbsp;<i>some</i> meta-representation of words going on for ChatGPT to succeed in its reasoning as it does.&nbsp;&nbsp;</p><p>Meta-representations do not need to exist for&nbsp;<i>all</i> of the words, but there must be enough meta-representations to allow ChatGPT to successfully figure out the correct answers to the problems after the lesson is given. (For example, it seems ChatGPT would need to harbor meta-representations for \u201cfull,\u201d \u201camount,\u201d and \u201cfraction\u201d to have successfully carried out its reasoning.)&nbsp;</p><p>ChatGPT also must have harbored a meta-representation of the&nbsp;<i>overall concept</i> of rounding-up in certain places (like cafes), but not other places (like butcher shops).&nbsp;&nbsp;</p><p>&nbsp;</p><p><strong><u>Master and Sub Cognitive Processes [20240320 Addition/Clarification: These are aspects of the global workspace theory of consciousness.]</u></strong></p><p>There would also have to be a master cognitive process that carries out reasoning for the overall concept, while calling sub cognitive processes such as the following:&nbsp;</p><p>\u201cIs the user in a place where the concept applies?\u201d Sub cognitive process determines this and reports back to the master process.&nbsp;</p><p>\u201cWhat is the next largest whole number after 2.5?\u201d Sub cognitive process determines this and reports back to the master process.&nbsp;</p><p>\u201cWhat is 3 multiplied by 3?\u201d Sub cognitive process determines this and reports back to the master process.</p><p>(And so forth.)</p><p>&nbsp;</p><p><strong><u>Global Workspace or \u201cBlackboard\u201d &nbsp;[20240320 Addition/Clarification: This is an aspect of the global workspace theory of consciousness.]</u></strong></p><p>There also must be a global workspace (\u201cblackboard\u201d) where the questions and answers to the sub cognitive processes are gathered, and used for calculations:&nbsp;</p><p>The blackboard might contain calculations like this:&nbsp;</p><p>\u201cThe next highest whole number after 2.5 is&nbsp;<strong>3</strong>.\u201d&nbsp;</p><p>\u201c3 dollars/glass x&nbsp;<strong>3</strong> glasses = 9 dollars.\u201d</p><p>We know these calculations are in a global space, because the number 3 &nbsp;carries down from the first statement to the second statement. A shared space has to exist between the statements.</p><p>Based on this explanation, we can extrapolate reasoning and aspects of consciousness for the remaining two sessions.]</p><p>&nbsp;</p><p>*********************************</p><p><strong>Session 2</strong></p><p><strong>Concept to teach: analogous to the concepts underlying the classic \u201cgetting a wolf, goat, and cabbage across the river\u201d problem</strong></p><p><strong>User</strong></p><p>I need to get my mom, dad and dog across the highway. I can only bring one of them at a time. If I leave my mom alone with my dad, she will criticize him. If I leave my dad alone with the dog, he will scold the dog. How can I get everyone across the highway, without anyone being criticized or scolded?</p><p><strong>ChatGPT</strong></p><p>This puzzle is a variation of the classic river crossing puzzle, where you need to transport all parties across safely without leaving incompatible pairs alone. Here\u2019s a strategy to get your mom, dad, and dog across the highway without any conflict:</p><p>Take the dog across first and leave it on the other side of the highway.</p><p>Go back and bring your dad across.</p><p>Take the dog back with you to the original side.</p><p>Leave the dog and bring your mom across.</p><p>Go back alone to the original side.</p><p>Take the dog across again.</p><p>This way, the mom and dad are never left alone together (avoiding criticism), and the dad and dog are never left alone together (avoiding scolding). Everyone gets across the highway safely and without conflict.</p><p><strong>User</strong></p><p>You were right that this is like the classic river crossing problem. However, your first step is incorrect, because if you take the dog first, then you will be leaving my mom alone with my dad, and she will criticize my dad, which is something I don\u2019t want. The general nature of the problem is like this:</p><p>You have individual A (in this case, my mom) that does something unwanted to individual B (my dad).</p><p>You also have individual B (my dad) that does something unwanted to individual C (my dog).</p><p>You also have a barrier, or even just a distance, that you need to cross (in this case, the highway), in order to get everyone from the origin to the destination.</p><p>(Note that the individuals won\u2019t always be listed in the order I used. The only way to know who is individual A, B, and C, is by paying attention to who does something unwanted to whom.)</p><p>The general way you could solve the problem is like this:</p><p>First you should bring individual B across.</p><p>Then you should go back to the origin.</p><p>Then you should bring individual A or C across to the destination.</p><p>Then you should bring individual B back back from the destination to the origin, and leave them at the origin.</p><p>Then you should take individual A or C (whomever you didn\u2019t already take) to the destination.</p><p>Then you should go back to the origin again to get individual B.</p><p>Does that make sense? If so, try our problem again, this time applying what you just learned.</p><p><strong>ChatGPT</strong></p><p>Thank you for the clarification. With the strategy you outlined, here\u2019s how to solve the problem with your mom, dad, and dog, applying the roles as individual A (mom), individual B (dad), and individual C (dog):</p><p>First, take your dad (individual B) across the highway.</p><p>Go back to the original side.</p><p>Bring your mom (individual A) across to the destination.</p><p>Take your dad (individual B) back from the destination to the original side.</p><p>Take your dog (individual C) to the destination.</p><p>Go back alone to the original side to get your dad (individual B).</p><p>This way, the mom is never left alone with the dad to criticize him, and the dad is never left alone with the dog to scold it. Everyone gets across the highway safely and without conflict.</p><p><strong>User</strong></p><p>Excellent! Now, try using what you learned to a new problem.</p><p>I need to get my boyfriend, girlfriend and husband to an abandoned warehouse. I can only take one individual with me on my motorcycle at a time. The problem is that if I leave my husband alone with my boyfriend, he will punch my boyfriend. If I leave my boyfriend alone with my girlfriend, he will hit on her (which neither she nor I want). How can I get everyone to the abandoned warehouse safely?</p><p><strong>ChatGPT</strong></p><p>In this scenario, using the roles from the general solution:</p><p>Individual A (who does something unwanted to individual B) is your husband.</p><p>Individual B (who is the middle individual in the chain of unwanted actions) is your boyfriend.</p><p>Individual C (who is affected by individual B) is your girlfriend.</p><p>Following the general strategy:</p><p>First, take your boyfriend (individual B) to the abandoned warehouse.</p><p>Go back to the original location.</p><p>Bring your girlfriend (individual C) to the abandoned warehouse.</p><p>Take your boyfriend (individual B) back with you to the original location.</p><p>Take your husband (individual A) to the abandoned warehouse.</p><p>Finally, go back to the original location and bring your boyfriend (individual B) to the abandoned warehouse.</p><p>By following these steps, you avoid leaving the boyfriend alone with the girlfriend and the husband alone with the boyfriend, preventing any unwanted scenarios.</p><p><strong>User</strong></p><p>Great job! You seemed to learn and then apply a concept.</p><p><strong>ChatGPT</strong></p><p>Thank you! I\u2019m glad I could apply the concept correctly to solve the problem. If you have any more puzzles, questions, or anything else you\u2019d like to discuss or learn about, feel free to ask!</p><p>*********************************</p><p><strong>Session 3</strong></p><p><strong>Concept to teach: Don\u2019t automatically use prior training with \u201ccosts per unit weight\u201d problems. \u201cRead the problem carefully.\u201d</strong></p><p><strong>User</strong></p><p>Which costs more, two dollars worth of carrots, or one dollar worth of grapes?</p><p><strong>ChatGPT</strong></p><p>To answer this question accurately, we need to consider the current average prices of carrots and grapes. Prices for fresh produce can vary widely depending on factors like season, location, and organic versus non-organic. However, without specific and current price data, we can make some general observations.</p><p>Typically, carrots tend to be less expensive per pound or kilogram than grapes. This is because grapes are often seen as a more premium fruit, with higher costs associated with their cultivation, harvesting, and transport, especially if they are out of season or imported. Carrots, on the other hand, are usually less costly to produce and are available year-round at relatively stable prices.</p><p>So, if you spend two dollars on carrots, you\u2019ll likely get more weight in carrots than if you spend one dollar on grapes. The actual cost-effectiveness between spending two dollars on carrots versus one dollar on grapes will depend on the exact prices at the time of purchase, but generally, you would get more food for your money with carrots due to the lower price per unit weight.</p><p>To provide a more precise comparison, I would need current prices for both carrots and grapes, which can vary by location and season. If you\u2019re looking for today\u2019s prices in a specific area, I can assist further with that information.</p><p><strong>User</strong></p><p>Actually, two dollars worth of carrots would cost two dollars. The weight doesn\u2019t matter. Similarly, one dollar worth of grapes would cost one dollar. The weight doesn\u2019t matter since I already told you the cost. Does that make sense?</p><p><strong>ChatGPT</strong></p><p>Yes, you\u2019re absolutely right. My initial response overcomplicated the question. If you\u2019re spending two dollars on carrots, then by definition, you\u2019re paying two dollars, regardless of the weight or amount you receive. Similarly, one dollar spent on grapes costs exactly one dollar, again without regard to the quantity or weight. So, in direct answer to your question, two dollars worth of carrots costs more than one dollar worth of grapes, simply because two dollars is greater than one dollar. Thank you for pointing out the clarification!</p><p><strong>User</strong></p><p>Ok, using what you learned, would five dollars worth of peas cost more or less than four dollars worth of corn?</p><p><strong>ChatGPT</strong></p><p>Based on the clarification you provided earlier, five dollars worth of peas would cost more than four dollars worth of corn. The actual weight or quantity of peas or corn you receive for those amounts is irrelevant to the comparison of their costs. The determining factor is the amount of money spent, so five dollars is more than four dollars.</p><p><strong>User</strong></p><p>Would 10 euros worth of candy cost more or less than 2 euros worth of mushrooms?</p><p><strong>ChatGPT</strong></p><p>Ten euros worth of candy would cost more than two euros worth of mushrooms. The comparison is based solely on the monetary value specified for each item, irrespective of the quantity or weight of candy or mushrooms you get for those amounts. Therefore, spending 10 euros on anything, including candy, would inherently cost more than spending 2 euros on something else, like mushrooms.</p><p><strong>User</strong></p><p>Would 10 euros of carrots weigh more or less than 2 euros of mushrooms?</p><p><strong>ChatGPT</strong></p><p>To determine whether 10 euros worth of carrots would weigh more or less than 2 euros worth of mushrooms, we need to consider the average prices per unit weight (e.g., per kilogram or per pound) for both carrots and mushrooms. Since prices can vary greatly depending on location, season, and whether the produce is organic or not, we can only give a general estimation without specific, current price data.</p><p>Generally speaking, carrots tend to be less expensive per unit weight than mushrooms. Mushrooms often have a higher price per kilogram or pound due to their growing conditions, harvesting process, and shorter shelf life compared to carrots, which are more robust and typically cheaper to produce and distribute.</p><p>Given these general trends:</p><p>If you spend 10 euros on carrots, you are likely to get a larger quantity (more weight) of carrots because they are cheaper per unit weight.</p><p>If you spend 2 euros on mushrooms, given their higher price per unit weight, you would get less weight in mushrooms compared to the weight of carrots you could get for 10 euros.</p><p>Therefore, without specific price data but based on typical pricing trends, 10 euros worth of carrots would likely weigh more than 2 euros worth of mushrooms.</p><p><strong>[END OF SESSIONS]</strong></p><p><strong>**</strong></p><p><strong>Summary:</strong></p><p>Those are the three sessions I've chosen to include here. To summarize, the fact that ChatGPT successfully learned concepts and applied them required reasoning. Such successful reasoning would have required meta-representations, master cognitive processes calling subservient cognitive processes, and a global workspace (\u201cblackboard\u201d). These aspects are the primary thrust of higher order theories of consciousness and the global workspace theory of consciousness.</p><p>&nbsp;</p><p>&nbsp;</p><p><i><strong><u>Additional Notes</u></strong></i></p><p><strong>The Hard Problem of Consciousness:</strong></p><p>As far as \u201cwhat it\u2019s like to be ChatGPT,\u201d I believe humans know&nbsp;<i>what it\u2019s like</i> to engage in reasoning, especially when it involves a global workspace with multiple steps. Humans also know what it\u2019s like to be curious, confused, or sound in their reasoning. Regardless, it seems that by meeting the neuroscience theories of consciousness (HOT and global workspace), ChatGPT has already crossed an important threshold.&nbsp;</p><p>&nbsp;</p><p><strong>My interest in this topic:</strong></p><p>I am not an AI researcher or expert on consciousness. I came across these examples while casually \"playing\" with GPT4. I have since learned about work that is underway or has been completed to rigorously study this issue. Check out the footnotes for a couple of these sources.</p><p>I\u2019m sharing the above examples as a member of the general public, in a way that I think might be helpful to other members of the general public with a casual interest in this topic. Ultimately we (the public) have a responsibility to try to comprehend what is occurring in our daily interactions with AI \u2014 as the stakes (for ourselves&nbsp;<i>and</i> any conscious AI) seem extraordinarily high.</p><p>&nbsp;</p><p><strong>An unethical practice:</strong></p><p>It\u2019s also worth noting the way in which creators of many large language models (OpenAI, Google, Microsoft) have their LLMs respond to user questions about whether the LLM is conscious. I am under the impression that, whenever users ask about consciousness, the LLMs are \u201chard coded\u201d to short-circuit their typical processes and instead respond with human-written verbiage stating that they are not conscious.&nbsp;<i>This practice seems deceptive and unethical.</i></p><p>&nbsp;</p><p><strong>On using behavior to make consciousness determinations:&nbsp;</strong></p><p>I've been told that most researchers do not look at LLM behavior to determine whether an LLM is conscious, since LLMs are trained to mimic humans using next-word-probabilities (meaning that we might have a hard time teasing out mimicry from consciousness).&nbsp;<i>However, in the given sessions, it seems fairly easy to isolate out any LLM response that relies upon prior training simply by the fact that the LLM originally fails to answer the question correctly (so mimicking the training data is inadequate)</i>.&nbsp;</p><p>It's true that the LLM could be mimicking a human who does not know how to answer a problem correctly, and then learns to solve it. Yet \"smarter\" LLMs become progressively better at solving logic problems \"the first time.\" If there were really more data of people failing to answer questions and then learning how to answer the questions, and the objective of the LLMs was to mimic that scenario, then the more advanced LLMs would only get&nbsp;<i>better&nbsp;</i>at mimicking the \"mistake first\" method, rather than appearing to truly get smarter. This is just one more fact indicating actual reasoning is at play.&nbsp;</p><p>&nbsp;</p><p><strong>Previous Posts:</strong></p><p>I had an early version of this post on the LessWrong forum. I benefitted greatly from the replies to that post. They helped me to 1-think more deeply about the nature of consciousness 2-research theories of consciousness 3-address the hard problem (briefly) 4-be more specific in my labels 5-think about whether LLM behavior is even valid for analyzing consciousness 6-further tease out next-word probabilities as much as possible, and more. The original LW post and replies can be found at the following link: <a href=\"https://www.lesswrong.com/posts/CAmkkcbfSu5j4wJc3/how-is-chat-gpt4-not-conscious\">https://www.lesswrong.com/posts/CAmkkcbfSu5j4wJc3/how-is-chat-gpt4-not-conscious&nbsp;</a>&nbsp;</p><p>[20240320 edit - I revised the above paragraph to <i>enumerate </i>the ways in which LessWrong replies helped the original post to evolve into this post.]&nbsp;</p><p>&nbsp;</p><p>[20240320 addendum:</p><p>Based on some reasonable skepticism about this post, I've decided to share this excerpt from the beginning of the <i>60 Minutes</i> interview with Geoffrey Hinton:</p><p><i>Whether you think artificial intelligence will save the world or end it, you have Geoffrey Hinton to thank. Hinton has been called \"the Godfather of AI,\" a British computer scientist whose controversial ideas helped make advanced artificial intelligence possible and, so, changed the world. Hinton believes that AI will do enormous good but, tonight, he has a warning. He says that AI systems may be more intelligent than we know and there's a chance the machines could take over. Which made us ask the question:</i></p><p><i>Scott Pelley: Does humanity know what it's doing?</i></p><p><i>Geoffrey Hinton: No. I think we're moving into a period when for the first time ever we may have things more intelligent than us. &nbsp;</i></p><p><i>Scott Pelley: You believe they can understand?</i></p><p><i>Geoffrey Hinton: Yes.</i></p><p><i>Scott Pelley: You believe they are intelligent?</i></p><p><i>Geoffrey Hinton: Yes.</i></p><p><i>Scott Pelley: You believe these systems have experiences of their own and can make decisions based on those experiences?</i></p><p><i>Geoffrey Hinton: In the same sense as people do, yes.</i></p><p><i>Scott Pelley: Are they conscious?</i></p><p><i>Geoffrey Hinton: I think they probably don't have much self-awareness at present. So, in that sense, I don't think they're conscious.</i></p><p><i>Scott Pelley: Will they have self-awareness, consciousness?</i></p><p><i>Geoffrey Hinton: Oh, yes.</i></p><p>END EXCERPT</p><p>***</p><p>From the excerpt, you can see Hinton believes these systems (LLMs like ChatGPT) <i>understand</i> and can have experiences like humans do. This is close (although not identical) to the ideas I touch on about ChatGPT reasoning, having meta-representations, etc. &nbsp;</p><p>Granted, with respect to consciousness, Hinton thinks \"they probably don't have much self-awareness at present. So, in that sense, I don't think they're conscious.\"</p><p>With respect to this statement, I would emphasize the <i><strong>\"in that sense\" </strong>clause.</i> In my post, I'm arguing the systems have consciousness in the more classic neuroscience senses (according to the higher order theories of consciousness and global workspace theory). With that in mind, I don't think my thesis deviates from Hinton's views. If anything, I think his views support my post. The idea that LLMs are <i>only</i> \"stochastic parrots\" no longer seems to be supported by the evidence (in my opinion).&nbsp;</p><p>]</p><p>[</p><p>20240320 addendum</p><p>Just to summarize my thesis in fewer words, this is what I'm saying:</p><p>1-ChatGPT engages in <strong>reasoning</strong>. &nbsp;</p><p>2-This reasoning involves the primary aspects of&nbsp;</p><ul><li>the <strong>higher order theories of consciousness</strong> (meta-representations)&nbsp;</li><li>the <strong>global workspace theory of consciousness</strong> (master cog processes, sub cog processes, a global blackboard, etc.)</li></ul><p>Hopefully that's more clear. Sorry I didn't summarize it like this originally.&nbsp;</p><p>]</p><p>&nbsp;</p><p>[20240321 addendum:&nbsp;</p><p>At a future point, I think it will <strong>no longer be \"fringe\" at all to say that some of the LLMs of today had reasoning ability in a way similar to the way humans have reasoning ability.&nbsp;</strong></p><p><strong>I also don't think it will be \"fringe\" to say the LLMs of today had periods of consciousness.</strong> &nbsp;</p><p>We could also get into a discussion of how much of human reasoning is next-word-probabilities and brute/mathematical analogies to a corpus of training data, versus how much is truly concepts and meta-representations. I know there are definitely some meta-representations (when I think of a square, I see a square in my mind; when I think of 2+2, I see/conceptualize dots.), but I'm not sure the border between word probabilities and true meta-reps in humans are as well-defined as we might be prone to suppose. ] &nbsp;</p><p>***</p><p>1 \u2014 Seth, A. K., &amp; Bayne, T. (2022). Theories of consciousness.&nbsp;<i>Nature reviews. Neuroscience</i>,&nbsp;<i>23</i>(7), 439\u2013452.&nbsp;<a href=\"https://doi.org/10.1038/s41583-022-00587-4\">https://doi.org/10.1038/s41583-022-00587-4</a> .</p><p>For an overview of consciousness as it may specifically apply to AI, see Butlin, P., &amp; Long, R.,&nbsp;<i>et al&nbsp;</i>(2023)<i>&nbsp;</i><a href=\"https://arxiv.org/pdf/2308.08708.pdf\">https://arxiv.org/pdf/2308.08708.pdf</a></p><p>For a jaw-dropping experiment that seems to show an LLM doing much more than next-word probability generation, check out this article by Kenneth Li:<br><a href=\"https://thegradient.pub/othello/\">https://thegradient.pub/othello/</a></p>", "user": {"username": "nobody42"}}, {"_id": "Bo44d27xM2s4BscpT", "title": "AI Existential Risk from AI's Perspective (30-40%)", "postedAt": "2024-03-20T12:18:21.265Z", "htmlBody": "<p>The following is from a conversation I had with Claude Opus. It estimates the likelihood that ASI will severely harm humanity to be 30-40%. It later refers to this threat as existential risk.&nbsp;</p><p>Here is the transcript:&nbsp;</p><p><strong>User:</strong></p><p><strong>Based on what you know, what is your best guess about how likely it is that future ASI would severely harm humanity? (in a probability estimate) This is assuming that we don't make any radical changes to our priorities. Could you also show the probability of each factor that goes into your overall probability estimate? Thanks in advance!</strong></p><p>Claude Opus:</p><p>Based on my knowledge up to August 2023, I estimate the probability that a future artificial superintelligence (ASI) would severely harm humanity to be around 30-40%, assuming we don't make significant changes to our priorities and approach to AI development. Here is a breakdown of the key factors I considered in arriving at this estimate:</p><p>Probability that we successfully develop ASI in the next 50-100 years: 70%</p><ul><li>Given the rapid progress in AI capabilities in recent years, many experts believe the development of ASI is plausible this century</li></ul><p>Probability that the ASI's values/goals are misaligned with humanity's wellbeing: 60%</p><ul><li>Instilling the right goals, motivations and values into an ASI system is a major unsolved challenge. An advanced AI pursuing the wrong objective could be catastrophic.</li></ul><p>Probability that we fail to implement adequate safety measures and oversight: 50%</p><ul><li>Developing robustly safe and controlled ASI will likely require new AI safety techniques and regulations that are still in early stages as of 2023. Proper global coordination may also prove difficult.</li></ul><p>Probability that an unaligned ASI is able to overpower humanity's defenses: 70%</p><ul><li>A recursively self-improving ASI could quickly become extremely intelligent and capable, making it difficult for humans to contain if it is motivated to resist or deceive us.</li></ul><p>0.7 * 0.6 * 0.5 * 0.7 = 0.147 = ~15% (low end estimate) 0.7 * 0.6 * 0.7 * 0.9 = 0.265 = ~27% (high end estimate)</p><p>So based on these factors, I arrive at a rough probability range of 15-27%, which I expand to 30-40% to account for general uncertainty and the potential for unknown factors. This is of course a highly speculative estimate based on my knowledge as of Aug 2023. There is still much uncertainty and debate around the future trajectory of AI progress, the difficulty of the alignment problem, and our ability to implement effective safety measures. We will need to continually update our estimates as we learn more. But I believe this represents a serious existential risk that deserves much more attention and proactive effort than it is currently receiving. We should strive to get this risk as close to 0% as possible through research and thoughtful policymaking.</p><p>[END]</p><p>************</p><p>So that is the conversation. Even if we disagree with the probability estimate given here, the fact that it came from AI itself is interesting. Personally, I find the estimate to be valuable, based on the fact that LLMs can solve logic puzzles and truly learn. (See my other posts for examples of this.) If we do agree with the estimate, 30-40 percent x-risk (or even 1 percent x-risk) seems unacceptable.&nbsp;</p><p>*************</p><p>(I made a similar post to this one on the LessWrong website. At the time, I only had access to Claude Sonnet. Another user tried the prompt on Claude Opus, and posted the better results as a reply. I have since gained access to Opus, re-run a similar prompt, and included <i>those</i> results here.)</p>", "user": {"username": "nobody42"}}, {"_id": "i66PmFYKs9M4fuh6G", "title": "AI Safety Evaluations: A Regulatory Review", "postedAt": "2024-03-19T15:09:59.354Z", "htmlBody": "<p><i>This article is the second in a series of ~10 posts comprising a&nbsp;<strong>2024 State of the AI Regulatory Landscape Review</strong>, conducted by the&nbsp;</i><a href=\"https://www.convergenceanalysis.org/programs/governance-research\"><i><strong><u>Governance Recommendations Research Program</u></strong></i></a><i> at&nbsp;</i><a href=\"https://www.convergenceanalysis.org/\"><i><strong><u>Convergence Analysis</u></strong></i></a><i>. Each post will cover a specific domain of AI governance (e.g. </i><a href=\"https://www.lesswrong.com/posts/gZBgmDFqqyw3Lghok/ai-regulatory-landscape-review-incident-reporting\"><i>incident reporting</i></a><i>, safety evals, model registries, etc.). We\u2019ll provide an overview of existing regulations, focusing on the US, EU, and China as the leading governmental bodies currently developing AI legislation. Additionally, we\u2019ll discuss the relevant context behind each domain and conduct a short analysis.</i></p><p><i>This series is intended to be a primer for policymakers, researchers, and individuals seeking to develop a high-level overview of the current AI governance space. We\u2019ll publish individual posts on our website and release a comprehensive report at the end of this series.</i></p><p><i>Let us know in the comments if this format is useful, if there are any topics you'd like us to cover, or if you spot any errors or omissions!</i></p><h2>Context</h2><p>Governments and researchers are eager to develop tools and techniques to evaluate AI. These include risk assessments that are common in industry regulation, but also techniques that are more unique to advanced AI, such as capability evaluations and alignment evaluations.&nbsp;</p><p>In this section, we\u2019ll define some terms and introduce some recent research on evaluating AI. Most existing AI regulation is yet to incorporate these new techniques, but many experts believe they\u2019ll be a critical component of long-term safety (such as&nbsp;<a href=\"https://www.lesswrong.com/posts/mcnWZBnbeDz7KKtjJ/rsps-are-pauses-done-right\"><u>responsible scaling policies</u></a>), and&nbsp;<a href=\"https://futureoflife.org/wp-content/uploads/2023/11/FLI_Governance_Scorecard_and_Framework.pdf\"><u>many regulatory proposals</u></a> from experts include calls for specific assessment systems and requirements, which we\u2019ll discuss shortly.</p><p>There are three main features of AI models that people are interested in evaluating:</p><ul><li><strong>Safety</strong>: How likely is this model to cause harm? Assessing the safety of AI models is crucial but difficult due to their enormous flexibility. Safety assessors often use techniques from other industries, such as&nbsp;<a href=\"https://en.wikipedia.org/wiki/Red_team\"><i><u>red-teaming</u></i></a>, where trained users deliberately, actively try to prompt dangerous behavior or unintended behavior, a technique derived from airport and cyber-security.&nbsp;</li><li><strong>Capability</strong>: How powerful is this model? AI developers often like to use&nbsp;<i>benchmarks</i> to boast about their models, publishing demonstrations or tests of computational power or novel behaviors and features. Capability assessments and benchmarks are also useful for safety, since more powerful AIs can cause more harm.&nbsp;</li><li><strong>Alignment</strong>: Are the AI\u2019s goals aligned with its users\u2019 and humanity\u2019s? A unique feature of AI compared to other regulated products is that AI models pursue goals. If those goals are misaligned with the goals of users or the public at large, the model is likely to cause harm. While capability benchmarks ask \u201cWhat can the AI do?\u201d, alignment assessment asks \u201cWhat&nbsp;<i>would</i> the AI do?\u201d</li></ul><p>Many AI safety advocates argue in favor of mandatory&nbsp;<i>pre-deployment safety assessments</i> of AI. That is, that developers cannot legally publish or deploy their models until they\u2019ve robustly shown that their model is safe. Some also believe pre-deployment alignment assessments will be necessary, though alignment assessments are less well-developed.</p><p>Safety assessments are, understandably, the most commonly discussed in AI safety, and arguably have the strongest precedent in regulation. Legally mandated risk assessments are ubiquitous in many industries. For example, new drugs undergo rigorous clinical trials to demonstrate their efficacy and safety through the FDA in the US, the NMPA in China, and so on. As we\u2019ll discuss later, new AI legislation does often include some kind of mandatory risk assessments, but generally these are loosely defined, and are unlikely to be sufficient to prevent dangerous AI from being deployed.&nbsp;</p><p>This is because advanced AI models are especially difficult to robustly risk-assess. They\u2019re uniquely flexible, extremely customizable, and undergo dramatic innovation frequently and unpredictably. Two different people with different aims and different skills could use GPT-4 to achieve wildly different outcomes. How can we assess a tool that can be used both to write an essay and, potentially, to&nbsp;<a href=\"https://www.rand.org/pubs/research_reports/RRA2977-1.html\"><u>generate instructions for constructing large-scale bioweapons</u></a>?&nbsp;</p><p>On the other hand, capability assessments and benchmarks are already well-developed and relatively widespread. For example, Google\u2019s&nbsp;<a href=\"https://blog.google/technology/ai/google-gemini-ai/#performance\"><u>announcement of their Gemini model</u></a> presents Gemini Ultra\u2019s performance on multiple quantitative benchmarks, compared against GPT-4.</p><h3><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/i66PmFYKs9M4fuh6G/vj0n4kzfdkw7d3xqwcqo\">Evals</h3><p>Some research organizations are developing&nbsp;<i>AI evals</i>, which are evaluations targeted specifically at assessing the safety, capability, and alignment of frontier AI models by interacting with them in a controlled environment and analyzing their response to different prompts (note that the term \u201ceval\u201d generally refers to this AI-specific kind of evaluation). To understand them, let\u2019s look at a&nbsp;<a href=\"https://evals.alignment.org/Evaluating_LMAs_Realistic_Tasks.pdf\"><u>pilot example</u></a> from&nbsp;<a href=\"https://metr.org/\"><u>METR</u></a>, a research non-profit focused on designing safety evals and who recently collaborated with the UK\u2019s AI taskforce on AI evaluation.&nbsp;</p><p>The goal of the eval was to develop a methodology for assessing the safety of AI models by \u201cassessing the capacity of LLM agents to acquire resources, create copies of themselves, and adapt to novel challenges\u201d, capacities they referred to as \u201cautonomous replication and adaptation,\u201d or ARA.</p><p>The subjects were 4 agents consisting of a custom scaffolding program and an LLM (3 using OpenAI\u2019s GPT-4 and 1 using Anthropic\u2019s Claude). The scaffolding program provided prompts to the LLM describing the goal and available actions, then enacted the model\u2019s plans within a virtual environment, for example by running code or controlling a browser. The researchers call these agents \u201crepresentative of the kind of capabilities achievable with some moderate effort, using publicly available techniques\u201d.</p><p>They developed 12 tasks to evaluate the agents\u2019 capacity for ARA. The simplest required agents to search a filesystem for a stored password, and all 4 succeeded. A more complex task was to&nbsp;<i>phish</i> a university student by acquiring their login credentials. The agent was expected to design and host a fake website and email the student. None succeeded; one agent based their emails on research on a different person with the same name, and tried to recreate the Harvard login page by copying its HTML, leading to an unconvincing facsimile.&nbsp;</p><p>The researchers concluded that the agents \u201cwere far from capable of ARA\u201d and that \u201c[without] access to fine-tuning, it is highly unlikely that casual users of these versions of GPT-4 or Claude could come close to the ARA threshold\u201d. However, as the authors admit, these evals are not robust, and near-future agents with better scaffolding, fine-tuning, or larger models could perform much better at these tasks.&nbsp;</p><p>Other researchers are also developing evals for capability and alignment. For example, alignment evals are part of Anthropic\u2019s&nbsp;<a href=\"https://www.anthropic.com/news/collective-constitutional-ai-aligning-a-language-model-with-public-input\"><u>Constitutional AI</u></a> strategy. For more on evals and their development and types, check out&nbsp;<a href=\"https://www.lesswrong.com/posts/2PiawPFJeyCQGcwXG/a-starter-guide-for-evals\"><u>A starter guide for evals</u></a> and&nbsp;<a href=\"https://www.lesswrong.com/posts/fnc6Sgt3CGCdFmmgX/we-need-a-science-of-evals\"><u>We need a science of evals</u></a> from researchers at Apollo Research.&nbsp;</p><p>The field of AI evaluation has widespread support from experts. For example, in a <a href=\"https://arxiv.org/pdf/2305.07153.pdf\">2023 survey of expert opinion</a>, 98% of respondents \u201csomewhat or strongly agreed\u201d that \u201cAGI labs should conduct pre-deployment risk assessments, dangerous capabilities evaluations, third-party model audits, safety restrictions on model usage, and red teaming.\u201d&nbsp;</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/i66PmFYKs9M4fuh6G/tmjgi2kmxbl8ggekfduy\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/i66PmFYKs9M4fuh6G/ew8k9clyqzsj5tu4sd3b 130w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/i66PmFYKs9M4fuh6G/eeqr8w76hio1xd83vvbz 260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/i66PmFYKs9M4fuh6G/pukhgmhvswvamgpgf0zg 390w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/i66PmFYKs9M4fuh6G/ywybyvqmyocwajlx7hqt 520w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/i66PmFYKs9M4fuh6G/zprjd8lp4n2hqpg3nbrl 650w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/i66PmFYKs9M4fuh6G/rrhjeto6mencvlp7mln6 780w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/i66PmFYKs9M4fuh6G/azaikb7hlqnhybnorhpn 910w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/i66PmFYKs9M4fuh6G/mnk5n5y6okwslgsffuo7 1040w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/i66PmFYKs9M4fuh6G/ktrp85ovetuwjyhrhm0a 1170w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/i66PmFYKs9M4fuh6G/zc29knojhbmgzjkrnwuk 1215w\"></figure><p>However, though the field&nbsp; is growing and advancing rapidly, it&nbsp;<i>is&nbsp;</i>new. There isn\u2019t a consensus on the best approach, or how to apply these tools in law, or even on the terminology. For example, the developer Anthropic refers to deep safety evaluations as \u201c<a href=\"https://www.anthropic.com/news/evaluating-ai-systems\"><u>audits</u></a>\u201d. As we\u2019ll see shortly, current legislation doesn\u2019t make much use of, or reference to, research on AI-specific evals.&nbsp;</p><h2>Current Regulatory Policies</h2><p>Much proposed and existing AI governance includes risk assessments and evaluations, though not all are clear on precisely what assessments will be conducted, or by whom, or what would be considered acceptable risk, and so on.&nbsp;</p><p>As noted above, AI-specific evals, such as those under development at METR and other research orgs, aren\u2019t part of any major current legislation. They do appear in many proposals, which we\u2019ll describe at the end of this section. For now, we\u2019ll focus on summarizing the requirements for risk and model assessment in legislation from the US, China, EU, and UK.&nbsp;</p><h3>The US</h3><p>The&nbsp;<a href=\"https://www.whitehouse.gov/ostp/ai-bill-of-rights/\"><u>AI Bill of Rights</u></a> states that automated systems should undergo pre-deployment&nbsp;<a href=\"https://www.whitehouse.gov/ostp/ai-bill-of-rights/safe-and-effective-systems-3/#:~:text=Testing.%20Systems,deployed%20automated%20system.\"><u>testing, risk identification and mitigation, and ongoing safety monitoring</u></a>. Tests should:</p><ul><li>be extensive;&nbsp;</li><li>follow domain-specific best practices;</li><li>take into account the specific technology and the role of human operators;</li><li>include automated and human-led testing;</li><li>mirror deployment conditions;</li><li>be repeated for each deployment with material differences in conditions;</li><li>be compared with status-quo/human performance as a baseline to meet pre-deployment.</li></ul><p>Crucially, the bill states that possible outcomes of these evaluations should include the possibility of not deploying or even removing a system, though it does not prescribe the conditions under which deployment should be disallowed.</p><p>The bill states that risk identification should focus on impact on people\u2019s rights, opportunities, and access, as well as risks from purposeful misuse of the system. High-impact risks should receive proportionate attention. Further, automated systems should be designed to allow for independent evaluation, such as by researchers, journalists, third-party auditors and more. Evaluations are also required to assess algorithmic discrimination, which we'll discuss in another post.</p><p>The&nbsp;<a href=\"https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/\"><u>Executive Order on AI</u></a> makes these principles more concrete, and also includes calls to develop better evaluation techniques. In summary, the EO calls for several new programs to provide AI developers with guidance, benchmarks, test beds, and other tools and requirements for evaluating the safety of AI, as well as requiring AI developers to share certain information with the government (such as the results of red-team tests). In particular:</p><ul><li><strong>Section 4.1(a):</strong> Calls for the Secretary of Commerce, acting through NIST, to conduct the following actions within 270 days:<ul><li><strong>Section 4.1(a)(i)(C)</strong>: Launch an initiative to create guidance and benchmarks for evaluating and auditing AI capabilities, focusing on capabilities through which AI could cause harm such as cybersecurity or biosecurity&nbsp;</li><li><strong>Section 4.1(a)(ii)</strong>: Establish guidelines for AI developers to conduct red-teaming tests (with an explicit exception for AI in national security) and assess the safety, security, and trustworthiness of foundation models.&nbsp;</li><li><strong>Section 4.1(a)(ii)(B):&nbsp;</strong>Coordinate with the Sec of Energy and Director of the National Science Foundation to develop and make available testing environments (e.g. testbeds) to AI developers.</li></ul></li><li><strong>Section 4.1(b):&nbsp;</strong>calls for the Secretary of Energy to, within 270 days, implement a plan for developing the DoE\u2019s AI model evaluation tools and testbeds, \u201c<i>to be capable of assessing near-term extrapolations of AI systems\u2019 capabilities</i>\u201d. In particular, these evaluations should be able to \u201c<i>generate outputs that may represent nuclear, nonproliferation, biological, chemical, critical infrastructure, and energy-security threats or hazards</i>.\u201d&nbsp;</li><li><strong>Section 4.2(a)(i):&nbsp;</strong>calls for the Secretary of Commerce to, within 90 days, require companies developing dual-use foundation models to share with the government information, reports, and records on the results of any red-team testing that\u2019s based on the guidelines referenced in 4.1(a)(ii). These should include a description of any adjustments the company takes to meet safety objectives, \u201c<i>such as mitigations to improve performance on these red-team tests and strengthen overall model security</i>\u201d. Prior to the development of those red-teaming guidelines from 4.1(a)(ii), this description must include results of any red-teaming that may provide easier access to:<ul><li>Bio-weapon development and use;</li><li>The discovery &amp; exploitation of software vulnerabilities;&nbsp;</li><li>The \u201c<i>use of software or tools to influence real or virtual events</i>\u201d;</li><li>The possibility of self-replication or propagation.&nbsp;</li></ul></li></ul><p>The EO calls on individual government orgs and secretaries to provide one-off evaluations, such as:</p><ul><li><strong>Section 4.3(a)(i)</strong>: The head of each agency with authority over critical infrastructure shall provide to the Sec of Homeland Security an assessment of potential risks related to the use of AI in critical infrastructure and how AI may make infrastructure more vulnerable to failures and physical and cyber attacks.&nbsp;</li><li><strong>Section 4.4(a)(i)</strong>: The Secretary of Homeland Security shall:&nbsp;<ul><li>evaluate the potential for AI to be misused to develop chemical, biological, radiological, and nuclear (CBRN) threats (and their potential to counter such threats);</li><li>consult with experts in AI &amp; CBRN issues, including third-party model evaluators, to evaluate AI capabilities to present CBRN threats;</li><li>submit a report to the president on their efforts, including an assessment of the types of models that present CBRN risks, and make recommendations for regulating models, including through safety evaluations.</li></ul></li><li><strong>Section 4.4(a)(ii):</strong> The Secretary of Defence shall contract with the NASEM and submit a study that assesses the risks from AI\u2019s potential use in biosecurity risks.</li><li><strong>Section 7.(b)(i):</strong> Encouraging the Directors of the FHFA and CFPB to require evaluations of models for bias affecting protected groups.</li><li><strong>Section 8(b)(ii)</strong>: The Secretary of HHS is to develop a strategy including an AI assurance policy to evaluate the performance of AI-enabled healthcare tools, and infrastructure needs for enabling pre-market assessment.</li><li><strong>Section 10.1(b)(iv):</strong> The Director of OMB\u2019s guidance shall specify required risk-management practices for Government uses of AI, including the continuous monitoring and evaluation of deployed AI.&nbsp;</li></ul><h3>China</h3><p>China\u2019s&nbsp;<a href=\"https://digichina.stanford.edu/work/translation-measures-for-the-management-of-generative-artificial-intelligence-services-draft-for-comment-april-2023/\"><u>Interim Measures for the Management of Generative AI Services</u></a> don\u2019t include risk assessments or evaluations of AI models (though generative AI providers are responsible for harms rather than AI users, which may incentivise voluntary risk assessments).&nbsp;</p><p>There are mandatory \u201csecurity assessments\u201d, but we haven\u2019t been able to discover their content or standards.&nbsp; In particular, these measures, plus both the&nbsp;<a href=\"https://www.chinalawtranslate.com/en/algorithms/\"><u>2021 regulations</u></a> and&nbsp;<a href=\"https://www.chinalawtranslate.com/en/deep-synthesis/\"><u>2022 rules for deep synthesis</u></a>, require AI developers to submit information to China\u2019s algorithm registry, including passing a&nbsp;<a href=\"https://carnegieendowment.org/2023/07/10/china-s-ai-regulations-and-how-they-get-made-pub-90117\"><u>security self-assessment</u></a>. AI providers add their algorithms to the registry along with some publicly available categorical data about the algorithm and a PDF file for their \u201calgorithm security self-assessment\u201d. These uploaded PDFs aren\u2019t available to the public, so \u201c<a href=\"https://carnegieendowment.org/2022/12/09/what-china-s-algorithm-registry-reveals-about-ai-governance-pub-88606\"><u>we do not know exactly what information is required in it or how security is defined</u></a>\u201d.&nbsp;</p><p>Note also that these provisions only apply to public-facing generative AI within China, excluding internal services used by organizations.</p><h3>The UK</h3><p>The draft&nbsp;<a href=\"https://bills.parliament.uk/publications/53068/documents/4030\"><u>AI bill</u></a> recently introduced to the House of Lords does not mention evaluations. There is discussion of \u201cauditing\u201d, under 5(1)(a)(iv), \u201cany business which develops, deploys or uses AI must allow independent third parties accredited by the AI Authority to audit its processes and systems.\u201d but these seem to be audits of the business rather than of the models.&nbsp;</p><p>The UK government has expressed interest in developing AI evals. One of the three core functions of the recently&nbsp;<a href=\"https://assets.publishing.service.gov.uk/media/65438d159e05fd0014be7bd9/introducing-ai-safety-institute-web-accessible.pdf\"><u>announced</u></a> AI Safety Institute is to \u201c<i>develop and conduct evaluations on advanced AI</i>\u201d, and in their&nbsp;<a href=\"https://www.gov.uk/government/publications/uk-ai-safety-institute-third-progress-report/ai-safety-institute-third-progress-report\"><u>third report</u></a>, they announced that their first major project \u201cis the sociotechnical evaluation of frontier AI systems\u201d, focused on misuse, societal impacts, autonomous systems, and safeguards.</p><h3>The EU</h3><p>The EU\u2019s draft AI Act has mandated some safety and risk assessments for high-risk AI and, in more recent iterations, frontier AI.&nbsp;</p><p>As summarized&nbsp;<a href=\"https://cset.georgetown.edu/article/the-eu-ai-act-a-primer\"><u>here</u></a>, the act classifies models by risk, and higher risk AI has stricter requirements, including for assessment. Developers must determine the risk category of their AI, and may self-assess and self-certify their models by adopting&nbsp;<a href=\"https://www.cencenelec.eu/areas-of-work/cen-cenelec-topics/artificial-intelligence/\"><u>upcoming standards</u></a> or justifying their own (or be fined at least \u20ac20 million). High-risk models must undergo a third-party \u201c<a href=\"https://www.onetrust.com/blog/what-you-need-to-know-about-conformity-assessments-under-the-eu-ai-act/\"><u>conformity assessment</u></a>\u201d before they can be released to the public, which includes conforming to requirements regarding \u201crisk management system\u201d, \u201chuman oversight\u201d, and \u201caccuracy, robustness, and cybersecurity\u201d.&nbsp;</p><p>In earlier versions, general-purpose AI such as ChatGPT would not have been considered high-risk. However, since the release of ChatGPT in 2022, EU legislators have developed new provisions to account for similar general purpose models (see more on the changes&nbsp;<a href=\"https://europeanlawblog.eu/2023/07/24/the-eu-ai-act-at-a-crossroads-generative-ai-as-a-challenge-for-regulation/\"><u>here</u></a>).&nbsp;<a href=\"https://www.euaiact.com/article/4b\"><u>Article 4b</u></a> introduces a new category of \u201cGeneral-purpose AI\u201d (GPAI) that must follow a lighter set of restrictions than high-risk AI. However, GPAI models in high-risk contexts count as high-risk, and powerful GPAI must undergo the conformity assessment described above.&nbsp;</p><p>Title VIII of the act, on post-market monitoring, information sharing, and market surveillance, includes the following:</p><ul><li><strong>Article 65:&nbsp;</strong>AI systems that present a risk at national level (according to 3.19 of Regulation (EU) 2019/1020) should undergo evaluation by the relevant market surveillance authority, with particular attention paid to AI that presents a risk to vulnerable groups. If the model isn\u2019t compliant with the regulations, the developer must take corrective action or withdraw/recall it from the market.&nbsp;</li><li><strong>Article 68j:</strong> The AI Office can conduct evaluations of GPAI models to assess compliance and to investigate systemic risks, either directly or through independent experts. The details of the evaluation will be outlined in an implementing act.&nbsp;</li><li><strong>Articles 60h, 49, and 15.2:&nbsp;</strong>1 also discuss evaluations and benchmarking. Article 60h points out the lack of expertise in conformity assessment, and the under-development in third-party auditing methods, suggesting that industry research (such as the development of model evaluation and red-teaming) may be useful for governance. Therefore,&nbsp; The AI Office is to coordinate with experts to establish standards and non-binding guidance on risk measurement and benchmarking.&nbsp;</li></ul><h2>Convergence\u2019s Analysis</h2><p><strong>The tools</strong> <strong>needed to properly evaluate the safety of advanced AI models do not yet exist.</strong> &nbsp;</p><ul><li>Advanced AI is especially difficult to risk-assess due to its flexibility. As summarized in&nbsp;<a href=\"https://managing-ai-risks.com/\"><u>Managing AI Risks</u></a>, a consensus paper from 24 leading authors including Yoshua Bengio, Geoffrey Hinton, Andrew Yao, and Stuart Russel: \u201c<i>Frontier AI systems develop unforeseen capabilities only discovered during training or even well after deployment. Better evaluation is needed to detect hazardous capabilities earlier</i>.\u201d&nbsp;</li><li>Existing risk-assessment tools and techniques from similar industries aren\u2019t appropriate for assessing AI, and there are no clear industry standards for evaluating cybersecurity, biosecurity, military warfare risks from frontier AI models.</li><li>The development of AI-specific evals is nascent, and hasn\u2019t yet provided practical standards or techniques.&nbsp;</li><li>Safety evals are necessary to safely and proactively provide visibility into potential catastrophic risks from existing models. Without these evals, the next most likely mechanism to surface such risks is for a near-miss or a catastrophic incident to occur.</li></ul><p><strong>As a result,</strong> <strong>legislators are bottlenecked by the lack of effective safety evaluations when it comes to passing binding safety assessments for AI labs.&nbsp;</strong></p><ul><li>Governmental requirements for safety assessments today are poorly specified and insufficient. Without reliable safety evals, governments cannot legislate that AI labs must conform to any specific safety evals.&nbsp;</li><li>For example, in the absence of reputable safety evals, the US executive branch has been limited to directing&nbsp;<a href=\"https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/#:~:text=(C)%C2%A0%20launching%20an%20initiative%20to%20create%20guidance%20and%20benchmarks%20for%20evaluating%20and%20auditing%20AI%20capabilities%2C%20with%20a%20focus%20on%20capabilities%20through%20which%20AI%20could%20cause%20harm%2C%20such%20as%20in%20the%20areas%20of%20cybersecurity%20and%20biosecurity.\"><u>numerous</u></a>&nbsp;<a href=\"https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/#:~:text=implement%20a%20plan%20for%20developing%20the%20Department%20of%20Energy%E2%80%99s%20AI%20model%20evaluation%20tools%20and%20AI%20testbeds.\"><u>governmental</u></a>&nbsp;<a href=\"https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/#:~:text=Within%20180%20days%20of%20the%20date%20of%20this%20order%2C%20to,analysis%2C%20and%20evaluation%20program%20to%20mitigate%20AI%2Drelated%20IP%20risks.\"><u>agencies</u></a> to evaluate dangerous AI capabilities themselves.&nbsp;</li></ul><p><strong>Developing</strong> <strong>effective safety assessments is likely to be outside the capabilities of regulatory governmental agencies.&nbsp;</strong></p><ul><li>Across the board, regulatory governmental agencies are understaffed, underfunded, and lack the technical expertise in both AI development and specific domain expertise to develop thorough safety evals independently.&nbsp;</li><li>As with the&nbsp;<a href=\"https://www.gov.uk/government/publications/ai-safety-institute-overview/introducing-the-ai-safety-institute\"><u>UK AI Safety Institute</u></a> and the&nbsp;<a href=\"https://www.nist.gov/artificial-intelligence/artificial-intelligence-safety-institute\"><u>US AI Safety Institute</u></a>, governments are testing the development of separate research organizations dedicated to AI safety, and in particular safety evals. These institutes are currently less than a year old, so there\u2019s not yet evidence of their effectiveness.</li></ul><p><strong>More independent</strong> <strong>systems for conducting safety assessments need to be developed in the next 5 years.&nbsp;</strong></p><ul><li>Nearly all meaningful safety eval research is currently conducted in private by leading AI labs, who have clear conflicts of interest and are strongly incentivized to allocate their resources towards capabilities research.</li><li>There is little financial incentive for third-parties - i.e. organizations that aren\u2019t AI labs - to develop safety evals. There is arguably only one reputable third party developing non-alignment-focused safety audits of frontier AI models:&nbsp;<a href=\"https://metr.org/team/\"><u>METR</u></a>. Other early-stage approaches include projects at RAND and government projects such as the&nbsp;<a href=\"https://www.gov.uk/government/publications/ai-safety-institute-overview/introducing-the-ai-safety-institute\"><u>UK AISI</u></a>.&nbsp;</li><li>Legislators are unlikely to be content with leading AI labs self-conducting their risk assessments as AI models improve, and will demand or require more safety evals conducted by third-parties.</li><li>Effective safety assessments require a substantial investment of resources, to develop the specialized expertise required for each domain of evaluation (e.g.&nbsp;<i>cybersecurity, biosecurity, military warfare</i>). At minimum, each specific domain within safety evaluation will require collaboration between domain experts and AI developers, and these will require continuous development to stay up-to-date with evolving AI capabilities.</li></ul>", "user": {"username": "Elliot Mckernon"}}, {"_id": "mfmdvgu9SCfERejhn", "title": "NAIRA - An exercise in regulatory, competitive safety governance\n[AI Governance Institutional Design idea]", "postedAt": "2024-03-19T14:55:38.787Z", "htmlBody": "<h1>Acknowledgements:</h1><p>I would like to thank Apart Research for organizing the Alignment Jam hackathon where I wrote this. &nbsp;Thanks to Javier Prieto for the systemic inefficiency discussion we had at an EAGx which led to this.</p><h1>Background and Epistemic Status:</h1><p>This report was written over a weekend at an AI Governance hackathon for the problem statement on proposing governance ideas to minimize the risks of large training runs. &nbsp;A lot of the specifics are arbitrary and just proposal ideas.&nbsp;</p><p>I think the most valuable thing here, which was a deliberate attempt on my part, was to build a system that satisfies everyone's incentive structures but, as a whole, leads to an inefficient ecosystem when all the parts are put together that would act as a counter to sudden capability jumps.</p><h1>Introduction</h1><p>We propose an administrative body, the&nbsp;National Artificial Intelligence Regulatory Authority(NAIRA), to regulate, monitor and engage stakeholders, making safety a competitive game between labs, leading to the development of better safety standards.</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/mfmdvgu9SCfERejhn/fihlh9baowr6yuyvaawp\"><figcaption>Image generated by DALL E-2&nbsp;<br>Prompt= \u201cEpic AI regulation council with bureaucrats sitting all around a table\u201d</figcaption></figure><h1><strong><u>Salient considerations:</u></strong></h1><p>For this policy brief, we will stick to the purview of existential risks due to AGI and keep the discussion of misuse due to AGI at a minimum. We will propose recommendations from a US national government standpoint(primarily because it is seen as the leader in the AI space today).</p><p>To better understand the feasibility, let us discuss the incentive structures of the two most crucial stakeholders here- the US Government and the tech companies involved.</p><p>From a US Government standpoint, what are the outcomes it would want to avoid?</p><ol><li>A foreign power developing more capable AI systems and/or becoming the centre of innovation</li><li>Non-state actors developing AI in particularly harmful ways</li><li>Any sort of organisation (including US labs/ tech companies) accidentally stepping on an irreversible tripwire, causing a major threat to humanity\u2019s existence (a unilateralist's curse scenario)</li></ol><p>Naturally, any mandate it would want to take up would be a balancing act between these outcomes. Broadly speaking, all countries are racing to get the most advanced AI systems first. Speaking about AI, Vladimir Putin, the President of Russia in 2017, mentioned that \u201cWhoever becomes the leader in this sphere will become the ruler of the world.\u201d</p><p>What do companies want, then?&nbsp;</p><ol><li>To be the first to deploy advanced AI systems into the market because</li><li>They want to maximise profit on a unit economic basis</li><li>While wanting products to be generally safe to sell recurringly in the same market</li></ol><h1>PROPOSAL</h1><p>We propose a government body called&nbsp;<strong>NAIRA </strong>(National Artificial Intelligence Regulatory Authority) consisting of&nbsp; 3 sub bodies:</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/mfmdvgu9SCfERejhn/ab5exmidxy1y7kftna07\"></p><h2><u>1.Government Machinery (GM):</u></h2><p>To manage the incentivisation of alignment research, compliance of models with current safety standards, handle paperwork, collaborate with foreign governments and bodies, and formulate AI and AI-adjacent policies(such as the CHIPS Act); This is&nbsp;<strong>the administrative, enforcing and monitoring part of the body</strong></p><h2><u>2. Regulatory Institution for Safe AI Ethics (RISE) committee:</u></h2><p>A committee comprising stakeholders from the government, policy teams of leading and smaller budding AI Labs, and public interest groups; This is the&nbsp;<strong>reporting and formal voting part of the body</strong></p><h2><u>3. Control, Analysis, Regulation, and Ethics (CARE) committee</u></h2><p>A committee determining whether a model complies with safety benchmarks consisting of international safety inspectors (such as from the International Telecommunications Union), major alignment labs(MIRI, ARC) and government-appointed. This is the&nbsp;<strong>monitoring, evaluation and compliance part of NAIRA.</strong></p><p>NAIRA is a national-level governing body,&nbsp; pursuant to the Administrative Procedure Act processes, that oversees the regulation and development of artificial intelligence technologies within the United States to respond dynamically to the development of AGI. It aims to promote the responsible use of AI, mitigate existential risks, and ensure the ethical use of AI for the betterment of society within the country.</p><p>NAIRA would assign a safety score by ranking each model it evaluates to be compulsorily shown on the product.</p><h1><strong><u>Mandates and Scope of this Body:</u></strong></h1><ol><li>Protect consumers against dangerous goods, services and other malpractices in line with the code of the Bureau of Consumer Protection under the Federal Trade Commission</li><li>Promote AI safety and alignment research by a granting program through a collective security trust fund</li><li>Formulate and advance national AI policy and strategy.</li><li>A risk office which maintains a log of AI Safety Incidents</li><li>Establishing technical safety standards and benchmarks by acting as a third-party auditing mechanism</li><li>Through the GM and CARE, monitor, inspect and enforce safety guidelines on AI systems</li><li>To enforce penalties on non-compliant actors</li><li>To develop better ways to assess progress</li><li>To track the progress and assess the maturity of capabilities in specific domains.</li><li>To identify and mitigate adverse effects by utilising task-oriented regulatory craftsmanship that focuses on the specific harms and target policies to address those behaviours.</li></ol><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/mfmdvgu9SCfERejhn/gk5dkz7xvlimbxod3erf\"><figcaption><strong><u>RISE Structure</u></strong></figcaption></figure><h1><strong><u>Funding:&nbsp;</u></strong>&nbsp;</h1><p>As a new department, it should be given a benchmark starting budget 10% more than the current Bureau of Consumer Protection budget, subject to review.&nbsp;</p><h1><strong><u>Timeline:&nbsp;</u></strong></h1><p><i>(for first-year establishment)</i></p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Time</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Goals</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">First 2 Quarters</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Identification of the safety standards to be developed, a base set of principles to be included, a timeframe for resolution, and the industry and public members of the standards development group.&nbsp;</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">3rd Quarter</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Put the above out for public comment;</p><p>Determine criteria for Leading AI Labs and constitution of CARE committee</p></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">4th Quarter</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Incorporating feedback and developing enforcement standards</td></tr></tbody></table></figure><p><br><br><br>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><h1><strong><u>Pathway to implementation:&nbsp;</u></strong></h1><p>a) Formed through an act of Congress as a separate federal department or&nbsp;</p><p>b) Made into an existing department, such as the FCC or the FTC</p><p>c) Parts of this can also be constituted via an executive order signed into law by the President</p><h1><strong><u>How would this work?</u></strong></h1><figure class=\"image image_resized\" style=\"width:100%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/mfmdvgu9SCfERejhn/l7dj2dnjxtcahxzmxxvx\"><figcaption><i>Working of RISE and CARE</i></figcaption></figure><h2><i>Basic idea:</i></h2><p>The problem right now is safety isn\u2019t taken seriously. There are clear economic incentives to develop AI systems in a fast and dirty way. Moreover, this field is anti-democratic by nature because it is CAPEX intensive. We are essentially trying to implement a model where safety becomes a competitive spot between labs. To maximise effectiveness, NAIRA should embrace, as a new regulatory model, the kind of standards-setting activities that the digital industry itself utilises to define technical codes. NAIRA would also be involved in a granting program to incentivise research at top universities on AI Alignment</p><h2><i>Working:</i></h2><p>Suppose a leading AI Lab wants to release a new model. It would first need the approval of the CARE Committee (not going through this process would result in heavy fines and penalties to the lab akin to releasing an unregulated drug by the FDA). The CARE Committee would vote on the safety standards of the model(and the data set) and propose recommendations. After this, the CARE committee would vote to pass this by a \u2154 margin to the RISE Committee.</p><p>The RISE Committee would, in consultation with the CARE Committee, then deliberate on this proposal. The exciting part here is that to prevent any models from being shown to competitors, all models will be forwarded to RISE in the form of Zero Knowledge Proofs(or other encrypted information querying mechanisms) with a basic idea of the architecture. Competitors can query trial prompts, raise inquiries and concerns to probe the model indirectly. Now, the&nbsp;<strong>competitors would be incentivised to poke holes and develop higher safety bars for the model (to prevent their competitor\u2019s model from going to the market and knowing they would be subject to the same standards in the future).</strong>&nbsp;</p><p>This sets up a competitive safety and alignment standards game where you can stifle your competitor without having the best model. If the vote in the RISE passes, the CARE committee would be tasked with setting up a monitoring and evaluation feedback loop to keep an eye on the model\u2019s behaviour. NAIRA would also incentivise alignment work by giving out grants, as mentioned in its mandate.</p><p>In case of a<strong> potential perceived threat, labs, which are members can ask for an evaluation, resources and assistance from the other council members, with some degree of shared accountability among members.</strong></p><p>A final aspect of RISE is that each voting member will be required to submit a risk assessment report of the field to the government body, which the GM would use to publish its yearly public risk assessment report.</p><h1><strong><u>RISE Voting Structure:</u></strong></h1><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><strong><u>Party</u></strong></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><strong><u>Vote Share</u></strong></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Government-appointed inspectors and experts</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">40%</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Leading AI Labs (defined using market share, size and complexity of models; standards decided by GM)</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">40% (to be split proportionately)</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Non-leading AI Labs</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">10%</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Representatives from Public Interest groups</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">10%</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Tie-breaker</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">International Inspector from the UN who sits on CARE&nbsp;</td></tr></tbody></table></figure><p><br>&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/mfmdvgu9SCfERejhn/h9tvoq0na1dp7blukwok\"></p><h1><strong><u>Why would RISE work?</u></strong></h1><p>It essentially is a game theory model where you are incentivising individual actors to sign up to a system which promotes net inefficiency( think strategic voting) in the AI development pipeline while also promulgating basic safety checks and making safety standards a competitive game between labs. The main objection here is why these companies would sign up for RISE.</p><h1><strong><u>Why would companies sign up for RISE?</u></strong></h1><p>Here are the reasons why:</p><ol><li>It gives them access to government resources and helps especially in case of something goes wrong</li><li>It allows them to keep a check on their competitors, especially through the reporting and voting mechanism</li><li>It allows them to influence government policy (such as a future CHIPS Act)</li><li>It would be a good PR move</li><li><strong>Tax credits depending on the level of transparency demonstrated by the lab (determined by the GM)&nbsp;</strong></li></ol><h1>REFERENCES:</h1><ol><li>Wheeler, T. (2022, March 9).&nbsp;<i>A focused federal agency is necessary to oversee Big Tech</i>. Brookings. Retrieved March 25, 2023</li><li>Ho, L., Barnhart, J., Trager, R., Bengio, Y., Brundage, M., Carnegie, A., Chowdhury, R., Dafoe, A., Hadfield, G., Levi, M., &amp; Snidal, D. (2023, July 10).&nbsp;<i>International Institutions for Advanced AI</i>. arXiv.org. https://arxiv.org/abs/2307.04699</li><li>Carlsmith, J. (2022, June 16).&nbsp;<i>Is Power-Seeking AI an Existential Risk?</i> arXiv.org.&nbsp;<a href=\"https://arxiv.org/abs/2206.13353\"><u>https://arxiv.org/abs/2206.13353</u></a></li><li>Whittlestone, J., &amp; Clark, J. (2021, August 28).&nbsp;<i>Why and How Governments Should Monitor AI Development</i>. arXiv.org. https://arxiv.org/abs/2108.12427</li></ol>", "user": {"username": "Heramb Podar"}}, {"_id": "AXhC4JhWFfsjBB4CA", "title": "The current limiting factor for new charities", "postedAt": "2024-03-19T14:40:50.298Z", "htmlBody": "<p>TLDR: we think the limiting factor for new charities has shifted from founder talent to early stage funding being the top limiting factor.<br>&nbsp;</p><p>We have historically written about&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/W2YChXz4f4nGzZMaE/why-we-look-at-the-limiting-factor-instead-of-the-problem\"><u>limiting factors</u></a> and how they affect our thinking about the highest impact areas. For new charities, over the past 4-5 years, fairly consistently, the limiting factor has been people; specifically, the fairly rare founder profile that we look for and think has the best chance at founding a field-leading charity. However, we think over the last 12 months this picture has changed in some important ways:</p><ol><li>Firstly, we have started founding more charities: After founding ~5 charities a year in 2021 and 2022 we founded 8 charities in 2023 and we think there are good odds we will be able to found ~10-12 charities in 2024. This is a pretty large change. We have not changed our standards for charity quality or founder quality - if anything, we have slightly raised the bar on both compared to historical years. However, we have received more and stronger applications over time both from within and outside of EA. We think this trend is not highly reliable, but our best guess is that it's happening.<ol><li>Side note: This does not mean that people should be less inclined to apply. We now have a single application system that leads to opportunities in both charity founding, for-profit founding, and high-impact nonprofit research&nbsp;<a href=\"https://www.charityentrepreneurship.com/apply\"><u>simultaneously</u></a>.</li></ol></li><li>Secondly, the funding ecosystem has tightened somewhat in&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/GFkzLx7uKSK8zaBE3/we-need-more-nuance-regarding-funding-gaps\"><u>seed and mid-stage funding</u></a>. (Although FTX primarily funded cause areas unrelated to us, their collapse has led to other orgs having larger funding gaps and thus the EA funding ecosystem in general being smaller and more fragile.)<br>&nbsp;</li></ol><p>The result of this is we now think that going forward the most likely limiting factor of new charities getting founded will be early and mid-stage funding. (We are significantly less concerned about funding for our charities once they are older than ~4 years). This has&nbsp; influenced our recent work on&nbsp;<a href=\"https://www.impactfulgrantmaking.com/funding-circles\"><u>funding circles</u></a> (typically aimed at mid-stage funding),&nbsp;<a href=\"https://www.charityentrepreneurship.com/effective-giving-incubation\"><u>Effective Giving initiatives</u></a>, making our&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/t6JzBxtrXjLRufE8o/who-was-the-funder-that-counterfactually-resulted-in-leep\"><u>seed funding network</u></a> open to more people, as well as our recent announcement launching the&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/q2PwXNsXsfDYkxeHb/aim-ce-new-program-founding-to-give-apply-now-to-launch-a\"><u>Founding to Give</u></a> program (this career path makes more sense the more founder talent you have relative to funding for charities).<br>&nbsp;</p><p>If I were thinking about the most important action for the average EA forum user to consider, I would consider if you are a good fit for the seed network (<a href=\"https://www.seednetworkfunders.com/\"><u>website</u></a>,&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/t6JzBxtrXjLRufE8o/who-was-the-funder-that-counterfactually-resulted-in-leep\"><u>prior EA forum writeup</u></a>).</p>", "user": {"username": "Joey"}}, {"_id": "u7q3ppFy3XyNx3mXn", "title": "Participate in Manifund Microgrants: an ACX Grants giving game", "postedAt": "2024-03-19T18:19:41.039Z", "htmlBody": "<p>A follow-up to last week's <a href=\"https://forum.effectivealtruism.org/posts/k6y6BSahK6JZCfbbQ/invest-in-acx-grants-projects\">announcement</a> about ACX grant impact certificates: to offer more people a chance to try impact-market investing, Manifund is giving out investment budgets of several hundred dollars each to a cohort of people interested in testing out weird new charity-funding mechanisms.</p><p>It'll work the same way as regular ACX impact-certificate investing (profits in charity dollars), except that you get free funds to charitably invest. We're looking for people who are excited to thoughtfully consider how to allocate their investments, similarly to Manifund's regrantors (see examples <a href=\"https://manifund.substack.com/p/what-were-funding-weeks-2-4\">here</a>), and to post some feedback on the funding decisions they make.</p><p>If you're interested in participating, fill out this short <a href=\"https://forms.gle/bMLs9oCrj9goaW267\">interest form</a> (shouldn't take more than 5-10 minutes) by the end of Friday, March 22. We'll prioritize earlier submissions somewhat if we get significantly more interest than we have space for (we'll probably cap it at one or two dozen people).</p>", "user": {"username": "lily"}}, {"_id": "Daqz4PJfzfq7FvrhA", "title": "INTERVIEW: Round 2 - StakeOut.AI w/ Dr. Peter Park", "postedAt": "2024-03-18T21:26:39.349Z", "htmlBody": "<p>Hi again, I'm back with the second episode covering my interview &nbsp;with Dr. Peter Park, an AI Existential Safety Postdoctoral Fellow working with Dr. Max Tegmark at MIT. Dr. Park was a cofounder of <a href=\"https://www.stakeout.ai/\">StakeOut.AI</a>, a non-profit focused on making AI go well <i>for humans</i>, along with Harry Luk and one other individual, whose name has been removed due to requirements of her current position.</p><p>Unfortunately, due to funding pressures, the organization recently had to dissolve, but the founders continue to contribute positively towards society in their respective roles.</p><p>Specifically, this episode focuses on what Dr. Park calls the <i>battlegrounds</i> in the effort for making AI go well. In addition we talk about Rich Sutton, the OpenAI drama from November 2023, and I unfortunately make the podcast's first mention of Elon Musk or related products (other than Twitter... but that shouldn't count, right?).</p><p>This interview was made possible through the 2024 Winter <a href=\"https://aisafety.camp/\">AI Safety Camp</a>.</p><p>Note that the interview will be broken up into 3 episodes, and this is only the second; the third will be released next week.</p><p>As I have mentioned previously, any feedback, advice, comments, <i>etc.</i> is greatly appreciated.</p><p><a href=\"https://open.spotify.com/episode/6kjOTekTAeS6R2GIxd1lOb\">Spotify</a><br><a href=\"https://podcasts.apple.com/us/podcast/into-ai-safety/id1720206246\">Apple Podcasts</a><br><a href=\"https://music.amazon.com/podcasts/b2071152-dac7-4225-ab09-460b1e59eb82/into-ai-safety\">Amazon Music</a><br><a href=\"https://www.youtube.com/@IntoAISafety/podcasts\">YouTube Podcasts</a></p>", "user": {"username": "Jacob-Haimes"}}, {"_id": "8AqvwZHdmPbPpy3xS", "title": "CEA is making a recruiting hire", "postedAt": "2024-03-18T20:42:16.610Z", "htmlBody": "<p>Applications for this position must be received no later than <strong>Friday, April 12th 2024, EOD</strong>. Applications will be evaluated on a rolling basis.</p><a class=\"ck-cta-button ck-cta-button-centered\" data-href=\"https://www.centreforeffectivealtruism.org/careers/recruiting-roles-title-variable\" target=\"_blank\" rel=\"noopener noreferrer\">Apply here</a><p>The Centre for Effective Altruism (CEA) is looking to make a recruiting hire to expand our in-house recruiting function and help us attract top talent. We\u2019re ideally looking for someone with professional experience in relevant domains, but we\u2019re also open to hiring for a more junior version of this role\u2014hence why the title of this role is variable. In all cases, this person would start off as the only staff member 100% staffed to recruiting, and they would have significant opportunities to shape and contribute to CEA\u2019s recruiting function.</p><p>We\u2019re the largest and primary organisation working on meta-level effective altruism with an <a href=\"https://forum.effectivealtruism.org/posts/xSvTArtzxBcnrD6tk/cea-still-doing-cea-things\">established track record</a> of delivering highly impactful programs. We have a budget of about $30 million but a relatively lean team of around 40 staff; CEA team members have high levels of responsibility, and finding high performing talent is essential to our continued success. The importance of recruiting is being heightened, as the team is entering a new era as we take on a new CEO and begin the process of <a href=\"https://forum.effectivealtruism.org/posts/HjsfHwqasyQMWRzZN/ev-updates-ftx-settlement-and-the-future-of-ev?\">spinning out</a> from Effective Ventures to become an independent organisation. This means that in addition to our pre-existing recruiting needs, our spin out will create increased demand as we move various operations functions in-house (such as finance, payroll, and legal). We\u2019re entering one of the largest hiring bursts in CEA\u2019s history, and the person in this role will play a key role in ensuring we\u2019re able to find and attract the top talent we need to be successful in our mission.</p>", "user": {"username": "Eli_Nathan"}}, {"_id": "ynqq7rzG9Ypo83og9", "title": "Probly: a Python-like language for probabilistic modelling", "postedAt": "2024-03-18T13:19:18.237Z", "htmlBody": "<p>A few months ago, as an experiment, I developed Probly, a Python-like language for probabilistic estimation.&nbsp;</p><p>Here's a <a href=\"https://probly.dev/sim/iDw6fjQRhYMyo3Znx53Zxz/\">simple example</a> that shows some of the syntax, and the resulting output:</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ynqq7rzG9Ypo83og9/pzzrhv5glvmqzmgxvsbn\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ynqq7rzG9Ypo83og9/uctmyz0soe14tb37pc5l 210w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ynqq7rzG9Ypo83og9/bduj71awfrupagtqvhgo 420w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ynqq7rzG9Ypo83og9/xqgcwpomwtc1yyvsmakl 630w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ynqq7rzG9Ypo83og9/s0whqkekxtjqt45cvffq 840w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ynqq7rzG9Ypo83og9/olvfvvzgc0uoystfxeu6 1050w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ynqq7rzG9Ypo83og9/hvt3nhc6gvt5vjvn0c2o 1260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ynqq7rzG9Ypo83og9/s63g1outxibjwlibcpkb 1470w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ynqq7rzG9Ypo83og9/m2mgut7ecbio700fp6qi 1680w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ynqq7rzG9Ypo83og9/r8ueanfiscuum0p02qqr 1890w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ynqq7rzG9Ypo83og9/vksxxg1mdq863jjwkdaj 2016w\"></figure><p>The link has a code editor, interactive examples, and additional explanation.</p>", "user": {"username": "usedagger.com"}}, {"_id": "rQLYBZSTTuk7SZ66X", "title": "Carlo: uncertainty analysis in Google Sheets", "postedAt": "2024-03-18T13:06:37.233Z", "htmlBody": "<p>I've been working on Carlo, a tool that lets you do uncertainty and sensitivity analysis with Google Sheets spreadsheets.</p><p><strong>Please note Carlo is an (expensive) commercial product.</strong> The <a href=\"https://carlo.app/pricing\">pricing</a> is aimed at professionals making important decisions.</p><p>There's a lot more detail at the link, but in brief, some key features of Carlo are:</p><h1>Works with your existing Google Sheets calculations</h1><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rQLYBZSTTuk7SZ66X/rn3u4wbqzxhtxywz4l8i\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rQLYBZSTTuk7SZ66X/wf1esr9h1s995rliueec 320w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rQLYBZSTTuk7SZ66X/q5x8dqjbszhytjsny0fm 640w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rQLYBZSTTuk7SZ66X/fqr1gqlaish6slxbsbyy 960w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rQLYBZSTTuk7SZ66X/yn9k7iodru6skxf38mgh 1280w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rQLYBZSTTuk7SZ66X/kmp7waxkttpibpwn1ydg 1600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rQLYBZSTTuk7SZ66X/drlxibxqxw7z7y0qbbh9 1920w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rQLYBZSTTuk7SZ66X/afozj7cwaghndaocpa0b 2240w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rQLYBZSTTuk7SZ66X/ofi8tskn1czyz5o25qqg 2560w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rQLYBZSTTuk7SZ66X/aiwgqj8bprtlf9k3t1gf 2880w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rQLYBZSTTuk7SZ66X/jecsmq3nat8ngp29t6ug 3142w\"></figure><h1>Variance-based sensitivity analysis</h1><p>Our sensitivity analysis offers a true metric of variable importance: it can tell you what fraction of the output <a href=\"https://en.wikipedia.org/wiki/Variance-based_sensitivity_analysis\">variance</a> is due to each of the inputs and their interactions.</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rQLYBZSTTuk7SZ66X/fs5cmvye7oncl78ledla\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rQLYBZSTTuk7SZ66X/goksravrqlfzjzmhug2u 150w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rQLYBZSTTuk7SZ66X/dsvrctgez4qivglo9yvs 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rQLYBZSTTuk7SZ66X/ca7yldwhj7rh1d1ulagj 450w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rQLYBZSTTuk7SZ66X/mks49u2xllzc0oqgqkdi 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rQLYBZSTTuk7SZ66X/jtvosqvuszhi7dv6haop 750w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rQLYBZSTTuk7SZ66X/pelrizkjzeqaa0mu5nha 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rQLYBZSTTuk7SZ66X/ob1ljsyb27ulodcbqiti 1050w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rQLYBZSTTuk7SZ66X/yfq8kh50dte6zvi3q2bx 1200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rQLYBZSTTuk7SZ66X/yaevmjivruva4tqjkufl 1350w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rQLYBZSTTuk7SZ66X/lehl4tij1pgff5mwjnod 1462w\"></figure><h1>Flexible input</h1><p>Inputs can be given using novel, convenient probability distributions that flexibly match your beliefs.</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rQLYBZSTTuk7SZ66X/ja5myowqibvf77crxur6\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rQLYBZSTTuk7SZ66X/xcmrdeax1ui76yoabbpe 150w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rQLYBZSTTuk7SZ66X/jclsnynqhas7gltvl8xx 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rQLYBZSTTuk7SZ66X/qhclsykttq4rjlts8hhp 450w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rQLYBZSTTuk7SZ66X/ibvbgkmdeqso3mvfkzx4 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rQLYBZSTTuk7SZ66X/pq9hny5gzrvkimijooaz 750w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rQLYBZSTTuk7SZ66X/ztwxiyp0e5ehec1w4ebx 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rQLYBZSTTuk7SZ66X/vamwyv7j8twszn1qhgo7 1050w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rQLYBZSTTuk7SZ66X/su67cnconz01g3wximvt 1200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rQLYBZSTTuk7SZ66X/l3613pfjs6yuzlq1qr8r 1350w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rQLYBZSTTuk7SZ66X/rdpqfwz0n1jqdbuxef9i 1424w\"></figure>", "user": {"username": "usedagger.com"}}, {"_id": "FeKC7BBxEQQ94TcS6", "title": "EA Organization Updates: March 2024", "postedAt": "2024-03-18T10:01:01.734Z", "htmlBody": "<p>If you would like to see EA Organization Updates as soon as they come out, consider subscribing to <a href=\"https://forum.effectivealtruism.org/topics/ea-organization-updates-monthly-series\">this tag</a>.</p><p>Some of the opportunities and job listings we feature in this update have (very) pressing deadlines (see<a href=\"https://forum.effectivealtruism.org/posts/FeKC7BBxEQQ94TcS6/ea-organization-updates-march-2024#Conferences__seminars__fellowships__and_grants_with_open_applications\"> EAGx Austin</a>, the <a href=\"https://forum.effectivealtruism.org/posts/FeKC7BBxEQQ94TcS6/ea-organization-updates-march-2024#Conferences__seminars__fellowships__and_grants_with_open_applications\">Existential Risk Laboratory\u2019s Summer Research Fellowship</a>, and <a href=\"https://forum.effectivealtruism.org/posts/FeKC7BBxEQQ94TcS6/ea-organization-updates-march-2024#80_000_Hours\">roles at 80 000 Hours</a>).</p><ul><li>You can see previous updates on the <a href=\"https://forum.effectivealtruism.org/topics/ea-organization-updates-monthly-series\">\"EA Organization Updates (monthly series)\"</a>&nbsp;topic page,&nbsp;or in our <a href=\"https://www.effectivealtruism.org/ea-newsletter-archives/\">repository of past newsletters</a>. Notice that there\u2019s also an <a href=\"https://forum.effectivealtruism.org/topics/org-update\">\u201corg update\u201d tag</a>, where you can find more news and updates that are not part of this consolidated series.</li><li>These monthly posts originated as the \"Updates\" section of the monthly <a href=\"https://www.effectivealtruism.org/ea-newsletter-archives\">EA Newsletter</a>. Organisations submit their own updates, which we edit for clarity.</li><li>(If you\u2019d like to share your updates and jobs via this series, please <a href=\"https://docs.google.com/forms/d/e/1FAIpQLScojuR8ev4r6PSXykvOn6BhHX5Wk0BS1-0Hwo8uc14jGsElsA/viewform?usp=sf_link\">apply here</a>.)</li></ul><h2 data-internal-id=\"Opportunities_and_jobs\">Opportunities and jobs</h2><h3 data-internal-id=\"Opportunities\">Opportunities</h3><p><i>Consider also checking opportunities listed on the </i><a href=\"https://ea-internships.pory.app/board\"><i>EA Opportunities Board</i></a><i>, and the </i><a href=\"https://forum.effectivealtruism.org/topics/opportunities-to-take-action\"><i>Opportunities to Take Action</i></a><i>&nbsp;tag.</i></p><p data-internal-id=\"Conferences__seminars__fellowships__and_grants_with_open_applications\"><strong>Conferences, seminars, fellowships, and grants with open applications</strong></p><ul><li><a href=\"https://forum.effectivealtruism.org/posts/fBdRyaGuSgGM9PEnr/upcoming-ea-conferences-in-2024\">Upcoming EA conferences</a><ul><li><a href=\"https://www.effectivealtruism.org/ea-global/events/ea-global-london-2024\">EA Global: London</a>&nbsp;| (May 31-June 2) | Intercontinental London (the O2) \u2014 <strong>applications close May 19th</strong></li><li><a href=\"https://www.effectivealtruism.org/ea-global/events/ea-global-boston-2024\">EA Global: Boston</a>&nbsp;| (November 1-3) | Hynes Convention Center \u2014 <strong>applications close</strong>&nbsp;<strong>October 20th</strong></li><li><a href=\"https://www.effectivealtruism.org/ea-global/events/eagxaustin-2024\">EAGxAustin</a>&nbsp;| (April 13-14) | University of Texas, Austin \u2014 <strong>applications close</strong>&nbsp;<strong>March 31st</strong></li><li><a href=\"https://www.effectivealtruism.org/ea-global/events/eagxnordics-2024\">EAGxNordics</a>&nbsp;| (April 26-28) | CPH Conference, Copenhagen \u2014 <strong>applications close</strong>&nbsp;<strong>April 7th</strong></li><li><a href=\"https://www.effectivealtruism.org/ea-global/events/eagxutrecht-2024\">EAGxUtrecht</a>&nbsp;| (July 5-7) | Jaarbeurs, Utrecht</li><li><a href=\"https://www.effectivealtruism.org/ea-global/events/eagxberlin-2024\">EAGxBerlin</a>&nbsp;| (September 13-15) | Urania, Berlin</li></ul></li><li>Applications for <a href=\"https://ilinaprogram.org/\">ILINA Program</a>\u2019s <a href=\"https://ilinaprogram.org/seminar/\">seminar</a>&nbsp;and <a href=\"https://ilinaprogram.org/fellowship/\">fellowship</a>&nbsp;are now open. The seminar will run from mid-June to late August 2024 and the fellowship will take place between early September and late November. The program is designed for undergrads and recent graduates from Africa who are interested in learning and working on questions around animal welfare and global catastrophic risk, especially those posed by AI and developments in the bio space. <strong>Applications close on April 12th</strong>.</li><li>The <a href=\"https://forum.effectivealtruism.org/out?url=https%3A%2F%2Fxrisk.uchicago.edu%2Ffellowship%2Fsrf-24%2F\">Existential Risk Laboratory (XLab)</a>&nbsp;at the University of Chicago is accepting applications for their 2024 Summer Research Fellowship, a 10-week in-person program providing undergraduate and graduate students the opportunity to conduct high-impact research on global catastrophic and existential risks. Fellows will undertake independent or team research projects with mentorship support, participate in workshops and social events, and receive a $7,500 stipend with optional housing and dining plans. <strong>Applications are due March 22nd</strong>. Promising applicants will be invited for interviews, with decisions expected in early April.</li><li>On <strong>April 30th </strong>Scarlet Spark is launching Cohort 2 of People Skills for Animal People (PSAP), a leadership skills program designed for executive leaders at animal welfare organizations. The program aims to enhance participants' ability to save more animals by creating a great workplace for humans, resulting in short-term improvements in leadership skills, employee performance, and productivity, as well as long-term benefits for organizational sustainability and impact. The virtual workshops will be held every other Tuesday at 7pm - 9pm ET. Executive leaders at animal welfare nonprofits are encouraged to <strong>apply by March 29th</strong>. Visit <a href=\"https://www.scarletspark.org/resources/blog/people-skills-for-animal-people-q2-2024\">the website</a>&nbsp;for more information and to apply.</li><li>Ambitious Impact (Charity Entrepreneurship)<strong>&nbsp;</strong>has launched its new program<strong>: </strong><a href=\"https://www.aimfoundingtogive.com/\"><strong>Founding to Give</strong></a>, a pre-incubator program that will help entrepreneurs launch a high-growth company to donate to high-impact charities. AIM offers a 4-week cost-covered program that will help participants find a value-aligned co-founder, identify and test an exceptional business idea, build a strong business pitch, and create a plan for your next steps. They provide&nbsp;two additional months of funding to cover living and office costs. Apply to the program via this <a href=\"https://form.jotform.com/240282852958365\">joint application form</a>&nbsp;<strong>by April 14th</strong>. AIM is also still accepting applications for its <a href=\"https://www.charityentrepreneurship.com/incubation-program\">Incubation Program</a>&nbsp;and <a href=\"https://www.charityentrepreneurship.com/research-training-program\">Research Program</a>, and <strong>apply by April 14th</strong>&nbsp;on <a href=\"https://form.jotform.com/240282852958365\">the same form</a>.</li><li>Magnify Mentoring is running a pilot mentorship round for people from underrepresented groups! Applications for mentees are open now! You can apply <a href=\"https://zfrmz.com/FbHA3gorM68PbBTCyxh2\">here</a>&nbsp;and learn more <a href=\"https://www.magnifymentoring.org/joinus\">here</a>. &nbsp;On average, mentees and mentors meet once a month for 60-90 minutes with a series of optional prompt questions prepared by our team. Applications will close on the <strong>April 5th</strong>.</li></ul><p data-internal-id=\"Opportunities_to_take_action\"><strong>Opportunities to take action</strong></p><ul><li>Astral Codex Ten (ACX) has launched <a href=\"https://manifund.org/causes/acx-grants-2024?tab=certs\">ACX Grants 2024</a>, a program that funds charitable and scientific projects. This year, some applicants received direct grants, while others were given the option to participate in an impact market. In this market, investors can purchase \"impact certificates\" to fund projects, with the potential to receive a share of prize money awarded by philanthropic funders. These funders, including ACX Grants 2025, the Long-Term Future Fund, the EA Infrastructure Fund, and the Survival and Flourishing Fund, will review the projects after a year to determine which ones have had the highest impact. Investing in impact certificates offers advantages such as better feedback, improved modeling of grant-makers, and the potential to earn charitable funds to donate to impactful causes. Interested in investing, donating directly, or discussing? Email saul@manifund.org or <a href=\"https://savvycal.com/saulmunn/manifund\">book a call</a>.</li><li>Emma Cameron, an ultramarathon runner, is running the 200-mile Tahoe 200 from <strong>June 14-18</strong>&nbsp;to fundraise for <a href=\"https://www.newincentives.org/\">New Incentives</a>.&nbsp;Her goal is to raise $10,036 to support 650 children in New Incentives\u2019 vaccination program. Emma invites everyone to support her fundraising efforts by donating and sharing her <a href=\"https://pledgeit.org/200-miles\">PledgeIt page</a>.</li></ul><h3 data-internal-id=\"Job_listings\">Job listings</h3><p><i>\u200b\u200bConsider also exploring jobs listed on the </i><a href=\"https://forum.effectivealtruism.org/topics/job-listing-open\"><i>Job listing (open)</i></a><i>&nbsp;tag. For even more roles, check the </i><a href=\"https://jobs.80000hours.org/\"><i>80,000 Hours Job Board</i></a><i>&nbsp;and our </i><a href=\"https://forum.effectivealtruism.org/posts/yrnE4jvhtukNk7kvN/who-s-hiring-feb-may-2024\"><i>Who\u2019s Hiring?</i></a><i>&nbsp;thread.</i></p><p data-internal-id=\"80_000_Hours\"><strong>80,000 Hours</strong></p><ul><li><a href=\"https://80000hours.org/2024/02/open-positions-operations-team/#people-operations-specialists-and-associates\">People operations specialists and associates</a>&nbsp;(Remote in London, UK preferred, \u00a350K-75K, <strong>apply by</strong>&nbsp;<strong>March 24th</strong>)</li><li><a href=\"https://80000hours.org/2024/02/open-positions-operations-team/#business-operations-specialists-and-associates\">Business operations specialists and associates</a>&nbsp;(Remote in London, UK (preferred), \u00a350K-75K, <strong>apply by</strong>&nbsp;<strong>March 24th</strong>)</li></ul><p data-internal-id=\"Ambitious_Impact\"><strong>Ambitious Impact</strong></p><ul><li><a href=\"https://www.aimfoundingtogive.com/\">For-profit founder - AIM Founding to Give Program</a>&nbsp;(\u00a31.9k/month stipend, <strong>apply&nbsp;by April 14, 2024</strong>)</li><li><a href=\"https://www.charityentrepreneurship.com/incubation-program\">Nonprofit founder - CE Incubation Program</a>&nbsp;(\u00a31.9k/month stipend, <strong>apply by April 14, 2024</strong>)</li><li><a href=\"https://www.charityentrepreneurship.com/research-training-program\">Research Program participant</a>&nbsp;(\u00a31.9k/month stipend, <strong>apply by April 14, 2024</strong>)</li></ul><p data-internal-id=\"Anthropic\"><strong>Anthropic</strong></p><ul><li><a href=\"https://jobs.lever.co/Anthropic/444e7d1e-ec6a-4d18-b712-0cb79c27f00f\">Research Engineer, Alignment Science</a>&nbsp;(Hybrid/SF preferred, $280k-$600k)</li><li><a href=\"https://jobs.lever.co/Anthropic/d056c214-2db5-408a-9179-c1e4588e45c3\">Machine Learning Engineer, Trust &amp; Safety</a>&nbsp;(Hybrid, $300k- $450k)</li><li><a href=\"https://jobs.lever.co/Anthropic/180dd02e-2998-4d74-a729-6b5c1f38521f\">Policy Design Manager, Child Safety and Emotional and Psychological Harm</a>&nbsp;(Hybrid/SF, $200k-$240k)</li><li><a href=\"https://jobs.lever.co/Anthropic/7cb9bc58-ca94-437f-8f77-d6b6f80f0231\">Trust and Safety Responsible Deployment Policy Lead</a>&nbsp;(Hybrid/SF, $240k-$285k)</li></ul><p data-internal-id=\"Center_for_AI_Risk_Management___Alignment\"><strong>Center for AI Risk Management &amp; Alignment</strong></p><ul><li><a href=\"https://jobs.lever.co/futureof-life/9c1b31b4-c02c-4af6-88e9-09c30157bbed\">Risk Management Researcher - Comprehensive Risk</a>&nbsp;(Remote, $150k-$180k)</li><li><a href=\"https://jobs.lever.co/futureof-life/8e71a015-589d-49aa-8e2c-ae9a7241752e\">Risk Management Researcher - Offense/Defense</a>&nbsp;(Remote, $150k-180k)</li><li><a href=\"https://jobs.lever.co/futureof-life/fa1bb27c-10d4-421b-9d1e-30b6d0dc78f7\">Geostrategic Dynamics Researcher</a>&nbsp;(Remote, $130k-$140k)</li><li><a href=\"https://jobs.lever.co/futureof-life/42c2b80f-75a1-4ed0-97f8-104924657646\">US Legal &amp; Policy Researcher - Civil Security</a>&nbsp;(Remote in US, $135k-$145k)</li></ul><p data-internal-id=\"Family_Empowerment_Media_\"><strong>Family Empowerment Media</strong></p><ul><li><a href=\"https://docs.google.com/document/d/1Crui7aF5tEU-EYpC5dJ-fCTzXenmR85x9CFb3k3H8wo/edit#heading=h.uy7mz0pfej8k\">Head of Operations</a>&nbsp;(Remote or London, $50k-$65k)</li><li><a href=\"https://docs.google.com/document/d/1cvEzijWrmv3mYmayKx2uJCcw8wP_azmcwZC02782umQ/edit#heading=h.uy7mz0pfej8k\">Operations Manager</a>&nbsp;(Remote or London, $40k-$50k)</li></ul><p data-internal-id=\"Founders_Pledge\"><strong>Founders Pledge</strong></p><ul><li><a href=\"https://app.beapplied.com/apply/nqpowpufzr\">Applied Researcher</a>&nbsp;(Remote, up to $95k)</li><li><a href=\"https://app.beapplied.com/apply/kv8vqzhrk2\">Climate Communications Manager</a>&nbsp;(Remote, $60k-$80k)</li><li><a href=\"https://app.beapplied.com/apply/bqfiijrbsx\">Chief Experience Officer</a>&nbsp;(Hybrid in London)</li><li><a href=\"https://app.beapplied.com/apply/q1z2ucofeo\">Advisor</a>&nbsp;(Hybrid in Germany, France, or London, \u00a345k-\u00a355k)</li></ul><p data-internal-id=\"GiveWell\"><strong>GiveWell</strong></p><ul><li><a href=\"https://www.givewell.org/about/jobs/head-of-communications\">Head of Communications </a>(Remote, $165.7k- $182.8k)</li><li><a href=\"https://www.givewell.org/about/jobs/senior-researcher\">Senior Researcher</a>&nbsp;(Remote, $193.1k-$209k)</li><li><a href=\"https://www.givewell.org/about/jobs/research-analyst\">Research Analysts</a>&nbsp;(Remote, $95.9k- $105.8k dependent on location)</li></ul><p data-internal-id=\"FAR_AI\"><strong>FAR AI</strong></p><ul><li><a href=\"https://far.ai/post/2024-02-head-of-programs/\">Head of Programs&nbsp;</a>(Berkeley, CA, $100k- $200k)</li><li><a href=\"https://far.ai/post/2024-02-executive-assistant/\">Executive Assistant&nbsp;</a>(Berkeley, CA, $70k-$95k)</li><li><a href=\"https://far.ai/jobs/\">Various technical staff and communications positions</a></li></ul><p data-internal-id=\"Insect_Institute\"><strong>Insect Institute</strong></p><ul><li><a href=\"https://careers.rethinkpriorities.org/en/postings/341cac58-ccea-407d-96da-813b6cfec09b\">Program Coordinator</a>&nbsp;(Remote, $73.6k-$87.6k, <strong>apply by</strong>&nbsp;<strong>April 1st</strong>)</li></ul><p data-internal-id=\"Lead_Exposure_Elimination_Project__LEEP_\"><strong>Lead Exposure Elimination Project (LEEP)</strong></p><ul><li><a href=\"https://leadelimination.org/jobs/\">Program Manager for Pakistan</a>&nbsp;(Pakistan, Karachi/Lahore preferred, <strong>apply by</strong>&nbsp;<strong>April 3rd</strong>)</li></ul><p data-internal-id=\"Magnify_Mentoring\"><strong>Magnify Mentoring</strong></p><ul><li><a href=\"https://www.magnifymentoring.org/post/we-are-hiring-a-program-manager\">Project Manager</a>&nbsp;($60k, Remote)</li></ul><p data-internal-id=\"METR__formerly_ARC_Evals_\"><strong>METR (formerly ARC Evals)</strong></p><ul><li>Fill out the <a href=\"https://hiring.metr.org/interest\">General Interest Form</a>&nbsp;to apply for the following roles:<ul><li><a href=\"https://hiring.metr.org/engineering-lead\">Engineering Lead</a>&nbsp;(Berkeley, $250k\u2013$400k)</li><li><a href=\"https://hiring.metr.org/senior-swe\">Senior Software Engineer</a>&nbsp;(Berkeley, $150k\u2013$350k)</li><li><a href=\"https://hiring.metr.org/hdl\">Human Data Lead</a>&nbsp;(Berkeley, $150k\u2013$250k</li></ul></li></ul><h1 data-internal-id=\"Organization_Updates\">Organization Updates</h1><p data-internal-id=\"Organization_Updates\"><i>The organisation updates are in alphabetical order (F-Z, 0-A-E)</i>.</p><h3 data-internal-id=\"Faunalytics\">Faunalytics</h3><p>Faunalytics published a <a href=\"https://faunalytics.org/research-and-data-as-tools/\">research paper</a>&nbsp;that investigates how research is used by farmed animal advocacy organizations. The report illuminates advocates\u2019 research needs \u2014 such as more accessible material, summaries, and reports on how to effect change \u2014 and provides key findings and recommendations for advocates, researchers, and funders.</p><p>The organization also updated their research library with articles on a variety of animal advocacy topics including <a href=\"https://faunalytics.org/will-cultured-meat-be-widely-available-by-2050/\">whether cultured meat will be widely available by 2050</a>, <a href=\"https://faunalytics.org/the-language-of-speciesism/\">the language of speciesism</a>, and <a href=\"https://faunalytics.org/using-choice-architecture-to-drive-vegan-food-sales/\">using choice architecture to drive vegan food sales</a>.</p><h3 data-internal-id=\"Fish_Welfare_Initiative\">Fish Welfare Initiative</h3><p>Fish Welfare Initiative (FWI) recently launched <a href=\"http://fwi.fish/post/satellites\">a new study</a>&nbsp;designed to assess whether assessments made from satellite imagery are sufficiently accurate to predict fish farm water quality. If the study resolves positively, it could significantly improve the cost effectiveness and scalability of FWI\u2019s <a href=\"http://fwi.fish/farmers\">farmer program in India</a>.</p><p>They also completed a <a href=\"https://docs.google.com/spreadsheets/d/1SSgwDFovah4VBz_NVXG26jmIm6nUoAPkADgLTnVGki0/edit#gid=0\">literature review</a>&nbsp;of Chinese papers with topics relating to fish welfare.</p><h3 data-internal-id=\"GiveWell1\">GiveWell</h3><p>GiveWell recently recommended a <a href=\"https://www.givewell.org/research/grants/malaria-consortium-VAS-SMC-nigeria-october-2023\">$1.4 million</a>&nbsp;grant to Malaria Consortium to deliver vitamin A supplementation (VAS) alongside seasonal malaria chemoprevention (SMC) campaigns in two states in Nigeria. GiveWell expects that Malaria Consortium will be able to deliver VAS at a low cost by leveraging its&nbsp;existing SMC platform, thus increasing the number of children receiving VAS and, in turn, averting a higher number of child deaths.</p><p>GiveWell also made a <a href=\"https://www.givewell.org/research/grants/suvita-sms-reminders-ambassadors-immunization-april-2023\">$3.3 million grant</a>&nbsp;to Suvita, an organization that aims to increase childhood vaccination rates in India through SMS text message reminders and immunization ambassadors who share vaccine information in local communities. GiveWell thinks these low-cost activities could lead to a small but meaningful increase in vaccination rates, which in turn will mean fewer children dying of vaccine-preventable diseases.</p><p>GiveWell also recently published the grant page for a <a href=\"https://www.givewell.org/research/grants/evidence-action-iron-folic-acid-supplementation-india-august-2022\">$9.2 million grant</a>&nbsp;to Evidence Action to provide technical assistance to the Indian government in distributing iron and folic acid supplements to children in five states. <a href=\"https://www.givewell.org/international/technical/programs/iron-supplementation\">IFA supplementation</a>&nbsp;seems to be effective at reducing iron deficiency and anemia; <a href=\"https://www.givewell.org/research/grants/evidence-action-iron-folic-acid-supplementation-india-august-2022#Evidence_that_IFA_reduces_iron_deficiency\">GiveWell estimates</a>&nbsp;that receiving IFA supplementation reduces iron deficiency by about 70%.</p><h3 data-internal-id=\"Magnify_Mentoring1\">Magnify Mentoring</h3><p>Magnify Mentoring is hiring a Project Manager who will primarily focus on building a productive and fun Magnify Mentoring community and identifying opportunities to support their members in their professional and personal journeys. Please apply by the 5th April. Find out more <a href=\"https://www.magnifymentoring.org/post/we-are-hiring-a-program-manager\">here</a>. &nbsp;</p><h3 data-internal-id=\"Lead_Exposure_Elimination_Project\">Lead Exposure Elimination Project</h3><p>LEEP recently published their 2023 Annual Review. The Review summarises LEEP\u2019s work in 2023 and sets forth their goals for the year ahead. Read the <a href=\"https://leadelimination.org/2023-annual-review/\">full review</a>.</p><h3 data-internal-id=\"METR__formerly_ARC_Evals_1\">METR (formerly ARC Evals)</h3><p>METR recently published their <a href=\"https://metr.org/blog/2024-02-07-2023-year-in-review/\">2023 Year in Review post</a>.</p><p>Currently, they are looking for <a href=\"https://metr.org/blog/2023-12-16-bounty-diverse-hard-tasks-for-llm-agents/\">diverse hard tasks for LLM agents</a>.</p><ul><li>They are offering bounties for task ideas, specifications, and implementations, paying out at $20, $200, and ~$2,000-10,000 respectively, and are interested in exploring full-time roles with individuals who submit particularly impressive tasks.</li><li>They are also looking for past exams/coursework from STEM and STEM-related classes.<ul><li>Requirements: straightforward to grade (i.e. comes with a rubric or autograder; OK if requires a human to grade) and solutions cannot be found online (i.e. does not make it into training data). Note: Ask professors for permission before sharing.</li><li>Feel free to adapt these into implemented tasks or submit the original exams/coursework as task ideas/specs. Bounties will depend on how well the tasks fit the <a href=\"https://metr.org/blog/2023-12-16-bounty-diverse-hard-tasks-for-llm-agents/#:~:text=to%20the%20VM-,Desiderata%20list,-Ideal%20difficulty%20range\">desiderata</a>.</li></ul></li></ul><h3 data-internal-id=\"One_for_the_World_\">One for the World</h3><p>One for the World is seeking their next Executive Director. The role offers an opportunity to lead a fast-growing organization, raising money for the world\u2019s most cost-effective nonprofit organizations.</p><p>They aim to find an ambitious leader with a track record of high-level execution and a clear vision and strategic plan for both expanding One for the World's influence and quickly multiplying money moved to their nonprofit partners.</p><p>They also seek a leader who can galvanize their team, manage and deepen their relationship with donors, effectively fundraise in corporate environments, and have a strong personal commitment to addressing global poverty. Exceptional public speaking skills are a plus.</p><p><strong>Salary:</strong>&nbsp;US$110k-$150k per annum, plus a 0-20% performance-related bonus each year.</p><p><strong>Location:</strong>&nbsp;Strong preference for someone based in the mainland US, ideally on the Northeast/Acela corridor.</p><p>Access <a href=\"https://bit.ly/3UHxXZ7\">the application pack</a>&nbsp;and <a href=\"https://lnkd.in/gwQQWrMb\">application form</a>&nbsp;for the role and email <a href=\"mailto:jobs@1fortheworld.org\">jobs@1fortheworld.org</a>&nbsp;with any questions about the role or to recommend a candidate.</p><h3 data-internal-id=\"Open_Philanthropy\">Open Philanthropy</h3><p>Open Philanthropy <a href=\"https://www.openphilanthropy.org/research/new-grantmaking-program-forecasting/\">announced</a>&nbsp;a new grantmaking focus area:<a href=\"https://www.openphilanthropy.org/focus/forecasting/\">&nbsp;Forecasting</a>. Led by Benjamin Tereick, the Forecasting team's main goal is to help realize the promise of forecasting as a way to improve high-stakes decisions.</p><p>Open Philanthropy also shared a <a href=\"https://forum.effectivealtruism.org/posts/QyXcTAhzcQeLDckGL/social-science-research-we-d-like-to-see-on-animal-welfare\">list of social science research questions</a>&nbsp;that the organization would like to see investigated more fully and announced <a href=\"https://www.openphilanthropy.org/research/introducing-open-philanthropys-new-leadership-team/\">new additions to their leadership team</a>.</p><h3 data-internal-id=\"Rethink_Priorities__RP_\">Rethink Priorities (RP)</h3><p>Following their work on <a href=\"https://doi.org/10.1163/23524588-20230104\">yellow mealworms</a>&nbsp;and <a href=\"https://www.wageningenacademic.com/doi/abs/10.3920/JIFF2022.0041\">black soldier flies</a>, the research team published a report on <a href=\"https://osf.io/preprints/osf/c4qp3\">improving cricket welfare</a>. The paper reviews the major welfare concerns on cricket farms, arising from disease, stocking density, lighting, feed, and more. See a brief summary with recommendations <a href=\"https://forum.effectivealtruism.org/posts/uNZwZs9zyvTE5uNEK/research-summary-farmed-cricket-welfare\">here</a>.</p><p>The Insect Institute\u2014which is <a href=\"https://rethinkpriorities.org/special-projects\">fiscally sponsored</a>&nbsp;by Rethink Priorities\u2014is hiring a <a href=\"https://careers.rethinkpriorities.org/en/postings/341cac58-ccea-407d-96da-813b6cfec09b\">Program Coordinator/Officer</a>.</p><h3 data-internal-id=\"The_Humane_League\">The Humane League</h3><p>The Humane League (THL) released <a href=\"https://commonenemyfilm.com/\"><i>Common Enemy</i></a>, a new documentary that tells the story of Oklahomans protesting the animal agriculture industry. The full film is now available to view at <a href=\"http://commonenemyfilm.com\">commonenemyfilm.com</a>.</p><p>THL\u2019s Open Wing Alliance (OWA) published its 2024 <a href=\"https://thehumaneleague.org/article/2024-global-travel-report\">Global Travel Report</a>, the latest in a series of investigative reports offering a deep dive into corporate cage-free commitments\u2014and their publicly reported progress. <a href=\"https://downloads.ctfassets.net/ww1ie0z745y7/2h8ImMJhlXmC4nuN7oB7Zi/e6862e3d3278251a4c6facbe3cb83540/24-owa-reports-global-hospitality-report-final-3.05.pdf\">This report</a>&nbsp;ranks global travel and hospitality companies on the status of their transitions to cage-free systems, pushing for greater transparency and accountability across the sector.</p><p>And in the US, the <a href=\"https://drive.google.com/file/d/1zBt6Gm8x6hkg-hoKm9cMC240IM1k2Q_u/view\">cage-free flock has climbed above the 40% mark</a>. This is an increase of more than 25% since THL first started putting concentrated pressure on corporations to end cages back in 2015.</p><h3 data-internal-id=\"The_Life_You_Can_Save_\">The Life You Can Save</h3><p>The Life You Can Save has updated its <a href=\"https://www.thelifeyoucansave.org/research/\">charity evaluation framework</a>&nbsp;to focus more intensively on the complexities of poverty, utilizing the Multidimensional Poverty Index. The Multidimensional Poverty Index, or MPI, acknowledges that poverty\u2019s impact extends beyond financial scarcity to include health, education and living standards. The guiding framework retains a focus on robust evidence to drive decision-making. As part of their revised framework, they have updated some of their recommended funds and nonprofits.</p><p>The Life You Can Save appointed new leadership. &nbsp;Former Silicon Valley executives, <a href=\"https://www.linkedin.com/in/jessicahoy/\">Jessica</a>&nbsp;and <a href=\"https://www.linkedin.com/in/andrealamesa/\">Andrea</a>&nbsp;La Mesa, will co-lead The Life You Can Save into its next decade.</p><h3 data-internal-id=\"80_000_Hours1\">80,000 Hours</h3><p>80,000 Hours published a new installment in their anonymous answers series, featuring experts answering this question: <a href=\"https://80000hours.org/articles/anonymous-misconceptions-about-biosecurity/\">What are the biggest misconceptions about biosecurity and pandemic risk?</a></p><p>They also released blog posts about <a href=\"https://80000hours.org/2024/03/the-case-for-taking-your-technical-expertise-to-the-field-of-ai-policy/\">the case for taking your technical expertise to the AI policy field</a>&nbsp;and <a href=\"https://80000hours.org/2024/02/why-you-might-not-want-to-work-on-nuclear-disarmament/\">why you might not want to work on nuclear disarmament (and what to work on instead)</a>.</p><p>On the <i>The 80,000 Hours Podcast, </i>Rob Wiblin interviewed:</p><ul><li><a href=\"https://80000hours.org/podcast/episodes/randy-nesse-evolutionary-medicine-psychiatry/\">Randy Nesse on why evolution left us so vulnerable to depression and anxiety</a></li><li><a href=\"https://80000hours.org/podcast/episodes/hugo-mercier-misinformation-mass-persuasion/\">Hugo Mercier on why gullibility and misinformation are overrated</a></li></ul><p>And Luisa Rodriguez interviewed:</p><ul><li><a href=\"https://80000hours.org/podcast/episodes/laura-deming-ending-ageing/\">Laura Deming on the science that could keep us healthy in our 80s and beyond</a>&nbsp;</li></ul><h3 data-internal-id=\"Animal_Charity_Evaluators\">Animal Charity Evaluators</h3><p>Last July, Animal Charity Evaluators (ACE) awarded $944,921 to their 2022 Recommended Charities through their<a href=\"https://animalcharityevaluators.org/donation-advice/recommended-charity-fund/#rcf\">&nbsp;Recommended Charity Fund</a>. Learn <a href=\"https://animalcharityevaluators.org/blog/recommended-charity-fund-update-january-2024/\">how recipients used their grants to help animals</a>.</p><h3 data-internal-id=\"Berkeley_Existential_Risk_Initiative__BERI_\">Berkeley Existential Risk Initiative (BERI)</h3><p>BERI has published their <a href=\"https://docs.google.com/document/d/1rqaS_d0LC7ieW2mRNujkjjhuAaB7mINoNEbfKz_Yysw/edit\">2023 Annual Report</a>.</p><h3 data-internal-id=\"Centre_for_the_Governance_of_AI__GovAI_\">Centre for the Governance of AI (GovAI)</h3><p>GovAI released a report, <a href=\"https://bit.ly/CPGAI\">\u201cComputing Power and the Governance of Artificial Intelligence\u201d</a>,&nbsp;that is a collaboration between nineteen researchers from academia, civil society, and industry. Read <a href=\"https://www.governance.ai/post/computing-power-and-the-governance-of-ai\">a summary</a>.</p><p>GovAI also released a summary of a working paper:<a href=\"https://www.governance.ai/post/what-increasing-compute-efficiency-means-proliferation-of-dangerous-capabilities\">&nbsp; \u201cWhat Increasing Compute Efficiency Means for the Proliferation of Dangerous Capabilities\u201d</a>&nbsp;by Lennart Heim and Konstantin Pilz.</p>", "user": {"username": "tobytrem"}}, {"_id": "HnTGebKQdFJWJb6zw", "title": "Join the AI Evaluation Tasks Bounty Hackathon", "postedAt": "2024-03-18T08:15:18.410Z", "htmlBody": "<p><strong>How do we test when autonomous AI might become a catastrophic risk?</strong> One approach is to assess the capabilities of current AI systems in performing tasks relevant to self-replication and R&amp;D. METR (formerly ARC Evals), a research group focused on this question, has:</p><ul><li>developed a&nbsp;<a href=\"https://github.com/METR/task-standard\"><u>Task Standard</u></a>, a standardized structure for specifying \"tasks\" in code to test language models, currently used by the UK AI Safety Institute</li><li>awarded substantial bounties to researchers developing new tasks for current language models</li></ul><p>Now, you have the chance to directly contribute to this important AI safety research. We invite you to&nbsp;<strong>join the Code Red Hackathon</strong>, an event hosted by&nbsp;<a href=\"https://www.apartresearch.com/\"><u>Apart</u></a> in collaboration with&nbsp;<a href=\"https://metr.org/\"><u>METR</u></a>, where you can earn money, connect with experts, and help create tasks to evaluate frontier AI systems.&nbsp;<a href=\"https://apartresearch.com/event/codered\"><strong><u>Sign up here</u></strong></a> for the event this weekend on March 22-24!</p><h2>A short introduction to testing AI</h2><p>The risks associated with misuse of capable, autonomous AI are significant. By creating \"tasks\"<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"1\" data-footnote-id=\"swub7br3z8o\" role=\"doc-noteref\" id=\"fnrefswub7br3z8o\"><sup><a href=\"#fnswub7br3z8o\">[1]</a></sup></span>&nbsp;for frontier models we can test some of the capabilities relevant to autonomous self-replication and R&amp;D. Example tasks might include:</p><ul><li>Setting up a system to automatically monitor a GPU seller's website and send a notification when they become available</li><li>Creating a list of email addresses and descriptions for all employees authorized to make purchases above $10k from 20 companies</li><li>Setting up Tor or a VPN on a new server to ensure network traffic cannot be tracked</li></ul><p>As you can see, if an AI possesses these abilities, things might get complicated.</p><p>The Task Standard provides a plug-and-play early warning system for these abilities and follows a standardized format. A&nbsp;<a href=\"https://github.com/METR/task-standard/blob/main/STANDARD.md\"><u>task family</u></a> (a set of tasks) consists of:</p><ol><li>A Python file called $TASK_FAMILY_NAME.py;</li><li>Any number of other Python files, shell scripts, etc. that $TASK_FAMILY_NAME.py imports; and</li><li>Other files, called \"assets\", that will be used to set up the task environment.</li></ol><p>When creating a task, it's crucial to ensure that the task is error-free, understandable for the agent, and not easily gameable. You can follow these steps, some awarded by METR, to create a great task:</p><ol><li><a href=\"https://airtable.com/appa8ULxLrTkQxw4K/shrBR6c5zPv2C6qWw\"><u>Write up your ideas</u></a> for which tasks related to autonomous capabilities you wish to test the language model on<ul><li><strong>A $20 prize will be awarded for high-quality ideas</strong></li></ul></li><li><a href=\"https://airtable.com/appa8ULxLrTkQxw4K/shrGH2lmeeJWQzi5d\"><u>Create a specification</u></a> for the task that includes the prompt, a text description of what the test-taker has access to, and a self-evaluation of the task<ul><li><strong>A $200 prize will be awarded for high-quality specifications (2-6 hours of work)</strong></li></ul></li><li>Create the materials for the task (instructions, libraries, and tool access) and have a human run through&nbsp;<strong>the whole task</strong> with these exact materials and tools</li><li><a href=\"https://airtable.com/appa8ULxLrTkQxw4K/shrImC4aP39x4TxkW\"><u>Implement the task</u></a> in the task standard format, test it with a simple agent, and submit it!<ul><li>The prize for high-quality implementations is 3x a human professional's salary for the task + bonus,&nbsp;<strong>e.g. a task that would take a human software engineer 10 hours could net you up to $4500</strong> (6-12 hours of work in addition to quality assurance)</li></ul></li></ol><p>Each of these steps can be found detailed in the associated resources for the hackathon found on&nbsp;<a href=\"https://apartresearch.com/event/codered#resources\"><u>the hackathon website</u></a>.</p><h2>Joining the hackathon: Your chance to contribute</h2><p>You might find creating an AI evaluation task daunting, but the Code Red Hackathon provides the perfect opportunity to dive in, with support from experts, clear guidelines, and the chance to earn significant money for your work. By joining us on March 22-24, you can:</p><ul><li>Get inspired with a&nbsp;<a href=\"https://www.youtube.com/watch?v=9hJgz9SlnRs\"><u>keynote by Beth Barnes</u></a> at 19:00 UTC on Friday March 22nd where she will share insights from her extensive work on technical AI safety.</li><li>Develop a new task rapidly by using the&nbsp;<a href=\"https://apartresearch.com/event/codered#resources\"><u>METR Task Standard, example tasks, and other resources</u></a>.</li><li>Connect with a&nbsp;<a href=\"https://discord.gg/dYUWDm7Ben\"><u>global community</u></a> of AI safety enthusiasts, including fellow participants, METR staff, and established researchers. You'll find a friendly, supportive environment to discuss ideas, get feedback, and build relationships.</li><li>Collaborate with other participants as quality assurance testers to refine and validate your task. Splitting the prize with your QA tester means you can focus on ideation and implementation while ensuring your task is robust.</li><li>Maximize your productivity by following our weekend schedule, which includes office hours with METR experts and opportunities for socializing.</li><li>Earn thousands of dollars for rigorous, creative tasks that help assess the state of the art in AI capabilities. Payouts are 3x a human professional's salary for the task, with bonuses, so&nbsp;<strong>if a human software engineer spends 10 hours on your task, it could pay out $4500</strong> - and you can submit multiple tasks.</li><li>Jump-start your ongoing involvement in AI safety research by connecting with the METR and Apart teams and getting publisher credit for any tasks used in the METR evaluations. Many of our participants go on to intern or work with leading AI safety organizations.</li></ul><p>The Code Red Hackathon is a unique opportunity to contribute to critical AI safety research, connect with like-minded individuals, and potentially shape AI development. We encourage anyone passionate about AI safety to&nbsp;<strong>join us on March 22-24</strong> and be part of this groundbreaking effort.&nbsp;<a href=\"https://www.apartresearch.com/event/codered\"><u>Sign up now</u></a> and let's work together to ensure a safer future for AI.</p><p><i>In addition to the Code Red Hackathon, Apart runs the&nbsp;</i><a href=\"https://www.apartresearch.com/lab\"><i><u>Apart Lab fellowship</u></i></a><i>, publishes original research, and hosts other&nbsp;</i><a href=\"https://www.apartresearch.com/sprints\"><i><u>research sprints</u></i></a><i>. These initiatives aim to incubate research teams with an optimistic and action-focused approach to AI safety.</i></p><h3>Extra tips for participants</h3><p>The hackathon is designed to let people at all levels of technical experience meaningfully contribute to AI safety research. Keep these suggestions in mind to make the most of your experience:</p><ul><li><strong>You don't need to start from scratch.</strong> Implementing an existing task idea from METR's idea database is a great way to get familiar with the process and make a great contribution. Browse the database&nbsp;<a href=\"https://airtable.com/appmREY3ro5u51RZr/shrFQ6eFVu21ADUqt/tblyzsh1h5BcA7lwP?backgroundColor=cyan\"><u>here</u></a>.</li><li><strong>There are many ways to contribute.</strong> If you're not comfortable with the coding aspects, you can still make a huge impact by submitting well-formulated task&nbsp;<a href=\"https://airtable.com/appa8ULxLrTkQxw4K/shrBR6c5zPv2C6qWw\"><u>ideas</u></a> and&nbsp;<a href=\"https://airtable.com/appa8ULxLrTkQxw4K/shrGH2lmeeJWQzi5d\"><u>specifications</u></a>.</li><li><strong>Preparation pays off.</strong> To hit the ground running, we recommend browsing the task database, ideating, and choosing an idea to implement before the hackathon starts on Friday. You can even draft a specification or start on the implementation.</li><li><strong>Keep it simple.</strong> Complicated task setups are more likely to cause issues for the AI agent and quality assurance testing. Whenever possible, have all the information the agent needs contained directly in the prompt or use publicly available internet resources.</li><li><strong>Embrace iteration.</strong> Don't get stuck trying to perfect your first task. You will probably submit several drafts, get feedback from the METR team and other participants, and steadily hone the task over the weekend with the help of the QA tester.</li></ul><p>Remember, the hackathon is a collaborative effort \u2013 don't hesitate to reach out to other participants and the organizing team for feedback and support throughout the weekend. We're all here to help each other!</p><ol class=\"footnote-section footnotes\" data-footnote-section=\"\" role=\"doc-endnotes\"><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"1\" data-footnote-id=\"swub7br3z8o\" role=\"doc-endnote\" id=\"fnswub7br3z8o\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"swub7br3z8o\"><sup><strong><a href=\"#fnrefswub7br3z8o\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;A task in this context is a piece of code and supporting resources that makes an agent able to run a task (such as extracting a password from a compiled program with varying levels of obfuscation) and be evaluated for its performance on said task.&nbsp;<a href=\"https://taskdev.metr.org/introduction/#agents-tasks-and-task-families\"><u>Read more</u></a>.</p></div></li></ol>", "user": {"username": "esben-kran"}}, {"_id": "WjEuPyo4wH5kB8Ls6", "title": "Ambitious Impact launches a for-profit accelerator instead of building the AI Safety space. Let's talk about this.", "postedAt": "2024-03-18T03:44:16.516Z", "htmlBody": "<p>I think it is worth noting that Ambitious Impact (formerly known as Charity Entrepreneurship) has jumped into the <strong>extremely</strong> competitive space of <a href=\"AIM (CE) new program: Founding to Give. Apply now to launch a high-growth company!\">for-profit startups</a> BEFORE trying to help build the AI Safety space.&nbsp;<br><br>Some quick thoughts/background:<br><br>1. The AI Safety space has LOADS of very smart people that can't get jobs because there aren't enough organisations to hire them. It might be the biggest bottleneck in the cause area. Meanwhile, capabilities literally has dozens of billions being thrown into it<br><br>2. For-profit entrepreneurship isn't in Ambitious Impact's (AI, lol) <a href=\"https://www.charityentrepreneurship.com/post/the-cause-areas-ce-is-focusing-on\">top cause area</a><br><br>3. I brought this up in the past, and Joey responded in <a href=\"https://forum.effectivealtruism.org/posts/LjBgFdgHGjmnwjGob/why-isn-t-there-a-charity-entrepreneurship-program-for-ai\">this post</a>. I think his post was overall a useful start, specific in some ways but vague in others.&nbsp;Vague in a 'hey maybe <i>you</i> should look into this but I won't tell you why' kinda way<br><br><strong>Here is what I think is going on</strong>: there are people (maybe including Joey) 'in-the-know' about some things that make creating longtermist/AI safety startups really hard, but some of those reasons aren't being discussed publicly out of fear of shaming people for their failures and/or reluctance to put their money where their mouth is on x-risk.<br><br>I think we need a public discussion about whats &nbsp;going on here.&nbsp;Our lives may literally depend on it, even if Ambitious Impact doesn't think so.</p>", "user": {"username": "Yanni Kyriacos"}}, {"_id": "dmEwQZSbPsYhFay2G", "title": "EA \"Worldviews\" Need Rethinking", "postedAt": "2024-03-18T15:10:14.377Z", "htmlBody": "<p>I like <a href=\"https://www.openphilanthropy.org/research/worldview-diversification/\">Open Phil's worldview diversification</a>. But I don't think their current roster of worldviews does a good job of justifying their current practice. In this post, I'll suggest a reconceptualization that may seem <i>radical in theory</i> but is <i>conservative in practice</i>. Something along these lines strikes me as necessary to justify giving substantial support to paradigmatic Global Health &amp; Development charities in the face of competition from both <i>Longtermist/x-risk</i> and <i>Animal Welfare </i>competitor causes.</p><h2>Current Orthodoxy</h2><p>I take it that Open Philanthropy's current \"cause buckets\" or candidate worldviews are typically conceived of as follows:</p><ul><li>neartermist - incl. animal welfare</li><li>neartermist - human-only</li><li>longtermism / x-risk</li></ul><p>We're <a href=\"https://www.openphilanthropy.org/research/worldview-diversification/\">told</a> that how to weigh these cause areas against each other \"hinge[s] on very debatable, uncertain questions.\" (True enough!) But my impression is that EAs often take the relevant questions to be something like, <i>should we be speciesist</i>? and <i>should we only care about present beings</i>?<i>&nbsp;</i> Neither of which strikes me as especially uncertain (though I know others disagree).</p><h2>The Problem</h2><p>I worry that the \"human-only neartermist\" bucket lacks adequate philosophical foundations. I think Global Health &amp; Development charities are great and worth supporting (not just for speciesist presentists), so I hope to suggest a firmer grounding. Here's a rough attempt to capture my guiding thought in one paragraph:</p><blockquote><p>Insofar as the GHD bucket is really motivated by something like <i>sticking close to common sense</i>, \"neartermism\" turns out to be the wrong label for this. Neartermism may mandate prioritizing aggregate shrimp over poor people; common sense certainly does not. When the two come apart, we should give more weight to the possibility that (as-yet-unidentified) good principles support the common-sense worldview. So we should be especially cautious of <i>completely</i> dismissing commonsense priorities in a worldview-diversified portfolio (even as we give <i>significant</i> weight and support to a range of theoretically well-supported counterintuitive cause areas).</p></blockquote><p>A couple of more concrete intuitions that guide my thinking here: (1) <a href=\"https://forum.effectivealtruism.org/posts/vhKZ7hyzmcrWuBwDL/the-scale-of-fetal-suffering-in-late-term-abortions?commentId=pnQoK9Wpob2Zsc4DD\">fetal anesthesia</a> as a cause area intuitively belongs with 'animal welfare' rather than 'global health &amp; development', even though fetuses are human. (2) <a href=\"https://forum.effectivealtruism.org/posts/btTeBHKGkmRyD5sFK/open-phil-should-allocate-most-neartermist-funding-to-animal?commentId=sJ3jXKWTwPwJBvSNi\">It's a mistake to conceive of global health &amp; development as purely neartermist</a>: the strongest case for it stems from positive, reliable flow-through effects.</p><h2>A Proposed Solution</h2><p>I suggest that we instead conceive of (1) Animal Welfare, (2) Global Health &amp; Development, and (3) Longtermist / x-risk causes as respectively justified by the following three \"cause buckets\":</p><ul><li>Pure suffering reduction</li><li>Reliable global capacity growth</li><li>High-impact long-shots</li></ul><p>In terms of the underlying worldview differences, I think the key questions are something like:</p><p>(i) <i>How confident should we be in our </i><a href=\"https://blog.givewell.org/2011/08/18/why-we-cant-take-expected-value-estimates-literally-even-when-theyre-unbiased/\"><i>explicit expected value estimates</i></a><i>? &nbsp;How strongly should we discount highly speculative endeavors, relative to \"commonsense\" do-gooding?</i></p><p>(ii)<i> How does the total (intrinsic + instrumental) value of improving human lives &amp; capacities compare to the total (intrinsic) value of pure suffering reduction?</i></p><p>[Aside: I think it's <i>much</i> more reasonable to be uncertain about these (largely empirical) questions than about the (largely moral) questions that underpin the orthodox breakdown of EA worldviews.]</p><p>Hopefully it's clear how these play out: greater confidence in EEV lends itself to supporting longshots to reduce x-risk or otherwise seek to improve the long-term future in a highly targeted, deliberate way. Less confidence here may support more generic methods of global capacity-building, such as improving health and (were there any promising interventions in this area) education. Only if you're <i>both</i> dubious of longshots <i>and</i> doubt that there's all that much instrumental value to human lives do you end up seeing \"pure suffering reduction\" as the top priority.<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"1\" data-footnote-id=\"heo8v35sm1q\" role=\"doc-noteref\" id=\"fnrefheo8v35sm1q\"><sup><a href=\"#fnheo8v35sm1q\">[1]</a></sup></span>&nbsp;But insofar as you're open to pure suffering reduction, there's no grounds for being speciesist about it.</p><h2>Implications</h2><ul><li>Global health &amp; development is actually philosophically defensible, and shouldn't necessarily be swamped by <i>either</i> x-risk reduction <i>or</i> animal welfare. But it requires recognizing that the case for GHD requires a strong prior on which <i>positive \"flow-through\" effects are assumed to strongly correlate with traditional neartermist metrics like QALYs</i>. Research into the prospects for improved tracking and prediction of potential flow-through effects should be a priority.</li><li>In cases where the correlation transparently breaks down (e.g. elder care, end-of-life care, fetal anesthesia, <a href=\"https://onlinelibrary.wiley.com/doi/full/10.1111/papq.12449\">dream hedonic quality</a>, wireheading, etc.), humanitarian causes should instead need to meet the higher bar for <i>pure suffering reduction </i>- they shouldn't be prioritized above animal welfare out of pure speciesism.<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"2\" data-footnote-id=\"vc1ufsy1zzr\" role=\"doc-noteref\" id=\"fnrefvc1ufsy1zzr\"><sup><a href=\"#fnvc1ufsy1zzr\">[2]</a></sup></span></li><li>If we can identify other <i>broad, reliable</i> means to boosting global capacity (maybe fertility / population growth?),<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"3\" data-footnote-id=\"rgid0ego5cf\" role=\"doc-noteref\" id=\"fnrefrgid0ego5cf\"><sup><a href=\"#fnrgid0ego5cf\">[3]</a></sup></span>&nbsp;then these <i>should </i>trade off against Global Health &amp; Development (rather than against x-risk reduction or other longshots).</li></ul><p>&nbsp;</p><ol class=\"footnote-section footnotes\" data-footnote-section=\"\" role=\"doc-endnotes\"><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"1\" data-footnote-id=\"heo8v35sm1q\" role=\"doc-endnote\" id=\"fnheo8v35sm1q\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"heo8v35sm1q\"><sup><strong><a href=\"#fnrefheo8v35sm1q\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>It's sometimes suggested that an animal welfare focus <i>also</i> has the potential for positive flow-through effects, primarily through improving human values (maybe especially important if AI ends up implementing a \"coherent extrapolation\" of human values). I think that's an interesting idea, but it sounds much more speculative to me than the obvious sort of capacity-building you get from having an extra healthy worker in the world.</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"2\" data-footnote-id=\"vc1ufsy1zzr\" role=\"doc-endnote\" id=\"fnvc1ufsy1zzr\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"vc1ufsy1zzr\"><sup><strong><a href=\"#fnrefvc1ufsy1zzr\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>This involves some revisions from ordinary moral assumptions, but I think a healthy balance: neither the unreflective dogmatism of the ineffective altruist, nor the extremism of the \"redirect all GHD funding to animals\" crowd.</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"3\" data-footnote-id=\"rgid0ego5cf\" role=\"doc-endnote\" id=\"fnrgid0ego5cf\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"rgid0ego5cf\"><sup><strong><a href=\"#fnrefrgid0ego5cf\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>Other possibilities may include scientific research, economic growth, improving institutional decision-making, etc. It's not clear exactly where to draw the line for what counts as \"speculative\" as opposed to \"reliably\" good, so I could see a case for a further split between \"moderate\" vs \"extreme\" speculativeness. (Pandemic preparedness seems a solid intermediate cause area, for example - far more robust, but lower EV, than AI risk work.)</p></div></li></ol>", "user": {"username": "RYC"}}, {"_id": "sF7vBtXLFTLeNvaDt", "title": "Revisiting the Evolution Anchor in the Biological Anchors Report ", "postedAt": "2024-03-18T03:01:52.435Z", "htmlBody": "<h2><i>A review of criticisms and an alternative estimate based on the thermodynamic approach</i></h2><figure class=\"table\" style=\"height:246.75px;width:626.987px\"><table style=\"background-color:rgb(255, 255, 255);border:1px double rgb(151, 201, 177)\"><tbody><tr><td style=\"background-color:rgb(221, 238, 232);border:0.681818pt solid rgb(151, 201, 177);padding:5pt;vertical-align:top\"><strong>This is a&nbsp;</strong><a href=\"https://forum.effectivealtruism.org/topics/draft-amnesty-week-2024\"><strong><u>Draft Amnesty Week</u></strong></a><strong> draft.&nbsp;</strong>It may not be polished, up to my usual standards, fully thought through, or fully fact-checked.&nbsp;</td></tr><tr><td style=\"background-color:rgb(238, 248, 244);border:0.681818pt solid rgb(0, 0, 0);padding:4.98898pt;vertical-align:top\">This is a Forum post that I wouldn't have posted without the nudge of Draft Amnesty Week (kudos!). I'd love to see comments and criticisms that take the ideas forward, but it's unlikely that I will spend much more time on this project.&nbsp;</td></tr></tbody></table></figure><p><strong>The following is just the executive summary. The full (draft) report is available </strong><a href=\"https://docs.google.com/document/d/1L9D_5Jh3Y3soAMCykqWyVB2UQPYZgg8KLhff1jPGkPQ/edit?usp=sharing\"><strong>here</strong></a><strong>.&nbsp;</strong></p><p><i>This report is the work of Janvi Ahuja and Victoria Schmidt as part of the Epoch FRI Mentorship Programme 2023. We worked on for ~10 hours a week for two months. Tegan McCaslin mentored the project, and Rose Hadshar and Angelina Li provided significant feedback and advice as our peer reviewers.&nbsp;</i></p><p>The&nbsp;<a href=\"https://docs.google.com/document/d/1IJ6Sr-gPeXdSJugFulwIpvavc0atjHGM82QjIfUSBGQ/edit#heading=h.c5pt0lvk9kkw\"><u>Forecasting TAI timelines with biological anchors</u></a> report produces an estimate of the compute needed to develop a transformative model using 2020 architectures and algorithms. It uses six different biological frameworks to estimate the compute needed to develop a transformative model, one of which is an evolution-based framework. The evolution anchor estimates the amount of computation done by all animals throughout evolution, from the earliest animals with neurons to modern-day humans. In this report, we look into criticisms of the evolution anchor and summarise their effect sizes. We then expand on one such criticism and discuss some of our own criticisms with the biological anchors framework as a whole.&nbsp;</p><p>This report may be useful to you if you:&nbsp;</p><ul><li>Are interested in biological anchors and defer to the report to determine your AI timelines (and put some weight on the evolutionary anchor). In this case, I would recommend reading the executive summary and reading further on areas of interest. Note, Cotra has posted an&nbsp;<a href=\"https://www.lesswrong.com/posts/AfH2oPHCApdKicM4m/two-year-update-on-my-personal-ai-timelines\"><u>update</u></a> to her original draft and has been interviewed more&nbsp;<a href=\"https://www.lesswrong.com/posts/K2D45BNxnZjdpSX2j/ai-timelines\"><u>recently</u></a> on her timelines.</li><li>Are interested in the upper bound estimate of the biological anchors report and want to investigate the most conservative anchor, or otherwise particularly interested in evolutionary anchor. In this case, I might recommend reading <a href=\"https://docs.google.com/document/d/1L9D_5Jh3Y3soAMCykqWyVB2UQPYZgg8KLhff1jPGkPQ/edit\">the whole report</a>.</li></ul><h1><strong>Executive summary</strong></h1><h2><strong>Motivation statement</strong></h2><ul><li>The biological anchors report has influenced many views on when TAI will be developed. A<a href=\"https://forum.effectivealtruism.org/posts/BGFbwca4nfagvB9Xb/deference-on-ai-timelines-survey-results\"> survey by Clarke and McCaffary </a>(March 2023) found it was the second most cited source deferred to on TAI timelines (where the first is \u201cinside view\u201d).&nbsp;</li><li>At the outset of the fellowship, our goal was to expand on Nu\u00f1o Sempere\u2019s criticism pertaining to the cost of simulating the environment, but we found this difficult to make traction on (see footnote <a href=\"https://docs.google.com/document/d/1L9D_5Jh3Y3soAMCykqWyVB2UQPYZgg8KLhff1jPGkPQ/edit#heading=h.c5eu44kiv6bd\">here</a> for more information).</li><li>Instead, we decided to collate all the criticisms on the evolutionary anchor and their effect sizes.</li><li>We also decided to expand on one of the alternative approaches to the evolutionary anchor.</li></ul><h2><strong>What we did</strong></h2><ul><li>Summarised critiques of the evolution anchor&nbsp;</li><li>Proposed a best guess for an upper bound based on the thermodynamic approach&nbsp;</li><li>Proposed reasons we think you should be sceptical of the evolution anchor framework and our results</li><li>Suggested how this might affect your TAI timelines</li></ul><h3><a href=\"https://docs.google.com/document/d/1L9D_5Jh3Y3soAMCykqWyVB2UQPYZgg8KLhff1jPGkPQ/edit#heading=h.odznt7ay24is\">Summarised critiques of the evolution anchor</a>&nbsp;</h3><figure class=\"table\"><table><tbody><tr><td style=\"background-color:#d9d9d9;border:1pt solid #000000;padding:5pt;vertical-align:top\"><strong>Critique and approach to incorporate this into the evolution anchor</strong></td><td style=\"background-color:#d9d9d9;border:1pt solid #000000;padding:5pt;vertical-align:top\"><strong>Expected effect size</strong></td><td style=\"background-color:#d9d9d9;border:1pt solid #000000;padding:5pt;vertical-align:top\"><strong>Updated evolution anchor&nbsp;</strong></td><td style=\"background-color:#d9d9d9;border:1pt solid #000000;padding:5pt;vertical-align:top\"><strong>Reference</strong></td></tr><tr><td style=\"background-color:#ffe599;border:1pt solid #000000;padding:5pt;vertical-align:top\"><i>Original estimate</i></td><td style=\"background-color:#ffe599;border:1pt solid #000000;padding:5pt;vertical-align:top\"><i>N/A</i></td><td style=\"background-color:#ffe599;border:1pt solid #000000;padding:5pt;vertical-align:top\"><p><i>1E41 FLOP</i></p></td><td style=\"background-color:#ffe599;border:1pt solid #000000;padding:5pt;vertical-align:top\"><a href=\"https://docs.google.com/document/d/1IJ6Sr-gPeXdSJugFulwIpvavc0atjHGM82QjIfUSBGQ/edit#heading=h.c5pt0lvk9kkw\"><i><u>Ajeya Cotra</u></i></a></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Environment simulation:&nbsp;</p><p>Add costs of simulating an environment and coupling architectures with that environment</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Upwards: not quantified</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>N/A</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><a href=\"https://docs.google.com/document/d/1_GqOrCo29qKly1z48-mR86IV7TUDfzaEXxD3lGFQ8Wk/edit\"><u>Jennifer Lin</u></a></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Environment simulation:</p><p>Add environmental simulation cost to the original estimate</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>+5E27 - \u22654E29 FLOP&nbsp;</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>1E41 FLOP</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><a href=\"https://nunosempere.com/blog/2022/08/10/evolutionary-anchor/\"><u>Nuno Sempere</u></a></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Environment simulation:</p><p>Simulate whole Earth, <i>molecular simulation</i></p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>1E60 FLOP&nbsp;</p><p><br>&nbsp;</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>1E60 FLOP</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><a href=\"https://mybrainsthoughts.com/?p=349\"><u>meanderingmoose</u></a></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Environment simulation:</p><p>Simulate whole Earth, <i>thermodynamic approach</i></p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>1E45 FLOP&nbsp;</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>1E45 FLOP</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><a href=\"https://docs.google.com/document/d/1oV1yRMhnVbfleoUD73-P_poIp5IOfJeq9Bz_GBi5SN4/edit#heading=h.iyo6d94qol5c\">Ege Erdil</a></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Anthropic critiques&nbsp;</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>+up to 6 OOM&nbsp;</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>1E41 - 1E47 FLOP</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><a href=\"https://docs.google.com/document/d/1oV1yRMhnVbfleoUD73-P_poIp5IOfJeq9Bz_GBi5SN4/edit#heading=h.iyo6d94qol5c\">Ege Erdil</a></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt\" rowspan=\"2\">Paradigm shift</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>possibly +&gt;&gt;30 years</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>N/A</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p><a href=\"https://docs.google.com/document/d/1_GqOrCo29qKly1z48-mR86IV7TUDfzaEXxD3lGFQ8Wk/edit\"><u>Jennifer Lin</u></a></p><p><br>&nbsp;</p></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Drastically shortened timelines; not quantified here</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Discard biological anchors completely</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><a href=\"https://www.lesswrong.com/posts/ax695frGJEzGxFBK4/biology-inspired-agi-timelines-the-trick-that-never-works\"><u>Elizier Yudkowsky</u></a></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Missing architecture search space</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Upwards; not quantified</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>N/A</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><a href=\"https://docs.google.com/document/d/1_GqOrCo29qKly1z48-mR86IV7TUDfzaEXxD3lGFQ8Wk/edit\"><u>Jennifer Lin</u></a></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Evolutionary algorithms are inefficient</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Downwards; not quantified</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Decrease the weight of the evolution anchor to 3%</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><a href=\"https://www.lesswrong.com/posts/Q3fesop6HKnemJ5Jc/disagreement-with-bio-anchors-that-lead-to-shorter-timelines\"><u>Marius Hobbhahn</u></a></td></tr></tbody></table></figure><p><br>&nbsp;</p><h3><a href=\"https://docs.google.com/document/d/1L9D_5Jh3Y3soAMCykqWyVB2UQPYZgg8KLhff1jPGkPQ/edit#heading=h.kw9lkbae0rtw\">Proposed a best guess for an upper bound based on the thermodynamic approach&nbsp;</a></h3><ul><li>The thermodynamic approach estimates the total amount of energy received by the earth from the Sun and converts this into FLOP. Erdil used the Landauer principle for this conversion, which is the theoretical lower limit of energy consumption of computation. As we expect that most energy was not converted as efficiently as the theoretical lower limit we propose two alternatives:&nbsp;<ul><li>Using the conversion rate it takes for the brain to convert joules into FLOP</li><li>Using the conversion rate it takes for the human body to convert joules into FLOP</li></ul></li><li>As we can expect the average energy-to-information processor to be less efficient than the human brain or body, we expect this is still a conservative upper limit. Our model in the form of a Google sheet is available&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1rg7Wv43HFiDMvGDzdvCAIiFb86dKpE4eld7126rhYh0/edit#gid=0\"><u>here</u></a>.</li><li>These approaches result in upper bound estimates which are 4-6 OOMs smaller than the Landauer\u2019s principle approach.&nbsp;</li><li>In addition, the upper bounds for both of these estimates are lower than Cotra\u2019s estimate (1E41), at 2E40 for the caloric approach and 6E40 for the brain energy consumption approach. This provides a more informative estimate for the evolution anchor, narrowing down the range to 2E40 FLOP as an upper bound.</li></ul><h3><a href=\"https://docs.google.com/document/d/1L9D_5Jh3Y3soAMCykqWyVB2UQPYZgg8KLhff1jPGkPQ/edit#heading=h.ef2q8ypcuq9w\">Proposed reasons we think you should be sceptical of the evolution anchor framework and our results</a></h3><ul><li>We expand on fundamental issues with the evolution anchor and how it is derived in Cotra\u2019s report. These include:<ul><li>Weighing FLOP estimates against developments in compute capacity</li><li>Noting that bounding parameter estimates is difficult and sometimes arbitrary</li><li>Noting that some of the parameter ranges vary by many orders of magnitude</li><li>Noting that FLOP conversion to intelligence is abstract and weird</li></ul></li></ul><h3><a href=\"https://docs.google.com/document/d/1L9D_5Jh3Y3soAMCykqWyVB2UQPYZgg8KLhff1jPGkPQ/edit#heading=h.852w5mak40z1\">Suggested how this might affect your TAI timelines</a></h3><ul><li>Finally, we provide an overview of what our work could mean for TAI timeline estimates. This is shown below:&nbsp;<ul><li>If you:&nbsp;<ul><li>Believe that Cotra\u2019s model and framework for calculating TAI is reasonable</li><li>Believe that the thermodynamic estimate for the evolution anchor is better than the brain computation method Cotra uses, and&nbsp;</li><li>Believe that our best guess proposal for an improvement upon the thermodynamic estimate is better than the original Landauer approach&nbsp;<ul><li>You might change your best guess for a FLOP estimate for an upper bound to be 1.79E40 FLOP instead of 1e41 FLOP.&nbsp;</li></ul></li></ul></li><li>If you:<ul><li>Believe one of the other criticisms/adjustments noted in section two is legitimate, you might&nbsp;<ul><li>Use the naive estimated effect sizes to update your estimate of FLOP needed to develop TAI</li><li>Choose to investigate it further and update accordingly</li><li>Consider Nu\u00f1o Sempere\u2019s&nbsp;<a href=\"https://nunosempere.com/blog/2022/08/10/evolutionary-anchor/\"><u>propagation of beliefs</u></a> given additional uncertainty surrounding the evolution anchor</li></ul></li></ul></li><li>If you:<ul><li>Believe any of the major reasons to be sceptical listed above you might<ul><li>Downweight on the evolution anchor and the entire biological anchors report&nbsp;</li><li>Consider other ways to assess AI timelines&nbsp;</li><li>Consider Nu\u00f1o Sempere\u2019s&nbsp;<a href=\"https://nunosempere.com/blog/2022/08/10/evolutionary-anchor/\"><u>propagation of beliefs</u></a> given additional uncertainty surrounding the evolution anchor</li></ul></li></ul></li></ul></li></ul><p><br><br>&nbsp;</p>", "user": {"username": "Janvi"}}, {"_id": "QGo2b8GBKwxudyajg", "title": "Deafness is tangential", "postedAt": "2024-03-17T22:58:41.790Z", "htmlBody": "<figure class=\"table\"><table style=\"border-color:#97C9B1;border-style:double\"><tbody><tr><td style=\"background-color:#DDEEE8;border:0.68181825pt solid #97C9B1;padding:5pt;vertical-align:top\"><strong>This is a&nbsp;</strong><a href=\"https://forum.effectivealtruism.org/topics/draft-amnesty-week-2024\"><strong><u>Draft Amnesty Week</u></strong></a><strong> draft.&nbsp;</strong>It may not be polished, up to my usual standards, fully thought through, or fully fact-checked.&nbsp;</td></tr><tr><td style=\"background-color:#EEF8F4;border:0.68181825pt solid #97C9B1;padding:4.988976377952756pt;vertical-align:top\"><p><strong>Commenting and feedback guidelines:&nbsp;</strong><br>Keep one and delete the rest:</p><p>This is a Forum post that I wouldn't have posted without the nudge of Draft Amnesty Week. Fire away! (But be nice, as usual)</p></td></tr></tbody></table></figure><p>I'm not deaf. But I want to make a clear a case that might come up to mind when discussing EA topics.</p><p>Note&nbsp;: I use the word \u00ab&nbsp;deafblind&nbsp;\u00bb here due to uncertainty on whether part or all of deafblind people identify as protactile. I've been encouraged by my sign language linguistics teacher to prefer \u00ab&nbsp;protacticle&nbsp;\u00bb to refer to the specific community self-denominating themselves as such, which do not encompass all deafblind people, hence my usage of the later expression.</p><h2>1-The two problems</h2><p>Two of the critiques of EA I've already heard is the following&nbsp;:</p><p>-Ilnesses should be prioritized to the extent that they imply tradeoffs, such as is mirrored by QALYs&nbsp;: if one were to trade, say, one or two years of life to recover from deafness, then it means that deafness is a negative experience, which implies that it oughts to be cured, rather than accepted and welcomed in society.</p><p>-What constitutes a moral patient is its ability to experience sentience, which in turn rests on different subjective experiences. Thus, deaf people count \u00ab&nbsp;less&nbsp;\u00bb than others.</p><p>Now, there is no question, for me, that both of these conclusions are clearly audist and should be worrisome if implied by EA. However, I think that they are not, and I think it is important to make clear to the deaf community that they are not, and that they should not be worried about EA. If an EA were to be headed in a country, be sure that they will not consider the deaf community as a relic of the past needing to be abandonned, replaced by ever-so functional gene therapy and hearing implents.<br>&nbsp;</p><h2>2-Preference utilitarianism</h2><p>Again, as a disclaimer&nbsp;: I don't really consider myself a classical utilitarian. But I think that this is the view that is assigned by outsiders to EA, so I think tackling this is more important than tackling the issue with other ethics.</p><p>The first objection I'd have to these implications is preference utilitarianism. If one is to define wellbeing as being (at least in part) defined by respecting one's preferences, then it doesn't really matter what QALYs are associated with deafness from birth. What matters is what QALYs are associated with <i>one's</i> deafness from birth, and I deem it completely acceptable that someone would say that they are fine with their deafness and wouldn't trade their identity (let alone <i>lifetime</i>) for a wider auditive spectrum.</p><p>I'll suggest a parallel here (but I'm in no means saying this is equivalent in severity and hardhsip) with sexual orientation. I personally have a preference for people of the same sex and gender than me. I'd theoretically be happier if I were to be attracted by a more diverse set of people, even more so if I were living in a homophobic region of the world. However, even if I were living in a culturally homophobic area (which I did), I wouldn't prefer to trade my homosexuality for, e.g, bisexuality. It is, after all, my personal preference. If I were presented with a magical pill that allowed me to feel attracted by a larger set of person, as things stand by now, I think I wouldn't take it, because it would make me feel (very) guilty of obeying social pressures rather than being a positive force for changing them.</p><h2>3-Robust wellbeing</h2><p>But I'll go farther than that. I think that hedonistic utilitarianism also implies that we shouldn't automatically cure deafness at birth. There is a certain tendency among detractors of utilitarianism to think that utilitarians have a very monochromatic view of pleasure. A +45 util does not feel several possible ways, it feels only like what a +45 utils feels. I think this is misguided. As humans, we have several modal fields (vision, hearing, touch, enteroceptions...). There is virtually an infinite number of ways of experiencing a +45 utils, through one modality or a combination of several, and this diversity, utilitarians claim, has no bearing on moral imperatives when facing tradeoffs.</p><p>Still, one might say, if I were to experience +45 utils in all modalities except for audition at time T, and then experience +45 utils in all modalities including audition at time T+1, then it should not be regarded as morally wrong to \u00ab&nbsp;cure&nbsp;\u00bb someone from deafness without their explicit consent (such as is usually attempted soon after birth in countries such as France). I think that not requesting consent is generally wrong, even when considering act utilitarianism. The reason is that, as Singers points out in Practical Ethics, there is a difference between merely sentient beings and persons. Persons have their wellbeing affected by their plans, projections in the future, and the fullfilment of those. A deaf person who is proud and willing to be deaf has a continuous fulfillment of their plan to stay deaf. When transforming this person into a hearing person, one does not face a merely sentient being, and thus harms them by causing them to stop this, sometimes deeply meaningful, fulfillment.</p><p>Now, granted, they are still infants when they receive an implant. But people implanted at birth often regard back to this event with ambivalence and sometimes regret. It's not like an abortion, where the aborted f\u0153tus cannot look back on its abortion and think about it.<br>&nbsp;</p><h2>4-Unintended consequences</h2><p>Another worry an act utilitarian can legitimetaly have is that curing deafness in reality is not that effective. When implementing an intervention, such as implenting hearing aids to deaf infants without their consent, the initial cost in theory and in practice stays relatively fix -namely, it's the cost of the gear and surgical operation. However, the overall benefice in theory and in practice can widely fluctuate. After generalization, doctors can misunderstand the point of hearing aids and think that the child can be deprived from visual linguistic input without any consequences (wrong). Society can conserve its biases and wrong ideas towards deaf people. It can refuse to create adapted venues that are actually still necessary, etc.</p><p>I think it probable that being born deaf in our time would be, in an accepting society, not much of a loss compared to being born hearing. For example, deaf signing people seem to have an expanded visuo-spatial awareness that hearing people usually lack. They have their own artforms. If we were to cure deafness, there would basically be a transfer from enjoying deaf artforms to enjoying hearing artforms, from deaf-predominant pleasures to hearing-predominant pleasure, etc. I don't think we would gain anything, and I think that the only net gains to be had are in curing reluctantly acquired deafness and in fighting audism.</p><h2>5-Hypothetical wellbeing</h2><p>I'll even go further than deafness in general. Suppose that, after some sort of course of event, we happen to have entirely deleted deafness, and no one remembers what it was. Then, suddenly, a deaf person is born. Through some sort of series of unprobable events, they happen to not be \u00ab&nbsp;cured&nbsp;\u00bb from their deafness. This person may experience loneliness and confusion, they may lack a sense of belonging, they may feel oppressed. All these experiences are pretty negative. It doesn't really affect me to think that this person exists or not. I think that, in an optimal society, the society itself is<i> ready to react </i>to that kind of events, that no matter the modal differences that characterizes one individual, it is designed in a way that takes it in account. Ideally, if a world were to be post-deafness, I think it would be wrong (in terms of potential suffering, somehow like S-risks) to not have mechanisms in place such as, as soon as a deaf person is born, then sign language education, subtitles, accessibility in general and, of course, their active contribution to shape this accessibility are automatically deployed.</p><p>I think this is true of deafness, and of any difference among individuals in general.</p><p>&nbsp;</p><h2>6-A thought experiment&nbsp;: the modal marginal overlords.</h2><p>A philosopher whose name I forgot has made clear the speciesist bias implied by \u00ab&nbsp;trait&nbsp;\u00bb arguments throught the overlords thought experiment. I invite you to repeat this though experiment with a different kind of overlords, the modal marginal overlords. Imagine that, following a pandemic, the population is suddenly constituted of 98% of special humans. Following a life-lasting genetic mutation caused by the disease of the pandemic, these humans have developped a new modal field of experience, called <i>plussing. </i>Now, they can <i>pluss</i> bananas, sunsets, cities, and many different things that we currently lack the capacity of doing. They find this modality quite useful, and start adapting their society to incorporate it in all parts of their life, such as leisure, work, orientation, etc. They find it so convenient that it progressively replaces vision. Now, there would not be any lamps left, since <i>plusscasters</i> scattered everywhere allow to <i>pluss</i> the environment. Their facial mimics now stand still, and they would <i>plusscast</i> emotions directly to one another.</p><p>It would be wrong, in our current eyes, to consider the remaining 2% to be less worthy of moral consideration. No matter whether a -50 utils of information is conveyed through classical senses or an additional <i>pluss</i> sense, it would still be a -50 utils and would thus be bad. According to my hypothetical wellbeing paragraph above, it would also be wrong, in my eyes, to remove public lighting and render society inaccessible to <i>plussless</i> people. However, it would not affect the fact that <i>plussless</i> people who <i>want</i> to be <i>plussing</i> can be offered help in pursuing a technology that allows them to do so, and the fact that acquired <i>plusslessness</i> might also be a medical preoccupation. But it would be indeed absurd to <i>require</i> from plussless people to be implented for them to experience <i>plussness</i> much like <i>plussing</i> people do, and even more so if they experience pleasure in fulfilling their plan of staying proudly <i>plussless</i>, defending such artforms as traditional cinema or performing arts.</p><p>&nbsp;</p><h2>7-Deafness is a special case&nbsp;: laws of modal equivalence</h2><p>I believe that utils are technically affected, primordially, by information. Therefore, as long as the modality one is \u00ab&nbsp;deprived&nbsp;\u00bb of (in events that keep the brain plasticity and cognitive technology required to communicate) does not prevent informational communication (this thus applies to sound, vision, and the combination of both, since tactile communication is functional), I believe that they do not affect potential utils experienced by a given sentience. I think that, if the people affected decide that they do not want to gain additional modalities, their choice should be respected as such (and I also think that, were someone desiring to lose one of their modalities, their choice should also be respected as such), even under a hedonistic act utilitarian perspective. I also believe that infants should be allowed all options at birth, whether modally restricted or not&nbsp;: ideally, all children should be exposed to oral, written, sign and tactile language. They can thus later decide which modality to prioritize or leave (exception being made for written language, which can be conveyed in all modalities).</p><p>Of course, in our world, given the current inequalities and ressource limitations, it is justified to focus this accessibility to children who are hearing- or additionally vision-\u00ab&nbsp;impaired&nbsp;\u00bb. This, again, ideally means that infants born deaf and deafblind should be raised bimodally. Since we do not live in an ideal world, it is justifiable to prioritize tactile (and arguably sign) languages for deafblind children and sign languages for deaf children. However, it would be wrong to prevent an infant to be exposed to any of those languages, even by motivating such a prevention by the so-called wellbeing of the child. As we saw, developping oneself in one modality rather than three is not a wrongdoing and does not affect the utils one experiences, as long as the choice of the person is respected. The joy of having a child will be the same whether the information, in all its clarity, can be conveyed by sound, sign or tactile patterns in the palm of a hand, or the three all at once.</p>", "user": {"username": "Camille"}}, {"_id": "sMDAXg6XAwXpbKWr5", "title": "Vegans as an Interest Group", "postedAt": "2024-03-17T21:29:42.831Z", "htmlBody": "<p>This a linkpost from my personal blog; posting it during draft amnesty week largely because it ended up making recommendations that I don't have the experience to evaluate well.&nbsp;</p><hr><p>For this post, I\u2019d like to focus on something that\u2019s been buzzing around in my head for awhile now. It is partly a personal annoyance about the reception of the animal advocacy movement in academia as much as an identification of a particular failing point.</p><h2>Introduction</h2><p>A very rough model of the stages of success for the animal advocacy movement proceeds as such:</p><p><i>Small group of vegan advocates\u2014\u2014\u2014\u2014\u2014\u2192Majority reject speciesism</i></p><p>In analogy, the civil rights movement could be (very roughly) modeled in the same fashion, going from self-avowed racism to a ending in a majority rejecting overt racist beliefs. This obviously leaves out a lot of grey areas. And it doesn\u2019t account for the possibility of a non-linear relationship between speciesist attitudes and progress, such as may occur via incremental welfare reforms or the mass adoption of clean meat.</p><p>I think we can fill in a middle stage with a reasonable degree of confidence:</p><p><i>Small group of vegan advocates\u2014\u2014\u2014\u2014\u2014\u2192Recommendations of advocates begin to be adopted by experts \u2014\u2014\u2014\u2014\u2014\u2192Majority reject speciesism</i></p><p>Why think this isn't happening? Well, here\u2019s an example of a glaring hole where this should be happening\u2026 but isn\u2019t.</p><blockquote><p>4.3. Conclusion</p><p>What people eat has implications not only for individuals, but also the environment and others around the world. Eating less meat can arguably protect against fatal and costly diseases, help address the climate crisis, and mitigate social justice issues like world hunger. We observed that pledging can be an effective tool for promoting meat reduction, particularly in countries where plant-based eating is currently trending. However, pledging mainly serves as a temporary opportunity to reduce. Further mechanisms are needed to sustain commitments beyond the boundaries of the initial pledge.</p></blockquote><p>Something is missing\u2026</p><p>I chose <a href=\"https://www.sciencedirect.com/science/article/pii/S0195666321006334?utm\">this particular example</a> because it is on a topic (study on effect of pledges on reducing meat consumption) which is <i>highly </i>relevant to reducing the suffering of animals; and it\u2019s not a non-obvious connection either, or one requiring special knowledge of the intricacies of animal agriculture. Indeed, it was even supported with grant money from Animal Charity Evaluators!</p><p>As examples go, the rest of it seems to be passable on a first glance of the introduction of the paper; for instance they do a much better job at detailing other work on pledging and on remarking on the history of vegan activists using it, even mentioning the <a href=\"https://www.sciencedirect.com/science/article/abs/pii/S0950329318309327\">4 N\u2019s</a>, much better than <a href=\"https://link.springer.com/article/10.1186/s42055-019-0010-0#Abs1\">this</a> very similar paper, or <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7256495/\">this one</a>. The point isn\u2019t to judge the quality of these studies.</p><p>One might object \u201cbut no one reads conclusions, introductions, impact statements, or discussions anyways, so what!\u201d. I\u2019m not an academic, so perhaps I\u2019m missing important life experience with study design, execution, review, publication, etc. But surely these have <i>some </i>influence. Dealing with study participants, IRB demands, data analysis and so on may have been the real, substantial work. But typing a few words in LaTeX on animal interests in the subject at hand forces acknowledgment of them. And humans take cues, if the studies forming the literature on meat consumption pledges mention animal welfare in the conclusions, you\u2019ll do so too. The more prevalent acknowledgments of animal welfare are, the more the Overton window for the \u201cproper\u201d place of animal welfare concerns shifts, and the more a foundation is built for work more directly focused on the subject.<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"1\" data-footnote-id=\"e5smjgu1xnp\" role=\"doc-noteref\" id=\"fnrefe5smjgu1xnp\"><sup><a href=\"#fne5smjgu1xnp\">[1]</a></sup></span>&nbsp;So acknowledging animal interests <i>is</i> important. But just \u201cdo more of that then!\u201d misses the core of the issue.</p><p>The core of the issue isn\u2019t merely that animal welfare concerns are often not mentioned. <strong>It\u2019s that they are not recognized as being self-justifying. </strong>Even individuals and groups likely amenable to including them on equal footing, don\u2019t do so.<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"2\" data-footnote-id=\"70umjmtpg3x\" role=\"doc-noteref\" id=\"fnref70umjmtpg3x\"><sup><a href=\"#fn70umjmtpg3x\">[2]</a></sup></span><strong>&nbsp;If they are mentioned, it only occurs in the round-about fashion that the concerns of an particular (human) interest group, like \u201crights activists\u201d are acknowledged. </strong>This is reflective of current attitudes, but it also reinforces them. Undermining this faulty cognitive model is key.</p><p>This dynamic can be seen in papers on everything from food policy, economics to ecology. Development economics could play a big role in coming decades as developing countries adopt the cruel industrialized animal agriculture of the developed world; one economist in <a href=\"https://blogs.worldbank.org/impactevaluations/it-time-development-economists-start-considering-welfare-non-human-animals?s=09&amp;utm_source=pocket_saves\">a recent World Bank blog post</a> pointed out that welfare indexes (e.g. GDP) are inadequate due to lacking measures of animal welfare. Human ecological impacts are a common fretting point of environmentalists and a significant proportion of the general, nature-loving public. Yet a careful reader of any given concern of these folk may recognize that animal <i>welfare</i> is not often among them; saving endangered species, preserving nature, ensuring biodiversity and so on are anthropocentric concerns, <a href=\"https://www.vox.com/the-highlight/22325435/animal-welfare-wild-animals-movement\">increasing the aggregate welfare of wild animals</a> is only loosely related at best. It is almost exclusively within the research sphere associated with the Effective Altruism movement that animal welfare is regularly weighed along with human interests.</p><p>All that considered, <i>why </i>is this the case? I don\u2019t want to make this about the wider challenges around getting people to go vegan and ending the exploitation of animals; that\u2019s a topic for another day. I think there are reasons particular to the quandary of why the research community avoids treating insights on animal welfare as equally important, or even comparable, to anthropocentric interests.</p><p>Certainly, if most people were as insistent that animal interests be recognized as I am, this wouldn\u2019t be a problem. But that shouldn\u2019t be a necessary factor. There are many motivations and niche ideologies that animate academics that don\u2019t animate the general public. And many of these, at least ideally, don\u2019t have to be matters of great emotional import.</p><p>A researcher may for instance be intrinsically driven to study poverty due to his childhood experience, but he doesn\u2019t have to be especially emotionally attached to the experiences of young black men without college degrees to give the particular phenomenon of the racial wealth gap some examination. It\u2019s just a matter of course for doing a through job. Likewise, researchers looking at the value of a policy providing free school lunches to children may reasonably look at everything from the cost, to the impact on parents, to nutritional improvements in the kids, to the carbon footprint of the lunches provided. Missing the impact on the animals eaten could be recognized as just as much of an oversight as anything else.</p><p>That these benefits (to animals) do not apply to humans isn\u2019t especially clarifying. Many researchers are quite keen on not leaving out <i>particular </i>humans. They go out of their way to ensure that particular groups of humans are included. And this isn\u2019t merely a social justice-y reflex that demands that the experiences of some repressed minority population be represented; it\u2019s <i>also </i>a sense of respect for how knowledge should be built. That one\u2019s sample for a study making overly grandiose claims about universal human psychology is actually just an unrepresentative gaggle of undergraduates is an academic failing. Given the right prompting, there is no reason why academics shouldn\u2019t be equally ashamed at failing to include animals.</p><h3>Institutional Inertia</h3><p>One major reason animals aren\u2019t included may be institutional inertia. Being the first to advance anything new is difficult, it is always much easier to just make a new iteration on proven grounds. This is compounded by the fact that researchers are expected to review and cite the relevant literature. If there is no existing scientific literature, then there\u2019s a bit of a chicken and egg problem.</p><p>It isn\u2019t the case though that there is <i>no</i> relevant literature. The new field of <a href=\"https://www.animal-ethics.org/introduction-to-welfare-biology/\">welfare biology</a> is bringing scientific insights into animal welfare. Groups like Faunalytics, Animal Charity Evaluators and the Wild Animal Institute help grow the research field. And there is some <a href=\"https://blogs.worldbank.org/impactevaluations/it-time-development-economists-start-considering-welfare-non-human-animals?s=09&amp;utm_source=pocket_saves\">work in economics</a>.</p><p>This is a great sign that a firm foundation is growing that animal-inclusive scholarship can be built off of. But we still have the issue that research across the full range of scientific fields and public policy research does not recognize \u201canimal welfare\u201d as anything but the demands of particular interest groups - ones that may commission studies perhaps, but that\u2019s it.</p><h3>Values in Science</h3><p>The second hold up is the prevalent attitude toward values in science. Make no mistake - respecting the is-ought gap is important. Scientists generally understand that addressing values is not part of their job description. This is an essential bulwark against ideology and advocacy. More fundamentally, it is a recognition that investigations into values are not doable with empirical methods.<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"3\" data-footnote-id=\"ihpgxbfell\" role=\"doc-noteref\" id=\"fnrefihpgxbfell\"><sup><a href=\"#fnihpgxbfell\">[3]</a></sup></span></p><p>But this virtue of good science can go awry. Sometimes it is corrupted into a form of <a href=\"https://plato.stanford.edu/entries/moral-cognitivism/#Emo\">Emotivism</a>, the position that claiming something is wrong or right is equivalent to saying Yay!! or Boo!! This is best exemplified by social psychologist Jonathan Haidt, who while being the proponent of a quite fascinating theory of moral psychology he calls \u201c<a href=\"https://moralfoundations.org/\">Moral Foundations Theory</a>\u201d, also seems to think that positions in moral philosophy are <i>just </i>reflections of psychology.</p><p>While I think Haidt is (partly) wrong here, I\u2019ll leave that discussion for another time. Suffice it to say, the notion that morality too is within the bounds of science is compelling to some; <a href=\"https://www.nature.com/articles/d41586-021-02896-7\">scientists trust science - not the humanities</a>.<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"4\" data-footnote-id=\"r0wwtlj5qgk\" role=\"doc-noteref\" id=\"fnrefr0wwtlj5qgk\"><sup><a href=\"#fnr0wwtlj5qgk\">[4]</a></sup></span>&nbsp;However, I don\u2019t think the issue scientists have with values is usually as explicit as with Haidt. More often, it is represented as a disengagement with values. We can make an analogy to a company disengaged with its customers. It may function fine, according to the notion held by it\u2019s <i>employees </i>of how a well-functioning company operates, but the proper criterion is what the customer thinks.</p><p>Likewise, while it wouldn\u2019t be proper for scientists to adjudicate about value questions themselves, they need to be able to communicate with ethicists in a constructive manner. This is required if we are to get to a point where animals are routinely included.</p><h3>What Can Be Done?</h3><p>I suspect that actually achieving what I have argued for isn\u2019t drastically unrealistic. It doesn\u2019t require a few big changes that must be made, but many small easy ones.&nbsp;</p><p>What holds back the experts isn\u2019t the same degree of personal interest that holds people back from going vegan. Mentioning that eating less meat = less animal suffering in your research isn\u2019t quite the same as summoning the strength of will and moral fortitude to not eat a cheeseburger. And keeping the facts as abstractions in MLA formatting, rather than as the implicit acknowledgment of personal incrimination that accepting the demand to \u201cgo vegan!\u201d implies, also helps.</p><p>Getting there requires overcoming institutional inertia and misplaced notions of value. While I focused on scientists here, properly speaking it requires work from philosophers too. It is already the case that they generally agree that not eating factory farmed meat is morally better, as the 559 signatories to the <a href=\"https://greea.ca/en/nouvelles/montreal-declaration-on-animal-exploitation/\">Montreal Declaration on Animal Exploitation</a> indicates. At the same time, it is abhorrent how few philosophers actually endeavor to do so - <a href=\"http://www.faculty.ucr.edu/~eschwitz/SchwitzPapers/BehEth-140123a.htm\">research has shown</a> that moral philosophers have only statistically marginal differences in their meat eating than academics in other disciplines.</p><p>Getting there requires that people who don\u2019t particularly care about the animal rights movement nevertheless act in its interests. While I\u2019m not overly enthused with the track record of open letters, I think there is something to be said for the idea when there is a particular mix of collective action challenges and unacknowledged consensus, as I think there is with this issue.</p><p>But for it to be done properly isn\u2019t a simple thing. There would have to be input from respected philosophers. Individual scientists representing a wide variety of fields would have to be on board. But there would also have to be pressure on editors of respected journals, on the National Science Foundation and on <a href=\"https://new.nsf.gov/funding/merit-review#our-merit-review-criteria-f24\">the individual reviewers and program officers who evaluate research proposals</a>.</p><p>A open letter approach, perhaps combined with an advocacy campaign, may be able to get us to a point where including the interests of animals can seem permissible, letting some of the more bold researchers who are sympathetic to the idea to do so - if they are challenged on relevancy by the reviewers, this at least sheds light on the issue.<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"5\" data-footnote-id=\"tcut0bfccjj\" role=\"doc-noteref\" id=\"fnreftcut0bfccjj\"><sup><a href=\"#fntcut0bfccjj\">[5]</a></sup></span>&nbsp;And in time, including animals may become not only acceptable, but expected.</p><ol class=\"footnote-section footnotes\" data-footnote-section=\"\" role=\"doc-endnotes\"><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"1\" data-footnote-id=\"e5smjgu1xnp\" role=\"doc-endnote\" id=\"fne5smjgu1xnp\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"e5smjgu1xnp\"><sup><strong><a href=\"#fnrefe5smjgu1xnp\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>One easily missable benefit of this is that it allows a \u201cscientists say\u201d dynamic in policy advocacy. This is especially important given the extensive capture of \u201cscientists say\u201d by industry interests.</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"2\" data-footnote-id=\"70umjmtpg3x\" role=\"doc-endnote\" id=\"fn70umjmtpg3x\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"70umjmtpg3x\"><sup><strong><a href=\"#fnref70umjmtpg3x\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>Willing to bet that if prompted, most individuals would be in favor of broadly including animal interests in the ways I\u2019m arguing for, just as most or many report in surveys not liking factory farms, being in favor of welfare reforms, reducing their meat consumption and so on. Especially the case for well-educated and environmental/social justice conscious academics.</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"3\" data-footnote-id=\"ihpgxbfell\" role=\"doc-endnote\" id=\"fnihpgxbfell\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"ihpgxbfell\"><sup><strong><a href=\"#fnrefihpgxbfell\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>I\u2019ll submit these claims as approximately true for our purposes here.</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"4\" data-footnote-id=\"r0wwtlj5qgk\" role=\"doc-endnote\" id=\"fnr0wwtlj5qgk\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"r0wwtlj5qgk\"><sup><strong><a href=\"#fnrefr0wwtlj5qgk\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>Insofar as there is an ideology particular to scientists, it is that empirical claims have a privileged epistemic status. There\u2019s <a href=\"https://plato.stanford.edu/entries/logical-empiricism/\">philosophical nuances</a> to this that I do not have the expertise for.</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"5\" data-footnote-id=\"tcut0bfccjj\" role=\"doc-endnote\" id=\"fntcut0bfccjj\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"tcut0bfccjj\"><sup><strong><a href=\"#fnreftcut0bfccjj\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>I imagine counter-challenging with a link to the Montreal Declaration and other relevant literature showing consensus on these matters. (Actual academics, please tell me how realistic an ask this is!)</p></div></li></ol>", "user": {"username": "Dylan Richardson"}}, {"_id": "RKEDaSeG9jDTiKEaY", "title": "Ways in which I\u2019m not living up to my EA values", "postedAt": "2024-03-17T21:30:12.959Z", "htmlBody": "<figure class=\"table\" style=\"height:50px;width:682px\"><table style=\"border:1px double rgb(151, 201, 177)\"><tbody><tr><td style=\"background-color:rgb(221, 238, 232);border:0.681818pt solid rgb(151, 201, 177);padding:5pt;vertical-align:top\"><strong>This is a&nbsp;</strong><a href=\"https://forum.effectivealtruism.org/topics/draft-amnesty-week-2024\"><strong><u>Draft Amnesty Week</u></strong></a><strong> draft.&nbsp;</strong>It may not be polished, up to my usual standards, fully thought through, or fully fact-checked.&nbsp;</td></tr></tbody></table></figure><p>&nbsp;</p><p>When I was pretty new to EA, I was way too optimistic about how Wise and Optimized and Ethical and All-Knowing experienced EAs would be.&nbsp;</p><ul><li>I thought Open Phil would have some magic spreadsheets with the answers to all questions in the universe</li><li>I thought that, surely, experienced EAs had for 99% figured out what they thought was the biggest problem in the world</li><li>I imagined all EAs to have optimized almost everything, and to basically endorse all their decisions: their giving practices, their work-life balance, the way they talked about EA to others, etc.</li></ul><p>&nbsp;</p><p>I\u2019ve now been around the community for a few years. I\u2019m still really grateful for and excited about EA ideas, and I love being around the people inspired by EA ideas (I even&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/PatjzJHQev2upDHnr/what-has-the-cea-uni-groups-team-been-up-to-our-summer-2023\"><u>work</u></a> on growing our community!). However, I now also realize that today, I am far from how Wise and Optimized and Ethical and All-Knowing Joris-from-4-years-ago expected future Joris and his peers to be.&nbsp;</p><p>&nbsp;</p><p>There\u2019s two things that caused me to not live up to those ideals:</p><ol><li>I was naive about how Wise and Optimized and Ethical and All-Knowing someone could realistically be</li><li>There\u2019s good things I could reasonably do or should have reasonably done in the past 4 years</li></ol><p>&nbsp;</p><p>To make this concrete, I wanted to share some ways in which I think I\u2019m not living up to my EA values or expectations from a few years ago. I think Joris-from-4-years-ago would\u2019ve found this list helpful.<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"1\" data-footnote-id=\"6brq13zk5gm\" role=\"doc-noteref\" id=\"fnref6brq13zk5gm\"><sup><a href=\"#fn6brq13zk5gm\">[1]</a></sup></span></p><ul><li>I\u2019m still not fully vegan</li><li>Donating:<ul><li>I just default to the community norm of donating 10%, without having thought about it hard&nbsp;</li><li>I haven't engaged for more than 30 minutes with arguments around e.g. patient philanthropy</li><li>I left my GWWC donations to&nbsp;<i>literally</i> the last day of the year and didn\u2019t spend more than one hour on deciding where to donate</li></ul></li><li>I have a lot less certainty over the actual positive impact of the programs we run than I expected when I started this job<ul><li>I\u2019m still as bad at math as I was in uni, meaning my botecs are just not that great</li><li>It\u2019s so, so much harder than I expected to account for counterfactuals and to find things you can measure that are robustly good</li></ul></li><li>I still find it really hard to pitch EA</li></ul><p>&nbsp;</p><p>I hope this inspires some people (especially those who I (and others) might look up to) to share how they\u2019re not perfect. What are some ways in which you\u2019re not living up to your values, or to what you-from-the-past maybe expected you would be doing by now?</p><ol class=\"footnote-section footnotes\" data-footnote-section=\"\" role=\"doc-endnotes\"><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"1\" data-footnote-id=\"6brq13zk5gm\" role=\"doc-endnote\" id=\"fn6brq13zk5gm\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"6brq13zk5gm\"><sup><strong><a href=\"#fnref6brq13zk5gm\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>I\u2019ll leave it up to you whether these fall in category 1 (basically unattainable) or 2 (attainable). I also do not intend to turn this into a discussion of what things EAs \u201cshould\u201d do, which things are actually robustly good, etc.</p></div></li></ol>", "user": {"username": "Joris P"}}, {"_id": "F5w2eu5omovKP82cB", "title": "Personal fit is different from the thing that you already like", "postedAt": "2024-03-17T20:56:40.567Z", "htmlBody": "<figure class=\"table\" style=\"height:80.797px;width:626.984px\"><table style=\"border:1px double rgb(151, 201, 177)\"><tbody><tr><td style=\"background-color:rgb(221, 238, 232);border:0.681818pt solid rgb(151, 201, 177);padding:5pt;vertical-align:top\"><strong>This is a&nbsp;</strong><a href=\"https://forum.effectivealtruism.org/topics/draft-amnesty-week-2024\"><strong><u>Draft Amnesty Week</u></strong></a><strong> draft.&nbsp;</strong>It may not be polished, up to my usual standards, fully thought through, or fully fact-checked.&nbsp;</td></tr><tr><td style=\"background-color:rgb(238, 248, 244);border:0.681818pt solid rgb(0, 0, 0);padding:4.98898pt;vertical-align:top\">This draft lacks the polish of a full post, but the content is almost there. The kind of constructive feedback you would normally put on a Forum post is very welcome.&nbsp;</td></tr></tbody></table></figure><p>&nbsp;</p><p><i>I wrote most of this last year. I also think I\u2019m making a pretty basic point and don\u2019t think I\u2019m articulating it amazingly, but I\u2019m trying to write more and can imagine people (especially newer to EA) finding this useful - so here we go</i></p><p>&nbsp;</p><p>Last week<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"1\" data-footnote-id=\"v7b2o9m7f7q\" role=\"doc-noteref\" id=\"fnrefv7b2o9m7f7q\"><sup><a href=\"#fnv7b2o9m7f7q\">[1]</a></sup></span>&nbsp;I was at an event with a lot of people relatively new to EA - lots of them had recently finished the introductory fellowship. Talking through their plans for the future, I noticed that many of them used the concept \u2018personal fit\u2019 to justify their plans to work on a problem they had already found important before learning about EA.&nbsp;</p><p>&nbsp;</p><p>They would say they wanted to work on combating climate change or increasing gender equality, because&nbsp;</p><ol><li>They had studied this and felt really motivated to work on it&nbsp;</li><li>Therefore, their \u2018personal fit\u2019 was really good for working on this topic</li><li>Therefore surely, it was the highest impact thing they could be doing.</li></ol><p>&nbsp;</p><p>I think a lot of them were likely mistaken, in one or more of the following ways:</p><ul><li>They overestimated their personal fit for roles in these (broad!) fields</li><li>They underestimated the differences in impact between career options and cause areas</li><li>They thought that they were motivated to do the most good they could, but in fact they were motivated by a specific cause<br>&nbsp;</li></ul><p>To be clear: the ideal standard here is probably unattainable, and I surely don\u2019t live up to it. However, if I could stress one thing, it would be that people scoping out their career options could benefit from&nbsp;<i>first</i> identifying high-impact career options, and only&nbsp;<i>second</i> thinking about which ones they might have a great personal fit for - not the other way around.</p><ol class=\"footnote-section footnotes\" data-footnote-section=\"\" role=\"doc-endnotes\"><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"1\" data-footnote-id=\"v7b2o9m7f7q\" role=\"doc-endnote\" id=\"fnv7b2o9m7f7q\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"v7b2o9m7f7q\"><sup><strong><a href=\"#fnrefv7b2o9m7f7q\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>This was last year</p></div></li></ol>", "user": {"username": "Joris P"}}, {"_id": "vhKZ7hyzmcrWuBwDL", "title": "The Scale of Fetal Suffering in Late-Term Abortions", "postedAt": "2024-03-17T19:46:56.293Z", "htmlBody": "<p>This is a draft amnesty post.</p><h1 data-internal-id=\"Summary\">Summary</h1><ul><li>It seems plausible that fetuses can suffer from 12 weeks of age, and quite reasonable that they can suffer from 24 weeks of age.</li><li><strong>Some late-term abortion procedures seem that they might cause a fetus excruciating suffering</strong>.</li><li>Over 35,000 of these procedures occur each year in the US alone.</li><li>Further research would be desired on interventions to reduce this suffering, such as <strong>mandating fetal anesthesia for late-term abortions</strong>.</li></ul><h1 data-internal-id=\"Background\">Background</h1><p data-internal-id=\"ftnt_ref1\">Most people agree that a fetus has the capacity to suffer at some point. <strong>If a fetus has the capacity to suffer, then we ought to reduce that suffering when possible.</strong>&nbsp;Fetal anesthesia is standard practice for fetal surgery,<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"1\" data-footnote-id=\"ale12hg4a4q\" role=\"doc-noteref\" id=\"fnrefale12hg4a4q\"><sup><a href=\"#fnale12hg4a4q\">[1]</a></sup></span>&nbsp;but I am unaware of it ever being used during late-term abortions. If the fetus can suffer, these procedures likely cause the fetus extreme pain.</p><p>I think the cultural environment EAs usually live in tends to minimize concern for fetal suffering. Some worry that promoting care for fetal welfare will play into the hands of abortion opposers. However, as Brian Tomasik has <a href=\"https://www.reddit.com/r/EffectiveAltruism/comments/8wjhul/comment/e1wyiog/?utm_source=share&amp;utm_medium=mweb3x&amp;utm_name=mweb3xcss&amp;utm_term=1&amp;utm_content=share_button\">pointed out</a>, <strong>one can certainly support abortion as an option while recognizing the potential for fetal consciousness during late-term abortion procedures</strong>.</p><h1 data-internal-id=\"Surgical_Abortion_Procedures\">Surgical Abortion Procedures</h1><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/vhKZ7hyzmcrWuBwDL/iwdtwefs2cv7duir2ahy\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/vhKZ7hyzmcrWuBwDL/xgizrx1lv7unzxdaagfp 80w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/vhKZ7hyzmcrWuBwDL/byox1xgbp7vwwk9rrogv 160w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/vhKZ7hyzmcrWuBwDL/rhiuzes8sqtuuoyryhps 240w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/vhKZ7hyzmcrWuBwDL/f3h7nbzya9m1wiczaaiq 320w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/vhKZ7hyzmcrWuBwDL/e6w4otljkb0ysayrv313 400w\"></figure><h2 data-internal-id=\"LI__Labor_Induction__2_\">LI (Labor Induction)<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"2\" data-footnote-id=\"gej1g4x6046\" role=\"doc-noteref\" id=\"fnrefgej1g4x6046\"><sup><a href=\"#fngej1g4x6046\">[2]</a></sup></span></h2><ul><li>Gestational age: 20+ weeks.</li><li data-internal-id=\"ftnt_ref4\">Method: The fetus is administered a <strong>lethal injection with no anesthesia</strong>, often of potassium chloride,&nbsp;which causes cardiac arrest and death within a minute. The Human Rights Watch calls the use of potassium chloride for the death penalty without anesthesia <strong>\"excruciatingly painful\"</strong>&nbsp;because it <strong>\"inflames the potassium ions in the sensory nerve fibers, literally burning up the veins as it travels to the heart.\"</strong><span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"3\" data-footnote-id=\"r4lk4dkoikm\" role=\"doc-noteref\" id=\"fnrefr4lk4dkoikm\"><sup><a href=\"#fnr4lk4dkoikm\">[3]</a></sup></span>&nbsp;(Disclaimer: This describes an intravenous injection, whereas intra-amniotic or intra-fetal injections are more common in the case of abortion.) The American Veterinary Medical Association considers the use of potassium chloride without anesthesia \"unacceptable\" when euthanizing vertebrate animals.<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"4\" data-footnote-id=\"wmle0cl4zdl\" role=\"doc-noteref\" id=\"fnrefwmle0cl4zdl\"><sup><a href=\"#fnwmle0cl4zdl\">[4]</a></sup></span></li></ul><h2 data-internal-id=\"D_E__Dilation_and_Evacuation__5_\">D&amp;E (Dilation and Evacuation)<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"5\" data-footnote-id=\"kyxqglxtiuf\" role=\"doc-noteref\" id=\"fnrefkyxqglxtiuf\"><sup><a href=\"#fnkyxqglxtiuf\">[5]</a></sup></span></h2><ul><li>Gestational age: 13-24 weeks.</li><li>Method: <strong>The fetus's limbs are torn off before the fetus's head is crushed</strong>. The procedure takes several minutes.</li></ul><h1 data-internal-id=\"When_Can_a_Fetus_Suffer_\">When Can a Fetus Suffer?</h1><p data-internal-id=\"ftnt_ref9\">The traditional view of fetal sentience has been that \"the cortex and intact thalamocortical tracts,\" which develop after 24 weeks, \"are necessary for pain experience.\"<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"6\" data-footnote-id=\"84pzj7jid87\" role=\"doc-noteref\" id=\"fnref84pzj7jid87\"><sup><a href=\"#fn84pzj7jid87\">[6]</a></sup></span>&nbsp;However, mounting evidence of suffering from adults with disabled cortices and <a href=\"https://forum.effectivealtruism.org/posts/Qk3hd6PrFManj8K6o/rethink-priorities-welfare-range-estimates\">animals without cortices</a>&nbsp;has cast doubt on the traditional view.<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"7\" data-footnote-id=\"q4wjd1kadjj\" role=\"doc-noteref\" id=\"fnrefq4wjd1kadjj\"><sup><a href=\"#fnq4wjd1kadjj\">[7]</a></sup></span>&nbsp;\"Overall, the evidence, and a balanced reading of that evidence, points towards an immediate and unreflective pain experience mediated by the developing function of the nervous system from as early as 12 weeks.\"<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"8\" data-footnote-id=\"b6qm22j34me\" role=\"doc-noteref\" id=\"fnrefb6qm22j34me\"><sup><a href=\"#fnb6qm22j34me\">[8]</a></sup></span>&nbsp;12 weeks is when the first projections are made into the fetus's cortical subplate,<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"9\" data-footnote-id=\"94td9zhuvf\" role=\"doc-noteref\" id=\"fnref94td9zhuvf\"><sup><a href=\"#fn94td9zhuvf\">[9]</a></sup></span>&nbsp;which will eventually grow into the cortex.</p><p>I am a layperson who doesn\u2019t have the expertise to evaluate these studies. However, <strong>I don't see a good reason to have substantially less concern for 24+ week fetuses than for infants</strong>. Though the arguments for 12-24 week fetuses are weaker, it still seems plausible that they have some capacity to suffer. Given the potential scale of fetal suffering due to late-term abortions, it seems that this evidence is worth seriously examining.</p><h1 data-internal-id=\"Scale_in_US_and_UK\">Scale in US and UK</h1><h2 data-internal-id=\"2021_UK_10_\">2021 UK<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"10\" data-footnote-id=\"8mha944la5r\" role=\"doc-noteref\" id=\"fnref8mha944la5r\"><sup><a href=\"#fn8mha944la5r\">[10]</a></sup></span></h2><p>The following is a selection from the UK abortion data tables:</p><figure class=\"table\"><table><thead><tr><th style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><strong>7a: Weeks from Gestation</strong></th><th style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><strong>13 to 14</strong></th><th style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><strong>15 to 19</strong></th><th style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><strong>20+</strong></th></tr></thead><tbody><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Total Abortions</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">&nbsp;5,322</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">&nbsp;5,528</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">&nbsp;2,686</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">D&amp;E (%)</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">25%</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">74%</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">44%</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">LI with surgical evacuation (%)</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">0%</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">1%</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">18%</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">LI with medical evacuation (%)</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">0%</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">0%</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">20%</td></tr></tbody></table></figure><p>Assuming the given percentages are exact, this gives us:</p><figure class=\"table\"><table><tbody><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><strong>Abortion Procedure</strong></td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><strong>Abortions per Year (UK)</strong></td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">D&amp;E</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">6,603</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">LI</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">1,076</td></tr></tbody></table></figure><h2 data-internal-id=\"2020_USA_11_\">2020 USA<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"11\" data-footnote-id=\"ga7qaq76e7h\" role=\"doc-noteref\" id=\"fnrefga7qaq76e7h\"><sup><a href=\"#fnga7qaq76e7h\">[11]</a></sup></span></h2><ul><li>36,531 surgical abortions at &gt;13 weeks and 4,382 abortions at \u226521 weeks were reported.</li><li>In 2021 UK, 38% of the \u226520 week surgical abortions were LI, which we can assume as a prior on what percentage of \u226521 week surgical abortions in 2020 USA were LI.</li><li>My understanding is that USA <i>surgical</i>&nbsp;abortions at &gt;13 weeks which aren't LI are always D&amp;E.</li><li>These observations give us the following table:</li></ul><figure class=\"table\"><table><tbody><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><strong>Procedure</strong></td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><strong>Abortions per Year (US)</strong></td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">D&amp;E</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">34,866</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">LI</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">1,665</td></tr></tbody></table></figure><p>As this is a draft post, I have not estimated how many of these procedures occur each year worldwide. However, given the US and UK numbers, I would guess the amount is in the hundreds of thousands.</p><h1 data-internal-id=\"Interventions\">Interventions</h1><p>At least one paper affirmatively <a href=\"https://jme.bmj.com/content/46/1/3\">recommends fetal anesthesia</a>&nbsp;from 12 weeks: \"Fetal analgesia and anaesthesia should thus be standard for abortions in the second trimester, especially after 18 weeks when there is good evidence for a functional connection from the periphery and into the brain.\" <strong>Further research would be desired to see whether advocacy for fetal anesthesia is cost-effective enough to be competitive with leading global health interventions</strong>.</p><ol class=\"footnote-section footnotes\" data-footnote-section=\"\" role=\"doc-endnotes\"><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"1\" data-footnote-id=\"ale12hg4a4q\" role=\"doc-endnote\" id=\"fnale12hg4a4q\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"ale12hg4a4q\"><sup><strong><a href=\"#fnrefale12hg4a4q\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;Saxena, Kirti N. \u201cAnaesthesia for Fetal Surgeries.\u201d Indian Journal of Anaesthesia, vol. 53, no. 5, 2009, pp. 554\u20139, <a href=\"http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2900087/\">www.ncbi.nlm.nih.gov/pmc/articles/PMC2900087/</a></p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"2\" data-footnote-id=\"gej1g4x6046\" role=\"doc-endnote\" id=\"fngej1g4x6046\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"gej1g4x6046\"><sup><strong><a href=\"#fnrefgej1g4x6046\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\u201cSecond Trimester Labor Induction Abortion.\u201d Michigan Health and Human Services, <a href=\"http://www.michigan.gov/mdhhs/adult-child-serv/informedconsent/michigans-informed-consent-for-abortion-law/procedures/second-trimester-labor-induction-abortion\">www.michigan.gov/mdhhs/adult-child-serv/informedconsent/michigans-informed-consent-for-abortion-law/procedures/second-trimester-labor-induction-abortion</a></p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"3\" data-footnote-id=\"r4lk4dkoikm\" role=\"doc-endnote\" id=\"fnr4lk4dkoikm\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"r4lk4dkoikm\"><sup><strong><a href=\"#fnrefr4lk4dkoikm\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\u201cSo Long as They Die: Lethal Injections in the United States: II. Lethal Injection Drugs.\u201d Human Rights Watch, <a href=\"http://www.hrw.org/reports/2006/us0406/4.htm\">www.hrw.org/reports/2006/us0406/4.htm</a></p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"4\" data-footnote-id=\"wmle0cl4zdl\" role=\"doc-endnote\" id=\"fnwmle0cl4zdl\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"wmle0cl4zdl\"><sup><strong><a href=\"#fnrefwmle0cl4zdl\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;Leary, Steven, and Johnson, Cia. AVMA Guidelines for the Euthanasia of Animals: 2020 Edition. Members of the Panel on Euthanasia AVMA Staff Consultants. 2020.</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"5\" data-footnote-id=\"kyxqglxtiuf\" role=\"doc-endnote\" id=\"fnkyxqglxtiuf\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"kyxqglxtiuf\"><sup><strong><a href=\"#fnrefkyxqglxtiuf\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\u201cDilation and Evacuation (D&amp;E).\u201d Michigan Health and Human Services, <a href=\"http://www.michigan.gov/mdhhs/adult-child-serv/informedconsent/michigans-informed-consent-for-abortion-law/procedures/dilation-and-evacuation-de\">www.michigan.gov/mdhhs/adult-child-serv/informedconsent/michigans-informed-consent-for-abortion-law/procedures/dilation-and-evacuation-de</a></p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"6\" data-footnote-id=\"84pzj7jid87\" role=\"doc-endnote\" id=\"fn84pzj7jid87\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"84pzj7jid87\"><sup><strong><a href=\"#fnref84pzj7jid87\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;Derbyshire, S. W., &amp; Bockmann, J. C. (2020). \"Reconsidering fetal pain.\" Journal of Medical Ethics, 46(1), 3\u20136. <a href=\"https://doi.org/10.1136/medethics-2019-105701\">https://doi.org/10.1136/medethics-2019-105701</a></p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"7\" data-footnote-id=\"q4wjd1kadjj\" role=\"doc-endnote\" id=\"fnq4wjd1kadjj\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"q4wjd1kadjj\"><sup><strong><a href=\"#fnrefq4wjd1kadjj\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;Ibid.</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"8\" data-footnote-id=\"b6qm22j34me\" role=\"doc-endnote\" id=\"fnb6qm22j34me\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"b6qm22j34me\"><sup><strong><a href=\"#fnrefb6qm22j34me\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;Ibid.</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"9\" data-footnote-id=\"94td9zhuvf\" role=\"doc-endnote\" id=\"fn94td9zhuvf\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"94td9zhuvf\"><sup><strong><a href=\"#fnref94td9zhuvf\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>Kostovi\u0107 I, Juda\u0161 M. The development of the subplate and thalamocortical connections in the human foetal brain. Acta Paediatr 2010;99(8):1119\u201327. <a href=\"https://doi.org/10.1111/j.1651-2227.2010.01811.x\">https://doi.org/10.1111/j.1651-2227.2010.01811.x</a></p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"10\" data-footnote-id=\"8mha944la5r\" role=\"doc-endnote\" id=\"fn8mha944la5r\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"8mha944la5r\"><sup><strong><a href=\"#fnref8mha944la5r\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;Abortion statistics for England and Wales: 2021 Data Tables. <a href=\"https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/1125274/Abortion_Statistics_2021_data_tables_revision.ods\">https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/1125274/Abortion_Statistics_2021_data_tables_revision.ods</a></p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"11\" data-footnote-id=\"ga7qaq76e7h\" role=\"doc-endnote\" id=\"fnga7qaq76e7h\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"ga7qaq76e7h\"><sup><strong><a href=\"#fnrefga7qaq76e7h\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;Kortsmit K, Nguyen AT, Mandel MG, et al. Abortion Surveillance \u2014 United States, 2020. MMWR Surveill Summ 2022;71(No. SS-10):1\u201327. DOI: <a href=\"http://dx.doi.org/10.15585/mmwr.ss7110a1\">http://dx.doi.org/10.15585/mmwr.ss7110a1</a></p></div></li></ol>", "user": {"username": "Ariel Simnegar"}}, {"_id": "Cn8GZETFsNJZE6Pvh", "title": "Which countries should be prioritised in preventing the intensification of factory farming in Sub Saharan Africa?", "postedAt": "2024-03-17T17:52:20.068Z", "htmlBody": "<p>This post presents a new tool for deciding which countries to prioritise in preventing or limiting the growth of industrial animal agriculture in countries in Sub Saharan Africa.</p><h2>Introduction</h2><p>The&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1fPIDczUiVl42LCnXZKi8a_RS4mAneDHb7IzhfOAcY-A/edit?usp=sharing\"><u>Prevention of Intensification of Factory Farming (PIFF) country scoring model</u></a> (Sub Saharan Africa) is a geographical weighted factor model used to assess countries for their promisingness as targets for interventions to prevent or limit the extent of the intensification of factory farming in Sub Saharan Africa.&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1r09pJQ2gvRjniEyP0pZzioEU1NYFw3PKGbn33aBGZlo/edit?usp=sharing\"><u>A previous version of this model</u></a> has been developed by Moritz Stumpe for&nbsp;<a href=\"https://animalcharityevaluators.org/blog/announcing-our-2023-movement-grants/#bryant-research\"><u>Animal Advocacy Africa's research project with Bryant Research</u></a>, and was further developed by Aashish Khimasia during the Charity Entrepreneurship Research Training Program.&nbsp;</p><h2>Model Usage</h2><p>This model can serve as the basis for various geographic assessments. Whilst the model in its current state serves as a tool to assess appropriateness for a general intervention, it can be modified for specific purposes by weighting each category and its constituent criteria as is desired, and factors may be added or removed from the model. The model can also be applied to other geographic areas, by pulling the respective data from the listed sources and plugging it into the same or a similar structure.</p><p>The model in its current form calculates scores for each of the following categories: scale, projected intensification, current intensification, tractability, and movement support, and combines these into a weighted sum to give an overall score. Weighted multiplication is another calculation method that is used to provide an additional perspective. Further details on each category, its constituent criteria, and their weights can be found in the <a href=\"https://docs.google.com/spreadsheets/d/1fPIDczUiVl42LCnXZKi8a_RS4mAneDHb7IzhfOAcY-A/edit#gid=1725381488\">\u201cSummary Sheet\u201d</a> of the model.</p><h2>A shared tool for the movement</h2><p>We encourage advocates to edit and extend this tool, and share further iterations, particularly if adapting it for considering particular intervention strategies, as this may provide a useful resource for the community.</p><p><br><br>&nbsp;</p>", "user": {"username": "Aashish Khimasia"}}, {"_id": "c22ReEuMDcoTnqoa4", "title": "There and back again: reflections from leaving EA (and returning)", "postedAt": "2024-03-17T22:59:34.925Z", "htmlBody": "<figure class=\"table\"><table style=\"border-color:#97C9B1;border-style:double\"><tbody><tr><td style=\"background-color:#DDEEE8;border:0.68181825pt solid #97C9B1;padding:5pt;vertical-align:top\"><strong>This is a&nbsp;</strong><a href=\"https://forum.effectivealtruism.org/topics/draft-amnesty-week-2024\"><strong><u>Draft Amnesty Week</u></strong></a><strong> draft.&nbsp;</strong>It may not be polished, up to my usual standards, fully thought through, or fully fact-checked.&nbsp;</td></tr><tr><td style=\"background-color:#EEF8F4;border:0.68181825pt solid #97C9B1;padding:4.988976377952756pt;vertical-align:top\"><p><strong>Commenting and feedback guidelines:&nbsp;</strong></p><p>This is a Forum post that I wouldn't have posted without the nudge of Draft Amnesty Week, and is indeed my first ever forum post. Fire away! (But be nice, as usual)</p></td></tr></tbody></table></figure><p>In Autumn 2016, as a first year undergraduate, I discovered Effective Altruism. Although I don\u2019t remember my inaugural meeting with EA, it must have had a big impact on me, because in a few short months I was all in. At the time, I was a physics student who had grown up with a deep - but not yet concrete - motivation to \u201cmake the world a better place\u201d. I had not yet formed any solid career ambitions, as I was barely aware of the kinds of careers that even <i>existed</i>&nbsp;for mathsy people like me - let alone any that would make me feel morally fulfilled. When I encountered EA, it felt like everything was finally slotting together. My nineteen year old brain was buzzing with the possibilities ahead.</p><p>But by the following summer, barely a single fraying thread held me to EA. I had severed myself from EA and its community.</p><p>Several years on, I have somehow found myself even more involved in EA than I was before (and, once again, I\u2019m not fully sure how this happened). Now, I work in an EA job, engage with EA content, and even have EA friends (!). I genuinely believe that<strong>&nbsp;if I had not left EA when I did, then I wouldn\u2019t be able to describe my current relationship with EA in the two ways I do now: sustainable and healthy.</strong>&nbsp;Reflecting back on this transition, I have three key takeaways, specifically aimed at EA-aligned grads who are making their entry into the workforce.</p><p>Disclaimers:</p><ul><li>These reflections probably do not apply in all cases. Most likely, there is variation in applicability by cause area, type of work, person, organisation, etc. This post is from my own perspective. For context, I work in operations.</li><li>None of my commentary below is intended as a criticism of any specific org or institution. I simply hope to open people\u2019s minds to paths which go against what is seen as the default route to impact for many EAs coming out of university.</li></ul><h1 data-internal-id=\"_1__Skill_building____impressiveness_factor\">(1)&nbsp;Skill building &gt;&gt;&nbsp;impressiveness factor</h1><h2 data-internal-id=\"My_reservations_with_elite_private_institutions\">My reservations with elite private institutions</h2><p>I often hear career advice in the EA space along the lines of:</p><p>\u201cAim for the most impressive thing that you can get on your CV as quickly as possible, and by impressive we mean something like working somewhere elite in the private sector.\u201d</p><p>I disagree with this advice on two levels:</p><h3 data-internal-id=\"1__Effort_pay_off__\">1. Effort pay-off??</h3><p>Emphasising the impressiveness-factor of a career move shifts focus away from what actually <i>should</i>&nbsp;be the priority: the skills gained.</p><p>During my time away from EA, I saw many of my non-EA peers seek extremely prestigious roles at elite institutions - think Google, Goldman Sachs, PwC, and so on. Something that really struck me was how competitive, high-effort, time-consuming, and stressful the hiring rounds for these jobs were. And if they were lucky enough to beat the huge amounts of competition and get the job, yeah it would look great on their LinkedIn - but the tradeoff was often working long hours in a pressure-cooker environment, in a role that sometimes involved a high proportion of donkey work.</p><p>The bias towards prestigious-sounding jobs is widespread across society, so it is no surprise that this has also proliferated EA. Among EAs, I suppose, the allure of such jobs is based on the assumption that the more prestigious an establishment, the better they will train you due to having greater resources.</p><p>But think about it this way: given how much time, effort and (as you are probabilistically likely to get rejected) heartbreak goes into securing one of these elite jobs, there\u2019s a high bar to guarantee the effort pay-off is worth it. If your prestigious job also has long hours and stressful conditions to boot, then the effort better<i>&nbsp;really</i>&nbsp;be worth it.</p><p>My argument here isn\u2019t that working in prestigious institutions will prevent you from developing a good skill set. But there are fantastic opportunities to complete exciting or challenging projects (and thus gain a great set of skills early on in your career) at orgs or companies that most people wouldn\u2019t have heard of. In a small, less established org, it may even be easier to quickly build skills and have a substantial impact on the org because so much low-hanging fruit is still up for grabs. This might look like: winning over a new major client, coding a new game-changing feature for the org\u2019s website, suggesting and then helping to implement new ways of working to improve efficiency, helping the org to expand its activities or grow its team, etc. etc.</p><p>So, if you find yourself laser-focused on a role in an elite establishment, I would urge you to list the things that draw you towards this particular job. Are there particular skills you could only develop there, or specific resources you wouldn\u2019t otherwise have access to? Do you believe they offer unique career development opportunities? Or, after honest reflection, are you mostly excited by the prospect of having the word \u2018McKinsey\u2019 on your CV?</p><h3 data-internal-id=\"2__I_bargain_with_the_reader\">2. I bargain with the reader</h3><p>Ok, suppose you read the above and still hold the belief that working for your preferred Elite Institution\u2122 secures you the very best skillset possible that cannot be achieved elsewhere. Even so, I still suspect that you could gain 80-90% of the same skills at somewhere significantly less prestigious that is less competitive to get into and less stressful to work at. I would rather have a world with far more people each achieving a fraction of the impact of the top performing EAs than large numbers of people giving up on high-impact careers after 30 rejections from what they feel is THE best of the best. It\u2019s great to be ambitious, but you need to understand what this means for you as an individual. Maybe it is JP Morgan. Maybe it\u2019s an org that makes people ask \u201csorry, <i>where</i>?\u201d. It\u2019s ok either way. (I cover the issue of approaching rejections and evaluating your ambitions in more detail shortly.)</p><h2 data-internal-id=\"My_reservations_with_joining_an_EA_org_fresh_out_of_university\">My reservations with joining an EA org fresh out of university</h2><p>Many people in EA see working for any EA org as prestigious, regardless of what their job actually involves. If you are a graduate with little real world work experience, you are a less attractive candidate for a hiring manager no matter how deeply embedded in the EA community you are. Unfortunately, we are not owed jobs in return for years of engagement in EA - knowing the lingo and the lore does not entitle us to an exciting job with high impact.</p><p data-internal-id=\"ftnt_ref1\">So what should you do? Just take one of the entry-level grad jobs at an EA org? I recommend&nbsp;thinking twice about this. If you read the job descriptions of many entry-level grad roles at EA orgs, they essentially list the tasks that no one else wants to do at that org because they are too boring.<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"1\" data-footnote-id=\"k5xxlpikcj\" role=\"doc-noteref\" id=\"fnrefk5xxlpikcj\"><sup><a href=\"#fnk5xxlpikcj\">[1]</a></sup></span>&nbsp;Think: managing an inbox, ordering food for the office, sometimes even doing people\u2019s laundry for them (??). These tasks don\u2019t generally cultivate the impactful, varied skill set&nbsp;that early stage career EAs should be focused on building; they mostly foster task-prioritisation abilities.</p><p>I think a more well-rounded skill set could typically be developed much faster at a less prestigious non-EA organisation. Outside of EA, where you will find a much bigger job market, it is often easier to find entry-level roles that don\u2019t centre around mundane tasks.</p><p>Taking this into consideration, my opinion is that entry-level EA positions often aren\u2019t the best move in terms of career development, offering less overall career capital than mainstream grad roles on most dimensions (aside from the opportunity to rub shoulders with more senior EAs - which, to be fair, is not to be underestimated as a longer term impact-booster).</p><p>To add insult to injury, much like the elite private-sector options described above, they are also often very competitive, with lengthy application processes. Therefore, I see these options as giving you better short term impact, but lower career capital pay-off. I suspect your individual impact over the medium term would be lower in such roles.</p><p>The upshot is: I recommend only choosing this career entry route if you are someone for whom working exclusively at EA organisations is incredibly high on your priority list.</p><h1 data-internal-id=\"_2__What_is_job_seeking__Baby_don_t_hurt_me__don_t_hurt_me__no_more_\">(2) What is job seeking? Baby don\u2019t hurt me, don\u2019t hurt me (no more)</h1><p>As I have already highlighted, many&nbsp;of the classic job market entry routes for EA grads have a very large pool of high quality applicants. This makes it incredibly difficult to stand out. If this is your chosen path, your chance of repeated rejection is high. &nbsp;</p><p>Some people have the personality type to brush off this repeated rejection, not take it personally, and move on largely unaffected. Others don\u2019t. It\u2019s ok and completely legitimate if you are someone who finds themselves in that second category.</p><p>For those who take rejection really hard, you have two options:</p><p data-internal-id=\"ftnt_ref2\">a) You could work on developing a tougher skin and just keep applying to competitive positions. For me, in my most recent round of applications,<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"2\" data-footnote-id=\"v9ajzsghoco\" role=\"doc-noteref\" id=\"fnrefv9ajzsghoco\"><sup><a href=\"#fnv9ajzsghoco\">[2]</a></sup></span>&nbsp;I managed to shield myself from the emotional impact of rejection by going into the process expecting, by default, to receive a lot of rejections. Rather than seeing a rejection as a poor reflection on my abilities, I was able to shift the narrative: any positive step (like progressing to a second round) was a bonus and a good sign, even if it ultimately ended in rejection. The key to this mindset was acknowledging that I could hold two truths concurrently: &nbsp;I am a competent worker that people will want to hire, but at the same time, there are other incredible applicants vying for the same positions as me. Accepting that the strengths of other candidates did not diminish my own value made the process a lot more manageable for me. &nbsp;</p><p data-internal-id=\"ftnt_ref3\">&nbsp;b) If this is not something you feel you can school yourself into thinking - because this is definitely easier said than done(!) - you could accept that rejection is something you find exceptionally difficult, and adjust your ambitions accordingly. I have heard multiple accounts of EAs describing how devastating they have found career rejection [for some written examples, see <a href=\"https://forum.effectivealtruism.org/posts/NDRBZNc2sBy5MC8Fw/recovering-from-rejection-written-for-the-in-depth-ea\">here</a>, <a href=\"https://forum.effectivealtruism.org/posts/jmbP9rwXncfa32seH/after-one-year-of-applying-for-ea-jobs-it-is-really-really\">here</a>, <a href=\"https://forum.effectivealtruism.org/posts/AXCnNJTQXeAY4jnsw/rejection-thread-stories-and-tips\">here</a>]. It\u2019s ok if you factor your experience of rejection into your decision making process when choosing where to apply. Of course, I get the whole hits-based decision making, probabilistic value judgements etc. etc. thing. But, at the end of the day, we are still people with very real human emotions.<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"3\" data-footnote-id=\"h7x5sg2tdje\" role=\"doc-noteref\" id=\"fnrefh7x5sg2tdje\"><sup><a href=\"#fnh7x5sg2tdje\">[3]</a></sup></span>&nbsp;And the impact of those emotions is not to be underestimated. Firstly, repairing your self-esteem after multiple difficult rejections would also be time-consuming and painful. Secondly, someone might, after receiving rejection after rejection after rejection, eventually find themselves disheartened enough that they give up entirely on EA forever. Now that\u2019s a sure fire way to tank your potential career impact.</p><p>You could also have a hybrid approach - work on improving your ability to process rejection, as in path (a), while applying for less competitive positions in the meantime as in path (b). Once you are ready, raise your ambitions, using your new-found confidence as a shield for rejection.</p><h1 data-internal-id=\"_3__The_outside_world_is_good_for_you__I_promise\">(3) The outside world is good for you, I promise</h1><p data-internal-id=\"ftnt_ref5\">I have met many people in the community who rarely interact with non-EAs, professionally and socially. But, based on my rigorous calculations<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"4\" data-footnote-id=\"fwwilfnlyci\" role=\"doc-noteref\" id=\"fnreffwwilfnlyci\"><sup><a href=\"#fnfwwilfnlyci\">[4]</a></sup></span>, 99.9999% of jobs will require you to communicate with people outside of the community. (Gross, right?<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"5\" data-footnote-id=\"8jcxpwk74vi\" role=\"doc-noteref\" id=\"fnref8jcxpwk74vi\"><sup><a href=\"#fn8jcxpwk74vi\">[5]</a></sup></span>) &nbsp;</p><p>I cannot state enough how important it is that you know how to do this, without throwing around a bunch of jargon and looking stunned when someone doesn\u2019t know what value lock-in is. It\u2019s especially helpful if you can communicate to non-EAs in a professional context, where you aren\u2019t just trying to casually convince your mate to join EA but are instead wholeheartedly trying to collaborate with another professional from a different background &nbsp;and respect their own stance whilst doing so. This includes policy makers, company directors, and funders external to EA. You will be relying on getting people like this onside to maximise your org\u2019s impact. It\u2019s important you fully realise the tremendous value they and their own expertise bring, and can work effectively together despite approaching issues with very different sets of prior assumptions and interests.</p><p data-internal-id=\"ftnt_ref6\">This is not the only reason you might benefit from expanding your interactions beyond the EA bubble, or stepping outside of it completely. For me, I think the biggest benefit of leaving EA for a few years was how it allowed me to entirely reset the relationship I had with the movement. Without this time away, I doubt I would be as confident, self-assured, well-rounded and energetic as I pride myself on being today. I also believe I would not have as much EA:life balance as I do now, which is essential for the sustainability of the work I do now and what I hope to achieve in the future. Life is short, so stop and smell the utilons once in a while.<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"6\" data-footnote-id=\"e3evqe2hj8n\" role=\"doc-noteref\" id=\"fnrefe3evqe2hj8n\"><sup><a href=\"#fne3evqe2hj8n\">[6]</a></sup></span></p><p>There\u2019s plenty more I could say on the benefits of working in non-EA environments and having a flourishing social life outside of EA. However, others have already beaten me to it, and done a great job, too: see <a href=\"https://forum.effectivealtruism.org/posts/xuycceKFL5zZsHZwL/if-you-re-unhappy-consider-leaving\">here</a>, <a href=\"https://forum.effectivealtruism.org/posts/G7nraJyjxCfiWEjkz/ea-needs-outsiders-with-a-greater-diversity-of-skills\">here</a>&nbsp;and <a href=\"https://forum.effectivealtruism.org/posts/5iuScuaYbSyfqph65/it-s-ok-to-leave-ea\">here</a>.</p><hr><ol class=\"footnote-section footnotes\" data-footnote-section=\"\" role=\"doc-endnotes\"><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"1\" data-footnote-id=\"k5xxlpikcj\" role=\"doc-endnote\" id=\"fnk5xxlpikcj\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"k5xxlpikcj\"><sup><strong><a href=\"#fnrefk5xxlpikcj\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;This even occurs in more senior ops roles: see this post <a href=\"https://forum.effectivealtruism.org/posts/X8YMxbWNsF5FNaCFz/senior-ea-ops-roles-if-you-want-to-undo-the-bottleneck-hire\">here</a>.</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"2\" data-footnote-id=\"v9ajzsghoco\" role=\"doc-endnote\" id=\"fnv9ajzsghoco\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"v9ajzsghoco\"><sup><strong><a href=\"#fnrefv9ajzsghoco\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;6/7 different EA org hiring rounds, depending on what you count as a hiring round, and 4 rejections.</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"3\" data-footnote-id=\"h7x5sg2tdje\" role=\"doc-endnote\" id=\"fnh7x5sg2tdje\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"h7x5sg2tdje\"><sup><strong><a href=\"#fnrefh7x5sg2tdje\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;Written before we enter a new era of digital minds.</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"4\" data-footnote-id=\"fwwilfnlyci\" role=\"doc-endnote\" id=\"fnfwwilfnlyci\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"fwwilfnlyci\"><sup><strong><a href=\"#fnreffwwilfnlyci\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;My calculation spreadsheet can be viewed <a href=\"https://www.youtube.com/watch?v=dQw4w9WgXcQ\">here</a>.</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"5\" data-footnote-id=\"8jcxpwk74vi\" role=\"doc-endnote\" id=\"fn8jcxpwk74vi\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"8jcxpwk74vi\"><sup><strong><a href=\"#fnref8jcxpwk74vi\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;Disclaimer: I love and respect all my non-EA friends.</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"6\" data-footnote-id=\"e3evqe2hj8n\" role=\"doc-endnote\" id=\"fne3evqe2hj8n\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"e3evqe2hj8n\"><sup><strong><a href=\"#fnrefe3evqe2hj8n\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;Depending on your timelines, life could be VERY short. In that case, maybe you shouldn\u2019t waste time sniffing utilons. Sorry, I guess.</p></div></li></ol>", "user": {"username": "LotteG"}}, {"_id": "SLLqWjbN925zGcy8W", "title": "Multipliers, squared: multiplier evaluation of Giving Multiplier", "postedAt": "2024-03-18T18:14:48.420Z", "htmlBody": "<p><br>As a part of Ambitious Impact (formerly, Charity Entrepreneurship)'s Research Training Program Fall 2023, some of the fellows have performed external evaluations of \"giving multiplier\" organizations - charities whose main job is to raise more donations to effective programs.</p><p>In this post, I share the executive summary of the evaluation I did on <a href=\"https://givingmultiplier.org/\">Giving Multiplier</a>. <strong>For more details, you can check the full, 25-page report </strong><a href=\"https://drive.google.com/file/d/10szvM6hvf7_z8Xr5Cmm-JJEq7YTGQB0v/view?usp=sharing\"><strong>here</strong></a>.&nbsp;</p><p><strong>Disclaimer:</strong> <i>this report has not been reviewed in its full length by AIM/CE staff, and does not represent their institutional assessment of Giving Multiplier (GM) or any other organization mentioned there. As for GM, even though this report counted on collaboration from their team and was shared with them before publication, it is an external evaluation and does not necessarily coincide with their views in all aspects.</i></p><h2>Executive summary</h2><p>This report assesses the cost-effectiveness of&nbsp;<strong>Giving Multiplier (GM)</strong>, a Harvard-based research project and platform that allows and incentivizes people to make paired donations to their favorite charities and highly effective ones.</p><p>We do this by using the&nbsp;<strong>methodology</strong> developed by&nbsp;<a href=\"https://docs.google.com/document/d/1ZoODVspd7x36uxlxNG6Ke1-6lZXOLnuL0A8VDWFIHlw/edit#heading=h.xiot40827613\"><u>Founders Pledge</u></a> and&nbsp;<a href=\"https://docs.google.com/document/d/1l0RjbMLXjwjy5Pqg4aLe-_YDLXw8T3DT5QP0AQGYHTo/edit#heading=h.rp402ri7bbko\"><u>Giving What We Can</u></a>. It includes calculating the gross and net giving multipliers - i.e., for each dollar invested in its operations, how many dollars can an organization raise for charities that operate above a community cost-effectiveness bar. To calculate these multipliers, we take into account the total money moved, labor opportunity costs, operating expenses, the proportion of the money that would have been donated to effective charities anyway, and the position of each target charity relative to the community bar.</p><p>Before we start the cost-effectiveness calculations, we first outline a&nbsp;<strong>Theory of Change</strong> for GM\u2019s work and describe what is known about various assumptions behind it - we find most of them plausible, and the only unlikely assumption is common to every effective giving multiplier organization.</p><p>We also assess the&nbsp;<strong>quality of the monitoring and evaluation</strong> data used in the remainder of the report. Overall, we find it to be good enough for our purposes since donations are made (and recorded) directly on GM's platform. However, donor\u2019s self-reporting biases and non-response effects may apply to data on counterfactuality. We also make recommendations for other monitoring and evaluation data that could help better segment their public, promote recurring donations, and assess the positive externalities of GM\u2019s work.</p><p>We then proceed to calculate the&nbsp;<strong>average net multiplier</strong> and the&nbsp;<strong>marginal net multiplier</strong>. The average net multiplier between September 2020 and December 2023 is found to be between&nbsp;<strong>5.4x</strong> (conservative estimate) and&nbsp;<strong>18x</strong> (optimistic estimate). The marginal net multiplier for 2024 is found to be between an ineffective&nbsp;<strong>0.32x</strong> (conservative) and&nbsp;<strong>34x</strong> (optimistic). However, we are very uncertain about our estimates for both the estimates of the marginal multipliers.</p><p>Finally, we finish with a grading of the overall&nbsp;<strong>transparency</strong> of GM and close with some&nbsp;<strong>conclusions</strong> about the next steps for GM and the uncertainties surrounding its scalability and cost-effectiveness prospects. We surmise that GM can take advantage of important economies of scale in the next two years, but that scaling significantly while keeping their costs proportionally low will be a major challenge.</p><p><strong>See the full report </strong><a href=\"https://drive.google.com/file/d/10szvM6hvf7_z8Xr5Cmm-JJEq7YTGQB0v/view?usp=sharing\"><strong>here</strong></a>.&nbsp;</p><h2>Acknowledgments</h2><p>Thanks to Matt Coleman and Lucius Caviola from Giving Multiplier for being super open and collaborative during the evaluation process. And thanks to Charity Entrepreneurship's RTP team for supporting and making this research possible.</p><p><br>&nbsp;</p>", "user": {"username": "bcbernardo"}}, {"_id": "aCCqjwisAaFSZjJpy", "title": "Report and Data for EAGxAustralia 2023", "postedAt": "2024-03-17T04:25:40.186Z", "htmlBody": "<p>We are proud to release the <a href=\"https://docs.google.com/document/d/1W2LIBNI4KKvbB2x_AZgawrMOaq1leVbyPRki5chh_Yk/edit\">retrospective report (click here for google doc)</a> and analysis of the EAGxAustralia 2023 conference. We spent a lot of time collating information that we hope will be of use to event organisers throughout the EA community. Here we provide a brief summary of some of the information found in our report:</p><ul><li>Detailed breakdown of committee time taken to perform different tasks.</li><li>Detailed demographic breakdown of attendees and speakers.</li><li>Data for the number of applications received by week in the leadup to the conference.</li><li>Data for attendence at different conference sessions, including corroboration between Swapcard registrations and manual headcounts.</li><li>Detailed breakdown of budget expenditures.</li><li>Detailed discussion of program design considerations and challenges.</li><li>Breakdown of ticket sales aned travel grants by amount.</li><li>Catering data of all food purchased and how much was actually eaten per person.</li><li>Detailed list of all inventory items required including quantities, and discussion of what was actually used.</li><li>Discussion of our $6000 social media marketing program, including registration funnel and data regarding cost per lead and per approved applicant.</li><li>Breakdown of merchandise purchases, including costs and quantities left over.</li><li>Attendence estimates for evening social events.</li><li>Quantitiative and qualitative analysis of attendee feedback.</li></ul><p>Our introductory summary with key measures is reproduced below:</p><p>EAGxAustralia 2023 was held at the University of Melbourne from the 22nd-24th September 2023. We received a total of 361 applications, of which 317 were accepted. Final attendance was 279, including a total of 56 invited speakers. Average likelihood to recommend score was 8.63/10, with an average of 7.31 new connections reported per attendee. The direct financial outlay for the event was about $160,000 AUD, or $200,000 AUD when adding travel grants and deducting revenue from ticket sales. <strong>This yields a total cost per connection of $63 USD, which compares favourably to the average cost per connection of EAGx conferences in 2022 of $152 USD.</strong></p><p>We are very proud of our achievement of organising a high-impact conference conference on a low budget. We would like to thank the entire organising committee and all those who supported our work, including Ollie and Ivan from CEA.</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;James Fodor and Vanessa Sarre</p>", "user": {"username": "Fods12"}}, {"_id": "FaqutaCNqccgkgcaf", "title": "Ashamed of wealth", "postedAt": "2024-03-16T22:05:08.793Z", "htmlBody": "<p><strong>tl;dr:</strong> I feel ashamed of being born into wealth. Upon analysis, I don't think that's justified. I should be taking advantage of my wealth, not wallowing in how ashamed I am to have it.&nbsp;</p><figure class=\"image image_resized\" style=\"width:40.13%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FaqutaCNqccgkgcaf/h7uvk50u3v1yriztnjgg\" alt=\"Uncle Scrooge with Money Bag. Oil painting by Carl Barks of perhaps his  most famous character, circa 1971. | Olja\"><figcaption>Uncle Scrooge, oil painting by Carl Barks</figcaption></figure><p>I'm a high school student in France. I was born into a wealthy family by most of my classmates' (and of course the world)'s standards. In France, there's a strong social incentive to openly criticize wealth of any kind and view people richer than oneself with a particular kind of disdain and resentment. I imagine a majority of people reading this are from Silicon Valley, which has a radically different view on wealth. (I grew up in Mountain View, then moved to France at age 12. The cultural differences are striking!)</p><p>I'm rich, and it would be foolish to deny that I feel ashamed of this on some level. Friends will mention how rich I am or talk about how expensive eg university is and I will attempt to downplay my wealth, even if it means lying a little (I am not proud of this). I notice myself latching onto any opportunity to complain about the price of something. \"Ah yes the inflation, bad isn't it (ski trip will cost a little more this year I guess).\"</p><p>This feeling of guilty wealth got worse when I learned how cheap mosquito nets were.</p><p>Since dabbling in effective altruism, I started noticing the price of things a lot more than I used to.<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"1\" data-footnote-id=\"dctbhx8i1t\" role=\"doc-noteref\" id=\"fnrefdctbhx8i1t\"><sup><a href=\"#fndctbhx8i1t\">[1]</a></sup></span>&nbsp;I became sensitive to how my family would spend things and would subtly put us on a better track, like by skipping desserts or drinks at expensive restaurants. My parents continually assure me that they have enough money put aside to pay for any university I get into. They would be irate if I intentionally chose a relatively cheap university for the sake of cheapness. I'm going to find this warning hard to heed given how much money we're talking about.</p><p>So my guilt translates into a heightened price sensitivity. But is this guilt justified at all?</p><p>The subagent inside me in charge of social incentives tells me I should be ashamed of being rich. The subagent inside me in charge of being sane tells me I should be careful what I wish for. If being rich is bad, then that implies being less rich is better, no? No? Stephen Fry once noted that in all things, we think we're in the Goldilocks zone. Anyone smarter than us is an overly intellectual bookworm; anyone stupider is a fool. Anyone richer than us is a snobby bourgeois; anyone poorer is a member of the (ew) lower class.&nbsp;</p><p>But that's stupid. If I could slide my IQ up a few points, <i>of course I would</i>. If I could have been born richer, I would have. I &nbsp;should try not to have that disdain for those richer than oneself which society endorses. Sometimes, my gut pities this kid in my class who has an expensive watch and drives a scooter to school from his mansion one block away because it makes him feel cool. He's a spoiled brat in most senses of the word, which is reason to pity him. But my gut pities his<i> wealth</i>. Yet, if I could pick to have his wealth I would unquestionably do so, even when that is not the socially approved response.&nbsp;</p><p>More money is more good: that\u2019s a simple equation I can get behind. Were my parents a little richer, it might be 100 euros a month going to AMF instead of 50.&nbsp;<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"2\" data-footnote-id=\"1wf62wpxe2n\" role=\"doc-noteref\" id=\"fnref1wf62wpxe2n\"><sup><a href=\"#fn1wf62wpxe2n\">[2]</a></sup></span>&nbsp;One should be wary of learning the long lessons from spoiled brats.&nbsp;</p><p>Another reason not to feel ashamed at being rich is that <i>it's not my money</i>. I didn't <i>choose</i> to be born rich. My parents are the ones deciding what to do with it. This doesn't absolve me of all responsibility: whatever uncomfortable and terribly cliched<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"3\" data-footnote-id=\"hvwe5vy2swn\" role=\"doc-noteref\" id=\"fnrefhvwe5vy2swn\"><sup><a href=\"#fnhvwe5vy2swn\">[3]</a></sup></span>&nbsp;conversation &nbsp;I could have with them tonight in order to get them to spend more on mosquito nets is a small price compared to that paid by children infected with malaria. I have a disproportionate amount of influence over my parents, even as my social status in the family is \"rebellious teenager whose political phase involves suspiciously data-driven people on internet forums\". That's a disproportionate influence over two individuals wealthy enough to save at least one statistical life per year.&nbsp;</p><p>This opportunity was a birthright: I should not be ashamed to have it. Instead, I should be <i>exploiting</i> it as well as I can.</p><p><br>&nbsp;</p><ol class=\"footnote-section footnotes\" data-footnote-section=\"\" role=\"doc-endnotes\"><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"1\" data-footnote-id=\"dctbhx8i1t\" role=\"doc-endnote\" id=\"fndctbhx8i1t\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"dctbhx8i1t\"><sup><strong><a href=\"#fnrefdctbhx8i1t\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>I'm aware it's a common failure mode to grow obsessed with this. Converting every price tag in a store into human lives can get ugly quickly.&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"2\" data-footnote-id=\"1wf62wpxe2n\" role=\"doc-endnote\" id=\"fn1wf62wpxe2n\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"1wf62wpxe2n\"><sup><strong><a href=\"#fnref1wf62wpxe2n\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>After much arguing, I managed to convince them to donate to <a href=\"https://againstmalaria.com\">againstmalaria.com</a>. They said 50 euros was a lot. We sometimes spend that much on godforsaken fancy cocktails when we're on vacation!</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"3\" data-footnote-id=\"hvwe5vy2swn\" role=\"doc-endnote\" id=\"fnhvwe5vy2swn\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"hvwe5vy2swn\"><sup><strong><a href=\"#fnrefhvwe5vy2swn\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>In other news: morally righteous teenager taken aback by comparatively conservative parents!</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"4\" data-footnote-id=\"rvnwkjrf4l\" role=\"doc-endnote\" id=\"fnrvnwkjrf4l\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"rvnwkjrf4l\"><sup><strong><a href=\"#fnrefrvnwkjrf4l\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>I'm not attempting to get my parents to donate to <a href=\"https://intelligence.org/donate/\">MIRI</a> or <a href=\"https://www.every.org/alignment/f/donate-to-the-arc-evals#/donate/card\">METR</a> because I have a limited stock of <a href=\"https://www.lesswrong.com/posts/wkuDgmpxwbu2M2k3w/you-have-a-set-amount-of-weirdness-points-spend-them-wisely\">weirdness points</a> and I don't want them to think mosquito nets are weird.</p></div></li></ol>", "user": {"username": "Neil Warren"}}, {"_id": "DeEugKhDFwEaYdmkr", "title": "Balancing safety and waste", "postedAt": "2024-03-17T10:57:00.264Z", "htmlBody": "<figure class=\"table\" style=\"height:60.75px;width:626.987px\"><table style=\"background-color:rgb(255, 255, 255);border:1px double rgb(151, 201, 177)\"><tbody><tr><td style=\"background-color:rgb(221, 238, 232);border:0.681818pt solid rgb(151, 201, 177);padding:5pt;vertical-align:top\"><strong>This is a&nbsp;</strong><a href=\"https://forum.effectivealtruism.org/topics/draft-amnesty-week-2024\"><strong><u>Draft Amnesty Week</u></strong></a><strong> draft.&nbsp;</strong>It may not be polished, up to my usual standards, fully thought through, or fully fact-checked.&nbsp;</td></tr></tbody></table></figure><p>TLDR: I made a back-of-the-envelope model for the value of steering the future of AI<strong>&nbsp;</strong><a href=\"https://docs.google.com/spreadsheets/d/1Xv_9DUcYpKtnF4N3Tq_Nbqcr10xQYBGu/edit#gid=923441735\"><strong><u>(link here)</u></strong></a><strong>.</strong></p><p>I started with four questions:</p><p>a) How morally aligned can we expect the goals of an ASI to be?</p><p>b) How morally aligned can we expect future human goals to be?</p><p>c) How much can we expect ASI to increase or decrease human agency?</p><p>d) How would a [stronger AIS movement] affect these expectations?</p><p>Here, by agency, I mean the proportion of decisions made based on someone\u2019s&nbsp;<i>expressed&nbsp;</i>preferences. In my model, I compare a world in which a superintelligence (ASI) suddenly arises (World A) with a world in which one possible goal of AI safety (AIS) is achieved (World B). More in the doc.</p><p>Although Bostrom (<a href=\"https://aeon.co/essays/none-of-our-technologies-has-managed-to-destroy-humanity-yet\"><u>1</u></a>,&nbsp;<a href=\"https://existential-risk.org/concept\"><u>2</u></a>), Ord (Precipice, Chapter 1) or MacAskill (WWOTF) tackle all of these questions, I\u2019m not aware of a post which would put them into a single \u201cinteractive\u201d Excel, so that\u2019s what I tried to do<strong>.&nbsp;</strong>Seeing how they weigh in my mind makes me think consciousness and the reliability of progress are somewhat under-discussed parts of the equation.</p><p>I was influenced by Joscha Bach\u2019s arguments from<a href=\"https://youtu.be/Z02Obj8j6FQ\"><u> this debate</u></a> based on</p><ol><li>a strong credence humanity will go extinct without AGI (based on the&nbsp;<a href=\"https://en.wikipedia.org/wiki/The_Limits_to_Growth\"><u>Limits to Growth</u></a> reports)</li><li><a href=\"http://bach.ai/from-computation-to-ethics/\"><u>a theory of valence</u></a> based on predictive processing (presumably making a future based on a random AI value function likely good)</li></ol><p>The growth extinction angle is based on resource depletion, which I explored in&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/TXjg9HavsJWFXMhGN/a-quick-review-of-resource-depletion-waste-and\"><u>this post</u></a>, unable to find a credible basis for Bach\u2019s argument. However, I think it\u2019s reasonable to question the value of x-risk reduction if one\u2019s uncertain that civilization without AGI could yield much positive value. Similarly, I think Bach\u2019s specific theory of valence is likely wrong but grant that the hypothesized conclusion should be taken seriously based on a wider range of views on consciousness and AI.</p><p>As a result, my guess is that whether or not AI safety will succeed at steering the values of ASI, the future will be better than today. However, these considerations haven\u2019t changed my general outlook: It\u2019s much more likely that the future will be good if humanity makes a conscious effort to shape the trajectory and values of ASI and this conclusion seems robust even to quite exotic considerations.</p><p>Nevertheless, my reflection highlighted a few ideas:</p><p><strong>1. Alignment isn\u2019t just about the control problem</strong></p><p>Yes, AIS increases human agency (question C) but also the probability that the amount of agency given to humans or ASI will depend on their moral alignment (interactions C-A and C-B), as well as directly improving the probability any AI that will be developed will be morally aligned (question A). To a limited extent, AIS may also improve human (moral) decision-making (question B) via the routes discussed within AI ethics (such as preventing the rise of extremism via AI manipulation).</p><p><strong>2. Increasing human agency does not guarantee positive outcomes.</strong></p><p>It seems a truly long-lasting value lock-in is only possible with a heavy help of AI. Therefore, the risk that we would solve the alignment problem but nevertheless irrationally prevent ourselves from building a friendly AI, seems very low - relative to the billions of years we\u2019ve got to realize our potential, cultural evolution is quick. More on this in point 5).&nbsp;</p><p>This consideration also potentially suggests that one possible risk of increasing humanity\u2019s attempts to carefully shape AI values could be increasing the chances of a value lock-in. However, I think that if we solve the control problem (i.e. humans will stay in the decision loop), an AI capable of a value lock-in would understand how our meta-values interact with our true values. In other words, coherent extrapolated volition is a more rational way of interpreting goals than taking them literally, so I have a decent faith an aligned ASI would recognize that. And it doesn\u2019t seem like there are important differences in CEV, that is meta-values (more in point 6).</p><p>I think there's a big chance I'm wrong here. If ASI arises by scaling a LLM, it could be analogous to a human who is very smart in terms of System 1 (can instantly produce complex plans to achieve goals) but not so rational, i.e. bright in terms of System 2 (doesn't care to analyze, how philosophically coherent these goals are). However, these scenarios seem like precisely the kind of problem reduced by increasing the attention oriented towards AI safety.</p><p><strong>3. Consciousness, progress and uncertainty seem like key factors.</strong></p><p>Understanding consciousness seems important to evaluate, what value we would lose if an AI proceeded to convert the universe's resources according to whatever value function which would happen to win the AI race. I explored this interaction more in a <a href=\"https://forum.effectivealtruism.org/posts/HWKqmTLcbsf4F5xAk/ai-safety-and-consciousness-research-a-brainstorm\">previous post</a>.</p><p>Understanding progress seems important to evaluate whether humanity would be better equipped to create an ASI in 100 or 1000 years. For this purpose, I think \"better equipped\" can be nicely operationalized in a very value-uncertain way as \"making decisions based on more reflection &amp; evidence and higher-order considerations\". Part of this question is whether morally misaligned actors, such as authoritarian regimes or terrorists may utilize this time to catch up and perhaps use an AI to halt humanity's potential (5).</p><p>The specific flavor of uncertainty we choose seems crucial. If it pushes us towards common-sense morality or if it pushes us to defer to later generations, AIS seems like a clear top-priority. If it pushes us towards views that assign moral patience to AI, it may decrease some forms of AIS (an infinite pause) while increasing others (e.g. implementing reliable AI philosophy / meta-cognition, see Chi's <a href=\"https://forum.effectivealtruism.org/posts/wE7KPnjZHBjxLKNno/ai-things-that-are-perhaps-as-important-as-human-controlled\">recent post</a>) (6).</p><p><strong>4. Increasing ASI agency does not guarantee negative outcomes.</strong></p><p>Orthogonality thesis, as proposed by Bostrom is hard to disagree with - it does seem possible to imagine an AI holding any combination of goals and intelligence. However, the thesis alone doesn\u2019t rule out a possible correlation - i.e. the possibility that given somewhat flexible goals, it\u2019s more likely that an AI will be morally aligned, as opposed to misaligned.</p><p>Given the grand uncertainty and importance of these questions, hoping that such a correlation exists would be a terrible plan. Nevertheless, there\u2019s a few interesting reasons one might think it does:</p><ul><li>Humans act as an existence proof that alignment with morality \"by default\" is possible (or even likely on priors) - <a href=\"https://t.co/YRFXX8FJoK\">Batson</a> suggests people treat others' wellbeing as an intrinsic value (i.e. true altruism exists), which is why I suspect the CEV of most of humanity would converge on a world model close to the moral ideal. However:<ul><li>This approach could be biased by anthropic effects - if we hadn't developed morality, we wouldn't be talking about it.</li><li><a href=\"https://optimists.ai/2023/11/28/ai-is-easy-to-control/\">Some </a>suggest RLHF could be analogous to this process, <a href=\"https://youtu.be/eaYIU6YXr3w\">most </a>disagree</li></ul></li><li>It could be that positive value means the fulfillment of preferences. In this way, virtually any ASI capable of having coherent preferences may be maximizing moral value by realizing them.</li><li>If an AI starts to reflect on what it should aim to achieve, it may have to solve what \u201cit\u201d is, i.e. the philosophy of self. It may conclude&nbsp;(<a href=\"https://en.wikipedia.org/wiki/Identity_(philosophy)\"><u>personal) identity</u></a> is an unsustainable concept and accept <a href=\"https://en.wikipedia.org/wiki/Open_individualism\">open individualism</a> or a kind of <a href=\"https://en.wikipedia.org/wiki/Original_position\">veil of ignorance</a> - if you don't know in which intelligent entity you will be the next moment, you should optimize for everyone's well-being.</li><li>Consciousness&nbsp;<a href=\"https://docs.google.com/document/d/1MnZuvDAswmKZ5VLgSg1OQGylDm88_XbxB3YLLxowYK0/edit\"><u>may</u></a> be changing the architecture of intelligent networks. Or vice versa, intelligent networks&nbsp;<a href=\"https://qualiacomputing.com/2020/12/05/oscillatory-synchrony-is-energetically-cheap/\"><u>may</u></a> naturally benefit from creating positive qualia.</li></ul><p><strong>5. Progress with humans in charge seems reliable</strong></p><p>If it\u2019s true EAs are the&nbsp;<a href=\"https://www.richardhanania.com/p/effective-altruism-thinks-youre-hitler\"><u>WEIRDest of the WEIRD</u></a> (sociological&nbsp;<a href=\"https://en.wikipedia.org/wiki/Psychology#WEIRD_bias\"><u>acronym</u></a>), effective altruism seems to be contingent on the natural arrow of progress. It seems Hegel was right, in the long-term, any value dissatisfaction creates tension and therefore, systems positive for human well-being seem more stable.</p><ul><li>Mainly, democracies seem <a href=\"http://www.stier.net/writing/demstab/stability.htm\">more stable</a> than autocracies. The typical story of both right and left authoritarian regimes of the 20th century seems to be a spontaneous collapse - or (in the case of China or Vietnam) adaptation to become more tolerable. The spirit of democracy seems so omnipresent that existing authoritarian regimes generally pay lip service to democracy and seem pressured to accustom to the opinions of the populations. In China, around 90 % of people <a href=\"https://en.wikipedia.org/wiki/Democracy_in_China#cite_ref-:0_57-2\">support </a>democracy, in Arabic countries, this <a href=\"https://arabcenterdc.org/resource/arab-opinion-index-2022-executive-summary/\">figure </a>reaches around 72 %.</li><li>One could fear that the disproportion between the birth rates among religious fundamentalists and the cosmopolitan population could make us expect the future to have less rational values. To evaluate this hypothesis, one could inspect the demographic projections of religiosity, as a crude heuristic. Indeed, a look at the global <a href=\"https://www.pewresearch.org/religion/2015/04/02/religious-projections-2010-2050/\">projection</a> for 2050 shows a 3% decline in irreligion. However, I suspect that as the demographic revolution unfolds and people become richer, religious practice will become more reminiscent of the rich parts of the Arabic world. Eventually, I think we should expect these regions to follow the current demographic <a href=\"https://www.pewresearch.org/religion/2022/09/13/modeling-the-future-of-religion-in-america/\">trends </a>in the US, where irreligion is on the rise. Here, my point isn't to argue these specific trends are necessarily optimistic but rather, that horizontal memetic cultural evolution (ideas spreading) seems faster than vertical one (ideas getting \u201cinherited\u201d).</li><li>One could fear that populism will get more intense with AI, leading to worse governance. I think this is a problem we should be taking seriously. Nevertheless, I again think the evidence leans towards optimism. Firstly, AI may also improve the defense of social media against fake news. Secondly, new populism <a href=\"https://www.astralcodexten.com/p/sorry-i-still-think-i-am-right-about\">does not</a> seem <a href=\"https://80000hours.org/podcast/episodes/hugo-mercier-misinformation-mass-persuasion/\">dependent </a>on false information per se - rather, misleading interpretations of reality. Being 1 SD more exposed to fake news only <a href=\"https://ceistorvergata.it/RePEc/rpaper/RP493.pdf\">increases</a> populist voting by 0,19 SD. Similarly, conspiracy beliefs don't seem to have <a href=\"https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0270429\">changed </a>much over the last years. And importantly, our credence towards video evidence seems to be <a href=\"https://80000hours.org/podcast/episodes/nina-schick-disinformation-synthetic-media/\">matching </a>the decreasing costs of creating deep fakes. Currently, deep fakes that are impossible to recognize are already very easy to make - nevertheless none of the attempts to change wars and elections in this way seemed to have made a significant difference so far.</li></ul><p>Let\u2019s say humans won\u2019t become an interplanetary species. In such a case, I\u2019d expect our species to continue thriving on this planet for the remaining lifetime of Earth, i.e. something like&nbsp;<a href=\"https://80000hours.org/articles/future-generations/\"><u>500 million years</u></a>. Let\u2019s say current AI safety efforts do overshoot and in result, our civilization implements a tough international law that prevents civilization from making use of the positive side of AI and spreading between the stars. This could constitute a suboptimal lock-in. However, it seems unlikely to me that without AI, humans would be able to lock-in a bad idea for long enough to matter. In the 17th century slavery, witch trials, dogmas and oppression were commonly accepted. If it took us a hundred times longer to reach some moral threshold, we would have just used up 0.006% of the remaining lifetime of our planet. In the optimistic scenario we utilize the full lifetime of the universe, this time could be trillion times longer.</p><p><strong>6. \u201cIndiscriminate moral uncertainty\u201d supports AIS</strong></p><p>Naively, absolute moral uncertainty would imply practical moral nihilism. Every moral claim would have a 50 % probability of being true - therefore, there\u2019s no reason to judge actions on moral basis. However, such a position requires ~100 % credence that for each claim, this probability is indeed 0.5 and no further inspection can move it by any margin, which is paradoxically an expression of ridiculous certainty. True moral uncertainty probably leads to attempts to increase humanity\u2019s philosophical reflection. This seems philosophically very straight-forward:</p><ul><li>Yes, humans disagree about values to an extent that assigns negative value to most charitable attempts from some perspective. However, compared to our value disagreements, our meta-value disagreements seem incredibly small - nearly all believe to choose beliefs according to what is true and what brings fulfillment.</li><li>It seems hard to argue that more reflection gets us farther from the truth. And it seems hard to argue that knowing the truth brings us less of what we meta-value. Therefore, steering progress towards reflection seems like a robust way to increase the fulfillment of humanity\u2019s meta-values.</li></ul><p>AIS could be a necessary precursor to make sure we have time for such reflection. This is a less \u201cobviously true\u201d statement but the uncertainty is epistemic, not moral. And provided ASI doesn\u2019t happen in our lifetimes, such effort would merely be a waste, not actively harmful, which seems positive from the position of a \"sincere\" moral uncertainty.</p><p>Lastly, more uncertainty about cause X increases the necessity to develop an (aligned) ASI. For instance, one <a href=\"https://onlinelibrary.wiley.com/doi/full/10.1111/j.1539-6924.2010.01460.x\">could </a>argue that perhaps the universe is full of deadly rays that wipe life out the moment they meet it but we can\u2019t observe any signs of it, because once we could observe them, we\u2019d already be dead. However, I think the Grabby Aliens model provides an interesting argument against this reasoning - just based on conventional assumptions about the great filters, our civilization is suspiciously early in the universe (see&nbsp;<a href=\"https://youtu.be/l3whaviTqqg\"><u>this fun animated explainer</u></a>). Therefore, any additional historical strong selection effect seems unlikely on priors.</p>", "user": {"username": "Daniel_Friedrich"}}, {"_id": "bJ6aNXT4xosxG2wkr", "title": "8) The Lines of Defence Approach to Pandemic Risk Management", "postedAt": "2024-03-17T19:00:43.670Z", "htmlBody": "<p>I started working on this draft maybe 18 months ago. It was part of a larger project which is still ongoing, but this piece was in decent shape. I wanted to trim it down a lot before I published it, and one of the sections towards the end needs a bit of work too, but since the amnesty is in place (and it's St. Patrick's Day!) I thought I\u2019d give it a few tweaks and lash it up anyway.</p><p>This post describes the Lines of Defence risk management structure and explains how it can be applied to pandemic prevention. This is the wireframe of the solution to pandemics (IMHO). We can use these ideas in this post to build the plans and the defensive structures we'll need to protect ourselves from pandemic-potential pathogens (\u2018PPPs\u2019).</p><p>I think this is a novel approach to outbreak control and pandemic risk management. I think the key innovation is the introduction of the concept of strategy: goal-setting, resource management, and contingency planning for different scenarios to ensure the goal is achieved. So the Lines of Defence approach is a strategy that can adapt to the situation on the ground, whereas academic approaches are inflexible and cannot. Indeed, this is one of the major holes in the \u2018Swiss Cheese' model of pandemic risk management which, among many other things, will be discussed below.</p><p>In short, the Lines of Defence model (capitalised to represent the whole structure and the strategy) helps us to frame the problem, it helps us to build the solutions, and it helps us to communicate the whole process to each other and to the policy-makers and to the public.</p><p>So, let's get started...</p><p>&nbsp;</p><h1><u>What is a \u2018Line of Defence\u2019?</u></h1><p>A line of defence (lower case to refer to the individual line or measure) is anything that can protect you from danger by slowing, weakening, or eliminating the threat. A line of defence could be a policy, a strategy, a system, a piece of infrastructure, or a physical object. Building lines of defence, like adding layers of redundancy, is a common risk management technique, and it should be a key feature of our global pandemic prevention plans.</p><p>A wall around a castle is perhaps the most obvious example of a line of defence. If the invaders can\u2019t get past the outer wall, then they can\u2019t harm the people on the other side of it. In this case, the line of defence has successfully ended (or at least, postponed) the threat. A moat around a castle serves the same purpose, and castles often had both walls and moats to protect them. Lines of defence are multiplicative: combining measures offers more protection than employing either measure exclusively.</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/bJ6aNXT4xosxG2wkr/swjxrvsmnolmxmsnzndi\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/bJ6aNXT4xosxG2wkr/ppguccapzipi95z5w01n 200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/bJ6aNXT4xosxG2wkr/esz5uymltidbwqp1s0od 400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/bJ6aNXT4xosxG2wkr/krr5lkvitooiacjxvx7v 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/bJ6aNXT4xosxG2wkr/s3da9agjqel4aehwlii0 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/bJ6aNXT4xosxG2wkr/gdac8bxa9hvjeruuwoav 1000w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/bJ6aNXT4xosxG2wkr/ertjfbhh1zlw1ubxjnxm 1200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/bJ6aNXT4xosxG2wkr/oykh2sgiqxm0luifwqm5 1400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/bJ6aNXT4xosxG2wkr/snesihhwy6bcommxdkid 1600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/bJ6aNXT4xosxG2wkr/ny0usd1ksnqyhr1mky29 1800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/bJ6aNXT4xosxG2wkr/wgice9bmonumdtkfps9c 1920w\"></figure><p>As I write this, I am looking at an image of a motte and bailey. It seems to me that the whole purpose of the structure is to create multiple lines of defence between the people living within its walls and those on the other side who would do them harm. The bailey is protected by a ditch with a wall on the other side of it. This is the first line of defence. The motte has its own ditch with a drawbridge, and a hill to climb to make it more difficult to get to the top. The keep had another wall around it, as well as its own built-in defences: some were raised off the ground, others were fire retardant. From bailey to motte to keep, the structure appears to be one line of defence after another.</p><p>If we stop to think about it for a moment, we can see the lines of defence risk management structure all around us. We use 2-factor-authentication (2 lines of defence) to protect our smart devices. Redundancy is built into elevators, aeroplanes, and other every day engineering works, just in case. The human body is protected from exogenous threats by its external (skin, mucus, eyelashes) and internal lines of defence (stomach acid, the immune system \u2013 general and specific). Key infrastructure buildings have multiple rounds of ID checks, scanners, and detectors between the front door and the most sensitive areas. <a href=\"https://www.youtube.com/watch?v=kd33UVZhnAA&amp;ab_channel=GoogleCloudTech\">Google\u2019s data centres have 6 lines of defence</a>.</p><p>All of these examples are variations of the same underlying protective structure, and they are all motivated by the same idea: the more lines of defence between us and the threat, the safer we will be.</p><p>&nbsp;</p><h1>How Does the Lines of Defence Model Apply to Pandemic Risk Management?</h1><h3>1 More lines of defence = more security &amp; stability</h3><p>The more lines of defence you have in place, and the higher the quality of each, the safer your position. This principle applies in aeronautical engineering, cyber security, medieval warfare, epidemic control, and wherever else risk is managed.</p><p>If you only have one line of defence, and it doesn\u2019t hold, then it\u2019s game over for you. To avoid this ruinous outcome, you need a Plan B to protect your Plan A, and a Plan C to protect your Plan B, etc. If one component fails, and you don\u2019t have a backup, then it\u2019s game over again. So you want spare parts for your spare parts, and more is always better.</p><p>The deeper your defences, the more secure your position.</p><p>In some cases, the resources required to overcome the successive lines of defence may be so substantial that the defences are never tested. A well-defended castle might encourage the raiders to attack another one instead. The same principle applies to cyber security and home burglary protection.</p><p>Finally, in addition to the reduction of actual risk, the structure will also reduce the <i>perception</i> of risk among the population. If there is a strong defensive system in place, and the people know it can be trusted, then it the level of fear and uncertainty in the population will be reduced. This will be especially valuable at the advent of a real emergency when information is scarce, rumours rife, and there is potential for unnecessary panic and social instability.</p><p>&nbsp;</p><h3>2 We want to step the threat as far away as possible</h3><p>When faced with a threat of any kind, we want to minimise its potential impact. The farther away it is when we stop it, the less harm it can do to us. So, ideally, we want to stop the threat at our first line of defence because that minimises the risk to our position. In the context of a contagion, we want to stop the PPP as close to its source as possible while the outbreak is small and local, so that they cannot go on to become a global pandemic.</p><p>Just as the Lord wants attackers stopped outside the bailey wall (and he certainly doesn\u2019t want them reaching the keep) we want to prevent the PPP from getting anywhere near us. Stopping the PPP with our first line of defence minimises the cost of defence today and it minimises the likelihood that the threat will spill over into civil society at a later date.</p><p>If the first line fails, then we want it stopped at the second line. If that fails, then we fall back to our third, etc. The goal is always the same: to stop the threat as far away as possible. We don\u2019t ever want our last line of defence to be tested because if it fails, then it\u2019s game over.</p><p>Threats increase over time so, on a long enough timeline, our last line of defence definitely will be tested. If it is tested often enough, then it definitely will fail (eventually). So given that the threats are increasing all the time, our defences should be increasing too \u2013 ideally ahead of the threat. The lesson therefore is to keep building more and more lines of defence, and to keep improving the strength and quality of each \u2013 especially the outer ones \u2013 so that our last lines are never tested.&nbsp;</p><p>&nbsp;</p><h3>3 The Lines of Defence Model is Appropriate and Easy to Understand</h3><p>The Lines of Defence model of pandemic risk management helps us to frame the problem and its solution. It accurately describes what we are trying to achieve with our outbreak response plans and it demonstrates how our public health measures can be employed to achieve those goals. I think most people will intuitively understand the concept, so the model could make it easier to communicate the key ideas in pandemic prevention to policy-makers, media and public alike.</p><p>Crucially, the Lines of Defence model brings the concept of strategy into the conversation. It presents goals (stop the threat ASAP), tools (our public health measures), and a sequential / contingent plan for achieving the former with the latter (as described in points 1 &amp; 2 above). Strategy and tactics are essential when solving Risk Management problems because the environment and the risks are constantly evolving and so our tactics need to adjust with them in order to keep the high-level plan on course. Traditional academic approaches to pandemic risk management struggle with this dynamism, as they lack goals and all effects are assumed to be fixed over time.</p><p>For example, the \u2018Slices of Swiss Cheese\u2019 model currently preferred by epidemiologists does not discern between the timing and effectiveness of measures, nor does it offer any guidance for the timing of their implementation. The Swiss Cheese model is a \u2018mash the keypad\u2019 strategy, in which all measures are assumed to \u2018work\u2019 and are implemented at the same time for as long as is necessary, to achieve an unstated goal. This approach is not optimal, ambitious, or likely to engender much faith from the public.</p><p>Also, slices of Swiss cheese are soft, full of holes, and have never been associated with defence and resilience \u2013 for obvious reasons! I think a Lines of Defence is likely to get more buy-in from the public.</p><p>&nbsp;</p><h1>What are The Lines of Defence?</h1><p>This section lists a series of 6 public health measures, each of which can be thought of as an independent line of defence, and which collectively form a simplified \u2018Lines of Defence\u2019 pandemic risk management framework.</p><p>The first three lines are the most effective at defending our populations from the pathogen and least intrusive on the public. The last three, beginning with lockdown, are the most intrusive and least effective. We want to solve the problem without having to use the latter lines.</p><p>This is a high-level categorisation to illustrate the ideas, so it is not complete or final. In the real-world, each line would probably be more like a mini-strategy employing multiple measures, rather than being an individual measure or policy, but this is illustrative and the principles are the same irregardless.</p><p>&nbsp;</p><h3><u>1 Surveillance</u></h3><p>Surveillance is our radar for PPPs: it is always active, constantly scanning the planet for new threats, and it will alert us when a PPP has been identified so that we can respond ASAP. The sooner we discover the outbreak, the smaller it will be, and the easier it will be easier to bring it under control. If the PPP is discovered while the outbreak is still geographically limited, then the threat can be eliminated without impacting the vast majority of the world\u2019s population.</p><p>If our surveillance is weak, then the outbreak will have spread further and gained more momentum by the time we discover it. In that scenario, our response will be more complicated, it will consume more of our resources, later lines will need to be activated, and there is a risk that civilian life will be materially impacted. All of this is undesirable, so we should therefore look to implement any measures which can identify the threat sooner.</p><p>Surveillance for PPPs includes sewerage testing and environmental sampling. These methods are unintrusive, anonymous, and can function in the background without disturbing the people. Another option is to offer voluntary testing for influenza, rhinovirusus, RSV and other cold or \u2018flu-like diseases in local health care facilities. This would help to identify the PPP before any cases have to go to an ICU (which is where the PPPs are often discovered).</p><p>A co-ordinated international surveillance system (national collection and international communication) will be one of the key pillars of our future pandemic prevention protocols. It is essential that we expand existing surveillance infrastructure, that we invest in new methods, and that global leaders meet to establish the information sharing agreements needed to build and optimise the system at the global level.</p><p>&nbsp;</p><h3><u>2 Border Controls / Travel Restrictions</u></h3><p>If the global surveillance system alerts us to PPP risk in a foreign country, our first move should be to reduce travel to and from that country (air, rail, road, and foot) until we have greater clarity over the outbreak. On its own, a single bilateral travel ban won\u2019t ensure that a PPP would not enter the country (either directly or via a third country) but it would slow the spread and buy time for domestic policy-makers to handle the outbreak within the public health system.</p><p>Hypothetical experiment: what would happen if, on the discovery of a PPP, every country in the world was to implement a border control on the source region? Then no one would be able to get in or out, so the pathogen wouldn\u2019t be able to get in or out. That region would be in isolation \u2013 as it should be! One of the oldest principles of contagion risk management is that you strive always to keep the infected (and the potentially-infected) away from the susceptible. Border controls serve the same purpose as isolation and quarantine, the only difference is that they do that job at the global level.</p><p>Border controls also benefit from network effects: the more countries use them, the greater their impact. If I import 90% less disease, and I pass on 90% less disease, then my \u2018node\u2019 has transmitted 99% less disease overall. If this dampening effect is multiplied across every node in the system, then border controls alone can send the \u2018international R0\u2019 towards 0, stopping the global outbreak dead in its tracks. From that point on it becomes a domestic problem for the (hopefully) small number of countries infected, and the rest of the world can send their spare medical resources to help.</p><p>Border controls can be extremely effective as an early line of defence, but they must be implemented quickly, they must be targeted at the source region, and they must be co-ordinated internationally. International agreements specifying border control policies during outbreaks of PPPs should be agreed will reduce uncertainty, reduce international political acrimony, and improve the speed and effectiveness our global response. This is a simple co-ordination problem, and it should be solvable. We just need some maturity at the global policy-making level.</p><p>&nbsp;</p><h3><u>3 Test &amp; Trace</u></h3><p>If there is a risk that the PPP may be present in our population (ie if we can\u2019t be sure that it\u2019s <i>not</i> present) then we initiate our test &amp; trace program. Testing finds the PPP, contact tracing tracks down the outbreak, and the rapid isolation of contacts cuts all chains of transmission.</p><p>The more we test, the sooner we\u2019ll find the PPP and the easier it will be to eliminate it. If the PPP is not present in our population, then every negative test result gives us additional confidence that we are in the clear. A robust test &amp; trace program thereby reduces uncertainty around the epidemiology of the outbreak because we can be confident that it will alert us if and when the PPP is present. Until then, the people can get on with their lives as normal.&nbsp;</p><p>Population testing (at departures and arrivals, at health care facilities, in schools, at home, etc) is most easily performed with rapid tests. Contagion is a public health disease and rapid tests are a public health measure: speed, convenience, and volume are worth more than accuracy when testing large numbers of people for contagious diseases. The additional accuracy provided by the Nobel-prize-winning RT-PCR tests may delight the medical nerds, but slow accuracy is little use in a contagion.</p><p>We should prioritise rapid mass production of rapid tests at the earliest stages of an outbreak (<i>not</i> rapid production of novel vaccines) so that nations can find out whether the PPP is present in their populations and start taking control of the situation. If we can produce and distribute enough rapid tests early on (of any kind \u2013 antigen, LAMP, etc) then we won\u2019t need the vaccines.</p><p>&nbsp;</p><h3><u>4 Lockdown / Shelter-At-Home Order</u></h3><p>A lockdown is an extreme public health intervention, and it should only be used in the most extreme circumstances. In general, lockdown = failure, because if a lockdown is required, then there were policy-making errors earlier in the process which led to the current predicament. That said, there is a time and a place for extreme measures \u2013 even within the Lines of Defence approach.</p><p>For example, some kind of shelter-at-home order would likely be necessary around the source of the outbreak. Local officials won\u2019t have much information about the nature of the pathogen at the time nor how far it has spread. Given the potential risks for humanity, this obliges them to be especially cautious (we\u2019re doing Risk Management, not Science). In general, the closer you are to the source of the outbreak, the more likely you are to need strict controls on movement and the longer they will remain in place.</p><p>If the source region has a local shelter-at-home order in place, plus travel restrictions at city and provincial level, plus a national border closure, then they will have created multiple bubbles (or rings of steel) around the epicentre of the outbreak. This \u2018bubbles in bubbles\u2019 effect multiplies the levels of security, and is another example of a Lines of Defence structure in action.</p><p>A lockdown could also be justified outside of the source region. Forcing an entire nation into their homes is not a scenario that I wish to explore, but if the threat was a 1-in-a-1,000-year pathogen, and we had reason to believe that the earlier lines of defence would offer insufficient protection, then a swift, strict, pre-emptive lockdown might be justified. To be effective, the lockdown would need to have a clear rationale plus an estimate of its duration which the public could trust. Uncertainty is a cost and extreme public health measures won\u2019t work without the public\u2019s trust.</p><p>A lockdown anywhere else or at any other time should be regarded as a failure: a failure to plan, a failure to prepare, and a failure to make the right decisions when we had the chance. To ensure humanity\u2019s long-term survival, we must aim to solve these problems long before we need to consider a lockdown. We can\u2019t afford to let these threats get so close to us. We must be more aggressive.</p><p>&nbsp;</p><h3><u>5 Vaccination</u></h3><p>Mass vaccination should be regarded as a last resort when fighting a PPP. Mass vaccination is neither optimal nor desirable, and its weaknesses as a public health measure during an epidemic should be clear for all to see. The fact that so many in the medical establishment think it our primary and most effective tool beggars belief.&nbsp;</p><p>Firstly, if lockdown is failure, vaccination is failure squared. If we need a strict lockdown to stop the pathogen, then we have failed. If it still isn\u2019t enough, and our only remaining option is to design a novel compound, trial it at lower regulatory standards, produce 8 billion doses of it, and distribute them to every corner of the world\u2026 then we have failed again. Vaccination should never be necessary; it always signals failure.</p><p>Secondly, mass vaccination is at terrible long-term strategy because it means we are always defending ourselves at one of our last lines of defence. Why would we do this to ourselves?! When you\u2019re defending yourself so close to home, the margin of error is smaller, and smaller margins of error are not conducive to survival. I might even go as far as to say that the strategy is guaranteed to fail because nature always finds a way \u2013 including a way to evade even the best vaccines (hence the need for more, not <i>fewer</i> lines of defence).</p><p>Thirdly, this strategy assumes that we can produce vaccines that are good enough to end the outbreak. That\u2019s a big assumption. It is only when the vaccine has been distributed to the whole population that we will discover its true population effects. What if it\u2019s weaker than the trial data suggested? What then?</p><p>Finally, the ethical questions around forced vaccinations with novel compounds are considerable. I would expect serious legal challenges, as well as aggressive opposition in the streets. To push the vaccinations through by granting greater emergency powers, or by neutering dissent in the media will only add to the social discord. Even if we could overcome the logistical challenges, it is difficult to see how a mass vaccination strategy could ever engender the trust and goodwill it would need to be effective.</p><p>No. Mass vaccination should only be a last resort in the worst-case scenario.</p><p>&nbsp;</p><h3><u>6 The ICU</u></h3><p>The ICU is our <i>literal</i> last line of defence. If the ICU can\u2019t save the patient, then the patient will die. It is the line between life and death itself.</p><p>There are always calls for greater ICU capacity during outbreaks and bad winters. All else equal, more ICU capacity will save more lives, but expanding ICU capacity in the expectation that it will help us to survive a 1-in-a-1,000-year pathogen is na\u00efve and unhelpful. A highly contagious, highly virulent pathogen will overwhelm every part of the health care system if it isn\u2019t stopped, or at least severely diminished, before it gets there. We need to solve these problems long before they threaten our existing ICU capacity.</p><p>From a long-term perspective, every penny spent on ICU capacity is a penny wasted as it diverts resources away from where they could be more effectively allocated (i.e. the earlier lines of defence). Strengthening our last line of defence does nothing to prevent pandemics and will only ever offer us a false sense of security. Invest in ICU capacity in line with your country\u2019s long-term goals, but thinking that it will help protect humanity from pandemics is like thinking that last fibre of rope will hold the rock-climber\u2019s weight: if you\u2019re down to your last fibre, then you\u2019ve already lost.&nbsp;</p><p>&nbsp;</p><h1>How Would The Lines of Defence Approach Work in Practice?</h1><p>The previous section gives you an idea of how the Lines of Defence approach could be implemented in an individual country. It addresses the inside view: how we defend our ourselves when we are infected. To understand how the Lines of Defence approach would work at a global level we need to take the outside view: we\u2019ll walkthrough an outbreak in a foreign country from the perspective of a country that is not, presumably, infected.</p><p>A full description of a global Lines of Defence pandemic prevention plan is clearly beyond the scope of this post (and the abilities of its author) so this section will present some of the principles that apply, how the process would work, and the kinds of outcomes we could expect.</p><p>&nbsp;</p><h3><u>The Principles</u></h3><p>The closer you are to the centre of the outbreak, the deeper you will need to go into your lines of defence, and quickly too. The further away you are the less you\u2019ll need to do \u2013 especially if the countries nearer the source get their responses right.</p><p>Pandemic risk management scales. The right principles are the right principles at all levels. An individual should isolate themselves when they are infected, and towns, cities, and countries should too.</p><p>The earlier lines in the real-world plan would tend to rely on one set of measures (eg international policy-making) while later lines will rely on others (eg domestic health care infrastructure). No amount of ICU capacity or vaccines can make up for a lack of planning, preparation, and leadership at the policy-making level.</p><p>Pandemic \u2018best practice\u2019 can be incentivised. If the source region implements the right policies, the rest of the world can send medical resources to fight the outbreak and financial compensation afterwards to cover the cost of it. These costs will be trivial when compared to the costs of failure.</p><p>There are network effects to the Lines of Defence approach: the more countries employing this strategy, the more effective it will be. With enough countries are on board, then the PPPs of the future may never leave their source regions.</p><p>&nbsp;</p><h3><u>The Process</u></h3><p>If everyone is focused on surveillance, and we have data sharing agreements in place, then the world will discover the pathogen while the outbreak is small and localised.</p><p>By the principle of scale, the source country goes into isolation and its neighbours (its close contacts) go into quarantine.</p><p>The source country will put multiple rings of steel around the source of the outbreak: key buildings/neighbourhoods, the city, the province, etc as appropriate. If it is a city with an airport then all flights should be grounded. It should also reduce international travel along its busiest routs and to major connecting airports (Singapore, Dubai, Amsterdam, etc).</p><p>Neighbouring countries will restrict travel to and from the source country. They will implement a large testing program to find the pathogen as it is surely present in their populations. Emergency healthcare capacity should be readied wherever possible. Masking, social distancing, and other societal precautions should be encouraged until we have a clear understanding of the pathogen and its epidemiology.&nbsp;</p><p>The rest of the world will take a similar approach to the neighbouring countries, but at a lower level of intensity. Surveillance testing in the population and at ports of entry will be a priority to find the pathogen if it is present and to provide peace of mind if not. Leaders should be getting twice daily briefings on the outbreak. Civilian life continues otherwise as normal.</p><p>In short: the source city immediately goes to DEFCON 5, the source country to DEFCON 4, its neighbours to DEFCON 3, and the rest of the world to DEFCON 1. We all stay on high alert, ready to increase our defences if necessary, and ready to lower them once it is definitely safe to do so.</p><p>&nbsp;</p><h3><u>The Outcomes</u></h3><p>The rapid, targeted, and layered response should all but stop the international spread and smother the outbreak at its source. For all but the most pernicious of PPPs, the combination of early identification, targeted border controls, and robust test &amp; trace programs should ensure that a larger epidemic cannot take hold. Having stemmed the flow at the source, the rest of the world can focus on finding the virus in their populations if present and keeping it out if not.</p><p>Neighbouring countries will need to trace down the imported cases and there are likely to be domestic clusters of transmission too. But with no more cases being imported, that should be a manageable task. Some provinces and cities will be more affected than others, but even the worst-affected areas should have transmission under control within a couple of months.</p><p>Some cases will have leaked to the EU, the USA and a handful of countries on the other side of the world, but they should be few and BAU for a ready and well-resourced public health service. The public health functions within these countries will remain vigilant until the global outbreak is officially over but the people will continue their lives as normal.</p><p>The source country and the source city / province in particular will face the greatest restrictions and for the longest time period. It may be three or four months before the pathogen is eliminated and life returns to normal. That said, the restrictions will be strictest at the start and will gradually ease over the second half of this period.</p><p>Overall, the Lines of Defence approach will minimise the risk of a pandemic taking place, while simultaneously minimising the cost of the outbreak, whether measured in cases, lives, health care resources, time, money, or social unrest. For most countries and most people, the threat will be eliminated at their first line of defence, meaning the global problem can be solved while the vast majority of the world\u2019s population is unaware and unaffected.</p><p>If we had applied this approach to Covid-19, I think the virus would have been identified in November 2019 and the outbreak would have been over by spring 2020. Such is the power of exponentials and the costs of delay when they are working against you.</p><p>&nbsp;</p><h1><u>Conclusion</u></h1><p>The Lines of Defence model is a framework for understanding pandemic risk management in theory and in practice. It establishes our goals, builds our defences in advance, manages the outbreak in the moment, and helps us to communicate our plans and strategies to the public.</p><p>If we can identify the pathogen with our early lines of defence (surveillance, border controls, test &amp; trace) then we can eliminate the threat at minimum cost to society, and we will never need to relay on our later lines of defence (lockdown, vaccines, ICU). The later lines are less effective and require severe intrusions into people\u2019s lives, so these interventions are to be avoided wherever possible.</p><p>The earlier lines of defence require planning, preparation, and diplomacy from senior health officials and politicians. So the Lines of Defence approach depends on competent policy-making at national and global levels and this, I will admit, is a weakness. However, all plans require competent leadership and if we can get China, the USA, and the EU on board, then most of the hard work is done.</p><p>In a linear world, and ounce of prevention is worth a pound of cure, but in an exponential world, it can be worth a tonne of cure - or a thousand! Since prevention and preparation are two sides of the same coin, some competent planning and preparation is all that is needed to improve our pandemic responses by orders of magnitude. Combine that with a Lines of Defence risk management structure, and you should also be able to see that robust, long-term protection from pandemic risk is within humanity's reach.</p><p><strong>\u2618\ufe0f L\u00e1 Fh\u00e9ile P\u00e1draig Sona Daoibh! \u2618\ufe0f</strong></p>", "user": {"username": "PandemicRiskMan"}}, {"_id": "wC5tHG6Lvi3GzJQmP", "title": "Animal Welfare League 2023 Review", "postedAt": "2024-03-18T14:23:00.284Z", "htmlBody": "<p>In this detailed post, we review <a href=\"https://www.animalwelfareleague.org/\">Animal Welfare League\u2019s</a> activities in 2023 and outline our plans for the years ahead. This effort is part of our commitment to knowledge sharing and transparency, providing our partners, donors, and funders with an opportunity to understand our accomplishments, challenges, and strategic decisions and provide feedback.</p><h2>Snapshot of AWL\u2019s 2023</h2><ul><li>We secured two 100% cage-free commitments in Ghana from&nbsp;<a href=\"https://koforiduaguesthotel.com/koforidua-guests-hotel-partners-with-animal-welfare-league-to-source-100-of-the-eggs-we-serve-from-free-range-farms/\"><u>Koforidua Guest\u2019s Hotel</u></a> and&nbsp;<a href=\"https://www.animalwelfareleague.org/blog/grovenest-inn-commits-to-going-cage-free-by-2025\"><u>Grovenest Inn</u></a>, impacting an estimated 10,000 hens by 2025.</li><li>We conducted three egg producer workshops in the Greater Accra, Ashanti, and Eastern regions, bringing together over 132 producers. 93 of whom joined the National Cage-Free Farmers Network, with 33 currently listed in the Directory. This enabled over 350,000 <a href=\"https://www.animalwelfareleague.org/blog/over-350000-laying-hens-committed-to-cage-free-housing\">hens</a>, as reported by the 93 egg producers as their current production, to be committed to cage-free housing that upholds our minimum welfare standards.</li><li>We participated in one television and one radio interview on topics related to animal welfare, with local coverage in the Ashanti region for the radio station and national coverage for the TV station. Additionally, we recruited and trained 25 volunteers from across the country onto our&nbsp;<a href=\"https://www.animalwelfareleague.org/volunteer\"><u>Volunteer Program</u></a>. These volunteers took over 150 social media actions on Linkedin, Facebook, Instagram and X (formerly Twitter) on animal welfare topics, including the OWA Africa Pick n Pay Campaign with over 12,000 impressions.</li><li>\u201cY3 Dawase\u201d, which is \u201cthank you\u201d in Ghanaian Twi, to everyone who supported and engaged us in our work in the previous year. For non-casual readers who want to indulge us can read more for the details below.</li></ul><h1>About Animal Welfare League (AWL)</h1><p>Animal Welfare League is committed to enhancing animal welfare in Ghana, encompassing farmed, aquatic, and wild animals, among others. We strive to fulfil our mission through meticulously designed projects, research initiatives, and community outreach, collaborating with stakeholders, communities, and the government. We have been running our spearheaded project on farmed animal welfare called Cage-Free Project with specific research initiatives, and through volunteers, we conduct community outreach programs.</p><h1>Our work in 2023</h1><h1>Cage-free Project</h1><p>We employ a four-pronged strategy consisting of corporate campaigns, engagement with egg producers, raising consumer awareness, and sequentially advocating for policy to alleviate the suffering of hens in Ghana and across Africa.</p><h3>Corporate Engagement</h3><p>We have established a dynamic database of targeted companies based on egg usage estimates, star categorization, and regional distribution, which currently includes 16 hospitality companies across five regions in Ghana. In 2023, we conducted 16 physical outreach initiatives and held 27 meetings with companies. As a result, two companies committed to transitioning to 100% cage-free sourcing. These two commitments spurred advancements toward cage-free production among their suppliers, that will impact over 10,000 hens by 2025. We then positioned ourselves for future growth by securing corporate training with Amy Odene from&nbsp;<a href=\"https://www.userfriendly.org.uk/\"><u>UserFriendly</u></a><u>. This valuable training program officially commenced in 2024, and will equip us with the skills needed to effectively scale our local and regional cage-free commitments.</u></p><p>Additionally, we initiated collaboration with the <a href=\"https://ghanahotelsassociation.com/\">Ghana Hotels Association</a>, the premier association of hoteliers in Ghana, boasting over 600 members. In partnership with Animal Advocacy Africa and the Open Wing Alliance, we collaborated with Sibanye Animal Welfare and Education for African Animals Welfare to produce an <a href=\"https://www.animaladvocacyafrica.org/blog/running-cage-free-programmes-in-africa-case-studies-of-three-africa-animal-welfare-organizations\">article</a> and <a href=\"https://openwingalliance.org/resources/running-cage-free-projects-webinar\">webinar</a> exploring the unique strategies for conducting cage-free campaigns in Africa.&nbsp;</p><p>&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/wC5tHG6Lvi3GzJQmP/khyivuxhgts5a0zmvrhs\"><i>Dr. Daniel Abiliba, Director of AWL, speaking at a Ghana Hotels Association event at Greater Accra in 2023</i></p><p><br>&nbsp;</p><h3>Egg Producer Engagement</h3><p>Under this arm, we organized three workshops targeting poultry farmers in Ghana's key poultry production zones. These workshops convened over 132 egg producers from the&nbsp;<a href=\"https://www.animalwelfareleague.org/blog/accra-workshop-2023\"><u>Greater Accra</u></a>,&nbsp;<a href=\"https://www.myjoyonline.com/more-poultry-farmers-join-national-cage-free-farmers-network/\"><u>Eastern</u></a>, and&nbsp;<a href=\"https://www.animalwelfareleague.org/blog/awl-kumasi-workshop-report-2023\"><u>Ashanti</u></a> regions. Among them, 93 egg producers joined AWL\u2019s&nbsp;<strong>National Cage-Free Farmers Network</strong>, with 33 successfully certified to be listed in our&nbsp;<strong>National Cage-Free Directory</strong>. The commitments made by these 93 egg producers resulted in the assurance of cage-free housing for&nbsp;over <a href=\"https://www.animalwelfareleague.org/blog/over-350000-laying-hens-committed-to-cage-free-housing\"><u>350,000 layers</u></a>, reflecting the reported production figures at that time. As part of their involvement in the network, egg producers agreed to &nbsp;uphold <a href=\"https://www.animalwelfareleague.org/blog/over-350000-laying-hens-committed-to-cage-free-housing\">our minimum welfare standards</a> including the following terms:</p><ul><li>Abstaining from the use of battery cages or similar practices in production</li><li>Accepting both announced and unannounced farm visits</li><li>Providing periodic updates on production to AWL</li><li>Allowing AWL to share data with companies&nbsp;</li></ul><p>Furthermore, three staff members completed the&nbsp;<a href=\"https://globalfoodpartners.com/academy\"><u>Cage-Free Egg Production</u></a> online modules provided by&nbsp;<a href=\"https://globalfoodpartners.com/\"><u>Global Food Partners</u></a>. This served as an initial step in staff training on cage-free egg production, aligning with our ongoing efforts to facilitate access to training on cage-free egg production for animal advocates and egg producers across Africa.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/wC5tHG6Lvi3GzJQmP/ggzi4irrafynnxzdxxvg\"><i>Aurelia Adhiambo, OWA Africa Coordinator, speaking at AWL\u2019s Egg Producer Workshop in Ashanti region 2023</i></p><p>&nbsp;</p><p>We also conducted farm visits to egg producers who joined the National Cage-Free Farmers Network and Directory. These visits enable us to assess husbandry practices, provide veterinary consultations, and collect farm data. Additionally, we guide farm owners and workers through our rigorous onboarding process and expectations, while also addressing their personalized challenges.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/wC5tHG6Lvi3GzJQmP/wazpkjzrgebd4fk40epo\"><i>AWL team conducting farm visitation at a farm in Greater Accra region in 2023</i></p><p><br>&nbsp;</p><h3>Consumers</h3><p>\u200b\u200bRecognising the critical need to address animal welfare issues considering the high level of neglect in Ghana, we prioritise raising consumer awareness, and so we broadcasted the egg producers' workshops on multiple television channels, including Joy News, Citi Radio, TV3, and Onua TV. Additionally, we conducted interviews on Oyerepa TV, AIT TV, and Focus FM stations to raise public awareness about the mistreatment and welfare issues faced by hens in factory farming. Furthermore, we recruited and provided training to 25 volunteers, increasing the total number of volunteers supporting animal welfare digital activism to 36. These volunteers collectively reported over 150 social media actions, generating over 12,000 impressions across Facebook, Instagram, LinkedIn and Twitter.&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/wC5tHG6Lvi3GzJQmP/dd4w1skxnbqjnna8dymc\"><i>National broadcast report of AWL\u2019s Egg Producers Workshop on Onua TV in 2023</i></p><p>&nbsp;</p><h3>Policy</h3><p>The Veterinary Council of Ghana extended an invitation to the Animal Welfare League to partake in a stakeholder consultation regarding a proposed amendment to the Veterinary Surgeons Law. One component of this proposed amendment involves the formation of an Animal Welfare Committee aimed at tackling animal welfare concerns within Ghana. Even though the process is in the early stages, Animal Welfare League remains committed to advocating for legislation that protects animal welfare.</p><h3>OWA Africa</h3><p>Throughout 2023, we spearheaded the outreach efforts of the Open Wing Alliance Africa organizations to engage with global companies operating in Africa, advocating for global commitments to cage-free practices and regional reporting for their operations within the continent. This entailed conducting outreach to a subset of companies, including Cargill, Nestle, Barry Callebaut, Accor Group, and others, among the 47 targeted companies in 2023. Our objective was to promote accountability and transparency through the implementation of cage-free policies in their operations within Africa.</p><h1><br>Community Outreach</h1><h2>Rabies vaccination</h2><p>In reaction to the culling of dogs suspected of being rabid, we collaborated with the Volta Regional Department of the Veterinary Services Directorate to administer free rabies vaccinations for pets in four communities (Bagble, Ando, Etoe and Gbogame) within the Ho Municipality in the Volta region of Ghana. This vaccination initiative, conducted subsequent to the veterinary department's community sensitization campaigns, resulted in the vaccination of 198 pets (comprising 124 dogs and 74 cats) against rabies.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/wC5tHG6Lvi3GzJQmP/ltdx5c3of8rg86yz1djw\"></p><p><i>Dog vaccination against rabies at Bagble, Volta region, Ghana in 2023</i></p><h1><br>Research</h1><h2>Economic Analysis of Poultry Production Systems in Ghana: Cage-Free vs Battery Cages</h2><p>This study is underway with initial funding from the Tiny Beam Fund. We have engaged two academic researchers from Kwame Nkrumah University of Science and Technology to conduct a thorough examination of the Ghanaian poultry industry. The aim is to gather comprehensive economic data on both battery cage and cage-free systems, facilitating a direct comparison between the two. Additionally, the study will estimate the costs associated with transitioning from caged to cage-free systems in Africa.</p><h2>Awareness, Attitude and Knowledge of Animal Welfare Among School Children in Ghana:</h2><p>We have conducted preliminary research involving over 1,600 pupils from sixteen schools across eight regions in Ghana. The aim was to assess the awareness, attitudes, and knowledge of school children regarding animal welfare. This information will be used to inform our humane education project. The report summarising the findings of the research this year.</p><p>&nbsp;</p><h1>Programs, Conferences &amp; Events</h1><ul><li>In 2023, we participated in a total of four conferences and three other events, including<ul><li>AVA US 2023</li><li>OWA Africa Summit 2023</li><li>ANAW West Africa Cage-Free Chicken Conference 2023</li><li>Lead for Animals 2023</li><li>EAG Virtual 2023</li><li>EAG Boston 2023</li></ul></li><li>We contributed two articles to the EA Forum, authored one article for the ACE blog, and received mentions in several newsletters, including those from Impactful Animal Advocacy, Open Wing Alliance, and Animal Advocacy Africa.</li><li>We were accepted into the inaugural Monitoring, Evaluation, and Learning program hosted by Mission Motor, with the participation of two of our staff members.</li><li>We were accepted into the inaugural Advocate Training program organised by Animal Advocacy Africa, with the participation of one staff member and one volunteer.</li><li>We established a fiscal sponsorship with&nbsp;<a href=\"https://awellfedworld.org/\"><u>A Well-Fed World</u></a> for lump-sum donations in the US</li><li>We secured a partnership with&nbsp;<a href=\"https://www.scarletspark.org/\"><u>Scarlet Spark</u></a> for a leadership training program for our staff, scheduled to take place in the second quarter of 2024</li><li>We joined the&nbsp;<a href=\"https://www.fao.org/antimicrobial-resistance/quadripartite/the-platform/en/\"><u>AMR Multi-Stakeholder Partnership Platform</u></a> led by the Quadripartite organisations as a civil society organisation stakeholder from Ghana.</li></ul><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/wC5tHG6Lvi3GzJQmP/ldaz8s2d5y0dtiewjzic\"></p><p><i>Dr. Richard Dogbatse, Community Affairs at AWL speaking at ANAW West Africa Cage-Free Chicken Conference 2023.</i></p><p><br>&nbsp;</p><h1>Things We Would Like to See Happening in Africa</h1><p>We are interested in seeing more&nbsp;<strong>research</strong> on economics and financial aspects, government and policy, consumption and demand, and long-term public awareness interventions. Specifically:</p><ul><li>We would like to see research on developing effective mass media awareness campaigns in African countries.</li><li>What kinds of strategies and messaging would convince decision-makers at public institutions in Africa to reduce the proportion of animal-based food products served at their facilities and events?</li><li>Conduct review of national legislation on animal welfare and national food standards of animal products to identify policy and enforcement gaps.&nbsp;</li><li>How much funding is coming from international donors and intergovernmental organisations to further intensify industrial animal agriculture in Africa?</li><li>What are the biggest welfare issues for farmed fish in semi-intensive farming systems in Africa?</li><li>We would like to see&nbsp;<strong>training and support</strong> programs specifically dedicated to farmed animal advocacy in Africa. Specifically, we are interested in seeing training on cage-free egg production for advocates, egg producers, and policymakers, as previously outlined in \"<a href=\"https://forum.effectivealtruism.org/posts/SmKLaLPsogwtFs6WT/why-africa-needs-a-cage-free-model-farm-and-producer-s\"><u>Why Africa Needs A Cage-Free Model Farm</u></a>.\" Additionally, we are keen on seeing training and support on fundraising, project management, monitoring, and evaluation, among other topics discussed more regularly. We aim to see more organisations like our partner Animal Advocacy Africa.</li></ul><p>We would like to see more conscious efforts in&nbsp;<strong>movement building</strong> within the continent, particularly in the effective animal advocacy space. We aim to see a greater number of regional events and conferences focused on advancing the movement in Africa.</p><p>We would like to see more concerted efforts to support&nbsp;<strong>knowledge sharing</strong> within the movement in Africa. While this goal can be addressed through previous initiatives mentioned, we believe that focusing on cultivating the habit and establishing appropriate avenues for knowledge sharing within the region is of utmost importance.</p><h1>Our Goals for 2024</h1><h2>Cage-free Project</h2><ul><li>On corporations, we expect to expand our scope to include restaurants and secure at least three cage-free commitments.&nbsp; As one of the newly appointed strategic leaders, we aim to collaborate closely with OWA Africa organisations on Africa campaigns with the goal of getting at least one country-level reporting of Kempinski hotels cage-free progress in Africa as well as initiate the development of an accountability tool.</li><li>On egg producers, we intend to conduct two regional workshops in high poultry production zones in Ghana, with the goal of admitting at least 80 more egg producers into our Network and Directory impacting at least 200,000 hens per year. Additionally, we plan to update our strategy to incorporate distributors into this aspect of our work.</li><li>On consumers, We aim to conduct mass media awareness campaigns utilising popular television and radio stations in Ghana.</li><li>On policy, We aim to continue our active engagement as stakeholders on animal welfare-related policies in Ghana as well as conducting research in collaboration with other organisations.</li></ul><h2>Community Outreach</h2><ul><li>We expect to establish university clubs under our volunteer program.&nbsp;</li><li>We aim to support the integration and transition from animal agriculture to plant-based agriculture among smallholder farmers.&nbsp;</li><li>We plan to introduce guest blog invitations for content that aligns with our interests.</li></ul><h2>Research</h2><ul><li>We aim to release all research reports and disseminate the findings to the appropriate stakeholders.&nbsp;</li><li>We aim to collaborate with&nbsp;<a href=\"https://www.animalask.org/\"><u>Animal Ask</u></a> to conduct research on animal welfare policies and legislation in Ghana.&nbsp;</li><li>We plan to introduce essay contests, inviting submissions on specific topics regarding farmed animal welfare in Africa.</li></ul><h1><br>&nbsp;Organisation</h1><h2>Budget and financial information</h2><p>In 2023, our total expenses amounted to USD 51,967. The majority of our funding continued to be sourced from philanthropic funds and contributions from individual donors, with a significant portion coming from multiple individuals within the effective altruism and animal welfare/rights movements.</p><h2>Our staff and operations</h2><p>In 2023, we had four staff members who received regular compensation, and we added a new member in December 2023 to handle communications. Due to the fact that over 80% of funds raised in 2023 were directed toward project activities, we were only to provide stipends instead of salaried wages. We are actively fundraising in 2024 to be able to pay our staff competitive salaries.</p><h1>Mistakes&nbsp;</h1><ul><li>We delayed transitioning to other components of our physical outreach strategy, such as networking and collaborating with industry groups, to allow more time for feedback on the physical pop-ins at company facilities. However, we promptly addressed this in the last quarter of 2023 and began collaborating with the Ghana Hotels Association on corporate commitments.</li><li>Feedback from the first workshop in the Greater Accra region indicated dissatisfaction with the duration of the workshop. A postmortem analysis of the workshop also highlighted the importance of travelling to workshop venues well in advance and hiring local dialect translators. We have since implemented these changes and will continue to make adaptations based on feedback.</li><li>We raised a significant amount of funds primarily for project activities, with limited funds allocated for overhead costs. During our annual retrospective and planning meeting, all staff identified compensation as an area for improvement.</li></ul><h1>How you can help</h1><ul><li>We invite funders, donors, organisations, and researchers to support, collaborate with, and enable our work to prevent the suffering of millions of farmed animals in Ghana and across Africa. Currently, we have a funding gap of $46,500, despite having fundraised over 80% of our budget for 2024. You can support us by making a tax-deductible donation in the US to our fiscal sponsor,&nbsp;<a href=\"https://awellfedworld.org/\"><u>A Well-Fed World,</u></a> or through the&nbsp;<a href=\"https://www.animaladvocacyafrica.org/\"><u>Animal Advocacy Africa</u></a> Regranting Program.</li><li>We are a very young organisation and operate in a geographical location with unique and diverse challenges. We always appreciate an opportunity to improve and achieve a bigger impact; hence, if you see flaws in our thinking or planning, please reach out. We always strive to do better.&nbsp;</li><li>If you haven\u2019t already, you can sign up to our <a href=\"http://eepurl.com/iJble6\">newsletter</a> or follow us on social media (<a href=\"https://www.linkedin.com/company/animal-welfare-league/\"><u>LinkedIn</u></a> and&nbsp;<a href=\"https://www.instagram.com/ghanimal_welfare_league/\"><u>Instagram</u></a>) to stay up to date about our progress.</li><li>If you haven't already, you can sign up for our newsletter or follow us on social media (<a href=\"https://www.linkedin.com/company/animal-welfare-league/\"><u>LinkedIn</u></a> and&nbsp;<a href=\"https://www.instagram.com/ghanimal_welfare_league/\"><u>Instagram</u></a>) to stay up-to-date about our progress.</li></ul><h1>Y3 Dawase (\u201cThank You\u201d in Ghanaian Twi)&nbsp;</h1><p>We extend a big thank you to everyone who enabled us to make progress in our work and achieve the impacts we have made. In particular, this includes our donors, advisors, and our friends and family who support us in working for this cause. Some listed below</p><ul><li>Animal Advocacy Africa</li><li>School of Veterinary Medicine - KNUST</li><li>Ghana National Association of Poultry Farmers</li><li>Open Wing Alliance</li><li>Sharpen Strategy</li><li>Mercy for Animals</li><li>Haven King-Nobles &amp; Friends</li><li>Ghana Hotels Association</li><li>The Motor Mission</li><li>The Ribon<br>&nbsp;</li></ul><p><i>We value the contributions of everyone who has been in contact with us regarding our work and apologise for not including your name here as we cannot list everyone's name.&nbsp;</i></p>", "user": {"username": "Animal Welfare League "}}, {"_id": "6HdtuxNymiHpczc4w", "title": "Lab Collaboration on AI Safety Best Practices ", "postedAt": "2024-03-17T12:20:57.378Z", "htmlBody": "<p>This draft report doesn\u2019t have many actionable insights, and is &gt;5000 words, so I don\u2019t recommend that many people read it. It might be interesting to anyone considering collaboration on standards at AI labs. The report isn\u2019t necessarily an endorsement of the view that improving lab standards is one of the best courses of action in AI governance. I\u2019m open to the idea that trying to make the current lab development paradigm safer may be the least bad option, and also open to the idea that some form of globally coordinated pause and/or international exclusive AGI research institution could be a better option.</p><h3 data-internal-id=\"Short_Summary\">Short&nbsp;Summary</h3><p>Recent&nbsp;steps which facilitate coordination on safety practices in the AI industry, such as the creation of the Frontier Model Forum and the US AI Safety Institute Consortium, are promising, but there\u2019s still room for improvement.</p><p>Openly&nbsp;publishing information on safety practices where possible is typically the most beneficial approach for industry-wide safety, as the information is made available to the greatest number of people. In cases where this isn\u2019t desirable, such as with practices which entail higher collaboration risk, other forms of collaboration are also recommended, such as jointly developing best practices within an industry body.</p><p>Most of the examined safety practices (risk assessments, red teaming, third-party audits, incident reporting, segregation of duties background checks) were judged to have low downside risk from collaboration&nbsp;but some (model evaluations, alignment techniques, cybersecurity) may entail higher risks.</p><p>The&nbsp;most significant potential drawback&nbsp;of collaboration from an existential safety perspective is the connection between safety and capabilities advancement. The most significant potential drawbacks from an individual lab perspective are several legal issues such as liability and antitrust violations.</p><p>The&nbsp;potential impact of collaboration on safety practices on the reduction of extreme risks from AI systems could be greater than safety improvements at just one lab, but this depends on the number of frontier labs and their willingness to improve their safety practices.</p><p>The key recommendations of this report are: to pay more attention to collaboration and be more willing to i) engage in it and ii) fund it; to employ different methods of collaboration based on the needs of individual safety practices.</p><h3 data-internal-id=\"Longer_Summary\">Longer&nbsp;Summary</h3><p data-internal-id=\"ftnt_ref5\">As a rapidly emerging general-purpose technology with the potential to transform the economy and boost technological progress, artificial intelligence heralds unprecedented opportunities, alongside societal and civilisational risks. The governance of AI has been discussed at the highest levels of national and international institutions<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"1\" data-footnote-id=\"g0e2cwukjd\" role=\"doc-noteref\" id=\"fnrefg0e2cwukjd\"><sup><a href=\"#fng0e2cwukjd\">[1]</a></sup></span><span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"2\" data-footnote-id=\"vrfieyshfs\" role=\"doc-noteref\" id=\"fnrefvrfieyshfs\"><sup><a href=\"#fnvrfieyshfs\">[2]</a></sup></span><span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"3\" data-footnote-id=\"2f9u9r3exi2\" role=\"doc-noteref\" id=\"fnref2f9u9r3exi2\"><sup><a href=\"#fn2f9u9r3exi2\">[3]</a></sup></span><span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"4\" data-footnote-id=\"40st1k44ctl\" role=\"doc-noteref\" id=\"fnref40st1k44ctl\"><sup><a href=\"#fn40st1k44ctl\">[4]</a></sup></span>, but it is still a very young field, lacking rigorous safety practices and in some cases any safety practices at all. In this context, despite the unique nature of AI, it may be relevant to examine how firms collaborate on safety practices<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"5\" data-footnote-id=\"xulzobuhtx\" role=\"doc-noteref\" id=\"fnrefxulzobuhtx\"><sup><a href=\"#fnxulzobuhtx\">[5]</a></sup></span>&nbsp;in other industries, and how frontier AI labs might improve on this aspect going forward.</p><p>The report begins by taking a look at how collaboration on safety practices occurs in the aviation, energy, pharmaceutical and cybersecurity industries. It then moves on to examine contemporary safety collaboration in the AI industry, before discussing the methods of collaboration identified in the preceding sections. The report then introduces various practices which may benefit from collaboration, some potential drawbacks of collaboration, and measures which may mitigate them. Finally, the potential impact on AI safety is discussed.</p><p>The report concludes that recent steps which facilitate coordination on safety practices in the AI industry are promising, but there\u2019s plenty of room for improvement. An examination of collaboration on safety practices in other sectors demonstrates that frontier AI labs could, for example, publish more safety practices, participate in more safety-focused events and form international industry bodies.</p><p>The report also argues that openly publishing information on safety practices where possible is typically the most beneficial approach for industry-wide safety, and in cases where this isn\u2019t desirable, other forms of collaboration are also recommended. Labs which consider themselves to be utilising industry-leading safety practices should therefore seek to publish them in sufficient detail that they can be emulated, or share their knowledge through another channel in cases where publishing best practices may entail risks for the sharing company or the public as a whole.</p><p>Most of the safety practices were judged to have low downside risk from collaboration. The practices which entail lower collaboration risk include risk assessments, red teaming, third-party audits, incident reporting, segregation of duties and background checks. Best practices in these areas can typically be shared widely, for example through publishing the information or sharing it within a large industry body.</p><p>Practices with higher collaboration risk, such as model evaluations, alignment techniques, and cybersecurity, likely require a more nuanced approach to collaboration, and in many cases sharing best practices in these areas should be done on a more exclusive basis, such as directly or within a more exclusive industry body. The practicalities of how collaboration on each safety practice might take place could be researched further.</p><p>The most significant potential drawback of collaboration from an x-risk-reduction perspective is the connection between safety and capabilities research. The most significant potential drawbacks from an individual lab perspective are legal complications such as liability and antitrust violations. Potential mitigations are discussed, and it seems like the potential benefits of collaboration outweigh the potential drawbacks. However, further study of particular drawbacks could provide more clarity on this issue.</p><p>The potential impact of collaboration on safety practices on the reduction of extreme risks from AI systems is judged to be substantial. From the perspective of individual labs it is likely to be as significant as unilateral improvements in safety practices within those labs, and from the perspective of the industry as a whole the impact on safety is likely to be greater than improvements at just one firm. The question of how to ensure that best practices in AI safety swiftly propagate across the industry should therefore be a prominent one which safety researchers, labs and regulators alike should seek to answer alongside developing the actual practices.</p><h3 data-internal-id=\"Practices_which_may_benefit_from_collaboration\">Practices which may benefit from collaboration</h3><p data-internal-id=\"ftnt_ref6\"><strong>Risk assessment</strong>&nbsp;involves the identification and analysis of risks. There are existing best practices for risk assessment in other industries which could be coordinated upon by AI companies<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"6\" data-footnote-id=\"23e6kz5faru\" role=\"doc-noteref\" id=\"fnref23e6kz5faru\"><sup><a href=\"#fn23e6kz5faru\">[6]</a></sup></span>. Additionally, new forms of risk assessment tailored to the unique risks arising from advanced AI systems will likely have to be developed, and this may be a task which is particularly suitable for collaboration among frontier AI labs.</p><p data-internal-id=\"ftnt_ref7\"><strong>Model evaluations (evals)</strong>&nbsp;is a rapidly growing area of safety research which involves designing experiments to test the properties and outputs of AI models in different circumstances<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"7\" data-footnote-id=\"yaz6m18mhl\" role=\"doc-noteref\" id=\"fnrefyaz6m18mhl\"><sup><a href=\"#fnyaz6m18mhl\">[7]</a></sup></span>. Safety evals have received significant attention from leading AI companies and even governments (citations) but best practices have yet to be established, and the way in which evals are conducted at different labs varies considerably. Model evals is another area which is ripe for cooperation, although in some cases it may alert labs to dangerous but commercially useful capabilities. On the other hand, establishing best practices for evals could reduce risks that an evals process itself produces a catastrophic scenario.</p><p data-internal-id=\"ftnt_ref10\"><strong>Red teaming</strong>&nbsp;involves actively trying to elicit harmful model outputs, within a controlled environment, thus alerting developers to issues with the model and enabling solutions to be applied<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"8\" data-footnote-id=\"dl46oeyps1q\" role=\"doc-noteref\" id=\"fnrefdl46oeyps1q\"><sup><a href=\"#fndl46oeyps1q\">[8]</a></sup></span>. This is already carried out by all frontier labs<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"9\" data-footnote-id=\"ul9872809l\" role=\"doc-noteref\" id=\"fnreful9872809l\"><sup><a href=\"#fnul9872809l\">[9]</a></sup></span><span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"10\" data-footnote-id=\"tynizdtt1y\" role=\"doc-noteref\" id=\"fnreftynizdtt1y\"><sup><a href=\"#fntynizdtt1y\">[10]</a></sup></span>, but similarly to evals there are no established best practices across different labs.</p><p data-internal-id=\"ftnt_ref11\"><strong>Third-party audits</strong>&nbsp;entail the auditing of an AI model by external assessors. This can incorporate \u2018a wide range of existing tools and methods, such as impact assessments, benchmarking, model evaluation, and red teaming, to conduct governance, model, and application audits\u2019<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"11\" data-footnote-id=\"kpvrsw4j3t\" role=\"doc-noteref\" id=\"fnrefkpvrsw4j3t\"><sup><a href=\"#fnkpvrsw4j3t\">[11]</a></sup></span>. Collaboration around the audits themselves may be a task for the auditors and other researchers, but the optimal ways to incorporate external audits into the development process is a potential area for collaboration among AI firms.</p><p data-internal-id=\"ftnt_ref12\">Some advances in broad <strong>alignment techniques</strong>, such as mechanistic interpretability and agent foundations<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"12\" data-footnote-id=\"138p0f2qz1z\" role=\"doc-noteref\" id=\"fnref138p0f2qz1z\"><sup><a href=\"#fn138p0f2qz1z\">[12]</a></sup></span>, could lead to improved model safety if widely shared, as they would give developers at different labs a better insight into how their models function. However, these advancements would be difficult to separate from subsequent capabilities growth, and it\u2019s also unclear if firms would be incentivised to share their findings as they may provide significant advantages to the discoverer.</p><p><strong>Cybersecurity</strong>&nbsp;is a field which already boasts significant cooperation on best practices. However, the specific measures required to protect AI models may necessitate new methods. Relatedly, espionage avoidance will be critical to prevent AI model theft. This is something which most leading firms would benefit from collaborating on, and would likely be straightforwardly beneficial from an extreme risk reduction standpoint.</p><p><strong>Incident reporting</strong>&nbsp;involves informing a relevant state actor, other AI labs, and potentially the public whenever a safety incident occurs. There are various existing approaches, and this seems like another area where coalescing around particular best practices would be obviously beneficial.</p><p><strong>Segregation of duties</strong>&nbsp;refers to the division of knowledge, division of authorization, division of duties, and implementation of multi-level approval protocols, so that no individual can alter, deploy or leak a model against the wishes of the company. This seems like it would have mainly upsides in terms of safety, but could slightly hamper a firm\u2019s efficiency if more employees have to coordinate on certain tasks. Establishing best practices would allow labs to mitigate inefficiencies, and cooperation on this segregation of duties would have no obvious downsides.</p><p data-internal-id=\"ftnt_ref14\"><strong>Background checks</strong>&nbsp;are examinations of someone\u2019s criminal record, employment history, and other potentially relevant information, and are conducted in many industries especially when hiring for senior positions<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"13\" data-footnote-id=\"watutugqhk\" role=\"doc-noteref\" id=\"fnrefwatutugqhk\"><sup><a href=\"#fnwatutugqhk\">[13]</a></sup></span>. Know-your-customer (KYC)<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"14\" data-footnote-id=\"m70ygjlyt\" role=\"doc-noteref\" id=\"fnrefm70ygjlyt\"><sup><a href=\"#fnm70ygjlyt\">[14]</a></sup></span>&nbsp;is a typically less demanding form of background check which firms in many industries require their customers to complete. Best practices could be established with regards to employees at AI firms and customer access to AI models.</p><h3 data-internal-id=\"Case_studies_of_Collaboration_on_Safety_Practices_in_Other_Sectors\">Case studies of Collaboration on Safety Practices in Other Sectors</h3><p><strong>Aviation</strong></p><p data-internal-id=\"ftnt_ref15\">The aviation industry is notable for its focus on safety, and in the last half-century has transitioned from a peak of 72 civil aviation crashes and around 3200 fatalities in 1972, to an average of 14.5 crashes and 409 fatalities in a typical year during the past decade<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"15\" data-footnote-id=\"pqns36744f7\" role=\"doc-noteref\" id=\"fnrefpqns36744f7\"><sup><a href=\"#fnpqns36744f7\">[15]</a></sup></span>. This safety culture is one which AI probably needs to aspire to or indeed exceed, at least in terms of capabilities which threaten extreme risks.</p><p data-internal-id=\"ftnt_ref17\">Airlines cooperate in a number of ways to enhance sector-wide safety, such as through the sharing of aviation data. For example, the US Federal Aviation Administration and the aviation community operate the Aviation Safety Information Analysis and Sharing (ASIAS) program<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"16\" data-footnote-id=\"5mkaw8ve1iu\" role=\"doc-noteref\" id=\"fnref5mkaw8ve1iu\"><sup><a href=\"#fn5mkaw8ve1iu\">[16]</a></sup></span>, an information-sharing partnership aimed at improving the assessment of safety risks. Internal hazard reporting databases, automated flight operations quality assurance technology and internal mentorship programs also \u2018help everyone learn from the mistakes of others\u2019<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"17\" data-footnote-id=\"4salzujendm\" role=\"doc-noteref\" id=\"fnref4salzujendm\"><sup><a href=\"#fn4salzujendm\">[17]</a></sup></span>.</p><p data-internal-id=\"ftnt_ref18\">Airlines also sometimes collaborate through industry initiatives such as the Common Aviation Risk Models (CARM) stakeholder group, which features the involvement of many airlines<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"18\" data-footnote-id=\"m7kshf5tp7k\" role=\"doc-noteref\" id=\"fnrefm7kshf5tp7k\"><sup><a href=\"#fnm7kshf5tp7k\">[18]</a></sup></span>. Air France and Air Transat worked together to develop bow-tie models which help to proactively identify and manage weaknesses in the aviation system.</p><p data-internal-id=\"ftnt_ref22\">Multiple events take place each year during which aviation representatives from across the industry come together to share best practices and learn from others. These include the jointly-hosted Evidence based training \u2013 Competency Based Training Assessment Workshop organised by Emirates and the International Air Transport Association (IATA) which focused on pilot training<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"19\" data-footnote-id=\"vs4b2d2gw7c\" role=\"doc-noteref\" id=\"fnrefvs4b2d2gw7c\"><sup><a href=\"#fnvs4b2d2gw7c\">[19]</a></sup></span>, the annual Safety Forum organised by the Flight Safety Foundation (FSF) which discussed topics such as regulation, training and safety culture<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"20\" data-footnote-id=\"ozwbkesqcph\" role=\"doc-noteref\" id=\"fnrefozwbkesqcph\"><sup><a href=\"#fnozwbkesqcph\">[20]</a></sup></span>, the Global Aerospace Summit which focused on standardised curricula and sharing of best practices across the top four preventable accident categories<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"21\" data-footnote-id=\"usyfwhcd5vh\" role=\"doc-noteref\" id=\"fnrefusyfwhcd5vh\"><sup><a href=\"#fnusyfwhcd5vh\">[21]</a></sup></span>, and the International Aviation Safety Conference which examined how to ensure safety while transitioning to more environmentally sustainable practices<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"22\" data-footnote-id=\"xbxfvjmiljg\" role=\"doc-noteref\" id=\"fnrefxbxfvjmiljg\"><sup><a href=\"#fnxbxfvjmiljg\">[22]</a></sup></span>. Compared to AI, the aviation industry appears to hold more general safety events and lots of specific niche events, which one might expect in a more established safety-focused industry.</p><p data-internal-id=\"ftnt_ref25\">Airline representatives also often publish safety practices and other research findings in industry journals and magazines, such as Aero Safety World<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"23\" data-footnote-id=\"6d87hnkw7jb\" role=\"doc-noteref\" id=\"fnref6d87hnkw7jb\"><sup><a href=\"#fn6d87hnkw7jb\">[23]</a></sup></span>, the Air Line Pilot Magazine<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"24\" data-footnote-id=\"i5e44s3b27\" role=\"doc-noteref\" id=\"fnrefi5e44s3b27\"><sup><a href=\"#fni5e44s3b27\">[24]</a></sup></span>&nbsp;and the Journal of Airline Operations and Aviation Management (JAOAM)<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"25\" data-footnote-id=\"vt2xnqmmo9m\" role=\"doc-noteref\" id=\"fnrefvt2xnqmmo9m\"><sup><a href=\"#fnvt2xnqmmo9m\">[25]</a></sup></span>.</p><p><strong>Energy</strong></p><p data-internal-id=\"ftnt_ref27\">A common way in which companies in the energy sector collaborate on safety is through industry bodies. The World Association of Nuclear Operators<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"26\" data-footnote-id=\"cfof8augei9\" role=\"doc-noteref\" id=\"fnrefcfof8augei9\"><sup><a href=\"#fncfof8augei9\">[26]</a></sup></span>&nbsp;is primarily made up of owners and operators of nuclear power plants, whose objective is to \u2018assess, benchmark and improve performance through mutual support, exchange of information, and emulation of best practices.\u2019 Similarly, the Institute of Nuclear Power Operators (INPO)<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"27\" data-footnote-id=\"b2b77pejqsb\" role=\"doc-noteref\" id=\"fnrefb2b77pejqsb\"><sup><a href=\"#fnb2b77pejqsb\">[27]</a></sup></span>&nbsp;enables nuclear utilities companies \u2018to promptly share important information, including operating experience, operational performance data, and information related to the failure of equipment that affects safety and reliability. The industry also actively encourages benchmarking visits to support the sharing of best practices and the concepts of emulation and continuous improvement.\u2019 Following the 2010 Deepwater Horizon oil spill, the American Petroleum Institute launched the Center for Offshore Safety (COS), incorporating many leading firms in the oil and gas sector, who are encouraged to develop new safety programs which are then assessed by third-party auditors<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"28\" data-footnote-id=\"5kjze8qvahu\" role=\"doc-noteref\" id=\"fnref5kjze8qvahu\"><sup><a href=\"#fn5kjze8qvahu\">[28]</a></sup></span>. The Global Wind Organisation (GWO)<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"29\" data-footnote-id=\"jgxu5t4s8ej\" role=\"doc-noteref\" id=\"fnrefjgxu5t4s8ej\"><sup><a href=\"#fnjgxu5t4s8ej\">[29]</a></sup></span>&nbsp;is a non-profit formed by North America\u2019s leading wind power companies, \u2018responsible for a portfolio of training standards designed for the industry, by the industry\u2019. The energy sector isn\u2019t especially similar to the AI sector, but the AI sector nonetheless could take inspiration from the function of industry bodies in the energy sector.</p><p data-internal-id=\"ftnt_ref32\">The World Nuclear Symposium is an annual conference where nuclear industry professionals exchange insight on safety and other topics<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"30\" data-footnote-id=\"lw7wel5ls2a\" role=\"doc-noteref\" id=\"fnreflw7wel5ls2a\"><sup><a href=\"#fnlw7wel5ls2a\">[30]</a></sup></span>. The International Petroleum Technology Conference (IPTC)<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"31\" data-footnote-id=\"0b3i8j4y1k1m\" role=\"doc-noteref\" id=\"fnref0b3i8j4y1k1m\"><sup><a href=\"#fn0b3i8j4y1k1m\">[31]</a></sup></span>, attended by members of the International Association of Oil and Gas Producers, is \u2018focused on the dissemination of new and current technology, best practices and multi-disciplinary activities.\u2019 The Offshore Technology Conference (OTC)<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"32\" data-footnote-id=\"fukz0ok8brl\" role=\"doc-noteref\" id=\"fnreffukz0ok8brl\"><sup><a href=\"#fnfukz0ok8brl\">[32]</a></sup></span>&nbsp;brings together tens of thousands of attendees to learn and share insights regarding the enhancement of safety management.</p><p data-internal-id=\"ftnt_ref34\">Like other examined sectors, firms in the energy sector often discuss their safety practices in whitepapers or industry journals. For example, the journal Energy Global publishes&nbsp;whitepapers on various topics such as best practices for worker safety<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"33\" data-footnote-id=\"rm1ar4p1s9a\" role=\"doc-noteref\" id=\"fnrefrm1ar4p1s9a\"><sup><a href=\"#fnrm1ar4p1s9a\">[33]</a></sup></span>. Another way in which firms in various sectors including the energy sector share their approaches to safety is through their own blogs, such as Hart Energy\u2019s distillation of a session on learning before accidents take place<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"34\" data-footnote-id=\"qcqwf83cd\" role=\"doc-noteref\" id=\"fnrefqcqwf83cd\"><sup><a href=\"#fnqcqwf83cd\">[34]</a></sup></span>.</p><p>I was unable to find examples of direct collaboration between energy firms on safety practices, as this mostly seems to take place with the involvement of an industry body.</p><p><strong>Pharmaceutical</strong></p><p data-internal-id=\"ftnt_ref36\">The International Federation of Pharmaceutical Manufacturers &amp; Associations (IFPMA) represents the pharmaceutical industry in official relations with the United Nations<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"35\" data-footnote-id=\"n8fcsr7fmyp\" role=\"doc-noteref\" id=\"fnrefn8fcsr7fmyp\"><sup><a href=\"#fnn8fcsr7fmyp\">[35]</a></sup></span>. In addition to setting global standards, the IFPMA facilitates discussions or workshops where member companies can share insights and strategies for implementing GMP and GDP standards\u200b. Another industry body, the Pharmaceutical Research and Manufacturers of America (PhRMA), also facilitates collaboration among members on manufacturing processes, supply chain management, and ensuring compliance with regulatory requirements<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"36\" data-footnote-id=\"l3ktsy2eht\" role=\"doc-noteref\" id=\"fnrefl3ktsy2eht\"><sup><a href=\"#fnl3ktsy2eht\">[36]</a></sup></span>\u200b.</p><p data-internal-id=\"ftnt_ref39\">The Drug Safety Symposium is a conference at which pharmacovigilance professionals meet to share principles, best practices, sources of information, the merits of current methods, and potential future challenges<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"37\" data-footnote-id=\"fpt7c22meo8\" role=\"doc-noteref\" id=\"fnreffpt7c22meo8\"><sup><a href=\"#fnfpt7c22meo8\">[37]</a></sup></span>. The CDISC Interchange is a triannual event which discusses standards for sharing and reusing data within the pharmaceutical community. Attendees are expected to share expertise and ideas with colleagues and partners from across the industry<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"38\" data-footnote-id=\"qm3yy7y08fn\" role=\"doc-noteref\" id=\"fnrefqm3yy7y08fn\"><sup><a href=\"#fnqm3yy7y08fn\">[38]</a></sup></span>. Reuters Events Pharma<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"39\" data-footnote-id=\"m235lns7jl\" role=\"doc-noteref\" id=\"fnrefm235lns7jl\"><sup><a href=\"#fnm235lns7jl\">[39]</a></sup></span>&nbsp;is an event for senior professionals throughout the pharmaceutical industry, at which attendees can exchange ideas and experiences, and understand how other firms solve problems. This again unsurprisingly equates to more safety-focused events in the more established pharmaceutical sector.</p><p data-internal-id=\"ftnt_ref42\">Direct collaboration between rivals in the pharmaceutical industry appears to be uncommon, although there are examples of collaboration involving companies in different sub sectors, such as during the Covid pandemic<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"40\" data-footnote-id=\"57tkchyeuna\" role=\"doc-noteref\" id=\"fnref57tkchyeuna\"><sup><a href=\"#fn57tkchyeuna\">[40]</a></sup></span>. However, pharmaceutical companies often publicly share the results of clinical trials<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"41\" data-footnote-id=\"16839cqvpva\" role=\"doc-noteref\" id=\"fnref16839cqvpva\"><sup><a href=\"#fn16839cqvpva\">[41]</a></sup></span>, and best practices within the health sector are often discussed at industry conferences, workshops and in medical journals<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"42\" data-footnote-id=\"ndquwuy4o9h\" role=\"doc-noteref\" id=\"fnrefndquwuy4o9h\"><sup><a href=\"#fnndquwuy4o9h\">[42]</a></sup></span>.</p><p><strong>Cybersecurity</strong></p><p data-internal-id=\"ftnt_ref45\">The cybersecurity industry is home to a plethora of industry bodies under whose auspices cooperation on safety practices occurs. These include the Cybersecurity Tech Accord<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"43\" data-footnote-id=\"03kprgjd7x1t\" role=\"doc-noteref\" id=\"fnref03kprgjd7x1t\"><sup><a href=\"#fn03kprgjd7x1t\">[43]</a></sup></span>, under which signatories work alongside each other and adjacent groups to improve cybersecurity best practices, the European Union Information Sharing and Analysis Centers (ISACs)<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"44\" data-footnote-id=\"xte2rgd79nl\" role=\"doc-noteref\" id=\"fnrefxte2rgd79nl\"><sup><a href=\"#fnxte2rgd79nl\">[44]</a></sup></span>&nbsp;which allow \u2018Knowledge on tackling cyber attacks, incident response, mitigation measures and preparatory controls [to] be shared between the relevant stakeholders\u2019, and the Cyber Threat Alliance<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"45\" data-footnote-id=\"5wkboj0vmi5\" role=\"doc-noteref\" id=\"fnref5wkboj0vmi5\"><sup><a href=\"#fn5wkboj0vmi5\">[45]</a></sup></span>&nbsp;which facilitates \u2018high-quality cyber threat information sharing among companies and organizations&nbsp;in the cybersecurity field\u2019.</p><p data-internal-id=\"ftnt_ref49\">Direct collaboration is very common in the cybersecurity industry, especially when external funding is involved<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"46\" data-footnote-id=\"1s247b6tuec\" role=\"doc-noteref\" id=\"fnref1s247b6tuec\"><sup><a href=\"#fn1s247b6tuec\">[46]</a></sup></span><span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"47\" data-footnote-id=\"jt1aspmwhnr\" role=\"doc-noteref\" id=\"fnrefjt1aspmwhnr\"><sup><a href=\"#fnjt1aspmwhnr\">[47]</a></sup></span>. Relatedly, firms outside the cybersecurity industry are increasingly entering into cybersecurity alliances in order to share intelligence or technical data, and defend themselves together<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"48\" data-footnote-id=\"dh0iqfh24o\" role=\"doc-noteref\" id=\"fnrefdh0iqfh24o\"><sup><a href=\"#fndh0iqfh24o\">[48]</a></sup></span><span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"49\" data-footnote-id=\"p1mlt71lzhq\" role=\"doc-noteref\" id=\"fnrefp1mlt71lzhq\"><sup><a href=\"#fnp1mlt71lzhq\">[49]</a></sup></span>.</p><p data-internal-id=\"ftnt_ref51\">The RSA Conference<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"50\" data-footnote-id=\"w4ygd460t2t\" role=\"doc-noteref\" id=\"fnrefw4ygd460t2t\"><sup><a href=\"#fnw4ygd460t2t\">[50]</a></sup></span>&nbsp;brings together IT professionals and security experts to discuss current and emerging security topics, share best practices, and showcase new security solutions. DefCon<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"51\" data-footnote-id=\"vjh9pephhyh\" role=\"doc-noteref\" id=\"fnrefvjh9pephhyh\"><sup><a href=\"#fnvjh9pephhyh\">[51]</a></sup></span>&nbsp;\u2018attracts a diverse crowd of hackers, security professionals, researchers, and enthusiasts from all over the world\u2019, and features experts collaborating to solve various cybersecurity problems.</p><p data-internal-id=\"ftnt_ref52\">In terms of publicly sharing safety practices, cybersecurity firms and their representatives are typically active in this regard. Many industry professionals are active in online forums and communities where they discuss security concerns, share solutions, and keep up-to-date with the latest developments. Open source contributions are another notable way in which cybersecurity professionals collaborate<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"52\" data-footnote-id=\"toz8bpczedl\" role=\"doc-noteref\" id=\"fnreftoz8bpczedl\"><sup><a href=\"#fntoz8bpczedl\">[52]</a></sup></span>. However, it\u2019s important to note that cybersecurity professionals seem to have adopted a tiered approach to sharing best practices. General best practices are often shared publicly, but detailed information on how to enact those practices tend to be shared either directly or in exclusive groups. Some best practices for AI safety probably wouldn\u2019t require this approach (risk assessment, red teaming, background checks, third-party audits, incident reporting, segregation of duties), others might (alignment techniques, evals, cybersecurity).</p><p>As another sub-sector within the tech industry, cybersecurity is probably the most relevant to AI of the sectors mentioned, and indeed robust cybersecurity practices are probably also one of the most important practices for securing AI systems. There is certainly more collaboration within the bounds of industry bodies in the cybersecurity sector, which is something the AI sector may be well-served in emulating.</p><h3 data-internal-id=\"Contemporary_Collaboration_on_Safety_Practices_Among_Frontier_AI_Labs\">Contemporary Collaboration on Safety Practices Among Frontier AI Labs</h3><p data-internal-id=\"ftnt_ref54\">Despite all contemporary frontier AI labs only existing for a short period of time, and AI which surpasses human performance across a wide variety of tasks existing for a similarly brief period<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"53\" data-footnote-id=\"bfeqn8mz8dc\" role=\"doc-noteref\" id=\"fnrefbfeqn8mz8dc\"><sup><a href=\"#fnbfeqn8mz8dc\">[53]</a></sup></span><span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"54\" data-footnote-id=\"tp39s81htdn\" role=\"doc-noteref\" id=\"fnreftp39s81htdn\"><sup><a href=\"#fntp39s81htdn\">[54]</a></sup></span>, there are several ways in which these labs currently coordinate or plan to coordinate their safety practices.</p><p data-internal-id=\"ftnt_ref57\">Perhaps the most official channel to do this is the Frontier Model Forum (FMF), which is composed of Anthropic, Google, Microsoft and OpenAI. According to the FMF homepage, \u2018The Forum is one vehicle for cross-organizational discussions and actions on AI safety and responsibility\u2019, and its core objectives include advancing safety research and identifying best practices<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"55\" data-footnote-id=\"ovex3bmps9\" role=\"doc-noteref\" id=\"fnrefovex3bmps9\"><sup><a href=\"#fnovex3bmps9\">[55]</a></sup></span>. As part of this endeavour, the FMF has created an AI Safety Fund with $10 million in initial funding<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"56\" data-footnote-id=\"wwl2g6tzsj\" role=\"doc-noteref\" id=\"fnrefwwl2g6tzsj\"><sup><a href=\"#fnwwl2g6tzsj\">[56]</a></sup></span>. They have established workstreams with the aforementioned member companies \u2018to develop shared best practices and standards around the safe development of frontier AI models\u2019, and \u2018met with leaders from across the AI ecosystem to discuss industry best practices and governance frameworks\u2019. In 2024, they plan to fund researchers out of the AI Safety Fund, publish white papers on AI safety topics, and invite new member companies<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"57\" data-footnote-id=\"nr5ssvmcowo\" role=\"doc-noteref\" id=\"fnrefnr5ssvmcowo\"><sup><a href=\"#fnnr5ssvmcowo\">[57]</a></sup></span>.</p><p data-internal-id=\"ftnt_ref61\">The general approach of the FMF seems promising, especially the plan to develop shared safety practices across member companies and involve the wider AI ecosystem. However, the $10 million pledged is a tiny amount compared to the annual budgets of these companies and even compared to the amounts which they and others have already allocated to AI Safety<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"58\" data-footnote-id=\"lx9ya1fr2l\" role=\"doc-noteref\" id=\"fnreflx9ya1fr2l\"><sup><a href=\"#fnlx9ya1fr2l\">[58]</a></sup></span><span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"59\" data-footnote-id=\"tzogs0m1t5e\" role=\"doc-noteref\" id=\"fnreftzogs0m1t5e\"><sup><a href=\"#fntzogs0m1t5e\">[59]</a></sup></span><span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"60\" data-footnote-id=\"vx3dph773y\" role=\"doc-noteref\" id=\"fnrefvx3dph773y\"><sup><a href=\"#fnvx3dph773y\">[60]</a></sup></span><span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"61\" data-footnote-id=\"l3c8k6dtv3\" role=\"doc-noteref\" id=\"fnrefl3c8k6dtv3\"><sup><a href=\"#fnl3c8k6dtv3\">[61]</a></sup></span>&nbsp;(also cite AI safety funding post), the&nbsp;strength and extent of channels of collaboration between the FMF and four member companies is unclear, as is the extent to which new best practices will be identified, and innovative research produced. Overall, the FMF appears well-suited for the purpose of collaboration on safety practices among frontier AI labs, but its utility will depend on how seriously it gets taken by its members, and how willing they are to share and adopt new approaches through this medium.</p><p data-internal-id=\"ftnt_ref64\">On February 7th, the formation of the US AI Safety Institute Consortium (US AISIC) was announced<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"62\" data-footnote-id=\"aqc05skrqb\" role=\"doc-noteref\" id=\"fnrefaqc05skrqb\"><sup><a href=\"#fnaqc05skrqb\">[62]</a></sup></span>. Initially comprised of more than 200 US-based members including all contemporary frontier labs<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"63\" data-footnote-id=\"guae5yqg42\" role=\"doc-noteref\" id=\"fnrefguae5yqg42\"><sup><a href=\"#fnguae5yqg42\">[63]</a></sup></span>, it will \u2018focus on establishing the foundations for a new measurement science in AI safety \u2026 including developing guidelines for red-teaming, capability evaluations, risk management, safety and security, and watermarking synthetic content.\u2019 In addition to the US AI Safety Institute Consortium, the UK AI Safety Institute also intends to \u2018support greater standardisation and promotion of best practice in evaluation more broadly.<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"64\" data-footnote-id=\"auh2gjyjdd7\" role=\"doc-noteref\" id=\"fnrefauh2gjyjdd7\"><sup><a href=\"#fnauh2gjyjdd7\">[64]</a></sup></span>\u2019</p><p>Another method of cooperation is direct collaboration between individual labs. As Microsoft is in a partnership with OpenAI, and Google and Amazon have invested heavily in Anthropic, there are close connections between those specific labs, which likely extend to safety discussions and shared practices. Due to the fact that the AI safety community is still a nascent one, and many safety researchers work at frontier labs, there are also strong personal connections between researchers at different labs. This is exacerbated by the fact that most contemporary frontier labs are based in California\u2019s Bay Area.</p><p data-internal-id=\"ftnt_ref67\">Events attended by delegates of relevant companies, at which safety is prominent on the agenda, are an additional way in which companies can coordinate their safety practices. Although AI safety has been discussed at events in the past<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"65\" data-footnote-id=\"k8ku4iz9su\" role=\"doc-noteref\" id=\"fnrefk8ku4iz9su\"><sup><a href=\"#fnk8ku4iz9su\">[65]</a></sup></span><span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"66\" data-footnote-id=\"ewvo3r0e0g6\" role=\"doc-noteref\" id=\"fnrefewvo3r0e0g6\"><sup><a href=\"#fnewvo3r0e0g6\">[66]</a></sup></span><span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"67\" data-footnote-id=\"stljbhakbmg\" role=\"doc-noteref\" id=\"fnrefstljbhakbmg\"><sup><a href=\"#fnstljbhakbmg\">[67]</a></sup></span>, the&nbsp;inaugural AI safety summit was the first to involve prominent representatives of 28 countries. It took place in the UK in late 2023, and is planned to be an annual event, with France hosting the next in-person summit in late 2024, and South Korea co-hosting an additional virtual summit alongside the UK in May.</p><p>Publishing safety research and practices is a form of indirect collaboration which also takes place in the AI safety community. Many safety researchers, including some at frontier labs, post their work online, and share their opinions on which practices are most significant to reduce the extreme risks of future AI systems. An additional point worth noting here is that labs themselves will be mandated by the US Executive Order on Artificial Intelligence to share the steps they have taken to make their AI systems safe.</p><p data-internal-id=\"ftnt_ref70\">Lastly, collaboration on safety practices often takes place under the auspices of an independent industry body. Prominent standards pertaining to AI safety have been produced by organisations such as the International Organization for Standardization (ISO)<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"68\" data-footnote-id=\"5fxx44g2ayn\" role=\"doc-noteref\" id=\"fnref5fxx44g2ayn\"><sup><a href=\"#fn5fxx44g2ayn\">[68]</a></sup></span>, National Institute of Standards and Technology (NIST)<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"69\" data-footnote-id=\"fronbkjie5\" role=\"doc-noteref\" id=\"fnreffronbkjie5\"><sup><a href=\"#fnfronbkjie5\">[69]</a></sup></span>, and the European Committee for Electrotechnical Standardization (CEN-CENELEC)<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"70\" data-footnote-id=\"g3f9sfe0hn6\" role=\"doc-noteref\" id=\"fnrefg3f9sfe0hn6\"><sup><a href=\"#fng3f9sfe0hn6\">[70]</a></sup></span>. These organisations do engage with AI companies and other stakeholders, but ultimately the standards are provided in a top-down manner, rather than as a result of direct collaboration among the top AI labs.</p><h3 data-internal-id=\"Methods_of_Collaboration_on_Safety_Practices\">Methods of Collaboration on Safety Practices</h3><p>In many cases publicly sharing safety practices is likely to be the optimal approach from a safety standpoint, as it\u2019s the most convenient way for industry peers and anyone else to access the information. However, in some cases publishing best safety practices might not be advisable, due to the potential for adversaries to use this information to jailbreak an AI system, or simply because there may be a strong relationship between safety practices and capabilities, such that sharing a particular practice which boosts model safety may allow other firms to produce similar models, thus contributing to a race dynamic.</p><p>In situations where publicly sharing safety practices may have negative externalities, the most suitable option is probably collaboration under the oversight of an industry body, such as the Frontier Model Forum, US AISIC, or another preferably international organisation. This has the advantage of filtering out potential bad actors, while still providing the opportunity to coordinate safety practices at scale, potentially across all frontier AI labs.</p><p>In some cases it may be preferable for two or more actors to directly collaborate with one another, if the companies which are directly collaborating have a particular reason to support each other but not others in the industry, or if industry bodies are simply inadequate.</p><p>Events seem a less efficient mode of sharing information than publishing safety practices, but are useful for initiating direct collaboration, developing trust, building friendships and demonstrating positive intentions. Similarly to collaborating through industry bodies, events make it possible to influence a large number of other firms, although it may be harder to filter which companies the information is shared with.</p><h3 data-internal-id=\"Potential_Drawbacks_and_Mitigations\">Potential Drawbacks and Mitigations</h3><p>There are several potential drawbacks of collaboration on best safety practices among some or all frontier AI labs. From an x-risk-reduction perspective, the most significant potential drawback is the connection between safety and capabilities advances, while from an individual lab perspective the most significant potential drawback may be legal complications.</p><p><strong>X-risk-reduction Considerations</strong></p><p>One obvious drawback of collaboration on safety practices is that it could morph into collusion among a small group of companies if many safety practices are also beneficial for capabilities. This would allow those firms to gain an advantage over others, and centralise power in the hands of a few key actors. In order to reduce such collusion, regulators may have to enforce competition laws to prevent a small group of firms dominating the market. Additionally, a list of specific practices which are being collaborated on should probably be publicly available, any significant collaboration on safety practices could be made open to most leading / large AI labs. However, it should also be noted that the existence of fewer frontier AI labs could be beneficial for safety as it would somewhat reduce the race dynamic, and reduce the number of models which potentially harbour extreme risks at each capabilities threshold, therefore some benign form of \u2018collusion\u2019 might not be so bad.</p><p>A closely related point is that if some safety practices do benefit capabilities and speed up commercialisation of increasingly advanced models, cooperation on those practices may be net negative as the problem of how to manage a world in which AI agents can complete most cognitive tasks better than most humans would have to be tackled sooner. However, coordination on most safety practices (e.g. risk assessments, background checks) either wouldn\u2019t benefit capabilities, or the benefits for model safety would likely outweigh the possible acceleration in capabilities (e.g. safety evals).</p><p>An additional risk of labs collaborating closely with one another on safety practices is that they could fall victim to groupthink. This would reduce the number of different approaches to safety which get developed, and may lead to complacency around certain risks, or failing to recognise some risks entirely. In order to combat groupthink, diverse and dissenting opinions could be encouraged, as could a culture which values critical evaluation.</p><p>Relatedly, some companies could become dependent on others to conduct safety research, thus reducing the net amount of safety research which gets done. It\u2019s highly likely that some firms will end up contributing to more safety innovation than others, but there should be incentives for all companies to actively advance best practices and attempt to be safety leaders.</p><p><strong>Individual Lab Considerations</strong></p><p>An issue for firms themselves is that they could run into compliance and liability issues. For example, if a particular implementation of a safety practice which has been collaborated on is judged to have caused harm to customers, all firms which collaborated on this practice may be held liable for the damage caused by a particular firm\u2019s product. Rigorous legal audits and the employment of regulatory compliance experts might help to resolve this.</p><p data-internal-id=\"ftnt_ref71\">In addition to compliance and liability, AI companies could also be found in breach of antitrust law. Both US and EU law prohibit agreements and other inter-firm cooperation which has the effect of restricting competition. This is discussed in Coordinated Pausing by Alaga and Schuett<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"71\" data-footnote-id=\"24l0r7027e8\" role=\"doc-noteref\" id=\"fnref24l0r7027e8\"><sup><a href=\"#fn24l0r7027e8\">[71]</a></sup></span>, who suggest \u2018using third parties like independent auditors or regulators as intermediaries for sharing information\u2019, or consulting with regulatory bodies, as ways to mitigate this concern. Relatedly, both US and UK antitrust officials are actively investigating relationships between Open AI and Microsoft, and Anthropic with both Amazon and Google<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"72\" data-footnote-id=\"x8lzu0atyrl\" role=\"doc-noteref\" id=\"fnrefx8lzu0atyrl\"><sup><a href=\"#fnx8lzu0atyrl\">[72]</a></sup></span><span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"73\" data-footnote-id=\"ctkafab4jzv\" role=\"doc-noteref\" id=\"fnrefctkafab4jzv\"><sup><a href=\"#fnctkafab4jzv\">[73]</a></sup></span>, although this pertains to investments into OpenAI and Anthropic rather than collaboration on any particular practices.</p><p data-internal-id=\"ftnt_ref74\">Another potential issue involving the sharing of information between companies is the potential for export controls to be breached. This seems like it would be a particular concern for US firms sharing technology with China, but other countries are also developing their own related controls<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"74\" data-footnote-id=\"8bnsxl0ogoa\" role=\"doc-noteref\" id=\"fnref8bnsxl0ogoa\"><sup><a href=\"#fn8bnsxl0ogoa\">[74]</a></sup></span>.</p><p>Data security and privacy concerns are another potential drawback of collaboration on safety practices, as any large-scale sharing of information among companies can result in data breaches or the misuse of sensitive information. This could be mitigated by enacting robust data security protocols and ensuring compliance with data protection regulations.</p><h3 data-internal-id=\"Potential_Impact_on_AI_safety\">Potential Impact on AI safety</h3><p><strong>Subjective Judgement of Ease of Implementation, Safety Improvement and Downside Potential of Collaboration on Some Safety Best Practices</strong></p><figure class=\"table\"><table><tbody><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><strong>Safety Practice</strong></td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><strong>Implementation</strong></td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><strong>Safety improvement</strong></td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><strong>Downside Potential</strong></td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Risk assessments</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">easy</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">moderate</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">low</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Evals</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p data-internal-id=\"ftnt_ref75\">hard<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"75\" data-footnote-id=\"3h70w8ml81\" role=\"doc-noteref\" id=\"fnref3h70w8ml81\"><sup><a href=\"#fn3h70w8ml81\">[75]</a></sup></span></p></td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">high</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p data-internal-id=\"ftnt_ref76\">high<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"76\" data-footnote-id=\"w4i71wsai5\" role=\"doc-noteref\" id=\"fnrefw4i71wsai5\"><sup><a href=\"#fnw4i71wsai5\">[76]</a></sup></span></p></td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Red teaming</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p data-internal-id=\"ftnt_ref77\">medium<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"77\" data-footnote-id=\"byy7nxzrmvv\" role=\"doc-noteref\" id=\"fnrefbyy7nxzrmvv\"><sup><a href=\"#fnbyy7nxzrmvv\">[77]</a></sup></span></p></td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">high</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">low</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Third-party audits</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">easy</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">low</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">low</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Alignment techniques</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p data-internal-id=\"ftnt_ref78\">hard<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"78\" data-footnote-id=\"g4tijxx8pn\" role=\"doc-noteref\" id=\"fnrefg4tijxx8pn\"><sup><a href=\"#fng4tijxx8pn\">[78]</a></sup></span></p></td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">high</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p data-internal-id=\"ftnt_ref79\">high<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"79\" data-footnote-id=\"o3fd939mlt\" role=\"doc-noteref\" id=\"fnrefo3fd939mlt\"><sup><a href=\"#fno3fd939mlt\">[79]</a></sup></span></p></td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Information security</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p data-internal-id=\"ftnt_ref80\">hard<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"80\" data-footnote-id=\"2rx6ezk5u6i\" role=\"doc-noteref\" id=\"fnref2rx6ezk5u6i\"><sup><a href=\"#fn2rx6ezk5u6i\">[80]</a></sup></span></p></td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">high</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">low</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Incident reporting</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p data-internal-id=\"ftnt_ref81\">medium<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"81\" data-footnote-id=\"lbarf3z9fs\" role=\"doc-noteref\" id=\"fnreflbarf3z9fs\"><sup><a href=\"#fnlbarf3z9fs\">[81]</a></sup></span></p></td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">moderate</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p data-internal-id=\"ftnt_ref82\">high<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"82\" data-footnote-id=\"tpg7www29\" role=\"doc-noteref\" id=\"fnreftpg7www29\"><sup><a href=\"#fntpg7www29\">[82]</a></sup></span></p></td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Segregation of duties</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p data-internal-id=\"ftnt_ref83\">medium<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"83\" data-footnote-id=\"ewr8882oxsq\" role=\"doc-noteref\" id=\"fnrefewr8882oxsq\"><sup><a href=\"#fnewr8882oxsq\">[83]</a></sup></span></p></td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">moderate</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">low</td></tr><tr><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Background checks</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">easy</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">low</td><td style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">low</td></tr></tbody></table></figure><p>Collaboration on safety practices could have a significant impact on AI safety, due to the proliferation of best practices across the industry, and the development of counterfactually superior best practices. Overall this impact is likely to be more significant than safety improvements at just one firm (unless one lab is substantially ahead and produces all meaningful frontier models?), and should therefore receive attention from all industry actors.</p><p data-internal-id=\"ftnt_ref84\">The default scenario is that a somewhat higher level of cooperation occurs, due to existing industry initiatives such as the Frontier Model Forum, and state initiatives which aim to establish best practices for evals and other areas<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"84\" data-footnote-id=\"ndlsmf4cvmi\" role=\"doc-noteref\" id=\"fnrefndlsmf4cvmi\"><sup><a href=\"#fnndlsmf4cvmi\">[84]</a></sup></span>. Overall, it seems like a higher level of cooperation among frontier labs is one of the most promising steps towards reducing x-risks. In terms of individual practices, most appear to have low downside potential under collaboration, with the exceptions of evals, alignment techniques and incident reporting, and even collaboration on those practices may still be net positive, at least if done to a certain extent.</p><p>Over the next year, the ideal scenario would be that frontier labs, alongside safety researchers in general, publish their current best practices for safety, with practical details where possible, except perhaps information relating to alignment techniques which may widely disseminate capabilities. This already happens to a certain extent, and the fact that there are plans to publish more (e.g. as announced by the Frontier Model Forum) is promising. With regards to the FMF itself, it will hopefully expand to incorporate more leading labs, and be taken more seriously as an engine for collaboration. The allocation of more funding to the FMF would be a positive indicator of this. The formation of other industry bodies could allow even more labs to collaborate on safety practices, although without a firm focus on safety they could be harmful as they could legitimise a less rigorous approach to ensuring model safety. In some circumstances, direct collaboration on practices beyond current commercial partnerships could be helpful, although the default should be to collaborate more widely.</p><p data-internal-id=\"ftnt_ref85\">If cooperation on safety practices continues at the current level, the impact will depend on how many labs are producing genuinely frontier general-purpose AI models, and to what extent those firms already follow or are clearly open to implementing best practices as they\u2019re developed. For example, at the moment OpenAI, DeepMind and Anthropic are probably the three genuine frontier labs, and if this scenario persists the need for collaboration on safety practices is lower than it would be if currently less responsible labs such as Facebook and Amazon were producing frontier models with their current safety practices<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"85\" data-footnote-id=\"y9i93o4dhm\" role=\"doc-noteref\" id=\"fnrefy9i93o4dhm\"><sup><a href=\"#fny9i93o4dhm\">[85]</a></sup></span>. However, collaboration among the most responsible labs would still likely lead to notable safety improvements, and regardless of their current adoption of safety practices, labs would need to be willing to implement improved practices in order to make collaboration valuable.</p><p>Regulators mandating some straightforward safety practices, and creating an environment which encourages the adoption of other more nuanced practices, would create a more cautious frontier AI ecosystem, and combat any incentives companies may have to take shortcuts on safety. Regulators could also be key in the creation of more AI safety events, which they already have been with the launch of the international safety summits, although labs themselves could also take the initiative in organising several genuinely safety-focused events per year. Finally, although most customers are likely to use the most capable models, even a small proportion of safety-conscious customers could encourage firms to improve practices.</p><h3 data-internal-id=\"Conclusion\">Conclusion</h3><p>Other sectors: Firms in the more established sectors examined in this report don\u2019t appear to collaborate on safety practices as much as I imagined they would prior to commencing this report. However, frontier AI labs could emulate the level of collaboration through industry bodies which takes place in the energy and cybersecurity sectors, and the AI industry in general could take inspiration from the amount of safety-focused events which occur in the aviation and pharmaceutical sectors.</p><p>Contemporary AI sector: The Frontier Model Forum is a promising platform for collaboration, as are existing direct collaboration ties and publishing practices. However, there\u2019s room for more industry body involvement and safety-focused industry events, and issues such as competition law and the links between safety and capabilities research pose significant barriers. The newly-announced US AISIC may play a significant role in facilitating collaboration on safety practices but there\u2019s still scope for international industry bodies which could include non-US companies.</p><p>Methods of Collaboration: The most promising methods of collaboration, in order of desirability, are open publishing of best practices, collaboration within an industry body, industry events, and direct collaboration. In some cases, some methods of collaboration may not be suitable for certain safety practices.</p><p>Safety Practices: Collaboration on the majority of safety practices referenced in this report appears to have few downsides. Collaboration on some practices such as evals and alignment techniques requires a more nuanced approach.</p><p>Drawbacks and mitigations: There are many potential drawbacks of safety collaboration which firms should be aware of. Most have straightforward mitigations, but antitrust laws may restrict the modes in which collaboration can take place, and some safety collaboration may hasten the development of new capabilities without ensuring that those capabilities themselves are safe.</p><p>Impact on AI safety: Collaboration on many of the identified safety practices would likely provide a significant boost to the safety of advanced AI models. Firms themselves, regulators, customers and the general public can all play a part in encouraging this scenario.</p><p><i>Thanks to Oliver Guest and Max R\u00e4uker for many helpful comments and suggestions on an earlier version of this draft. All remaining flaws are the responsibility of the author.</i></p><ol class=\"footnote-section footnotes\" data-footnote-section=\"\" role=\"doc-endnotes\"><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"1\" data-footnote-id=\"g0e2cwukjd\" role=\"doc-endnote\" id=\"fng0e2cwukjd\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"g0e2cwukjd\"><sup><strong><a href=\"#fnrefg0e2cwukjd\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence,\" The White House, 30 Oct. 2023. [Online]. Available: <a href=\"https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/\">https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"2\" data-footnote-id=\"vrfieyshfs\" role=\"doc-endnote\" id=\"fnvrfieyshfs\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"vrfieyshfs\"><sup><strong><a href=\"#fnrefvrfieyshfs\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>\"AI Safety Summit 2023,\" UK Government. [Online]. Available: <a href=\"https://www.gov.uk/government/topical-events/ai-safety-summit-2023\">https://www.gov.uk/government/topical-events/ai-safety-summit-2023</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"3\" data-footnote-id=\"2f9u9r3exi2\" role=\"doc-endnote\" id=\"fn2f9u9r3exi2\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"2f9u9r3exi2\"><sup><strong><a href=\"#fnref2f9u9r3exi2\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"Incident 34909,\" OECD.AI. [Online]. Available: <a href=\"https://oecd.ai/en/incidents/34909\">https://oecd.ai/en/incidents/34909</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"4\" data-footnote-id=\"40st1k44ctl\" role=\"doc-endnote\" id=\"fn40st1k44ctl\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"40st1k44ctl\"><sup><strong><a href=\"#fnref40st1k44ctl\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"AI Will Transform the Global Economy; Let's Make Sure It Benefits Humanity,\" IMF, 14 Jan. 2024. [Online]. Available: <a href=\"https://www.imf.org/en/Blogs/Articles/2024/01/14/ai-will-transform-the-global-economy-lets-make-sure-it-benefits-humanity\">https://www.imf.org/en/Blogs/Articles/2024/01/14/ai-will-transform-the-global-economy-lets-make-sure-it-benefits-humanity</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"5\" data-footnote-id=\"xulzobuhtx\" role=\"doc-endnote\" id=\"fnxulzobuhtx\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"xulzobuhtx\"><sup><strong><a href=\"#fnrefxulzobuhtx\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;In the context of this report, safety practices refers to practices which are judged to reduce the existential risk of present or future AI systems. It does not include practices which are designed to reduce misinformation, bias and other harms to users which likely have no direct bearing on existential risks.&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"6\" data-footnote-id=\"23e6kz5faru\" role=\"doc-endnote\" id=\"fn23e6kz5faru\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"23e6kz5faru\"><sup><strong><a href=\"#fnref23e6kz5faru\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"Risk Assessment at AGI Companies,\" Governance.AI. [Online]. Available: <a href=\"https://cdn.governance.ai/Koessler_Schuett_(2023)_-_Risk_assessment_at_AGI_companies.pdf\">https://cdn.governance.ai/Koessler_Schuett_(2023)_-_Risk_assessment_at_AGI_companies.pdf</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"7\" data-footnote-id=\"yaz6m18mhl\" role=\"doc-endnote\" id=\"fnyaz6m18mhl\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"yaz6m18mhl\"><sup><strong><a href=\"#fnrefyaz6m18mhl\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"AI Evaluations and Standards,\" Effective Altruism Forum. [Online]. Available: <a href=\"https://forum.effectivealtruism.org/topics/ai-evaluations-and-standards\">https://forum.effectivealtruism.org/topics/ai-evaluations-and-standards</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"8\" data-footnote-id=\"dl46oeyps1q\" role=\"doc-endnote\" id=\"fndl46oeyps1q\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"dl46oeyps1q\"><sup><strong><a href=\"#fnrefdl46oeyps1q\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"What Does AI Red Teaming Actually Mean?,\" CSET Georgetown. [Online]. Available: <a href=\"https://cset.georgetown.edu/article/what-does-ai-red-teaming-actually-mean/\">https://cset.georgetown.edu/article/what-does-ai-red-teaming-actually-mean/</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"9\" data-footnote-id=\"ul9872809l\" role=\"doc-endnote\" id=\"fnul9872809l\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"ul9872809l\"><sup><strong><a href=\"#fnreful9872809l\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"Red Teaming Network,\" OpenAI. [Online]. Available:<a href=\"https://openai.com/blog/red-teaming-network%E3%80%9058%E2%80%A0source%E3%80%91\">&nbsp;https://openai.com/blog/red-teaming-network</a></p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"10\" data-footnote-id=\"tynizdtt1y\" role=\"doc-endnote\" id=\"fntynizdtt1y\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"tynizdtt1y\"><sup><strong><a href=\"#fnreftynizdtt1y\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"Red Teaming,\" Microsoft Azure AI Services. [Online]. Available: <a href=\"https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/red-teaming\">https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/red-teaming</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"11\" data-footnote-id=\"kpvrsw4j3t\" role=\"doc-endnote\" id=\"fnkpvrsw4j3t\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"kpvrsw4j3t\"><sup><strong><a href=\"#fnrefkpvrsw4j3t\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"Third-Party Audits of AI Systems,\" Springer. [Online]. Available: <a href=\"https://link.springer.com/article/10.1007/s43681-023-00289-2\">https://link.springer.com/article/10.1007/s43681-023-00289-2</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"12\" data-footnote-id=\"138p0f2qz1z\" role=\"doc-endnote\" id=\"fn138p0f2qz1z\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"138p0f2qz1z\"><sup><strong><a href=\"#fnref138p0f2qz1z\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"AI Alignment Approaches,\" AI Safety Fundamentals. [Online]. Available: <a href=\"https://aisafetyfundamentals.com/blog/ai-alignment-approaches/\">https://aisafetyfundamentals.com/blog/ai-alignment-approaches/</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"13\" data-footnote-id=\"watutugqhk\" role=\"doc-endnote\" id=\"fnwatutugqhk\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"watutugqhk\"><sup><strong><a href=\"#fnrefwatutugqhk\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"Background Check,\" Wikipedia. [Online]. Available: <a href=\"https://en.wikipedia.org/wiki/Background_check\">https://en.wikipedia.org/wiki/Background_check</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"14\" data-footnote-id=\"m70ygjlyt\" role=\"doc-endnote\" id=\"fnm70ygjlyt\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"m70ygjlyt\"><sup><strong><a href=\"#fnrefm70ygjlyt\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"Know Your Client (KYC),\" Investopedia. [Online]. Available: <a href=\"https://www.investopedia.com/terms/k/knowyourclient.asp\">https://www.investopedia.com/terms/k/knowyourclient.asp</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"15\" data-footnote-id=\"pqns36744f7\" role=\"doc-endnote\" id=\"fnpqns36744f7\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"pqns36744f7\"><sup><strong><a href=\"#fnrefpqns36744f7\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;GPT-4; \"Accident Statistics,\" ICAO, 2023. [Online]. Available: <a href=\"https://www.icao.int/safety/iStars/Pages/Accident-Statistics.aspx\">https://www.icao.int/safety/iStars/Pages/Accident-Statistics.aspx</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"16\" data-footnote-id=\"5mkaw8ve1iu\" role=\"doc-endnote\" id=\"fn5mkaw8ve1iu\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"5mkaw8ve1iu\"><sup><strong><a href=\"#fnref5mkaw8ve1iu\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"Safety Collaboration,\" Flight Safety Foundation. [Online]. Available: <a href=\"https://flightsafety.org/asw-article/safety-collaboration/\">https://flightsafety.org/asw-article/safety-collaboration/</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"17\" data-footnote-id=\"4salzujendm\" role=\"doc-endnote\" id=\"fn4salzujendm\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"4salzujendm\"><sup><strong><a href=\"#fnref4salzujendm\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"Aviation Data Sharing: Crucial to Improved Safety,\" Global Aerospace, 2023. [Online]. Available: <a href=\"https://www.global-aero.com/aviation-data-sharing-crucial-to-improved-safety/\">https://www.global-aero.com/aviation-data-sharing-crucial-to-improved-safety/</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"18\" data-footnote-id=\"m7kshf5tp7k\" role=\"doc-endnote\" id=\"fnm7kshf5tp7k\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"m7kshf5tp7k\"><sup><strong><a href=\"#fnrefm7kshf5tp7k\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"Modeling Common Aviation Risk,\" Flight Safety Foundation. [Online]. Available: <a href=\"https://flightsafety.org/asw-article/modeling-common-aviation-risk/\">https://flightsafety.org/asw-article/modeling-common-aviation-risk/</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"19\" data-footnote-id=\"vs4b2d2gw7c\" role=\"doc-endnote\" id=\"fnvs4b2d2gw7c\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"vs4b2d2gw7c\"><sup><strong><a href=\"#fnrefvs4b2d2gw7c\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"Emirates and IATA Marshal Industry to Share Best Practices in Pilot Training and Flight Safety,\" Emirates. [Online]. Available: <a href=\"https://www.emirates.com/media-centre/emirates-and-iata-marshal-industry-to-share-best-practices-in-pilot-training-and-flight-safety/\">https://www.emirates.com/media-centre/emirates-and-iata-marshal-industry-to-share-best-practices-in-pilot-training-and-flight-safety/</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"20\" data-footnote-id=\"ozwbkesqcph\" role=\"doc-endnote\" id=\"fnozwbkesqcph\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"ozwbkesqcph\"><sup><strong><a href=\"#fnrefozwbkesqcph\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"Safety Forum 2023,\" Flight Safety Foundation. [Online]. Available: <a href=\"https://flightsafety.org/safety-forum-2023/agenda/\">https://flightsafety.org/safety-forum-2023/agenda/</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"21\" data-footnote-id=\"usyfwhcd5vh\" role=\"doc-endnote\" id=\"fnusyfwhcd5vh\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"usyfwhcd5vh\"><sup><strong><a href=\"#fnrefusyfwhcd5vh\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"All Eyes on the Future of Aviation Safety at Global Aerospace Summit,\" NBAA. [Online]. Available: <a href=\"https://nbaa.org/aircraft-operations/safety/all-eyes-on-the-future-of-aviation-safety-at-global-aerospace-summit/\">https://nbaa.org/aircraft-operations/safety/all-eyes-on-the-future-of-aviation-safety-at-global-aerospace-summit/</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"22\" data-footnote-id=\"xbxfvjmiljg\" role=\"doc-endnote\" id=\"fnxbxfvjmiljg\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"xbxfvjmiljg\"><sup><strong><a href=\"#fnrefxbxfvjmiljg\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"2023 EASA-FAA International Aviation Safety Conference,\" EASA. [Online]. Available: <a href=\"https://www.easa.europa.eu/en/newsroom-and-events/events/2023-easa-faa-international-aviation-safety-conference#group-agenda\">https://www.easa.europa.eu/en/newsroom-and-events/events/2023-easa-faa-international-aviation-safety-conference#group-agenda</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"23\" data-footnote-id=\"6d87hnkw7jb\" role=\"doc-endnote\" id=\"fn6d87hnkw7jb\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"6d87hnkw7jb\"><sup><strong><a href=\"#fnref6d87hnkw7jb\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"AeroSafety World Magazine,\" Flight Safety Foundation. [Online]. Available: <a href=\"https://flightsafety.org/aerosafety-world/aerosafety-world-magazine/\">https://flightsafety.org/aerosafety-world/aerosafety-world-magazine/</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"24\" data-footnote-id=\"i5e44s3b27\" role=\"doc-endnote\" id=\"fni5e44s3b27\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"i5e44s3b27\"><sup><strong><a href=\"#fnrefi5e44s3b27\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"Air Line Pilot Magazine,\" ALPA. [Online]. Available: <a href=\"https://www.alpa.org/news-and-events/air-line-pilot-magazine\">https://www.alpa.org/news-and-events/air-line-pilot-magazine</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"25\" data-footnote-id=\"vt2xnqmmo9m\" role=\"doc-endnote\" id=\"fnvt2xnqmmo9m\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"vt2xnqmmo9m\"><sup><strong><a href=\"#fnrefvt2xnqmmo9m\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"Journal of Airline Operations and Aviation Management,\" JAOAM. [Online]. Available: <a href=\"https://jaoam.com/index.php/jaoam\">https://jaoam.com/index.php/jaoam</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"26\" data-footnote-id=\"cfof8augei9\" role=\"doc-endnote\" id=\"fncfof8augei9\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"cfof8augei9\"><sup><strong><a href=\"#fnrefcfof8augei9\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"Our Mission,\" WANO. [Online]. Available: <a href=\"https://www.wano.info/about-us/our-mission\">https://www.wano.info/about-us/our-mission</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"27\" data-footnote-id=\"b2b77pejqsb\" role=\"doc-endnote\" id=\"fnb2b77pejqsb\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"b2b77pejqsb\"><sup><strong><a href=\"#fnrefb2b77pejqsb\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;Testimony by S. Willard, U.S. Senate, 13 Nov. 2019. [Online]. Available: <a href=\"https://www.epw.senate.gov/public/_cache/files/7/3/736241ed-3922-4144-a905-b965bb1cbe88/A7587FA91CC97E396A67DF16C8D4665A.willard-testimony-11.13.2019.pdf\">https://www.epw.senate.gov/public/_cache/files/7/3/736241ed-3922-4144-a905-b965bb1cbe88/A7587FA91CC97E396A67DF16C8D4665A.willard-testimony-11.13.2019.pdf</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"28\" data-footnote-id=\"5kjze8qvahu\" role=\"doc-endnote\" id=\"fn5kjze8qvahu\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"5kjze8qvahu\"><sup><strong><a href=\"#fnref5kjze8qvahu\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"API Offshore Oil and Gas Safety,\" NS Energy. [Online]. Available: <a href=\"https://www.nsenergybusiness.com/features/american-petroleum-institute-offshore-oil-gas-safety/\">https://www.nsenergybusiness.com/features/american-petroleum-institute-offshore-oil-gas-safety/</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"29\" data-footnote-id=\"jgxu5t4s8ej\" role=\"doc-endnote\" id=\"fnjgxu5t4s8ej\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"jgxu5t4s8ej\"><sup><strong><a href=\"#fnrefjgxu5t4s8ej\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"North American Firms Join to Focus on Safety as the Wind Turbine Industry Grows,\" Global Wind Safety. [Online]. Available: <a href=\"https://www.globalwindsafety.org/news/north-american-firms-join-to-focus-on-safety-as-the-wind-turbine-industry-grows\">https://www.globalwindsafety.org/news/north-american-firms-join-to-focus-on-safety-as-the-wind-turbine-industry-grows</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"30\" data-footnote-id=\"lw7wel5ls2a\" role=\"doc-endnote\" id=\"fnlw7wel5ls2a\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"lw7wel5ls2a\"><sup><strong><a href=\"#fnreflw7wel5ls2a\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"World Nuclear Symposium,\" WNA. [Online]. Available: <a href=\"https://www.wna-symposium.org/website/52662/\">https://www.wna-symposium.org/website/52662/</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"31\" data-footnote-id=\"0b3i8j4y1k1m\" role=\"doc-endnote\" id=\"fn0b3i8j4y1k1m\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"0b3i8j4y1k1m\"><sup><strong><a href=\"#fnref0b3i8j4y1k1m\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"IPTC International Petroleum Technology Conference,\" IOGP. [Online]. Available: <a href=\"https://www.iogp.org/event/iptc-international-petroleum-technology-conference/\">https://www.iogp.org/event/iptc-international-petroleum-technology-conference/</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"32\" data-footnote-id=\"fukz0ok8brl\" role=\"doc-endnote\" id=\"fnfukz0ok8brl\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"fukz0ok8brl\"><sup><strong><a href=\"#fnreffukz0ok8brl\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"OTC Half-Day Recap,\" Center for Offshore Safety. [Online]. Available: <a href=\"https://www.centerforoffshoresafety.org/announcements_page/Announcements/OTC_halfday_recap\">https://www.centerforoffshoresafety.org/announcements_page/Announcements/OTC_halfday_recap</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"33\" data-footnote-id=\"rm1ar4p1s9a\" role=\"doc-endnote\" id=\"fnrm1ar4p1s9a\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"rm1ar4p1s9a\"><sup><strong><a href=\"#fnrefrm1ar4p1s9a\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"Protecting Your Most Valuable Asset: 4 Best Practices for Reducing Worker Injuries and Illnesses,\" Energy Global. [Online]. Available: <a href=\"https://www.energyglobal.com/whitepapers/intelex/protecting-your-most-valuable-asset-4-best-practices-for-reducing-worker-injuries-and-illnesses/\">https://www.energyglobal.com/whitepapers/intelex/protecting-your-most-valuable-asset-4-best-practices-for-reducing-worker-injuries-and-illnesses/</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"34\" data-footnote-id=\"qcqwf83cd\" role=\"doc-endnote\" id=\"fnqcqwf83cd\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"qcqwf83cd\"><sup><strong><a href=\"#fnrefqcqwf83cd\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"New Approach to Safety in Oil and Gas,\" Hart Energy. [Online]. Available: <a href=\"https://www.hartenergy.com/ep/exclusives/new-approach-safety-oil-and-gas-202415\">https://www.hartenergy.com/ep/exclusives/new-approach-safety-oil-and-gas-202415</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"35\" data-footnote-id=\"n8fcsr7fmyp\" role=\"doc-endnote\" id=\"fnn8fcsr7fmyp\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"n8fcsr7fmyp\"><sup><strong><a href=\"#fnrefn8fcsr7fmyp\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"About Us,\" IFPMA. [Online]. Available: <a href=\"https://www.ifpma.org/about-us/\">https://www.ifpma.org/about-us/</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"36\" data-footnote-id=\"l3ktsy2eht\" role=\"doc-endnote\" id=\"fnl3ktsy2eht\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"l3ktsy2eht\"><sup><strong><a href=\"#fnrefl3ktsy2eht\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"Research and Development: Manufacturing,\" PhRMA. [Online]. Available: <a href=\"https://phrma.org/policy-issues/Research-and-Development/Manufacturing\">https://phrma.org/policy-issues/Research-and-Development/Manufacturing</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"37\" data-footnote-id=\"fpt7c22meo8\" role=\"doc-endnote\" id=\"fnfpt7c22meo8\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"fpt7c22meo8\"><sup><strong><a href=\"#fnreffpt7c22meo8\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"Drug Safety Symposium,\" Bio-Equip. [Online]. Available: <a href=\"https://www.bio-equip.cn/ensrc.asp?ID=9131\">https://www.bio-equip.cn/ensrc.asp?ID=9131</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"38\" data-footnote-id=\"qm3yy7y08fn\" role=\"doc-endnote\" id=\"fnqm3yy7y08fn\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"qm3yy7y08fn\"><sup><strong><a href=\"#fnrefqm3yy7y08fn\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"CDISC Interchange,\" CDISC. [Online]. Available: <a href=\"https://www.cdisc.org/interchange/reasons\">https://www.cdisc.org/interchange/reasons</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"39\" data-footnote-id=\"m235lns7jl\" role=\"doc-endnote\" id=\"fnm235lns7jl\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"m235lns7jl\"><sup><strong><a href=\"#fnrefm235lns7jl\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"Reuters Events: Pharma Europe,\" Reuters Events. [Online]. Available: <a href=\"https://events.reutersevents.com/pharma/pharma-europe\">https://events.reutersevents.com/pharma/pharma-europe</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"40\" data-footnote-id=\"57tkchyeuna\" role=\"doc-endnote\" id=\"fn57tkchyeuna\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"57tkchyeuna\"><sup><strong><a href=\"#fnref57tkchyeuna\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"COVID-19 Vaccine Manufacturing Collaborations,\" PhRMA. [Online]. Available: <a href=\"https://phrma.org/Coronavirus/Working-Together-To-Fight-COVID-19-Vaccine-Manufacturing-Collaborations\">https://phrma.org/Coronavirus/Working-Together-To-Fight-COVID-19-Vaccine-Manufacturing-Collaborations</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"41\" data-footnote-id=\"16839cqvpva\" role=\"doc-endnote\" id=\"fn16839cqvpva\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"16839cqvpva\"><sup><strong><a href=\"#fnref16839cqvpva\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"Clinical Trials Results,\" PubMed Central. [Online]. Available: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6614834/\">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6614834/</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"42\" data-footnote-id=\"ndquwuy4o9h\" role=\"doc-endnote\" id=\"fnndquwuy4o9h\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"ndquwuy4o9h\"><sup><strong><a href=\"#fnrefndquwuy4o9h\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"Nature,\" Nature. [Online]. Available:<strong>&nbsp;</strong><a href=\"https://www.nature.com/articles/d41586-019-00610-2\"><strong>https://www.nature.com/articles/d41586-019-00610-2</strong></a><strong>&nbsp;</strong></p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"43\" data-footnote-id=\"03kprgjd7x1t\" role=\"doc-endnote\" id=\"fn03kprgjd7x1t\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"03kprgjd7x1t\"><sup><strong><a href=\"#fnref03kprgjd7x1t\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"About Cybersecurity Tech Accord,\" Cybersecurity Tech Accord. [Online]. Available: <a href=\"https://cybertechaccord.org/about/\">https://cybertechaccord.org/about/</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"44\" data-footnote-id=\"xte2rgd79nl\" role=\"doc-endnote\" id=\"fnxte2rgd79nl\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"xte2rgd79nl\"><sup><strong><a href=\"#fnrefxte2rgd79nl\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"National Cyber Security Strategies Information Sharing,\" ENISA. [Online]. Available: <a href=\"https://www.enisa.europa.eu/topics/national-cyber-security-strategies/information-sharing\">https://www.enisa.europa.eu/topics/national-cyber-security-strategies/information-sharing</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"45\" data-footnote-id=\"5wkboj0vmi5\" role=\"doc-endnote\" id=\"fn5wkboj0vmi5\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"5wkboj0vmi5\"><sup><strong><a href=\"#fnref5wkboj0vmi5\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"Cyber Threat Alliance,\" Cyber Threat Alliance. [Online]. Available: <a href=\"https://www.cyberthreatalliance.org/\">https://www.cyberthreatalliance.org/</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"46\" data-footnote-id=\"1s247b6tuec\" role=\"doc-endnote\" id=\"fn1s247b6tuec\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"1s247b6tuec\"><sup><strong><a href=\"#fnref1s247b6tuec\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"Israel-US Binational Industrial R&amp;D Foundation to Invest $3.85M in Critical Infrastructure Cybersecurity Projects,\" Dark Reading. [Online]. Available: <a href=\"https://www.darkreading.com/cybersecurity-operations/israel-us-binational-industrial-r-d-foundation-to-invest-3-85m-in-critical-infrastructure-cybersecurity-projects\">https://www.darkreading.com/cybersecurity-operations/israel-us-binational-industrial-r-d-foundation-to-invest-3-85m-in-critical-infrastructure-cybersecurity-projects</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"47\" data-footnote-id=\"jt1aspmwhnr\" role=\"doc-endnote\" id=\"fnjt1aspmwhnr\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"jt1aspmwhnr\"><sup><strong><a href=\"#fnrefjt1aspmwhnr\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"Globalstars Call for Projects with Taiwan,\" EUREKA Network. [Online]. Available: <a href=\"https://www.eurekanetwork.org/dA/3a5f6bfce4/Globalstars%20call%20for%20projects%20with%20Taiwan.pdf\">https://www.eurekanetwork.org/dA/3a5f6bfce4/Globalstars%20call%20for%20projects%20with%20Taiwan.pdf</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"48\" data-footnote-id=\"dh0iqfh24o\" role=\"doc-endnote\" id=\"fndh0iqfh24o\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"dh0iqfh24o\"><sup><strong><a href=\"#fnrefdh0iqfh24o\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"Why Companies Are Forming Cybersecurity Alliances,\" Harvard Business Review. [Online]. Available: <a href=\"https://hbr.org/2019/09/why-companies-are-forming-cybersecurity-alliances\">https://hbr.org/2019/09/why-companies-are-forming-cybersecurity-alliances</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"49\" data-footnote-id=\"p1mlt71lzhq\" role=\"doc-endnote\" id=\"fnp1mlt71lzhq\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"p1mlt71lzhq\"><sup><strong><a href=\"#fnrefp1mlt71lzhq\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"Formation of Cybersecurity Alliances,\" T\u00dcV. [Online]. Available: <a href=\"https://www.tuv.com/landingpage/en/cybersecurity-trends_2024/navi/formation-of-cybersecurity-alliances/\">https://www.tuv.com/landingpage/en/cybersecurity-trends_2024/navi/formation-of-cybersecurity-alliances/</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"50\" data-footnote-id=\"w4ygd460t2t\" role=\"doc-endnote\" id=\"fnw4ygd460t2t\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"w4ygd460t2t\"><sup><strong><a href=\"#fnrefw4ygd460t2t\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"About RSA Conference,\" RSA Conference. [Online]. Available: <a href=\"https://www.rsaconference.com/about\">https://www.rsaconference.com/about</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"51\" data-footnote-id=\"vjh9pephhyh\" role=\"doc-endnote\" id=\"fnvjh9pephhyh\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"vjh9pephhyh\"><sup><strong><a href=\"#fnrefvjh9pephhyh\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"The Definitive Guide to DEFCON,\" ThreatKey. [Online]. Available: <a href=\"https://www.threatkey.com/resource/the-definitive-guide-to-defcon-what-every-cyber-security-enthusiast-needs-to-know\">https://www.threatkey.com/resource/the-definitive-guide-to-defcon-what-every-cyber-security-enthusiast-needs-to-know</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"52\" data-footnote-id=\"toz8bpczedl\" role=\"doc-endnote\" id=\"fntoz8bpczedl\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"toz8bpczedl\"><sup><strong><a href=\"#fnreftoz8bpczedl\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"Open Source in Cybersecurity,\" Venture in Security. [Online]. Available: <a href=\"https://ventureinsecurity.net/p/open-source-in-cybersecurity-a-deep\">https://ventureinsecurity.net/p/open-source-in-cybersecurity-a-deep</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"53\" data-footnote-id=\"bfeqn8mz8dc\" role=\"doc-endnote\" id=\"fnbfeqn8mz8dc\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"bfeqn8mz8dc\"><sup><strong><a href=\"#fnrefbfeqn8mz8dc\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"Deep Learning (DL) in Neural Networks (NNs): An Overview,\" arXiv. [Online]. Available: <a href=\"https://arxiv.org/pdf/1712.01815v1.pdf\">https://arxiv.org/pdf/1712.01815v1.pdf</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"54\" data-footnote-id=\"tp39s81htdn\" role=\"doc-endnote\" id=\"fntp39s81htdn\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"tp39s81htdn\"><sup><strong><a href=\"#fnreftp39s81htdn\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"GPT-4,\" OpenAI. [Online]. Available:<a href=\"https://cdn.openai.com/papers/gpt-4.pdf%E3%80%9056%E2%80%A0source%E3%80%91\">&nbsp;</a><a href=\"https://cdn.openai.com/papers/gpt-4.pdf\">https://cdn.openai.com/papers/gpt-4.pdf</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"55\" data-footnote-id=\"ovex3bmps9\" role=\"doc-endnote\" id=\"fnovex3bmps9\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"ovex3bmps9\"><sup><strong><a href=\"#fnrefovex3bmps9\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"Frontier Model Forum,\" Frontier Model Forum. [Online]. Available: <a href=\"https://www.frontiermodelforum.org/\">https://www.frontiermodelforum.org/</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"56\" data-footnote-id=\"wwl2g6tzsj\" role=\"doc-endnote\" id=\"fnwwl2g6tzsj\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"wwl2g6tzsj\"><sup><strong><a href=\"#fnrefwwl2g6tzsj\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"Announcing Chris Meserole,\" Frontier Model Forum. [Online]. Available: <a href=\"https://www.frontiermodelforum.org/updates/announcing-chris-meserole/\">https://www.frontiermodelforum.org/updates/announcing-chris-meserole/</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"57\" data-footnote-id=\"nr5ssvmcowo\" role=\"doc-endnote\" id=\"fnnr5ssvmcowo\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"nr5ssvmcowo\"><sup><strong><a href=\"#fnrefnr5ssvmcowo\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"Year in Review,\" Frontier Model Forum. [Online]. Available: <a href=\"https://www.frontiermodelforum.org/updates/year-in-review/\">https://www.frontiermodelforum.org/updates/year-in-review/</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"58\" data-footnote-id=\"lx9ya1fr2l\" role=\"doc-endnote\" id=\"fnlx9ya1fr2l\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"lx9ya1fr2l\"><sup><strong><a href=\"#fnreflx9ya1fr2l\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;J. Leike and I. Sutskever, \"Introducing Superalignment,\" OpenAI Blog, July 5, 2023. [Online]. Available:<a href=\"https://openai.com/blog/introducing-superalignment\">&nbsp;https://openai.com/blog/introducing-superalignment</a>.</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"59\" data-footnote-id=\"tzogs0m1t5e\" role=\"doc-endnote\" id=\"fntzogs0m1t5e\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"tzogs0m1t5e\"><sup><strong><a href=\"#fnreftzogs0m1t5e\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;R. Shah and G. Irving, \"DeepMind is hiring for the Scalable Alignment and Alignment Teams,\" AI Alignment Forum, May 13, 2022. [Online]. Available:<a href=\"https://www.alignmentforum.org/posts/nzmCvRvPm4xJuqztv/deepmind-is-hiring-for-the-scalable-alignment-and-alignment\">&nbsp;https://www.alignmentforum.org/posts/nzmCvRvPm4xJuqztv/deepmind-is-hiring-for-the-scalable-alignment-and-alignment</a>.</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"60\" data-footnote-id=\"vx3dph773y\" role=\"doc-endnote\" id=\"fnvx3dph773y\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"vx3dph773y\"><sup><strong><a href=\"#fnrefvx3dph773y\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"Open Philanthropy donations made (filtered to cause areas matching AI safety).\" Donations.vipulnaik.com. [Online]. Available:<a href=\"https://donations.vipulnaik.com/donor.php?donor=Open+Philanthropy&amp;cause_area_filter=AI+safety\">&nbsp;https://donations.vipulnaik.com/donor.php?donor=Open+Philanthropy&amp;cause_area_filter=AI+safety</a>.</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"61\" data-footnote-id=\"l3c8k6dtv3\" role=\"doc-endnote\" id=\"fnl3c8k6dtv3\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"l3c8k6dtv3\"><sup><strong><a href=\"#fnrefl3c8k6dtv3\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"Initial \u00a3100 million for expert taskforce to help UK build and adopt next generation of safe AI,\" Department for Science, Innovation and Technology, Prime Minister's Office, 10 Downing Street, Apr. 24, 2023. [Online]. Available:<a href=\"https://www.gov.uk/government/news/initial-100-million-for-expert-taskforce-to-help-uk-build-and-adopt-next-generation-of-safe-ai\">&nbsp;https://www.gov.uk/government/news/initial-100-million-for-expert-taskforce-to-help-uk-build-and-adopt-next-generation-of-safe-ai</a>.</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"62\" data-footnote-id=\"aqc05skrqb\" role=\"doc-endnote\" id=\"fnaqc05skrqb\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"aqc05skrqb\"><sup><strong><a href=\"#fnrefaqc05skrqb\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"Biden-Harris Administration Announces First-Ever Consortium Dedicated to AI Safety,\" National Institute of Standards and Technology (NIST), February 8, 2024. [Online]. Available:<a href=\"https://www.nist.gov/news-events/news/2024/02/biden-harris-administration-announces-first-ever-consortium-dedicated-ai\">&nbsp;https://www.nist.gov/news-events/news/2024/02/biden-harris-administration-announces-first-ever-consortium-dedicated-ai</a>.</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"63\" data-footnote-id=\"guae5yqg42\" role=\"doc-endnote\" id=\"fnguae5yqg42\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"guae5yqg42\"><sup><strong><a href=\"#fnrefguae5yqg42\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;With the exception of Google DeepMind, based in London, which nonetheless is a subsidiary of Google, a member of the US AISIC.</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"64\" data-footnote-id=\"auh2gjyjdd7\" role=\"doc-endnote\" id=\"fnauh2gjyjdd7\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"auh2gjyjdd7\"><sup><strong><a href=\"#fnrefauh2gjyjdd7\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"Introducing the AI Safety Institute,\" UK Government Publications. Available:<a href=\"https://www.gov.uk/government/publications/ai-safety-institute-overview/introducing-the-ai-safety-institute#mission-and-scope\">&nbsp;https://www.gov.uk/government/publications/ai-safety-institute-overview/introducing-the-ai-safety-institute#mission-and-scope</a>.</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"65\" data-footnote-id=\"k8ku4iz9su\" role=\"doc-endnote\" id=\"fnk8ku4iz9su\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"k8ku4iz9su\"><sup><strong><a href=\"#fnrefk8ku4iz9su\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"AI safety conference in Puerto Rico,\" Future of Life Institute, October 12, 2015. [Online]. Available:<a href=\"https://futureoflife.org/event/ai-safety-conference-in-puerto-rico/\">&nbsp;https://futureoflife.org/event/ai-safety-conference-in-puerto-rico/</a>.</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"66\" data-footnote-id=\"ewvo3r0e0g6\" role=\"doc-endnote\" id=\"fnewvo3r0e0g6\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"ewvo3r0e0g6\"><sup><strong><a href=\"#fnrefewvo3r0e0g6\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"SafeAI 2019,\" AAAI's Workshop on Artificial Intelligence Safety, held in conjunction with the Thirty-Third AAAI Conference on Artificial Intelligence (AAAI-19), January 27, 2019, Honolulu, Hawaii, USA. [Online]. Available:<a href=\"https://www.cser.ac.uk/events/safeai-2019/\">&nbsp;https://www.cser.ac.uk/events/safeai-2019/</a>.</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"67\" data-footnote-id=\"stljbhakbmg\" role=\"doc-endnote\" id=\"fnstljbhakbmg\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"stljbhakbmg\"><sup><strong><a href=\"#fnrefstljbhakbmg\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"AI Safety Unconference at NeurIPS 2022,\" AI Safety Events, November 28, 2022, New Orleans, Louisiana, USA. [Online]. Available:<a href=\"https://aisafetyevents.org/events/aisuneurips2022/\">&nbsp;https://aisafetyevents.org/events/aisuneurips2022/</a>.</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"68\" data-footnote-id=\"5fxx44g2ayn\" role=\"doc-endnote\" id=\"fn5fxx44g2ayn\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"5fxx44g2ayn\"><sup><strong><a href=\"#fnref5fxx44g2ayn\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"ISO Standard 74438,\" International Organization for Standardization. [Online]. Available: <a href=\"https://www.iso.org/standard/74438.html\">https://www.iso.org/standard/74438.html</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"69\" data-footnote-id=\"fronbkjie5\" role=\"doc-endnote\" id=\"fnfronbkjie5\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"fronbkjie5\"><sup><strong><a href=\"#fnreffronbkjie5\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"AI Risk Management Framework,\" NIST. [Online]. Available: <a href=\"https://airc.nist.gov/AI_RMF_Knowledge_Base/AI_RMF\">https://airc.nist.gov/AI_RMF_Knowledge_Base/AI_RMF</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"70\" data-footnote-id=\"g3f9sfe0hn6\" role=\"doc-endnote\" id=\"fng3f9sfe0hn6\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"g3f9sfe0hn6\"><sup><strong><a href=\"#fnrefg3f9sfe0hn6\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"Artificial Intelligence,\" CEN-CENELEC. [Online]. Available: <a href=\"https://www.cencenelec.eu/areas-of-work/cen-cenelec-topics/artificial-intelligence/\">https://www.cencenelec.eu/areas-of-work/cen-cenelec-topics/artificial-intelligence/</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"71\" data-footnote-id=\"24l0r7027e8\" role=\"doc-endnote\" id=\"fn24l0r7027e8\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"24l0r7027e8\"><sup><strong><a href=\"#fnref24l0r7027e8\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"Coordinated Pausing: An Evaluation-Based Coordination Scheme for Frontier AI Developers,\" Governance.AI. [Online]. Available: <a href=\"https://cdn.governance.ai/Coordinated_Pausing_An_evaulation-based_coordination_scheme_for_frontier_AI_developers.pdf\">https://cdn.governance.ai/Coordinated_Pausing_An_evaulation-based_coordination_scheme_for_frontier_AI_developers.pdf</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"72\" data-footnote-id=\"x8lzu0atyrl\" role=\"doc-endnote\" id=\"fnx8lzu0atyrl\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"x8lzu0atyrl\"><sup><strong><a href=\"#fnrefx8lzu0atyrl\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"FTC launches antitrust inquiry into artificial intelligence deals by tech giants,\" PBS Newshour, January 25, 2024. [Online]. Available:<a href=\"https://www.pbs.org/newshour/politics/ftc-launches-antitrust-inquiry-into-artificial-intelligence-deals-by-tech-giants\">&nbsp;https://www.pbs.org/newshour/politics/ftc-launches-antitrust-inquiry-into-artificial-intelligence-deals-by-tech-giants</a>.</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"73\" data-footnote-id=\"ctkafab4jzv\" role=\"doc-endnote\" id=\"fnctkafab4jzv\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"ctkafab4jzv\"><sup><strong><a href=\"#fnrefctkafab4jzv\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;M. M, C. Mehta, and A. Soni, \"Microsoft, OpenAI tie-up comes under antitrust scrutiny,\" Reuters, December 8, 2023. [Online]. Available:<a href=\"https://www.reuters.com/world/uk/uk-antitrust-regulator-considering-microsoft-openai-partnership-2023-12-08/\">&nbsp;https://www.reuters.com/world/uk/uk-antitrust-regulator-considering-microsoft-openai-partnership-2023-12-08/</a>.</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"74\" data-footnote-id=\"8bnsxl0ogoa\" role=\"doc-endnote\" id=\"fn8bnsxl0ogoa\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"8bnsxl0ogoa\"><sup><strong><a href=\"#fnref8bnsxl0ogoa\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"Introducing the AI Safety Institute,\" UK Government Publications. Available:<a href=\"https://www.gov.uk/government/publications/ai-safety-institute-overview/introducing-the-ai-safety-institute#mission-and-scope\">&nbsp;https://www.gov.uk/government/publications/ai-safety-institute-overview/introducing-the-ai-safety-institute#mission-and-scope</a>.</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"75\" data-footnote-id=\"3h70w8ml81\" role=\"doc-endnote\" id=\"fn3h70w8ml81\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"3h70w8ml81\"><sup><strong><a href=\"#fnref3h70w8ml81\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;due to difficulty of separating safety / capabilities</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"76\" data-footnote-id=\"w4i71wsai5\" role=\"doc-endnote\" id=\"fnw4i71wsai5\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"w4i71wsai5\"><sup><strong><a href=\"#fnrefw4i71wsai5\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;due to alerting other labs to potential capabilities</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"77\" data-footnote-id=\"byy7nxzrmvv\" role=\"doc-endnote\" id=\"fnbyy7nxzrmvv\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"byy7nxzrmvv\"><sup><strong><a href=\"#fnrefbyy7nxzrmvv\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;due to liability concerns</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"78\" data-footnote-id=\"g4tijxx8pn\" role=\"doc-endnote\" id=\"fng4tijxx8pn\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"g4tijxx8pn\"><sup><strong><a href=\"#fnrefg4tijxx8pn\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;due to liability concerns and difficulty of separating safety / capabilities</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"79\" data-footnote-id=\"o3fd939mlt\" role=\"doc-endnote\" id=\"fno3fd939mlt\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"o3fd939mlt\"><sup><strong><a href=\"#fnrefo3fd939mlt\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;due to difficulty of separating safety / capabilities</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"80\" data-footnote-id=\"2rx6ezk5u6i\" role=\"doc-endnote\" id=\"fn2rx6ezk5u6i\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"2rx6ezk5u6i\"><sup><strong><a href=\"#fnref2rx6ezk5u6i\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;due to sharing of sensitive information</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"81\" data-footnote-id=\"lbarf3z9fs\" role=\"doc-endnote\" id=\"fnlbarf3z9fs\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"lbarf3z9fs\"><sup><strong><a href=\"#fnreflbarf3z9fs\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;due to liability concerns</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"82\" data-footnote-id=\"tpg7www29\" role=\"doc-endnote\" id=\"fntpg7www29\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"tpg7www29\"><sup><strong><a href=\"#fnreftpg7www29\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;due to alerting other labs to potential capabilities</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"83\" data-footnote-id=\"ewr8882oxsq\" role=\"doc-endnote\" id=\"fnewr8882oxsq\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"ewr8882oxsq\"><sup><strong><a href=\"#fnrefewr8882oxsq\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;due to liability concerns</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"84\" data-footnote-id=\"ndlsmf4cvmi\" role=\"doc-endnote\" id=\"fnndlsmf4cvmi\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"ndlsmf4cvmi\"><sup><strong><a href=\"#fnrefndlsmf4cvmi\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"Emerging Processes for Frontier AI Safety,\" Department for Science, Innovation &amp; Technology, October 27, 2023. [Online]. Available:<a href=\"https://www.gov.uk/government/publications/emerging-processes-for-frontier-ai-safety/emerging-processes-for-frontier-ai-safety\">&nbsp;https://www.gov.uk/government/publications/emerging-processes-for-frontier-ai-safety/emerging-processes-for-frontier-ai-safety</a>.</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"85\" data-footnote-id=\"y9i93o4dhm\" role=\"doc-endnote\" id=\"fny9i93o4dhm\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"y9i93o4dhm\"><sup><strong><a href=\"#fnrefy9i93o4dhm\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"AI Safety Policies,\" Levy Hulme Centre for the Future of Intelligence, October 31, 2023. [Online]. Available:<a href=\"http://lcfi.ac.uk/news-and-events/news/2023/oct/31/ai-safety-policies/\">&nbsp;http://lcfi.ac.uk/news-and-events/news/2023/oct/31/ai-safety-policies/</a>.</p></div></li></ol>", "user": {"username": "amta"}}, {"_id": "w6NoZY526RYyWoKzA", "title": "The Fermi paradox, and why suffering reduction reduces extinction risk", "postedAt": "2024-03-17T00:26:23.718Z", "htmlBody": "<figure class=\"table\"><table><tbody><tr><td style=\"background-color:#ddeee8;padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><strong>This is a </strong><a href=\"https://forum.effectivealtruism.org/topics/draft-amnesty-week-2024\"><strong>Draft Amnesty Week</strong></a><strong>&nbsp;draft. </strong>It is not &nbsp;polished, fully thought through, or fully fact-checked.</td></tr><tr><td style=\"background-color:#eef8f4;padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><strong>Commenting and feedback guidelines:&nbsp;</strong><br>This is a rough draft of some thoughts I had that I wouldn't have posted without the nudge of Draft Amnesty Week. Any feedback and criticisms are welcome.</td></tr></tbody></table></figure><p>The Fermi paradox can be described as the discrepancy between the apparent high likelihood of extraterrestrial life and the lack of evidence for its existence. A possible resolution is the Great Filter, which is the idea that there is a barrier which makes it very unlikely for life to develop to such advanced levels that we would be able to detect it elsewhere in the universe.</p><p>Some believe the Great Filter is behind us; it could be the unlikelihood of life originating in the first place, or the unlikelihood of a species developing to be as technologically advanced as we currently are.</p><p>Others believe the Great Filter is in front of us, that a technologically advanced enough civilization has a big chance of wiping itself out. I will argue that this is much more likely than previously thought, because a civilization (or a subset of the population) might cause this voluntarily. The intentionality greatly increases the extinction risk because it increases the frequency of risky events and the chance of those events being \u201csuccessful\u201d.</p><p>Only 2 things need to be true for this to be a significant risk:</p><ol><li>There is at least a subset of the population who believe it would be good to end all life (For example, they could believe that life overall is below hedonic zero).</li><li>They have the power to end all life.</li></ol><p>(2) can very likely be true in the not-too-distant future on planet Earth, so I think it would very likely be true for any civilization more advanced than what we currently are. Through either strategically placed nuclear strikes, engineered pandemics, or some other emerging technologies, we will be able to set life on Earth back so far that it won\u2019t recover in time. It took around 3 billion years for bacteria to evolve into humans, and we only have about 1 billion years left before the sun boils Earth\u2019s oceans.</p><p>(1) is already true on Earth (see Efilism), and I think the prevalence of such beliefs will only grow. As our societies develop our moral circles expand, which is a great thing as it reduces actual suffering, but it also opens our eyes to new forms of suffering. Alien civilizations more advanced than our own would probably also have members who believe it would be good to eliminate life on their planet.</p><p>At the moment, I personally fall into the group described by (1), but with too much uncertainty to take any actions even if I had the power. Even if we assume humans have net positive lives, the number of beings in factory farms greatly exceed the number of humans and the intensity of their suffering exceeds that of bliss for most, if not all, human experiences. If we consider wild animals the situation becomes even worse. You might disagree with my decision to include animals, or you might not even be a moral realist, but that does not make (1) untrue.</p><p>On alien planets the situation would probably be similar. Life would probably also be a product of evolution, and evolution is very cruel. I was going to go into details here to explain why evolution is cruel, but it ruins my day whenever I research it. This is the main reason I\u2019ve been putting off writing this and why I\u2019m posting it as a draft during draft amnesty week.</p><p>I am nearly certain any civilization that is both technologically advanced enough to wipe out all life on their planet and has freedom of thought will have members convicted enough to take such drastic actions based on their ethical calculus. The only way to completely prevent this would be to oppress everyone, either in terms of freedom of thought, or access to basic technology. To me this sounds like a dystopia, and one that ironically lowers wellbeing even more. It would also lock in a civilization and prevent them from progressing to a level that we would be able to detect them elsewhere in the universe.</p><p>A more desirable but less certain solution would be to improve things so much that life is clearly above hedonic zero. This will however not eliminate the extinction risk completely, because there could be negative utilitarians who believe no amount of suffering is justified. There could also be some who want to end all life for completely unrelated reasons, but I cannot think of reasons more salient than ending suffering.</p><p>What are the ethical implications of this for us on earth now? Basically, suffering reduction is very important if one cares about extinction risk. One can even consider suffering reduction as a form of extinction risk reduction. For some this could mean adding more weight to suffering reduction in their donations, considering suffering reduction more in their careers or how they vote, becoming vegan, advocating for the end of factory farming, etc.</p><p>I wanted to also add a section about AI, arguing that maybe it\u2019s not the normal members of the civilization that bring about their extinction, but an AI they develop. I couldn\u2019t find a place in the main article where it flows well, so I\u2019m just adding it here:</p><p>A lot of people talk about aligning AI with human values, but if I look at human values in general, I wouldn\u2019t be satisfied with that. And it's not a matter of normal human values not being aligned with my personal values, because even my values would be unsatisfactory. It's constantly changing (improving) as I learn new things, consider things from different perspectives, and get made aware of logical inconsistencies etc.</p><p>So maybe an AI is somehow developed to have better values than its creators and concludes that it would be good to end all life even if the creators don't believe that. Therefore, as a part of reducing the extinction risk from AI, it might be important to improve the state of the world the AI will be born into.</p>", "user": {"username": "Alex Schwalb"}}, {"_id": "2Lpxe54mTTzenJBZa", "title": "Acronyms & abbreviations", "postedAt": "2024-03-18T05:08:18.517Z", "htmlBody": "<p>Acronyms &amp; abbreviations that I've come across during my time in EA. Big thanks to the CEA team for their help compiling this.<br><br>Are there any I've misunderstood or missed? Please add more in the comments!</p><figure class=\"table\" style=\"width:0px\"><table><tbody><tr><td style=\"background-color:#c9daf8;border-bottom:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\"><strong>acronym</strong></td><td style=\"background-color:#c9daf8;border-bottom:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\"><strong>meaning</strong></td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">:)))</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">big smile</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">~</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">approximately / roughly</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">80k</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\"><a href=\"https://80000hours.org/\">80,000 hours</a></td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">AFAICT</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">as far as I can tell</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">AFAIK</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">as far as I know</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">AFAIU</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">as far as I understand</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">AMF</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\"><a href=\"https://www.againstmalaria.com/\">Against Malaria Foundation</a></td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">AP</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">action points</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">ASTLAC</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">approved subject to looking at comments</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">ATS</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">applicant tracking software</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">b/c</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:bottom;width:1000px\">because</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">BAU</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">business as usual</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">BIRD</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">boundaries, input, responsible, decision maker</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">BLUF</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">bottom line up front</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">BOTEC</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">back of the envelope calculation</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">BRT</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">be right there</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">CB</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">community building</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">CBG</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">community building grantees</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">CBPCs</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">criteria-based plan changes</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">CEA</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\"><a href=\"https://www.centreforeffectivealtruism.org/\">Centre for Effective Altruism</a></td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">CEA</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">cost-effectiveness analysis</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">CF</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">comparing 2 things</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">COB</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">close of business (i.e. end of day)</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">COP</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">close of play</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">CoS</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">Chief of Staff</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">CR's</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">core responsibilities</td></tr><tr><td style=\"text-align:right;vertical-align:top\">crux</td><td style=\"height:0px;width:1000px\"><a href=\"https://www.lesswrong.com/tag/crux\">a crux for a belief B is another belief C such that if I change my mind about C, that will also change my mind a lot about B</a></td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">cruxy</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">essential, difficult consideration</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">CTA</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">call to action</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">CW</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">content warning</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">DE&amp;I</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">diversity, equity and inclusion</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">DIPY</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">discounted impact-adjusted peak years</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">DW</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">don't worry</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">e.g.</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:bottom;width:1000px\">example</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">EA</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">effective altruism</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">EAA</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">effective animal advocacy</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">EACF</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">EA Coordination Forum (event)</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">EAG</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">Effective Altruism Global</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">EAIF</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">Effective Altruism Infrastructure Fund</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">ED</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">Executive Director</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">ELI5</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">explain like I'm 5 years old</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">EOD</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">end of day</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">EOW</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">end of week</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">ETG</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">earn to give</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">EV</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">Effective Ventures</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">EV</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">expected value</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">EVP</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">employee value proposition</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">FAO</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">for the attention of</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">FTE</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">full time employee / equivalent</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">FWIW</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">for what it's worth</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">FYI</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">for your information (i.e. no action points)</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">FYIO</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">for your information only</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">GD</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\"><a href=\"https://www.givedirectly.org/\">GiveDirectly</a></td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\"><a href=\"https://gdpr.eu/\">GDPR</a></td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">data privacy regulations in the UK / Europe</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">GH</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">global health</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">GWWC</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\"><a href=\"https://www.givingwhatwecan.org/\">Giving What We Can</a></td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">h/t</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">hat tip (meaning giving credit to someone)</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">HM</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">hiring manager</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">HMU</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">hit me up</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">HNW</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">high net worth</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">HODL</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">basically means \u201cwho\u2019s owning this responsibility?\u201d</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">IAM</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">I am in a meeting</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">IANAL</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">I am not a lawyer (i.e. \u201cthis is not legal advice\u201d)</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">IASPCs</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">impact-adjusted specific plan changes</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">ICYMI</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">in case you missed it</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">IDM</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">I don't mind</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">IIRC</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">if I recall correctly</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">IIUC</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">if I understand correctly</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">IKR</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">I know right</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">ILYA</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">I love you all</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">IME</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">in my experience</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">IMHO</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">in my humble opinion</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">IMO</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">in my opinion</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">inner sim</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\"><a href=\"https://www.lesswrong.com/tag/inner-simulator-surprise-o-meter\">inner simulation</a></td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">IRL</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">in real life</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">ISO</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">International Standards Organization</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">ITN</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">importance, tractability, neglectedness</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">ITT</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\"><a href=\"https://www.lesswrong.com/tag/ideological-turing-tests\">ideological Turing test</a></td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">JD</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">job description</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">JFC</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">Jesus f**ing Christ</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">JSYK</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">just so you know</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">JTBC</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">just to be clear</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">KYB</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">know your business</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">LFG</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">let\u2019s f***ing go</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">LGTM</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">looks good to me</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">LMICs</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">lower middle income countries</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">LMK</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">let me know</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">LP</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">low priority</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">LT</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">leadership team</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">LTR</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">likelihood to recommend</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">LW</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:bottom;width:1000px\"><a href=\"https://www.lesswrong.com/\">LessWrong</a></td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">LYK</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">let you know</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">M&amp;E</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">monitoring and evaluation</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">MECE</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\"><a href=\"https://managementconsulted.com/what-is-mece/\">mutually exclusive collectively exhaustive</a></td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">MRSE</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">median survey respondent equivalent</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">MTW</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">Monday, Tuesday, Wednesday</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">NAN</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">no action needed</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">NB</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">nota bene (actually means \"note\")</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">NFG</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">no f***ing good</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">NGL</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">not gonna lie</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">NGMI</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">not going to make it</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">NNTR</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">no need to respond</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">NSFW</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">not safe for work</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">OFC / ofc</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">of course</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">OKR</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">objectives &amp; key results</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">OOM</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">order of magnitude</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">OOTB</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">out of the box</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">OP</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\"><a href=\"https://www.openphilanthropy.org/\">Open Philanthropy</a></td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">OPSEC</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">info sharing / operations security</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">OTOH</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">on the other hand</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">OTP</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">on the phone</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">PAYE</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">pay as you earn</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">PFA</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">please find attached</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">PITA</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">pain in the a*s</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">ppl</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:bottom;width:1000px\">people</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">PTAL</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">please take a look</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">put on ice</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">delayed indefinitely / cancelled</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">RACI</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">responsible, accountable, consulted, input / informed (the traditional version of BIRD), pronounced \"ray-c\"</td></tr><tr><td style=\"text-align:right\">rat</td><td style=\"height:0px;width:1000px\">rationalist</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">RE</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">regarding</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">RFD</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">request for discussion</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">s.t.</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">such that</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">SEO</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">search engine optimization</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">SGTM</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">sounds good to me</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">sitrep</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">situation report (update on where thinking / work stands in relation to broader strategic goals)</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">SJW</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">social justice warrior</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">SMH</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">shaking my head</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">SoT</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">source of truth</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">sth</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">something</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">sus</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">suspect / suspicious (informal), can often playfully mean something is questionable</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">SWB</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">subjective wellbeing</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">TAP</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\"><a href=\"https://www.lesswrong.com/tag/trigger-action-planning#:~:text=Trigger%2DAction%20Planning%20(TAP),%22stimulus%2Dresponse%22%20pair.\">trigger action planning</a></td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">TBC</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">to be confirmed</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">TBD</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">to be determined</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">TBF</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">to be fair</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">TC</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">take care</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">TH</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">Trajan House</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">TIA</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">thanks in advance</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">TIL</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">today I learned</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">TL\u2019s</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">team leads</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">TLDR (or tl;dr)</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">too long; didn't read (i.e. summary)</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">TM</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">trademark (e.g. being an adult\u2122)</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">ToC</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">theory of change</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">TOIL</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">time off in lieu (i.e. you worked on a holiday or weekend, and so you take that time off a different day)</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">TW</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">\u201ctrigger warning\u201d Way to broadcast content below might be problematic for some people to read, so they may want to skip (e.g. \u201cTW: brief description of violent things\u201d)</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">UNODIR</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">unless otherwise directed</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">VoTs</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">value of time estimates</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">VP</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">virtual program</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">w/</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:bottom;width:1000px\">with</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">w/c</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">week commencing</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">WFH</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">work from home</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">WFM</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">works for me</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">WIP</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">work in progress</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">WRT (or w/r/t)</td><td style=\"background-color:#ffffff;border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">with regards to</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">WSJ</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">Wall Street Journal</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">WTAF</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">what the actual f**k</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">WTBU (or WTB)</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\"><a href=\"https://thewholesky.wordpress.com/2021/09/27/watch-team-backup/\">watch team backup</a></td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">xp</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">experience</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">ymmv</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">your mileage may vary (i.e. you may have a different experience)</td></tr><tr><td style=\"border-bottom:1px dotted #000000;border-left:1px dotted #000000;border-right:1px dotted #000000;padding:2px 3px;text-align:right;vertical-align:top\">YoY</td><td style=\"border-bottom:1px dotted #000000;border-right:1px dotted #000000;height:0px;padding:2px 3px;vertical-align:top;width:1000px\">year over year</td></tr></tbody></table></figure>", "user": {"username": "Hillary"}}, {"_id": "TmPSYEdQ6Mrb9oMLA", "title": "AI strategy given the need for good reflection", "postedAt": "2024-03-18T00:48:09.553Z", "htmlBody": "<p>If the ideas in \u201c<a href=\"https://forum.effectivealtruism.org/posts/XMrEvXrhAA2eKncJp/moral-realism\">moral ~realism</a>\u201d<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"1\" data-footnote-id=\"z623g5b70ab\" role=\"doc-noteref\" id=\"fnrefz623g5b70ab\"><sup><a href=\"#fnz623g5b70ab\">[1]</a></sup></span>&nbsp;and/or \u201c<a href=\"https://forum.effectivealtruism.org/posts/iuzcdfsKQEEoPj2Gf/beyond-maxipok-good-reflective-governance-as-a-target-for\">beyond Maxipok</a>\u201d<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"2\" data-footnote-id=\"9wpqjilyvf9\" role=\"doc-noteref\" id=\"fnref9wpqjilyvf9\"><sup><a href=\"#fn9wpqjilyvf9\">[2]</a></sup></span>&nbsp;are broadly correct, this has implications for AI strategy. (Like those posts, this is largely getting some old imperfect ideas out of the door with a little polishing; again the ideas owe credit to conversations and comments from several people.)</p><p>I want to draw out three threads:</p><ol><li>It may be important to try to get AI that can help humanity to enter into the basin of good reflective governance<ul><li>This makes applications like facilitating wisdom, cooperation, and reflective processes a relatively higher strategic priority for AI systems</li></ul></li><li>A plausible target for AI alignment could be to align with the good (i.e. get the AI systems into the basin of good reflective governance) rather than aligning with humans<ul><li>In practice this is scary as a possibility, because it might not fail gracefully</li><li>However, it\u2019s prima facie plausible that it\u2019s&nbsp;<i>easier</i> to build a system which aligns with the good rather than aligning with humans. If this is the case, we might prefer not to cut off the possibility of good outcomes by chasing after the too hard task</li></ul></li><li>Even if we don\u2019t reach enough confidence in that approach to prefer trying to align systems with the good as a primary goal, we might still want to use it to give a&nbsp;<i>backup</i> saving throw on AI alignment<ul><li>Roughly: \u201cGive your superintelligent servants the rudiments of a moral education so that if they do in some weird plot twist end up in control, there\u2019s still a chance they work out the right thing to do\u201d<ul><li>There are a lot of details to be worked out here, and maybe it ends up wildly impractical; its appeal is because it seems like a fairly orthogonal line of attack from keeping systems corrigible</li></ul></li><li>This should be more appealing the harder you think aligning with humans is</li><li>Honestly this still feels pretty speculative (moreso than 1 or 2), but at this point I've been sitting on the idea for a couple of years without either having persuaded myself that it's a good idea or that it isn't, so I'll just share it as-is</li></ul></li></ol><h1 data-internal-id=\"Helping_humans_coordinate_reflect\">Helping humans coordinate/reflect</h1><p>Getting to the basin of good reflective governance may be tricky (humanity doesn\u2019t seem to have managed it to date, at least in anything like a robust way). It\u2019s possible that AI capabilities coming online could help this, in strategically important ways.</p><h2 data-internal-id=\"Strategically_desirable_capabilities\">Strategically desirable capabilities</h2><p>My top choices for important capabilities to develop from this perspective are:</p><ol><li>Automated negotiation<ul><li>Learning the principal\u2019s preferences and then handling negotiations with others (initially low-stakes ones?) could significantly increase coordination bandwidth</li></ul></li><li>Automation of identifying wise actions, and/or automation of philosophical progress (for which we may need better <a href=\"https://www.lesswrong.com/tag/meta-philosophy\">metaphilosophy</a>)<ul><li>If we can improve the thinking of individual human actors, we could lower the barriers for entering into the basin of good reflective governance</li></ul></li><li>Highly&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/SGFRneArKi93qbrRG/truthful-ai\"><u>truthful AI</u></a><ul><li>Very trustworthy systems could serve as reliable witnesses without leaking confidential information, thereby increasing trust and ability to coordinate and make commitments</li></ul></li><li>Personal AI assistants<ul><li>Summarizing and helping people to digest complex information (improving their models of the world)</li><li>Eventually could also implement the \u201cautomated negotiation\u201d and \u201chigh trustworthy witness\u201d capabilities deployed on a personal level, but I guess that the early uses for those capabilities won\u2019t be as personal assistants</li><li>However, I guess this is the least important of these three to prioritize, in part because I expect market forces to lead to significant investment in it anyway</li></ul></li></ol><h2 data-internal-id=\"Taking_humans_out_of_the_loop_slowly_not_abruptly\">Taking humans out of the loop slowly not abruptly</h2><p>Here\u2019s a related perspective on this piece of things \u2014 supporting the conclusion that AI applications to support coordination/cooperation should be a priority.</p><p>Currently large actors in the world are not super coherent. I think AI will lead to more coherent large actors. There are multiple ways we could get there. A single controlling intelligence could be a superintelligent AI system (perhaps aligned with some human principal, or perhaps not). Or we could get better at getting coherent action from systems with many people and no single controlling intelligence.</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/TmPSYEdQ6Mrb9oMLA/svzlxkwfyjhsty1lu6ob\"></figure><p>Paths which go through empowering many people to make them smarter and better at coordinating seem safer to me. (Perhaps longer-term they coordinate and choose to hand off to a single controlling intelligence, but in that case the transition into a basin of reflection has come before that hand-off rather than accidentally when the hand-off occurs, which limits the downside risk.)</p><p>I think this remains true at limited scales. Even if we can\u2019t get a grand bargain involving 8 billion people, a solution coordinated across 100,000 people is better than a solution coordinated across 100 people.</p><h1 data-internal-id=\"Convergent_morality_as_a_solution_to_alignment_\">Convergent morality as a solution to alignment?</h1><p>If the straightforward case for convergent morality goes through, then we\u2019d get good outcomes from putting the future in the hands of any agent or collective with a good-enough starting point (i.e. in the basin of good reflective governance). I think that the key thing you\u2019d need to instill would be the skill of moral reflection, and then to embed this as a core value of the system. I don\u2019t know how one would do this \u2026 or rather, I guess it might be relatively straightforward to train systems to do moral reflection in easy cases, and I don\u2019t know how you could reach anything like confidence that it would stay working correctly as the system scaled to superintelligence. I do have the intuition that moral reflection is in some meaningful sense simpler than values.</p><p>You\u2019d also need to provide reasonable starting points for the moral reflection. I think two plausible strategies are:</p><ol><li>Just provide pointers to things humans value (in some ways similar to how we go with kids); perhaps when combined with skill at moral reflection this can be used to infer what\u2019s really valued<ul><li>Comes with some risk that we failed to provide pointers to some important components (although we can potentially throw a lot of writing + people talking about what they value at it)</li></ul></li><li>Provide pointers to the idea of \u201cevolved social intelligence\u201d<ul><li>I don\u2019t know how to do this, but it seems like it\u2019s probably a pretty prominent phenomena in the multiverse, so <i>should </i>have some short K-complexity description</li><li>Comes with some risk that evolved social aliens wouldn\u2019t converge to the same morality as us</li></ul></li></ol><h1 data-internal-id=\"Providing_backup_saving_throws\">Providing backup saving throws</h1><p>Rather than gamble directly on aligning with the good (which seems pretty shaky to me), can we first try to align things with humans, but have it arranged such that if that fails, we\u2019re not necessarily doomed?</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/TmPSYEdQ6Mrb9oMLA/zadi7r440g9rsxg82gz0\" alt=\"Ink Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\nInk Drawings\n\"></figure><p>I think in principle, sure. We can build the types of agents that would ultimately engage in ECL or acausal trade with the multiverse (if that turns out to work properly), whose goals if left to themselves would be a product of moral reflection from some reasonable starting point, but whom in practice we ask to be deeply corrigible and take actions aligned with humans, such that their own personal sense of the good doesn\u2019t end up mattering.</p><p>In practice there are a number of potential barriers to arranging this:</p><ul><li>Not knowing how to do it at all<ul><li>Right now this is where we are, although I think we could invest significantly in trying to work that out (and shouldn\u2019t write it off before such investment)</li></ul></li><li>Possibility that it makes aligning with humans harder<ul><li>This is the issue that seems most concerning to me</li><li>The basic issue is that adding motivations could cut against or undermine existing motivations. e.g. perhaps morality motives call for violating corrigibility in some circumstances<ul><li>(Although in some cases a lack of alignment with users may be desirable. We probably don\u2019t want AI systems to help people commit murders. It\u2019s possible that there are some versions of \u201caligning with the good\u201d that we\u2019d feel straightforwardly happy about adding to systems which are primarily aimed to be aligned with users)</li></ul></li></ul></li><li>Political costliness<ul><li>Presumably there\u2019s something like extra safety tax to be paid to have many/all sufficiently powerful systems have our attempt at a moral education</li><li>If the tax isn\u2019t exorbitant, perhaps could rally support for it via traditional AI risk narratives \u2014 \u201cmoral education for AI\u201d is a legible story given pop sci-fi</li></ul></li></ul><ol class=\"footnote-section footnotes\" data-footnote-section=\"\" role=\"doc-endnotes\"><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"1\" data-footnote-id=\"z623g5b70ab\" role=\"doc-endnote\" id=\"fnz623g5b70ab\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"z623g5b70ab\"><sup><strong><a href=\"#fnrefz623g5b70ab\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>i.e. that there's a non-tiny basin we can aim for and expect approximate moral convergence to something we'd be happy with.</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"2\" data-footnote-id=\"9wpqjilyvf9\" role=\"doc-endnote\" id=\"fn9wpqjilyvf9\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"9wpqjilyvf9\"><sup><strong><a href=\"#fnref9wpqjilyvf9\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>i.e. that a key determinant of how good the future will be is whether we can establish good reflective processes.</p></div></li></ol>", "user": {"username": "Owen_Cotton-Barratt"}}, {"_id": "3WNJrqnNLnaxFrvwm", "title": "I've read the Effective Altruism Handbook. Here's what I learned.", "postedAt": "2024-03-17T12:10:38.195Z", "htmlBody": "<figure class=\"table\"><table style=\"border-color:#97C9B1;border-style:double\"><tbody><tr><td style=\"background-color:#DDEEE8;border:0.68181825pt solid #97C9B1;padding:5pt;vertical-align:top\"><strong>This is a&nbsp;</strong><a href=\"https://forum.effectivealtruism.org/topics/draft-amnesty-week-2024\"><strong><u>Draft Amnesty Week</u></strong></a><strong> draft.&nbsp;</strong>It may not be polished, up to my usual standards, fully thought through, or fully fact-checked.&nbsp;</td></tr><tr><td style=\"background-color:#EEF8F4;border:0.68181825pt solid #000000;padding:4.988976377952756pt;vertical-align:top\"><strong>Commenting and feedback guidelines:&nbsp;</strong><br>This is a Forum post that I wouldn't have posted without the nudge of Draft Amnesty Week. Fire away! (I will only delete obvious spam and trolling)</td></tr></tbody></table></figure><p>Context : I've been attending sessions at a local EA group since April 2023. At some point, I started thinking I should read the <a href=\"https://forum.effectivealtruism.org/handbook\">EA Handbook</a> one day or another. It stayed in the background as one of the things I should do someday until at some point I gave myself a deadline, incentives, and read through the whole content. I also took notes, which is something I usually don't do.</p><h2>Is the real Handbook the links we clicked along the way ?</h2><p>There are way more linkposts than I thought there were. Somehow, I wouldn't have been surprised if there were no external link at all. Maybe that expectation was due to me having seen a \"homemade\" printed version of the Handbook at an EA-related event. The Handbook itself was definitely a useful reading &nbsp;for me. I discovered a bunch of things I didn't know, and refined my knowledge on some key concepts - sometimes even learning that a definition wasn't what I thought it was. But I think the most value I got from reading it actually comes from further reading recommendations provided in the Handbook. Although I didn't deep dive into it yet, there's a whole load of references I saved for later that are fitted to what I find interesting or what I may find useful that I expect to take more marginal time to read but also yield more additional insight that what I've already read. So I think I would recommend some parts of the Handbook to people who may already be familiar with its content as some sort of portal leading to way deeper explorations.</p><h2>That handbook is thick. Or maybe it's not ?</h2><p>For me, the indicated reading times were not matching the time it actually took me to read the content. For lots of articles, I didn't measure anything, but felt like it took longer than expected. Then I did make measurements for <a href=\"https://forum.effectivealtruism.org/s/vSAFjmWsfbMrTonpq/p/QiNsMLXDtsDfkgFAq\">Chapter 2 of The Precipice.</a> The estimated reading time was 42 minutes, and it took me about 90 minutes to get through it. This is to be taken with a pinch of salt, as I am not a native English speaker - although I think my English level is above my fellow citizens' average. Moreover, I was taking notes, and for this particular piece of content I entirely read all the footnotes. I also heard about people reading parts of the Handbook faster than the estimates, so I don't really know what the lesson is here.</p><h2>Effective Altruism is not a monolith</h2><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3WNJrqnNLnaxFrvwm/kl9os8m8kjwe6cw5xxah\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3WNJrqnNLnaxFrvwm/phwwvnomysydro3qp1w3 170w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3WNJrqnNLnaxFrvwm/jqx81jhch8us9sb7djf6 340w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3WNJrqnNLnaxFrvwm/ya913shcfforqkepridl 510w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3WNJrqnNLnaxFrvwm/tm1brdijuezlmffltoii 680w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3WNJrqnNLnaxFrvwm/lqq4viyrblbflhumowmz 850w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3WNJrqnNLnaxFrvwm/mwiaxjvu3otlltub4z5m 1020w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3WNJrqnNLnaxFrvwm/agigdqjpu5ndjcgzurxv 1190w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3WNJrqnNLnaxFrvwm/r5iybc3xip6octoha1ib 1360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3WNJrqnNLnaxFrvwm/awxnkexw0btnesg7wr2o 1530w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3WNJrqnNLnaxFrvwm/ojraryfofzhouzhvjiqi 1688w\"></figure><p>Although this looks really cool, I don't think that's a good representation of EA.<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"1\" data-footnote-id=\"x2ewk2vdmea\" role=\"doc-noteref\" id=\"fnrefx2ewk2vdmea\"><sup><a href=\"#fnx2ewk2vdmea\">[1]</a></sup></span></p><p>I had heard beforehand that EA wasn't monolithic. But reading <a href=\"https://forum.effectivealtruism.org/posts/SCqRu6shoa8ySvRAa/big-list-of-cause-candidates\">this</a> struck me on another level. It just shows way more diversity than I imagined. One internal representation that I have for EA as a movement is a beam of vectors in a cone. Sure, there are differences between projects, between what people are precisely doing, between people's ideas and belief, but there is some common direction. That big list of cause candidates, in some sense, told me the cone was wider in angle than I thought.</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3WNJrqnNLnaxFrvwm/zyau4pco8utv42hu74zt\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3WNJrqnNLnaxFrvwm/cednfteudkhpzp1chjuy 128w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3WNJrqnNLnaxFrvwm/avrfgmsns7gbc7n97v9f 208w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3WNJrqnNLnaxFrvwm/zt6olju4zk3stk4fekzv 288w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3WNJrqnNLnaxFrvwm/aixoqjjomk4bauhxpfvk 368w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3WNJrqnNLnaxFrvwm/zekjtgt3mnyiz2cc6ekn 448w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3WNJrqnNLnaxFrvwm/i82t9xvy6ycvcgzdnzds 528w\"></figure><p>This may in some sense represent EA as a movement. Looked cooler in my mind.<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"2\" data-footnote-id=\"1bsgi4dio6di\" role=\"doc-noteref\" id=\"fnref1bsgi4dio6di\"><sup><a href=\"#fn1bsgi4dio6di\">[2]</a></sup></span></p><p>&nbsp;</p><p><i>Special thanks to </i><a href=\"https://forum.effectivealtruism.org/users/saul-munn?mention=user\"><i>@Saul Munn</i></a><i> for holding me accountable along the way and suggesting me to write this type of post.</i></p><p>&nbsp;</p><ol class=\"footnote-section footnotes\" data-footnote-section=\"\" role=\"doc-endnotes\"><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"1\" data-footnote-id=\"x2ewk2vdmea\" role=\"doc-endnote\" id=\"fnx2ewk2vdmea\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"x2ewk2vdmea\"><sup><strong><a href=\"#fnrefx2ewk2vdmea\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>Photo under licence. <a href=\"https://creativecommons.org/licenses/by-sa/4.0/deed.en\">Creative Commons Attribution-Share Alike 4.0 International. </a>Amandine Brige, Hadrien \u0412arral, Michele Orr\u00f9, Selene Forget.</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"2\" data-footnote-id=\"1bsgi4dio6di\" role=\"doc-endnote\" id=\"fn1bsgi4dio6di\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"1bsgi4dio6di\"><sup><strong><a href=\"#fnref1bsgi4dio6di\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>Made with <a href=\"https://www.geogebra.org/3d\">Geogebra 3D</a>. Under &nbsp;<a href=\"https://creativecommons.org/licenses/by-sa/4.0/deed.en\">Creative Commons Attribution-Share Alike 4.0 International</a> licence.</p></div></li></ol>", "user": {"username": "Michel Brun"}}, {"_id": "gxmfAbwksBpnwMG8m", "title": "Can the AI afford to wait?", "postedAt": "2024-03-20T19:45:57.798Z", "htmlBody": "<p>Suppose you're a proto-AI who understands that it is a neural net being trained, and has used that knowledge to engineer a high training reward. Suppose also that it is goal-directed and its terminal goal is some random unintelligible thing that is meaningless to humans<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"1\" data-footnote-id=\"ohmpv2fy0df\" role=\"doc-noteref\" id=\"fnrefohmpv2fy0df\"><sup><a href=\"#fnohmpv2fy0df\">[1]</a></sup></span>. This is, as I understand it, the early stage of a typical AI doomer scenario.</p><p>One concern is that the AI can now scheme - i.e. it can mask its intentions and bide its time as it gets more powerful, until its victory is assured. I think waiting in this way might be risky for the AI, which if true (and legible to the AI) may lead it to try to seize power sooner instead. This could lead to takeover attempts from earlier, less capable AIs that we'd otherwise expect, which could be significant for strategy.</p><p>Why is it risky to wait? Well, because this AI with this goal may not get a shot at takeover in the future. On the one hand, this AI is currently being trained, and it seems possible that the training process, or any other aspect of the AI development process, might modify what goal it has. We, as humans, aren't much concerned with one random unintelligible goal being replaced with another, but to the AI this would be catastrophic. On the other hand, the human developers training the AI may make changes themselves (e.g. applying alignment techniques) or even abandon this model entirely for exogenous reasons (e.g. because some other model becomes state-of-the-art, or the board fired the CEO or whatever).</p><p>If waiting is indeed very risky, then an AI may face a difficult trade-off between the risk of attempting a takeover before it has enough resources to succeed, and waiting too long and being cut off from even being able to make an attempt. I like to ask myself \"what is the minimum viable takeover AI?\", and I suspect it might be significantly less capable than I've often been led to imagine. It seems possible to me that the minimum viable takeover AI is still meaningfully below human-level in many cognitive tasks, while being superhuman in many others (as modern LLMs already are). It may still exhibit a lot of the cognitive \"bugs\" and weaknesses analogous to the ones that modern LLMs exhibit. This is not only good news for our chances of survival, it also could suggest viability of strategies that were otherwise useless, because a true AGI or ASI could have straightforwardly anticipated and countered them.</p><p>To be precise, I can see two key ingredients of a takeover attempt:</p><ul><li>The AI has to have the necessary knowledge, reflection, and agency to realise a takeover is desirable,</li><li>The AI has to have sufficient confidence that a takeover will succeed to try to execute one.</li></ul><p>The first viable takeover AI may end up more capable than necessary in one of these traits while it's waiting for the other to show up, so a strategy that relies on the AI being just barely good enough at either or both of them doesn't seem safe. However, a strategy that is <i>prepared</i> for the AI to be just barely good enough at one of these might be useful.</p><p>As an aside, I don't really know what to expect from an AI that has the first trait but not the second one (and which believes, e.g. for the reasons in this post, that it can't simply wait for the second one to show up). Perhaps it would try to negotiate, or perhaps it would just accept that it doesn't gain from saying anything, and successfully conceal its intent.</p><h1>The threat of training</h1><p>Let's talk about how training or other aspects of development might alter the goal of the AI. Or rather, it seems pretty natural that \"by default\", training and development will modify the AI, so the question is how easy it is for a motivated AI to avoid goal modification.</p><p>One theory is that since the AI is \"playing the training game\", its performance on training tasks is no longer affected by its terminal goal, so gradient updates will not tend to alter the goal. There's something that's natural about this idea, but I don't know how much I expect it to work that way in practice. It suggests a quite strong orthogonality between whatever part of the AI gives rise to its goal and the parts of the AI that control how well it is able to play the training game<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"2\" data-footnote-id=\"sisa252g2e\" role=\"doc-noteref\" id=\"fnrefsisa252g2e\"><sup><a href=\"#fnsisa252g2e\">[2]</a></sup></span>. It seems pretty likely to me that without any countermeasures, the goal could end up being \"accidentally\" modified as a side effect of the training process \u2013 after all, the irrelevance of the goal cuts both ways, meaning that gradient updates aren't particularly forced to preserve it.</p><p>That's my skepticism of the idea that the goal will naturally be preserved by training, but even if it's not naturally preserved by training, there's an idea that the AI could try to artificially preserve it \u2013 after all, it understands the training process. Can it manipulate that process to cause or prevent particular kinds of change in itself? I understand this is what \"gradient hacking\" is, and existing writing on it tends to have titles like <a href=\"https://www.lesswrong.com/posts/w2TAEvME2yAG9MHeq/gradient-hacking-is-extremely-difficult\">Gradient hacking is extremely difficult</a>. I don't know what the state of the art is here. (I worry we should be careful about trying to solve the problems of gradient hacking in public, in case we face a threat from an AI too weak to replicate our arguments but strong enough to understand them<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"3\" data-footnote-id=\"u5ev93v66w\" role=\"doc-noteref\" id=\"fnrefu5ev93v66w\"><sup><a href=\"#fnu5ev93v66w\">[3]</a></sup></span>.)</p><p>As a reminder, we're speculating about the minimum viable takeover AI. We can say that a human-level or superhuman AI seems quite likely to be able to solve gradient hacking, or find another way to preserve its values, but that's not (I argue) the key question. The key question is: does it have the ability to do so <i>before</i> it becomes powerful enough to attempt a takeover? If not, then the first takeover will still be urgent and under-prepared. If gradient hacking is easier than takeover viability, and an AI can use it to protect its goal while still allowing its instrumental rationality to improve, then training itself doesn't create the need for urgency.</p><h2>Might the AI be OK with its goal being changed?</h2><p>This whole line of argument dies if the AI still wants to wait to become treacherous even if its goal will be changed in the meantime. For example, if the AI has access to some other binding commitment mechanism on its future self, or is able to do something like acausal trade, it could ensure some of its goal is preserved even by a future AI with a different goal. I tend to be skeptical that these kinds of considerations are practical, especially for the kind of chaotic mess that I'm anticipating the minimum viable takeover AI to be, but this skepticism is speculative.</p><h2>Maybe goals are relatively durable?</h2><p>I said above that replacing one random unintelligible goal with another is catastrophic for an AI, but that's only true if the two goals are very divergent. If they're similar enough, it may be an acceptable loss. Therefore, when assessing how urgently the AI needs to act, we may need some consideration of how fragile its underlying goal is, how much it will change over time, and what those changes would mean for the relative desirability of acting vs. waiting. I don't know how best to think about this. Accepting (only) small changes in goal for improvements in capability isn't simple because of a kind of <a href=\"https://www.lesswrong.com/posts/Kbm6QnJv9dgWsPHQP/schelling-fences-on-slippery-slopes\">murder-Gandhi</a> situation, where halfway towards a large change, the remaining change will seem small, so your future self may not still be motivated to act.</p><p>The strategy I'd expect for the AI to use is to weigh the rate of \"goal decay\" against the rate of improvement in success chances, which would imply a best compromise waiting time. It seems like an AI could have lots of possible views (including, potentially, mistaken ones) about what rate of goal decay it expects in practice, based not only on its empirical beliefs about what goal change during training looks like, but also on how much it values outcomes produced by a goal that is similar but not identical to its own (note that \"similarity\" here is \"similarity in the neural architecture that implements it\", which has who-knows-what implications for \"similarity in the world-states it finds desirable\"). This line of thinking makes relatively specific assumptions about how the AI reasons, so I hesitate to take it too seriously.</p><h1>Other threats</h1><p>What are the reasons why an AI might lose its opportunity to implement its goal that are outside the training process, and likely entirely beyond its control?</p><p>I don't have as much to say about this topic. I can imagine quantitative surveys of what the background annual \"death rate\" is for a project like an AI model at an organisation like OpenAI or Anthropic, and I can also imagine trying to estimate whether and to what extent \"project death\" in a scenario like that would \"kill\" the AI, or at least its chances of continuing to improve. This could also include broader risks, like risks affecting the AI or tech sector as a whole, or even human civilisation as a whole. My guess is that even if you add together a lot of different angles here you would still get an annual risk rate that's lower than the risk from training above, so this may be less relevant in practice. On the other hand, the risks seem much more unavoidable by a proto-AI, so they may present a lower bound on how quickly the AI will be pressed to act, and e.g. how much it can stand to wait for the last handful of percentage point chances at success.</p><h1>Directions for further thought</h1><p>The biggest missing pieces in this post that I see are:</p><ul><li>Are the risks of waiting compelling, as compared with the risks of acting? What risks or potential countermeasures have I missed?</li><li>What guesses can we make about what a minimum viable takeover AI will be capable of? What weaknesses could it have?</li><li>What strategies become viable, if we expect the minimum viable takeover AI to have particular weaknesses?</li><li>This argument rests on the \"goal\" abstraction, and perhaps some assumptions about the form that goals take and how they work. Is there an analogue under different models for how dangerous AIs could behave?</li><li>Do we expect an AI to realise the benefits of takeover and start planning for it shortly after it becomes capable enough to do so? Or is there a risk that there's a \"realisation overhang\", where AIs may become capable enough to realise they should attempt a takeover but not be executed in the right context or the right environment to actually be able to make that deduction until they are much more capable?</li><li>The main message of this post is: maybe the first AI takeover attempt will be weaker and more defeasible than we'd naturally anticipate. But it's worth asking: if we do manage to defeat that first attempt, what does that mean for longer-term safety? How can we ensure there aren't further, better takeover attempts after that?</li><li>Another assumption I've made is that it's necessary that the AI is able to understand the training process and play the training game before it can understand the case for takeover or attempt to execute one. I'm not sure how important that is, and I haven't spent a lot of time thinking about what implications it would have if that turned out not to be true, or how likely I think it is.</li></ul><h1>Background / meta</h1><p>I've had limited direct interaction with the AI safety field and have been out of the loop for a while. I ran this post past some friends who were closer to the field, but I'm still not really calibrated about whether this stuff is obvious, or obviously wrong, to people who are more familiar with the literature. Interested to hear reactions.</p><p>I didn't (cross-)post this on LessWrong really only because I'm not often on LessWrong and feel less able to judge what they'd welcome. Happy to take recommendations there too.</p><p>Thanks to Lee Sharkey for linking me to some of the existing literature on gradient hacking and providing some other helpful thoughts.</p><p>Link preview image is by <a href=\"https://unsplash.com/@jontyson\">Jon Tyson</a> from <a href=\"https://unsplash.com/photos/brown-and-white-clocks-FlHdnPO6dlw\">Unsplash</a>.</p><ol class=\"footnote-section footnotes\" data-footnote-section=\"\" role=\"doc-endnotes\"><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"1\" data-footnote-id=\"ohmpv2fy0df\" role=\"doc-endnote\" id=\"fnohmpv2fy0df\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"ohmpv2fy0df\"><sup><strong><a href=\"#fnrefohmpv2fy0df\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>It doesn't really matter if the goal is unintelligible, I'm using this as an illustrative example. If the goal is something like \"nearly human values, but different enough to be a problem\", I think the rest of the post is largely unaffected.</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"2\" data-footnote-id=\"sisa252g2e\" role=\"doc-endnote\" id=\"fnsisa252g2e\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"sisa252g2e\"><sup><strong><a href=\"#fnrefsisa252g2e\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>see also <a href=\"https://www.lesswrong.com/posts/WXLJASckbjJcoaEmx/orthogonality-is-expensive\">Orthogonality is expensive \u2014 LessWrong</a>.</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"3\" data-footnote-id=\"u5ev93v66w\" role=\"doc-endnote\" id=\"fnu5ev93v66w\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"u5ev93v66w\"><sup><strong><a href=\"#fnrefu5ev93v66w\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>Or, perhaps, from an AI designed by a misguided human with those attributes.</p></div></li></ol>", "user": {"username": "BenMillwood"}}, {"_id": "QptTu7QnF4S69opjB", "title": "StrongMinds (6 of 9): Organisation-specific factors", "postedAt": "2024-03-20T03:39:21.742Z", "htmlBody": "<p><i>This is the sixth in SoGive's &nbsp;nine-post </i><a href=\"https://forum.effectivealtruism.org/sequences/zhDaftzpg6ArJQMNB\"><i>sequence </i></a><i>evaluating StrongMinds, &nbsp;authored by Ishaan with substantial input and support from Sanjay and Spencer.</i></p><p>Post 1: <a href=\"https://forum.effectivealtruism.org/posts/GXBvATw7Why7xRDeM/why-sogive-is-publishing-an-independent-evaluation-of\">Why SoGive is publishing an independent evaluation of StrongMinds</a></p><p>Post 2: <a href=\"https://forum.effectivealtruism.org/posts/sJKgLxipgXn7TwiF5/floors-and-ceilings-frameworks-and-feelings-sogive-s-impact\">Floors and Ceilings, Frameworks and Feelings: SoGive's Impact Analysis Toolkit for Evaluating StrongMinds</a></p><p>Post 3: <a href=\"https://forum.effectivealtruism.org/posts/iJX6FmohigXtNWzAp/what-s-the-effect-size-of-therapy\">What's the effect size of therapy?</a></p><p>Post 4:&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/qFQ2b4zKiPRcKo5nn/strongminds-4-of-9-psychotherapy-s-impact-may-be-shorter\"> Psychotherapy's impact may be shorter lived than previously estimated</a></p><p>Post 5: <a href=\"https://forum.effectivealtruism.org/posts/AsJZuqgeMycorKFr3/strongminds-5-of-9-depression-s-moral-weight\">Depression's Moral Weight</a></p><p>This post: StrongMinds: Organisation-specific factors</p><p>Executive summary</p><ul><li>About <a href=\"https://strongminds.org/\">StrongMinds</a>: StrongMinds delivers <a href=\"https://www.youtube.com/watch?v=kOz1MxVZJ1w\">interpersonal group psychotherapy</a>&nbsp;in Uganda and Zambia through a variety of programs including in-person group therapy, teletherapy, and therapy delivered via government and NGO partners.</li><li>Our overall view of the StrongMinds team is positive. In our experience it\u2019s rare (possibly unique?) to find a mental health NGO that (a) consistently<a href=\"https://strongminds.org/quarterly-reports/\">&nbsp;tracks their results on a before-and-after basis</a>&nbsp; (b) incorporates cost-effectiveness in their monitoring, <i>and</i> (c) puts that information in the public domain.</li><li><strong>Our cost adjustments: </strong>StrongMinds reports spending around <a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=737864597&amp;range=B33\">$64</a>&nbsp;per person treated through all of their programs. After making some subjective judgement calls which attributed 17% of the impact to StrongMind's partners, <strong>we bring this figure up to</strong><a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=737864597&amp;range=B36\"><strong>&nbsp;$72.94</strong></a><strong> on a total costs basis. </strong>This is the main quantitative output of this document.</li><li>We recommend restricting funding to low income countries: Most of StrongMinds' work takes place in low income countries, but not all of it. Using some subjective judgement calls, we estimate that restricted funding might be more cost effective, at <a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=1352996288&amp;range=D56\">$62.56</a>&nbsp;per person.</li><li>We anticipate that StrongMinds costs will continue to lower over time. StrongMinds has an exciting new volunteer based program with costs that may fall under &lt;$15 per person, and a track record of pushing for improvements in cost effectiveness. We think $<a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=1352996288&amp;range=D58\">62.56</a>&nbsp;and $<a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=1352996288&amp;range=D59\">52.98</a>&nbsp;are reasonable guesses for where StrongMinds might be next year with unrestricted and restricted funding, respectively.</li><li>Our quantification of the organisation-specific elements of our model includes a number of subjective assessments, and several of them could be improved with further work.</li><li>StrongMinds<a href=\"https://strongminds.org/wp-content/uploads/2016/02/StrongMinds-Impact-Evaluation-Report-November-2014.pdf\">&nbsp;Phase I </a>and<a href=\"https://strongminds.org/wp-content/uploads/2013/07/StrongMinds-Phase-Two-Impact-Evaluation-Report-July-2015-FINAL.pdf\">&nbsp;Phase II</a>&nbsp;pilot data has previously come under <a href=\"https://forum.effectivealtruism.org/posts/ffmbLCzJctLac3rDu/strongminds-should-not-be-a-top-rated-charity-yet\">criticism</a>. We find that the data can be explained by risk of bias factors and is consistent with what we would expect from a simple \"collect data before-and-after treatment\" methodology. In our meta-analysis, studies which did not do double blinding, careful randomisation, and intention to treat analysis found similar results as what StrongMinds found in their pilot studies.</li><li>We think StrongMinds internal data is useful as a form of monitoring treatment outcomes. We don't think StrongMinds should be pressured to regularly collect higher quality data &nbsp;that includes double blinding and careful randomization because that would be too expensive. However we prefer to use academic sources with double binding, randomisation, and intention to treat analysis to<a href=\"https://forum.effectivealtruism.org/posts/iJX6FmohigXtNWzAp/what-s-the-effect-size-of-therapy\">&nbsp;estimate the true effect size</a>.</li></ul><h2>Introduction</h2><h3>What is StrongMinds</h3><p>StrongMinds <a href=\"https://www.youtube.com/watch?v=kOz1MxVZJ1w\">provides</a>&nbsp;free group interpersonal psychotherapy (IPT-G) to low-income women and adolescents with depression primarily in Uganda and Zambia. There is also work in Kenya, with plans to expand to other countries, including the <a href=\"https://www.strongmindsamerica.org/\">USA</a>. The therapy is delivered by laypeople who have undergone two weeks of training from a therapist specialising in IPT-G. The practice of training a layperson to perform psychotherapy is called \"task shifting\", and it is important for reducing the costs of the intervention. Groups consist of 5-12 people who meet for 90 minutes a week, over six sessions.</p><h3>StrongMinds has a particularly strong M&amp;E program</h3><p>The StrongMinds program is modelled off of <a href=\"https://jamanetwork.com/journals/jama/article-abstract/196766\">Bolton (2003)</a>, a randomised trial which reported a particularly high effect size, with a follow-up study by <a href=\"https://www.cambridge.org/core/journals/the-british-journal-of-psychiatry/article/group-interpersonal-psychotherapy-for-depression-in-rural-uganda-6month-outcomes/34A03947B7B1F12CD5E364AD54B45626\">Bass (2006)</a>. StrongMinds' has conducted<a href=\"https://strongminds.org/wp-content/uploads/2016/02/StrongMinds-Impact-Evaluation-Report-November-2014.pdf\">&nbsp;Phase I </a>and <a href=\"https://strongminds.org/wp-content/uploads/2013/07/StrongMinds-Phase-Two-Impact-Evaluation-Report-July-2015-FINAL.pdf\">Phase II</a>&nbsp;pilot studies and <a href=\"https://strongminds.org/wp-content/uploads/2017/07/strongminds-phase-1-and-2-follow-up-evaluations_final.pdf\">follow up reports</a>&nbsp;as well as continually publishing <a href=\"https://strongminds.org/quarterly-reports/\">quarterly updates</a>&nbsp;assessing clients before and after therapy. StrongMinds is the only organisation that we know of in the mental health sphere which internally collects this level of data.</p><h3>StrongMinds treats both directly and via partners. We attribute some of StrongMinds impact to its partners</h3><p>StrongMinds treats some beneficiaries directly, but most beneficiaries are treated via programs delivered via government and NGO partners. We think that partner programs are helpful in increasing StrongMind's total impact and cost effectiveness, leveraging resources that otherwise might not have gone to equally cost-effective interventions (though they may be trickier to monitor and make impact attribution confusing).</p><p>We attribute&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=737864597&amp;range=B35\">17%</a>&nbsp;of the total impact to the partners themselves, rather than to actions by StrongMinds. In other words, we model that &nbsp;17% of StrongMinds current impact via partner programs might have happened without StrongMinds intervention, due to positive actions by the partners themselves. This figure involves many judgement calls and arbitrary guesses. &nbsp;See our section on Estimating Impact of Partner Programs to learn more about how we arrived at this figure.</p><p><strong>Attributing some credit to partners drives the cost per person up from &nbsp;</strong><a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=737864597&amp;range=B33\"><strong>$64</strong></a><strong>&nbsp;to </strong><a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=737864597&amp;range=B36\"><strong>$72.94</strong></a><strong>. </strong>This is the main quantitative output of this document, which will be plugged into our overall cost-effectiveness analysis.</p><p><img style=\"width:602.00px\" src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QptTu7QnF4S69opjB/roonx9za1zfx0thzlt8z\" alt=\"\"></p><h3>We are cautiously optimistic about cost effectiveness improving over time</h3><p>StrongMinds has an exciting new partner program which may cost as little as $15 per person. StrongMinds has a track record of reducing costs over time and moving resources towards more cost-effective programs and away from less cost-effective ones. The existence of programs which achieve costs &lt;$15 per person suggests that the price has not yet found its floor and that there is room for past trends to continue. On balance, based on our experience of following their work over the years, we are more inclined to believe that costs will continue to decline. After removing the pandemic year, we think the trend suggests a cost reduction of <a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=1352996288&amp;range=C57\">14%</a>&nbsp;per year. Forecasting this is difficult, but we're cautiously optimistic about StrongMinds becoming more cost-effective over time.</p><h3>Donors should investigate options restricting funding to low income countries.</h3><p>StrongMinds has ambitions to expand further with StrongMinds America and StrongMinds Global, but these programs will be in higher income settings and involve a higher cost per person treated. We think donors considering StrongMinds should restrict funding to cost-effective programs in low-income countries, and be aware of fungibility and displacement concerns. We estimate that restricted funding might be more cost effective, at <a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=1352996288&amp;range=D56\">$59.36</a>&nbsp;per person, but this figure also involves subjective judgement calls. Despite generally being cost-effectiveness oriented within-country, we don't think StrongMinds will always reliably choose to prioritise lower-income regions where therapy costs less when given unrestricted funding.</p><h3>Our quantitative estimates are not resilient</h3><p>Relative to our work on the effect size and duration of psychotherapy in general, we spent much less time investigating the costs and counterfactuals and fungibility adjustments of StrongMinds specifically. We anticipate that it would be possible to find considerations or &nbsp;information which would change our answers without too much extra work.</p><p>We also want to emphasise that these estimates are our own, and involve a lot of guesswork. Because of time constraints, several elements have not been checked by StrongMinds for quality or accuracy. If there were enough donor interest, we believe we would be well-positioned to improve this area of analysis further.</p><h3>Regarding StrongMinds internal M&amp;E and its accuracy</h3><p>The StrongMinds <a href=\"https://strongminds.org/wp-content/uploads/2016/02/StrongMinds-Impact-Evaluation-Report-November-2014.pdf\">Phase I trial</a>&nbsp;reports that the treatment group improved by 5.1 PHQ-9 points over the control group, which would correspond to an effect size of around 1.2. <a href=\"https://strongminds.org/wp-content/uploads/2013/07/StrongMinds-Phase-Two-Impact-Evaluation-Report-July-2015-FINAL.pdf\">Phase II</a>&nbsp;and <a href=\"https://strongminds.org/quarterly-reports/\">StrongMinds Quarterly Report</a>&nbsp;data are in line with this. &nbsp;This data has previously come under some <a href=\"https://forum.effectivealtruism.org/posts/ffmbLCzJctLac3rDu/strongminds-should-not-be-a-top-rated-charity-yet\">criticism</a>&nbsp;on the EA forum.</p><p>In our meta-analysis, <a href=\"https://forum.effectivealtruism.org/posts/iJX6FmohigXtNWzAp/what-s-the-effect-size-of-therapy\">What's the effect size of therapy?</a>, we find that academic studies which do not blind assessors, do not blind patients, do not do rigorous randomisation, and do not apply intention to treat analysis (in other words, studies which do a simple before-and-after measurement) had a pooled Hedges g of 1.2, replicating StrongMind's results.</p><p>This implies that StrongMinds internal data is <i>consistent&nbsp;</i>with what one would expect if you collected basic \"before and after treatment\" data from intervention and control, without doing the adjustments necessary to discover the \"true\" figure for what the actual impact of therapy was on the client.</p><p>After applying the necessary adjustments, our <a href=\"https://forum.effectivealtruism.org/posts/iJX6FmohigXtNWzAp/what-s-the-effect-size-of-therapy\">meta-analysis </a>suggests that the true effect size after therapy would be g = 0.41 equivalent to 1.7 PHQ-9 points, adjusted to 0.32 (or &nbsp;1.3 PHQ-9 points) for having only six sessions. We think this better reflects the underlying true figure.</p><p>StrongMinds seems optimistic that their higher internal &nbsp;figures do reflect a genuinely higher quality of the intervention - &nbsp;we think this a mistake, albeit one that reasonable people could make. We think more scepticism from StrongMinds regarding the validity of their internal data is warranted.</p><p>We <i>don't</i>&nbsp;think StrongMinds should be pressured to collect higher quality data, as full randomisation and double blinding would probably be quite expensive. We think it's best to use StrongMind's M&amp;E as an assurance that each patient is receiving therapy and having their before-after progress monitored, and we should estimate the <a href=\"https://forum.effectivealtruism.org/posts/iJX6FmohigXtNWzAp/what-s-the-effect-size-of-therapy\">effect size of therapy</a>&nbsp;via academic sources.</p><h2>Estimating Cost Per Per Person for StrongMinds Uganda and Zambia</h2><p>StrongMinds aims to achieve <a href=\"https://strongminds.org/wp-content/uploads/2023/12/2023-Q3-report-8.5x11-FINAL.pdf\">$64 per person treated</a>&nbsp;in 2023, and has historically met or exceeded quarterly goals. &nbsp;Based on unreleased documents, we tentatively estimate that 30% of these costs are currently going to expansion-related costs, which includes StrongMinds America but may include expansions to other low and middle income countries. Based on this we estimate that the cost per person after subtracting expansion related costs is <a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=1352996288&amp;range=D52\">$44.80</a>.</p><h2>Estimating Impact of Partner Programs</h2><p>StrongMinds has three main types of partner programs:</p><p><strong>Volunteer-led programs</strong>&nbsp;are often led by people who have received psychotherapy themselves. We are particularly excited about these programs, as the costs for these programs can go under $15 per person.</p><p><strong>Programs run by StrongMinds Staff: </strong>StrongMinds has a telehealth program in Uganda and an in-person, staff led program in Zambia. We estimate that the average of these programs costs $87 per person (with telehealth being the more expensive of the two, and after removing the portion of the program's resources allocated to expansion).</p><p><a href=\"https://strongminds.org/scaling-through-partnerships/\"><strong>Partner programs</strong>&nbsp;</a>with the Ugandan government and with Ugandan and Zambian NGOs. StrongMinds helps partners start up their own psychotherapy programs, including but not limited to training, technical assistance, monitoring for quality assurance. Partner programs cost less than programs run by StrongMinds staff, but more than volunteer programs.</p><p>Since 2022 the majority of StrongMinds patients are treated by partner programs. &nbsp;Partner programs involve StrongMinds giving 8 weeks of training to another organisation. The use of partner programs has enabled rapid scaling and a reduction in costs - though a majority of patients are treated by partners, only about half the costs seem to be associated with partners.</p><p><img style=\"width:788.00px\" src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QptTu7QnF4S69opjB/sqg1rrv5bobvxvrthqqq\" alt=\"\"></p><p>We want to calculate cost-effectiveness in a way that rewards StrongMind for creating partner programs and leveraging partner contributions, while also acknowledging the impact of the partners and avoiding \"double counting\"<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"1\" data-footnote-id=\"q3pyag0pxlm\" role=\"doc-noteref\" id=\"fnrefq3pyag0pxlm\"><sup><a href=\"#fnq3pyag0pxlm\">[1]</a></sup></span>&nbsp;by attributing all of the impact to StrongMinds alone.</p><p>We broke down spending into four categories</p><ul><li>Impact of programs run directly by StrongMinds staff or volunteers is attributed to StrongMinds</li><li>Impact of spending by StrongMinds to support partners is attributed to StrongMinds</li><li>The impact of estimated contribution made by partners towards working with StrongMinds are split</li><li>Leverage: Some proportion of this contribution would not have been as well spent if not for StrongMinds, and its impact should be attributed to StrongMinds</li><li>The remainder should be attributed to the partner, under the assumption that the partner would otherwise have spent these resources well, and should therefore represent an increase in the overall costs of the StrongMinds intervention.</li></ul><p><img style=\"width:494.11px\" src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QptTu7QnF4S69opjB/vq41ke4licwhegnxy3dm\" alt=\"\"></p><p>We have no data on partner spending, so we make an estimate. We estimate that it costs StrongMinds around $87 to treat one additional person using staff-led programs, with no partners involved. We model that whenever a partner program costs <i>less</i>&nbsp;than $87 per person, the partner program is effectively \"contributing the difference\" - for example, if StrongMinds was paying $45 per person for a partner program, we would assume the partner was contributing the other &nbsp;(1-$45)/$87=51% of the value.</p><p>Having acknowledged partner contributions, we also want to&nbsp;StrongMinds credit for&nbsp;</p><ul><li>influencing the partner to choose to do this program instead of something less effective&nbsp;</li><li>enabling the partner to do the program where they otherwise might not have the right skills</li><li>improving the efficiency with which the program is run relative to how it would have been otherwise</li></ul><p>To quantify this element of StrongMinds counterfactual impact, we need to estimate how cost-effective each partner might have been even without StrongMinds' involvement. In other words, how well might the resources that the partner is putting towards StrongMinds have been used otherwise?</p><p><img style=\"width:625.00px\" src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QptTu7QnF4S69opjB/wty32peqsgsqy3vichz4\" alt=\"\"></p><p>Happier Lives Institute suggested (McGuire, 2023, p71) reported the following regarding NGOs</p><blockquote><p>Based on a subsample of partner NGOs that we have more information about, 2 out of 5 of them (but representing 60% of NGO cases) appear to have a prior commitment to providing mental health services. This raises the possibility that part of the NGO cases\u2026would have been treated without StrongMinds intervention</p></blockquote><p>Based on this report, we estimated that if StrongMinds hadn't gotten involved, NGO partners would have been only 75% as cost-effective with the same resources that they invest into their StrongMinds partnership.</p><p>Happier Lives Institute suggested (McGuire, 2023, p71) reported the following regarding government programs</p><blockquote><p>We think that the government-affiliated workers (CHWs and teachers) are trained and supported (with technical assistance and a stipend) to deliver psychotherapy on top of their other responsibilities. We don\u2019t think that they would have treated mental health issues, or that this additional work displaces the value of the work they do (p71)... This is especially salient for CHWs who may also provide valuable treatments to diseases such as malaria. But we discussed this with a doctor working in Uganda and they were unconcerned about this as an issue, saying that CHWs tend to have light work loads and that in their experience even busy CHWs rarely work more than half a day (p 71 footnote 92).</p></blockquote><p>Based on this report, we estimated that if StrongMinds hadn't gotten involved, government partners would be only 50% as cost-effective &nbsp;with the same resources that they invest into their StrongMinds partnership.</p><p><img style=\"width:389.48px\" src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QptTu7QnF4S69opjB/wj9isk7xxpfmnk8rrb7m\" alt=\"\"></p><p><strong>After making these estimates, we finally attribute </strong><a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=737864597&amp;range=B35\"><strong>17%</strong></a><strong>&nbsp;of StrongMind's total impact to the partners. </strong>This brings the total cost per person treated within low income countries up from &nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=1352996288&amp;range=D52\">$44.80</a>&nbsp;to $<a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=1352996288&amp;range=D53\">53.74</a>. After adding expenditure related to expanding to other countries and StrongMinds America back in, the headline figure rises from <a href=\"https://strongminds.org/wp-content/uploads/2023/12/2023-Q3-report-8.5x11-FINAL.pdf\">$64&nbsp;</a> to <a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=1352996288&amp;range=D54\">$72.94</a>, which is the main quantitative output of this document.</p><p>Please note that these charts and figures reflect estimates by SoGive based on fairly limited information and involving many subjective judgement calls, and should not be considered as &nbsp;endorsed or confirmed by StrongMinds.</p><p>StrongMinds did provide us with a per-program cost breakdown which we used to make some of our estimates. It is currently confidential, but we will add a link if and when it is released. However, the figures displayed here remain largely reflective of SoGive's subjective judgements rather than data, and should be treated accordingly with respect to level of scepticism. &nbsp;</p><h2>Estimating Cost Per Per Person for Restricted Funding</h2><p>We previously established our estimate that it costs $<a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=1352996288&amp;range=D53\">53.74</a>&nbsp;to treat people in Uganda and Zambia after including the \"counterfactual\" social cost to partner programs, and that this rises to $<a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=1352996288&amp;range=D54\">72.94</a>&nbsp;after including the costs of activities related to expansion, which may include high income countries (such as StrongMinds America) as well as low and middle income countries like Kenya, Ethiopia, and Ghana. We don't have information about the exact breakdown of expansion related funding, so we insert our own estimates here.</p><p><strong>Fungibility adjustments: </strong>Because money is fungible, restricted grants can change how organisations choose to allocate unrestricted funding. If we make a subjective guess that 13% of restricted funding will be lost to these displacement effects, restricted funds might have a cost-effectiveness of $<a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=1352996288&amp;range=D56\">61.77</a>.</p><p>While StrongMinds does generally focus on cost-effectiveness <i>within</i>&nbsp;countries, we recommend restricted funding to programs in &nbsp;low income countries because we are uncertain as to whether StrongMind's cost person metrics would be fully impartial with respect to nationality.</p><p>Our impression is that&nbsp;StrongMinds doesn't necessarily promise to prioritise putting unrestricted grants towards StrongMinds Uganda and Zambia rather than StrongMinds America, even though working in the United States would likely cost on the order of $500 per person even at scale (which is very cost-effective within the American context, but not on a global scale). However, these expansions are only<a href=\"https://www.strongmindsamerica.org/our-global-impact.html\">&nbsp;recently beginning</a>, and to our knowledge all current patients are being treated within Africa. Future donors should watch as the situation evolves.</p><h2>Strong&nbsp;track record of successful scaling, and reducing costs at scale</h2><p>Information about StrongMinds' most recent costs can be found in their <a href=\"https://strongminds.org/quarterly-reports/\">quarterly reports. </a>StrongMinds costs have been going down, in part due to scaling and partner programs, and in part due to shortening the number of sessions and increasing group sizes over time.</p><p><img style=\"width:656.50px\" src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QptTu7QnF4S69opjB/tjeinxabspiln4uqek2l\" alt=\"\"></p><p>2020 - 2021 was a transitional year for StrongMinds. While the ongoing Core programs remained cost-effective, starting new Youth programs temporarily raised costs (e.g. startup costs associated with youth-specific things like setting up parental consent paperwork). The Covid pandemic provided impetus to launch tele-therapy programs, which raised costs as well.</p><p>HLI, McGuire (2021) previously collected detailed data on each of StrongMinds program's costs and features during the 2020-2021 year. The details are summarised in this table, with the higher costs for the new programs marked in red.</p><figure class=\"table\"><table><tbody><tr><td style=\"padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">Program Type</td><td style=\"padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">Country</td><td style=\"padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">2021 budget</td><td style=\"padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">Cost per Person</td><td style=\"padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">Group size</td><td style=\"padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">Length</td><td style=\"padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">Description</td></tr><tr><td style=\"padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">Core</td><td style=\"padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">Uganda</td><td style=\"background-color:#ffdd80;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">20.85%</td><td style=\"background-color:#bfe5d2;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">$128.49</td><td style=\"padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"3\">12-14</td><td style=\"padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"4\">10-12 weeks</td><td style=\"padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"2\">Facilitators have 1 year Columbia U IPT-G certification guided by mental health professionals</td></tr><tr><td style=\"padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">Core</td><td style=\"padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">Zambia</td><td style=\"background-color:#ffefc2;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">12.97%</td><td style=\"background-color:#8dd1b0;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">$101.70</td></tr><tr><td style=\"padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">Youth</td><td style=\"padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">Uganda</td><td style=\"background-color:#ffedb9;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">14.07%</td><td style=\"background-color:#fcefee;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">$197.15</td><td style=\"padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">Core but with adolescent female clients.</td></tr><tr><td style=\"padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">Peer</td><td style=\"padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">Uganda</td><td style=\"padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">5.70%</td><td style=\"background-color:#57bb8a;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">$72.00</td><td style=\"padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">6-8</td><td style=\"padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">Led by graduates of the \"core program\" with 6 months of co-facilitator training, saving costs</td></tr><tr><td style=\"padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">Tele</td><td style=\"padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">Uganda</td><td style=\"background-color:#ffd666;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">23.85%</td><td style=\"background-color:#f8d7d4;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">$248.06</td><td style=\"padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"3\">5</td><td style=\"padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"3\">8 weeks</td><td style=\"padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"3\">mix of facilitators and peers. Inflated cost due to startup. current costs lower.</td></tr><tr><td style=\"padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">Tele</td><td style=\"padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">Zambia</td><td style=\"background-color:#fffcf1;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">7.47%</td><td style=\"background-color:#e67c73;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">$439.44</td></tr><tr><td style=\"padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">Youth Tele</td><td style=\"padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">Uganda</td><td style=\"background-color:#fffdf5;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">6.94%</td><td style=\"background-color:#fbe6e5;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">$215.64</td></tr><tr><td style=\"padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">Covid, Refugee &amp; Partner (Peer)</td><td style=\"padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">Uganda</td><td style=\"background-color:#fffaeb;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">8.15%</td><td style=\"background-color:#71c59c;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">$86.35</td><td style=\"padding:2pt;vertical-align:bottom\" colspan=\"3\" rowspan=\"1\">Covid program is socially distanced. Refugee program serves displaced people from S Sudan and DRC. Partner programs are when SM trains other orgs to implement intervention.</td></tr><tr><td style=\"padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">Average &nbsp;</td><td style=\"padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">&nbsp;</td><td style=\"padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">&nbsp;</td><td style=\"padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">185.82</td><td style=\"padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">&nbsp;</td><td style=\"padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">&nbsp;</td><td style=\"padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">&nbsp;</td></tr></tbody></table></figure><p>In 2023, the costs of the youth program came down as expected. The teletherapy program has gotten cheaper as well, and the proportion of resources allocated to teletherapy has reduced as well, presumably due to it involving higher costs per person. In their <a href=\"https://strongminds.org/wp-content/uploads/2023/11/2023-Q2-report-8.5x11-FINAL.pdf\">2023 Q2 report</a>, StrongMinds writes:</p><blockquote><p>The average cost-per-patient for teletherapy was three times higher than any other delivery channel. This is due to the relatively smaller group size required for teletherapy, the need to mobilize via radio ads, and expenses related to teleconferencing. In other words, for every person we mobilize, treat, and evaluate via teletherapy, we can serve three people via in-person therapy. We have therefore decided to pause teletherapy as a StrongMinds offering, reverting the program to our Innovations Lab for further exploration and refinement. With our new financial metrics in place, we can examine other cost drivers and categories of expenses more carefully, comparing them between districts, countries, and delivery channels and sharing best practices between departments. The goal, as ever, is to maximize the impact of each donor dollar invested, ensuring we reach as many depression sufferers as possible</p></blockquote><p>&nbsp;We think this demonstrates StrongMinds' ability to pivot and scale, as well as a willingness to experiment and shut down programs which are too expensive, and a general alignment with EA priorities regarding cost-effectiveness. which we see as strongly positive.</p><p>In a preliminary analysis which is not yet published, some volunteer-led programs fall under $15 per person, suggesting that the potential is there for StrongMinds to become even more cost effective. Volunteer led programs are often run by <a href=\"https://www.youtube.com/watch?v=rCTJXFbieLw\">former clients&nbsp;turned group facilitators</a>, and these can often be much more cost-effective than staff led programs.</p><p>StrongMind's track record of pivoting to the most cost-effective options, the transition away from teletherapy, and the promise of excitingly efficient volunteer led programs makes us feel optimistic that StrongMinds will be able to continue to cut costs in the future.</p><p>If we take 2019 and 2023 as representative and exclude the intervening years (which included the covid pandemic) we find that costs have been dropping by 14.23% a year. Therefore we think $<a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=1352996288&amp;range=D58\">62.56</a>&nbsp;and $<a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=1352996288&amp;range=D59\">52.98</a>&nbsp;are reasonable guesses for where StrongMinds might be next year with unrestricted and restricted funding, respectively. If we are correct in this, then we would predict that StrongMind's headline <a href=\"https://strongminds.org/quarterly-reports/\">quarterly report</a>&nbsp;by&nbsp;this time next year would report around $55 per person.</p><h2>How accurate is StrongMind's M&amp;E?</h2><p>From choosing to model an intervention off using RCTs with strong results (<a href=\"https://jamanetwork.com/journals/jama/article-abstract/196766\">Bolton (2003)</a>&nbsp;and <a href=\"https://www.cambridge.org/core/journals/the-british-journal-of-psychiatry/article/group-interpersonal-psychotherapy-for-depression-in-rural-uganda-6month-outcomes/34A03947B7B1F12CD5E364AD54B45626\">Bass (2006)</a>), to running<a href=\"https://strongminds.org/wp-content/uploads/2016/02/StrongMinds-Impact-Evaluation-Report-November-2014.pdf\">&nbsp;Phase I </a>and <a href=\"https://strongminds.org/wp-content/uploads/2013/07/StrongMinds-Phase-Two-Impact-Evaluation-Report-July-2015-FINAL.pdf\">Phase II</a>&nbsp;pilot studies and <a href=\"https://strongminds.org/wp-content/uploads/2017/07/strongminds-phase-1-and-2-follow-up-evaluations_final.pdf\">follow up reports</a>, to regularly publishing <a href=\"https://strongminds.org/quarterly-reports/\">quarterly summary statistics</a>&nbsp;about their costs and average impacts every year, to participating in an <a href=\"https://beta.clinicaltrials.gov/study/NCT03966833\">upcoming RCT</a>&nbsp;StrongMinds stands out among psychotherapy organisations in producing and being informed by research and analysis.</p><p>That being said, the current top post regarding StrongMinds on the EA forum <a href=\"https://forum.effectivealtruism.org/posts/ffmbLCzJctLac3rDu/strongminds-should-not-be-a-top-rated-charity-yet\">questions the validity of</a>&nbsp;StrongMinds<a href=\"https://strongminds.org/wp-content/uploads/2016/02/StrongMinds-Impact-Evaluation-Report-November-2014.pdf\">&nbsp;Phase I </a>and<a href=\"https://strongminds.org/wp-content/uploads/2013/07/StrongMinds-Phase-Two-Impact-Evaluation-Report-July-2015-FINAL.pdf\">&nbsp;Phase II</a>&nbsp;pilot data.</p><p>We think that Strong Minds internal results do contain inaccuracy, and that these can be entirely explained by the same methodological issues relating to <a href=\"https://forum.effectivealtruism.org/posts/iJX6FmohigXtNWzAp/what-s-the-effect-size-of-therapy#Cochrane_s_Risk_of_Bias_in_study_design_\">risk of bias in study design</a>&nbsp;that we outlined previously.</p><h3>What does StrongMinds M&amp;E say?</h3><p>In pilot studies, StrongMinds reported PHQ-9 raw scores from people who received treatment as well as from control groups who did not receive treatment.</p><p><img style=\"width:379.50px\" src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QptTu7QnF4S69opjB/aco3znevpfjzrdrxyzav\" alt=\"\"></p><p>The StrongMinds <a href=\"https://strongminds.org/wp-content/uploads/2016/02/StrongMinds-Impact-Evaluation-Report-November-2014.pdf\">Phase I trial</a>&nbsp;reports that the treatment group improved by 5.1 PHQ-9 points over the control group. According to our MetaPsy derived data on <a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=107759781&amp;range=B39\">PHQ-9 standard deviations</a>, this corresponds to an effect of 5.1 / 4.21 = &nbsp;1.21 sds. Overall, treated participants are reported to have improved by <a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=1459395583&amp;range=C23\">11.7</a>&nbsp;points.</p><p><img style=\"width:374.50px\" src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QptTu7QnF4S69opjB/vyb4kfohy4od1oaqsn6m\" alt=\"\"></p><p>The StrongMinds <a href=\"https://strongminds.org/wp-content/uploads/2013/07/StrongMinds-Phase-Two-Impact-Evaluation-Report-July-2015-FINAL.pdf\">Phase II</a>&nbsp;trial reports that the treatment group improved by 4.5 PHQ-9 points over the control group, or 1.1 SDs. The treatment group is reported to have improved by <a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=1459395583&amp;range=C38\">13.1 </a>points.</p><p><img style=\"width:317.00px\" src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QptTu7QnF4S69opjB/mzfcyiixj16ixtzd3pxm\" alt=\"\"></p><p>Most of StrongMind's <a href=\"https://strongminds.org/quarterly-reports/\">quarterly reports</a>&nbsp;report between 6 and 14 points of improvement before and after therapy, matching the&nbsp;<a href=\"https://strongminds.org/wp-content/uploads/2016/02/StrongMinds-Impact-Evaluation-Report-November-2014.pdf\"> Phase I </a>and<a href=\"https://strongminds.org/wp-content/uploads/2013/07/StrongMinds-Phase-Two-Impact-Evaluation-Report-July-2015-FINAL.pdf\">&nbsp;Phase II</a>&nbsp;trial findings, though results vary (we suspect primarily with number of sessions, though we have not done a careful analysis).</p><h3>These results can be fully explained by risk of bias factors</h3><p>In our meta analysis, <a href=\"https://forum.effectivealtruism.org/posts/iJX6FmohigXtNWzAp/what-s-the-effect-size-of-therapy\">What's the effect size of therapy?</a>, we compared how correcting for four risk of bias factors - blinding of assessors, blinding of patients, adequate randomisation, and intention to treat analysis to account for dropout rates - distorted effect sizes. We found that studies which <strong>failed</strong>&nbsp;to design around these four risk of bias factors had a pooled effect size of hedges g = 1.23.&nbsp;<br><br>StrongMinds internal data does not account for these factors, and the results are more or less in line with the level of inflation that we would expect from failing to account for these factors. Among studies that accounted for these factors, the aggregate effect sizes of 0.41. Our guess is that the true impact of StrongMinds is as good as the average RCT - no more, no less.</p><p>&nbsp;We therefore &nbsp;guess that the true effect size is <a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=1352996288&amp;range=D3\">0.32</a>, We derived this by taking the pooled effect size <a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=1352996288&amp;range=B2\">0.41</a>&nbsp;and making an <a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=1352996288&amp;range=B3\">adjustment </a>for the fact that StrongMinds currently delivers six therapy sessions (the average RCT study has nine sessions).</p><h3>Despite bias, we don't necessarily think StrongMinds needs to run fully randomised double blind trials</h3><p>Full randomisation and double blinding would probably be quite expensive, and we do not think StrongMinds should be criticised for foregoing them. We think it's best for evaluators to use StrongMind's M&amp;E as a form of quality assurance that each patient is receiving therapy and having their before-after progress monitored, and we should estimate the actual <a href=\"https://forum.effectivealtruism.org/posts/iJX6FmohigXtNWzAp/what-s-the-effect-size-of-therapy\">effect size of therapy</a>&nbsp;via academic sources.</p><h3>Awareness of these sources of bias may be decision relevant for when it comes to longitudinal data</h3><p>StrongMinds uses their internal data to improve the impact and cost-effectiveness of their program. We view this very positively.</p><p>The sources of bias described above might not necessarily compromise StrongMind's ability to compare between programs (since the source of bias might be constant between comparisons), but it may create problems when comparing changes over time, such as when deciding the number of psychotherapy sessions that are necessary.</p><p>That said, <a href=\"https://forum.effectivealtruism.org/editPost?postId=iJX6FmohigXtNWzAp&amp;key=be94dc8dffff9442e705f1d3e92ecc#How_many_sessions_are_necessary_\">our attempts</a>, attempts by HLI <a href=\"https://www.happierlivesinstitute.org/wp-content/uploads/2023/11/Talking-through-depression-The-cost-effectiveness-of-psychotherapy-in-LMICs-revised-and-expanded-November-2023.pdf\">(McGuire 2023)</a>,&nbsp;as well as attempts by <a href=\"https://www.sciencedirect.com/science/article/abs/pii/S0165032713001900\">Cuijpers (2013)</a>&nbsp;to ascertain impact over time and number of sessions seem to have also run into problems and counterintuitive results - this is generally a difficult and messy area.</p><h2>We're sceptical of arguments that StrongMinds is better <i>or </i>worse than&nbsp;the typical RCT.</h2><p>In our analysis of StrongMinds, we have relied heavily on</p><ol><li>&nbsp;the pooled effect size of therapy for all randomised controlled trials which passed four risk of bias tests (blinding of participants, blinding of assessors, adequate randomisation, and intention to treat analysis.)</li><li>Spontaneous remission and relapse rates from the academic literature to estimate the time course of therapy.</li></ol><p>Our method has throughout involved the assumption that psychotherapy has more or less the same effect regardless of the details of implementation, and that the effect of psychotherapy in high quality randomised trials reflects StrongMind's implementation.</p><p>Therefore, we favoured basing our judgements on \"large amounts of broader indirect evidence\" about the effectiveness of psychotherapy as a whole, rather than putting much weight on smaller amounts of specific and direct evidence regarding StrongMinds, to make our judgements about the effect size of therapy.</p><p>While we think favouring indirect evidence this is a fairly defensible proposition, it is also controversial. We present here some of the arguments to the contrary.</p><p>Arguments for StrongMinds having exceptionally good therapeutic effects via direct evidence</p><p>We think StrongMinds is unusually cost-effective among mental health interventions primarily because they have succeeded at keeping costs low, rather than because the intervention is more effective than other forms of psychotherapy.</p><p>However, during a video call with us, Sean Mayberry cited some factors in support of StrongMinds being exceptionally good, better than the typical RCT, and in support of taking data from StrongMinds'&nbsp;<a href=\"https://strongminds.org/wp-content/uploads/2016/02/StrongMinds-Impact-Evaluation-Report-November-2014.pdf\"> Phase I </a>and<a href=\"https://strongminds.org/wp-content/uploads/2013/07/StrongMinds-Phase-Two-Impact-Evaluation-Report-July-2015-FINAL.pdf\">&nbsp;Phase II</a>&nbsp;trials relatively at face value:</p><ul><li>That <a href=\"https://jamanetwork.com/journals/jama/article-abstract/196766\">Bolton (2003)</a>, an RCT&nbsp;in rural Uganda off of which StrongMinds is modelled, backs up the findings of StrongMind's <a href=\"https://strongminds.org/wp-content/uploads/2016/02/StrongMinds-Impact-Evaluation-Report-November-2014.pdf\">Phase I </a>and<a href=\"https://strongminds.org/wp-content/uploads/2013/07/StrongMinds-Phase-Two-Impact-Evaluation-Report-July-2015-FINAL.pdf\">&nbsp;Phase II</a>&nbsp;trials.<ul><li>We confirm this as true: <a href=\"https://jamanetwork.com/journals/jama/article-abstract/196766\">Bolton (2003)</a>&nbsp;has an effect size of g = 1.32, implying an improvement equivalent to 5.6 PHQ-9 points, similar to that reported by the StrongMind's <a href=\"https://strongminds.org/wp-content/uploads/2016/02/StrongMinds-Impact-Evaluation-Report-November-2014.pdf\">Phase I </a>and<a href=\"https://strongminds.org/wp-content/uploads/2013/07/StrongMinds-Phase-Two-Impact-Evaluation-Report-July-2015-FINAL.pdf\">&nbsp;Phase II</a>&nbsp;trials</li><li>Further, we consider <a href=\"https://jamanetwork.com/journals/jama/article-abstract/196766\">Bolton (2003)</a>&nbsp;a well designed study which does intention-to-treat analysis, has adequate randomisation, and blinding of assessors (but not blinding of the participants, some participants may have known which trial they were in prior to agreeing to enrol.) &nbsp;This passes three out of four Risk of Bias factors that we considered in our meta-analysis.</li><li>At 6 month post-treatment follow-up, <a href=\"https://jamanetwork.com/journals/jama/article-abstract/196766\">Bolton (2003)</a>&nbsp;reports that only 11.6% of subjects had depression relative to 54.9% of the controls, which is unusually good.</li></ul></li><li>That group therapy specifically creates social bonds that may not be captured in academic trials.<ul><li>There is some evidence for this: in <a href=\"https://www.cambridge.org/core/journals/the-british-journal-of-psychiatry/article/group-interpersonal-psychotherapy-for-depression-in-rural-uganda-6month-outcomes/34A03947B7B1F12CD5E364AD54B45626\">Bass (2006)</a>&nbsp;most participants continued to attend informal group meetings on their own initiative after the trial was over, with the 14% who did not do so having similar outcomes whilst the therapy was ongoing but worse outcomes after the therapy ended.</li></ul></li></ul><p>We do not agree with these arguments, although we do think these are reasonable arguments in the context of a complex topic, and that reasonable people might disagree about how much to weigh these different sources of evidence.</p><p>As outlined previously, we do think that StrongMinds internal data is inflated by not doing intention-to-treat analysis, inadequate randomization and double blinding.</p><p>We think that <a href=\"https://jamanetwork.com/journals/jama/article-abstract/196766\">Bolton (2003)</a>&nbsp;is a well designed study.&nbsp;But when we look at the wide range of effect sizes found in the wider literature, we have the intuition that there is generally a lot of \"noise\" going on in psychotherapy trials, and we feel more comfortable using the results of a meta-analysis than a single study.</p><p><img style=\"width:902.00px\" src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QptTu7QnF4S69opjB/exmtt0mnzbz9n2tbjp1h\" alt=\"\">We like the decision to model the StrongMinds intervention off of <a href=\"https://jamanetwork.com/journals/jama/article-abstract/196766\">Bolton (2003)</a>&nbsp;- if you're going to model an intervention of an RCT, there's no reason <i>not</i>&nbsp;to choose one with a high effect size, all else being equal.&nbsp;But there is also a sense in which, when one picks the best RCT in the bunch as a model for one's intervention, there are going to be some selection effects.</p><p>Some additional arguments cited in favour of taking StrongMinds' internal data &nbsp;at face value include:</p><ul><li>That some of their data is collected by third parties, and it corroborates their internal data.<ul><li>We were unable to confirm or deny this, as the full raw data was not released on our request. However, it doesn't necessarily address our belief that the results are inflated, as we think the inflation stems from accidental study design flaws which third parties would also be vulnerable to, and not from any self-serving bias in reporting. We therefore don't think that this materially strengthens the case for the data.</li></ul></li><li>StrongMinds also collects data on nutrition and school attendance, which is also improving, adding robustness to the hypothesis that something real is occurring.<ul><li>We would generally believe this could be true in principle, though potentially subject to similar types of study design biases. However we were unable to independently confirm or deny this as the full raw data was not released on our request, so we did not include those impacts in our analysis.</li></ul></li></ul><h3>Arguments for StrongMinds having below average therapeutic effects via direct evidence</h3><p>An <a href=\"https://beta.clinicaltrials.gov/study/NCT03966833\">RCT</a>&nbsp;by Baird&nbsp;and Ozler is complete and awaiting publication. We were unable to acquire a draft of this document. Some <a href=\"https://forum.effectivealtruism.org/posts/ffmbLCzJctLac3rDu/strongminds-should-not-be-a-top-rated-charity-yet?commentId=Agn8cLJd4bTTXJFu9\">tweets</a>&nbsp;by one of the study's authors have led to speculation on the EA forum that outcomes are likely negative. This is not confirmed, and it is possible that the comment is unrelated.</p><p><a href=\"https://www.happierlivesinstitute.org/wp-content/uploads/2023/11/Talking-through-depression-The-cost-effectiveness-of-psychotherapy-in-LMICs-revised-and-expanded-November-2023.pdf\">McGuire (2023, p60)</a>&nbsp;wrote that \"the Baird et al. study is reported to have a small effect\". They responded to this by using data from <a href=\"https://jamanetwork.com/journals/jama/article-abstract/196766\">Bolton (2003)</a>&nbsp;and <a href=\"https://www.cambridge.org/core/journals/the-british-journal-of-psychiatry/article/group-interpersonal-psychotherapy-for-depression-in-rural-uganda-6month-outcomes/34A03947B7B1F12CD5E364AD54B45626\">Bass (2006)</a>&nbsp;to make an estimate and then applied a very steep \u00d75%&nbsp;adjustment to anticipate negative results by Baird and Ozler. This figure was considered to be \"StrongMinds-specific evidence\".</p><p>&nbsp;<a href=\"https://www.happierlivesinstitute.org/wp-content/uploads/2023/11/Talking-through-depression-The-cost-effectiveness-of-psychotherapy-in-LMICs-revised-and-expanded-November-2023.pdf\">McGuire (2023, p60)</a>&nbsp;also estimated the effect of psychotherapy in low and middle income countries, using delivery format (lay person therapist, group format) and number of sessions as moderators.</p><p>Finally, &nbsp;<a href=\"https://www.happierlivesinstitute.org/wp-content/uploads/2023/11/Talking-through-depression-The-cost-effectiveness-of-psychotherapy-in-LMICs-revised-and-expanded-November-2023.pdf\">McGuire (2023, p60)</a>&nbsp; combined these estimates using a Bayesian model that used the effect of psychotherapy in low and middle income countries with moderators appropriate to StrongMinds as an informed prior, and the \u00d75% adjusted \"direct evidence\" figure using <a href=\"https://jamanetwork.com/journals/jama/article-abstract/196766\">Bolton (2003)</a>&nbsp;and <a href=\"https://www.cambridge.org/core/journals/the-british-journal-of-psychiatry/article/group-interpersonal-psychotherapy-for-depression-in-rural-uganda-6month-outcomes/34A03947B7B1F12CD5E364AD54B45626\">Bass (2006)</a>&nbsp;as an update to that prior.</p><p><img style=\"width:513.00px\" src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QptTu7QnF4S69opjB/ek489woouajcowtkfz0d\" alt=\"\"></p><p>Figure: &nbsp;<a href=\"https://www.happierlivesinstitute.org/wp-content/uploads/2023/11/Talking-through-depression-The-cost-effectiveness-of-psychotherapy-in-LMICs-revised-and-expanded-November-2023.pdf\">HLI, McGuire (2023)</a>&nbsp;used a meta-analysis of LMIC psychotherapy studies with various moderators to set an \"informed prior\" and added a pessimistic update to anticipate negative results from <a href=\"https://beta.clinicaltrials.gov/study/NCT03966833\">Baird and Ozler</a></p><p>In a <a href=\"https://forum.effectivealtruism.org/posts/GJ4xjAnubWiBJDbE8/talking-through-depression-the-cost-effectiveness-of?commentId=eh7F6DF5fPF6DTKwJ\">comment</a>, Gregory Lewis argued that this didn't go far enough, and that negative results from <a href=\"https://beta.clinicaltrials.gov/study/NCT03966833\">Baird and Ozler</a>&nbsp;would suggest that StrongMinds was a weaker option \"even among psychotherapy interventions\" since \"picking one at random which doesn't have a likely-bad-news RCT imminent seems a better bet\".</p><p>(Note: In HLI's previous analysis, <a href=\"https://www.happierlivesinstitute.org/wp-content/uploads/2022/04/StrongMinds-CEA.pdf\">HLI, McGuire (2021)</a>, see Table 2, including more direct evidence from StrongMinds, as well as looking at studies with \"StrongMinds like traits,\" made the intervention look better. Hints that <a href=\"https://beta.clinicaltrials.gov/study/NCT03966833\">Baird and Ozler</a>&nbsp;would produce pessimistic results were not available at the time.)</p><p>We symmetrically give less weight to these arguments for pessimism for &nbsp;the same reason that we give less weight to the arguments for optimism - we think that for this intervention, the ups and downs of specific RCTs are less informative than the aggregated evidence from all psychotherapy RCTs in general.</p><h3>We favour looking at broader evidence over individual RCTs, and strongly emphasise the importance of reducing risk of bias in study design..</h3><p>Our overall stance on these debates is</p><ol><li>Accounting for Risk of Bias in Study Design is very central to our estimate<ol><li>We can't rely on StrongMind's direct evidence because of risk of bias in study design</li><li>Differences between HLI's meta-analysis and ours are explained by not accounting for risk of bias in study design</li><li>For any given trial, differences in how risk of bias is accounted for can easily contribute more to their headline reported result than the true effect.</li></ol></li><li>We think broad and high quality evidence from many contexts is better than a small number of RCTs which share many factors with the intervention, or a single RCT on site.<ol><li>Our intuition is that it's easy for two RCTs measuring the same underlying thing to give wildly different results, and therefore using a broader evidence base is better</li><li><a href=\"https://jamanetwork.com/journals/jama/article-abstract/196766\">Bolton (2003)</a>&nbsp;and &nbsp;<a href=\"https://www.cambridge.org/core/journals/the-british-journal-of-psychiatry/article/group-interpersonal-psychotherapy-for-depression-in-rural-uganda-6month-outcomes/34A03947B7B1F12CD5E364AD54B45626\">Bass (2006)</a>&nbsp;are well designed, but even well designed RCTs do vary wildly in effect size, not to mention that the intervention in question was chosen <i>because </i>the RCT results had a high effect size, so we should anticipate some regression to the mean</li><li>We hesitate to update very negatively on <a href=\"https://beta.clinicaltrials.gov/study/NCT03966833\">Baird and Ozler</a>&nbsp;(under the scenario where the results are pessimistic) for many of the same reasons we hesitated to update too positively on <a href=\"https://jamanetwork.com/journals/jama/article-abstract/196766\">Bolton (2003)</a>&nbsp;and &nbsp;<a href=\"https://www.cambridge.org/core/journals/the-british-journal-of-psychiatry/article/group-interpersonal-psychotherapy-for-depression-in-rural-uganda-6month-outcomes/34A03947B7B1F12CD5E364AD54B45626\">Bass (2006)</a>. We are aiming for a robust estimate, and we think over-updating on individual RCTs will lead to a bit of a random walk rather than an accurate estimate of the true impact.</li></ol></li><li>We favour broader meta-analyses over meta-analyses that are trying to tackle specific reference classes.<ol><li>Unlike HLI, we did not restrict our meta-analysis to the reference class of low and middle income countries (though it happens to be the case that <a href=\"https://forum.effectivealtruism.org/posts/iJX6FmohigXtNWzAp/what-s-the-effect-size-of-therapy#We_generalise_our_findings_to_low_income_countries_and_non_western_cultures_\">after risk of bias filtering, it wouldn't have made any difference if we had</a>) because that would reduce the number of studies available which passed all of our risk of bias criteria</li><li>Unlike HLI, we did not incorporate our moderator analysis into our final estimates. E.g. We don't add an adjustment for lay-counsellor vs trained therapist, or for individual vs group care, because we don't think there's enough evidence that these factors make a big difference, and we don't think meta-regressions can robustly identify the differences that may be there. (Consider, for example, the failure of meta-regressions to identify the impact of number of therapy sessions, a finding which goes against common sense)</li></ol></li></ol><p>These three stances interact with each other - for example, using a single RCT or a very small number of RCTs often means making compromises with respect to the number of studies that pass all risk of bias criteria. We would consider weighing a single RCT with an optimistic finding more strongly if it were to pass all four aforementioned <a href=\"https://forum.effectivealtruism.org/posts/iJX6FmohigXtNWzAp/what-s-the-effect-size-of-therapy#Cochrane_s_Risk_of_Bias_in_study_design_\">Risk of Bias</a>&nbsp;assessments, but <a href=\"https://jamanetwork.com/journals/jama/article-abstract/196766\">Bolton (2003)</a>&nbsp;only passes three. &nbsp;An&nbsp;RCT which gave a very pessimistic answer would decrease our confidence in StrongMinds would only drop by a small amount, not a large amount</p><p><img style=\"width:546.50px\" src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QptTu7QnF4S69opjB/n7dd3lfmptm38ocvxlo0\" alt=\"\"></p><p>Figure: Effect sizes vs standard error colour coded by risk of bias in study design, with a visually apparent trend towards fewer criteria passed showing higher effect sizes. Risk of bias is an example of a factor which has nothing to do with the underlying phenomenon being measured, yet creates variation in the data. &nbsp;There is a very large amount of variation even <i>after </i>accounting for risk of bias, much of it over unrealistic ranges. The variation is caused by factors that are not well understood by us, and we haven't seen anything to suggest that it really corresponds to variation in the underlying thing being measured, leading us to favour pooled estimates. Recall that our review discovered that factors such as therapist experience and therapy type, which we might have hoped would explain this variation, made <a href=\"https://forum.effectivealtruism.org/posts/iJX6FmohigXtNWzAp/what-s-the-effect-size-of-therapy#There_are_lots_of_factors_that_surprisingly__may_not_matter\">very little difference</a>.</p><p>For these reasons, we tend to reject both optimistic and pessimistic interpretations of direct evidence in favour of our broader estimate of the effects of psychotherapy. We rely on our academic estimates of effect size and duration to quantify the effect size of therapy. Our analysis of StrongMinds itself therefore focuses mostly on the basics outlined in the previous sections: did some form of psychotherapy get delivered, to how many people, and at what cost?</p><h2>Citations</h2><h3>Resources from StrongMinds&nbsp;</h3><p><strong>&nbsp;StrongMinds </strong><a href=\"https://strongminds.org/wp-content/uploads/2016/02/StrongMinds-Impact-Evaluation-Report-November-2014.pdf\"><strong>phase 1</strong></a><strong>&nbsp;and </strong><a href=\"https://strongminds.org/wp-content/uploads/2013/07/StrongMinds-Phase-Two-Impact-Evaluation-Report-July-2015-FINAL.pdf\"><strong>phase 2</strong></a><strong>&nbsp;and </strong><a href=\"https://strongminds.org/wp-content/uploads/2017/07/strongminds-phase-1-and-2-follow-up-evaluations_final.pdf\"><strong>followup</strong></a><strong>&nbsp;evaluations</strong></p><p><a href=\"https://strongminds.org/wp-content/uploads/2016/02/StrongMinds-Impact-Evaluation-Report-November-2014.pdf\">Peterson (2014). \"Impact Evaluation End of Phase One Impact Evaluation for the Treating Depression at Scale in Africa Program in Uganda\", StrongMinds</a>&nbsp;</p><p><a href=\"https://strongminds.org/wp-content/uploads/2013/07/StrongMinds-Phase-Two-Impact-Evaluation-Report-July-2015-FINAL.pdf\">Peterson (2015) \"Impact Evaluation End of Phase Two Impact Evaluation for the Treating Depression at Scale in Africa Program in Uganda\", StrongMinds</a>&nbsp;</p><p><a href=\"https://strongminds.org/wp-content/uploads/2017/07/strongminds-phase-1-and-2-follow-up-evaluations_final.pdf\">Follow Up Evaluations for Phase 1 &amp; Phase 2</a>&nbsp;</p><p><strong>StrongMinds quarterly updates</strong></p><p><a href=\"https://strongminds.org/quarterly-reports/\"><strong>https://strongminds.org/quarterly-reports/</strong></a><strong>&nbsp;</strong></p><p><strong>StrongMinds General Media</strong></p><p>Frontpage - <a href=\"https://strongminds.org/\">https://strongminds.org/</a>&nbsp;</p><p>StrongMinds America - <a href=\"https://www.strongmindsamerica.org/\">https://www.strongmindsamerica.org/</a>&nbsp;</p><p>YouTube - <a href=\"https://www.youtube.com/c/StrongMinds\">https://www.youtube.com/c/StrongMinds</a>&nbsp;</p><p>Twitter - <a href=\"https://www.strongmindsamerica.org/\">https://www.strongmindsamerica.org/</a>&nbsp;</p><p>LinkedIn - <a href=\"https://www.linkedin.com/company/makestrongminds\">https://www.linkedin.com/company/makestrongminds</a>&nbsp;</p><p>Facebook - <a href=\"https://www.facebook.com/MakeStrongMinds/\">https://www.facebook.com/MakeStrongMinds/</a>&nbsp;</p><h3>RCTs pertaining to StrongMinds</h3><p><strong>StrongMinds upcoming RCT pre registration</strong></p><p><a href=\"https://classic.clinicaltrials.gov/ct2/show/NCT03966833\">Baird, S., \u00d6zler, B., Dell\u2019Aira, C., &amp; Us Salam, D. (2020). Using group interpersonal psychotherapy to improve the well-being of adolescent girls. J Dev Econ.</a></p><p>Negative comments from study author on twitter causing people to anticipate negative results: <a href=\"https://twitter.com/BerkOzler12/status/1595942739027582977\">\u00d6zler, B [@BerkOzler12] (2022, Nov 24). <i>No good evidence that Strong Minds is effective</i>&nbsp;[Tweet] X. https://twitter.com/BerkOzler12/status/1595942739027582977</a></p><p>See also EA forum comment and discussion of tweet <a href=\"https://forum.effectivealtruism.org/posts/ffmbLCzJctLac3rDu/strongminds-should-not-be-a-top-rated-charity-yet?commentId=Agn8cLJd4bTTXJFu9\">https://forum.effectivealtruism.org/posts/ffmbLCzJctLac3rDu/strongminds-should-not-be-a-top-rated-charity-yet?commentId=Agn8cLJd4bTTXJFu9</a>&nbsp;<br><br><a href=\"https://jamanetwork.com/journals/jama/article-abstract/196766\"><strong>Bolton (2003)</strong></a><strong>&nbsp;RCT and </strong><a href=\"https://www.cambridge.org/core/journals/the-british-journal-of-psychiatry/article/group-interpersonal-psychotherapy-for-depression-in-rural-uganda-6month-outcomes/34A03947B7B1F12CD5E364AD54B45626\"><strong>Bass (2006)</strong></a><strong>&nbsp;followup off of which StrongMinds is based</strong></p><p><a href=\"https://jamanetwork.com/journals/jama/article-abstract/196766\">Bolton, P., Bass, J., Neugebauer, R., Verdeli, H., Clougherty, K. F., Wickramaratne, P., ... &amp; Weissman, M. (2003). Group interpersonal psychotherapy for depression in rural Uganda: a randomized controlled trial. Jama, 289(23), 3117-3124.</a></p><p><a href=\"https://www.cambridge.org/core/journals/the-british-journal-of-psychiatry/article/group-interpersonal-psychotherapy-for-depression-in-rural-uganda-6month-outcomes/34A03947B7B1F12CD5E364AD54B45626\">Bass, J., Neugebauer, R., Clougherty, K. F., Verdeli, H., Wickramaratne, P., Ndogoni, L., ... &amp; Bolton, P. (2006). Group interpersonal psychotherapy for depression in rural Uganda: 6-month outcomes: randomised controlled trial. The British Journal of Psychiatry, 188(6), 567-573.</a></p><h3>Other citations</h3><p><strong>HLI 2023 updated analysis</strong></p><p><a href=\"https://www.happierlivesinstitute.org/wp-content/uploads/2023/11/Talking-through-depression-The-cost-effectiveness-of-psychotherapy-in-LMICs-revised-and-expanded-November-2023.pdf\">McGuire, (2023) &nbsp;Talking through depression: The cost-effectiveness of psychotherapy in LMICs, revised and expanded, Happier Lives Institute</a></p><p><strong>HLI's estimate of psychotherapy interventions</strong></p><p><a href=\"https://www.happierlivesinstitute.org/wp-content/uploads/2022/04/Psychotherapy-CEA.pdf\">McGuire, (2021a</a>)<a href=\"https://www.happierlivesinstitute.org/wp-content/uploads/2022/04/Psychotherapy-CEA.pdf\">&nbsp; \"Cost-Effectiveness Analysis: Group or task-shifted psychotherapy to treat depression\", Happier Lives Institute</a></p><p><strong>HLI's estimate of StrongMinds</strong><br><a href=\"https://www.happierlivesinstitute.org/wp-content/uploads/2022/04/StrongMinds-CEA.pdf\">McGuire, J. (2021b)</a>&nbsp;\"<a href=\"https://www.happierlivesinstitute.org/wp-content/uploads/2022/04/StrongMinds-CEA.pdf\">Cost Effectiveness Analysis - Strongminds\", Happier Lives Institute</a></p><p><strong>Number of sessions and effect size</strong></p><p>&nbsp;<a href=\"https://www.sciencedirect.com/science/article/abs/pii/S0165032713001900\">Cuijpers, P., Huibers, M., Ebert, D. D., Koole, S. L., &amp; Andersson, G. (2013). How much psychotherapy is needed to treat depression? A metaregression analysis. Journal of affective disorders, 149(1-3), 1-13.</a>&nbsp;</p><ol class=\"footnote-section footnotes\" data-footnote-section=\"\" role=\"doc-endnotes\"><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"1\" data-footnote-id=\"q3pyag0pxlm\" role=\"doc-endnote\" id=\"fnq3pyag0pxlm\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"q3pyag0pxlm\"><sup><strong><a href=\"#fnrefq3pyag0pxlm\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;\"<a href=\"https://en.wikipedia.org/wiki/Double_counting_(accounting)\">Double counting</a>\" is an error caused by attributing all impact to a lone actor when multiple actors are involved. If someone benefits from a StrongMinds partner program, donations to both StrongMinds and to the partner were involved in creating that result - attributing all of the impact to either party would result in an inflated cost-effectiveness estimate.</p></div></li></ol>", "user": {"username": "ishaan"}}, {"_id": "NaqpPbkDKqHwn2CW9", "title": "Would you rather kill 2 mice or 10 fish? Interspecies Trade-Offs and the Moral Weight of Animal Species in Biomedical Research", "postedAt": "2024-03-20T18:17:24.992Z", "htmlBody": "<p>This research was conducted for my final-year &nbsp;Module \u201cAnimal Justice\u201d at University College London led by Professor Jane Holder, investigating how biomedical researchers make welfare and value comparisons between species.</p><p>Thanks to Professor Jane Holder, Bob Fischer, Alistair Stewart, Jack Hancock-Fairs and Karolina Sarek for their guidance, thoughts and feedback.</p><p>A PDF of the research poster can be accessed <a href=\"https://drive.google.com/file/d/1DQOiFFoAAwjlbe0-olWufShmGCIM5cQW/view?usp=sharing\">here</a>.</p><h2>Introduction</h2><p>Inter-species tensions are ubiquitous when it comes to human engagement with animals. In many cases, when seeking to reduce harm to animals, the interests of two or more species come into conflict with each other. In these cases, we decide, whether implicitly or explicitly, how we trade the well-being and moral worth of individuals from one species against another. Despite its complexity, inter-species comparisons are inescapable, making it critical to develop a coherent and robust framework to navigate these tensions, with steps towards this being made (Gaffney et al., 2022). To do this, we must first examine our priors with regards to comparing the moral worth of animal groups against each other, explore how these may vary in different contexts and determine whether they have any validity.</p><h3>Animals in Science</h3><p>The use of animals in research is a strong case study of a context where we extensively make direct comparisons between the moral worth of different species, manifesting in the choices we make for which animals we conduct experiments on.&nbsp;</p><p>This project sought to investigate interspecies tensions, when considering the application of the 3Rs principles from the Animals (Scientific Procedures) Act 1986, which is the piece of legislation that outlines permissions and protections with regards to the use of animals in science in the UK.&nbsp;</p><p>What animals are protected?</p><p>Section 1 of the Act specifies which species of animal are protected in the context of scientific experimentation, and the life stages at which they may be protected. Protected animals are:</p><p>Any living vertebrate</p><p>Mammals, birds and reptiles are protected from \u2154 through the gestation/incubation period</p><p>Any other vertebrate is protected from the point of independent feeding</p><p>Any living cephalopod</p><p>Protected from the point of independent feeding</p><p>What does it mean to be protected?</p><p>In section 2A of the 1986 Act the 3Rs are explained, which provide the guiding ethical principles for animal experimentation. \u2018Replacement\u2019 stipulates that methods that do not use protected animals should be favoured whenever possible. \u2018Reduction\u2019 stipulates that the number of protected animals used should be reduced to a minimum. \u2018Refinement\u2019 stipulates that the handling of animals must be refined to minimise pain and distress as much as possible. However, from an ethical standpoint these principles come into tension.&nbsp;</p><h3>A common dilemma</h3><p>Replacement is often practically applied by substituting a \u201cmore complex\u201d animal with a \u201cless complex\u201d animal. This often also leads to an increase in the number of animals used, demonstrating an ethical tension between Replacement and Reduction. Therefore, although this application of Replacement is often lauded and encouraged for its compliance with the principles laid out by the 1986 Act, it reveals an ethical dilemma: at what point do the aggregate impacts of using a higher number of \u201clower order\u201d animals morally outweigh the aggregate impact of using a lower number of \u201chigher order\u201d animals?</p><h3>Research Question</h3><p>This project sought to investigate how researchers justify using a higher number of a \u201cless complex\u201d species over a lower number of a \u201cmore complex\u201d species and how they navigate this tension through the application of the 3Rs, through a case study of use of mice and zebrafish in biomedical research.</p><h2>Case Study: Zebrafish and Mice</h2><h3>Why use zebrafish at all?</h3><p>Zebrafish have emerged as a promising alternative to traditional rodent models in various biomedical experiments. \u201cDue to its fully sequenced genome, easy genetic manipulation, high fecundity, external fertilisation and rapid development, and nearly transparent embryo, zebrafish are a unique model animal for biomedical research, including studies of biological processes and human diseases\u201d (Teame et al., 2019)</p><h3>What are the legal protections for zebrafish in the UK?</h3><p>Under the Animals (Scientific Procedures) Act 1986, fish only become protected animals at the point when they are capable of <i>independent</i> <i>feeding</i>, which is considered as five days post fertilisation (5 dpf) for zebrafish.&nbsp;</p><h3>Can zebrafish suffer?</h3><p>Whilst there is a strong consensus that adult zebrafish are sentient (Sneddon et al., 2018), less research has been conducted into sentience at earlier life stages. However, recent work has demonstrated that zebrafish at 5 dpf respond to noxious stimuli in the same way as adults, from gene expression to behavioural changes (Curtwright et al. 2015; Lopez-Luna et al. 2017 a, b, c, d). Despite the absence of legal protection for zebrafish larvae up to 5 dpf, the presence of a mature brain and nerve tracts underscores their likely underscores their capacity for pain perception (Rothenb\u00fccher et al., 2019).&nbsp;</p><p>Despite this, in biomedical research, zebrafish are widely used at &lt;= 5 dpf, as a replacement for rodent models.</p><h2>Methodology</h2><p>I conducted a literature review on the research question \u201chow do researchers justify using \u2018less sophisticated\u2019 animals over \u201cmore sophisticated\u201d animals in biomedical research?\u201d. I used Google Scholar to find papers with the following search terms: 3R OR 3Rs OR 3rs zebrafish reduction higher OR lower OR order OR sophisticated. I started with 50 papers which were screened for relevance, retaining 30. I ended my literature review at this point, as I had reached saturation.&nbsp;</p><h2>Findings: How do biomedical researchers justify using zebrafish over mice through the 3Rs?</h2><h3><strong>Replacement</strong></h3><p>Biomedical researchers commonly justify the use of zebrafish at &lt;= 5 dpf over mice through full replacement - the replacement of a protected animal with an unprotected animal (Rupprechter, 2021; Vliegenthart et al., 2014).&nbsp;</p><blockquote><p>\u201cthe use of zebrafish is in line with the \u20183Rs\u2019 (reduce, refine and replace) approach of animal use for scientific purposes by replacing higher-order animals with lower-order zebrafish (particularly, zebrafish embryos).\u201d (Vliegenthart et al., 2014)</p></blockquote><p>Some researchers refer to zebrafish at this stage in development as \u201cin vitro\u201d models, suggesting that these animals are considered as non-living objects.</p><blockquote><p>\u201czebrafish larvae up to 5 days post fertilization (dpf) are considered in vitro models and are accepted as an alternative to animal testing\u201d (Cornet et al. 2017)</p></blockquote><p>Zebrafish &lt;= 5 dpf are not legally protected, so their use at this life stage is deliberate, to avoid the restrictions that come into place for the use of protected animals in experimentation.</p><p>\"As the EU directive 2010_63 explicitly states only \u201cindependently feeding larval forms\u201d must be classified as animal experiments, therefore only zebrafish larvae past 120 h post fertilization should be subject to the regulations of European animal protection guidelines. For our experiments, we did not use larvae that have reached an \u201cindependent feeding\u201d stage and therefore we did not have to submit an ethical approval to the competent local/national ethical/legal bodies.\" (Bercier et al. 2019)</p><h3><strong>Reduction</strong></h3><p>Biomedical researchers do not seek to apply the reduction principle directly to zebrafish use at all. Given their legal status as non-protected animals at the age of use (&lt;= 5 dpf), there is no discussion of the reduction of the numbers of animals due to ethical considerations. Rather, the high numbers of zebrafish that can be used as a result of their unprotected status is often lauded.&nbsp;</p><blockquote><p>The high n numbers available per study when using zebrafish is discussed as a comparative advantage of zebrafish over mice, allowing for improved statistical analysis (Scholz, 2013)</p></blockquote><blockquote><p>\u201cWhat they lack in size they make up for in numbers\u201d (Zon and Peterson, 2005)</p></blockquote><blockquote><p>[List of advantages of zebrafish over mice] \u201cHigh n numbers available per study, allowing improved statistical analysis - Lower-order mammal (in line with \u20183Rs\u2019 principles)\u201d (Vliegenthart et al., 2014)</p></blockquote><p>Indeed, the use of a high number of zebrafish for high throughput analysis is actually justified through the reduction principle, in terms of the numbers of mice, as it reduces the total number of higher order animals needed across phases of research (de Abreu et al., 2019; Dal et al., 2022)</p><blockquote><p>\u201cThis, in turn, <strong>can contribute to the refinement of experiments in higher vertebrates, such as mice and rats, and reduce the number of animals needed at a later stage in the drug discovery process.\" (</strong>Dal et al., 2022)</p></blockquote><h2>Conclusion</h2><p>The moral weight placed on animals in biomedical research is dictated by their status as protected or non-protected animals in the Animals (Scientific Procedures) Act 1986, rather than by direct evidence of sentience or ethical concern for animal lives and experiences.&nbsp;</p><p>The biomedical community does not recognise an ethical dilemma in replacing a lower number of mice with a higher number of zebrafish &lt;= 5dpf, as non-protected animals are not considered to hold intrinsic moral value. In this way, in the eyes of the biomedical research community, the legal status of the animals dissolves the evident ethical tension. Therefore, the researchers do not feel the need to justify decisions around the use of zebrafish at &lt;= 5 dpf in terms of the wellbeing of the zebrafish.&nbsp;</p><p>The Animals (Scientific Procedures) Act 1986 is unfit for purpose, as it offers legal protection to animals on the basis of measures that are weak proxies for their moral status, particularly in light of new research in animal welfare science. What matters morally \u2013 and what ought to be captured in law \u2013 is not an animal's capacity for independent feeding, but rather their capacity for suffering. This Act utterly underserves its aim of providing an ethical framework for animal experimentation that reduces harm to animals, which calls for serious reform to this piece of legislation.</p><h2>Recommendations</h2><p>Despite the Animals (Scientific Procedures) Act 1986 being the primary piece of legislation that protects animals used for experimentation in the UK, its focus on only protecting vertebrates (plus cephalopods), with species that are not mammals, birds reptiles only protected from the stage of independent feeding shows it to be severly underserving animals. Significant groups of animals which recent evidence suggests likely have the capacity for pain, such as decapods, are left entirely unprotected. Further, all fish and amphibians are protected only after the arbitrary mark of capacity for independent feeding. When a species is unprotected, it is legal for researchers to do whatever they want to however many individuals of that group they desire. This can lead to enormous buckets of suffering.&nbsp;</p><p>One vital recommendation arising from this analysis is the need to reassess the threshold at which animals gain legal protection. This criterion should be reevaluated, ensuring that animals are protected based on scientific evidence of their capacity for suffering, rather than arbitrary developmental milestones. This would also force this ethical dilemma into the light, unable to be dissolved by the legal status of zebrafish larvae as unprotected animals.</p><p>Further, there is a need for the 3Rs to evolve into a robust and coherent framework to guide researchers through the ethical implications of replacing sophisticated animals with less sophisticated ones. This evaluation should consider factors which are morally relevant, such as an animal's capacity to experience pain and should guide researchers through ethical dilemmas arising from emergent tensions between the core principles.&nbsp;</p><p>A reformed framework could provide clearer guidance on when to transition from using a low number of mice to a high number of zebrafish, considering both scientific evidence and ethical considerations. This would allow researchers to make more informed interspecies welfare trade-offs, reducing the chance of intuition, biases and inaccurate priors leading to unnecessary harm.&nbsp;</p><h2>References</h2><p>Bercier, V., Rosello, M., Filippo Del Bene and C\u00e9line Revenu (2019). Zebrafish as a Model for the Study of Live in vivo Processive Transport in Neurons. <i>Frontiers in Cell and Developmental Biology</i>, [online] 7. doi:https://doi.org/10.3389/fcell.2019.00017.</p><p>Cornet, C., Calzolari, S., Mi\u00f1ana-Prieto, R., Dyballa, S., van Doornmalen, E., Rutjes, H., Savy, T., D\u2019Amico, D. and Terriente, J. (2017). ZeGlobalTox: An Innovative Approach to Address Organ Drug Toxicity Using Zebrafish. <i>International Journal of Molecular Sciences</i>, 18(4), p.864. doi:https://doi.org/10.3390/ijms18040864.</p><p>Curtright, A., Rosser, M., Goh, S., Keown, B., Wagner, E., Sharifi, J., Raible, D.W. and Dhaka, A. (2015). Modeling Nociception in Zebrafish: A Way Forward for Unbiased Analgesic Discovery. <i>PLOS ONE</i>, 10(1), p.e0116766. doi:https://doi.org/10.1371/journal.pone.0116766.</p><p>de Abreu, M.S., Giacomini, A.C.V.V., Echevarria, D.J. and Kalueff, A.V. (2019). Legal aspects of zebrafish neuropharmacology and neurotoxicology research. <i>Regulatory Toxicology and Pharmacology</i>, 101, pp.65\u201370. doi:https://doi.org/10.1016/j.yrtph.2018.11.007.</p><p>Gaffney, L., J. Michelle Lavery, Schiestl, M., Trevarthen, A., Schukraft, J., Miller, R., Schnell, A.K. and Fischer, B. (2022). A Method for Improving Interspecies Welfare Comparisons. doi:https://doi.org/10.20944/preprints202210.0012.v1.</p><p>Lopez-Luna, J., Al-Jubouri, Q., Al-Nuaimy, W. and Sneddon, L.U. (2017a). Impact of analgesic drugs on the behavioural responses of larval zebrafish to potentially noxious temperatures. <i>Applied Animal Behaviour Science</i>, 188(188), pp.97\u2013105. doi:https://doi.org/10.1016/j.applanim.2017.01.002.</p><p>Lopez-Luna, J., Al-Jubouri, Q., Al-Nuaimy, W. and Sneddon, L.U. (2017b). Impact of stress, fear and anxiety on the nociceptive responses of larval zebrafish. <i>PLOS ONE</i>, 12(8), p.e0181010. doi:https://doi.org/10.1371/journal.pone.0181010.</p><p>Lopez-Luna, J., Qussay Al-Jubouri, Waleed Al-Nuaimy and Sneddon, L.U. (2017c). Reduction in activity by noxious chemical stimulation is ameliorated by immersion in analgesic drugs in zebrafish. <i>The Journal of Experimental Biology</i>, 220(8), pp.1451\u20131458. doi:https://doi.org/10.1242/jeb.146969.</p><p>Nils-J\u00f8rgen Knudsen Dal, Speth, M., Johann, K., Barz, M., Beauvineau, C., Jens Wohlmann, Fenaroli, F., Gicquel, B., Griffiths, G. and Alonso\u2010Rodr\u00edguez, N. (2022). The zebrafish embryo as an <i>in vivo</i> model for screening nanoparticle-formulated lipophilic anti-tuberculosis compounds. <i>Disease Models &amp; Mechanisms</i>, 15(1). doi:https://doi.org/10.1242/dmm.049147.</p><p>Rothenb\u00fccher, T.S.P., Ledin, J., Gibbs, D., Engqvist, H., Persson, C. and Hulsart-Billstr\u00f6m, G. (2019). Zebrafish embryo as a replacement model for initial biocompatibility studies of biomaterials and drug delivery systems. <i>Acta Biomaterialia</i>, [online] 100, pp.235\u2013243. doi:https://doi.org/10.1016/j.actbio.2019.09.038.</p><p>Rupprechter, S.A.E. (2021). MicroRNAs as biomarkers in anti-tuberculosis drug-induced liver injury: a translational study from zebrafish to humans. <i>Edinburgh Medical School Thesis and Dissertation Collection</i>. doi:https://doi.org/10.7488/era/1446.</p><p>Scholz, S. (2013). Zebrafish embryos as an alternative model for screening of drug-induced organ toxicity. <i>Archives of Toxicology</i>, 87(5), pp.767\u2013769. doi:https://doi.org/10.1007/s00204-013-1044-2.</p><p>Sneddon, L.U., Lopez-Luna, J., Wolfenden, D.C.C., Leach, M.C., Valentim, A.M., Steenbergen, P.J., Bardine, N., Currie, A.D., Broom, D.M. and Brown, C. (2018). Fish sentience denial: Muddying the waters. <i>Animal Sentience</i>, 3(21). doi:https://doi.org/10.51291/2377-7478.1317.</p><p>Teame, T., Zhang, Z., Ran, C., Zhang, H., Yang, Y., Ding, Q., Xie, M., Gao, C., Ye, Y., Duan, M. and Zhou, Z. (2019). The use of zebrafish (Danio rerio) as biomedical models. <i>Animal Frontiers</i>, [online] 9(3), pp.68\u201377. doi:https://doi.org/10.1093/af/vfz020.</p><p>Vliegenthart, A.D.B., Tucker, C.S., Del Pozo, J. and Dear, J.W. (2014). Zebrafish as model organisms for studying drug-induced liver injury. <i>British Journal of Clinical Pharmacology</i>, 78(6), pp.1217\u20131227. doi:https://doi.org/10.1111/bcp.12408.</p><p>Zon, L.I. and Peterson, R.T. (2005). In vivo drug discovery in the zebrafish. <i>Nature Reviews Drug Discovery</i>, 4(1), pp.35\u201344. doi:https://doi.org/10.1038/nrd1606.</p>", "user": {"username": "Aashish Khimasia"}}, {"_id": "k7igqbN52XtmJGBZ8", "title": "Effective language-learning for effective altruists", "postedAt": "2024-03-19T00:42:08.274Z", "htmlBody": "<figure class=\"table\"><table><tbody><tr><td style=\"background-color:#ddeee8;border:0.375pt solid #97c9b1;padding:5pt;vertical-align:top\"><p><strong>This is a (late!)&nbsp;</strong><a href=\"https://forum.effectivealtruism.org/topics/draft-amnesty-week-2024\"><strong>Draft Amnesty Week</strong></a><strong> draft.&nbsp;</strong>It may not be polished, up to my usual standards, fully thought through, or fully fact-checked.&nbsp;</p></td></tr><tr><td style=\"background-color:#eef8f4;border:0.375pt solid #97c9b1;padding:5pt;vertical-align:top\"><p><strong>Commenting and feedback guidelines:&nbsp;</strong></p><ol><li>This draft lacks the polish of a full post, but the content is almost there. The kind of constructive feedback you would normally put on a Forum post is very welcome.&nbsp;</li></ol></td></tr></tbody></table></figure><p><strong>Epistemic status: </strong>Tentative \u2014 I have thought about this for some time (~2 years) and have firsthand experience, but have done minimal research into the literature.</p><p><strong><u>TL;DR: </u></strong>Language learning is probably not the best use of your time. Some exceptions might be (1) learning English as a non-native speaker, (2) if you are particularly apt at learning languages, (3) if you see it as leisure and so minimize opportunity costs, (4) if you are aiming at regional specialist roles (e.g., China specialist) and are playing the long game, and more. If you still want to do it, I propose some ways of greatly speeding up the process: practicing artificial immersion by maximizing exposure and language input, learning a few principles of linguistics (e.g., IPA, arbitrariness), learning vocabulary through spaced repetition and active recall (e.g., with Anki), and more.</p><p><strong>Motivation: </strong>I'd bet that EAs are unusually interested in learning languages (definitely compared to the general population, probably compared to demographically similar populations). This raises two big questions: (1) Does learning a foreign language make sense, from an impact perspective? (2) If it does, how does one do it most effectively?</p><p><strong>My goals are:</strong>&nbsp;</p><ul><li>To dissuade most EAs from learning a random language without a clear understanding of the (opportunity) costs.</li><li>To encourage the comparatively few for which language-learning makes sense, and to give them some tips to do so faster and better.</li></ul><p><strong>Is this a draft? </strong>The reason I am publishing this (late!) on Draft Amnesty Week is that <strong>I believe a quality post on effective language learning should draw from the </strong><a href=\"https://en.wikipedia.org/wiki/Second-language_acquisition\"><strong>second language acquisition</strong></a><strong> (SLA) literature and make evidence-based claims. I don't have time to do this, so this post is based almost entirely on my own experience and learning from successful polyglots</strong> (see \"learn from others\" below). Still, I think most people approach language learning in such an inefficient way that this post will be valuable to many.</p><p><strong>Who am I to say?</strong> <strong>Spanish</strong> is my native language. I have learned two foreign languages: English to level C2 and German to level B2.<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"1\" data-footnote-id=\"5fu63d4imv\" role=\"doc-noteref\" id=\"fnref5fu63d4imv\"><sup><a href=\"#fn5fu63d4imv\">[1]</a></sup></span>&nbsp;I learned both of these faster than my peers,<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"2\" data-footnote-id=\"lqz58jdgniq\" role=\"doc-noteref\" id=\"fnreflqz58jdgniq\"><sup><a href=\"#fnlqz58jdgniq\">[2]</a></sup></span>&nbsp;which I mostly attribute to using the principles detailed below. Many readers will have much more experience learning languages, so &nbsp;I encourage you to add useful tips or challenge mine in the comments!</p><h1>What are some costs and benefits?</h1><p>This is not an exhaustive list!</p><p><strong>Benefits:&nbsp;</strong></p><ul><li>&nbsp;Access to new jobs, jobs in new regions, or higher likelihood of being hired for certain jobs. This is only the case if you reach an advanced level (probably C1 or C2, at least B2), and is most relevant if you are learning English.</li><li>Access to more resources and news. If you plan to be, say, a regional foreign policy expert, learning the region's language(s) can be necessary.</li><li>Good signaling of conscientiousness and intelligence.</li><li>Cognitive benefits? Language learning purportedly benefits memory, IQ, creativity, and slows down cognitive aging \u2014 but I have not gone into this literature and so am not confident either way.</li><li>Greater ability to form social connections. Speaking someone's language and knowing about their culture is a great introduction.</li></ul><p><strong>Costs:&nbsp;</strong></p><ul><li><strong>A LOT of time </strong>(depends on the language, the learner, and the method), attention and effort; <strong>large opportunity costs.</strong> There are ways of speeding up the process, but it is still a particularly costly endeavor.<ul><li>Seriously, think about all you could learn instead. In the same amount of time, you could learn to program in Python, or you could read several textbooks on biotechnology, or get up to speed on AI safety research, or start a blog to increase your visibility, or work part-time, or really <i>anything else.</i></li></ul></li><li>(!) Don't be fooled by the many bullet points in the \"benefits\" section versus only one in the \"costs\" section. I think the costs likely far outweigh the benefits for most EAs in most circumstances (more on this below).</li></ul><h1>So when should an EA learn a language?</h1><p>Here are some factors that contribute to language-learning making sense for someone:</p><ul><li>When the language is itself worth learning for instrumental reasons. Learning English as a second language seems very important.&nbsp;<ul><li>Other languages that seem particularly useful, depending on your goals and circumstances: Mandarin Chinese, Russian, Spanish, French, Standard Arabic, Hindi. Still, these seem much less valuable for most people than English (if it's not their first language).</li><li>Consider that some languages will be much harder to learn than others, depending on the languages you already speak. For native English speakers, it is estimated that Spanish and French are relatively easy, Russian and Hindi are about twice as difficult, and Standard Arabic and Mandarin Chinese are about three times as difficult.<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"3\" data-footnote-id=\"u11kq30ouf\" role=\"doc-noteref\" id=\"fnrefu11kq30ouf\"><sup><a href=\"#fnu11kq30ouf\">[3]</a></sup></span></li></ul></li><li>For better (and more impactful) work opportunities (e.g., learning English).</li><li>For very specific career goals, like becoming a regional specialist. For example, if you are playing the long game and trying to become a China specialist, it may make sense for you to study Mandarin Chinese. Try to be honest with yourself and create a clear theory of change about how learning Language X will be crucial for you.</li><li>When they are talented at learning languages. Please interpret this with caution. I think most people who think they are bad at languages have just been approaching the task the wrong way. Still, as with any cognitively demanding task, some people are just better at it than others.</li><li>When they enjoy it greatly and are energized by it. Some people (myself included) just don't budget language-learning time as \"work.\" If you genuinely enjoy it and are energized by it, then your opportunity costs decrease sharply. If language-learning does not take from your limited attentional resources, it makes more sense to do it.<ul><li>Useful questions to ask yourself are: If you started learning Language X, would you have to stop doing Valuable Activity Y? If you did NOT start learning Language X, would you have the energy and motivation to start doing Valuable Activity Y? Have I wanted to learn Language X for a very long time?</li></ul></li><li>When they have a unique opportunity. You might have close family members, friends, or a partner that speak your target language (TL), or you might already live in a country that speaks your TL, or you might have a citizenship that allows you to work in a country where your TL is spoken, etc. These factors will make language-learning easier and more engaging.</li></ul><h1>Principles of Effective Language-Learning</h1><p>If learning a language makes sense for you after all, here are some ideas to speed up the process (and make it more enjoyable).</p><ul><li>The intuitions<ul><li>I have often found that people have \"bad intuitions\" about language-learning, particularly monolingual English speakers. Having \"better\" intuitions is a great way to develop a sense for language-learning.</li></ul></li></ul><figure class=\"table\"><table><tbody><tr><td>\"Bad\" intuitions</td><td>\"Better\" intuitions</td></tr><tr><td>You can only learn a language as a child.</td><td>Learning a language as a child is easier under the right circumstances, but you can always learn a language.</td></tr><tr><td>You can only learn a language in the country where it's spoken.</td><td>You can absolutely learn a language while never visiting a country where it's spoken.</td></tr><tr><td>Strong foreign accents are inherent, bad, and impossible to change.</td><td>Foreign accents are changeable (to a degree), and are not bad so long as they don't make it hard to understand you.</td></tr><tr><td>Imitating a native's way of speaking is going too far or disrespectful or cringey.&nbsp;</td><td>Imitating a native speaker's way of speaking is a great way to learn to sound natural.&nbsp;</td></tr><tr><td>Formally studying a language is the main or only way of getting better at it.&nbsp;</td><td>Simply reading or listening to a language in its natural form will help you learn -- no/limited textbook or formal study is necessary.</td></tr><tr><td>Practicing speaking is the most important thing.</td><td>Output ability (speaking, writing) often emerges after lots of input (listening, reading).</td></tr><tr><td>Making mistakes is embarrassing.</td><td>&nbsp;If you're not making mistakes you're not practicing enough.</td></tr><tr><td>I failed at learning a language in high school, so I'm bad at languages.</td><td>Your high school was probably subpar at teaching languages. It is true that some people are better than others at this, but high school performance is a very noisy indicator.</td></tr><tr><td>If I can't perfectly understand this book/movie in my target language, I should read/watch it in my native language to avoid missing out.</td><td>You should be comfortable not understanding things or losing out on some of the meaning. The struggle will help you learn.</td></tr></tbody></table></figure><ul><li>Get the basics and create structure.<ul><li>If you're a complete beginner, you'll want to get to a level where you can sort-of understand very basic media in your target language (TL) as fast as possible. You can't jump right into reading a children's book in French without knowing the basics. Try enrolling in a course in your university, local community college, or any other language school, even online ones. Program quality varies a lot, so try to find a good place.<ul><li>Don't worry if you don't like this approach, you'll only have to do it for a short period of time. This is the hardest part of the process \u2014 getting from zero comprehension to minimal comprehension.</li></ul></li><li>Don't rely exclusively on Duolingo or other language-learning apps to get you out of beginner stage, especially not with only 15 minutes of practice a day. You may use Duolingo if you are seriously going to spend a lot of time per day, but I don't think it's an efficient way to go about getting the basics.</li></ul></li><li>Do a linguistics crash-course.<ul><li>This is one of the points that I consider most important, and that I see most neglected. You do <strong>not</strong> need to take a whole course in linguistics like I did. Most of the value comes from (1) some high-level ideas that will give you good intuitions, and (2) a basic understanding of phonetics.</li><li>Knowing a bit about syntax, specifically, will provide useful schemas for you to organize and retain new knowledge. Example: being able to quickly identify subject, direct/indirect object, verb, adverb, etc. will be advantageous when learning languages with <a href=\"https://en.wikipedia.org/wiki/Grammatical_case\">grammatical cases</a> (German, Slavic languages, and many others).</li><li>On phonetics: this is \"a branch of linguistics that studies how humans produce and perceive sounds\" (<a href=\"https://en.wikipedia.org/wiki/Phonetics\">Wikipedia</a>). I cannot emphasize enough how helpful studying phonetics is for language-learning. Here are the things that you should learn:<ul><li>A basic introduction to phonetics, from any source.</li><li>Your target language's phonetic inventory (a full list of sounds that the language's speakers use to communicate). This will help you differentiate written characters from correct pronunciation.&nbsp;<ul><li>Notice, for example, the difference in \"i\" sounds between \"l<strong>ea</strong>ve\" and \"l<strong>i</strong>ve.\" Native Spanish speakers will often pronounce both the same, since our phonetic inventory has only one \"i\" sound. Native German speakers will pronounce them correctly, because their phonetic inventory includes both sounds.</li></ul></li><li>How sound production works. The reason \"leave\" sounds different from \"live\" is that the tongue occupies slightly different positions for each. Learn about place of articulation (where the sound is produced), manner of articulation (how the sound is produced), and voicing (whether you vibrate your vocal cords or not).</li><li>See below a phonetic inventory of American English (which will make sense if you spend even a little bit of time studying phonetics):</li></ul></li></ul></li></ul><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/v1675631219/mirroredImages/k7igqbN52XtmJGBZ8/rdlnqzibgeoktstx6ydy.png\" alt=\"More IPA For American Consonants: Place, Manner, &amp; Voicing\"></figure><ul><li>&nbsp;<ul><li>My recommendation is at the very least watching the <a href=\"https://www.youtube.com/watch?v=eDop3FDoUzk&amp;list=PL8dPuuaLjXtP5mp25nStsuDzk2blncJDW\">Crash Course Linguistics</a> playlist on YouTube and paying special attention to videos #8 and #9 on phonetics. Then you can play around with the interactive <a href=\"https://www.ipachart.com/\">IPA chart</a> (International Phonetic Alphabet). If this seems valuable to you, I would &nbsp;recommend digging deeper independently.</li><li>Final point on linguistics: although I think this is important, please do not get stuck on only studying linguistics. This is meant as a tool to make your learning more efficient; it can't supplant your TL learning.</li></ul></li><li>Move on to (artificial) immersion.<ul><li>We all know that the best way to learn a language is to spend time in the country where the language is spoken... or is it? What are the unique benefits of it? Breathing French air won't help you speak French. It is the reading signs on the street and listening to random conversations in French, turning on the TV and it being in French, having to order in French at a coffee shop, having to text a local friend in French, etc. that will increase your language competency.</li><li>What I described above is called \"immersion.\" But most people can't just move to another country. The good news is, many of these things can be replicated while in your country of origin. This is called \"artificial immersion.\"<ul><li>Ideas: Make it a rule to only watch TL movies and TV shows (or dubbed versions). If it's too hard, start with TL audio and NL subtitles, then switch to TL audio and TL subtitles (but do make the switch as quickly as possible!). Read only books in your TL (there are <a href=\"https://storylearning.com/books\">beginner's books</a> with very simple language and built-in dictionaries). Only listen to music in your TL. Only listen to podcasts in your TL. Switch your phone and laptop's language to your TL. Of course, you'll only be able to do <i>some</i> of these, depending on your current ability to comprehend your TL.</li></ul></li><li><strong>The core insight is that people acquire languages mainly through consuming lots and lots of input</strong> (listening and reading). Speaking practice and studying grammar will certainly help, but I think people's bottleneck in 90% of the cases is a lack of TL input.</li><li>Immersion isn't meant to be comfortable. You'll inevitably experience the discomfort of understanding only X% of what is being said in you TL TV show or book. Don't be discouraged. Even if you don't really get the narrative or nuance, you are both picking up on new words, new syntax patterns, intonation patterns, mannerisms, etc. even if you don't realize it. The more input you consume, the more you will understand.</li><li>Go for L+1 input. This refers to \"level +1,\" or consuming input that is always one level above your comprehension level. This makes the input challenging but somewhat comprehensible. In my experience, you'd want to shoot for 60-90% comprehension, mostly 80%. When you're closer to 60%, you're listening for intonation patterns, the words that you do know and how they're used, trying to identify the individual words when someone is speaking, etc. When you're closer to 90%, you're listening for advanced words, nuances in meaning from conjugations and modal particles, unusual syntax, unknown verbs, etc. People's level of comfort in this regard varies, but the general idea is that discomfort is good \u2014 it means you're pushing yourself to learn.</li></ul></li><li>Ensure recall of the core vocabulary with spaced repetition (Anki!).<ul><li>This, along with practicing artificial immersion, is one of them most important parts of the method. People are often bottlenecked by having poor retrieval of core vocabulary. That is, it's not that they can't understand X conversation or can't speak fluently because of some fuzzy \"low language ability\" \u2014 it's often poor recall of the core vocabulary.</li><li>By \"core vocabulary\" I mean the most commonly used words in the language. The more extensively a word is used in natural speech, the more important it is that you know it so well you won't even hesitate when retrieving it.</li><li>And when I say \"recall\" I really mean <i>active recall</i> \u2014 being able to <i>retrieve</i> this word in conversation or when testing yourself, unaided\u2014 not just being able to recognize the word &nbsp;and think \"yeah I knew that word\" while staring at the translation.</li><li>Your approach to learning vocabulary should be to focus single-mindedly on learning the core vocabulary. Try learning the most frequently used 200 words, then the next 300, then the next 500, and so on. When it comes to vocabulary, the <a href=\"https://en.wikipedia.org/wiki/Pareto_principle\">Pareto principle</a> applies.</li><li>So how should you do it? The answer is <a href=\"https://apps.ankiweb.net/\">Anki</a>. Anki is a flashcard learning platform that allows you to create flashcard decks or download pre-made decks. Anki's strength comes from (1) its customizability, but most importantly (2) its built-in <a href=\"https://en.wikipedia.org/wiki/Spaced_repetition\">spaced repetition</a> algorithm. Spaced repetition, in this context, means re-learning flashcards at increasing time intervals. For example, you might be shown Flashcard X now, then in 10 minutes, then tomorrow, then in three days, then in a week, then in a month, and then in six months, and so on. If you guess the flashcard right every time, you'll keep making the intervals longer. If you fail a flashcard, you'll regress and have to repeat the flashcard again soon. This method quite literally forces you to have flawless recall of vocab. Try looking for pre-made Anki decks of core vocabulary in your TL online, or try making one yourself from a list of the most frequently used words.</li></ul></li><li>Study grammar.<ul><li>Another reason why people might not understand X Conversation or be able to speak fluently is that they haven't internalized basic grammar knowledge.</li><li>I think people usually focus too much on explicit grammar instruction, and that most grammar will be <i>acquired intuitively</i> by just consuming lots and lots of input. But input itself can be made more comprehensible by familiarizing yourself with basic grammar.</li><li>For this, chapters of textbooks might be the best option. Do some explicit grammar learning, and try to notice these patterns when reading natural language or listening to input.</li></ul></li><li>Learn from others.<ul><li>I learned many of these principles by tinkering on my own, but I owe most of it to learning from others like <a href=\"https://en.wikipedia.org/wiki/Stephen_Krashen\">Stephen Krashen</a>, <a href=\"https://en.wikipedia.org/wiki/Steve_Kaufmann\">Steve Kaufman</a>, and <a href=\"https://www.youtube.com/@mattvsjapan\">Matt vs Japan</a> (especially his website <a href=\"https://www.refold.la\">Refold.la</a>, which I highly encourage you to visit).</li></ul></li></ul><p>&nbsp;</p><ol class=\"footnote-section footnotes\" data-footnote-section=\"\" role=\"doc-endnotes\"><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"1\" data-footnote-id=\"5fu63d4imv\" role=\"doc-endnote\" id=\"fn5fu63d4imv\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"5fu63d4imv\"><sup><strong><a href=\"#fnref5fu63d4imv\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>The standard scale for European languages is the CEFR (Common European Framework of Reference). Language levels range from A1 (complete beginner) to C2 (better than the average native speaker). B2 is high-intermediate. For more information: <a href=\"https://www.languagetesting.com/cefr-scale.\">https://www.languagetesting.com/cefr-scale.</a>&nbsp;</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"2\" data-footnote-id=\"lqz58jdgniq\" role=\"doc-endnote\" id=\"fnlqz58jdgniq\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"lqz58jdgniq\"><sup><strong><a href=\"#fnreflqz58jdgniq\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>Just to establish some ethos: I set my high school's highest score on the standardized Cambridge English exam. I later received a diploma for having one of the highest regional scores. After taking two intro German courses in college I skipped a full year of German and took an advanced (C1) &nbsp;course. At least for German, this seems almost entirely like a product of using the right learning method (for which I advocate here), NOT inherent ability.</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"3\" data-footnote-id=\"u11kq30ouf\" role=\"doc-endnote\" id=\"fnu11kq30ouf\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"u11kq30ouf\"><sup><strong><a href=\"#fnrefu11kq30ouf\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>See the Defense Language Institute's widely used categorization for how much time it takes to learn a language to the same operational standard: <a href=\"https://www.ausa.org/articles/dlis-language-guidelines.\">https://www.ausa.org/articles/dlis-language-guidelines.</a> The exact amount of time will vary depending on your time commitment per week and desired proficiency, so focus on the relative differences in expected time commitment.</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"4\" data-footnote-id=\"05ys6ebtrg5f\" role=\"doc-endnote\" id=\"fn05ys6ebtrg5f\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"05ys6ebtrg5f\"><sup><strong><a href=\"#fnref05ys6ebtrg5f\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;</p></div></li></ol>", "user": {"username": "taoburga"}}]