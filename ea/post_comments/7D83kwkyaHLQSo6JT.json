[{"_id": "eXppjMA8qfQds28nP", "postedAt": "2023-12-24T01:59:51.831Z", "postId": "7D83kwkyaHLQSo6JT", "htmlBody": "<p>I really loved people's comments on why they voted the way they did, but this post is already quite long, so I'm sharing a longer list of excerpts as a sort of \"Appendix Comment.\"&nbsp;</p><h1>Why people voted the way they did (&amp; other highlights from the comments) - <strong>extended edition</strong></h1><blockquote><p><i>\u201cRealized I'm too partial to [global health] and biased against animal welfare, [so I committed to vote for the] most effective animal organization. Rethink's&nbsp;</i><a href=\"https://forum.effectivealtruism.org/posts/cMcEBSNiy4meDrmuE/rethink-priorities-needs-your-support-here-s-what-we-d-do\"><i><u>post</u></i></a><i> was very convincing.&nbsp;</i><a href=\"https://forum.effectivealtruism.org/posts/bBm64htDSKn3ZKiQ5/meet-the-candidates-in-the-forum-s-donation-election-2023#Charity_Entrepreneurship__Incubated_Charities_Fund\"><i><u>CE</u></i></a><i> has the most innovative ideas in GHD and it isn't close. GiveWell is GiveWell.\u201d&nbsp;</i></p><p><i>\u2014 Someone who voted for all 3 winning orgs (and GiveWell).</i></p></blockquote><p>We asked voters if they wanted to share a note about why they voted the way they did (or something else). 74 people (~20%) wrote a comment. Some excerpts are slightly tweaked for clarity/length and/or to avoid highly recognizable styles (please reach out if you\u2019re worried and would like me to remove your comment).</p><p><strong>See the </strong><a href=\"https://forum.effectivealtruism.org/posts/7D83kwkyaHLQSo6JT/winners-in-the-forum-s-donation-election-2023#Highlights_from_the_comments__why_people_voted_the_way_they_did\"><strong>shortened version in the post above</strong></a><strong> \u2014 this is the extended version.</strong> There's a bit of repetition, but I think most of it is new.</p><p><strong>Rethink Priorities</strong>\u2019s&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/cMcEBSNiy4meDrmuE/rethink-priorities-needs-your-support-here-s-what-we-d-do\"><u>funding request post</u></a> was mentioned a lot to explain why someone is donating to or voting for RP. People also noted specific aspects of RP\u2019s work or approach that they appreciate:&nbsp;</p><ul><li>\u201cI found the request for funding from Rethink priorities quite compelling, I value their work, in particular the annual survey they run.\u201d</li><li>\u201cI think Rethink Priorities create many public benefits.\u201d (And someone else: \u201c... [RP] are quite productive with the resources they have, and provide a good service to the EA community in terms of generalist-style research on cause areas.\u201d)</li><li>\u201cReading about [RP\u2019s] plans to do more moral weights and animal welfare work in the coming year and how this depended on marginal funding.\u201d</li><li>\u201cFish Welfare &amp; Rethink because I think they work on the relatively most neglected current problems, where marginal contributions seriously matter. Global health out of personal interest (but I gave them a much weaker weight).\u201d&nbsp;</li><li>\u201cI prioritized animal welfare charities, especially ones that focus on neglected groups of animals like Rethink Priorities and Wild Animal Initiative.\u201d&nbsp;</li><li>\u201cI think of [my top choices] as driving growth in either knowledge or funding, mostly for [global health and development] or EA as a whole.\u201d (From someone who gave points to many projects, with the most going to RP, CE, and GWWC)</li><li>Someone mentioned&nbsp;<a href=\"https://manifold.markets/AaronBergman18/what-donationaccepting-entity-eg-ch\"><u>this market</u></a><u>.</u></li><li>\u201cALLFED and Rethink Priorities both consist of highly talented and motivated individuals that are working on high-potential, high-impact projects. Both organizations have left a strong impression on me in terms of their approach to reasoning and problem solving. [...] Both organizations have recently posted extremely well-detailed [updates on their financial situation and how additional funding would help]. [...]\u201d</li></ul><p><strong>CE\u2019s Incubated Charities Fund</strong> (and Charity Entrepreneurship more broadly) got a lot of appreciation for their good and/or unusual ideas and track record:&nbsp;</p><ul><li>\u201cOutstanding teams and track record\u201d (from someone who gave most of their points to CE\u2019s Fund and some to RP)</li><li>\u201c...direct-action global health charities need more funding now, especially in light of reductions in future funding from Open Phil. [And] there's enough potential upside to charity incubation to put a good bit of money there.\u201d</li><li>\"[AWF], because I was convinced by the post about how animal welfare dominates in non-longtermist causes, [CE], so that there can be even more excellent ways of making the world a better place by donating, [GWWC], because I wish we had unlimited money to give to all the others\"</li><li>\u201cThe Forum's Giving Season inspired me to choose some additional places to donate in addition to my usual GiveWell donation.\u201d (RP, CE)</li><li>\u201c[CE and THL] are actually doing something rather than \"analysis\", and have great track records.\u201d</li><li>Someone who gave points to CE\u2019s Fund, EAIF, GWWC, and others wrote that they wanted to \u201csupport funds or [organizations] that have exponential impact through their work\u201d</li><li>\"I lean longtermist but feel like [some orgs\u2019] salaries are too high and more frugal [orgs] like Charity Entrepreneurship are more cost-effective.\u201d</li></ul><p>A number of people wrote that they\u2019d updated towards donating to&nbsp;<strong>animal welfare</strong> as a result of recent discussions (<a href=\"https://forum.effectivealtruism.org/posts/btTeBHKGkmRyD5sFK/open-phil-should-allocate-most-neartermist-funding-to-animal\"><u>often explicitly because of this post</u></a>). Many gave a lot of their points to the&nbsp;<strong>Animal Welfare Fund</strong>, sometimes explicitly citing&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/PTHskHoNpcRDZtJoh/gwwc-s-evaluations-of-evaluators\"><u>GWWC\u2019s evaluations of the evaluators</u></a>. Some also said they wanted to vote for animal welfare to correct for its relative neglectedness in EA or to emphasize that it has a central place in EA:</p><ul><li>\u201cI voted for animal charities to [...] direct the money to where it can do a lot of good, but also to demonstrate to the EA community that *animal welfare belongs as a central EA cause area.* As an EA working on AI risk, I feel very deeply that this community should continue to stand up for sentient beings who are experiencing unimaginable suffering now. [...] Why these particular animal welfare donations [ACE, THL, AWF]? I want to strengthen central institutions in animal welfare so that they can in turn use their best judgment to distribute funds among tried-and-tested and speculative giving opportunities.\"</li><li>\u201cI think the median EA underweights animal stuff, so I\u2019m throwing all my points towards ACE Movement Grants.\u201d</li><li>\u201c[Gave a lot more points to animal welfare than human health and development] because [the latter is] much less cost-effective than animal welfare: [<a href=\"https://forum.effectivealtruism.org/posts/btTeBHKGkmRyD5sFK/open-phil-should-allocate-most-neartermist-funding-to-animal\"><u>link to this post</u></a>]. Gave [fewer points to longtermist candidates] since factory farming could continue if we prevent a catastrophe...\u201d</li><li>\u201c...my vote was mostly [based on] thinking a lot of people would put money on longtermist options. My vote goes to keeping a lot of money on the more consensual areas of the movement (poverty &amp; animal rights; it's true they get a lot of money during this time, but most of it, we know, is not effectively given).\u201d</li><li>\u201cI weakly believe helping non-human animals is probably more cost-effective than helping humans, and GCR-reduction projects seem [uncertain, hard to evaluate, and not capital-constrained right now]. [GWWC] tentatively evaluates the EA Animal Welfare fund as probably more cost-effective than ACE, which is consistent with conversations I had\u2026\u201d (<a href=\"https://forum.effectivealtruism.org/posts/PTHskHoNpcRDZtJoh/gwwc-s-evaluations-of-evaluators\"><u>the reference</u></a>)</li><li>\u201c...I have struggled for years to come up with a ratio I can defend [of human vs. animal donations]. So I just use a [heuristic] and always donate 80% to the charity I think is \u2018current best human/animal charity.\u2019 This is why the EA Animal Welfare Fund is currently at 80%\u2026 I used to [allocate 80%] to&nbsp;<a href=\"https://www.givewell.org/charities/sci-foundation/November-2021-version\"><u>SCI</u></a> but posts on the Forum have convinced me animal welfare as a field is more funding constrained right now, [so] my marginal dollar means more [and SCI wasn\u2019t on the list]. I am a fan of hits-based giving\u2026 AWF [might not pan out], but might also uncover extraordinary potential. I am quite bullish on funding animal welfare efforts in geographically neglected areas or on neglected groups of animals, but I think this is best done the same way VC Investing works: fund a lot of opportunities \u2014 even some speculative ones \u2014 and then a few gems [will make up for] losses. In a way you could see this 80% as analogous to \u2018medium-high risk equity ETF\u2019 in my giving portfolio.\u201d</li><li>\u201cSome recent conversations and readings have swayed me in the direction of large-scale suffering reduction for animals being neglected.\u201d</li></ul><p>And here are some comments about&nbsp;<strong>why people gave points or donated to&nbsp;</strong><i><strong>other</strong></i><strong> candidates</strong>, or other considerations people shared:</p><ul><li>\u201cI feel like big charities get a lot of attention and smaller charities don't always get enough. But they still do important work.\u201d (Someone who gave points to AWF, but also FWI, WAI, ACE Movement Grants, and Faunalytics.)</li><li>\u201cI prefer helping other humans rise over poverty, disease and suffering... once we can help a majority of people come out of poverty and live without [danger], we should collectively focus on other animals.\u201d (AMF, GD, and others.)</li><li>\u201cAI x-risk seems clearly the most important and highest expected value. Wild Animal Initiative is a huge neglected need and maybe investing a bit more in it might have a positive impact on AI x-risk too.\u201d (LTFF, WAI, and others)</li><li>\u201cI allocated [my points] in adjustment from an estimate of EA dollars by cause area. I made it 4:1 for animal welfare to global health because of a post I read, and made MIRI and ALLFED about 80% of longtermist funding (40% each) when I read that ALLFED could be more effective than AI safety. Since many people in the EA community have confidence in AI safety being the most important cause, I wasn't ready to put ALLFED quite over the mark until more research is done. I put The Humane League as 80% of animal welfare funding, because of the 10 million dollar funding gap. When I didn't have time to research, I just distributed funds evenly within a cause area.\u201d I think they\u2019re referencing&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/btTeBHKGkmRyD5sFK/open-phil-should-allocate-most-neartermist-funding-to-animal\"><u>this post on animal welfare</u></a> and possibly&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/xmmqDdGqNZq5RELer/shallow-evaluations-of-longtermist-organizations#Execution_details_about_ALLFED_in_particular\"><u>this post re: ALLFED</u></a> (or posts linked in it).&nbsp;</li><li>\u201cI don't normally donate anything to \u2018meta\u2019 work like research or fundraising, but thinking about a larger pot of money, I wanted to give some to the best of those [areas]\u201d (GW, RP, some others)</li><li>\u201cI prioritize longtermism, and I think that we might be able to influence how AI treats wild animals (e.g. in simulations). I generally have picked organizations that have a lot of room for more funding...\u201d (ALLFED, RP, WAI)</li><li>\u201c...saving lives does not seem as urgent to me as mitigating suffering. GiveDirectly has for years to me seemed like a better [bet] with regard to a mitigating long-term suffering perspective. GiveDirectly is [the] rock-solid input-output play [\u2026] in my portfolio.\u201d</li><li>\u201c[ALLFED] seems like the only x-risk-focused charity where marginal dollars from individual donors matter a lot. [Others seem much more] talent-constrained. \u2026 [And they\u2019re working on a relatively neglected set of problems in x-risk.]\u201d</li><li>Someone who gave most of their points to MIRI said they \u201cexpect Yudkowsky &amp; Soares will select the best grantmakers [...] to spend their money\u2026\u201d Another MIRI voter (who also gave points to EAIF and LTFF) said they wished some projects were candidates that aren\u2019t, and that they hoped MIRI would donate to those projects and other theoretical researchers, as they prioritize fundamental AI alignment work.</li><li>\u201cI am pretty longtermist so I favored those organizations, but I also wanted to put some options on the board from a wide variety of cause areas due to the nature of the ranked choice voting \u2014 i.e., in case longtermist charities all lost out and the winners were dominated by animal welfare, I at least wanted to express an opinion on which animal-welfare charities seem best to me.\u201d</li><li>\u201cI included GWWC after I noticed the community is not paying enough attention to Earning to Give and the growth of GWWC pledges have stagnated over the last few years.\u201d</li></ul><p><strong>Broader patterns:&nbsp;</strong></p><ul><li>A number of people said they work in one field (often existential risk reduction) but want to donate or direct at least some funding to a different field (often global health, animal welfare, or cross-cause charities), either because they believe those causes need&nbsp;<i>funding</i> more (while others might need&nbsp;<i>labor</i> more) or because they wanted to split their/EA resources across causes. Some also explicitly wanted to split their vote across causes. E.g.:<ul><li>\u201cAs an EA working on AI risk, I feel very deeply that this community should continue to stand up for sentient beings who are experiencing unimaginable suffering now.\u201d</li><li>\u201c\u2026and THL and GFI as I think they represent good orgs working on short-term causes. \u2026 I prioritise short-term causes slightly less than catastrophic risks at present, but think it is important for a portfolio approach to funding.\u201d (Someone who also said they work for a specific risk-oriented org.)&nbsp;</li><li>\u201c\u200b\u200bGood split between long-term decisive impact and near-term efficient impact.\u201d</li><li>\u201cI wanted a split between the major 3 pillars (Animal Welfare, GH&amp;D, Longtermism/GCR) of EA. I'm generally more support of 'big tent'/cause area buckets for donations rather than EV maxxing\u201d</li></ul></li><li>Some referenced specific posts or recent changes, while others said they went with cached thoughts:&nbsp;<ul><li>\u201cBasically a nebulous combination of my assessment of each project (mostly formed before the election), as well as the fact that each has (in the lead-up to the election) vocally reported being funding-constrained.\u201d</li><li>\u201cI (somewhat) know all the organizations and went with my cached judgments of the cost-effectiveness of marginal donations to them.\u201d</li></ul></li></ul><p><strong>People also shared thoughts related to Giving Season:&nbsp;</strong></p><ul><li>\u201c...Would have LOVED more debates/ posts about \u2018LTFF vs ALLFED?\u2019 and \u2018EA Funds Animal Welfare Fund vs. The Humane League?\u2019\u201d (This person also cited two posts.)</li><li>\u201cThe whole giving season event is the reason I finished a [related text] that had been sitting in my drafts for a couple months. \u2026 I also found the marginal funding posts super interesting.&nbsp; It made me more excited about earning to give and helped me understand the perspective of nonprofits engaged in fundraising, particularly the posts from RP (Peter Wildeford and Abraham Rowe).&nbsp; Because it sounds like they would use funds for things that I consider promising, like moral weight research and cross-cause cost-effectiveness modeling, I allocated more votes toward them.\"</li><li>\u201cNot sure how much that is because of the Donation Election or just the Forum in general, but it led quite naturally to me reading most of the related posts on the Forum. Due to this I'm now donating to Rethink Priorities this year &amp; I was able to recommend impactful climate charities to non-EA friends who wanted to donate in that area.\u201d</li><li>\u201cLoved this! Really pushed me to think about donation priorities through a compare/contrast and consideration of the marginal dollar way which I've always meant to work on more, but haven't done so enough. I have a few ingrained priors I have formed overtime which initially formed my idea of what would be relatively highest and what wouldn't be considered. I think that the major updates to my priors were from info on the EA Forum, especially recent grant info. For instance, Rethink Priorities got a big boon from this, while EA Infrastructure Funds got a downgrade (the name mislead me at first). As a side note, it would be cool if someone developed software for a version of this for private donations! (maybe this already exists?) Especially if it is as simple and easy to operate as this; excel sheets work (and are needed for more complicated analyses), but take effort to read.&nbsp; Only additional functions needed would be an ability to add more funds/charities and a way for it to be easily cross-posted to social media for further conversation.\u201d</li></ul><p>Finally, shoutout to the voter who added: \u201cThank you for listening to my TED talk. I am legally obligated to tell you this is not financia-, err, altruism advice\u201d after their (decently long) comment.&nbsp;</p>", "parentCommentId": null, "user": {"username": "Lizka"}}, {"_id": "33fDmo4z9E7hxKFjF", "postedAt": "2023-12-24T08:24:50.058Z", "postId": "7D83kwkyaHLQSo6JT", "htmlBody": "<p>Thanks for sharing the results, and the detailed analysis, Lizka!</p><p>I would be curious to know:</p><ul><li>How the results would look like if votes were weighted by karma (or the logarithm of karma).</li><li>More about who voted. For example, the distributions of karma and years since joining the EA Forum.</li></ul><blockquote><p><strong>TL;DR: </strong>We ran a&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/hAzhyikPnLnMXweXG/participate-in-the-donation-election-and-the-first-weekly#Participate_in_the_Donation_Election\"><u>Donation Election</u></a> in which 341 Forum users<a href=\"https://forum.effectivealtruism.org/posts/7D83kwkyaHLQSo6JT/winners-in-the-forum-s-donation-election-2023#fn6w7y3qtru6v\"><sup>[1]</sup></a>&nbsp;voted on how we should allocate the Donation Election Fund ($34,856<a href=\"https://forum.effectivealtruism.org/posts/7D83kwkyaHLQSo6JT/winners-in-the-forum-s-donation-election-2023#fn5i6rlzul5i\"><sup>[2]</sup></a>).</p></blockquote><p>So there were as many voters as 8 % (= 341/<a href=\"https://data.centreforeffectivealtruism.org/\">4443</a>) of the monthly active EA Forum users in November. One could have voted quite quickly, so I wonder whether you have any thoughts on why participation was not higher.</p>", "parentCommentId": null, "user": {"username": "vascoamaralgrilo"}}, {"_id": "Z4E8kkkAWPmdBTzi8", "postedAt": "2023-12-24T16:32:36.031Z", "postId": "7D83kwkyaHLQSo6JT", "htmlBody": "<p>Probably no way to answer this with available data, but I'm curious about the extent to which individual revealed preferences (election votes edition) are concordant or discordant with their revealed preferences (personal donations edition). To the extent they are discordant, what factors might explain the discordance, and what might we learn from having two different types of revealed preferences to pull from? This loops back into some of the discussions earlier in the year about whether there should be more of a community voice in funding allocation and if so how that could be carried out in a way that is less open to manipulation.</p><p>For instance, I think this system makes it frictionless for me to specify smaller preferences (and even mildly encouraged doing so). That strikes me as an advantage it has over GWWC pledge fulfillment information, where even if I take the time to give to the organization that is tenth on my list, I might not take the time to enter that donation into the GWWC database. In contrast, I think the structure of the Donation Election mildly encouraged me to give points to organizations I thought would generate lots of other votes as well.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefcw34qte01c5\"><sup><a href=\"#fncw34qte01c5\">[1]</a></sup></span></p><p>(My own votes didn't track my donations that closely, but that may be due to unusual personal circumstances this year for me).</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fncw34qte01c5\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefcw34qte01c5\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Only mildly so -- e.g., a voter would be disenfranchised in all rounds after all organizations to which they assigned votes were eliminated. They would be treated as indifferent among all remaining choices. Thus, a rational voter who was not indifferent would distribute points such that they threw at least one point to an organization they expected to be in the top four. Given that most voters gave points to 2-4 organizations, this probably creates a small bias toward organizations perceived as more popular.</p></div></li></ol>", "parentCommentId": null, "user": {"username": "Jason"}}, {"_id": "der6XznQyAJsphfNY", "postedAt": "2023-12-24T20:39:29.598Z", "postId": "7D83kwkyaHLQSo6JT", "htmlBody": "<p>One can discern from the spreadsheet where the points of each eliminated organization went, at least initially:</p><ul><li>It does not appear that any organization's elimination \"sent\" points predominately to orgs in the same cause area.</li><li>GWWC's elimination predominately sent points to organizations I would classify as neartermist.</li><li>EAIF's elimination sent over twice as many points to LTFF as to the next highest benefactor (RP).&nbsp;</li><li>LTFF's elimination sent almost as many points to RP as the other two winners.</li></ul><p>None of this was too unexpected to me, but it is mildly interesting to get harder data on the relationship between cause area support and support for specific cross-cause / meta organizations. Specifically, we can see which cross-cause organizations voters tended to gravitate toward when an object-level charity in a given cause was eliminated.&nbsp;</p><p>(I only marked third-place gains that subjectively seemed to clearly exceed the rest of the field.)</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/der6XznQyAJsphfNY/cwkir4c81weunl3vejjp\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/der6XznQyAJsphfNY/xtsumdq1ehwbwqjofqpq 190w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/der6XznQyAJsphfNY/ridhgnmnrd2jclg3ryuq 380w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/der6XznQyAJsphfNY/aoxp7zcjol0l4en1n2tr 570w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/der6XznQyAJsphfNY/ri4eiba5zizugdiaaz0g 760w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/der6XznQyAJsphfNY/ur6mp9bpeqzlr3a51kcb 950w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/der6XznQyAJsphfNY/zm0asu9c7jryezofavrw 1140w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/der6XznQyAJsphfNY/kullzzk7diluhmiuvpw6 1330w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/der6XznQyAJsphfNY/ptqm0ijmkg3sqvshmpgs 1520w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/der6XznQyAJsphfNY/uf33y1xq067ifexpwa9p 1710w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/der6XznQyAJsphfNY/qz9d1nfivxfjzbctjhid 1827w\"></figure>", "parentCommentId": null, "user": {"username": "Jason"}}, {"_id": "D8zPiN5HK5yEHdDGn", "postedAt": "2023-12-25T02:49:53.957Z", "postId": "7D83kwkyaHLQSo6JT", "htmlBody": "<p>I recall there was some discussion about different voting systems for the Donation Election. I think it would be interesting to see whether/how different the results would have been with a different system. We can't really retrofit the data to quadratic voting, but I think it would be possible for approval voting and rank-choice voting (for approval voting we could just say that any candidate receiving points from a person is approved, unless they voted for many candidates in which case just the top 12). I am not sure what codebase you have at the backend for this, but I could imagine switching the voting system could be fairly easy; maybe it isn't worth it though.</p>", "parentCommentId": null, "user": {"username": "Oscar Delaney"}}, {"_id": "MQr3C8hAhP3y68d4Z", "postedAt": "2023-12-26T00:52:03.750Z", "postId": "7D83kwkyaHLQSo6JT", "htmlBody": "<p>I want to be really careful about not de-anonymizing voters (even internally), but I'll see what we can check safely.&nbsp;</p><p>Re: the number of voters: I'm not sure. I wish more people had voted, but it's generally quite hard to get people to do things (see e.g. the <a href=\"https://en.wikipedia.org/wiki/1%25_rule\">1% rule</a> and its variants), and this is not outside of my expectations.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref81jk6f57squ\"><sup><a href=\"#fn81jk6f57squ\">[1]</a></sup></span>&nbsp;We probably could have done more to advertise the election; I'd include that in lessons for next time (although I also think that, if the Forum runs another election in a year, there'll be more natural interest as this will be a more established \"thing\").&nbsp;</p><p>Some reasons I expect people didn't vote: people thought they were ~unqualified (I heard this worry and <a href=\"https://forum.effectivealtruism.org/posts/dLsay2t8Pf88Cmi4E/vote-in-the-donation-election-by-15-december\">tried to push back on it here</a>, but could probably do better in the future), they just weren't interested (e.g. because they didn't think this is relevant, or their favorite projects weren't candidates) or didn't have time, they just didn't hear about the election, or they meant to do it and never got around to it.&nbsp;</p><p>I should also flag that a lot of monthly active Forum users are ~weekly users, I think, and I expect that those are significantly less likely to vote. You can see this chart from the Forum survey we ran a while back (I'm hoping to share a writeup on it soon), which sort of illustrates this (it's a bit iffy because (1) the Forum survey will overrepresent more frequent users \u2014 although that arguably boosts my point, and (2) this question had an issue where people who use the Forum ~3 times a month don't really have an obvious answer to give, but oh well):&nbsp;</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/MQr3C8hAhP3y68d4Z/tj6h4ilmy3y7iklmijbo\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/MQr3C8hAhP3y68d4Z/tmaeb6myczw7jijw3icp 120w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/MQr3C8hAhP3y68d4Z/bd9bkrxgbpjme551moa4 240w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/MQr3C8hAhP3y68d4Z/aduxedpvfiom8eujverr 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/MQr3C8hAhP3y68d4Z/ajty0zga9rckxbkvln6c 480w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/MQr3C8hAhP3y68d4Z/t67okzrmyvllal7gb4mw 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/MQr3C8hAhP3y68d4Z/wvlwdsssqslu1nbt14z6 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/MQr3C8hAhP3y68d4Z/g7poepsb7lyns92iqw7v 840w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/MQr3C8hAhP3y68d4Z/ati4si2iyiglfle25iiu 960w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/MQr3C8hAhP3y68d4Z/wqopsd0usagrnwcx36sa 1080w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/MQr3C8hAhP3y68d4Z/girku5hyfokhz2i19l59 1200w\"></figure><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn81jk6f57squ\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref81jk6f57squ\">^</a></strong></sup></span><div class=\"footnote-content\"><p>We (Online Team) had some very casual internal forecasts on how many voters we'd get. I had initially (late November) put 50% for getting to 400 voters (most other people on the team were lower), then went higher as we got closer to that goal, and lower again later when voting slowed down. (We also had forecasts for 200 and 100; I had started with 80% and 90% there.)</p></div></li></ol>", "parentCommentId": "33fDmo4z9E7hxKFjF", "user": {"username": "Lizka"}}, {"_id": "N9wdKuuiw6kAkEdHE", "postedAt": "2023-12-26T01:08:57.003Z", "postId": "7D83kwkyaHLQSo6JT", "htmlBody": "<p>Thanks for bringing this up! I actually explored this a bit, but hid it in a footnote:&nbsp;</p><blockquote><p>Interestingly, I think approval voting would have yielded similar winners (with a big assumption about how to extrapolate what people would have \u201capproved\u201d of) \u2014 if you rank projects by the number of voters who gave it at least 10%, for instance, the picture doesn\u2019t change much (if you increase from 10% to 20%, LTFF starts showing up in the top 3 again).&nbsp;</p><p>What would have happened with ranked-choice voting is [more] unclear to me; the voting system was in fact very different, and my quick attempts at trying to see what would happen if I tried to interpret the scores as ranks were extremely contingent on minor tweaks in how I interpret things and on decisions like whether I used \u201crankings\u201d of all the candidates or only the top 10, etc. If I only rank points given when they amount to over 5% of a voter\u2019s total points and add some randomness to produce rankings out of equal scores, the results look&nbsp;<i>fairly</i> similar, but I didn\u2019t do things carefully.&nbsp;</p></blockquote><p>I was initially lazier with ranked-choice voting, but now finished a rough ~run of the elimination process and got very similar results as what we got with our voting system. Note that I chose the 5% cutoff as the thing that seemed most reasonable given how people voted before I saw the results with this translation into RCV, but things might in fact still change quite a bit if you choose a different translation into RCV (e.g. only the top 5 projects people gave points to, instead of the projects people gave at least 5% of their points to). The ranking I got was:</p><ol><li>RP</li><li>CE's Fund</li><li>AWF (very close call; I had added some randomness to get orderings and on some reloads it was beating CE, but that seemed rarer than CE beating AWF)</li><li>LTFF</li><li>GW</li><li>GD</li><li>AMF</li><li>THL</li><li>GFI</li><li>ALLFED</li><li>Etc.</li></ol><p>(Please don't trust these results too much, though; I was not careful here.)</p><p>Re <a href=\"https://forum.effectivealtruism.org/posts/dLsay2t8Pf88Cmi4E/vote-in-the-donation-election-by-15-december#Some_other_common_questions\">quadratic voting, see also here</a>.&nbsp;</p>", "parentCommentId": "D8zPiN5HK5yEHdDGn", "user": {"username": "Lizka"}}, {"_id": "FwtrPtMAFs2EHvEsF", "postedAt": "2023-12-26T01:21:14.214Z", "postId": "7D83kwkyaHLQSo6JT", "htmlBody": "<p>I agree that this is hard with available data. I guess we could try to look at donation data e.g. from <a href=\"https://forum.effectivealtruism.org/posts/nb6tQ5MRRpXydJQFq/ea-survey-2020-series-donation-data#Which_charities__causes_and_categories__are_EAs_donating_to_\">here</a> or <a href=\"https://forum.effectivealtruism.org/posts/rszgfHdkmzCDDPM9k/where-are-you-donating-this-year-and-why-open-thread-1\">responses to this post</a> and see how well it matches what people collectively voted for (ideally weighted by ~Forum engagement), but both groups are probably pretty different from the voting group (and the second group is small). A lot of comments on why people voted the way they did also noted something about why they're <i>donating</i> to the candidates they voted for (but definitely not all comments).&nbsp;</p><p>Also:&nbsp;</p><ul><li>A lot of people probably donated to charities or projects that weren't candidates (including me, although I did also donate to something I think I gave some points to)</li><li>There are ~strategic reasons for voting for charities you aren't donating to (e.g. it's <a href=\"https://forum.effectivealtruism.org/posts/x2iT45T5ci3ea9yKW/dialogue-on-donation-splitting\">not clear (to me) if you should split donations or how much</a>, but if you've thought a fair bit about different candidates, you probably want to give points to multiple candidates)</li></ul>", "parentCommentId": "Z4E8kkkAWPmdBTzi8", "user": {"username": "Lizka"}}, {"_id": "5Eph9nL3f6yzeEiCJ", "postedAt": "2023-12-26T03:07:16.134Z", "postId": "7D83kwkyaHLQSo6JT", "htmlBody": "<p>Whoops my mistake. OK thanks, interesting! Maybe next year we can have an informal meta-vote beforehand on which voting system we want to use ;) I think currently I am in favour of RCV but maybe I am biased by being Australian and the fact that we use that here, so it seems especially intuitive and nice to me.</p>\n", "parentCommentId": "N9wdKuuiw6kAkEdHE", "user": {"username": "Oscar Delaney"}}, {"_id": "nqAeHoj9Q4Y9RZwaw", "postedAt": "2023-12-26T23:17:21.759Z", "postId": "7D83kwkyaHLQSo6JT", "htmlBody": "<p>Someone else I talked to is also in favor of RCV, and I agree that it has benefits (e.g. easier to use than this system), but I also think it has some downsides \u2014 e.g. I <i>think</i> it's a worse exercise for voters than this system is. Btw, you might also be interested in <a href=\"https://forum.effectivealtruism.org/posts/iJSYZJJrLMigJsBeK/lizka-s-shortform?commentId=nmfz9ySdD5WBAgqPE\">the discussion that happened on my quick take before we decided on a voting system</a>.&nbsp;</p><p>(My current top, low-resilience guess about changes we should make to the voting system, if we ran this again, is that we should remove the 3-winner restriction and that we should think about trying to get people to vote on cause/problem areas \u2014 separate from voting on charities.)</p>", "parentCommentId": "5Eph9nL3f6yzeEiCJ", "user": {"username": "Lizka"}}, {"_id": "aFXLErjA9jppvziSC", "postedAt": "2023-12-26T23:28:12.451Z", "postId": "7D83kwkyaHLQSo6JT", "htmlBody": "<p>Nice, wow there was lots of engagement on this beforehand! I think I am now leaning towards abrahamrowe's suggestion to just take the average of everyone's distributions, possibly with some minimum threshold to avoid the hassle of disbursing small amounts of money. But so many considerations - a more complicated decision than initially meets the eye I think.</p>\n", "parentCommentId": "nqAeHoj9Q4Y9RZwaw", "user": {"username": "Oscar Delaney"}}, {"_id": "82ShpxasvLqNss3gF", "postedAt": "2023-12-27T04:46:06.173Z", "postId": "7D83kwkyaHLQSo6JT", "htmlBody": "<p>I object to your translation of actual-votes into approval-votes and RCV-votes, at least in the case of my vote. I gave almost all of my points to my top pick, almost all of the rest to my second pick, almost all of the rest to my third pick, and so forth until I was sure I had chosen something that would make top 3. But e.g. I would have approved of multiple. (Sidenote: I claim my strategy is optimal under very reasonable assumptions/approximations. You shouldn't distribute points like you're trying to build a diverse portfolio.)</p>", "parentCommentId": "N9wdKuuiw6kAkEdHE", "user": {"username": "zsp"}}, {"_id": "TWxgYsEKzxEwAuLDu", "postedAt": "2023-12-27T08:31:03.913Z", "postId": "7D83kwkyaHLQSo6JT", "htmlBody": "<p>Thanks! I agree that the approach you describe is optimal under very reasonable assumptions, but I think in practice few people used it (the median ratio between someone's top choice and their second choice was 2, the mean if you throw out one outlier was ~20; only 7 people voted for at least 2 candidates and had ratios between their top two that were at least 20). Moreover, we had some<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefx30aaafexs\"><sup><a href=\"#fnx30aaafexs\">[1]</a></sup></span>&nbsp;voters who didn't vote the way you describe, but who did assign a fairly big number of projects similar small point values \u2014 I think kind of throwing in some points for charities they don't favor that much, and I didn't want to overweight their votes in the way I tallied the RCV-translated (or approval-translated) scores.&nbsp;</p><p>Still, I agree that my translations are bad \u2014 I should at least represent scores from people who basically approximated RCV in the current voting method the way they would be counted in RCV. I might try this (and think about what translation actually makes sense \u2014 just the top 10 charities people voted for?) later, but might not prioritize doing it.&nbsp;</p><p>For approval voting, you could also just look at the number of voters who gave a charity <i>any</i> (positive) number of points; these counts are included in this post and wouldn't have changed the top 3.&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnx30aaafexs\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefx30aaafexs\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Quickly estimating: there were 90 voters who voted for at least 4 candidates whose last two votes differed by a ratio of less than 1.5. There were 27 if instead of requiring at least 4 candidates, you require that the smallest point assignment is &lt;5.&nbsp;</p><p>Or looking at it another way: across all ratios (across all voters) between what a given voter gave the candidate they ranked N and the candidate they ranked N+1, if we remove only the top 1 percentile of ratios (removing because a few people did use an approximation of RCV - equivalent in this case to removing ratios higher than 100:1), the mean is 2. Across all ~12K ratios, about 500 are exactly 1.&nbsp;</p></div></li></ol>", "parentCommentId": "82ShpxasvLqNss3gF", "user": {"username": "Lizka"}}, {"_id": "GpB6ZCHjBt59kSYr5", "postedAt": "2023-12-30T16:19:36.032Z", "postId": "7D83kwkyaHLQSo6JT", "htmlBody": "<p>There are many different voting methods that use ranked ballots, and it's frustrating that one of the worst gets all the attention, and is considered synonymous with the term \"ranked choice voting\".</p>\n<p>Do the ranked ballots produce a Condorcet winner? A strict Condorcet ranking of the rest?</p>\n", "parentCommentId": "N9wdKuuiw6kAkEdHE", "user": {"username": "Jonathan Bright"}}]