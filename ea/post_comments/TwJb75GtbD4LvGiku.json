[{"_id": "JvE7t7rPDeExATqe4", "postedAt": "2018-05-22T17:23:09.897Z", "postId": "TwJb75GtbD4LvGiku", "htmlBody": "<p>What do you think are the implications of moral anti-realism for choosing altruistic activities? </p>\n<p>Why should we care whether or not moral realism is true?</p>\n<p>(I would understand if you were to say this line of questions is more relevant to a later post in your series.)</p>\n", "parentCommentId": null, "user": {"username": "jayquigley"}}, {"_id": "DXAJW4CmQr6cy3ZHv", "postedAt": "2018-05-22T17:23:21.212Z", "postId": "TwJb75GtbD4LvGiku", "htmlBody": "<p>One thought is that if morality is not real, then we would not have reasons to do altruistic things. However, I often encounter anti-realists making arguments about which causes we should prioritize, and why. A worry about that is that if morality boils down to mere preference, then it is unclear why a different person should agree with the anti-realist's preference.</p>\n", "parentCommentId": "JvE7t7rPDeExATqe4", "user": {"username": "jayquigley"}}, {"_id": "gNLuXMLBdhiYAKwi8", "postedAt": "2018-05-22T17:35:16.160Z", "postId": "TwJb75GtbD4LvGiku", "htmlBody": "<p>So you know who's asking, I happen to consider myself a realist, but closest to the <em>intersubjectivism</em> you've delineated above. The idea is that morality is the set of rules that impartial, rational people would advocate as a public system. Rationality is understood, roughly speaking, as the set of things that virtually all rational agents would be averse to. This ends up being a list of basic harms--things like pain, death, disability, injury, loss of freedom, loss of pleasure. There's not much more objective or &quot;facty&quot; about rationality than the fact that basically all vertebrates are disposed to be averse to those things, and it's rather puzzling for someone not to be. People can be <em>incorrect</em> about whether a thing is harmful, just as they can be incorrect about whether a flower is red. But there's nothing much more objective or &quot;facty&quot; about whether the plant is red than that ordinary human language users on earth are disposed to see and label it as red.</p>\n<p>I don't know whether or not you'd label that as objectivism about color or about rationality/harm. But I'd classify it as a weak form of realism and objectivism because people can be <em>incorrect</em>, and those who are not reliably disposed to identify cases correctly would be considered <em>blind</em> to color or to harm. </p>\n<p>These things I'm saying are influenced by Joshua Gert, who holds very similar views. You may enjoy his work, including his <em>Normative Bedrock</em> (2012) or <em>Brute Rationality</em> (2004). He is in turn influenced by his late father Bernard Gert, whose normative ethical theory Josh's metaethics work complements.</p>\n", "parentCommentId": "DXAJW4CmQr6cy3ZHv", "user": {"username": "jayquigley"}}, {"_id": "NREJ9r2WvLxpZj43H", "postedAt": "2018-05-22T22:10:31.972Z", "postId": "TwJb75GtbD4LvGiku", "htmlBody": "<p>Cool! I think this is helpful both in itself as well as here as a complement to my post. I also thought about making a chart but was too lazy in the end. If I may, I'll add some comments about how this chart relates to the distinctions I made/kept/found: </p>\n<p>&quot;Judgment-dependent cognitivism&quot; corresponds to what I labelled subjectivism and intersubjectivism, and &quot;judgment-_in_dependent cognitivism&quot; corresponds to &quot;objectivism.&quot; (Terminology adopted from the Sayre-McCord essay; but see the Scanlon essay for the other terminology.) </p>\n<p>I'm guessing &quot;Kantian rationalism&quot; refers to views such as Scanlon's view. I'm didn't go into detail in my post with explaining the difference between constructivism as an intersubjectivist position and constructivism as a version of non-naturalism. I tried to say something about that in footnote 7 but I fear it'll only become more clear in my next post. Tl;dr is that non-naturalists think that we can have <em>externalist</em> reasons for doing something, reasons we cannot &quot;shake off&quot; by lacking internal buy-in or internal motivation. By contrast, someone who merely endorses constructivism as an intersubjectivist (or &quot;judgment-dependent&quot;) view, such as Korsgaard for instance, would reject these externalist reasons. </p>\n<p>I agree with the way you draw the lines between the realist and the anti-realist camp. The only thing I don't like about this (and this is a criticism not about your chart, but about the way philosophers have drawn these categories in the first place) is that it makes it seem as though we have to choose exactly one view. But by removing the entire discussion from the &quot;linguistic level&quot; (taking a stance on how we interpret moral discourse), we can acknowledge e.g. that subjectivism or intersubjectivism represent useful frameworks for thinking about morality-related questions, whether moral discourse is completely subjectivist or intersubjectivist in nature or not. And even if moral discourse was all subjectivist (which seems clearly wrong to me but let's say it's a hypothetical), for all we'd know that could still allow for the possibility that an objectivist moral reality exists in a meaningful and possibly action-relevant sense. I like Luke's framing of &quot;<a href=\"https://www.lesswrong.com/posts/3zDX3f3QTepNeZHGc/pluralistic-moral-reductionism\">pluralistic moral reductionism</a>&quot; because it makes clear that there is more than one option.</p>\n", "parentCommentId": "yJfZboMaSLQa65zgy", "user": {"username": "Lukas_Gloor"}}, {"_id": "K8Ge4ifL7CDfacjYZ", "postedAt": "2018-05-22T22:49:57.809Z", "postId": "TwJb75GtbD4LvGiku", "htmlBody": "<blockquote>\n<p>The idea is that morality is the set of rules that impartial, rational people would advocate as a public system. </p>\n</blockquote>\n<p>Yes, this sounds like constructivism. I think this is definitely a useful framework for thinking about some moral/morality-related questions. I don't think all of moral discourse is best construed as being about this type of hypothetical rule-making, but like I say in the post, I don't think interpreting moral discourse should be the primary focus. </p>\n<blockquote>\n<p>Rationality is understood, roughly speaking, as the set of things that virtually all rational agents would be averse to. This ends up being a list of basic harms--things like pain, death, disability, injury, loss of freedom, loss of pleasure. </p>\n</blockquote>\n<p>Hm, this sounds like you're talking about a substantive concept of rationality, as opposed to a merely &quot;procedural&quot; or &quot;instrumental&quot; concept of rationality (such as it's common on Lesswrong and with anti-realist philosophers like Bernard Williams). Substantive concepts of rationally always go under moral non-naturalism, I think.  </p>\n<p>My post is a little confusing with respect to the distinction here, because you can be a constructivist in two different ways: Primarily as an intersubjectivist metaethical position, and &quot;secondarily&quot; as a form of non-naturalism. (See my comments on Thomas Sittler's chart.) </p>\n<blockquote>\n<p>People can be incorrect about whether a thing is harmful, just as they can be incorrect about whether a flower is red. But there's nothing much more objective or &quot;facty&quot; about whether the plant is red than that ordinary human language users on earth are disposed to see and label it as red.</p>\n</blockquote>\n<p>Yeah, it should be noted that &quot;strong&quot; versions of moral realism are not committed to silly views such as morality existing in some kind of supernatural realm. I often find it difficult to explain moral non-naturalism in a way that makes it sound as non-weird as when actual moral non-naturalists write about it, so I have to be careful to not strawman these positions. But what you describe may still qualify as &quot;strong&quot; because you're talking about rationality as a substantive concept. (Classifying something as a &quot;harm&quot; is one thing if done in a descriptive sense, but probably you're talking about classifying things as a harm in a sense that has moral connotations \u2013 and that gets into more controversial territory.) </p>\n<p>The book title &quot;normative bedrock&quot; also sounds relevant because my next post will talk about &quot;bedrock concepts&quot; (Chalmers) at length, and specifically about &quot;irreducible normativity&quot; as a bedrock concept, which I think makes up the core of moral non-naturalism.</p>\n", "parentCommentId": "gNLuXMLBdhiYAKwi8", "user": {"username": "Lukas_Gloor"}}, {"_id": "xj8KEQrzjrLhLp5Cg", "postedAt": "2018-05-23T05:55:00.145Z", "postId": "TwJb75GtbD4LvGiku", "htmlBody": "<p>Thanks for your engaging insights!</p>\n<blockquote>\n<p>this sounds like you're talking about a substantive concept of rationality</p>\n</blockquote>\n<p>Yes indeed!</p>\n<blockquote>\n<p>Substantive concepts of rationally always go under moral non-naturalism, I think.</p>\n</blockquote>\n<p>I'm unclear on why you say this. It certainly depends on how exactly 'non-naturalism' is defined.</p>\n<p>One contrast of the Gert-inspired view I've described and that of some objectivists about reasons or substantive rationality (e.g. Parfit) is that the latter tend to talk about reasons as brute normative facts. Sometimes it seems they have no story to tell about why those facts are what they are. But the view I've described does have a story to tell. The story is that we had a certain robust agreement in response toward harms (aversion to harms and puzzlement toward those who lack the aversion). Then, as we developed language, we developed terms to refer to the things that tend to elicit these responses.</p>\n<p>Is that potentially the subject of the 'natural' sciences? It depends: it seems to be the subject not of physical sciences but of psychological and linguistic sciences. So it depends whether psychology and linguistics are 'natural' sciences. Does this view hold that facts about substantive rationality are not identical with or reducible to any natural properties? It depends on whether facts about death, pain, injury, and dispositions are reducible to natural properties.</p>\n<p>It's not clear to me that the natural/non-natural distinction applies all that cleanly to the Gert-inspired view I've delineated. At least not without considerably clarifying both the natural/non-natural distinction and the Gert-inspired view.</p>\n<blockquote>\n<p>you can be a constructivist in two different ways: Primarily as an intersubjectivist metaethical position, and &quot;secondarily&quot; as a form of non-naturalism.</p>\n</blockquote>\n<p>This seems like a really interesting point, but I'm still a little unclear on it.</p>\n<p><em>Rambling a bit</em></p>\n<p>It's helpful to me that you've pointed out that my Gert-inspired view has an objectivist element at the 'normative bedrock' level (some form of realism about harms &amp; rationality) and a constructivist element at the level of choosing first-order moral rules ('what would impartial, rational people advocate in a public system?').</p>\n<p>A question that I find challenging is, 'Why should I care about, or act on, what impartial, rational people would advocate in a public system?' (Why shouldn't I just care about harms to, say, myself and a few close friends?) Constructivist answers to <em>that</em> question seem inadequate to me. So it seems we are forced to choose between two unsatisfying answers. On the one hand, we might choose a minimally satisfying realism that asserts that it's a brute fact that we should care about people and apply moral rules to them impartially; it's a brute fact that we 'just see'. On the other hand, we might choose a minimally satisfying anti-realism that asserts that caring about or acting on morality is not actually something we should do; the moral rules are what they are and we can choose it if our heart is in it, but there's not much more to it than hypotheticals.</p>\n", "parentCommentId": "K8Ge4ifL7CDfacjYZ", "user": {"username": "jayquigley"}}, {"_id": "3j2tTo2zEvQNedzti", "postedAt": "2018-05-23T13:13:58.022Z", "postId": "TwJb75GtbD4LvGiku", "htmlBody": "<blockquote>\n<p>Why should we care whether or not moral realism is true?</p>\n</blockquote>\n<p>I plan to address this more in a future post, but the short answer is this that for some ways in which moral realism has been defined, it really doesn't matter (much). But there are some versions of moral realism that <em>would</em> &quot;change the game&quot; for those people who currently reject them. And vice-versa, if one currently endorses a view that corresponds to the two versions of &quot;strong moral realism&quot; described in the last section of my post, one's priorities could change noticeably if one changes one's mind towards anti-realism. </p>\n<blockquote>\n<p>What do you think are the implications of moral anti-realism for choosing altruistic activities?</p>\n</blockquote>\n<p>It's hard to summarize this succinctly because for most of the things that are straightforwardly important under moral realism (such as moral uncertainty or deferring judgment to future people who are more knowledgeable about morality), you can also make good arguments in favor of them going from anti-realist premises. Some quick thoughts: </p>\n<p> \u2013 The main difference is that things become more &quot;messy&quot; with anti-realism. </p>\n<p>\u2013 I think anti-realists should, all else equal, be more reluctant to engage in &quot;bullet biting&quot; where you abandon some of your moral intuitions in favor of making your moral view &quot;simpler&quot; or &quot;more elegant.&quot; The simplicity/elegance appeal is that if you have a view with many parameters that are fine-tuned for your personal intuitions, it seems extremely unlikely that other people would come up with the same parameters if they only thought about morality more. Moral realists may think that the correct answer to morality is one that everyone who is knowledgeable enough would endorse, whereas anti-realists may consider this a potentially impossible demand and therefore place more weight on finding something that feels very intuitively compelling on the individual level. Having said that, I think there are a number of arguments why even an anti-realist might want to adopt moral views that are &quot;simple and elegant.&quot; For instance, people may care about doing something meaningful that is &quot;greater than their own petty little intuitions&quot; \u2013 I think this is an intuition that we can try to cash out somehow even if moral realism turns out to be false (it's just that it can be cashed out in different ways). </p>\n<p>\u2013 &quot;Moral uncertainty&quot; works differently under anti-realism, because you have to say what you are uncertain <em>about</em> (it cannot be the one true morality because anti-realism says there is no such thing). One can be uncertain about what one would value after moral reflection under ideal conditions. This kind of &quot;valuing moral reflection&quot; seems like a very useful anti-realist alternative to moral uncertainty. The difference is that &quot;valuing reflection&quot; may be underdefined, so anti-realists have to think about how to distinguish having underdefined values from being uncertain about their values. This part can get tricky. </p>\n<p>\u2013 There was recently a discussion about &quot;goal drift&quot; in the EA forum. I think it's a bigger problem with anti-realism all else equal (unless one's anti-realist moral view is egoism-related.) But again, there are considerations that go into both directions. :) </p>\n", "parentCommentId": "JvE7t7rPDeExATqe4", "user": {"username": "Lukas_Gloor"}}, {"_id": "4ZQ56h9YLFX8HB8ee", "postedAt": "2018-05-23T14:38:00.804Z", "postId": "TwJb75GtbD4LvGiku", "htmlBody": "<p>Thanks for putting this out there. I like how you list the two versions of moral realism you find coherent, and especially that you list what would convince you of each.</p>\n<p>My intuition here is the first option is the case, but also that instead of speaking about <em>moral realism</em> we should talk about <em>qualia formalism</em>. I.e., whether consciousness is real enough such that it can be spoken about in crisp formal terms, seems prior to whether morality is real in that same sense. I've written about this <a href=\"https://qualiaresearchinstitute.org/2018/02/17/the-problems-of-consciousness-a-taxonomy/\">here</a>, and spoke about this in the intro of <a href=\"https://qualiaresearchinstitute.org/2018/04/13/videos-from-tsc2018/\">my TSC2018 talk</a>.</p>\n<p>Whether qualia formalism is true seems an empirical question; if it is, we should be able to make novel and falsifiable predictions with it. This seems like a third option for moving forward, in addition to your other two.</p>\n", "parentCommentId": null, "user": {"username": "MikeJohnson"}}, {"_id": "8RLFoxRdC7GjifJHX", "postedAt": "2018-05-24T13:15:34.972Z", "postId": "TwJb75GtbD4LvGiku", "htmlBody": "<p>Thanks for writing this up in a fairly accessible manner for laypeople like me. I am looking forward to the next posts. So far, I have only one reflection on the following bit of your thinking. It is a side point but it probably would help me to better model your thinking.</p>\n<blockquote>\n<p>And all I\u2019m thinking is, \u201cWhy are we so focused on interpreting religious claims? Isn\u2019t the major question here whether there are things such as God, or life after death!?\u201d The question that is of utmost relevance to our lives is whether religion\u2019s metaphysical claims, interpreted in a straightforward and realist fashion, are true or not. An analysis of other claims can come later.</p>\n</blockquote>\n<p>Do you think analyses of the other claims are never of more value than analyses of the metaphysical claims?</p>\n<p>Because my initial reaction to your claim was something like &quot;why would we focus on whether there is a god or life after death - it seems hardly possible to make substantial advances there in a meaningful way and these texts were meant to point at something a lot more trivial. They are disguised as profound and with metaphysical explanations only to make people engage with and respect them in times where no other tools were available to do so on a global level.&quot;</p>\n<p>I.e. no matter the answer to the metaphysical questions, it could be useful to interpret religious claims because they could be pointing at something that people thought would help to structure society, whether the metaphysical claims hold or not.</p>\n<p>Thus, I wonder whether the bible example is a little weak. You would have to clarify that you assume that people sometimes actually believe they are having a meaningful discussion around &quot;what's Real Good?&quot;, assuming moral realism through god(?), as opposed to just engaging in intellectual masturbation, consciously or not.</p>\n<p>If I do not take those people (who suppose moral realism proven through bible) seriously, I can operate based on the assumption that the authors of such writings supposed any form of moral non-naturalism, subjectivism, intersubjectivism or objectivism, as described by you. Any of which could have led to the idea of creating better mechanisms to enforce either the normative Good, the social contract, or allow everyone to maximally realise their own desires by creating an authority (&quot;god&quot;) that allows to move society into a better equilibrium for any of these theories.</p>\n<p>In that case, taking the claims about the (metaphysical) nature of that authority to be of any value of information/as providing valuable ground for discussion seems to be a waste of time or even giving them undeserved attention and credit, distracting from more important questions. Your described reaction though takes the ideas seriously and I wonder why you think there is any ground to even consider them as such?</p>\n<p>I think this concern is somewhat relevant to the broader discussion, too, because you seem to imply that we can't (or even shouldn't?) make any advances on non-metaphysical claims before we haven't figured out the metaphysical ones. Though, what you mean is probably more along the lines of &quot;be ready to change everything once we have figured out moral philosophy&quot;, not implying that we shouldn't do anything else in the meantime. Is that correct? If so, this point might get lost if not pronounced more prominently.</p>\n", "parentCommentId": null, "user": {"username": "konrad"}}, {"_id": "WJQnKdGyu8wFGD7Na", "postedAt": "2018-05-25T16:18:40.566Z", "postId": "TwJb75GtbD4LvGiku", "htmlBody": "<p>Probably intuitions about this issue depend on which type of moral or religious discourse one is used to. As someone who spent a year at a Christian private school in Texas where creationism was taught in Biology class and God and Jesus were a very tangible part of at least some people's lives, I definitely got a strong sense that the metaphysical questions are extremely important.</p>\n<p>By contrast, if the only type of religious claims I'd ever came into contact with had been moderate (picture the average level of religiosity of a person in, say, Zurich), then one may even consider it a bit of a strawman to assume that religious claims are to be taken literally. </p>\n<blockquote>\n<p>I think this concern is somewhat relevant to the broader discussion, too, because you seem to imply that we can't (or even shouldn't?) make any advances on non-metaphysical claims before we haven't figured out the metaphysical ones.</p>\n</blockquote>\n<p>Just to be clear, all I'm saying is that I think it's going to be less useful to discuss &quot;what are moral claims usually about.&quot; What we should instead do is instead what Chalmers describes (see the quote in footnote 4). Discussing what moral claims are usually about is not the same as making up one's mind about normative ethics. I think it's very useful to discuss normative ethics, and I'd even say that discussing whether anti-realism or realism is true might be slightly less important than making up one's mind about normative ethics. Sure, it informs to some extent how to reason about morality, but as <a href=\"https://www.utilitarian.net/singer/by/197301--.htm\">has been pointed out</a>, you can make <em>some</em> progress about moral questions also from a lens of agnosticism about realism vs. anti-realism. </p>\n<p>To go back to the religion analogy, what I'm recommending is to first figure out whether you believe in a God or an afterlife that would relevantly influence your priorities now, and not worry much about whether religious claims are &quot;usually&quot; or &quot;best&quot; to be taken literally or taken metaphorically(?). </p>\n", "parentCommentId": "8RLFoxRdC7GjifJHX", "user": {"username": "Lukas_Gloor"}}, {"_id": "m4ZeNihQZkea2ETaP", "postedAt": "2018-05-30T16:37:34.674Z", "postId": "TwJb75GtbD4LvGiku", "htmlBody": "<p>The descriptive task of determining what ordinary moral claims mean may be more relevant to questions about whether there are objective moral truths than is considered here. Are you familiar with Don Loeb's metaethical incoherentism? Or the empirical literature on metaethical variability? I recommend Loeb's article, &quot;Moral incoherentism: How to pull a metaphysical rabbit out of a semantic hat.&quot; The title itself indicates what Loeb is up to.</p>\n", "parentCommentId": null, "user": {"username": "LanceSBush"}}, {"_id": "zssPuXQDFtqryA4ox", "postedAt": "2018-05-31T00:36:19.716Z", "postId": "TwJb75GtbD4LvGiku", "htmlBody": "<p>For One Compelling Axiology, assuming that &quot;ideal&quot; is defined in a manner that does not beg the question, the theory implies that moral facts allow us to make empirical predictions about the world - for instance, a given philosopher, or group of philosophers, or ASI, or myself, will adopt such-and-such moral attitude with probability p. Moreover, moral facts seem to be defined purely in terms of their empirical ramifications.</p>\n<p>This I find to be deeply troubling because it provides no grounds to say that there are any moral facts at all, just empirical ones. Suppose that there is a moral proposition X which states the one compelling axiology, okay. Now on what grounds do you say that X is a moral fact? <em>Merely</em> because it's always compelling? But such a move is a non sequitur. </p>\n<p>Of course, you can say that you would be compelled to follow X were you to be an ideal reasoner, and therefore it's reasonable of you to follow it. But again, all we're saying here is that we would follow X were we to have whatever cognitive properties we associate with the word &quot;ideal&quot;, and that is an empirical prediction. So it doesn't establish the presence of moral facts, there are just empirical facts about what people aspire to do under various counterfactuals and predicates.</p>\n", "parentCommentId": null, "user": {"username": "kbog"}}, {"_id": "r8zLdCvi9qBEWreHX", "postedAt": "2018-05-31T08:53:53.532Z", "postId": "TwJb75GtbD4LvGiku", "htmlBody": "<p>Do you think your argument also works against Railton's moral naturalism, or does my One Compelling Axiology (OTA) proposal introduce something that breaks the idea? The way I meant it, OTA is just a more extreme version of Railton's view. </p>\n<p>I think I can see what you're pointing to though. I wrote: </p>\n<blockquote>\n<p>Note that this proposal makes no claims about the linguistic level: I\u2019m not saying that ordinary moral discourse let\u2019s us <em>define</em> morality as convergence in people\u2019s moral views after philosophical reflection under ideal conditions. (This would be a circular definition.) Instead, I am focusing on the aspect that such convergence would be practically relevant: [...]</p>\n</blockquote>\n<p>So yes, this would be a bad proposal for what moral discourse is about. But it's meant like this: Railton claims that morality is about doing things that are &quot;good for others from an impartial perspective.&quot; I like this and wanted to work with that, so I adopt this assumption, and further add that I only want to call a view moral realism if &quot;doing what is good for others from an impartial perspective&quot; is well-specified. Then I give some account of what it would mean for it to be well-specified.</p>\n<p>In my proposal, moral facts are not defined as that which people arrive at after reflection. Moral facts are still defined as the same thing Railton means. I'm just adding that maybe there are no moral facts in the way Railton means if we introduce the additional requirement that (strong) underdetermination is not allowed. </p>\n", "parentCommentId": "zssPuXQDFtqryA4ox", "user": {"username": "Lukas_Gloor"}}, {"_id": "2dRZjfF8munXLygHP", "postedAt": "2018-05-31T09:17:49.058Z", "postId": "TwJb75GtbD4LvGiku", "htmlBody": "<p>Inspired by another message of yours, there's at least one important link here that I failed to mention: If moral discourse is about a, b, and c, and philosophers then say they want to make it about q and argue for realism about q, we can object that whatever they may have shown us regarding realism about q, it's certainly not <em>moral</em> realism. And it looks like the Loeb paper also argues that if moral discourse is about mutually incompatible things, that looks quite bad for moral realism? Those are good points! </p>\n", "parentCommentId": "m4ZeNihQZkea2ETaP", "user": {"username": "Lukas_Gloor"}}, {"_id": "LKGcA9nrpGmiqb443", "postedAt": "2018-06-04T12:29:13.142Z", "postId": "TwJb75GtbD4LvGiku", "htmlBody": "<p>Thanks for writing this, Lukas. :-)</p>\n<p>As a self-identified moral realist, I did not find my own view represented in this post, although perhaps Railton\u2019s naturalist position is the one that comes the closest. I can identify both as an objectivist, a constructivist, and a subjectivist, indeed even a Randian objectivist. It all rests on what the nature of the ill-specified \u201csubject\u201d in question is. If one is an open individualist, then subjectivism and objectivism will, one can argue, collapse into one. According to open individualism, the adoption of Randianism (or, in Sidgwick\u2019s terminology, \u201crational egoism\u201d) implies that we should do what is best for all sentient beings. In other words, subjectivism without indefensibly demarcated subjects (or at least subjects whose demarcation is not granted unjustifiable metaphysical significance) is equivalent with objectivism. Or so I would argue.</p>\n<p>As for Moore\u2019s open question argument (which I realize was not explored in much depth here), it seems to me, as has been pointed out by others, that there can be an ontological identity between that which different words refer to even if these words are not commonly reckoned strictly synonymous. For example: Is water the same as H2O? Is the brain the mind? These questions are hardly meaningless, even if we think the answer to both questions is 'yes'. Beyond that, one can also defend the view that \u201cthe good\u201d is a larger set of which any specific good thing we can point to is merely a subset, and hence the question can also make sense in this way (i.e. it becomes a matter of whether something is part of \u201cthe good\u201d).</p>\n<p>To turn the tables a bit here, I would say that to reject moral realism, on my account, one would need to say that there is no genuine normative force or property in, say, a state of extreme suffering (consider being fried in a brazen bull for concreteness). [And I think one can fairly argue that to say such a state has \u201cgenuine normative force\u201d is very much an understatement.]</p>\n<p>\u201cNormative force for the experiencing subject or for all agents?\u201d one may then ask. Yet on my account of personal identity, the open individualist account (cf. <a href=\"https://en.wikipedia.org/wiki/Open_individualism\">https://en.wikipedia.org/wiki/Open_individualism</a> and <a href=\"https://www.smashwords.com/books/view/719903)\">https://www.smashwords.com/books/view/719903)</a>, there is no fundamental distinction, and thus my answer would simply be: yes, for the experiencing subject, and hence for all agents (this is where our intuitions scream, of course, unless we are willing to suspend our strong, Darwinianly adaptive sense of self as some entity that rides around in some small part of physical reality).\nOne may then object that different agents occupy genuinely different coordinates in spacetime, yet the same can be said of what we usually consider the same agent. So there is really no fundamental difference here: If we say that it is genuinely normative for Tim at t1 (or simply Tim1) to ensure that Tim at t2 (or simply Tim2) suffers less, then why wouldn\u2019t the same be true of Tim1 with respect to John1, 2, 3\u2026?</p>\n<p>With respect to the One Compelling Axiology you mention, Lukas, I am not sure why you would set the bar so high in terms of specificity in order to accept a realist view. I mean, if \u201call philosophers or philosophically-inclined reasoners\u201d found plausible a simple, yet inexhaustive principle like \u201creduce unnecessary suffering\u201d why would that not be good enough to demonstrate its \"realism\" (on your account) when a more specific one would? It is unclear to me why greater specificity should be important, especially since even such an unspecific principle still would have plenty of practical relevance (many people can admit that they are not living in accordance with this principle, even as they do accept it).</p>\n", "parentCommentId": null, "user": {"username": "MagnusVinding"}}, {"_id": "yjhqoYAK2rMMnLD6J", "postedAt": "2018-06-05T18:27:00.504Z", "postId": "TwJb75GtbD4LvGiku", "htmlBody": "<blockquote>\n<p>To turn the tables a bit here, I would say that to reject moral realism, on my account, one would need to say that there is no genuine normative force or property in, say, a state of extreme suffering (consider being fried in a brazen bull for concreteness).</p>\n</blockquote>\n<p>Cool! I think the closest I'll come to discussing this view is in footnote 18. I plan to have a post on moral realism via introspection about the intrinsic goodness (or badness) of certain conscious states. </p>\n<p>I agree with reductionism about personal identity and I also find this to be one of the most persuasive arguments in favor of altruistic life goals. I would not call myself an open indvidualist though because I'm not sure what the position is exactly saying. For instance, I don't understand how it differs from empty individualism. I'd understand if these are different <em>framings</em> or different <em>metaphores</em>, but if we assume that we're talking about positions that can be true or false, I don't understand what we're arguing about when asking whether open individualism or true, or when discussing open vs. empty individualism.<br />Also, I think it's perfectly coherent to have egoistic goals even under a reductionist view of personal identity. (It just turns out that egoism is not a well-defined concept either, and one has to make some judgment calls if one ever expects to encounter edge-cases for which our intuitions give no obvious answers about whether something is still &quot;me.&quot;) </p>\n<blockquote>\n<p>With respect to the One Compelling Axiology you mention, Lukas, I am not sure why you would set the bar so high in terms of specificity in order to accept a realist view. I mean, if \u201call philosophers or philosophically-inclined reasoners\u201d found plausible a simple, yet inexhaustive principle like \u201creduce unnecessary suffering\u201d why would that not be good enough to demonstrate its &quot;realism&quot; (on your account) when a more specific one would? It is unclear to me why greater specificity should be important, especially since even such an unspecific principle still would have plenty of practical relevance (many people can admit that they are not living in accordance with this principle, even as they do accept it).</p>\n</blockquote>\n<p>Yeah, fair point. I mean, even Railton's own view has plenty of practical relevance in the sense that it highlights that certain societal arrangements lead to more overall well-being or life satisfaction than others. (That's also a point that Sam Harris makes.) But if that's all we mean by &quot;moral realism&quot; then it would be rather trivial. Maybe my criteria are a bit too strict, and I would indeed already regard it as <em>extremely</em> surprising if you get something like One Compelling Axiology that agrees on population ethics while leaving a few other things underdetermined.</p>\n", "parentCommentId": "LKGcA9nrpGmiqb443", "user": {"username": "Lukas_Gloor"}}, {"_id": "Yt8hMhgBfHgHmNgiX", "postedAt": "2018-06-06T08:05:58.457Z", "postId": "TwJb75GtbD4LvGiku", "htmlBody": "<p>Thanks for your reply :-)</p>\n<blockquote>\n<p>For instance, I don't understand how [open individualism] differs from empty individualism. I'd understand if these are different framings or different metaphores, but if we assume that we're talking about positions that can be true or false, I don't understand what we're arguing about when asking whether open individualism or true, or when discussing open vs. empty individualism. </p>\n</blockquote>\n<p>I agree completely. I identify equally as an open and empty individualist. As I've written elsewhere (in You Are Them): \"I think these 'positions' are really just two different ways of expressing the same truth. They merely define the label of 'same person' in different ways.\"</p>\n<blockquote>\n<p>Also, I think it's perfectly coherent to have egoistic goals even under a reductionist view of personal identity.</p>\n</blockquote>\n<p>I guess it depends on what those egoistic goals are. The fact that some egoistic goals are highly instrumentally useful for the benefit of others (even if one doesn't intend to benefit others, cf. Smith's invisible hand, the deep wisdom of Ayn Rand, and also, more generally, the fact that many of our selfish desires probably shouldn't be expected to be that detrimental to others, or at least our in-group, given that we evolved as social creatures) is, I think, a confounding factor that makes it seem plausible to say that pursuing them is coherent/non-problematic (in light of a reductionist view of personal identity). Yet if it is transparent that the pursuit of these egoistic goals comes at the cost of many other beings' intense suffering, I think we would be reluctant to say that pursuing them is \"perfectly coherent\" (especially in light of such a view of personal identity, yet many would probably even say it regardless; one can, for example, also argue it is incoherent with reference to inconsistency: \"we should not treat the same/sufficiently similar entities differently\").\nFor instance, would we, with this view of personal identity, really claim that it is \"perfectly coherent\" to choose to push button A: \"you get a brand new pair of shorts\", when we could have pushed button B: \"You prevent 100 years of torture (for someone else in one sense, yet for yourself in another, quite real sense) which will not be prevented if you push button A\". It seems much more plausible to deem it perfectly coherent to have a selfish desire to start a company or to signal coolness or otherwise gain personal satisfaction by being an effective altruist.</p>\n<blockquote>\n<p>But if that's all we mean by \"moral realism\" then it would be rather trivial.</p>\n</blockquote>\n<p>I don't quite understand why you would call this trivial. Perhaps it is trivial that many of us, perhaps even the vast majority, agree. Yet, as mentioned, the acceptance of a principle like \"avoid causing unnecessary suffering\" is extremely significant in terms of its practical implications; many have argued that it implies the adoption of veganism (where the effects on wildlife as a potential confounding factor is often disregarded, of course), and one could even employ it to argue against space colonization (depending on what we hold to constitute necessity). So, in terms of practical consequences at least, I'm almost tempted to say that it could barely be more significant. And it's not clear to me that agreement on a highly detailed axiology would necessarily have significantly more significant, or even more clear, implications than what we could get off the ground from quite crude principles (it seems to me there may well be strong diminishing returns here, if you will, as you can also seem to agree weakly with in light of the final sentence of your reply). Also because the large range of error produced by empirical uncertainty may, on consequentialist views at least, make the difference in practice between realizing a detailed and a crude axiology a lot less clear than the difference between the two axiologies at the purely theoretical level -- perhaps even so much so as to make it virtually vanish in many cases.</p>\n<blockquote>\n<p>Maybe my criteria are a bit too strict [...]</p>\n</blockquote>\n<p>I'm just wondering: too strict for what purpose?</p>\n<p>This may seem a bit disconnected, but I just wanted to share an analogy I just came to think of: Imagine mathematics were a rather different field where we only agreed about simple arithmetic such as 2 + 2 = 4, and where everything beyond that were like the Riemann hypothesis: there is no consensus, and clear answers appear beyond our grasp. Would we then say that our recognition that 2 + 2 = 4 holds true, at least in some sense (given intuitive axioms, say), is trivial with respect to asserting some form of mathematical realism? And would finding widely agreed-upon solutions to our harder problems constitute a significant step toward deciding whether we should accept such a realism? I fail to see how it would.</p>\n", "parentCommentId": "yjhqoYAK2rMMnLD6J", "user": {"username": "MagnusVinding"}}, {"_id": "FWPhzxjsbkeuTGSqD", "postedAt": "2018-06-08T12:32:27.592Z", "postId": "TwJb75GtbD4LvGiku", "htmlBody": "<p>Thanks, this makes sense.</p>\n<p>As someone who spent a year at a Tennessean high school surrounded by Baptists, I understand your experience. I just ended up with a different conclusion: no one is interested in the metaphysical questions because they have to be settled if you want to continue living your &quot;normal&quot; life. What looks like interest in the metaphysical questions is a mere self-preservation mechanism for the normative ethical claims and not to be taken at face value.</p>\n<p>To me, it seems faulty to assume any believer &quot;reasons&quot; about the existence of god, their brains just successfully trick them into thinking that. That's why I felt it was weak as a metaphor for anti-realism vs realism. So from an outside view your metaphor makes sense if you take believers to be &quot;reasoning&quot; about anything but felt to me like it was more distracting from the thing you meant to point at, than actually pointing at it. The thing being:</p>\n<blockquote>\n<p>I think it's going to be less useful to discuss &quot;what are moral claims usually about.&quot; What we should instead do is instead what Chalmers describes (see the quote in footnote 4). Discussing what moral claims are usually about is not the same as making up one's mind about normative ethics. I think it's very useful to discuss normative ethics, and I'd even say that discussing whether anti-realism or realism is true might be slightly less important than making up one's mind about normative ethics. Sure, it informs to some extent how to reason about morality, but as has been pointed out, you can make some progress about moral questions also from a lens of agnosticism about realism vs. anti-realism.</p>\n</blockquote>\n", "parentCommentId": "WJQnKdGyu8wFGD7Na", "user": {"username": "konrad"}}, {"_id": "TtxHaexhRnsvtw4eu", "postedAt": "2018-06-13T03:14:07.764Z", "postId": "TwJb75GtbD4LvGiku", "htmlBody": "<p>Yes I think it applies to pretty much any other kind of naturalism as well. At least, any that I have seen.</p>\n", "parentCommentId": "r8zLdCvi9qBEWreHX", "user": {"username": "kbog"}}, {"_id": "pooJajExrckW3KjfR", "postedAt": "2020-06-13T09:57:02.622Z", "postId": "TwJb75GtbD4LvGiku", "htmlBody": "<p>Thanks for this post - this topic seems quite important to me, and I think this post has reduced my confusion and sharpened my thinking. I look forward to reading the later posts in the sequence.</p><blockquote>However, not committing to any specific perspective calls into question whether there even is, in theory, a correct answer. If there are many different and roughly equally plausible interpretations of &#x201C;impartial perspective&#x201D; or &#x201C;desire fulfillment&#x201D; (or more generally: of <em><a href=\"https://plato.stanford.edu/entries/well-being/#MooCha\">well-being</a></em> defined as &#x201C;that which is good for a person&#x201D;), then the question, &#x201C;Which of these different accounts is <em>correct</em>?&#x201D;&#xA0;may not have an answer.</blockquote><p>I found this argument confusing. Wouldn&apos;t it be acceptable, and probably what we&apos;d <em>expect</em>, for a metaethical view to not also provide answers on normative ethics or axiology? It seems  that finding out there are &quot;speaker-independent moral facts, rules or values&quot; would be quite important, even if we don&apos;t yet know what those facts are. And it doesn&apos;t seem that not yet knowing those facts should be taken as strong evidence that those facts don&apos;t exist? Perhaps the different interpretations are equally plausible <em>at the moment</em>, but as we learn and debate more we will come to see some interpretations as more plausible?</p><p>Analogously, you and I could agree that there is an objectively correct and best answer to the question &quot;What percentage of Americans are allergic to bees?&quot;, despite not yet knowing what that answer is. And then we could look it up. Whereas if we believed there <em>wasn&apos;t </em>an objectively correct and best answer, we might decide our current feelings about that question are the best thing we&apos;d get, and we might not bother looking it up. And it doesn&apos;t seem like we should take &quot;we don&apos;t yet know the percentage&quot; as strong evidence that there is no correct percentage. </p><p>Is there a reason that analogy doesn&apos;t hold in the case of moral realism vs anti-realism? Or am I misunderstanding the paragraph I quoted above?</p><p>(To be clear, I&apos;m not trying to imply that the case for moral anti-realism is as weak as the case for allergy-percentage anti-realism. Moral anti-realism seems quite plausible to me. I&apos;m just trying to understand the particular argument I quoted above.)</p>", "parentCommentId": null, "user": {"username": "MichaelA"}}, {"_id": "53bYiw79snyGDbqyt", "postedAt": "2020-06-14T11:10:22.813Z", "postId": "TwJb75GtbD4LvGiku", "htmlBody": "<blockquote>I found this argument confusing. Wouldn&apos;t it be acceptable, and probably what we&apos;d <em>expect</em>, for a metaethical view to not also provide answers on normative ethics or axiology?</blockquote><p>I&apos;m not saying metaethical views <em>have to</em> advance a particular normative-ethical theory. I&apos;m just saying that if a realist metaethical view doesn&apos;t do this, it becomes difficult to explain how proponents of this view could possibly know that there really is &quot;a single correct theory.&quot; </p><p>So for instance, looking at the arguments by Peter Railton, it&apos;s not clear to me whether Railton even expects there to be a single correct moral theory. His arguments leave morality under-defined. &quot;Moral realism&quot; is commonly associated with the view that there&apos;s a single correct moral theory. Railton has done little to establish this, so I think it&apos;s questionable whether to call this view &quot;moral realism.&quot; </p><p>Of course, &quot;moral realism&quot; is just a label. It matters much more that we have clarity about what we&apos;re discussing, instead of which label we pick. If someone wants to use the term &quot;moral realism&quot; for moral views that are explicitly under-defined (i.e., views according to which many moral questions don&apos;t have an answer), that&apos;s fine. In that sense, I would be a &quot;realist.&quot;</p><blockquote>It seems that finding out there are &quot;speaker-independent moral facts, rules or values&quot; would be quite important, even if we don&apos;t yet know what those facts are.</blockquote><p>One would think so, but as I said, it depends on what we mean exactly by &quot;speaker-independent moral facts.&quot; On some interpretations, those facts may be forever unknowable. In that case, knowledge that those facts exist would be pointless in practice. </p><p>I write more about this in my <a href=\"https://forum.effectivealtruism.org/posts/C2GpA894CfLcTXL2L/moral-anti-realism-sequence-3-against-irreducible#3__Irreducible_normativity_fails_as_a_concept\">3rd post</a>, so maybe the points will make more sense with the context there. But really the main point of this 1st post is that I make a proposal in favor of being cautious about the label &quot;moral realism&quot; because, in my view, some versions of it don&apos;t seem to have action-guiding implications for how to go about effective altruism. </p><p>(I mean, if I had started out convinced of moral relativism, then sure, &quot;moral realism&quot; in Peter Railton&apos;s sense would change my views in very action-guiding ways. But moral relativists are rare. I feel like one should draw the realism vs. anti-realism distinction in a place where it isn&apos;t obvious that one side is completely wrong. If we draw the distinction in such a way that Peter Railton&apos;s view qualifies as &quot;moral realism,&quot; then it would be rather trivial that anti-realism was wrong. This would seem uncharitable to all the anti-realist philosophers who have done important work on normative ethics.) </p>", "parentCommentId": "pooJajExrckW3KjfR", "user": {"username": "Lukas_Gloor"}}, {"_id": "Npqv3x2aH4nRDrWk8", "postedAt": "2020-07-03T08:38:15.149Z", "postId": "TwJb75GtbD4LvGiku", "htmlBody": "<p>Are the links to the footers broken?</p><p>(really enjoying the post by the way)</p>", "parentCommentId": null, "user": {"username": "Ben_Snodin"}}, {"_id": "buEkMoo9ev4G9LeR3", "postedAt": "2020-07-03T12:56:05.567Z", "postId": "TwJb75GtbD4LvGiku", "htmlBody": "<p>Thanks! </p><p>At the time when I wrote this post, the formatting either didn&apos;t yet allow the hyperlinked endnotes, or (more likely) I didn&apos;t know how to do the markdown. I plan to update the endnotes here so they become more easily readable. </p><p>Update 7/7/2020: I updated the endnotes. </p>", "parentCommentId": "Npqv3x2aH4nRDrWk8", "user": {"username": "Lukas_Gloor"}}, {"_id": "4CasFeEZQwLLLPbej", "postedAt": "2023-09-05T15:22:14.866Z", "postId": "TwJb75GtbD4LvGiku", "htmlBody": "<p>I was about to make a comment elsewhere about moral realism when it occurred to me that I didn't have a strong sense of what people mean by \"moral realism\", so I whipped out Google and immediately found myself here. Given all those references at the bottom, it seems like you are likely to have correctly described what the field of philosophy commonly thinks of as moral realism, yet I feel like I'm looking at nonsense.</p><p>Moral realism is based on the word \"real\", yet I don't see anything I would describe as \"real\" (in the territory-vs-map sense) in Philippa Foot or Peter Railton's forms of \"realism\". Indeed, I found the entire discussion of \"moral realism\" here to be <i>bewilderingly</i> abstract and platonic, sorely lacking in connection to the physical world. If I didn't know these were supposed to be \"moral realist\" views, I would've classified them as non-realist with high confidence. Perplexingly absent from the discussion above are <strong>the</strong> key ideas I would personally have used to ground a discussion on this topic, ideas like \"qualia\", \"the hard problem of consciousness\", \"ought vs is\", \"axioms of belief\" or, to coin a phrase, \"monadal experiencers\".</p><p>At the same time, you mention in a reply that \"anti-realism says there is no such thing\" as \"one true morality\" which is consistent with my intuition of what anti-realism seems like it should mean \u2015 that morality is fundamentally grounded in personal taste. But then, Foot and Railton's accounts <i>also</i> seem grounded in <i>their</i> personal tastes.</p><p>I'm no philosopher, just a humble (j/k) rationalist. So I would like to ask how you would classify my own account of \"moral realism worthy of the name\" as something that must ultimately be grounded in territory rather than map.</p><p>I have three ways of describing my system of \"moral realism worthy of the name\". One is to say that there is some <i>territory</i> that would lead us to an account of morality. This territory is as-yet undiscovered by modern science, but by reductionist analysis we can still say a lot about what this morality looks like (although there will probably be quite a bit of irreducible uncertainty about morality, until science can reveal more about the underlying territory). Another is to say that I have an <i>axiom</i> about qualia \u2015 that monadal experiencers exist, and experience qualia. Finally, I would say that a \"moral realism worthy of the name\" is also concerned with the problem of deriving ought-statements from is-statements (note: tentatively I think I can define \"X should be\" as equivalent to \"X is good\" where \"good\" is used in its ordinary everyday secular sense, not in an ideological or religious sense.)</p><p>Please have a look at this <a href=\"https://twitter.com/DPiepgrass/status/1645492780175872000\">summary of my views</a> on Twitter. My question is, how does this view fit into the philosophy landscape? I mean, what terms from the Encyclopedia of Philosophy would you use to describe it? Is it realist or (paradoxically) anti-realist?</p><p>By the way...</p><blockquote><p>I would call myself a moral realist if I could be convinced that there is One Compelling Axiology [....] I would count something as the One Compelling Axiology if all philosophers or philosophically-inclined reasoners, after having engaged in philosophical reflection under ideal conditions,[19] would deem the search for the One Compelling Axiology to be a sufficiently precise, non-ambiguous undertaking for them to have made up their minds rather than \u201crejected the question,\u201d and if these people would all come to largely the same conclusions. [....] ideal conditions for philosophical reflection means having access to everything [...] including [...] superintelligent oracle AI.</p></blockquote><p>This part reads to me as if you'd been asked \"what would change your mind\" and you responded \"realistically, nothing.\" But then, my background involves banging my head against the wall with <a href=\"https://medium.com/big-picture/talking-to-climate-deniers-514177e31888\">climate dismissives</a>, so I have a visceral understanding that \"science advances one funeral at a time\" as Max Planck said. So my next thought, more charitably, is \"well, maybe Lukas will make his judgement from the perspective of an imagined future where all necessary funerals have already taken place.\" Separately, I note that my conception of \"realism\" requires nothing like this, it just requires a foundation that is <i>real</i>, even if we don't understand it well.</p>", "parentCommentId": null, "user": {"username": "dpiepgrass"}}, {"_id": "C6LSmEsXvWRHZBQPi", "postedAt": "2023-09-09T12:29:03.539Z", "postId": "TwJb75GtbD4LvGiku", "htmlBody": "<blockquote><p>Moral realism is based on the word \"real\", yet I don't see anything I would describe as \"real\" (in the territory-vs-map sense) in Philippa Foot or Peter Railton's forms of \"realism\". [...]</p><p>At the same time, you mention in a reply that \"anti-realism says there is no such thing\" as \"one true morality\" which is consistent with my intuition of what anti-realism seems like it should mean \u2015 that morality is fundamentally grounded in personal taste. But then, Foot and Railton's accounts <i>also</i> seem grounded in <i>their</i> personal tastes.</p></blockquote><p>Yeah, that's why I also point out that I don't consider Foot's or Railton's account worthy of the name \"moral realism.\" Even though they've been introduced and discussed that way.</p><blockquote><p>So I would like to ask how you would classify my own account of \"moral realism worthy of the name\" as something that must ultimately be grounded in territory rather than map.</p></blockquote><p>I think it's surprisingly difficult to spell out what it would mean for morality to be grounded in the territory. My \"One Compelling Axiology\" version of moral realism constitutes my best effort at operationalizing what it would mean. Because if morality is grounded in the territory, that should be the cause for ideal reasoners to agree on the exact nature and shape of morality.<br><br>At this point of the argument, philosophers of a particular school tend to object and say something like the following:&nbsp;<br><br>\"It's not about what human reasoners think or whether there's convergence of their moral views as they become more sophisticated and better studied. Instead, it's about what's <i>actually</i> true! It could be that there's a true morality, but all human reasoners (even the best ones) are wrong about it.\"</p><p>But that sort of argument begs the question. What does it mean for something to be true if we could all be wrong about it even under ideal reasoning conditions? That's the part I don't understand. So, when I steelman moral realism, I assume that we're actually in a position to find out the moral truth. (At least that this is possible in theory, under the best imaginable circumstances.)<br><br>There's an endnote in a later post in my series that's quite relevant to this discussion. The post is <a href=\"https://forum.effectivealtruism.org/posts/SotZAFkGbgBEFBnQX/moral-uncertainty-and-moral-realism-are-in-tension\">Moral uncertainty and moral realism are in tension</a>, and I'll quote the endnote here:&nbsp;</p><blockquote><p>Someone could object that convergence arguments [convergence arguments are a type of argument in favor of moral realism; they say that moral realism is true if sophisticated reasoners tend to converge in their moral views as they approach ideal reasoning conditions] are never strong enough to establish moral realism with high confidence. Firstly (1), what counts as \u201cphilosophically sophisticated reasoners\u201d or \u201cidealized reasoning conditions\u201d is under-defined. Arguably, subtle differences to these stipulations could influence whether convergence arguments work out. Secondly (2), even conditional on expert convergence, we couldn\u2019t be sure whether it reflects the existence of a speaker-independent moral reality. Instead, it could mean that our philosophically sophisticated reasoners happen to have the same <i>subjective</i> values. Thirdly (3), what reasoners consider self-evident may change over time. Wouldn\u2019t sophisticated reasoners born in (e.g.) the 17th century disagree with what we consider self-evident today? Those are forceful objections. If we only applied the most stringent criteria for what counts as \u201cmoral realism,\u201d we\u2019d arguably be left with moral non-naturalism (\u201cirreducible normativity\u201d). After all, the only reason some philosophers consider non-naturalism (with its strange metaphysical postulates) palatable is because they find moral naturalism <i>too watered down</i> as an alternative. Still, I would consider convergence among a pre-selected set of expert reasoners both relevant and surprising. Therefore, I\u2019m inclined to consider naturalist moral realism an intelligible hypothesis. I think it\u2019s <i>false</i>, but I could imagine situations where I\u2019d change my mind. Here are some quick answers to the objections above: (1) We can imagine circumstances where the convergence <i>isn\u2019t</i> sensitive to the specifics; naturalist moral realism is meant to apply at least under those circumstances. (2) Without the concept of \u201cirreducible normativity,\u201d <i>any</i> answers in philosophy will be subjective in some sense of the word (they have to somehow appeal to our reasoning styles). Still, convergence arguments would establish that there are for-us relevant insights at the end of moral reflection, and that the destination is the same for everyone! (3) When I talk about \u201cmorality,\u201d I already have in mind some implicit connotations that the concept has to fulfill. Specifically, I consider it an essential ingredient to morality to take an \u201cimpartial stance\u201d of some sort. To the degree that past reasoners didn\u2019t do this, I\u2019d argue that they were answering a different question. (When I investigate whether moral realism is true, I\u2019m not interested in whether everyone who ever used the word \u201cmorality\u201d was talking about the exact same thing!) Among past philosophers who saw morality as impartial altruism, we actually find a surprising degree of moral foresight. Jeremy Bentham\u2019s Wikipedia article reads as follows: <i>\u201cHe advocated individual and economic freedoms, the separation of church and state, freedom of expression, equal rights for women, the right to divorce, and (in an unpublished essay) the decriminalising of homosexual acts. He called for the abolition of slavery, capital punishment and physical punishment, including that of children. He has also become known as an early advocate of animal rights.\u201d</i> To get a sense for the clarity and moral thrust of Bentham\u2019s reasoning, see also this now-famous quote: <i>\u201cThe day may come when the rest of the animal creation may acquire those rights which never could have been withholden from them but by the hand of tyranny. The French have already discovered that the blackness of the skin is no reason why a human being should be abandoned without redress to the caprice of a tormentor. It may one day come to be recognised that the number of the legs, the villosity of the skin, or the termination of the os sacrum, are reasons equally insufficient for abandoning a sensitive being to the same fate. What else is it that should trace the insuperable line? Is it the faculty of reason, or perhaps the faculty of discourse? But a fullgrown horse or dog is beyond comparison a more rational, as well as a more conversable animal, than an infant of a day, or a week, or even a month, old. But suppose they were otherwise, what would it avail? The question is not, Can they reason? nor Can they talk? but, Can they suffer?\u201d</i></p></blockquote><p>In the above endnote, I try to defend why I think my description of the One Compelling Axiology version of moral realism is a good steelman, despite some moral realists not liking it because I don't allow for the possibility that moral reality is forever unknowable to even the best human reasoners under ideal reasoning conditions.</p><blockquote><p>This part reads to me as if you'd been asked \"what would change your mind\" and you responded \"realistically, nothing.\" But then, my background involves banging my head against the wall with <a href=\"https://medium.com/big-picture/talking-to-climate-deniers-514177e31888\">climate dismissives</a>, so I have a visceral understanding that \"science advances one funeral at a time\" as Max Planck said. So my next thought, more charitably, is \"well, maybe Lukas will make his judgement from the perspective of an imagined future where all necessary funerals have already taken place.\"</p></blockquote><p>Definitely! I'm assuming \"ideal reasoning conditions\" \u2013 a super high bar, totally unrealistic in reality. For the sort of thing I'm envisioning, see my post, <a href=\"https://forum.effectivealtruism.org/posts/6STzb6XBAyu3Xxxka/the-moral-uncertainty-rabbit-hole-fully-excavated\">The Moral Uncertainty Rabbit Hole, Fully Excavated</a>. Here's a quote from the section on \"reflection procedures\":&nbsp;</p><blockquote><p>Here\u2019s one example of a reflection environment:</p><ul><li><i><strong>My favorite thinking environment:</strong></i> Imagine a comfortable environment tailored for creative intellectual pursuits (e.g., a Google campus or a cozy mansion on a scenic lake in the forest). At your disposal, you find a well-intentioned, superintelligent AI advisor fluent in various schools of philosophy and programmed to advise in a value-neutral fashion. (Insofar as that\u2019s possible \u2013 since one cannot do philosophy without a specific methodology, the advisor must already endorse certain <a href=\"https://www.alignmentforum.org/posts/w6d7XBCegc96kz4n3/the-argument-from-philosophical-difficulty\">metaphilosophical</a> commitments.) Besides answering questions, they can help set up experiments in virtual reality, such as ones with <a href=\"https://www.fhi.ox.ac.uk/brain-emulation-roadmap-report.pdf\">emulations</a> of your brain or with modeled copies of your younger self. For instance, you can design experiments for learning what you'd value if you first encountered the EA community in San Francisco rather than in Oxford or started reading Derek Parfit or Peter Singer <i>after</i> the blog Lesswrong, instead of the other way around.<a href=\"https://forum.effectivealtruism.org/posts/6STzb6XBAyu3Xxxka/the-moral-uncertainty-rabbit-hole-fully-excavated#fn-3RbphKB2djKSeg8Tx-2\"><sup>[2]</sup></a> You can simulate conversations with select people (e.g., famous historical figures or contemporary philosophers). You can study how other people\u2019s reflection concludes and how their moral views depend on their life circumstances. In the virtual-reality environment, you can augment your copy\u2019s cognition or alter its perceptions to have it experience new types of emotions. You can test yourself for biases by simulating life as someone born with another gender(-orientation), ethnicity, or into a family with a different socioeconomic status. At the end of an experiment, your (near-)copies can produce write-ups of their insights, giving you inputs for your final moral deliberations. You can hand over authority about choosing your values to one of the simulated (near-)copies (if you trust the experimental setup and consider it too difficult to convey particular insights or experiences via text). Eventually, the person with the designated authority has to provide to your AI assistant a precise specification of values (the format \u2013 e.g., whether it\u2019s a utility function or something else \u2013 is up to you to decide on). Those values then serve as your idealized values after moral reflection.</li></ul><p>(Two other, more rigorously specified reflection procedures are <a href=\"https://ordinaryideas.wordpress.com/2012/04/21/indirect-normativity-write-up/\">indirect normativity</a> and <a href=\"https://ai-alignment.com/strong-hch-bedb0dc08d4e\">HCH</a>.<a href=\"https://forum.effectivealtruism.org/posts/6STzb6XBAyu3Xxxka/the-moral-uncertainty-rabbit-hole-fully-excavated#fn-3RbphKB2djKSeg8Tx-3\"><sup>[3]</sup></a> Indirect normativity outputs a utility function whereas HCH attempts to formalize \u201cidealized judgment,\u201d which we could then consult for all kinds of tasks or situations.)<a href=\"https://forum.effectivealtruism.org/posts/6STzb6XBAyu3Xxxka/the-moral-uncertainty-rabbit-hole-fully-excavated#fn-3RbphKB2djKSeg8Tx-4\"><sup>[4]</sup></a></p><p>\u201cMy favorite thinking environment\u201d leaves you in charge as much as possible while providing flexible assistance. Any other structure is for you to specify: you decide the reflection strategy.<a href=\"https://forum.effectivealtruism.org/posts/6STzb6XBAyu3Xxxka/the-moral-uncertainty-rabbit-hole-fully-excavated#fn-3RbphKB2djKSeg8Tx-5\"><sup>[5]</sup></a> This includes what questions to ask the AI assistant, what experiments to do (if any), and when to conclude the reflection.</p></blockquote><p>Part of the point of that quote is that there's some subjectivity about how to set up \"ideal reasoning conditions\" \u2013 but we can still agree that, for practical purposes, something like the above constitutes better reasoning conditions than what we have available today. And if the best reasoners in EA (for example) or some other context where people start out with good epistemics all tended to converge after that sort of reflection, I'd consider that strong evidence for (naturalist) moral realism, the way I prefer to define it. (But some philosophers would reject this steelman of moral realism and say that my position is always, by definition, anti-realism, no matter what we might discover in the future about expert convergence, because they only want to reason about morality with \"irreducible\" concepts, i.e., non-naturalist moral realism.)&nbsp;</p><blockquote><p>Please have a look at this <a href=\"https://twitter.com/DPiepgrass/status/1645492780175872000\">summary of my views</a> on Twitter. My question is, how does this view fit into the philosophy landscape?</p></blockquote><p>Definitely seems realist. I'm always a bit split whether people who place a lot of weight on qualia in their justification for moral realism are non-naturalists or naturalists. They often embrace moral naturalism themselves, but there's a sense in which I think that's illegitimately trying to have their cake and eat it. See <a href=\"https://forum.effectivealtruism.org/posts/oXhhxeQMBjJriMjb8/dismantling-hedonism-inspired-moral-realism?commentId=ehftbbCNdR4QshHpA\">this comment discussion here</a> below my post on hedonist moral realism and qualia-inspired views.<br><br>&nbsp;I haven't found the time to look through your summary of views on Twitter in much detail, but my suspicion is that you'd run into difficulties defining what it means for morality to be real/part of the territory and also have that be defined independently of \"whatever causes experts to converge their opinions under ideal reasoning conditions.\"&nbsp;</p>", "parentCommentId": "4CasFeEZQwLLLPbej", "user": {"username": "Lukas_Gloor"}}, {"_id": "YL28FJi7dHanguy4d", "postedAt": "2023-09-19T17:16:57.402Z", "postId": "TwJb75GtbD4LvGiku", "htmlBody": "<blockquote><p>my suspicion is that you'd run into difficulties defining what it means for morality to be real/part of the territory and also have that be defined independently of \"whatever causes experts to converge their opinions under ideal reasoning conditions.\"&nbsp;</p></blockquote><p>In the absence of new scientific discoveries about the territory, I'm not sure whether experts (even \"ideal\" ones) should converge, given that an absence of evidence tends to allow room for personal taste. For example, can we converge on the morality of abortion, or of factory farms, without understanding what, in the territory, leads to the moral value of persons and animals? I think we can agree that less factory farming, less meat consumption and fewer abortions are better all else being equal, but in reality we face tradeoffs \u2015 potentially less enjoyable meals (luckily there's Beyond Meat); children raised by poor single moms who didn't want children.</p><p>I don't even see how we can conclude that higher populations are better, as EAs often do, for (i) how do we detect what standard of living is better than non-existence, or how much suffering is worse than non-existence, (ii) how do we rule out the possibility that the number of beings does not scale linearly with the number of monadal experiencers, and (iii) we need to balance the presumed goodness of higher population against a higher catastrophic risk of exceeding Earth's carrying capacity, and (iv) I don't see how to rule out that things other than valence (of experiences) are morally (terminally) important. Plus, how to value the future is puzzling to me, appealing as longtermism's linear valuation is.</p><p>So while I'm a moral realist, (i) I don't presume to know what the moral reality actually is, (ii) my moral judgements tend to be provisionary and (iii) I don't expect to agree on everything with a hypothetical clone of myself who starts from the same two axioms as me (though I expect we'd get along well and agree on many key points). But what everybody in my school of thought should agree on is that scientific approaches to the Hard Problem of Consciousness are important, because we can probably act morally better after it is solved. I think even some approaches that are generally considered morally unacceptable by society today are worth consideration, e.g. destructive experiments on the brains of terminally ill patients who (of course) gave their consent for these experiments. (it doesn't make sense to do such experiments today though: before experiments take place, plausible hypotheses must be developed that could be falsified by experiment, and presumably any possible useful nondestructive experiments should be done first.)</p><p>[Addendum:]</p><blockquote><p>I'm always a bit split whether people who place a lot of weight on qualia in their justification for moral realism are non-naturalists or naturalists.</p></blockquote><p>Why? At the link you said \"<i>I'd think she's saying that pleasure has a property that we recognize as \"what we should value\" in a way that somehow is still a naturalist concept. I don't understand that bit.</i>\" But by the same token \u2015 if I assume Hewitt talking about \"pleasure\" is essentially the same thing as me talking about \"valence\" \u2015 I don't understand why you seem to think it's \"illegitimate\" to suppose valence exists in the territory, or what you think is there instead.</p>", "parentCommentId": "C6LSmEsXvWRHZBQPi", "user": {"username": "dpiepgrass"}}, {"_id": "9cxoDbg7xLwP8ybbm", "postedAt": "2023-09-19T18:38:32.562Z", "postId": "TwJb75GtbD4LvGiku", "htmlBody": "<blockquote><p>So while I'm a moral realist, (i) I don't presume to know what the moral reality actually is</p></blockquote><p>If you don't think you know what the moral reality is, why are you confident that there is one?<br><br>I discuss possible answers to this question <a href=\"https://forum.effectivealtruism.org/posts/SotZAFkGbgBEFBnQX/moral-uncertainty-and-moral-realism-are-in-tension\">here</a> and explain why I find all of the unsatisfying.&nbsp;<br><br>The only realism-compatible position I find somewhat defensible is something like \"It may turn out that morality isn't a crisp concept in thingspace that gives us answers to all the contested questions (population ethics, comparing human lives to other sentient beings, preferences vs hedonism, etc), but we don't know yet. It may also turn out that as we learn more about the various options and as more facts about human minds and motivation and so on come to light, there will be a theory that 'stands out' as the obvious way of going about altruism/making the world better. Therefore, I'm not yet willing to call myself a confident moral anti-realist.\"<br><br>That said, I give some arguments in my sequence why we shouldn't expect any theory to 'stand out' like that. I believe these questions will remain difficult forever and competent reasoners will often disagree on their respective favorite answers.</p><blockquote><p>Why? At the link you said \"<i>I'd think she's saying that pleasure has a property that we recognize as \"what we should value\" in a way that somehow is still a naturalist concept. I don't understand that bit.</i>\" But by the same token \u2015 if I assume Hewitt talking about \"pleasure\" is essentially the same thing as me talking about \"valence\" \u2015 I don't understand why you seem to think it's \"illegitimate\" to suppose valence exists in the territory, or what you think is there instead.</p></blockquote><p>This goes back to the same disagreement we're discussing, the one about expert consensus or lack thereof. The naturalist version of \"value is a part of the territory\" would be that when we introspect about our motivation and the nature of pleasure and so on, we'll agree that pleasure is what's valuable. However, empirically, many people don't conclude this; they aren't hedonists. (As I defend in the post, I think they aren't thereby making any sort of mistake. For instance, it's simply false that non-hedonist philosophers would categorically be worse at constructing thought experiments to isolate confounding variables for assessing whether we value things other than pleasure only instrumentally. I could totally pass the Ideological Turing test for why some people are hedonists. I just don't find the view compelling myself.)&nbsp;</p><p>At this point, hedonists could either concede that there's no sense in which hedonism is true for everyone \u2013 because not everyone agrees.&nbsp;<br><br>Or they can say something like \"Well, it may not seem to you that you're making a mistake of reasoning, but pleasure has this property that it is GOOD in a normative sense irreducible to any of your other dispositions, and you're missing that, so you ARE making a mistake about normativity, even if you say you don't care.\"&nbsp;<br><br>And then we're back to \"How do they know this?\" and \"What's the point of 'normativity' if it's disconnected to what I (on reflection) want/what motivates me?\" Etc. It's the same disagreement again. The reason I believe Hewitt and others want to have their cake and eat is because they want to simultaneously (1) downplay the relevance of empirical information about whether sophisticated reasoners find hedonism compelling (2) while still claiming that hedonism is correct in some direct, empirical sense, which makes it \"part of the territory.\" The tension here is that claiming that \"hedonism is correct in some direct, empirical sense\" would predict expert convergence.</p>", "parentCommentId": "YL28FJi7dHanguy4d", "user": {"username": "Lukas_Gloor"}}, {"_id": "ieAycDmEgnpnxc5Nh", "postedAt": "2023-09-19T20:36:26.962Z", "postId": "TwJb75GtbD4LvGiku", "htmlBody": "<blockquote><p>If you don't think you know what the moral reality is, why are you confident that there is one?</p></blockquote><p>I am confident that <strong>if</strong> there is no territory relevant to morality, then illusionism is true and (paradoxically) it doesn't matter what our maps contain because the brains that contain the maps do not correlate with any experiences in base reality. I therefore ignore illusionism and proceed with the assumption that there is something real, that it is linked to brains and correlates positively with mental experience, that it is scientifically discoverable, and that prior to such a discovery we can derive reasonable models of morality grounded in our current body of scientific/empirical information.</p><blockquote><p>The naturalist version of \"value is a part of the territory\" would be that when we introspect about our motivation and the nature of pleasure and so on, we'll agree that pleasure is what's valuable.</p></blockquote><p>I don't see why \"introspecting on our motivation and the nature of pleasure and so on\" should be what \"naturalism\" means, or why a moral value discovered that way necessarily corresponds with the territory. I expect morally-relevant territory to have similarities to other things in physics: to be somehow simple, to have existed long before humans did, and to somehow interact with humans. By the way, I prefer to say \"positive valence\" over \"pleasure\" because laymen would misunderstand the latter.</p><blockquote><p>At this point, hedonists could either concede that there's no sense in which hedonism is true for everyone \u2013 because not everyone agrees.&nbsp;</p></blockquote><p>I don't concede because people having incorrect maps is expected and tells me little about the territory.</p><blockquote><p>Or they can say something like \"Well, it may not seem to you that you're making a mistake of reasoning, but pleasure has this property that it is GOOD in a normative sense irreducible to any of your other dispositions</p></blockquote><p>I'm not sure what these other dispositions are, but I'm thinking on a level below normativity. I say positive valence is good because, at a level of fundamental physics, it is the best candidate I am aware of for what <i>could</i> be (terminally) good. If you propose that \"knowledge is terminally good\", for example, I wouldn't dismiss it entirely, but I don't see how human-level knowledge would have a physics-level meaning. It does seem like something related to knowledge, namely comprehension, is part of consciousness, so maybe comprehension is terminally good, but if I could only pick one, it seems to me that valence is a better candidate because \"obviously\" pleasure+bafflement &gt; torture+comprehension. (fwiw I am thinking that the <i>human sense</i> of comprehension differs from genuine comprehension, and both might even differ from physics-level comprehension if it exists. If a philosopher terminally values the second, I'd call that valuation nonrealist.)</p><blockquote><p>claiming that \"hedonism is correct in some direct, empirical sense\" would predict expert convergence.</p></blockquote><p>\ud83e\udd37\u200d\u2642\ufe0f Why? When you say \"expert\", do you mean \"moral realist\"? But then, which kind of moral realist? Obviously I'm not in the Foot or Railton camp \u2015 in my camp, moral uncertainty follows readily from my axioms, since they tell me there is <i>something</i> morally real, but not what it is.</p><p>Edit: It would certainly be interesting if other people start from similar axioms to <a href=\"https://twitter.com/DPiepgrass/status/1645524942656778241\">mine</a> but diverge in their moral opinions. Please let me know if you know of philosopher(s) who start from similar axioms.</p>", "parentCommentId": "9cxoDbg7xLwP8ybbm", "user": {"username": "dpiepgrass"}}, {"_id": "7n8X5Ymajb6oq9w9u", "postedAt": "2023-09-19T22:45:54.136Z", "postId": "TwJb75GtbD4LvGiku", "htmlBody": "<blockquote><p>I don't concede because people having incorrect maps is expected and tells me little about the territory.</p></blockquote><p>I'm clearly talking about expert convergence under ideal reasoning conditions, as discussed earlier. Weird that this wasn't apparent. In physics or any other scientific domain, there's no question whether experts would eventually converge if they had ideal reasoning conditions. That's what makes these domains scientifically valid (i.e., they study \"real things\"). Why is morality different? (No need to reply; it feels like we're talking in circles.)</p><p>FWIW, I think it's probably consistent to have a position that includes (1) a <i>wager</i> for moral realism (\"if it's not true, then nothing matters\" \u2013 your wager is about the importance of qualia, but I've also seen similar reasoning around normativity as the bedrock, or free will), and (2), a simplicity/\"lack of plausible alternatives\" argument for hedonism. This sort of argument for hedonism only works if you take realism for granted, but that's where the wager comes in handy. (Still, one could argue that <a href=\"https://longtermrisk.org/tranquilism/\">tranquilism</a> is 'simpler' than hedonism and therefore more likely to be the one true morality, but okay.) Note that this combination of views isn't quite \"being confident in moral realism,\" though. It's only \"confidence in acting as though moral realism is true.\"</p><p>I talk about wagering on moral realism in <a href=\"https://forum.effectivealtruism.org/posts/BYjj4WdrxgPJxMre9/metaethical-fanaticism-dialogue\">this dialogue</a> and the preceding post. In short, it seems fanatical to me if taken to its conclusions, and I don't believe that many people really believe this stuff deep down without any doubt whatsoever. Like, if push comes to shove, do you really have more confidence in your understanding of illusionism vs other views in philosophy of mind, or do you have more confidence in wanting to reduce the thing that Brian Tomasik calls suffering, when you see it in front of you (regardless of whether illusionism turns out to be true)? (Of course, far be it from me to discourage people from taking weird ideas seriously; I'm an EA, after all. I'm just saying that it's worth reflection if you really buy into that wager wholeheartedly, or if you have some meta uncertainty.)<br><br>I also talk a bit about consciousness realism in <a href=\"https://forum.effectivealtruism.org/posts/6nPnqXCaYsmXCtjTk/why-realists-and-anti-realists-disagree#fn-tL4dDJ5GABx9GbWAg-18\">endnote 18</a> of my post \"Why Realists and Anti-Realists Disagree.\" I want to flag that I personally don't understand why consciousness realism would necessarily imply moral realism. I guess I can see that it gets you closer to it, but I think there's more to argue for even with consciousness realism. In any case, I think illusionism is being strawmanned in that debate. Illusionists aren't denying anything worth wanting. Illusionists are only denying something that never made sense in the first place. It's the same as compatibilists in the free will debate: you never wanted \"true free will,\" whatever that is. Just like one can be mistaken about one's visual field having lots of details even at the edges, or how some people with a brain condition can be mistaken about seeing stuff when they have blindsight, illusionists claim that people can be mistaken about some of the properties they ascribe to consciousness. They're not mistaken about a non-technical interpretation of \"it feels like something to be me,\" because that's just how we describe the fact that there's something that both illusionists and qualia realists are debating. However, illusionists claim that qualia realists are mistaken about a <i>philosophically-loaded</i> interpretation of \"it feels like something to be me,\" where the hidden assumption is something like \"feeling like something is a property that is either on or off for something, and there's <i>always a fact of the matter</i>.\" See the dialogue in endnote 18 of that post on why this isn't correct (or at least why we cannot infer this from our experience of consciousness.) (This debate is btw very similar to the moral realism vs anti-realism debate. There's a sense in which anti-realists aren't denying that \"torture is wrong\" in a loose and not-too-philosophically loaded sense. They're just denying that based on \"torture is wrong,\" we can infer that there's a fact of the matter about all courses of action \u2013 whether they're right or wrong.) Basically, the point I'm trying to make here is that illusionists aren't disagreeing with you if you say your conscious. They're only disagreeing with you when, based on introspecting about your consciousness, you now claim that you know that an omniscient being could tell about every animal/thing/system/process whether it's conscious or not, that there must be a fact of the matter. But just because it feels to you like there's a fact of the matter doesn't mean that there may not be myriads of edge cases where we (or experts under ideal reasoning conditions) can't draw crisp boundaries about what may or may not be 'conscious.' &nbsp;That's why illusionists like Brian Tomasik end up saying that consciousness is about what kind of algorithms you care about.</p>", "parentCommentId": "ieAycDmEgnpnxc5Nh", "user": {"username": "Lukas_Gloor"}}, {"_id": "hzmoGGLMqW4vR6mfA", "postedAt": "2023-10-18T13:52:14.963Z", "postId": "TwJb75GtbD4LvGiku", "htmlBody": "<p>Empty individualism is quite different from open individualism.&nbsp;<br>Empty individualism says that you only exist during the present fraction of a second. This leads to the conclusion that no matter what action you take, the amount of pain or pleasure you will experience as a consequence thereof will remain zero. This therefore leads to nihilism.<br>Open Individualism on the other hand says that you will be repeatedly reincarnated as every human that will ever live. In the words of David Pearce: \u201cIf open individualism is true, then the distinction between decision-theoretic rationality and morality (arguably) collapses. An intelligent sociopath would do the same as an intelligent saint; it\u2019s all about me.\u201d&nbsp;<br>This means that the egoistic sociopaths would change themselves into altruists of sorts.<br><br>The only way I know of in which empty individualism can lead towards open individualism works as follows:<br>When choosing which action to take, one should select the action which leads to the least amount of suffering for oneself. If there were a high probability that empty individualism is true and a very small but non-zero probability that open individualism is true, one would still have to take the action dictated by open individualism because empty individualism stays neutral with regads to which action to take, thereby making itself irrelevant.<br><br>Note however that empty individualism vs open individualism is a false dichotomy as there are other contenders such as closed individualism which is the common-sensical view, at least here in the West. So since empty individualism makes itself irrelevant, at least for now the contention is just between open individualism and closed individualism. It would in principle certainly be possible to calculate whether open individualism or closed individualism is more likely to be true. Furthermore, it would be possible to calculate whether AGI would be open individualist towards humanity or not. To conduct such a caclulation successfully before the singularity would however require a collaboration between many theoreticians.</p>", "parentCommentId": "Yt8hMhgBfHgHmNgiX", "user": {"username": "g@leuenberger.ai"}}]