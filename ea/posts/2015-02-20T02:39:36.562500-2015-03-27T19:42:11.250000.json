[{"_id": "MA5dFrnnB2PLAmTsw", "title": "The Path to Biomedical Progress", "postedAt": "2015-02-27T13:52:34.948Z", "htmlBody": "<p><i>Note: Before the launch of the Open Philanthropy Project Blog, this post appeared on the </i><a href=\"http://blog.givewell.org/\"><i>GiveWell Blog</i></a><i>. Uses of \u201cwe\u201d and \u201cour\u201d in the below post may refer to the Open Philanthropy Project or to GiveWell as an organization. Additional comments may be available at the </i><a href=\"http://blog.givewell.org/2015/02/27/the-path-to-biomedical-progress/\"><i>original post</i></a><i>.</i></p><p><i>We\u2019ve continued to look into </i><a href=\"https://www.openphilanthropy.org/focus/scientific-research\"><i>scientific research funding</i></a><i> for the purposes of the </i><a href=\"https://www.openphilanthropy.org/blog\"><i>Open Philanthropy Project</i></a><i>. This hasn\u2019t been a high priority for the last year, and our investigation remains preliminary, but I plan to write several posts about what we\u2019ve found so far. Our early focus has been on biomedical research specifically.</i></p><p>Most useful new technologies are the product of many different lines of research, which progress in different ways and on different time frames. I think that when most people think about scientific research, they tend to instinctively picture only a subset of it. For example, people hoping for better cancer treatment tend instinctively to think about \u201cstudying cancer\u201d as opposed to \u201cstudying general behavior of cells\u201d or \u201cstudying microscopy techniques,\u201d even though all three can be essential for making progress on cancer treatment. Picturing only a particular kind of research can affect the way people choose what science to support.</p><p>I\u2019m planning to write a fair amount about what I see as promising approaches to biomedical sciences philanthropy. Much of what I\u2019m interested in will be hard to explain without some basic background and vocabulary around different types of research, and I\u2019ve been unable to find an existing guide that provides this background. (Indeed, many of what I consider \u201coverlooked opportunities to do good\u201d may be overlooked because of donors\u2019 tendencies to focus on the easiest-to-understand types of science.)</p><p>This post will:</p><ul><li>Lay out a basic guide to the roles of different types of biomedical research: improving tools and techniques, studying healthy biological processes, studying diseases and conditions of interest, generating possible treatments, preliminarily evaluating possible treatments, and clinical trials.</li><li>Use the example of the cancer drug Herceptin to compare the roles of these different sorts of research more concretely.</li><li>Go through what I see as some common misconceptions that stem from overfocusing on a particular kind of research, rather than on the complementary roles of many kinds of research.</li></ul><h1>Basic guide to the roles of different types of biomedical research</h1><figure class=\"image\"><img src=\"http://blog.givewell.org/wp-content/uploads/2015/02/pathtobiomedicalprogress-31.png\"></figure><p>Below are some distinctions I\u2019ve found it helpful to draw between different kinds of research. This picture is highly simplified: many types of research don\u2019t fit neatly into one category, and the relationships between the different categories can be complex: any type of research can influence any other kind. In the diagram to the right (click to expand), I\u2019ve highlighted the directions of influence I believe are generally most salient.</p><p><strong>(A) Improving tools and techniques.</strong> Biomedical researchers rely on a variety of tools and techniques that were largely developed for the general purpose of measuring and understanding biological processes, rather than with any particular treatment or disease/condition in mind. Well-known examples include microscopes and <a href=\"http://en.wikipedia.org/wiki/DNA_sequencing\">DNA sequencing</a>, both of which have been essential for developing more specific knowledge about particular diseases and conditions. More recent examples include <a href=\"http://en.wikipedia.org/wiki/CRISPR\">CRISPR-related gene editing techniques</a>, <a href=\"http://en.wikipedia.org/wiki/RNA_interference\">RNA interference</a>, and <a href=\"http://www.nobelprize.org/nobel_prizes/medicine/laureates/2007/\">using embryonic stem cells to genetically modify mice</a>. All three of these provide ways of experimenting with changes in the genetic code and seeing what results. The former two may have direct applications for treatment approaches in addition to their value in research; the latter two were both <a href=\"http://www.nobelprize.org/nobel_prizes/medicine/laureates/\">relatively recently honored with Nobel Prizes.</a> Improvements in tools and techniques can be a key factor in improving most kinds of research on this list. Sometimes improvements in tools and techniques (e.g., faster/cheaper DNA sequencing; more precise microscopes) can be as important as the development of new ones.</p><p><strong>(B) Studying healthy biological processes.</strong> Basic knowledge about how cells function, how the immune system works, the nature of DNA, etc. has been essential to much progress in biomedical research. Many of the recent <a href=\"http://www.nobelprize.org/nobel_prizes/medicine/laureates/\">Nobel Prizes in Physiology or Medicine</a> were for work in this category, some of which led directly to the development of new tools and techniques (as in the case of CRISPR-based gene editing, which is drawn from insights about bacterial immune systems).</p><p><strong>(C) Studying diseases and conditions of interest.</strong> Much research focuses on understanding exactly what causes a particular disease and condition, as specifically and mechanistically as possible. Determining that a disease is caused by bacteria, a virus, or by a particular overactive gene or protein can have major implications for how to treat it; for example, <a href=\"http://en.wikipedia.org/wiki/Imatinib#History\">the cancer drug Gleevec was developed by looking for a drug that would bind to a particular protein</a>, which researchers had identified as key to a particular cancer. Note that (C) and (B) can often be tightly intertwined, as studying differences between healthy and diseased organisms can tell us a great deal both about the disease of interest and about the general ways in which healthy organisms function. However, (B) may have more trouble attracting support from non-scientists, since the applications can be less predictable and clear.</p><p><strong>(D) Generating possible treatments.</strong> No matter how much we know about the causes of a particular disease/condition, this doesn\u2019t guarantee that we\u2019ll be able to find an effective treatment. Sometimes (as with Herceptin - more below) treatments will suggest themselves based on prior knowledge; other times the process comes down largely to trial and error. For example, malaria researchers know a fair amount about the parasite that causes malaria, but have only identified a limited number of chemicals that can kill it; because of the ongoing threat of drug resistance developing, they continue to go through many thousands of chemicals per year in a trial-and-error process, checking whether each shows potential for killing the relevant parasite. (<a href=\"http://files.givewell.org/files/conversations/Micah%20Manary%208-28%20and%209-30-14%20%28public%29.pdf\">Source</a>)</p><p><strong>(E) Preliminarily evaluating possible treatments</strong> (sometimes called \u201cpreclinical\u201d work). Possible treatments are often first tested \u201cin vitro\u201d - in a simplified environment, where researchers can isolate how they work. (For example, <a href=\"http://files.givewell.org/files/conversations/Micah%20Manary%208-28%20and%209-30-14%20%28public%29.pdf\">seeing whether a chemical can kill isolated parasites in a dish</a>.) But ultimately, a treatment\u2019s value depends on how it interacts with the complex biology of the human body, and whether its benefits outweigh its side effects. Since clinical trials (next paragraph) are extremely expensive and time-consuming, it can be valuable to first test and refine possible treatments in other ways. This can include animal testing, as well as other methods for predicting a treatment\u2019s performance.</p><p><strong>(F) Clinical trials.</strong> Before a treatment comes to market, it usually goes through <a href=\"https://clinicaltrials.gov/ct2/about-studies/learn\">clinical trials</a>: studies (often highly rigorous experiments) in which the treatment is given to humans and the results are assessed. Clinical trials <a href=\"https://grants.nih.gov/policy/clinical-trials/glossary-ct.htm#ClinicalTrial\">typically involve four different phases</a>: early phases focused on safety and preliminary information, and later phases with larger trials focused on definitively understanding the drug\u2019s effects. Many people instinctively picture clinical trials when they think about biomedical research, and clinical trials account for a great deal of research spending (<a href=\"http://www.appliedclinicaltrialsonline.com/sizing-clinical-research-market\">one estimate</a>, which I haven\u2019t vetted, is that clinical trials cost tens of billions of dollars a year, over half of industry R&amp;D spending). However, the number of clinical trials going on generally is - or should be - a function of the promising leads that are generated by other types of research, and the most important leverage points for improving treatment are often within these other types of research.</p><p>(A) - (C) are generally associated with academia, while (D) - (F) are generally associated with industry. There are a variety of more detailed guides to (D) - (F), often referred to as the \u201cdrug discovery process\u201d (<a href=\"http://phrma-docs.phrma.org/sites/default/files/pdf/rd_brochure_022307.pdf\">example</a>).</p><h1>Example: Herceptin</h1><p><a href=\"http://en.wikipedia.org/wiki/Trastuzumab\">Herceptin</a></p><p>&nbsp;is a drug used for certain breast cancers, first approved in 1998. Its development relied on relatively recent insights and techniques, and it is notable for its relative lack of toxicity and side effects compared to other cancer drugs. I perceive it as one of the major recent success stories of biomedical research (in terms of improving treatment, as opposed to gaining knowledge) - it was <a href=\"http://www.fiercepharma.com/special-reports/10-best-selling-drugs-2013\">one of the best-selling drugs of 2013</a> - and it\u2019s an unusually easy drug to trace the development of because there is a book about it, <a href=\"http://www.amazon.com/Her-2-Making-Herceptin-Revolutionary-Treatment/dp/0812991842/ref=sr_1_1?ie=UTF8&amp;qid=1419567535&amp;sr=8-1&amp;keywords=her2\"><i>Her-2: The Making of Herceptin</i></a> (which I recommend).</p><p>Here I list, in chronological order, some of the developments which seem to have been crucial for developing Herceptin. My knowledge of this topic is quite limited, and I don\u2019t mean this as an exhaustive list. I also wish to emphasize that many of the items on this list were the result of general inquiries into biology and cancer - they weren\u2019t necessarily <i>aimed</i> at developing something like Herceptin, but they ended up being crucial to it. Throughout this summary, I note which of the above types of research were particularly relevant, using the same letters in parentheses that I used above.</p><ul><li>In the 1950s, there was a great deal of research focused on understanding the <a href=\"http://en.wikipedia.org/wiki/Genetic_code\">genetic code</a> (B). For purposes of this post, it\u2019s sufficient to know that a <i>gene</i> serves the function of a set of instructions for building a <i>protein</i>, a kind of molecule that can come in many different forms serving a variety of biological functions. The research that led to understanding the genetic code was itself helped along by multiple new tools and techniques (A) such as Linus Pauling\u2019s techniques for modeling possible three-dimensional structures (<a href=\"http://www.nature.com/scitable/topicpage/discovery-of-dna-structure-and-function-watson-397\">more</a>).</li><li>In the 1970s, studies on chicken viruses that were associated with cancer led to establishing the idea of an <i>oncogene</i>: a particular gene (often resulting from a mutation) that, when it occurs, causes cancer. (C)</li><li>In 1983, several scientists established a link between oncogenes and a particular sort of protein called epidermal growth factor receptors (EGFRs), which give cells instructions to grow and proliferate. In particular, they determined that a particular EGFR was identical to the protein associated with a known chicken oncogene. This work was a mix of (B) and (C), as it grew partly out of a general interest in the role played by EGFRs. It also required being able to establish which gene coded for a particular protein, using techniques that were <a href=\"http://en.wikipedia.org/wiki/Molecular_cloning#History_of_molecular_cloning\">likely established in the 1970s or later</a> (A).</li><li>In 1986, an academic scientist collaborated with Genentech to analyze the genes present in a series of cancerous tumors, and cross-reference them with a list of possible cancer-associated EGFRs (C). One match involved a particular gene called <i>HER2/neu</i>; tumors with this gene (in a mutated form) showed excessive production of the associated protein, which suggested that (a) the mutated <i>HER2/neu</i> gene was overproducing HER2/neu proteins, causing excessive cell proliferation and thus cancer; (b) this particular sort of cancer might be mitigated if one could destroy or disable HER2/neu proteins. This work likely benefited from advances in being able to \u201cread\u201d a genetic code more cheaply and quickly.</li><li>The next step was to find a drug that could destroy or disable the HER2/neu proteins (D). This was done using a relatively recent technique (A), <a href=\"http://en.wikipedia.org/wiki/Monoclonal_antibody\">developed in the 1970s</a>, that relied on a strong understanding of the immune system (B) and of another sort of cancer that altered the immune system in a particular way (C). Specifically, researchers were able to mass-produce antibodies designed to recognize and attach to the EGFR in question, thus signaling the immune system to destroy them.</li><li>At that time, monoclonal antibodies (mass-produced antibodies as described above) were seen as highly risky drug candidates, since they were produced from other animals and likely to be rejected by human immune systems. However, in the midst of the research described above, a new technique (A) was created for getting the body to accept these antibodies, greatly improving the prospects for getting a drug.</li><li>Researchers then took advantage of a relatively recent technique (A) for inserting human tumors into modified mice, which allowed them to test the drug and produce compelling preliminary evidence (E) that the drug might be highly effective.</li><li>At this point - 1988 - there was a potential drug and some supportive evidence behind it, but its ultimate effect on cancer in humans was unknown. It would be another ten years before the drug went through all relevant clinical trials (F) and received FDA approval, under the name Herceptin. <i>Her-2: The Making of Herceptin</i> gives a great deal of detail on the challenges of this period.</li></ul><p>As detailed above, many essential insights necessary for Herceptin\u2019s development came out very long before the idea of Herceptin had been established. My impression is that most major biomedical breakthroughs of the last few decades have a similar degree of reliance on a large number of previous insights, many of them fundamentally concerning tools and techniques (A) or the functioning of healthy organisms (B) rather than just disease-specific discoveries.</p><h1>General misperceptions that can arise from over-focusing on certain types of research</h1><p>I believe that science supporters often have misperceptions about the promising paths to progress, stemming from picturing only certain types of research. Below, I informally list some of these misperceptions, as informal non-attributed quotes.</p><ul><li>\u201cPublicly funded research is unnecessary; the best research is done in the for-profit sector.\u201d My impression is that most industry research falls into categories (D)-(F). (A)-(C), by contrast, tend to be a poor fit for industry research, because they are so far removed from treatments both in terms of time and risk. Because it is so hard to say what the eventual use is of a new tool/technique or insight into healthy organisms, it is likely more efficient for researchers to put insights into the public domain rather than trying to monetize them directly.</li><li>\u201cDrug companies don\u2019t do valuable research - they just monetize what academia provides them for free.\u201d This is the flipside of the above misconception, and I think it overfocuses on (A)-(C) without recognizing the challenges and costs of (D)-(F). Given the very high expenses of research in categories (D)-(F), and the current norms and funding mechanisms of academia, (D)-(F) are not a good fit for academia.</li><li>\u201cThe best giving opportunities will be for diseases that aren\u2019t profitable for drug companies to work on.\u201d This might be true for research in categories (D)-(F), but one should also consider research in categories (A)-(C); this research is generally based on a different set of incentives from those of drug companies, and so I\u2019d expect the best giving opportunities to follow a different pattern.</li><li>\u201cMuch more is spent on disease X than disease Y; therefore disease Y is underfunded.\u201d I think this kind of statement often overweights the importance of (F), the most expensive but not necessarily most crucial category of research. If more is spent on disease X than on disease Y, this may be simply because there are more promising clinical trial candidates for disease X than disease Y. Generally, I am wary of \u201ctotal spending\u201d figures that include clinical trials; I don\u2019t think such figures necessarily tell us much about society\u2019s priorities.</li><li>\u201cAcademia is too focused on knowledge for its own sake; we need to get it to think more about practical solutions and treatments.\u201d I believe this attitude undervalues (A)-(B) and understates how important general insights and tools can be.</li><li>\u201cWe should focus on funding research with a clear hypothesis, preliminary support for the hypothesis, and a clear plan for further testing the hypothesis.\u201d I\u2019ve heard multiple complaints that much of the NIH takes this attitude in allocating funding. Research in category (A) is often not hypothesis-driven at all, yet can be very useful. More on this in a future post.</li><li>\u201cThe key obstacles to biomedical progress are related to reproducibility and reliability of studies.\u201d I think that reproducibility is important, and potentially relevant to most types of research, but it is most core to clinical trials (F). Studies on humans are generally expensive and long-running, and so they may affect policy and practice for decades without ever being replicated. By contrast, for many other kinds of research, there is some cheap effective \u201creplication\u201d - or re-testing of the basic claims - via researchers trying to build on insights in their own lab work, so a non-reproducible study might in many cases mean a relatively modest waste of resources. I\u2019ve heard varying opinions on how much waste is created by reproducibility-related issues in early-stage research, and think it is possible that this issue is a major one, but it is far from clear that it is <i>the</i> key issue.</li></ul>", "user": {"username": "HoldenKarnofsky"}}, {"_id": "J2tmgAn8ne6Yhk27o", "title": "Half-assing it with everything you've got", "postedAt": "2015-03-13T06:30:20.822Z", "htmlBody": "<p>I hang out around a lot of <a href=\"http://www.effectivealtruism.org/\">effective altruists</a>. Many of them are motivated primarily by something like guilt (for having great resource and opportunity while others suffer) or shame (for not helping enough). Hell, many of my non-EA friends are primarily motivated by guilt or shame.</p><p>I'm not going to criticize guilt/shame motivation: I have this policy where, when somebody puts large amounts of effort or money towards making the world a better place, I try really hard not to condemn their motives. Guilt and shame may be fine tools for jarring people out of complacence. However, I worry that guilt and shame are unhealthy long-term motivators. In many of my friends, guilt and shame tend to induce akrasia, reduce productivity, and drain motivation. So over the next few weeks, I'll be writing a series of posts about removing guilt/shame motivation and replacing it with something stronger.</p><h1>1</h1><p>Say you're a college student, and you have a paper due. The quality of the paper will depend upon the amount of effort you put in. We'll say that you know the project pretty well: you can get an A with only moderate effort, and with significant effort you could produce something much better than the usual A-grade paper.</p><figure class=\"image\"><img src=\"http://mindingourway.com/content/images/2015/Mar/Quality0.png\"></figure><p>The education environment implicitly attempts to convince students that their preferences point ever rightward along this line. Parents and teachers say things like \"you should put in your best effort,\" and they heap shame upon people who don't strive to push ever rightward along the quality line.</p><p>People generally react to this coercion in one of two ways. The first group (the \"slackers\") rejects the implication that quality=preferences. These are the people who don't care about the class, who complain constantly about the useless pointless work they have to do, who half-ass the assignment and turn in something that either barely passes or fails entirely. Slackers tend to resent the authority forcing them to write the paper.</p><p>The second group (the \"tryers\") are the ones who accept the premise that quality=preferences, and strive ever rightwards on the quality line. Tryers include people of all ability levels: some struggle as hard as they can just to get a C, others flaunt their ability to produce masterpieces. Some try to curry favor with the teacher, others are perfectionists who simply can't allow themselves to turn in anything less than their best effort. Some of them are scrupulous people, who feel guilty even after getting an A, because they know they could have done better, and think they should have. Some are humble, some are show-offs, but all of them are pushing rightward.</p><p>Society has spent a <i>lot</i> of time conditioning us to think of the tryers as better than the slackers. Being a tryer is a virtue. Slackers are missing the point of education; why are they even there? The tryers are going to go places, the slackers will never amount to anything.</p><p>But in fact, both groups are doing it wrong.</p><p>If you want to be highly effective, <i>remember what you're fighting for.</i></p><p>And, spoiler alert, you aren't fighting for \"write a high-quality paper.\" That would be a pretty silly thing to fight for.</p><p>What is your goal in taking this class? Perhaps you're doing it thanks to a combination of social pressure (your parents said to), social inertia (everybody else goes to college), and a vague belief that this is the path towards a good job and a comfortable life. Or perhaps you're there because you want good grades so you can acquire lots of money and power which you will use to <a href=\"http://mindingourway.com/the-value-of-a-life/\">fight dragons</a>. Or perhaps you're there out of a genuine thirst for knowledge. But no matter why you're there, your reason for being there will pick out a single target point on the quality line. Your goal, then, is to hit that quality target \u2014 no higher, no lower.</p><p>Your preferences are not \"move rightward on the quality line.\" Your preferences are to <i>hit the quality target with minimum effort.</i></p><figure class=\"image\"><img src=\"http://mindingourway.com/content/images/2015/Mar/Quality1.png\"></figure><p>If you're trying to pass the class, then pass it with minimum effort. Anything else is wasted motion.</p><p>If you're trying to ace the class, then ace it with minimum effort. Anything else is wasted motion.</p><p>If you're trying to learn the material to the fullest, then mine the assignment for all its knowledge, and don't fret about your grade. Anything else is wasted motion.</p><p>If you're trying to do achieve some combination of good grades (for signalling purposes), respect (for social reasons), and knowledge (for various effects), then pinpoint the minimum quality target that gets a good grade, impresses the teacher, and allows you to learn the material, and hit that as efficiently as you can. Anything more is wasted motion.</p><p>Your quality target may be significantly left of F \u2014 if, say, you've already passed the class, and this assignment doesn't matter. Your quality target may be significantly to the right of A \u2014 if, say, you're there to learn the material, and grade inflation means that it's much easier to produce an A-grade paper than it is to complete the assignment in the maximally informative way. But no matter what, your goals will induce a quality target.</p><p>Both the slackers <i>and</i> the tryers are pursuing lost purposes. The slackers scoff at the tryers, who treat an artificial quality line like it's their actual preferences and waste effort over-achieving. The tryers scoff at the slackers, who are taking classes but refusing to learn. And both sides are right! Because both sides are wasting motion.</p><p>The slackers fail to deploy their full strength because they realize that the quality line is not their preference curve. The tryers deploy their full strength at the wrong target, in attempts to go as far right as possible, wasting energy on a fight that is not theirs. So take the third path: <i>remember what you're fighting for.</i> Always deploy your full strength, in order to hit your quality target as fast as possible.</p><p>Half-ass everything, with everything you've got.</p><p>(My teachers used to say that I could do great things if only I applied myself. I used to tell them that if they wanted me to apply more effort, they would need to invent higher letter grades.)</p><h1>2</h1><p>A common objection arises here:</p><blockquote><p><i>Some things are too important to \"half-ass.\" Some things are simply worth fighting for with your full strength. It's one thing to half-ass a homework assignment, and another thing entirely to half-ass saving a life. Sometimes you want to push as far right as you can on the quality curve.</i></p></blockquote><p>This is both true and false, because it is mixed up. Given any project, <i>always</i> aim no higher than the quality target, and always strive for minimum expenditure of effort. It doesn't matter whether you're writing a term paper, pulling a person out of a burning house, or creating a galaxy-spanning human civilization \u2014 the goal is always to achieve some quality target with minimum effort. Negentropy is scarce.</p><p>That said, the quality target can be <i>really really high.</i> In fact, the quality target is sometimes unatainably high. Often, we simply aren't capable of hitting our quality targets, and in those cases, we <i>do</i> want to push as far right along the preference curve as we can.</p><figure class=\"image\"><img src=\"http://mindingourway.com/content/images/2015/Mar/Quality2.png\"></figure><p>This can occur naturally whenever you work on something difficult relative to your skill level, or in competitive situations, or if you're signalling your ability to work hard. But don't get confused. Even if you write for the love of writing, you eventually have to stop editing and call it finished. Even if you're getting somebody out of a burning building, you eventually stop putting effort towards ensuring that they survive in favor of putting that effort towards saving other dying people instead. Even if you're building an intergalactic civilization, you need to trade off energy spent building the civilization against energy spent living in it.</p><p>There are goals for which you cannot achieve your quality targets, and in those cases, you will push ever rightwards. But too many people automatically assume that, when an authority figure describes a quality line, they're \"supposed to\" push as far right as possible. They think they \"should\" care about quality. This is silly: real world problems are not about producing the highest-quality products. In all walks of life, the goal is to hit a quality target with minimum effort.</p><p>This is of course only a fuzzy and inaccurate description of reality. The relative costs of time, effort, energy, attention, and quality are generally in flux, and change with both information and circumstance. The essential point is to be able to differentiate between the implicit quality line highlighted circumstance, and your actual preference curve.</p><hr><p>Let me be clear about what I'm <i>not</i> saying. If you're taking a college course, I'm <i>not</i> telling you that you should be scraping by by only the barest of margins. If you're saving a life, I'm <i>not</i> telling you to prefer speed over caution. In general, I'm decidedly <strong>not</strong> saying that you must always identify the worst outcome that you'd grudgingly accept as your target.</p><p>What I am saying is, don't conflate the quality line with the preference curve. Don't get confused when the teacher labels one quality-point \"pass\" and another \"fail,\" for these are just labels, and your deeper goals are likely only tangentially related to those labels. Remember what you're trying to achieve, identify your quality target, and aim for that: no higher, no lower.</p><p>(Also, remember that the planning fallacy exists! If you shoot for a D, you might get an F. Humans tend to be overconfident. When you pick your targets, be cautious, and leave yourself comfortable margins.)</p><h1>3</h1><p>The common slacker objection goes:</p><blockquote><p><i>But what if \"get the minimum passing grade as quick as possible\" is also boring? What if this task, too, is meaningless?</i></p></blockquote><p>Then get out of college!</p><p>I personally find that shooting for the minimum acceptable quality is usually <i>fun</i>. Doing the homework assignment is boring, but finding a way to get the homework assignment up to an acceptable level <i>with as little total effort as possible</i> is an interesting optimization problem that actually engages my wits, an optimization problem which both my inner perfectionist and my inner rebel can get behind.</p><p>But sometimes, after remembering what you're fighting for, the whole project will still seem worthless. Sometimes, the goal of getting the minimum passing grade with minimum effort will still stink of somebody else trying to pass off their arbitrary metric as your true preferences. In that case, consider dropping the class.</p><p>More generally, if there's no variation on \"achieve such-and-such a goal with minimum effort\" that seems worth doing, then you may need to abandon that goal entirely.</p><hr><p>By contrast, the common tryer objection runs as follows:</p><blockquote><p><i>But I'm a perfectionist! I physically can't stop caring about a low-quality product. I'm compelled to do my best.</i></p></blockquote><p>Great! Harness the perfectionist within you, and point it towards the goal of hitting your target with minimum effort.</p><p>Instead of being a perfectionist about the paper, be a perfectionist about <i>writing</i> the paper. Be a perfectionist about identifying good strategies, about abandoning sunk costs, about killing your darlings, about noticing when you're done. Be a perfectionist about wasting no attention. Be a perfectionist about learning from your mistakes. Perfectionism can be a powerful tool, but there's no need to point it at overachieving on metrics you don't care about.</p><h1>4</h1><p>Attempting to hit a quality target with the least possible effort is, in a sense, a much more difficult task than pushing as far right on the quality-line as possible. One always could push further right on the quality line with more time: when one is trying to write a great paper, they always <i>could</i> correct their flaws with more time and energy. But when one is trying to produce a paper with minimal wasted motion, mistakes are irrevocable. Time cannot be un-wasted.</p><p>In this sense, switching from being a tryer to a whole-assed-half-asser may lead to more guilt and shame than usual, if you start feeling guilty about every wasted motion.</p><p>However, I see far too many people feeling guilt and shame about not having pushed far enough along the quality line. They feel guilty about not putting effort towards their job (which they hate); they feel guilty about not being a good enough friend (when they are nearly at breakdown themselves); they feel guilty about not fulfilling their parent's expectations (which are ridiculous and uninformed). In order to replace guilt and shame with intrinsic motivation, it is first necessary to break the slacker/tryer dichotomy. If you've got to feel guilty, please feel guilty about missing your own targets, rather than feeling guilty about not adopting some arbitrary quality line as your true preferences. The former type of guilt is the one that I have a shot at addressing.</p><p>(Scrupulous people: in the interim, please don't feel guilty about wasting motion! Treat it like an important part of the human action process rather than something to be ashamed of. Future posts will expand on this idea.)</p><h1>5</h1><p>Most people seem to have two modes of working on problems: the slacker path-of-least-resistance \"coasting\" mode, and the tryer make-a-masterpiece \"overachiever\" mode. When faced with a problem, most people either put in the minimum effort necessary to scrape by without pissing off the relevant authorities, or else they pour their heart and soul into the task.</p><p>Almost everybody spends some time in both modes. Some people overachieve in history class and coast in grammar class. Some people overachieve at work and coast in their relationship. In fact, most heartwarming bad-students-can-be-good-people-too stories are about how students who are slacking in most domains are secretly trying really hard when it comes to dance/sports/music/number theory.</p><p>This, of course, is another piece of tryer propaganda: \"Don't worry,\" the movies say, \"these slackers aren't bad people, because they're secretly tryers in other domains!\" As if you're only a good person if you can adopt <i>some</i> arbitrary quality line as your true preferences.</p><p>Most people are trapped in the slacker/tryer dichotomy. They either do as little as they can get away with or as much as they can manage. They're either aiming for barely acceptable or they're aiming to be the best. Very few people seem able to pick a target in the middle and then pursue it with <i>everything they've got.</i> Very few people seem capable of deploying their <i>full strength</i> to hit \"mediocre\" as efficiently as possible.</p><p>Reject the dichotomy. Keep your eye on the preference curve. And remember that the preference curve says this, and only this:</p><p><i>Succeed, with no wasted motion.</i></p><p>The slacker in you rebels against pointless tasks, and the tryer in you wants perfection. So satisfy both: aim for the minimum necessary target, and move there as efficiently as possible.</p><p>And if ever you forget what it means to \"succeed\" in one context or another, take a moment to pause and remember what you're fighting for.</p>", "user": {"username": "So8res"}}, {"_id": "FToWZyZCSDdp2jdhY", "title": "Postdoctoral research positions at CSER (Cambridge, UK)", "postedAt": "2015-03-26T18:03:27.544Z", "htmlBody": "<html><body><p>[To be cross-posted at LessWrong, FLI news page]</p>\n<p>I&apos;m delighted to announce that the&#xA0;<a href=\"http://cser.org/\">Centre for the Study of Existential Risk</a>&#xA0;has had considerable recent success in grantwriting and fundraising, among other activities (full update coming shortly). As a result, we are now in a position to advance to CSER&apos;s next stage of development: full research operations. Over the course of this year, we will be recruiting for a full team of postdoctoral researchers to work on a combination of general methodologies for extreme technological (and existential) risk analysis and mitigation, alongside specific technology/risk-specific projects.</p>\n<p>Our first round of recruitment has just opened - we will be aiming to hire up to 4 postdoctoral researchers; details below. A second recruitment round will take place in the Autumn. We have a slightly unusual opportunity in that we get to cast our net reasonably wide. We have a number of planned research projects (listed below) that we hope to recruit for. However, we also have the flexibility to hire one or more postdoctoral researchers to work on additional projects relevant to CSER&apos;s aims. Information about CSER&apos;s aims and core research areas is available on our website. We request that as part of the application process potential postholders send us a research proposal of no more than 1500 words, explaining what your research skills could contribute to CSER. At this point in time, we are looking for people who will have obtained a doctorate in a relevant discipline by their start date.</p>\n<p>&#xA0;</p>\n<p>I would also humbly ask that the Effective Altruism community aid us in spreading the word far and wide about these positions. There are many brilliant people working within the existential risk community. However, there are academic disciplines and communities that have had less exposure to existential risk as a research priority than others (due to founder effect and other factors), but where there may be people with very relevant skills and great insights. With new centres and new positions becoming available, we have a wonderful opportunity to grow the field, and to embed existential risk as a crucial consideration in all relevant fields and disciplines.</p>\n<p>Thanks very much,</p>\n<p>Se&#xE1;n &#xD3; h&#xC9;igeartaigh (Executive Director, CSER)</p>\n<p>&#xA0;</p>\n<p>&quot;The Centre for the Study of Existential Risk (University of Cambridge, UK) is recruiting for to four full-time postdoctoral research associates to work on the project&#xA0;<em>Towards a Science of Extreme Technological Risk</em>.</p>\n<p>We are looking for outstanding and highly-committed researchers, interested in working as part of growing research community, with research projects relevant to any aspect of the project.&#xA0;<strong>We invite applicants to explain their project to us, and to demonstrate their commitment to the study of extreme technological risks.</strong></p>\n<p>We have several shovel-ready projects for which we are looking for suitable postdoctoral researchers. These include:</p>\n<ul>\n<li>Ethics and evaluation of extreme technological risk (ETR) (with Sir Partha Dasgupta;</li>\n<li>Horizon-scanning and foresight for extreme technological risks (with Professor William Sutherland);</li>\n<li>Responsible innovation and extreme technological risk (with Dr Robert Doubleday and the Centre for Science and Policy).</li>\n</ul>\n<p>However, recruitment will&#xA0;<strong>not necessarily be limited to these subprojects, and our main selection criterion is suitability of candidates and their proposed research projects to CSER&#x2019;s broad aims</strong>.</p>\n<p>Details are available&#xA0;<a href=\"http://cser.org/vacancies/\">here</a>. Closing date:&#xA0;<strong>April 24th</strong>.&quot;</p></body></html>", "user": {"username": "Sean_o_h"}}, {"_id": "JurQ38r7sQSjDjg3H", "title": "Meetup : EA Berlin #2", "postedAt": "2015-03-26T16:55:04.882Z", "htmlBody": "<html><body><h2>Discussion article for the meetup : <a href=\"/meetups/2g\">EA Berlin #2</a></h2>\n\t\t  <div>\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span>19 April 2015 02:00:00AM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span>VEBU, 4th floor (counting EG as 0th floor), Genthiner Str. 48, 10785 Berlin</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div>\n\t\t    <div><p>There&#x2019;s no set agenda, but we&#x2019;ll surely have enough to discuss. Feel free to bring some veggie snacks if you like.</p>\n\n<p>Please send me a message or an email to telofy at yoursiblings dot org if you want to attend, so I can keep you briefed of changes.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href=\"/meetups/2g\">EA Berlin #2</a></h2></body></html>", "user": {"username": "Telofy"}}, {"_id": "RK58u9ZjjDK6CQs4e", "title": "EA Week at Harvard", "postedAt": "2015-03-26T15:55:05.245Z", "htmlBody": "<html><body><p><span>Hi EAs,</span></p>\n<p>&#xA0;</p>\n<p><span>Harvard College EA is going to organize an &quot;EA week&quot; &#xA0;from April 12 to 17.</span></p>\n<p><span><br></span></p>\n<p><span>Currently, we are planning on doing the following events:</span></p>\n<ul>\n<li>\n<p><span>Peter Singer talk promoting his new book on EA, hopefully with free EA-style t-shirts to for attendees.</span></p>\n</li>\n<li>\n<p><span>Daron Acemoglu talk on institutions and economic development</span></p>\n</li>\n<li>\n<p><span>80k-style events, including a competition for free 80k coaching and career panels.</span></p>\n</li>\n<li>\n<p><span>A movie night</span></p>\n</li>\n<li>\n<p><span>Giving games, and possibly a fundraiser</span></p>\n</li>\n<li>\n<p><span>Possibly a panel with the Dean of Harvard College, who expressed his support for this.</span></p>\n</li>\n</ul>\n<div><span><span><br></span></span></div>\n<p><span>We are currently trying to find ways to get as much as we can from this opportunity. In particular, we would like to:</span></p>\n<ul>\n<li>\n<p><span>Reach as many Harvard students (and faculty) as possible</span></p>\n</li>\n<li>\n<p><span>Align this with current efforts in EA outreach</span></p>\n</li>\n<li>\n<p><span>Learn more about large-scale events so that we can aim higher in next years</span></p>\n</li>\n</ul>\n<div><span><span><br></span></span></div>\n<p><span>We would love to hear if the broader EA movement can have any </span><span>input</span><span> on this, because we would love to make this as aligned with existing EA strategies as possible. In particular, we would be interested in hearing your ideas on:</span></p>\n<ul>\n<li>\n<p><span>General Outreach:</span><span> How should we formulate the main message of the week?</span></p>\n</li>\n<li>\n<p><span>T-shirt design</span><span>: what design should we use? We are not in love with the current EA logo but would use it if EAs think it is the best option. What message should the T-shirt carry?</span></p>\n</li>\n<li>\n<p><span>Demand:</span><span> If we manage to make the t-shirts look nice, what is your estimate of demand among EAs outside Harvard?</span></p>\n</li>\n<li>\n<p><span>Other things:</span><span> Are we missing some obvious things EAs are already doing (i.e. an initiative) or do you have other general ideas?</span></p>\n</li>\n</ul>\n<div><span><span><br></span></span></div>\n<p><span>We can also offer two </span><span>giving opportunities</span><span>:</span></p>\n<ul>\n<li>\n<p><span><span>We need to raise $1-2k in order to make the </span><span>T-shirts</span><span>, depending on the expected demand outside Harvard.</span></span></p>\n</li>\n</ul>\n<div><span><span>UPDATE: We already found a donor.</span></span></div>\n<ul>\n<li>\n<p><span>Peter Singer</span><span> typically asks the hosts of his talks to give ~10k to effective charities. While this is not a strict demand, we would like to come close to this goal. To this end, we will try to find external sources, so that we redirect more money to good causes. However, we would appreciate if someone who is already planning to give to an effective charity is willing to do so nominally for the purpose of this talk, so that we have a safety cushion in case fundraising doesn&#x2019;t go well.</span></p>\n</li>\n</ul>\n<div><span><span>UPDATE: Charity Science offered a backup</span></span></div>\n<p><br><span>If you&apos;re interested in either of these opportunities, please comment or contact us at harvardea@gmail.com. Thanks!</span></p></body></html>", "user": {"username": "Ales_Flidr"}}, {"_id": "4fPxQjq6GFZgurSsf", "title": "Room for Other Things: How to adjust if EA seems overwhelming", "postedAt": "2015-03-26T14:10:52.928Z", "htmlBody": "<h2><span>Overwhelming obligations</span></h2>\n<p>The <a href=\"https://www.youtube.com/watch?v=onsIdBanynY\">drowning child argument</a> has persuaded many people to join the effective altruism movement. It highlights one of EA\u2019s central concepts: opportunity costs. The money spent on expensive clothes could instead be used to donate to cost-effective charities overseas, where it can save a person's life. Of course, the force of the argument does not stop there: If you're left with more money, or if you could work for a few extra hours to earn more, you can donate more to help additional people. Every decision we make has opportunity costs \u2013 this realization can <a href=\"https://www.youtube.com/watch?v=onsIdBanynY\">feel overwhelming</a>.\u00a0</p>\n<p><span>Several critics consider the ideas behind effective altruism flawed or impractical because they appear to demand too much from us. In his widely cited essay </span><em>A Critique of Utilitarianism</em><span>, Bernard Williams argues that the idea of always trying to bring about the best outcome</span><sup>1</sup><span> places too high a burden on a person by taking away their choice in what they want to do in life:\u00a0</span></p>\n<p><span>\u00a0</span></p>\n<blockquote>\n<p><span>It is to alienate him in a real sense from his actions and the source of his action in his own convictions. It is to make him into a channel between the input of everyone\u2019s projects, including his own, and an output of optimific decision; but this is to neglect the extent to which <em>his</em> actions and <em>his</em> decisions have to be seen as the actions and decisions which flow from the projects and attitudes with which he is most closely identified. It is thus, in the most literal sense, an attack on his integrity.</span></p>\n</blockquote>\n<p>\u00a0</p>\n<p><span>When I first read Williams\u2019 critique a few years ago, I already considered myself an effective altruist and, as such, I found the arguments surprisingly unimpressive. I felt that <em>obviously</em>, if someone\u2019s goal is to make the world a better place, <em>this</em> is the person\u2019s decision, her chosen life-project. However, as I\u2019m now more aware of than before, people have the tendency to <a href=\"http://lesswrong.com/lw/dr/generalizing_from_one_example/\">overestimate how similar others are to themselves</a>. \u00a0I was already so immersed in EA thinking that I forgot how things may feel for others. Williams\u2019 critique highlights an important point. People can be altruistically motivated but have other goals in life besides doing the most good, or they may have pre-existing commitments that contribute to their identity and happiness. If so, they might \u2013 consciously or unconsciously \u2013 view the all-encompassing interpretations of effective altruism as something that threatens what they value. This can manifest itself either in rationalizations against the idea of EA, or \u2013 if the person is more introspective \u2013 it might lead to a genuine conflict of internal motivations, which often results in unhappiness. The situation becomes especially difficult for such a person if he/she is being pressured, either externally (by other people\u2019s expectations) or internally (e.g. by comparing oneself to a very high moral standard or to a person who gave up everything else for effective altruism). \u00a0Needless to say, such an outcome is very unfortunate, both for the people themselves and for them not getting involved because of it.\u00a0</span></p>\n<p><span><br /></span></p>\n<h2><span>A healthier framing</span></h2>\n<p>Perhaps it cannot be entirely avoided that some people are going have an aversive reaction, at least to some extent, when they learn more about effective altruism. There is truth to the saying \u201cignorance is bliss\u201d: Some ideas, like the drowning child argument, irreversibly change the way we view life. Nevertheless, I believe that the feeling of \u201coverwhelmingness\u201d discussed above is uncalled for.</p>\n<p><span>In this article I want to present a way to see or frame effective altruism that I consider both philosophically correct and useful from a motivational point of view. I prefer to think of EA as a choice, rather than some sort of external moral obligation. In reply to people who are concerned that effective altruism is overwhelming or overly demanding, I want to point out two important considerations:\u00a0</span></p>\n<ol>\n<li><span>If you view EA as a possible goal to have, there is nothing contradictory about having other goals in addition.\u00a0</span></li>\n<li><span>Even if EA becomes your <em>only</em> goal, it does <em>not</em> mean, necessarily, that you should spend the majority of your time thinking about it, or change your life in drastic ways. (More on this below.)</span></li>\n</ol>\n<h2><span>What are goals?</span></h2>\n<p><span>Imagine you could shape yourself and the world any way you like, unconstrained by the limits of what is considered feasible. What would you do? Which changes would you make? Your answers to these questions describe your ideal world. To guide our actions in practice, we also have to specify how important various good things are compared to other good things. So, in a second step, imagine that you had the same powers to shape the world as you wish, but this time, they are limited. You cannot make every change you had in mind, so you need to prioritize some changes over others. Which changes would be most important to you? The outcome of this thought experiment approximates your goals<sup>2</sup>.\u00a0</span></p>\n<h3><span>1) Having other goals besides EA</span></h3>\n<p><span><span>It is perfectly possible to give a lot of weight to one's personal well-being or one's favored life-projects, while still choosing to dedicate some amount of time and money to effective altruism. There is nothing contradictory about having multiple goals \u2013 it just means that one is willing to make tradeoffs in the face of resources being limited. Some people may think that it is somehow wrong or \u201cinelegant\u201d to have several goals, but as long as the person herself is fine with it, that\u2019s all that matters.\u00a0</span></span></p>\n<h3><span>2) EA as a goal does not necessarily imply sacrificing all other commitments</span></h3>\n<p><span>Giving up all personal commitments is bad on any account of rational goal-achievement, if this would make a person psychologically unable to continue working productively toward their goals. Compared to a <a href=\"http://www.benkuhn.net/stress\">perfect utilitarian robot</a>, humans have many shortcomings. This applies to everyone, but the degrees vary from person to person. It makes just as little sense to compare oneself to a perfect utilitarian robot than to compare oneself to a person who is, for whatever reason, unreachably in a different starting position from one's own.\u00a0</span></p>\n<p><span>When people think of effective altruists, what sort of person are they typically picturing? Most likely, we first think of the people who went into investment banking, working excessive hours and night-shifts, to donate 50% of their income; or the people who quit promising career paths in order to work full-time for EA organizations; or the famous philosopher who </span><a href=\"http://www.nickbostrom.com/\">churns out paper after paper</a><span>. Of course, these sorts of people are outliers, high-achievers that don\u2019t represent the typical population. It takes specific personality traits and skills to be motivated and able to do EA almost as an extreme sport. A more typical EA would be someone with a more \u201cnormal\u201d job who donates say 10% of their income, or everything above a limit that is enough to live comfortably while having some financial security in the future.\u00a0</span></p>\n<p><span>The \u201chigh-achievers\u201d mentioned first are arguably the EAs who make the most difference individually, yet they only represent a small minority of EAs, even more so as EA becomes increasingly more mainstream. Are these people more motivated than other EAs, are they the only ones who \u201ctake EA seriously\u201d? I don't think so. These people aren\u2019t more motivated to be EAs; rather, they are more motivated and/or more </span><em>suited</em><span> to do the </span><em>things that are most effective from an EA-standpoint</em><span>. This distinction is important. Outliers don\u2019t necessarily care more, but their personalities and skills make them better better positioned to contribute effectively</span><sup>3</sup><span>.\u00a0</span></p>\n<p><span>For the typical person, therefore, being an EA does not imply trying to do all the things the highest-achieving EAs are doing. One could be tempted to view this as a watered-down version of EA, as \u201cEA light\u201d, but this would be getting it wrong. If you\u2019re doing the best you can, there\u2019s nothing watered down about your goals, your moral ideals. Comparing yourself to the most skilled and hardworking EAs would be making the same kind of mistake, on a lower level, as comparing yourself to a perfect utilitarian robot. Even the most hardworking EAs need breaks sometimes, and in comparison with a perfect robot, they too fall short. Rationality is about making the best out of what you have. Holding yourself to impossible standards is silly and counterproductive. The better approach is to find smaller but sustainable ways to contribute.</span></p>\n<h2><span>Personalities are different</span></h2>\n<p><span>People don\u2019t only differ in regard to skills, they also differ in regard to what they\u2019re interested in. In my case, becoming an effective altruist came easy to me. I discovered all this information out there, <a href=\"http://lesswrong.com/\">LessWrong</a> and the now less active <a href=\"http://felicifia.org/\">Felicifia</a>, and I couldn\u2019t stop reading and having discussions with others. It wasn\u2019t like I had to force myself to do any of that. I think about EA-related topics most of the time because this is what I enjoy doing; if I found it strenuous (as some people will), I would be doing it less.</span></p>\n<p><span>Personality differences also reflect what sort of things people are (de)motivated by. Some people are attracted to weird (i.e. non-mainstream) ideas because they enjoy discussions. Others might dislike having to talk about or defend their positions constantly on the internet or in social settings, and if that's the case, a lot of EA-related activities become much harder.\u00a0</span></p>\n<p><span>Finally, personality differences also affect the way people prefer their life to go as a whole. Having balance in life is important for everyone, but some need a lot of it and others are more okay with a life that is optimized obsessively towards a single goal. People might have life-projects or strong commitments that would make them miserable if they had to be abandoned, <a href=\"http://www.givinggladly.com/2013/06/cheerfully.html\">wanting children</a> for example, or a specific job one really likes. These things are compatible with EA, because EA doesn\u2019t solely work if done as an extreme sport.</span></p>\n<p><span><br /></span></p>\n<h2><span>Some advice</span></h2>\n<p><span>It is important to take into account that people differ from each other in many respects, including previous commitments, \u00a0personality differences and differences in skills. Being rational about achieving your goals means, among other things, to understand what is within your reach and what isn\u2019t, and to not hold yourself responsible for being unable to do the impossible. I have the impression that some personality types, especially people who are very altruistic and caring, sometimes suffer from holding themselves to too high a standard, and being unable to allow themselves to relax in spite of all the <a href=\"http://lesswrong.com/lw/l30/on_caring/\">world\u2019s suffering on their shoulders</a>. Ben Kuhn\u2019s blogpost <a href=\"http://www.benkuhn.net/stress\">To stressed-out altruists</a> contains a great insight that is worth quoting at length:</span></p>\n<blockquote>\n<p><span>I think the culprit of stress for many EAs is a lack of <a href=\"http://en.wikipedia.org/wiki/Compartmentalization_(psychology)\">compartmentalization</a>. Now, to really understand the ideas of effective altruism, you need not to compartmentalize too much\u2014for example, I have a roommate who buys the idea of altruism in the abstract, but doesn\u2019t do anything about it because he separates his brain\u2019s \u201cabstract morality\u201d module and its \u201cdecide what to do\u201d module. Because of things like this, compartmentalization has an often-deserved poor reputation for letting people evade cognitive dissonance without really coming to terms with their conflicting ideas. But compartmentalization isn\u2019t always maladaptive: if you do it too little, then whatever you care about completely consumes you to the point of non-functional misery.</span></p>\n<p><span>\u00a0</span></p>\n<p><span>Effective altruism requires less compartmentalization than the average person has, so standard effective altruism discourse, which is calibrated against the average person, tries to break down compartmentalization. But you probably aren\u2019t the average person. If you\u2019re stressed out about effective altruism, <em>ignore the standard EA discourse and compartmentalize more</em>!\u00a0</span></p>\n</blockquote>\n<p><span><br />Most of the advice I\u2019d give to people struggling with EA is along the lines Ben talks about. Below, collected a list of things I use myself or would recommend for others for trying to learn to compartmentalize more. Of course, not everyone will find these applicable or equally helpful.\u00a0</span></p>\n<ul>\n<li><strong>Avoiding daily dilemmas</strong><span>: If you find yourself struggling internally every time you go to the grocery store, wondering whether you should buy expensive products or rather save the money for donations, it might make sense to set up clear heuristics for yourself, e.g. <a href=\"http://www.jefftk.com/p/keeping-choices-donation-neutral\">a yearly budget for charity</a>. Those heuristics then take care of recurring EA-related decisions. Choosing to donate a percentage of your income every month instead of \u201ctrying to see how much you can save\u201d each day allows you to stop ruminating about maybe saving the additional fifty cents (= deworming one more child!) every time you spend money on something. This way, you can free your mind from looming opportunity costs and focus on your personal needs, while still having the altruistic impact through your regular donations.<br /></span><span>\u00a0</span></li>\n<li><strong>Putting emotions into perspective</strong><span>: I find that a basic understanding of evolutionary biology can be helpful in some situations. To a large degree (the rest is upbringing, experiences, randomness), your emotional reactions to things are the way they are because these reactions proved beneficial, in terms of gene-copying success, in the environment of your ancestors. Your <em>personal</em> goals are not tied to gene-copying success, and the modern environment is very different from the evolutionary one. Therefore, we should expect that our emotions are not calibrated to fulfill EA-related goals in a modern environment. When you\u2019re feeling really bad about mistakes you may have made or about not doing enough, this does not necessarily reflect that what you <em>did/didn\u2019t do</em> is indeed really bad. From a pragmatic perspective, feeling bad only makes sense as a learning mechanism: if there\u2019s something you learn to do different the next time. Often people blame themselves for things that couldn\u2019t be anticipated or changed. And even if a genuine mistake happened, once the lesson is learned, it is important to try to take a <em>forward-looking perspective</em> and not fret about the past.\u00a0</span></li>\n</ul>\n<p><span><em><br />Note</em>: This next example works very well for me personally, but I can imagine that the competitive aspect of \u201ctrying to score as many points as possible\u201d is bad for some people.<br />\u00a0</span></p>\n<ul>\n<li><span><strong>Viewing EA as a game with varying levels of difficulty</strong>: When one looks at life from a consequentialist point of view where opportunity costs are always looming in the background, the vast majority of things to do will be \u201cwrong\u201d in the sense that a perfect robot with one's exact goals would do them differently. However, that need not concern us. Instead of looking at things as \u201cright vs. wrong\u201d, it's a lot more helpful to think of things like a score system in video games, where you can gather points open-endedly. Foregoing a few points here and there will be fine as long as we keep track of the important decisions. Because life isn\u2019t fair, the level of difficulty of the video game will sometimes be \u201chard\u201d or even \u201cinsane\u201d, depending on the situation you\u2019re in. The robot on the other hand would be playing on \u201ceasy\u201d, because it would never encounter a lack of willpower, skills or thinking capacity. So don\u2019t worry about not being able to score too many points in the <em>absolute</em> sense, and focus instead on how many points are reachable within the <em>difficulty-level that you\u2019re playing on</em>. <br />\u00a0</span></li>\n<li><span><strong>Separating conflicting motivations</strong>: If you find it hard to donate to organizations recommended by other EAs because you have a commitment to other charities, e.g. because you\u2019ve been a donor there for a long time, have visited the charity, or have found that their approach strongly resonates with you, then consider splitting your charitable budget into two parts, separating what you feel good about from what you consider has the best effect in terms of helping people. <a href=\"http://reg-charity.org/splitting-ii-feeling-good-about-donating/\">See this blogpost for a better explanation</a>. \u00a0An additional benefit is that, if this splitting is always an option, it prevents you from rationalizing that your previously favored charity is also the one that just happens to be most effective from an EA-point-of-view.\u00a0<br /><br /></span></li>\n<li><span><strong>Talking to other EAs</strong>: If you\u2019re feeling bad about something or have a problem with some aspect of EA, it is likely that you\u2019re not the only person to whom this ever happened. Talking to others who may be in a good position to help out or give advice might be a good thing to try.</span></li>\n</ul>\n<div><span><br /></span></div>\n<span><sup>1</sup>Williams is talking about utilitarianism as a moral theory, not about effective altruism as an idea/movement. I realize that the two are distinct. E.g., one can be an EA without subscribing to utilitarianism. Nevertheless, large parts of Williams\u2019 critique, and especially the passage I quoted, apply well to EA.\u00a0</span><span><br /></span><span><sup>2</sup>This question is of course a very difficult one, and what someone says after thinking about it for five minutes might be quite different from what someone would choose if she had heard all the ethical arguments in the world and thought about the matter for a long time. If you care about making decisions for good/informed reasons, you might want to refrain from committing too much to specific answers and instead give weight to what a better informed version of yourself would say after longer reflection.\u00a0</span><span><br /></span><span><sup>3</sup>Of course, the matter is not black-and-white. Caring/commitment does matter to a significant extent, i.e. there will be people who would be suited to do the extreme-EA thing but don\u2019t try enough.\u00a0</span><span><br /></span><span><sup>4</sup>This also goes the other way (cf. \u201cscope insensitivity\u201d), but standard EA discourse talks a lot about this already.\u00a0</span>\n<p>\u00a0</p>", "user": {"username": "Lukas_Gloor"}}, {"_id": "4jBvkrJqTHJQzY7mM", "title": "Marcus Davis will help with moderation until early May", "postedAt": "2015-03-25T19:12:11.614Z", "htmlBody": "<html><body><p>Hi all,</p>\n<p>Introducing <a href=\"/user/Marcus_A_Davis/\">Marcus Davis</a>,</p>\n<p>Marcus is an audio engineer from Chicago who read some philosophy and became interesting in effective altruism during college. Since then, he&apos;s become connected with a lot of effective altruists, especially through dot impact, where he&apos;s a regular contributor.</p>\n<p>Marcus has generously offered to join me in moderating the forum. He&apos;ll do this from tonight until around early-mid may while he has some spare time at hand.</p>\n<p>Our goal for moderation is the same as it&apos;s always been, to stay out people&apos;s the way and only to delete spam and harmful or destructive content. If you want to flag some content or if you have any other feedback, feel free to contact either one of us.</p>\n<p>Marcus will also help out by maintaining our basic level of social media presence. If you are interested in helping promote EA articles, then that&apos;s also a great reason to get in contact.</p>\n<p>Lastly, when Marcus gets back to his regular work in May, I&apos;ll be keen to see another moderator come on board so if you&apos;re interested, post me an email at ry.duff [at] gmail [dot] com.</p>\n<p>Great to have you on-board, Marcus</p></body></html>", "user": {"username": "RyanCarey"}}, {"_id": "C9ocXigPfNndZqn8j", "title": "We might be getting a lot of new EAs. What are we going to do when they arrive?", "postedAt": "2015-03-25T15:41:49.269Z", "htmlBody": "<html><body><p>In a conversation with Kerry Vaughn, he told me there&apos;s &quot;a gold rush&quot; around getting new people involved with the effective altruist movement. &#xA0;It&apos;s easy to see why this is so. &#xA0;EA has been more frequently in the press in the past year. &#xA0;And there are <em>four</em>&#xA0;different books on effective altruism coming out, at least two of which will be marketed heavily by professionals. &#xA0;<a href=\"/ea/gq/ea_advocates_announcement/\">EA Advocates</a> are helping spread EA content on Facebook and Twitter. &#xA0;The <a href=\"http://eao.causevox.com/\">EA Outreach</a> team is also working full speed on other projects and the upcoming <a href=\"http://www.effectivealtruismsummit.com/\">EA Global conference</a> sounds like it will be pretty awesome.</p>\n<p>So, fingers crossed, the EA movement will be growing a lot in 2015. &#xA0;But what should we do once those EAs show up?</p>\n<p>&#xA0;</p>\n<h2>From Intro to Impact</h2>\n<p><strong>Stages of Effective Altruism</strong></p>\n<p>Having someone self-identify as an effective altruist is great, but ideally we want them to do something <em>significant and impactful, </em>such as donating 10%+ of one&apos;s income to effective charities, spending a similarly significant time doing direct work, considering a more ethical diet, and/or advocating to others.</p>\n<p>While it definitely has happened with people in this community, my guess is that people don&apos;t usually pick up a copy of Singer&apos;s book, read it, and then instantly decide to give 10%. &#xA0;Instead, there seems to be some intervening stuff between getting introduced to EA and giving 10%.</p>\n<p>&#xA0;</p>\n<p><strong>A Funnel</strong></p>\n<p>From this, we can then theorize an &quot;EA funnel&quot;, similar to any other <a href=\"http://en.wikipedia.org/wiki/Purchase_funnel\">marketing / sales funnel</a>, where you maximize the impact of the EA movement by getting as many people involved with EA as possible and then getting as many of those people do give as much as they can. &#xA0;People can drop off at any stage along the way, which is what we seek to minimize.</p>\n<p>&#xA0;</p>\n<h2><strong>The Involvement Problem</strong></h2>\n<p><strong>Introduction is Well Funded</strong></p>\n<p>Many people are working hard to introduce people to EA. &#xA0;There&apos;s the four books I mentioned. &#xA0;There&apos;s this forum you&apos;re at here, plus the <a href=\"https://www.facebook.com/groups/effective.altruists/\">active Facebook group</a>. &#xA0;<a href=\"http://www.lesswrong.com\">LessWrong</a> also has a lot of EA activity. &#xA0;And there are many orgs -- such as The Life You Can Save, Giving What We Can, Charity Science, Raising for Effective Giving, and 80,000 Hours -- all working full-time to bring people into the movement. &#xA0;There are <a href=\"http://effectivealtruismhub.com/groups\">many meetups across the world</a> and people are <a href=\"/ea/ff/creating_a_local_effective_altruist_presence_in/\">working full speed to make more</a>. &#xA0;Lastly, there&apos;s <a href=\"/ea/d1/list_of_introductory_ea_presentations/\">a lot of EA introductory talks</a> going on throughout the world, including&#xA0;<a href=\"http://www.ted.com/talks/peter_singer_the_why_and_how_of_effective_altruism?language=en\">Peter Singer&apos;s TED talk</a>&#xA0;which has received over 1.1M views.</p>\n<p>There certainly are many more things that can be done to introduce people to EA. &#xA0;I&apos;ve heard many interesting proposals I&apos;d like to see go forward, such as <a href=\"http://www.effective-altruism.com/ea/dg/tlycs_pamphleting_pilot_program/\">experiments with flyering</a>.</p>\n<p>&#xA0;</p>\n<p><strong>Involvement is Relatively Underfunded</strong></p>\n<p>What can people do once they join the movement, to further their involvement?<br><br>...They certainly can join things. &#xA0;Facebook groups, this EA Forum, <a href=\"/ea/g3/announcing_the_effective_altruism_newsletter/\">mailing lists</a>. &#xA0;They can begin to post and comment.</p>\n<p>...They can <a href=\"http://effectivealtruismhub.com/user/profiles\">make an EA profile</a>.</p>\n<p>...They can start doing certain small actions, like <a href=\"http://www.charityscience.com/fundraisers.html\">running a fundraiser</a> or doing <a href=\"http://effectivealtruismhub.com/actions/shopping\">Shop for Charity</a>.</p>\n<p>...They could start earning and donating small amounts.</p>\n<p>...They could try to volunteer for an EA org.</p>\n<p>...They could join another action group, like <a href=\"/ea/gq/ea_advocates_announcement/\">EA Advocates</a> or <a href=\"http://www.dotimpact.im\">.impact</a>.</p>\n<p>...They could <a href=\"http://www.reducetarian.com/\">change their diet to be more animal-friendly</a>.</p>\n<p>&#xA0;</p>\n<p>But it seems hard for people to do more than that and many of these actions aren&apos;t even that well advertised anyway. &#xA0;So what can we do?</p>\n<p>&#xA0;</p>\n<h2><strong>I&apos;m an EA. &#xA0;Now What?</strong></h2>\n<p>There is little between the introduction and quitting your job. &#xA0;We should fix that. &#xA0;So what do I propose?</p>\n<p>&#xA0;</p>\n<p><strong>Get engaged on the &quot;small things&quot;</strong></p>\n<p><a href=\"/ea/7k/what_small_things_can_an_ea_do/\">We&apos;ve previously compiled a list of small things people can do</a>. &#xA0;People&apos;s identities are reinforced by taking action, so doing small actions can lead to people doing larger actions in the future. &#xA0;Moreover, these actions are quite valuable in their own right.</p>\n<p>We should update the list, think of what more we could add to it, think about how to <a href=\"http://www1.maths.leeds.ac.uk/~mmjhh/stuff/findmeatask/\">make it more digestible</a>, and then try to publish it widely (such as prominently on effectivealtruism.org).</p>\n<p>&#xA0;</p>\n<p><strong>Talk 1-on-1 with an EA</strong></p>\n<p>Several people are trying to talk to a lot of EAs, but they&apos;re busy with other things. &#xA0;I&apos;ve been lead to believe that there are more people who want conversations than there are people willing to talk, though I&apos;m not sure if this is true. &#xA0;Giving What We Can seems to have their member base covered with their latest hires, but no one is currently doing this for the wider EA community. &#xA0;There seems to be little standardized network to connect a new EA to a relevant person to have a friendly chat about how to get involved, whether by email or by Skype.</p>\n<p>We could try to build an informal network, but I think it might be easiest just to hire (as in pay, potentially well, with money) someone or multiple people to dedicate time to being in contact with new EAs. &#xA0;In particular, we&apos;d be looking for people who are (1) knowledgable about the community, (2) relatable and friendly, (3) generally reliable, and (4) has the time and desire to commit to do this moderately long-term.</p>\n<p>&#xA0;</p>\n<p><strong>More work on building and sustaining local groups</strong></p>\n<p>Despite the world of the internet, meeting in person is still important. &#xA0;There have been a lot more resources into building up local EA groups lately, but I&apos;m less sure if there&apos;s sufficient resources going into maintaining existing groups -- checking in, making sure people have sufficient funding, trying to apply lessons learned elsewhere, etc.</p>\n<p>We also should have better norms for EA meetups. &#xA0;I&apos;ve heard of many people, myself included, neglecting EA meetups because they have more impactful things to do than what usually turns out to be glorified socializing. &#xA0;But socializing is valuable for getting people involved and we should take this more seriously. &#xA0;To make things a bit better, remember you don&apos;t have to meet monthly -- even quarterly is probably better than never. &#xA0;Lastly, you could try to do more hands-on stuff in your meetups, like working through the aforementioned &quot;small stuff&quot; in groups, or doing other volunteering / outreach projects.</p>\n<p>&#xA0;</p>\n<p><strong>An Online Hangout</strong></p>\n<p>For those people not fortunate enough to be in a sizable local group, we can offer an online hangout. &#xA0;Currently, <a href=\"http://www.dotimpact.im\">.impact</a> is serving this role by providing a meetup for anyone to join and learn about how they can get involved in the community. &#xA0;And now we&apos;ll start running these biweekly.</p>\n<p>&#xA0;</p>\n<p><strong>Think about scalable, more meaningful, projects to offer more dedicated volunteers</strong></p>\n<p>Many people get involved in groups and do the small stuff, but want more. &#xA0;Generally, though, orgs are disappointed by people -- despite having the best of intentions -- finding themselves unable to follow through. &#xA0;This is totally understandable, but ends up giving a reputation of volunteers as unreliable and not worth the time.</p>\n<p>However, once we have enough small stuff for people to do, we can refer them to finish the small stuff and establish a track record. &#xA0;If someone has done a good job, say, running a fundraiser, than chances are that they&apos;ll also do a reasonable job at some other task. &#xA0;You can build from there.</p>\n<p>Right now, we don&apos;t really have that much readily available work to give to those people who are proven. &#xA0;So we need more work to develop some projects that anyone can do, but are a bit bigger than the current ones. &#xA0;Maybe current EA orgs could work to better open source tasks that are typically done by interns? &#xA0;Maybe we could think of something else?</p>\n<p>&#xA0;</p>\n<p><strong>Connect the funnel together</strong></p>\n<p>Lastly, we need to finish connecting introduction to further involvement. &#xA0;People who are introduced through any of the various materials should be funneled to a place where they can learn about how to get involved, or they might end up dropping off. &#xA0;And getting involved should include a clear progression from joining things, doing some small stuff, maybe talking 1-on-1, and progressing to more meaningful projects. &#xA0;Hopefully, this eventually culminates with someone either earning to give or working full-time on EA stuff.</p>\n<p>Right now, many people aren&apos;t getting any answers about what to do next after seeing EA content. &#xA0;And people who do get answers frequently get inconsistent ones. &#xA0;It might be hard with the books that have already gone to print, but I think we could standardize this some more.</p></body></html>", "user": {"username": "Peter_Hurford"}}, {"_id": "2C3S6AcZeEwgbMgpu", "title": "Giving What We Can September Internship- Applications Open! ", "postedAt": "2015-03-25T14:26:47.217Z", "htmlBody": "<html><body><p><span><span>Are you a student or recent graduate who is interested at interning at Giving What We Can? &#xA0;Are you free from the 14th to the 25th of September? &#xA0;If you answered yes to both of these questions you are in luck, Giving What We Can is running our September Internship program again this year and we are looking for applicants. &#xA0;</span></span></p>\n<p><span>The internship involves working at the Centre for Effective Altruisms&#x2019; offices in Oxford for two weeks. &#xA0;Successful applicants will get to work alongside 10 to 15 other interns, networking and working on exciting projects focused on the growth and improvement of Giving What We Can. &#xA0;Projects include working on Giving What We Can&#x2019;s outreach strategy, improving our social media presence, doing research for our blog and improving on the research we use for our recommendations. &#xA0;If you want the chance to meet other EAs and spend two weeks gaining skills and working in a prominent EA organisation, I encourage you to apply!  Note that this is an unpaid internship, and we won&apos;t be able to provide accommodation (although I can help you find something if you need help!) </span></p>\n<p><span>We will be closing applications at the end of next week (April 2nd 2015), so be sure to apply soon! If you are interested, follow the link </span><a href=\"https://docs.google.com/forms/d/1ennvc5siI-J0TR_PVZ6teryFp23wmQO7NlsVq6mN5u4/viewform?usp=send_form\"><span>here</span></a><span> to apply. &#xA0;&#xA0;If you know anyone else who might be free and interested do pass the message along! </span></p></body></html>", "user": {"username": "jonathancourtney"}}, {"_id": "5KT2K3fpyjP5HQvik", "title": "Criminal Justice Reform: DEA enforcement incentives?", "postedAt": "2015-03-25T02:20:15.761Z", "htmlBody": "<html><body><p>GiveWell is currently investigating criminal justice reform as an area of potentially effective giving. I just wanted to raise one particular issue for discussion and find out whether anyone else has investigated it.</p>\n<p>The War on Drugs continues despite a tide of public sentiment slowly rising against it. Part of the reason is potentially special interest groups who stand to lose a lot of money if things change. This includes the Prison Guard Union and Private Prison Corporations who fight to keep tough drug sentencing on the books, as well as Police Unions who rely on the WoD for a large part of their budget. <a href=\"http://www.forbes.com/sites/instituteforjustice/2015/03/19/the-dea-is-seizing-cash-without-warrants-in-its-version-of-stop-and-frisk/\">The DEA in particular has been incentivized by its ability to seize large amounts of cash without due process</a>.</p>\n<p>There is already some momentum generated by the <a href=\"https://www.youtube.com/watch?v=3kEpZWGgJks\">John Oliver piece on this subject</a>.&#xA0;The public is easily able to understand the concept of a perverse incentive in this situation because it is so transparent. Police agencies also might find it hard to mount resistance against changing this, but I don&apos;t know the shape of current efforts here.&#xA0;</p>\n<p>Why this might be of interest to EAs:</p>\n<p>Normally these sorts of freedom-for-first-worlders ideas would not be very interesting from an EA perspective. I think this is potentially different because of the downstream effects. Incentives to continue the WoD lessons significantly -&gt; Decriminalization -&gt; Demand side collapse for the support network for drug cartels whom murder many people in Latin America and seriously undermine the QoL for many others.</p>\n<p>Yes, the links in this chain are some pretty big jumps and might not happen. But if they are possible AND changing these incentives turn out to be relatively cheap it could be worth it.</p></body></html>", "user": {"username": "RomeoStevens"}}, {"_id": "2pCkRYGJ7LfafdYPz", "title": "EA Advocates announcement", "postedAt": "2015-03-24T20:41:08.054Z", "htmlBody": "<html><body><p>This post is an announcement of an initiative of the Centre for Effective Altruism called &quot;EA Advocates.&quot;</p>\n<p>EA Advocates is a new grassroots rapid response team that will amplify positive coverage of effective altruism and help spread information and ideas. Members will coordinate to execute responses during particular times when they can be unusually effective.</p>\n<p>Peter Singer has joined as the first public signatory of EA Advocates. If you choose to join this group, you&apos;re affirming your intention to participate in some simple, but important, actions on social networks and other online settings. Some of these will be as quick as sharing favorable articles, and others may involve writing comments or brief reviews of EA-related publications. Key initiatives that EA Advocates will take actions to support this year include the current release of <a href=\"http://www.mostgoodyoucando.com/\">Peter Singer&#x2019;s book</a>, Will MacAskill&#x2019;s book on effective altruism due out later this year, and the EA Global summit.</p>\n<div>To join, please provide your information at:&#xA0;<a href=\"http://www.effectivealtruism.org/advocates\">http://www.effectivealtruism.org/advocates</a></div>\n<div><br></div>\n<div>If you have any questions about the group and its plans, you can contact the project&#x2019;s organizer at the Centre for Effective Altruism, Chris Jenkins (me), at&#xA0;<a href=\"mailto:chris@centreforeffectivealtruism.org\">chris@centreforeffectivealtruism.org</a>.</div></body></html>", "user": {"username": "ChrisJenkins"}}, {"_id": "8XjFEaepdhWz93TK9", "title": "EA Survey bar chart plotter", "postedAt": "2015-03-24T02:37:06.394Z", "htmlBody": "<html><body><p>I&apos;ve made a <a href=\"http://pappubahry.com/misc/ea_survey/\">bar chart plotter</a> for the EA survey results (including only data from respondents who said they could be called an EA), which lets you choose the categories to plot. &#xA0;In addition to the survey being unrepresentative of the broader EA community&#xA0;in unknown ways (see, e.g., the discussion&#xA0;<a href=\"http://effectivealtruismhub.com/sites/effectivealtruismhub.com/files/survey/2014/results-and-analysis.pdf\">in the report</a>), this interface lets you make lots of different comparisons that weren&apos;t pre-registered: I&apos;d strongly advise against doing any serious statistics with the results. &#xA0;But still it&apos;s fun to explore!</p>\n<p>Some examples follow.</p>\n<p>The age breakdown:</p>\n<p><img src=\"https://pappubahry.com/misc/ea_survey/images/ea_survey_age_count.png\" alt=\"\"></p>\n<p>The median donation in each age group:</p>\n<p><img src=\"https://pappubahry.com/misc/ea_survey/images/ea_survey_age_q50_donation.png\" alt=\"\"></p>\n<p>The percentage of income donated by members of various EA groups (people can belong to more than one group):</p>\n<p><img src=\"https://pappubahry.com/misc/ea_survey/images/ea_survey_member_percent_donation.png\" alt=\"\"></p>\n<p>Others have noted the relatively low number of EA&apos;s currently donating 10% or more of their income; this observation does not apply to Giving What We Can members, who appear to be following their pledge. &#xA0;(Many GWWC members are full-time students, who are not required to donate 10%.)</p>\n<p>Data is from the EA survey data <a href=\"https://github.com/peterhurford/imsurvey\">on GitHub</a>, and the graphics library I used was&#xA0;<a href=\"http://d3js.org/\">d3.js</a>.</p></body></html>", "user": {"username": "pappubahry"}}, {"_id": "peqLP4SrtjHuNtPuA", "title": "Non-English language effective altruism (including a list of venues)", "postedAt": "2015-03-23T17:49:07.261Z", "htmlBody": "<html><body><p><em>The most up to date versions of the list here can be found on the Effective Altruism Hub&apos;s&#xA0;<a href=\"http://effectivealtruismhub.com/links\">links page</a>, with a community-editable version&#xA0;<a href=\"http://effective-altruism.wikia.com/wiki/Non-English_language_EA_venues\">cross-posted to the EA wiki</a>.</em></p>\n<p>Does anyone have thoughts or reports on non-English language effective altruism? Is it a promising area of outreach, and if so in what languages, and through what methods? In what countries and languages is it most active? (My impression is German, especially in Switzerland, and following that Dutch, Norwegian and Swedish. It&apos;s interesting that north European and historically protestant countries are particularly strong; I believe these have especially strong ethoses of private charity, in particular the UK - think the Victorian culture of charity.)&#xA0;</p>\n<p>A few things worth noting:</p>\n<ul>\n<li>The book&#xA0;<a href=\"http://www.thelifeyoucansave.org/\">The Life You Can Save</a> has been widely translated.</li>\n<li>Matt Wright and I got a basic version of the Giving What We Can site translated into several languages.</li>\n<li>Thanks to <a href=\"http://effectivealtruismhub.com/user/pablo-stafforini\">Pablo Stafforini</a>, Spanish now has&#xA0;http://altruismoeficaz.net&#xA0;</li>\n<li>The <a href=\"http://effectivealtruismhub.com/groups\">list and map of EA groups</a> shows the spread of these; some are much larger or more active than others (filtering to come if I, or someone else, get the time).</li>\n<li>Some have <a href=\"http://everydayutilitarian.com/essays/conversation-with-michael-bitton-about-ea-marketing/\">advocated &apos;spray and pay&apos; EA marketing</a>.</li>\n<li>There is a <a href=\"https://impact.hackpad.com/Non-English-language-EA-outreach-nbXvy0kq9ME\">.impact project page for non-English outreach</a>.</li>\n</ul>\n<p>Here&apos;s a list of non-English language EA venues which I just compiled for the Effective Altruism Hub&apos;s <a href=\"http://effectivealtruismhub.com/links\">links page</a>, and <a href=\"http://effective-altruism.wikia.com/wiki/Non-English_language_EA_venues\">cross-posted this to the EA wiki</a>. It currently consists entirely of the general EA Facebook groups for linguistic communities, but additions are welcome.</p>\n<ul>\n<li>German EA group: https://www.facebook.com/groups/1575844375976037/</li>\n<li>Italian EA group: https://www.facebook.com/groups/795131383874787/</li>\n<li>Hebrew EA group: https://www.facebook.com/groups/786744044734860/?ref=browser</li>\n<li>Bulgarian EA group: https://www.facebook.com/groups/1375044486151027/?ref=browser</li>\n<li>Czech EA group: https://www.facebook.com/groups/329548610588797/?ref=browser</li>\n<li>Dutch: https://www.facebook.com/groups/262932060523750/?ref=browser</li>\n<li>French: https://www.facebook.com/groups/altruistes.efficaces/?ref=browser</li>\n<li>Russian: https://www.facebook.com/groups/1568058766787596/?ref=browser</li>\n<li>Indian languages:&#xA0;https://www.facebook.com/groups/415216661980478/</li>\n<li>Spanish: https://www.facebook.com/groups/1605543996325148/</li>\n</ul>\n<p><strong>If you know anyone potentially interested in EA who speaks these languages, do point or invite them to these groups.</strong>&#xA0;To invite someone to a group, join it and then use the box at the top right of it.</p></body></html>", "user": {"username": "Tom_Ash"}}, {"_id": "ATgDNMhXvi9X3HWtS", "title": "Meetup : Global Poverty Discussion & Prep for \"Experience Poverty\" Fundraiser", "postedAt": "2015-03-23T13:19:57.970Z", "htmlBody": "<html><body><h2>Discussion article for the meetup : <a href=\"/meetups/2f\">Global Poverty Discussion &amp; Prep for &quot;Experience Poverty&quot; Fundraiser</a></h2>\n\t\t  <div>\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span>29 March 2015 02:30:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span>3136 Patty Lane, Middleton, WI 53562</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div>\n\t\t    <div><p>We&apos;ll get together to discuss global poverty and plan for our &quot;Experience Poverty&quot; Fundraiser, more info below. There&apos;ll be snacks! Bring your friends!</p>\n\n<p>Come regardless of whether you are planning on participating in the EA fundraiser!</p>\n\n<hr>\n\n<p>--Experience Poverty Fundraiser--</p>\n\n<p>a global effective altruism fundraiser to alleviate poverty</p>\n\n<p>What we will do: Get sponsored to eat for less than either $1.50/day (the global poverty line) or $2.50/day(what the median person spends on food), for 3 days (you can vary the length of time)</p>\n\n<p>The dates: April 6-8 (you can vary these, but most people in EA groups around the world will be doing it around then)</p>\n\n<p>The charity: The Schistosomiasis Control Initiative (de-worming; helps children in developing countries get healthy so they can do things like go to school)</p>\n\n<p>Where to sign up: <a href=\"http://experiencepoverty.causevox.com/\">http://experiencepoverty.causevox.com/</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href=\"/meetups/2f\">Global Poverty Discussion &amp; Prep for &quot;Experience Poverty&quot; Fundraiser</a></h2></body></html>", "user": {"username": "Gina_Stuessy"}}, {"_id": "8j3irerawuhH8LDyg", "title": "Meetup : How can you choose the best career to do the most good?", "postedAt": "2015-03-23T13:17:00.725Z", "htmlBody": "<html><body><h2>Discussion article for the meetup : <a href=\"/meetups/2e\">How can you choose the best career to do the most good?</a></h2>\n\t\t  <div>\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span>16 April 2015 06:00:00PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span>Frankfurt Adalbertstra&#xDF;e 36a</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div>\n\t\t    <div><p>This time we want to look at the question how we can choose the best career to do the most good in our lives. What do traditional &apos;do gooding&apos; careers look like upon closer inspection? How much good can a doctor do?</p>\n\n<p>We&apos;ll discuss the &apos;replacability argument&apos; and what our current plans are.</p>\n\n<p>If you want to take a look before, I recommend reading <a href=\"https://80000hours.org/.\">https://80000hours.org/.</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href=\"/meetups/2e\">How can you choose the best career to do the most good?</a></h2></body></html>", "user": {"username": "Denise_Melchin"}}, {"_id": "fiGwaK7AAw9xLHcaw", "title": "Common Misconceptions about Effective Altruism", "postedAt": "2015-03-23T09:25:36.304Z", "htmlBody": "<html><body><p>In reaction to a recent article that straw-manned effective altruism seemingly without intent, I decided to write an <a href=\"http://claviger.net/common-misconceptions-about-effective-altruism.html\">article on some common misconception about effective altuism</a>, and Tom Ash started two corresponding wiki pages, one on &#x201C;<a href=\"http://effective-altruism.wikia.com/wiki/Common_objections_to_effective_altruism\">Common objections to effective altruism</a>&#x201D; and one on &#x201C;<a href=\"http://effective-altruism.wikia.com/wiki/Common_objections_to_earning_to_give\">Common objections to earning to give</a>.&#x201D; I&#x2019;ve copied this article into the first. If you have anything to add or correct, you&#x2019;re invited to contribute it there, so that well-meaning journalists can more easily avoid such&#xA0;errors.</p>\n<div>&#xA0;</div>\n<hr>\n<div>&#xA0;</div>\n<p>Effective altruism has seen much welcome criticism that has helped it refine its strategies for determining how to reach its goal of doing the most good&#x2014;but it has also seen some criticism that is fallacious. In the following we want to correct some misconceptions that we&#x2019;ve become aware of so&#xA0;far.</p>\n<h2>If Everyone Did That (&#x201C;Kantian&#xA0;fallacy&#x201D;)</h2>\n<h3>Misconception</h3>\n<ol>\n<li>&#x201C;If we all followed such a ridiculous approach&#x201D; as effective altruism, then all worthwhile causes outside &#x201C;global health and nutrition&#x201D; would cease to receive funding.<sup><a href=\"#fn:ssir\">1</a></sup></li>\n</ol>\n<h3>Short&#xA0;Answers</h3>\n<ol>\n<li>\n<p>Top effective charities have limited room for more funding. At some point they&#x2019;ll have absorbed so much money that additional donations will do much less good, so other charities will become top&#xA0;charities.</p>\n</li>\n<li>\n<p>If only 0.03% of the yearly donations only in the <span>US</span> were shifted to the top effective charities we know of, they would have no room for more&#xA0;funding.</p>\n</li>\n<li>\n<p>Once that point is reached, doing the most good will get slightly more expensive or slightly more risky, and all the other previously less effective or less proven interventions would successively get their&#xA0;funding.</p>\n</li>\n<li>\n<p>But yes, &#x201C;funding for the arts&#x201D; would have to wait until deadly diseases and extreme poverty are sufficiently under&#xA0;control.</p>\n</li>\n</ol>\n<h3>Long&#xA0;Answers</h3>\n<p>In evaluating interventions, charity prioritization typically relies on the criteria of tractability, scalability, and neglectedness. The last two of these turn charity prioritization into an anti-inductive system, where some arguments along the lines of the categorical imperative become inapplicable: You recommend an underfunded intervention, then people follow your recommendation and donate to it, then it reaches its limits in scale, and finally you have to withdraw your recommendation as it is no longer&#xA0;underfunded.</p>\n<p>Imagine you are organizing a large two-day effective altruism convention. There are several hotels close to the venue, one of which is very well known and soon fully booked. Panicked attendees keep asking you what they should do, so you call the other hotels in the vicinity. It turns out there is one that is even closer to the venue with scores of rooms left. So you send out a tweet and recommend that people check in there. They do, and promptly the hotel is also fully booked, and you have to do another round of telephone calls and update your recommendation. But it is fallacious to argue that your first recommendation, or the very act of making it, was wrong to begin with just because if everyone follows it, it&#x2019;s no longer valid. That&#x2019;s in the nature of the&#xA0;beast.</p>\n<p>Because the &#x201C;if everyone did that&#x201D; argument so common, let&#x2019;s give it a name: &#x201C;Kantian fallacy.&#x201D; The &#x201C;buy low, sell high&#x201D; rule of the stock market is not wrong just because if everyone bought low, the price would not be low, and if everyone sold high, the price would not be high. Advising against the overused typeface Papyrus is not wrong just because if no one used it, it would no longer be overused. Surprising someone with a creative present is not wrong just because if everyone made the same present, it would not be&#xA0;surprising.</p>\n<p>The last analogy is less fitting than the previous ones, because we don&#x2019;t actually want good interventions to be underfunded. When all the governments and foundations see how great deworming is and allocate so much funding to it that hardly a worm survives, then any recommendation for more donations for deworming has to be withdrawn in favor of more neglected interventions&#x2014;but that&#x2019;s a reason to&#xA0;party!</p>\n<p>So what would recommendations look like when malaria, schistosomiasis, and poverty are eradicated or eliminated to the extent that other interventions become superior? Or what would happen when other bottlenecks thwart further effective donations in these&#xA0;areas?</p>\n<p>That future is already sending its sunny rays into the past as foundations like Good Ventures and the Gates Foundation already have much more funding available than the currently known top charities could absorb. What happens is that doing good either becomes more expensive (when you trade off cost-effectiveness for scalability) or more risky (when you trade off certainty for other qualities). The latter is the more interesting and encouraging scenario. More on that in the next&#xA0;section.</p>\n<h2>Exclusive Focus on Interventions That are Easy to&#xA0;Study</h2>\n<h3>Misconception</h3>\n<ol>\n<li>\n<p>&#x201C;I mentioned bed nets because that is mostly what Effective Altruism amounts to: It measures what is immediately and visibly measurable, a problem known as the Streetlight Effect.&#x201D;<sup><a href=\"#fn:week\">2</a></sup></p>\n</li>\n<li>\n<p>&#x201C;GiveWell has a particular fixation with global health and nutrition charities. It at least implicitly recommends that one should support charities only in those cause areas.&#x201D;<sup><a href=\"#fn:ssir\">1</a></sup></p>\n</li>\n</ol>\n<h3>Short&#xA0;Answers</h3>\n<ol>\n<li>\n<p>Empirically, more effective altruists are eager to invest into highly speculative, high risk&#x2013;high return interventions than prefer the safe investments of proven and repeatable medical&#xA0;interventions.</p>\n</li>\n<li>\n<p>This eagerness to accept financial and personal risks to effect superior positive impact has led to a flourishing culture of metacharities, prioritization research, medical research, political research and advocacy, research on global catastrophic risk, and much more within the&#xA0;movement.</p>\n</li>\n<li>\n<p>GiveWell in particular has long been been eager to expand to less easy-to-study interventions, so that it has been investigating (under the name Open Philanthropy Project) a wide range of global catastrophic risks, political causes, and opportunities for research funding since before effective altruism had a&#xA0;name.</p>\n</li>\n</ol>\n<h3>Long&#xA0;Answers</h3>\n<p>Where the last answer required a new name for a fancy fallacy, this one is simply called &#x201C;straw&#xA0;man.&#x201D;</p>\n<p>As a pioneer in the field of charity prioritization, GiveWell had a herculean task ahead of it and very limited resources in terms of money, time, and research analysts. (This was years before effective altruism had consolidated into a movement.) Since funneling more donations to above-average charities is already better than the status quo, the team quickly learned that as a starting point they had to focus narrowly on cause areas marked by extreme suffering, interventions with solid track-records of cost-effective and scalable implementation, and charities with the transparency and commitment to self-evaluation that would enable GiveWell to assess them. As it happens, these combinations were mostly found in the cause areas of disease and poverty. This decision was one of necessity at the time, but soon later, GiveWell managed to scale up its operations significantly, so that these restrictions no longer&#xA0;applied.</p>\n<p>Some of the best and most cost-effective giving opportunities may well lie in areas or involve interventions that are harder to study. Hence GiveWell has been investigating these under the brand of the Open Philanthropy Project (initially known as &#x201C;GiveWell Labs&#x201D;) since 2011. (That&#x2019;s still before effective altruism had a name or called itself a movement.) Much scientific research promises great cost-effectiveness; so do some interventions to avert global catastrophic risks and to solve political problems. Doing the most good may well mean investing somewhere in one of these areas&#x2014;where exactly, Open Phil has set out to find&#xA0;out.</p>\n<p>In 2012 the effective altruism movement got its name and consequently  consolidated its efforts at doing the most good. Nowhere in the agenda  of the movement it said that effective interventions needed to be easy  to study or quantify. In fact opinions and preferences on what &#x201C;the most  good&#x201D; means in practice vary (yet some are shared by almost everyone).  According to a <a href=\"/ea/gb/the_2014_survey_of_effective_altruists_results/\">2014 survey</a>,  about 71% of the EAs in the survey sample were interested in supporting  poverty-related causes, but almost 76% were interested in metacharity  including rationality and prioritization research, which are not easy to  quantify. About one third to fourth were interested in each of  antispeciesism, environmentalism, global catastrophic risk, political  causes, and (nonexistential) far future concerns, most of which are hard  to study. There is by no means an unwarranted bias toward interventions  that are easy to study; if anything, there&#x2019;s a surprising tendency  towards speculative, high risk&#x2013;high return&#xA0;interventions.</p>\n<p>Finally, GiveWell not only doesn&#x2019;t &#x201C;implicitly recommends that one should support charities only in [the cause areas of global health and nutrition]&#x201D; but (1) <a href=\"http://www.givewell.org/international/top-charities/give-directly\">recommends a charity</a> outside these areas, (2) writes on every charity review that did not lead to a recommendations that the &#x201C;write-up should not be taken as a &#x2018;negative rating&#x2019; of the charity&#x201D; (emphasis in original), and (3) gives reasons for why a philanthropist may legitimately choose not to donate to their recommended charities right on their <a href=\"http://www.givewell.org/charities/top-charities\">Top Charities</a>&#xA0;page.</p>\n<h2>Consequentialism and&#xA0;Utilitarianism</h2>\n<h3>Misconception</h3>\n<ol>\n<li>Effective altruism depends on a utilitarian or consequentialist morality as implied in statements like, &#x201C;not that [reducing corruption in the police force] could meet [effective altruism&#x2019;s] utilitarian criteria for review.&#x201D;<sup><a href=\"#fn:week\">2</a></sup></li>\n</ol>\n<h3>Short&#xA0;Answers</h3>\n<ol>\n<li>\n<p>What&#x2019;s so bad about wanting to maximize happiness and minimize suffering in the&#xA0;world?</p>\n</li>\n<li>\n<p>But there are also effective altruists with other moral systems, and effective altruism seems to follow from them as&#xA0;well.</p>\n</li>\n</ol>\n<h3>Long&#xA0;Answers</h3>\n<p>Admittedly most effective altruists are utilitarians or consequentialists. If you want to maximize happiness and minimize suffering in the world (or maximize informed preference satisfaction), then it&#x2019;s clear how effective altruism follows&#xA0;forcibly.</p>\n<p>But how about deontology? Take Rawls (figures courtesy of <a href=\"http://www.un.org/esa/socdev/rwss/docs/2010/chapter2.pdf\"><span>UN</span></a>, <a href=\"http://www.who.int/features/factfiles/en/\"><span>WHO</span></a>, and <a href=\"http://www.worldbank.org/en/topic/poverty/overview#3\">World Bank</a>):</p>\n<ol>\n<li>\n<p>More than one in ten people don&#x2019;t have access to safe drinking&#xA0;water.</p>\n</li>\n<li>\n<p>More than one in ten people suffer extreme&#xA0;hunger.</p>\n</li>\n<li>\n<p>More than one in nine people live in&#xA0;slums.</p>\n</li>\n<li>\n<p>Almost half the world&#x2019;s population are at risk of&#xA0;malaria.</p>\n</li>\n<li>\n<p>Almost half the world&#x2019;s population lives on less than the buying power of $2.50 per&#xA0;day.</p>\n</li>\n<li>\n<p>&#x2026;</p>\n</li>\n<li>\n<p>You have limited&#xA0;resources.</p>\n</li>\n</ol>\n<p>Imagine you&#x2019;re in the original position behind the veil of ignorance and have to allocate our limited resources. Surely you&#x2019;d make an admirable effective&#xA0;altruist.</p>\n<p>This is beside the point, but a less corrupt police force will provide greater safety to the population and enjoy greater trust in return. The rich will no longer have recourse to bribing the police, so that poorer people are in a better position to trade and negotiate with them. The positive marginal impact on the happiness of the poor is likely to be greater than the marginal negative impact on the happiness of the rich. So there&#x2019;s one of countless utilitarian cases for fighting&#xA0;corruption.</p>\n<h2>Top-Down and&#xA0;Elitist</h2>\n<h3>Misconception</h3>\n<ol>\n<li>&#x201C;The defective altruism distribution plan &#x2018;requires a level of expertise that few individuals have.&#x2019; Thus, over time, we would require a very centralized and top-down approach to marshal and manage social investment and charitable giving decisions in a manner acceptable to the proponents of this approach.&#x201D;<sup><a href=\"#fn:ssir\">1</a></sup></li>\n</ol>\n<h3>Short&#xA0;Answers</h3>\n<ol>\n<li>That this is the case is a central grievance of the charity market, which effective altruism tries to remedy and without which the movement might not even be&#xA0;necessary.</li>\n</ol>\n<h3>Long&#xA0;Answers</h3>\n<p>It is one of the unfortunate truisms of the human condition that no market is perfect, but the charity market is particularly and abysmally imperfect. If someone wants to buy a solid state drive they might check, among other things, the price per gigabyte. $.96 per gigabyte? Rather expensive. $.38 per gigabyte? Wow, what a bargain! When people want to invest into a company, they check out the company&#x2019;s earning over the past years, compare them to the stock price, and decide whether it&#x2019;s a bargain or usury. Or if you have a headache, do you buy a homeopathic remedy that does nothing for $20 or Aspirin for&#xA0;$5?</p>\n<p>I wasn&#x2019;t there when it happened, but I imagine when the first effective altruists wanted to donate they called charities and were like &#x201C;Hi, I like what you do and want to invest into your program. Could you give me your latest impact figures?&#x201D; I imagine the responses ranged from &#x201C;Our what?&#x201D; over &#x201C;You&#x2019;re the first to ever ask for that&#x201D; to &#x201C;We have no&#xA0;idea.&#x201D;</p>\n<p>When the charities that run the programs don&#x2019;t even know if they do anything good or anything at all in proportion to their cost, then how are donors supposed to find out? They would have to draw on the research of experts in the field and, to some extent, would have to become experts&#xA0;themselves.</p>\n<p>Prioritization organizations want to change that. They flaunt a pot of money promised to the charities that make the best case for being highly effective. That way they incentivize transparency, self-evaluation, and optimization. Eventually, we hope, this will encourage a charity market that makes it much easier for everyone to recognize the charities with the most &#x201C;bang for the&#xA0;buck.&#x201D;</p>\n<div>\n<hr>\n<ol>\n<li>\n<p>Ken Berger and Robert M. Penna, &#x201C;The Elitist Philanthropy of So-Called Effective Altruism,&#x201D; 2013, accessed 2015-03-23, http://www.ssireview.org/blog/entry/the_elitist_philanthropy_of_so_called_effective_altruism.&#xA0;<a title=\"Jump back to footnote 1 in the text\" href=\"http://claviger.net/common-misconceptions-about-effective-altruism.html#fnref:ssir\">&#x21A9;</a></p>\n</li>\n<li>\n<p>Pascal-Emmanuel Gobry, &#x201C;Can Effective Altruism Really Change the World?,&#x201D; 2015, accessed 2015-03-23, http://theweek.com/articles/542955/effective-altruism-really-change-world.&#xA0;<a title=\"Jump back to footnote 2 in the text\" href=\"http://claviger.net/common-misconceptions-about-effective-altruism.html#fnref:week\">&#x21A9;</a></p>\n</li>\n</ol></div></body></html>", "user": {"username": "Telofy"}}, {"_id": "qAqsYp5beGBaYvMwT", "title": "Should altruism be selfless?", "postedAt": "2015-03-22T22:22:09.183Z", "htmlBody": "<html><body><p><em>This is my blogging carnival submission for this month. The topic is: &quot;selflessness&quot;.</em></p>\n<p>Some moral philosophies emphasize consequences and outcomes at the expense of intentions. Other philosophies (including, I would say, common sense morality) place high value on good intentions even if those intentions happen to lead to bad outcomes.</p>\n<p>I don&apos;t often see effective altruists talking much about intentions. Data from the recently published 2014 EA Survey suggests that roughly 75% of EAs are consequentialists. Common EA rhetoric focuses on doing the maximum good, choosing the best possible cause, or perhaps donating as much as you can.</p>\n<p>But another common occurrence is for EAs to profess how much joy earning to give brings them, how fulfilling they find it, how little their donations disadvantage them because of the declining marginal utility of money, or about excited altruism more generally.</p>\n<p>The Maximum Philanthropy effective altruist lifestyle doesn&apos;t seem to be coming from a place of Maximum Selflessness. In some situations, it even seems to come from a place of outright self-benefit. Presumably (obviously?), the decision to achieve self-benefit via earning to give is at least in some part motivated by altruism but EA is very open about the existence of other powerful motivators: the &quot;warm glow&quot; of philanthropy and the benefits that come from perceived selflessness.</p>\n<p>Does this matter at all? What if I openly proclaimed that I was going to donate all my money for 100% selfish reasons? Should I be docked points? It seems that EA benefits from being viewed with a &quot;consequentialist gaze&quot; in that the philosophy generally attempts to achieve the best outcomes, although it is arguably no better than other popular viewpoints when it comes to intentions.</p>\n<p>To what extent does/should selflessness matter for being an effective altruist?</p>\n<p>Does anybody perceive any PR problems related to EA&apos;s closer relationship to Maximum Philanthropy than to Maximum Selflessness?</p></body></html>", "user": {"username": "Bitton"}}, {"_id": "gT3BxddC899gmpGxG", "title": "What Cause(s) Do You Support? And Why?", "postedAt": "2015-03-22T00:13:37.886Z", "htmlBody": "<html><body><h1><span>Not The Whole Picture</span></h1>\n<p>The results for the 2014 effective altruism survey <a href=\"/ea/gb/the_2014_survey_of_effective_altruists_results/\">were recently released</a>. While there&apos;s criticism the survey <a href=\"/ea/gb/the_2014_survey_of_effective_altruists_results/2yb\">wasn&apos;t as representative or accurate</a> as we would have hoped, the numbers given by survey respondents about what causes favor as the most effective to work within could be used as a proxy for what effective altruism supports on the whole. The numbers as taken from the survey results are given below.</p>\n<ul>\n<li>Poverty 579 <span> </span></li>\n<li>Metacharity 422&#xA0;<span> </span></li>\n<li>Rationality 411&#xA0;<span> </span><span> </span></li>\n<li>Cause Prioritization 345&#xA0;<span> </span></li>\n<li>AI Risks 332&#xA0;<span> </span></li>\n<li>Environmentalism 317&#xA0;<span> </span></li>\n<li>Existential Risk 301&#xA0;<span> </span></li>\n<li>Animals 296&#xA0;<span> </span></li>\n<li>Politics 291&#xA0;<span> </span></li>\n<li>Far future 233<span> </span></li>\n</ul>\n<p><span> <span> </span></span>Aside from how the sample may not be representative of effective altruism as a whole community, I&apos;m also not confident these results represent the nuance and specificity of why and how each of us support different causes. I think a big factor is many of us don&apos;t favor only one cause, and which cause we favor &quot;the most&quot; doesn&apos;t capture exactly capture how we would like our thoughts and actions to be represented. For example, the analysis of the survey noted:</p>\n<blockquote>\n<p>Despite &#x201C;animal welfare&#x201D; being a less popular cause than other causes, there appears to be a widespread concern for reducing meat among EAs, with 69.1% of EAs at least reducing the amount of meat they eat, a 33.1% vegan/vegetarian rate, and a 15.6% vegan rate. While it&#x2019;s hard to get reliable national statistics, it seems indisputable that the vegetarianism / veganism rate is much higher than the US national average of ~3% vegetarian and ~0.5% vegan.&#xA0;</p>\n</blockquote>\n<p><span> <span> </span></span>This indicates a concern for non-human animal welfare or rights within effective altruism beyond the 8.4% of survey respondents who responded they believe animal advocacy is the cause to work in where they believe the most good can be done. Many people may care about non-human animals, and thus are vegan or vegetarian, but believe either the forms of animal advocacy effective altruism has examined don&apos;t make it a tractable cause at the present time. They may also or otherwise believe while, e.g., reducing or eliminating factory farming is important, primarily working in other cause areas is more important and/or tractable. Regarding the third of survey respondents who reduce their meat consumption, this could be due to how some of us are uncertain about what moral weight to grant to non-human animals. As an anecdote, I know multiple friends and peers who entered effective altruism originally favoring other causes, but became vegetarians or reduced their level of meat consumption due to their exposure to arguments and reasoning from other effective altruists advocating for animals.&#xA0;</p>\n<p><span> <span> </span></span>Another confounding factor is many causes provided for the question on the survey overlap. &quot;Politics&quot; could overlap with any cause, including political advocacy for any other mentioned causes. &quot;Cause Prioritization&quot;, and the &quot;far future&quot; are also vague, arguably spurious, causes, allowing overlap with virtually any other cause. Any effective altruist could favor a specific cause (area), while also thinking &quot;cause prioritization&quot; and the &quot;far future&quot; are possibly the most important things ever, because who doesn&apos;t want to know what the best actions to take are, or how to preserve what we value for the indefinite future? <a href=\"http://en.wikipedia.org/wiki/Superintelligence:_Paths,_Dangers,_Strategies\">Concern for A.I. Risks</a>&#xA0;alone has virtual overlap with concern for existential risks, but doesn&apos;t why and how we&apos;re concerned about other existential risks. The idea of &quot;meta-charity&quot; is one perhaps unique to effective altruism, geared towards funding and supporting organizations within effective altruism which support and advocate for other causes more among the public more broadly, or research what new causes we should favor. This latter part of &quot;meta-charity&quot; seems indistinguishable from &quot;cause prioritization&quot;.&#xA0;</p>\n<h1><span>It&apos;s Okay to Have Complicated Opinions</span></h1>\n<p><span> <span> </span></span>These confusions and uncertainties aside, it&apos;s difficult enough for each of us as individuals trying to make hard ethical decisions based on mixed interpretations of limited information. I myself and dozens of other effective altruists I know are not so confident in supporting any single cause (area) that they don&apos;t believe which cause they favor most could switch in a matter of months. Also, the partnership between charity evaluator Givewell and foundation Good Ventures could return research causing us to favor new causes that currently aren&apos;t greatly represented within effective altruism, such as concern for <a href=\"http://www.givewell.org/labs/policy\">advocacy of various and specific policies</a>, <a href=\"http://www.givewell.org/labs/scientific-research-funding\">scientific research</a>, or <a href=\"http://www.givewell.org/labs/causes/biosecurity\">biosecurity</a>. What drew many of us to effective altruism in the first place was the idea of figuring out how to do the most good, without already having a specific cause in mind as one promising the most opportunity for doing good. Our minds can or will change. Effective altruism is a young movement, and the landscape of what causes may not be so stable.</p>\n<p><span> <span> </span></span>I believe all these considerations are frequently overlooked in conversations in effective altruism. I&apos;ve followed many conversations within effective altruism discussing the various pros and cons of specific cause areas. These conversations don&apos;t often leave room for us expressing uncertainty to explain how we have hope and skepticism, both unresolved, for multiple cause areas. I think those of us holding such opinions might represent a plurality of effective altruists. This may not be captured in either any statistics, or common impressions, of effective altruism. On the other hand, those of us with great confidence a single cause carries more opportunity to do the most good than any other cause may not often have way to put forward our best arguments for it.&#xA0;</p>\n<p><span> <span> <span> </span></span></span><em>So, I welcome you to make the case in the comments for why you believe what cause(s) do or don&apos;t provide the best opportunity for doing the most good, or not</em>. Remember when doing so to be <a href=\"/ea/7x/supportive_scepticism/\">supportive of others in discussion and debate</a>.</p></body></html>", "user": {"username": "Evan_Gaensbauer"}}, {"_id": "RSF9yLfmuJj3f4pCi", "title": "Precise Altruism", "postedAt": "2015-03-21T20:55:14.834Z", "htmlBody": "<h2>Summary</h2><p><a href=\"https://github.com/Telofy/precise-altruism\">Precise Altruism</a> is a service that reads a number of news feeds of effective altruism organizations and general news aggregators and classifies the news articles according to their relevance to altruism and effective altruism. Articles that fall into this category are then linked and summarized on Tumblr and posted to Twitter and Facebook under the name of Altrunews. (A post is by no means to be understood as an endorsement.)</p><p>You can follow Altrunews on <a href=\"http://altrunews.claviger.net/\">Tumblr</a>, <a href=\"https://twitter.com/Altrunews\">Twitter</a>, and <a href=\"https://www.facebook.com/altrunews\">Facebook</a>.</p><h2>Introduction</h2><p>Precise Altruism is a university project by <a href=\"https://github.com/helmersl/\">Lea Helmers</a> and me, which we worked on throughout a data science course by <a href=\"https://github.com/kashif\">Dr. Kashif Rasul</a> at the Freie Universit\u00e4t Berlin.</p><p>The service reads feeds from the following sources and classifies them based on a hand-annotated corpus of a few hundred news articles.</p><ul><li>The Against Malaria Foundation</li><li>GiveWell (two feeds)</li><li>GiveDirectly</li><li>Giving What We Can</li><li>The Live You Can Save</li><li>Charity Science</li><li>80,000 Hours</li><li>David Roodman\u2019s blog</li><li>Julia Wise\u2019s blog (Giving Gladly)</li><li>Ben Kuhn\u2019s blog</li><li>Brian Tomasik\u2019s blog (Reducing Suffering)</li><li>My own blog (claviger.net)</li><li>The Effective Altruism Forum</li><li>Animal Charity Evaluators</li><li>The Abdul Latif Jameel Poverty Action Lab (three feeds)</li><li>Center for Global Development</li><li>Sentience Politics</li><li>The Global Priorities Project</li><li>Gates Notes</li><li>Evidence Action</li><li>Your Siblings</li><li>The World Health Organization</li><li>Raising for Effective Giving</li><li>Good Ventures</li><li>Innovations for Poverty Action</li><li>Vegan Outreach</li><li>The Future of Humanity Institute</li><li>Animal Equality</li><li>The Google News feed of English-language news articles containing certain keywords</li><li>The Kuerzr feed of English-language news articles containing a similar set of keywords</li></ul><p>Unfortunately I couldn\u2019t find the feeds of the Schistosomiasis Control Initiative, the Copenhagen Consensus Center, and Mercy For Animals. I\u2019m open for further source feed suggestions, preferably Atom, not RSS.</p><p>By the way, <a href=\"/ea/d3/eas_on_rss_and_reddit/\">Peter Hurford</a> runs an unfiltered feed exclusively over EA blogs, and I wrote a thing once, the <a href=\"https://bitbucket.org/Telofy/resyndicator\">Resyndicator</a>, that could be used for something like that (especially in scenarios where it doesn\u2019t already exist).</p><h2>The Classifier</h2><p>The heart of our application is a classification pipeline built with <a href=\"http://scikit-learn.org/\">scikit-learn</a>, which uses tf-idf to generate a feature matrix of our news data and then a Stochastic Gradient Descent classifier to assign them one of our two categories.</p><p>We used grid search and cross-validation to determine the optimal classifier and an optimal set of parameters for it. Using only a small set of plausible parameters and only three splits for the cross-validation, we quickly determined the four out of initially ten classification algorithms that performed best on our data, Stochastic Gradient Descent, Logistic Regression, and two variations of the Support Vector Machines classifier. In our final, most finely tuned run, Stochastic Gradient Descent achieved an F1 score of 93%, about two percentage points more than the best of the other three classifiers.</p><p>The clearest takeaways from the grid search over a plausible SGD parameter set were that as loss functions <code>log</code>, <code>hinge</code>, <code>modified_huber</code>, and <code>perceptron</code> performed well; that as penalty <code>l2</code> and <code>elasticnet</code> performed well; that activating the shuffling helped; that using bigrams in addition to unigrams was useful but that 3-grams did not improve the F1 score; and that the best values for <code>alpha</code> and <code>n_iter</code> varied widely among the best configurations.</p><p>It\u2019s been almost a year since I implemented this, so please don\u2019t quiz me on the details.</p><figure class=\"image image_resized\" style=\"width:14.09%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/RSF9yLfmuJj3f4pCi/tftjx03bmltv0qntqf0x\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/RSF9yLfmuJj3f4pCi/md7nwu0auosj3hbl54bw 106w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/RSF9yLfmuJj3f4pCi/plzljnrkgefsfladrvoj 186w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/RSF9yLfmuJj3f4pCi/m0wgzru2ghreqgpqrj6t 266w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/RSF9yLfmuJj3f4pCi/cs2sdxmki3r60gxulj9n 346w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/RSF9yLfmuJj3f4pCi/z0ltiha8yb1ctigqz5xp 426w\"></figure><h2>The Daemon</h2><p>The daemon is the service that continuously runs on the server and continually checks the source feeds. It sends <code>if-modified-since</code> and <code>if-none-matches</code> headers whenever possible to minimize server load and traffic. Then the feed entries are compared to those in the database to filter out known ones, whereby we also compute the <a href=\"http://en.wikipedia.org/wiki/Jaccard_index\">Jaccard distance</a> between the preprocessed titles to avoid posting the same press releases over and&nbsp;over.</p><p>The articles that are typically associated with these entries are then fetched, stripped of boilerplate using Readability, summarized using Sumy, and finally posted to Tumblr. We extended the extraction step with one that also extracts a featured image and added a naive keyword extraction for the post tags on&nbsp;Tumblr.</p><figure class=\"image image_resized\" style=\"width:14.4%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/RSF9yLfmuJj3f4pCi/x0u4ohhla2jlkltxewaa\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/RSF9yLfmuJj3f4pCi/ufroz9zfnbtrk98qe8za 106w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/RSF9yLfmuJj3f4pCi/bxpgaqxslqdhbdczkwbk 186w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/RSF9yLfmuJj3f4pCi/pj0wix6lzxxsky4dgkeu 266w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/RSF9yLfmuJj3f4pCi/iukwkbuxoha5ttgqcues 346w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/RSF9yLfmuJj3f4pCi/qy1lrdknmqtxwrbj5pvx 426w\"></figure>", "user": {"username": "Telofy"}}, {"_id": "xxanTNJsco5Hkzqso", "title": "Tech job Q&A", "postedAt": "2015-03-19T17:52:17.386Z", "htmlBody": "<html><body><p>There&apos;s been some <a href=\"https://www.facebook.com/groups/effective.altruists/permalink/841118925944466/\">discussion in the Facebook group</a>&#xA0;where a bunch of people wanted various info about jobs in the tech industry.</p>\n<p>A lot of people expressed interest in asking questions and a lot of people expressed interest in answering them, so I thought maybe the forum would be a better venue for this than a Facebook comment thread. So, ask away! I&apos;ll come back to answer stuff later today. (And hopefully some other folks will too so that it&apos;s not just my perspective!)</p></body></html>", "user": {"username": "Ben_Kuhn"}}, {"_id": "MxwmSuChbMpPtPRCA", "title": "At the intersection of Global Health and Global Risks: Bill Gates talks about epidemic preparation [LINK]", "postedAt": "2015-03-18T20:07:52.496Z", "htmlBody": "<html><body><p>http://www.nytimes.com/2015/03/18/opinion/bill-gates-the-ebola-crisis-was-terrible-but-next-time-could-be-much-worse.html</p>\n<p>&gt;&quot;<span>when you build a clinic to deliver primary health care, you&#x2019;re also creating part of the infrastructure for fighting epidemics.&quot;</span></p>\n<p>I&apos;m happy to see this area getting attention</p></body></html>", "user": {"username": "RomeoStevens"}}, {"_id": "E3t6adWgDXm3pNoYh", "title": "Assessing EA Outreach\u2019s media coverage in 2014", "postedAt": "2015-03-18T12:02:38.223Z", "htmlBody": "<html><body><p>&#xA0;</p>\n<p><em>Effective Altruism Outreach is a sub-project within the Centre for Effective Altruism, led by Niel Bowerman, Kerry Vaughan, Tyler Alterman and William MacAskill. Its primary purpose is to grow and strengthen the effective altruism community. For more information, see </em><a href=\"http://www.nielbowerman.com/2014/05/effective-altruism-outreach-plans/\"><span><em>here</em></span></a><em>.</em></p>\n<p>A core part of EA Outreach&#x2019;s strategy for 2015 involves gaining attention to EA ideas from mainstream media. It&#x2019;s highly unclear to us how valuable this is: it&#x2019;s perfectly plausible to us that this will involve generating a lot of noise, but that this won&#x2019;t ultimately generate much value; it&#x2019;s also plausible to us that it will lead to significant connections that wouldn&#x2019;t have otherwise happened. It may also be that some sorts of media attention are much more valuable than others. For these reasons, and because we feel we don&#x2019;t currently have a good understanding of these issues, we&#x2019;re conceiving of this aspect of EA Outreach as an experiment. We&#x2019;ll therefore periodically take the opportunity to reflect on aspects of our media initiatives, so that we can better assess whether we should continue with this aspect of our strategy, and if so in what way we should approach it. It seems almost impossible to get high-quality evidence on the issues that we care about in this area, so in our &#x2018;experimentation&#x2019; strategy we are forced to rely on a small number of data points and a lot of reflection.</p>\n<p>In 2014, getting media attention for EA was not one of our aims. However, the popularity of my ALS ice bucket challenge article provided us with an opportunity to do some media outreach and start some discussion of effective altruism in the media. In this post, I describe what happened, what short-term and long-term impact I think it had, and what lessons I took away from it.</p>\n<p><a></a></p>\n<p><strong>Background</strong></p>\n<p>On August 14, 2014, I wrote an article on the Ice Bucket Challenge for Quartz, which the magazine entitled &#x201C;<a href=\"http://qz.com/249649/the-cold-hard-truth-about-the-ice-bucket-challenge/\"><span>The Cold Hard Truth about the Ice Bucket Challenge</span></a>.&#x201D; It became extremely popular. We can&#x2019;t disclose the viewing figures, but it received about nine times as many views as my second most popular article, and 30 times as many views as my median article. The article <a href=\"http://www.sharedcount.com/%22%20%5Cl%20%22url=http://qz.com/249649/the-cold-hard-truth-about-the-ice-bucket-challenge/\"><span>received</span></a> 141 Google+ shares, 467 LinkedIn shares, 1490 tweets, 16,008 Facebook shares and 41,967 Facebook likes. It also led to a significant amount of attention in other venues, with coverage in <a href=\"http://www.theguardian.com/sustainable-business/2014/sep/05/als-ice-bu\"><span><em>The Guardian</em></span></a>, <a href=\"http://www.telegraph.co.uk/men/the-filter/11058891/Why-I-turned-down-the-Ice-Bucket-Challenge.html\"><span><em>The Telegraph</em></span></a>, <a href=\"http://www.latimes.com/business/hiltzik/la-fi-mh-ice-b\"><span><em>Los Angeles Times</em></span></a>, <a href=\"http://www.newyorker.com/news/daily-comment/better-ice-bucket-challenge\"><span><em>The New Yorker</em></span></a>, <a href=\"http://www.bbc.com/news/magazine-29013707\"><span>BBC News</span></a>, <a href=\"http://www.cbsnews.com/news/ice-bucket-challenge-more-than-just-hashtag-activism/\"><span>CBS News</span></a>, <a href=\"http://www.vox.com/2014/8/20/6040435/als-ice-bucket-challenge-and-why-we-give-to-charity-donate\"><span>Vox</span></a>, <a href=\"http://www.slate.fr/\"><span>Slate</span></a>, and dozens of other news sources, and appearances from Niel Bowerman and I in international <a href=\"http://www.bbc.co.uk/programmes/b04g1drf\"><span>radio</span></a> and <a href=\"http://stream.aljazeera.com/sto\"><span>television</span></a>.</p>\n<p>The article had a mixed reception. &#xA0;Of those we sampled, most twitter shares were positive; most facebook comments were critical.&#xA0;</p>\n<p>On August 18, I wrote a follow-up article, which Quartz entitled &#x201C;<a href=\"/%22htt\"><span>This week, let&#x2019;s dump a few ice buckets to wipe out malaria too</span></a>&#x201D; (again, I wasn&#x2019;t responsible for the title). This one received the typical number of views.</p>\n<p>&#xA0;</p>\n<p><strong>Positive impact</strong></p>\n<p>The short-run impact of the article was as follows:</p>\n<p><strong><em>Referrals to GiveWell</em></strong><em>:</em> ~10,000 unique visitors. Elie told me that, on average, 1 in 200 unique visitors donate, that the average donation is ~$1000, and that he estimates that 50% of people are repeat donors. However, we both agree that these numbers would give too high an estimate of the value of a unique visitor, because much of GiveWell&#x2019;s money moved comes from very large donors, who have heard about GiveWell from multiple sources.</p>\n<p>From their <a href=\"http://files.givewell.org/files/images/GiveWell%20Metrics%20Report%20%E2%80%93%202013.pdf\"><span>2013 metrics data</span></a>, $3mn was moved via small donors (less than $10k) in 2013. On average, 14% of donors came via online referral; assuming that this is representative for small donors that would give $420,000 via online referral. There were 151,000 visitors via referral links, giving a money moved per visitor figure of $2.78.</p>\n<p>Using this number, the Quartz article would have moved $27,800 (not including regular giving beyond a year). This was quickly estimated, and there may well be errors in this assessment, and still seems somewhat too high to me. We could therefore give cautious bounds of between $5,000 and $50,000 moved as a result of the article.*</p>\n<p><strong><em>Referrals to Giving What We Can:</em></strong> ~9,000 unique visitors. Soon after the article, we received 3 pledges and 8 try out givers who cited &#x2018;on-line article&#x2019;. We&#x2019;ll follow up with these people, but it&#x2019;s likely that not all were influenced by the Quartz article, rather than some other online article. If we assume 3 pledges only, the article raised approximately $1&#xA0;million in pledged donations. Converting this into the value of present donations is a tricky issue, but my guess is that the long-run money moved via new pledges is somewhat greater than that via increased traffic to GiveWell&#x2019;s site.</p>\n<p><strong><em>Donations to SCI: </em></strong>As a result of the initial article I wrote, Tim Harford invited Niel Bowerman from CEA and Elie Hassenfeld from GiveWell onto BBC Radio 4&#x2019;s &#x2018;More or Less&#x2019; show on &#x2018;the numbers behind the news&#x2019; to discuss effective altruism. &#xA0;This resulted in follow-up pieces on the popular More or Less&#x2019;s podcast, in BBC magazine, and in the Financial Times. &#xA0;In the interview with Tim Harford, Elie and Niel discussed SCI, and Tim Hartford decided to donate there at the end of the show. &#xA0;After the appearances, SCI contacted us to report that they had received several &#xA3;1000s of donations as a result of our media. &#xA0;The exact amount SCI received as a result of this media attention was difficult for them to estimate relative to the variable background rate, but they suggested it may have been as much as &#xA3;10,000. &#xA0;</p>\n<p>Given these figures, and given the fact that an article as successful as the ice bucket article is perhaps a one in twenty event, my impression is that the short-run benefits of writing articles are not themselves sufficient to justify the time investment, compared to other sorts of outreach.</p>\n<p>However, my guess is that the main benefit of media attention is longer-term: leading to further media opportunities in the future; improving my position as a public advocate of effective altruism; increasing the real-world credibility of the effective altruism movement; generating connections with people who we wouldn&#x2019;t otherwise have met; and, most importantly, learning via practical experience of engaging in the media.</p>\n<p>This view is consistent with our conclusions from previous media rounds. Relative to the size of the media attention Giving What We Can and 80,000 Hours has had in previous years, the short-run benefit has been lower than one would expect. However, it has led to some of our most valuable relationships, with people who were initially in very different circles, who we would not otherwise have met.</p>\n<p>&#xA0;</p>\n<p><strong>Why was the article so popular?</strong></p>\n<p>My leading explanations (in order of plausibility; not mutually exclusive) are:</p>\n<ul>\n<li>Snowball effects</li>\n<li>The article piggy-backed on an extremely popular trend.&#xA0;</li>\n<li>The title of the article was particularly good at arousing interest.</li>\n<li>The article defended a minority position.</li>\n<li>The article discussed an issue that&#x2019;s rarely covered in the media.</li>\n</ul>\n<p>&#xA0;</p>\n<p><strong>Mistakes made</strong></p>\n<p>In my view, the article is of lower quality than other Quartz articles I&#x2019;ve written. It was written quickly; it half-makes several distinct points rather than having one clear focused point; given that people many find the central points surprising, it made those points too hastily; and at times the tone was unnecessarily snarky.&#xA0;</p>\n<p>I do not know if I should have spent more time on the article to improve its quality. If I&#x2019;d known how popular it would be, then I certainly should have done; but I didn&#x2019;t know that (nor did I know how popular Quartz articles could get). Moreover, I have a distinct worry that what I call poor quality was a <em>positive</em> factor, in terms of the article&#x2019;s popularity. People are more easily annoyed&#x2014;and more likely to voice their annoyance on social media&#x2014;at articles with poorly justified claims; readers will more easily read whatever they want into vague or ambiguous statements; and an article with several distinct claims has a higher chance of piquing the reader&#x2019;s curiosity. This explanation, if true, would be deeply depressing, but would also explain a lot about the poor quality of many popular articles. This could be investigated further by, for example, looking at popular writers, and seeing how the quality of their most popular writing compares to the quality of their less popular writing.</p>\n<p>The potential costs from the article were:</p>\n<p>(i) angering people, and turning them off ideas relating to effective altruism;&#xA0;</p>\n<p>(ii) damaging my brand, or the brand of effective altruism.&#xA0;</p>\n<p>My impression is that, for a one-off article, these aren&#x2019;t particularly great costs. Consideration (ii) is the larger concern. There is a real long-run risk of being perceived as a charity skeptic (similar to e.g. Bill Easterly), which suggests I want to strictly limit how many &#x2018;critical of charity&#x2019; pieces I write. I&#x2019;m even more concerned with associating the brand with poor quality of argument than with the sort of contrarianism that this article might have been perceived as embodying. This provides a reason in favour of writing fewer but more in-depth articles.</p>\n<p>A separate mistake, in my view, is that we should have capitalized more on the success of the article. For example, I could have written a series of articles on the topic, using the opportunity to discuss charity cost-effectiveness in more depth. This would have also mitigated some of the brand-related worries. As noted, my follow-up article was only as popular as my typical article, which I took to be evidence against spending more time on it. However, other articles on the ice bucket challenge also did very well on Quartz, and my follow-up article had a poor title, so I think I put too much weight on that fact.</p>\n<p>&#xA0;</p>\n<p><strong>Overall Assessment</strong></p>\n<p>It&#x2019;s very difficult to assess how valuable the article was, and whether it was positive or negative in value.&#xA0;</p>\n<p>My guess is that the benefits outweigh the costs in this instance. However, I don&#x2019;t think that I should keep writing similar articles: my hunch is that the marginal costs, in terms of brand damage, of articles like this are either non-diminishing or increasing, whereas the marginal benefits (learning and profile), are decreasing. I do plan on writing more articles for Quartz.com, Vox.com, and other media outlets, however I plan on making them comparatively more rigorous than the article in question. &#xA0;</p>\n<p>&#xA0;</p>\n<p><strong>Lessons learned</strong></p>\n<p>The short-term benefits of media attention are comparatively small but non-negligible.</p>\n<p>Representing the minority view in an ongoing debate seems to be a promising strategy of gaining media attention. &#xA0;In an attempt to insure &#x201C;balance&#x201D;, the media give roughly equal weight to all viewpoints, regardless of popularity. &#xA0;As a consequence, articles defending minoritarian positions will tend to receive disproportionate media coverage.</p>\n<p>Brand-management is going to be very difficult, because it&#x2019;s so difficult to predict what will go viral, difficult to predict how people will react, and very difficult to judge what the appropriate level of controversiality is.</p>\n<p>&#xA0;</p>\n<p><strong>Future experiments</strong></p>\n<p>In the coming months I will experiment by with writing longer and comparatively more rigorous articles on carefully chosen topics.&#xA0;</p>\n<p>This will greatly increase the time cost of writing articles. How to balance increased quantity with increased quality is difficult to know. Moreover, though developing a personal brand as &#x201C;the really reasonable and well-informed guy&#x201D; would be optimal, it&#x2019;s highly unclear to me whether this is achievable. There are examples of people who have been successful in this regard (like Nate Silver and Tim Harford), but it&#x2019;s difficult to generalize from cherry-picked examples. However, it&#x2019;s worth trying it out.&#xA0;</p>\n<p>These articles will be stored up and released around the time of my book launch to help raise the profile of the book and to help boost book sales. &#xA0;</p>\n<p>&#xA0;</p>\n<p><strong>Plans for 2015</strong></p>\n<p>EA Outreach has hired Goldberg McDuffie Communications to raise the profile of Peter Singer&#x2019;s book launch in April 2015. &#xA0;We have already distributed advanced copies of Peter&#x2019;s book to over 100 journalists. &#xA0;</p>\n<p>In May 2015 Peter Singer will be in the UK for the UK launch of his book and Yale University Press will be working with us to promote Peter&#x2019;s book here. &#xA0;Text Publishing will manage Peter&#x2019;s Australian book launch and associated media push. &#xA0;</p>\n<p>We&#x2019;re still deciding whether to hire a publicist or marketing firm to help with the launch of my book in August 2015; it&#x2019;s unclear what the value added will be over my publishers&#x2019; own efforts. &#xA0;Penguin will be promoting my book in the US, and we have Guardian Faber and CEA publicizing my book in the UK. &#xA0;We will be negotiating rights with other countries in the next few months. &#xA0;</p>\n<p>&#xA0;</p>\n<p><span>*</span> Given that the money moved per visitor figure <strong>may</strong> be as high as $2.78, and may be even higher, it seems worthwhile to experiment with paying for ads to GiveWell&#x2019;s site, to see if one can achieve a better than 1:1 return on expenditure.</p>\n<p>&#xA0;</p>\n<p><span> </span></p>\n<p>&#xA0;</p>\n<p><!--[if gte mso 9]><xml> <o:DocumentProperties> <o:Revision>0</o:Revision> <o:TotalTime>0</o:TotalTime> <o:Pages>1</o:Pages> <o:Words>2157</o:Words> <o:Characters>12295</o:Characters> <o:Company>Oxford University</o:Company> <o:Lines>102</o:Lines> <o:Paragraphs>28</o:Paragraphs> <o:CharactersWithSpaces>14424</o:CharactersWithSpaces> <o:Version>14.0</o:Version> </o:DocumentProperties> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--> <!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>JA</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> <w:UseFELayout /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--> <!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:Cambria; mso-ascii-font-family:Cambria; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Cambria; mso-hansi-theme-font:minor-latin;} --> <!--[endif] --> <!--StartFragment--> <!--EndFragment--></p>\n<p>&#xA0;</p></body></html>", "user": {"username": "William_MacAskill"}}, {"_id": "dTw2ZocntaMso4iaA", "title": "We are Seb Farquhar and Owen Cotton-Barratt from the Global Priorities Project, AUsA!", "postedAt": "2015-03-17T15:59:12.529Z", "htmlBody": "<html><body><p><span>Hi, we are Seb Farquhar and Owen Cotton-Barratt from the Global Priorities Project here from 8pm-10pm UK GMT (4-6pm Eastern) to answer any questions you might have! You can post questions below before then - on our research, the work we&#x2019;ve done externally, our plans for the future, or anything else. Suggestions and comments are equally welcome.</span></p>\n<p><span><br></span></p>\n<p><span>What the Global Priorities Project does</span></p>\n<p><span>The Global Priorities Project researches prioritisation and connects effective altruists with governments and foundations.</span></p>\n<p><span><br></span></p>\n<p><span>We identify good policy ideas and decision-making methods based on effective altruist principles.This involves </span><a href=\"http://globalprioritiesproject.org/2015/02/project-overview-problems-of-unknown-difficulty/\"><span>blue-skies research</span></a><span>, focus on </span><a href=\"http://globalprioritiesproject.org/2015/03/ylds-and-ylls/\"><span>specific relevant questions</span></a><span>, but also testing </span><a href=\"http://globalprioritiesproject.org/2015/02/research-note-requiring-liability-insurance-for-dual-use-research/\"><span>concrete policy ideas </span></a><span>with stakeholders through one-on-one meetings and conferences.</span></p>\n<p><span><br></span></p>\n<p><span>Decision-makers generally do not have the time to start with fundamentals, so we put ideas in a form that decision-makers will engage with. For example, our recent report on </span><a href=\"http://globalprioritiesproject.org/2015/02/unprecedented-technological-risks/\"><span>Unprecedented Technological Risks</span></a><span> lays out why global catastrophic risk from things like AI, engineered pathogens, and nanotechnology needs to be taken seriously, in a format that suits policy-makers. We are using platforms like the Oxford Martin School to raise public awareness of EA considerations - like our recent OMS post on developing </span><a href=\"http://globalprioritiesproject.org/2015/02/the-hidden-benefit-of-self-driving-cars-that-might-matter-the-most/\"><span>social institutions for AI safety</span></a><span>.</span></p>\n<p><span><br></span></p>\n<p><span>We have begun to have decision-makers approach us privately for advice, as they have learned we have useful insights. </span></p>\n<p><span><br></span></p>\n<p><span>At the same time, we believe EAs can also learn from traditional decision-making institutions. We make sure the lessons flow in both directions. We offer </span><a href=\"http://globalprioritiesproject.org/2015/03/neutral-hours-a-tool-for-valuing-time/\"><span>advice to EAs</span></a><span> on individual decisions based on our research. We also advise other EA organisations - for example helping 80,000 Hours </span><a href=\"https://80000hours.org/career-guide/big-picture/should-you-wait/\"><span>develop their career advice</span></a><span>.</span></p>\n<p><span><br></span></p>\n<p><span>Where things go from here</span></p>\n<p><span>The Global Priorities Project is young - we are still testing out avenues for impact (like making really focused policy proposals, drafting primers on important topics like discount rates for policy-makers, or even working as policy evaluation consultants) before we narrow our focus too tightly. Each of our projects is an experiment, and we have learned valuable lessons already and are improving our work from that.</span></p>\n<p><span><br></span></p>\n<p><span>We are also, unfortunately, forced to shelve most our our project ideas because we lack staff. We are hoping to hire a third full-time staff member with complementary skills later this year. To do that, and secure 12 months of reserves, we have a fundraising target of &#xA3;100,000 by the end of May. </span></p></body></html>", "user": {"username": "Sebastian_Farquhar"}}, {"_id": "z5swaf6342AbG93Mp", "title": "The 2014 Survey of Effective Altruists: Results and Analysis", "postedAt": "2015-03-17T00:29:07.352Z", "htmlBody": "<div>\n<p>It's my great pleasure to announce that, after seven months of hard work and planning fallacy, the EA Survey is finally out.</p>\n<p>It's a long document, however, <a href=\"https://rethinkpriorities.org/s/EASurvey2014.pdf\"><strong> so we've put it together in an external PDF</strong></a>.</p>\n<p>\u00a0</p>\n<h2><strong>Introduction</strong></h2>\n<p>In May 2014, a team from <a href=\"http://dotimpact.im/\">.impact</a> and <a href=\"http://www.charityscience.com/\">Charity Science</a> released a survey of the effective altruist community. The survey offers data to supplement and clarify those anecdotes, with the aim of better understanding the community and how to promote EA.</p>\n<p>In addition it enabled a number of other valuable projects -- initial seeding of\u00a0<a href=\"http://effectivealtruismhub.com/user/profiles/intro\">EA Profiles</a>, the\u00a0<a href=\"http://effectivealtruismhub.com/donations/intro\">new EA Donation Registry</a> and the\u00a0<a href=\"http://effectivealtruismhub.com/map\">Map of EAs</a>. It also let us put many people in touch with local groups they didn\u2019t know about, and <a href=\"/ea/ff/creating_a_local_effective_altruist_presence_in/\">establish presences</a> in over 40 new cities and countries so far.</p>\n<p>\u00a0</p>\n<h2>Summary of Important Findings</h2>\n<ul>\n<li>\n<p>The survey was taken by 2,408 people, 1,146 (47.6%) of whom provided enough data to be considered, and 813 of whom considered themselves members of the EA movement (70.9%) and were included for the entire analysis.</p>\n</li>\n</ul>\n<ul>\n<li>\n<p>The top three sources people in our sample first heard about EA from were LessWrong, friends, or Giving What We Can. LessWrong, GiveWell, and personal contact were cited as the top three reasons people continued to get more involved in EA. (Keep in mind that EAs in our sample might not mean all EAs overall\u2026 more on this later.)</p>\n</li>\n</ul>\n<ul>\n<li>\n<p>66.9% of the EAs in our sample are from the United States, the United Kingdom, and Australia, but we have EAs in many countries. You can see the public location responses <a href=\"http://effectivealtruismhub.com/map\">visualized on a map</a>!</p>\n</li>\n</ul>\n<ul>\n<li>\n<p>The Bay Area had the most EAs in our sample, followed by London and then Oxford. New York and Washington DC have surprisingly many EAs and may have flown under the radar.</p>\n</li>\n</ul>\n<ul>\n<li>\n<p>The EAs in our sample in total donated over $5.23 million in 2013. The median donation size was $450 in 2013 donations.</p>\n</li>\n</ul>\n<ul>\n<li>\n<p>238 EAs in our sample donated 1% of their income or more, and 84 EAs in our sample give 10% of their income. You can see the past and planned donations that people have chosen to made public on <a href=\"http://effectivealtruismhub.com/donations\">the EA Donation Registry</a>.</p>\n</li>\n</ul>\n<ul>\n<li>\n<p>The top three charities donated to by EAs in our sample were GiveWell's three picks for 2013 -- AMF, SCI, and GiveDirectly. MIRI was the fourth largest donation target, followed by unrestricted donations to GiveWell.</p>\n</li>\n</ul>\n<ul>\n<li>\n<p>Poverty was the most popular cause among EAs in our sample, followed by metacharity and then rationality.</p>\n</li>\n</ul>\n<ul>\n<li>\n<p>33.1% of EAs in our sample are either vegan or vegetarian.</p>\n</li>\n</ul>\n<ul>\n<li>\n<p>34.1% of EAs in our sample who indicated a career indicated that they were aiming to earn to give.</p>\n</li>\n</ul>\n<p>\u00a0</p>\n<h2>\u00a0The Full Document</h2>\n<p><strong><a href=\"http://effectivealtruismhub.com/sites/effectivealtruismhub.com/files/survey/2014/results-and-analysis.pdf\">You can read the rest at the linked PDF! --&gt;</a></strong></p>\n<p>\u00a0</p>\n<h2><span>A Note on Methodology</span></h2>\n<p>One concern worth putting in the forefront is that we used a convenience sample, trying to sample as many EAs as we can in places we knew where to find them. \u00a0But we didn't get everyone.</p>\n<p>It\u2019s easy to survey, say, all Americans in a reliable way, because we know where Americans live and we know how to send surveys to a random sample of them. Sure, there may be difficulties with subpopulations who are too busy or subpopulations who don\u2019t have landlines (though surveys now call cell phones).</p>\n<p>Contrast this with trying to survey effective altruists. It\u2019s hard to know who is an EA without asking them first, but we can\u2019t exactly send surveys to random people all across the world and hope for the best. Instead, we have to do our best to figure out where EAs can be found, and try to get the survey to them.</p>\n<p>We did our best, but some groups may have been oversampled (more survey respondents, by percentage, from that group than are actually in the true population of all EAs) or undersampled (not enough people in our sample from that subpopulation to be truly representative). This is a limitation that we can\u2019t fully resolve, though we\u2019ll strive to improve next year. At the bottom of this analysis, we include a methodological appendix that has a detailed discussion of this limitation and why we think our survey results are still useful.</p>\n<p>You can find much more than you\u2019d ever want in the methodological appendix at the bottom of the PDF.</p>\n<p>-</p>\n<p>In sum, this is probably the most exhaustive study of the effective altruism movement in existence. \u00a0It certainly exhausted us!</p>\n<p>I'm really excited about the results and look forward to how they will be able to inform our movement.</p>\n</div>", "user": {"username": "Peter_Hurford"}}, {"_id": "Fiqu3FiEb2GooxJu8", "title": "Why averting a DALY through deworming may be better than through malaria nets", "postedAt": "2015-03-16T13:51:29.799Z", "htmlBody": "<html><body><p>A <a title=\"Global Priorities Project - using YLLs and YLDs to evaluate health interventions\" href=\"http://globalprioritiesproject.org/2015/03/ylds-and-ylls/\">new research note is up</a> on the Global Priorities Project site.</p>\n<p>Summary of the note:</p>\n<p>Global public health remains a top contender for the best way to improve welfare through aid. Within health interventions, it is natural to allocate marginal spending to avert the most expected DALYs (disability adjusted life-years) per dollar.</p>\n<p>However, not all DALYs are the same and there are important differences between years of life lost (YLLs) and years lived with disability (YLDs). Not accounting for these categories separately may introduce a bias in decision-making because DALYs do not address non-health outcomes for individuals and the effects of outcomes on others. These effects are different in situations which involve primarily YLLs as opposed to YLDs. This analysis is of particular practical importance to effective altruists because two of the most promising interventions address different types of DALYS &#x2013; deworming primarily averts YLDs and bed nets to prevent malaria primarily avert YLLs.&#xA0;This make us more inclined towards deworming as a top intervention than a naive evaluation would suggest. More sophisticated analyses incorporate terms that address many of these effects, but may still undervalue deworming relative to malaria nets.</p>\n<p>This document is primarily written for people who already place a high weight on DALYs in identifying top public health opportunities. It does not argue for the use of DALYs, or consequentialist reasoning in identifying public health opportunities.</p>\n<p>You can view the full article <a href=\"http://globalprioritiesproject.org/2015/03/ylds-and-ylls/\">here.</a></p></body></html>", "user": {"username": "Sebastian_Farquhar"}}, {"_id": "Qb6RiMdcj5Hr7z6DT", "title": "Meetup : Toronto: Is existential risk reduction a good use of resources?", "postedAt": "2015-03-16T04:27:36.677Z", "htmlBody": "<html><body><h2>Discussion article for the meetup : <a href=\"/meetups/2d\">Toronto: Is existential risk reduction a good use of resources?</a></h2>\n\t\t  <div>\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span>19 March 2015 07:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span>1266 Queen Street West #6, Toronto, ON</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div>\n\t\t    <div><p>Existential risks are threats to our future. Examples include nuclear war, some (possibly engineered) extremely lethal disease, and threats due to emerging technologies.</p>\n\n<p><a href=\"http://www.existential-risk.org/concept.html\">http://www.existential-risk.org/concept.html</a></p>\n\n<p>The effective altruism movement is a friendly alliance containing those who see existential risk as a top priority together with those favouring more conventional causes such as poverty alleviation and animal rights.</p>\n\n<p>The question to think about for this meeting is: is it sane and altruistic to try to reduce existential risk?</p>\n\n<p>Sub-problems:</p>\n\n<ul>\n<li><p>how morally relevant are the vast number of potential future generations?</p></li>\n<li><p>which existential risks do we focus on?</p></li>\n<li><p>how do we make existential risk reduction tractable?</p></li>\n<li><p>in particular, how do we measure the risk of something that hasn&apos;t happened yet? How do we know we&apos;re reducing it?</p></li>\n<li><p>overall, how does xrisk weigh against other areas of EA interest?</p></li>\n</ul>\n\n<p>Also worth giving a shout-out to <a href=\"http://gcrinstitute.org/\">http://gcrinstitute.org/</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href=\"/meetups/2d\">Toronto: Is existential risk reduction a good use of resources?</a></h2></body></html>", "user": {"username": "Giles"}}, {"_id": "6rSi8Mq6jf4Po5Huy", "title": "Last month in EA projects (from .impact - next meeting on Sunday)", "postedAt": "2015-03-15T06:58:33.257Z", "htmlBody": "<html><body><p>A <a href=\"/ea/fr/a_call_for_ideas_ea_ventures/2u5\">recent discussion here</a> suggested that communication and coordination about the EA projects that are happening or being considered could be improved, and that many people weren&apos;t aware of <a href=\"http://dotimpact.im/\">.impact</a>&apos;s providing a venue for this. With this in mind, I thought we&apos;d start posting the notes from its monthly project update meetings on Google Hangouts.</p>\n<p>Here are the notes from the last meeting. They&apos;re scrappy and partial, and largely consist of the original agenda, but do give a decent sense of the most major progress and new ideas. All previous notes can be found <a href=\"http://dotimpact.im/meetings.html\">here</a>, as can the agenda for the next meeting - which is happening this Sunday, and to which anyone&apos;s very welcome! It&apos;s at 9pm UTC (2pm Pacific, 5pm Eastern, 9pm London) and a Google Hangouts link to join will be posted in the <a href=\"https://www.facebook.com/events/353353871519723/\">Facebook event</a> at that time.</p>\n<h1>15 Feb 2015 Projects Update Meeting</h1>\n<h2>Participants</h2>\n<ul>\n<li><a href=\"https://impact.hackpad.com/ep/profile/yYmVtny2ziw\"></a>Tom Ash, Vancouver, Charity Science</li>\n<li><a href=\"/ep/profile/CIjWQRglobd\"></a>Matthieu Tanguay-Carel</li>\n<li><a href=\"/ep/profile/DXCa0lIQAlX\"></a>Kyle Scott, CEA</li>\n<li><a href=\"/ep/profile/w3Qmb3E3Rtf\"></a>Rochelle Harris</li>\n<li><a href=\"/ep/profile/zoB0sSw4vCQ\"></a>Samuel Hilton, London</li>\n<li>Randy Carlton, Boston-based, Charity.is/Commonwealth Market</li>\n<li><a href=\"/ep/profile/tO3BKBSagAl\"></a>Haseeb Qureshi</li>\n<li><a href=\"/ep/profile/B5kgnyspIUQ\"></a>Ozzie Gooen</li>\n<li><a href=\"/ep/profile/vjQUe66H1PF\"></a>Patrick Brinich-Langlois</li>\n</ul>\n<h2>Project Updates</h2>\n<p><strong><a href=\"/e1HVjGcw27B\"></a>.meta&#xA0;</strong></p>\n<p><em>Updates</em></p>\n<ul>\n<li>Tom made some edits to .impact&#x2019;s form for people interested in EA projects or volunteering at <a href=\"http://dotimpact.im/join.html\"></a>http://dotimpact.im/join.html - what are people&#x2019;s thoughts? \n<ul>\n<li>Main changes (some minor ones) \n<ul>\n<li>Attempting to gauge how likely people are to do work \n<ul>\n<li>In intro text said &quot;Please be conservative when giving your answers, as past experience suggests that it&#x2019;s easy to overestimate how likely you are to volunteer. We&#x2019;d love to hear from you if you&#x2019;re potentially interested in this though, even if you decide there&#x2019;s a good chance you won&#x2019;t end up volunteering!&quot;</li>\n<li>Replaced &quot;How interested are you?&quot; with &quot;Being conservative, how likely are you to work on a project?&quot;, including the following options: \n<ul>\n<li>I&#x2019;m interested, but it&#x2019;s quite unlikely (&lt;25%) that I&#x2019;ll end up doing so</li>\n<li>I&#x2019;m interested, but it&#x2019;s somewhat unlikely (25-50%) that I&#x2019;ll end up doing so</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Asked &quot;Are you interested in volunteering on an existing project or starting your own?&quot;</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Tom discussed EA Outreach contacting people who submit this and they&#x2019;d like to do so. They suggested a few small changes which he made.</li>\n</ul>\n<p><em>Discussion</em></p>\n<ul>\n<li>What do people think of these changes? \n<ul>\n<li>They might seem unwelcoming. But the rationale is that there&#x2019;s ample experience across many EA organizations that many people who express interest in volunteering don&#x2019;t end up doing much (plausibly due to the overestimation mentioned), and it&#x2019;s helpful for anyone contacting them to have probed this.</li>\n</ul>\n</li>\n<li>How should we make people who might like to get involved in EA volunteering aware of the form and .impact in general?</li>\n</ul>\n<p><strong><a href=\"/1sERjDWSMiI\"></a>Small EA task suggester</strong></p>\n<p><em>Description</em></p>\n<ul>\n<li>New project</li>\n<li>Description from Sam \n<ul>\n<li>Target audience: \n<ul>\n<li>- Ever got a min with not much to do?</li>\n<li>- Do you ever feel that the EA community spends too much time talking and not enough time acting?</li>\n<li>- Have you never volunteered you time but want to put time into effective actions without too much commitment?</li>\n<li>- Want to do something effective with your time but do not know what?</li>\n</ul>\n</li>\n<li>Me and <a href=\"https://www.facebook.com/jacob.hilton.395\"></a>Jacob have written a little app/web page aimed to help and to encourage EA volunteering. See:<a href=\"http://www1.maths.leeds.ac.uk/~mmjhh/stuff/findmeatask/\"></a><a href=\"http://www1.maths.leeds.ac.uk/~mmjhh/stuff/findmeatask/\"></a>http://www1.maths.leeds.ac.uk/~mmjhh/stuff/findmeatask/</li>\n<li>Instructions: Click to say how much time you have. Get a task. If you do not like it click \u001cfind me another task\u001d. Choose to do a task. Start timer. Do as much as you can before the time finishes. Get points!!</li>\n<li>Then post thoughts below.</li>\n<li>This is a very early minimum viable product beta test version. What I am keen to know is: \n<ul>\n<li>- Do you think we should put more time into this?</li>\n<li>- Would you use this? Regularly?</li>\n<li>- What features does it need for you to use this?</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Original FB thread: <a href=\"https://www.facebook.com/groups/effective.altruists/permalink/809561952433497/\"></a>https://www.facebook.com/groups/effective.altruists/permalink/809561952433497/</li>\n</ul>\n<p><em>Discussion</em></p>\n<ul>\n<li>Kyle: would be ideal to have someone processing people who wanted to volunteer</li>\n<li>Tom: there are different types of tasks, including ones people can do without management (easy wins that we just want to promote), which this is particular useful to launch</li>\n<li>Tom: when do you plan to launch? \n<ul>\n<li>Sam: not planned yet</li>\n</ul>\n</li>\n<li>Haseeb: have option to see all the tasks</li>\n<li>Kyle: Maybe a voting system for tasks?</li>\n<li>Feedback \n<ul>\n<li>Easy view of list of all the tasks</li>\n<li>Make it customisable</li>\n<li>Can rate tasks - may effect if task appears</li>\n<li>Urgency sorting - may effect if task appears</li>\n<li>Add to google canedar</li>\n<li>A notification or google group that adds to the tasks</li>\n<li>maybe make it look nicer</li>\n</ul>\n</li>\n<li>The list of task is more important than functionality</li>\n<li>Can let people use trello to vote on tasks</li>\n<li>Platform for listing tasks \n<ul>\n<li>trello \n<ul>\n<li>has a star function (ask Ollie)</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>&#xA0;Ozzie: open source? \n<ul>\n<li>AP Sam: ask Jacob to do that on github</li>\n</ul>\n</li>\n<li>Kyle: I googled and found this: <a href=\"http://dharmafly.com/tasket\"></a>http://dharmafly.com/tasket</li>\n<li>Sam: Poll on people&#x2019;s thoughts \n<ul>\n<li>Release something simple soon \n<ul>\n<li>Tom&#xA0;</li>\n<li><a href=\"/ep/profile/B5kgnyspIUQ\"></a>Ozzie Gooen</li>\n<li>Randy - Likes the Trello site to start. I wish Asana was free for large groups so we could create/copy project templates.</li>\n<li>Kyle</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p><strong><a href=\"/9F3o9W3pHyx\"></a>Marketing cost-effective poverty charities to religious people</strong></p>\n<ul>\n<li>Some planning and progress on this, to be described</li>\n</ul>\n<p><strong><a href=\"https://impact.hackpad.com/lGglK2kN3Ll\"></a>EA Forum</strong></p>\n<p><em>Updates</em></p>\n<ul>\n<li>Wrote up description of tasks for Patrick, could use some help on this</li>\n<li>Sam has some feedback / suggested improvements for EA forum \n<ul>\n<li>Integration with the wiki</li>\n<li>Sam never really lists London events on the forum, it&#x2019;s just an extra hassle, would be easier if you could input a recurring event \n<ul>\n<li>or even if events automatically listed following posts on fb / meetup</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p><strong><a href=\"https://impact.hackpad.com/lDH4EqYxnRv\"></a>EA Donation Registry</strong></p>\n<p><em>Updates</em></p>\n<ul>\n<li>Not going to integrate with MyGiving after all \n<ul>\n<li>Tom had a long correspondence about this with Steph Crampin \n<ul>\n<li>AP T: forward to Michelle</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Preferred solution is to add the checkbox saying &quot;Make my donations public on the EA Donation Registry&quot;, which Tom already coded up for GWWC and sent to them having discussed it, but which they&#x2019;re now not pasting in</li>\n</ul>\n<p><strong><a href=\"https://impact.hackpad.com/EA-Audio-Reading-group-DPGsHfop93r\"></a>EA Reading Group</strong></p>\n<ul>\n<li>Meeting next week, Sunday at 9pm UTC. Discussing Carnegie&#x2019;s &quot;How to Win Friends and Influence People&quot; (easy read).</li>\n<li>Almost 100% ported to the Goodreads group, facebook will still have events for awhile</li>\n<li>Got a bunch of new people from Goodreads, 33 total</li>\n<li><a href=\"/ep/profile/CIjWQRglobd\"></a>Matthieu Tanguay-Carel has stepped up to help manage the group, thanks so much!</li>\n<li>General congratulation</li>\n<li>Matt: Join and vote on the next books! <a href=\"https://www.goodreads.com/poll/list/151274-effective-altruists?type=group\"></a>https://www.goodreads.com/poll/list/151274-effective-altruists?type=group</li>\n</ul>\n<p><strong><a href=\"https://impact.hackpad.com/UiMcMLwoHZg\"></a>EA survey data analysis</strong></p>\n<p><em>Updates</em></p>\n<ul>\n<li>Should be published next weekend</li>\n</ul>\n<ul>\n<li>Outside view says this target won&#x2019;t actually happen</li>\n</ul>\n<ul>\n<li>Has Peter tried to get suggestions for possible restricted early distribution from Greg? \n<ul>\n<li>Asked, but not answered (update: now answered)</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>Kyle: Are we going to address the selection bias thing? \n<ul>\n<li>Yes, Peter has a really long appendix about it</li>\n</ul>\n</li>\n</ul>\n<p><strong><a href=\"/nbXvy0kq9ME\"></a>Non-English language EA outreach&#xA0;</strong></p>\n<ul>\n<li>Pablo is thinking of doing this online and seeking feedback at <a href=\"https://www.facebook.com/groups/effective.altruists/permalink/823288501060842/\"></a>https://www.facebook.com/groups/effective.altruists/permalink/823288501060842/</li>\n</ul>\n<p><strong><a href=\"/xJYlsB1g5Tb\"></a>Shop for Charity&#xA0;</strong></p>\n<ul>\n<li><a href=\"/ep/profile/y7eKf2jbylz\"></a>Jacob Hilton kindly built the Chrome extension suggested by <a href=\"/ep/profile/zoB0sSw4vCQ\"></a>Samuel Hilton&#xA0;</li>\n<li><a href=\"/ep/profile/vHoFISFIugY\"></a>Shane Stranahan volunteered to build versions for FF/Safari, not IE \n<ul>\n<li>Anyone have experience of this?</li>\n<li>Shane: should be ready tonight!</li>\n</ul>\n</li>\n<li>Will give S4C a proper push given the successful initial experiment</li>\n</ul>\n<p><strong><a href=\"/JtizSD2HxiM\"></a>Regular EA Digest&#xA0;</strong></p>\n<ul>\n<li><a href=\"/ep/profile/tucs5FVK7Uw\"></a>Giles Edkins&#x2019; idea</li>\n<li><a href=\"/ep/profile/wGSShLtThxm\"></a>Ryan Carey&#x2019;s suggestion: &quot;MVP: You could presumably hook reddit.com/r/smartgiving with IFTTT (if this then that) to use it to send a weekly digest.&quot;</li>\n<li><a href=\"/ep/profile/yYmVtny2ziw\"></a>Tom Ash: I&#x2019;ve just done this, you can sign up at <a href=\"http://eepurl.com/bej8LT\"></a>http://eepurl.com/bej8LT&#xA0;</li>\n<li>Will announce soon (update: now superseded by Evan&apos;s weekly updates email, so retiring in favour of this)&#xA0;</li>\n</ul>\n<p><strong><a href=\"/ROR81FGrnRU\"></a>Expand Tax Deductibility for Top Charities</strong></p>\n<ul>\n<li>Some progress on Norway</li>\n<li>Tom talked to people about arranging a tax-deductible US donations route that EA orgs can use for their US fundraising, looks like this is happening!</li>\n<li>Randy described plan. To begin with, we&#x2019;d be more focus on making sure we provided a good way to give for EAs. Later, we may try to draw in others. Here&#x2019;s a <a href=\"https://drive.google.com/file/d/0B8iViSdEEJWUMHJGazB0WFlrRWM/view?usp=sharing\"></a>presentation that I&#x2019;ve given to traditional donors and funders to start getting them toward more effective giving. The <a href=\"https://drive.google.com/file/d/0B8iViSdEEJWUYjVTdnRaZzl6V1U/view?usp=sharing\"></a>Need Map of the world is where we start getting people really rethinking how/where they are giving especially if you overlay this map with where you get your biggest bang for your buck.</li>\n<li>Ozzie mentioned the long term future DAF Patrick recently set up with Vanguard \n<ul>\n<li>From Randy: I&#x2019;m having trouble finding the exact tax code, but my impression is that an individual will not be able to receive a tax write off when contribution to another persons DAF. Here&#x2019;s a bit more <a href=\"http://www.irs.gov/publications/p526/ar02.html#en_US_2014_publink1000229701\"></a>info of interest from the IRS.&#xA0; This statement is concerning to me (and means the donor would need to be named on the DAF account to receive a valid tax write-off): Contributions to Donor-Advised Funds: You cannot deduct a contribution to a donor-advised fund if: You do not have an acknowledgment from that sponsoring organization that it has exclusive legal control over the assets contributed.</li>\n</ul>\n</li>\n<li>Rochelle is in a good place with social enterprise networks in the UK - feel free to let me know if this can be useful</li>\n</ul>\n<p><strong>Fermi Estimate Tool</strong></p>\n<ul>\n<li><a href=\"http://lesswrong.com/r/lesswrong/lw/lhf/graphical_assumption_modeling/\"></a>http://lesswrong.com/r/lesswrong/lw/lhf/graphical_assumption_modeling/</li>\n<li><a href=\"https://github.com/OAGr/fermi-backend\"></a>https://github.com/OAGr/fermi-backend</li>\n<li><img src=\"https://hackpad-attachments.s3.amazonaws.com/hackpad.com_vkgn6fmRsZJ_p.181143_1424038953295_undefined\" alt=\"\"></li>\n<li>Shane: plans? \n<ul>\n<li>Ozzie: open source, at least for now, maybe paid later</li>\n</ul>\n</li>\n</ul>\n<p>&#xA0;</p>\n<p><strong>Skillshare.im</strong></p>\n<ul>\n<li>Still getting offers</li>\n<li>Anyone want to work on? (rails experience) \n<ul>\n<li>Haseeb: I&#x2019;m currently teaching myself Ruby and plan to learn Rails soon, and I&#x2019;d like to eventually contribute to Skillshare, but I assume it&#x2019;ll take a while before I&#x2019;ll be of any use (?) \n<ul>\n<li>AP Tom: start email conv with Haseeb, Ozzie and Patrick giving them each others emails</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p><strong><a href=\"/RGo0fDldByW\"></a>Website for sharing ideas and matching people in teams</strong></p>\n<ul>\n<li>Tor described</li>\n<li>Was discussed</li>\n</ul>\n<h2>Free Discussion</h2>\n<p><strong><a href=\"/1oD6nsR6XNV\"></a>Radical Givers Proposal</strong></p>\n<ul>\n<li>Questions \n<ul>\n<li>1/3 requirement? \n<ul>\n<li>What about ppl who don\u0019t meet it? \n<ul>\n<li>\u001cIf you are making below 150% of median income, then we encourage you to give a nominal amount (probably 1%), just to keep yourself in the habit of giving.\u001d - will these ppl be members in <em>some</em> sense?</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>thoughts on name? \n<ul>\n<li>more descriptive name, such as etg or a variant?</li>\n<li>Randy: I think the name is good enough, and I actually like it and easily identifiable.</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Log \n<ul>\n<li>Current plan is to use a plain text logo rather than a designed one (ones were mocked up at <a href=\"https://99designs.co.uk/logo-design/contests/awesome-design-altruistic-nonprofit-radical-givers-where-love-452659/poll/ypcxah?utm_source=voting_app&amp;utm_medium=web&amp;utm_campaign=voting\"></a>https://99designs.co.uk/logo-design/contests/awesome-design-altruistic-nonprofit-radical-givers-where-love-452659/poll/ypcxah?utm_source=voting_app&amp;utm_medium=web&amp;utm_campaign=voting )</li>\n</ul>\n</li>\n<li>There was a long discussion of this</li>\n</ul></body></html>", "user": {"username": "Tom_Ash"}}, {"_id": "7gqjXdicKXDcxEuoF", "title": "Rationality: From AI to Zombies was released today!", "postedAt": "2015-03-15T01:52:54.157Z", "htmlBody": "<html><body><p>Eliezer Yudkowsky&apos;s blog posts have finally been systematised and released into an ebook. MIRI&apos;s Robbie Bensinger is to be thanked for this. They are available as a &apos;pay as you want&apos; download from <a href=\"https://intelligence.org/rationality-ai-zombies/\">MIRI&apos;s website</a>.</p>\n<p>Eliezer&apos;s preface begins as follows:</p>\n<p>&quot;You hold in your hands a compilation of two years of daily blog posts. In retrospect, I look back on that project and see a large number of things I did completely wrong. I&#x2019;m fine with that. Looking back and not seeing a huge number of things I did wrong would mean that neither my writing nor my understanding had improved since 2009. Oops is the sound we make when we improve our beliefs and strategies; so to look back at a time and not see anything you did wrong means that you haven&#x2019;t learned anything or changed your mind since then...&quot;</p>\n<p>Robbie gives his own description:</p>\n<p>&quot;Stylistically, the essays in this book run the gamut from &#x201C;lively textbook&#x201D; to &#x201C;compendium of thoughtful vignettes&#x201D; to &#x201C;riotous manifesto,&#x201D; and the content is correspondingly varied. Rationality: From AI to Zombies collects hundreds of Yudkowsky&#x2019;s blog posts into twenty-six &#x201C;sequences,&#x201D; chapter-like series of thematically linked posts. The sequences in turn are grouped into six books, covering the following topics:</p>\n<p>&#xA0;</p>\n<p>\n</p><ul>\n<li>Book 1&#x2014;Map and Territory. What is a belief, and what makes some beliefs work better than others? These four sequences explain the Bayesian notions of rationality, belief, and evidence. A running theme: the things we call &#x201C;explanations&#x201D; or &#x201C;theories&#x201D; may not always function like maps for navigating the world. As a result, we risk mixing up our mental maps with the other objects in our toolbox.</li>\n<li>Book 2&#x2014;How to Actually Change Your Mind. This truth thing seems pretty handy. Why, then, do we keep jumping to conclusions, digging our heels in, and recapitulating the same mistakes? Why are we so bad at acquiring accurate beliefs, and how can we do better? These seven sequences discuss motivated reasoning and confirmation bias, with a special focus on hard-to-spot species of self-deception and the trap of &#x201C;using arguments as soldiers.&#x201D;</li>\n<li>Book 3&#x2014;The Machine in the Ghost. Why haven&#x2019;t we evolved to be more rational? Even taking into account resource constraints, it seems like we could be getting a lot more epistemic bang for our evidential buck. To get a realistic picture of how and why our minds execute their biological functions, we need to crack open the hood and see how evolution works, and how our brains work, with more precision. These three sequences illustrate how even philosophers and scientists can be led astray when they rely on intuitive, non-technical evolutionary or psychological accounts. By locating our minds within a larger space of goal-directed systems, we can identify some of the peculiarities of human reasoning and appreciate how such systems can &#x201C;lose their purpose.&#x201D;</li>\n<li>Book 4&#x2014;Mere Reality. What kind of world do we live in? What is our place in that world? Building on the previous sequences&#x2019; examples of how evolutionary and cognitive models work, these six sequences explore the nature of mind and the character of physical law. In addition to applying and generalizing past lessons on scientific mysteries and parsimony, these essays raise new questions about the role science should play in individual rationality.</li>\n<li>Book 5&#x2014;Mere Goodness. What makes something valuable&#x2014;morally, or aesthetically, or prudentially? These three sequences ask how we can justify, revise, and naturalize our values and desires. The aim will be to find a way to understand our goals without compromising our efforts to actually achieve them. Here the biggest challenge is knowing when to trust your messy, complicated case-by-case impulses about what&#x2019;s right and wrong, and when to replace them with simple exceptionless principles.</li>\n<li>Book 6&#x2014;Becoming Stronger. How can individuals and communities put all this into practice? These three sequences begin with an autobiographical account of Yudkowsky&#x2019;s own biggest philosophical blunders, with advice on how he thinks others might do better. The book closes with recommendations for developing evidence-based applied rationality curricula, and for forming groups and institutions to support interested students, educators, researchers, and friends.</li>\n</ul>\n<p></p>\n<p>&#xA0;</p>\n<p>There&apos;s obviously a lot there but I have found it quite influential, and Eliezer is the leading proponent of a very compelling style of philosophy from which one could imagine launching an entire school of philosophical thought. Already, these materials have been very influential, and with this book&apos;s release, I think a lot of people will be prompted to do some rereading.</p></body></html>", "user": {"username": "RyanCarey"}}, {"_id": "kyTSjXhmriZ6Gruuv", "title": "Keep Track of Your Giving with MyGiving", "postedAt": "2015-03-12T17:27:58.577Z", "htmlBody": "<html><body><p>I just wanted to make a quick post plugging Giving What We Can&apos;s MyGiving tool.</p>\n<p>It is a great page that lets you track where you are giving, and helps you track your giving over time. It is a great way to stay motivated to give, no matter how much you are giving!</p>\n<p>It takes less than 5 minutes to set up and can really help track your giving habits.</p>\n<p>&#xA0;</p>\n<p>If you want to know more, you can check out the page here:</p>\n<p>https://www.givingwhatwecan.org/my-giving-introduction</p>\n<p>&#xA0;</p>\n<p>Happy Giving!&#xA0;</p></body></html>", "user": {"username": "jonathancourtney"}}, {"_id": "TXs3QpuCk58DzBorq", "title": "GiveWell Updates", "postedAt": "2015-03-11T22:43:30.967Z", "htmlBody": "<html><body><p>For those who follow GiveWell, they have released a bunch of thorough updates of their last year&apos;s progress, including the Open Philanthropy Project. Here they are:</p>\n<p>&#xA0;</p>\n<ul>\n<li><a href=\"http://blog.givewell.org/2015/03/03/givewells-progress-in-2014-and-plans-for-2015-summary/\">GiveWell&#x2019;s Progress in 2014 and Plans for 2015: summary</a></li>\n<li><a href=\"http://blog.givewell.org/2015/03/05/2015-plan-for-givewells-traditional-top-charities-work/\">2015 plan for GiveWell&#x2019;s traditional (&#x201C;top charities&#x201D;) work</a></li>\n<li><a href=\"http://blog.givewell.org/2015/03/10/open-philanthropy-project-update-u-s-policy/\">Open Philanthropy Project Update: U.S. Policy</a></li>\n<li><a href=\"http://blog.givewell.org/2015/03/11/open-philanthropy-project-update-global-catastrophic-risks/\">Open Philanthropy Project Update: Global Catastrophic Risks</a></li>\n</ul>\n<div><br></div>\n<div>Here are the dot points from their summary:</div>\n<div>\n<ul>\n<li><strong>We made major progress on building capacity, and plan to continue expanding.</strong></li>\n<li><strong><strong>Our work on&#xA0;<a href=\"http://www.givewell.org/charities/top-charities\">top charities</a>&#xA0;produced much more output than in past years.</strong></strong></li>\n<li><strong><strong>We feel that our top charities generally improved as giving opportunities. There were no new additions to the list, though some of this year&#x2019;s &#x201C;standout charities&#x201D; may become top charities in the future.</strong><span>&#xA0;</span></strong></li>\n<li><span><strong>The Open Philanthropy Project progressed and evolved substantially, though it came short of our stretch goals.</strong></span></li>\n<li><span><strong><strong>We are planning to launch new websites for both GiveWell and the Open Philanthropy Project this year.</strong><span>&#xA0;</span></strong></span></li>\n<li><span><strong>Fundraising remains a priority.</strong><br><br></span></li>\n</ul>\n</div>\n<p>It all looks very promising. What are your thoughts?</p></body></html>", "user": {"username": "RyanCarey"}}, {"_id": "WwA9f3eCKm9yAHvKj", "title": "Announcing the Effective Altruism Newsletter", "postedAt": "2015-03-11T06:05:51.545Z", "htmlBody": "<html><body><p>Hi everyone,</p>\n<p>I&apos;m starting an effective altruism newsletter. I myself try to read all the blogs and updates coming from various effective altruism sources, as a matter of habit. I notice between charity evaluators and meta-charities, think tanks and research organizations, and top charities across all favored cause areas, there are over 20 sources and websites to check out.&#xA0;</p>\n<p>To keep tabs on all this, I&apos;ve set up an Effective Altruism Newsletter.</p>\n<ul>\n<li>You receive a newsletter up to once per week.</li>\n<li>The newsletter will include updates on all posts to this forum exceeding 10 upvotes, as well as major announcements from all organizations associated with effective altruism.</li>\n<li>Your email will be kept anonymous, you can unsubscribe at any time, and you&apos;re welcome to make suggestions for content.</li>\n</ul>\n<p>&#xA0;If you&apos;re interested in what it would be like, the sample newsletter for this week can be found here:<br><br><a href=\"https://docs.google.com/document/d/1F9Xz3d7TRvaMAmf_jwVWwL2wX0yJgDLznf4YLbhVK8U/edit?usp=sharing\">https://docs.google.com/document/d/1F9Xz3d7TRvaMAmf_jwVWwL2wX0yJgDLznf4YLbhVK8U/edit?usp=sharing</a><br><br>You can sign up by sending an email with &quot;Subscribe&quot; in the subject line to effectivealtruismnews@gmail.com</p>\n<p>I&apos;m hoping to set a Mailchimp system for the newsletter in a week or two, as well as an RSS Feed. In the next several weeks, I intend to set up RSS Feeds or mailing lists for specific cause areas, such as:</p>\n<ul>\n<li>Traditional Philanthropy and Global Aid: poverty reduction, and public health initiatives, in developing countries around the world.</li>\n<li>Animal Welfare: updates on effective altruism regarding animal welfare/rights, including focuses upon wild-animal suffering, factory-farming, and innovations in animal activism.</li>\n<li>Global Risks and Policy: work related to global catastrophic and existential risks, and how to mitigate them, including risks from machine intelligence and the future of humanity.</li>\n<li>Research, Strategy and Breakthroughs: focused upon major research generally related to effective altruism, such as updates from the Centre for Effective Altruism and its various offshoots; and Givewell and the Open Philanthropy Project. This would also include announcements of successes and updates from organizations which would be considered monumental.</li>\n</ul>\n<p>If you would like to wait until the email subscription system is improved, or a general or cause-specific RSS Feed, please still send an email to effectivealtruismnews@gmail.com. Let me know what you&apos;re interested in following or subscribing to. Then, I&apos;ll ensure your on that list when it gets started, and I&apos;ll notify you about it.</p>\n<p>&#xA0;</p>\n<p>&#xA0;</p></body></html>", "user": {"username": "Evan_Gaensbauer"}}, {"_id": "3yPMwrPwdpxfHNnmo", "title": "Upcoming AMA: Seb Farquhar and Owen Cotton-Barratt from the Global Priorities Project: 17th March 8pm GMT", "postedAt": "2015-03-10T21:25:39.329Z", "htmlBody": "<html><body><p><span>Hi Folks,</span></p>\n<p><span>After Seth Baum&#x2019;s excellent online interview, I&#x2019;m glad to announce that we&#x2019;re giving the AMA (Ask me anything format) another run. This time, we have none other than Seb Farquhar and Owen Cotton-Barratt from the Global Priorities Project. They will be coming online at:</span></p>\n<p><span>17th March 8pm GMT.</span></p>\n<p><span>Seb was one of the founding members of 80,000 Hours, spent last two years in consulting at McKinsey, and has once again returned, to head The Global Priorities Project, the think tank of the Effective Altruism community. </span></p>\n<p><span>Owen has been leading the research at the Global Priorities Project for the last year and is a Lecturer at the University of Oxford. He has a background in mathematics, health economics, and social choice.</span></p>\n<p><a href=\"http://www.fhi.ox.ac.uk/research/global-priorities-project/\"><span>The Global Priorities Project</span></a><span> is a young organization that has emerged from collaboration between the Future of Humanity Institute and the Centre for Effective Altruism. The organization is only about a year old but already it has had some interesting involvement in policy development, such as the recent paper on </span><a href=\"http://www.fhi.ox.ac.uk/wp-content/uploads/Unprecedented-Technological-Risks.pdf\"><span>Unprecedented Technological Risks</span></a><span>, which grew into a chapter of the annual report of the Government Chief Scientific Advisor. In 2015, the Global Priorities Project plans to expand by bringing a second full-time researcher on-board, alongside Owen. (You can also read their </span><a href=\"http://www.fhi.ox.ac.uk/wp-content/uploads/Unprecedented-Technological-Risks.pdf\"><span>strategy document</span></a><span> for more information.)</span></p>\n<p><span>Seb and Owen want to give the inside version of what the Global Priorities Project is currently working on, and what they plan for the future. They&#x2019;re happy to hear your thoughts on the Global Priorities Project and to answer your questions on a range of topics - you can post them here in advance if you want. I look forward to seeing them all answered this time next week!</span></p></body></html>", "user": {"username": "RyanCarey"}}, {"_id": "JtjZa2hRPWgmPxMxb", "title": "Meetup :  Effective Altruism UNSW Social Night", "postedAt": "2015-03-09T08:07:15.578Z", "htmlBody": "<html><body><h2>Discussion article for the meetup : <a href=\"/meetups/2c\"> Effective Altruism UNSW Social Night</a></h2>\n\t\t  <div>\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span>17 March 2015 05:30:00PM (+1100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span>Roundhouse, UNSW</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div>\n\t\t    <div><p>To celebrate the success of O Week, we&apos;ll be having a socials night. \nPlanned potential topics of conversation: common strategies for doing lots of good, should you get a job on wall street?, year in plan, (cognitive) biases impacting altruism, armchair economics, and whatever we feel like. \nDress: optional. Pants are fine. (wear casual)</p>\n\n<p>Looking forward to seeing you there. :)</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href=\"/meetups/2c\"> Effective Altruism UNSW Social Night</a></h2></body></html>", "user": {"username": "Peter McIntyre"}}, {"_id": "AH9dEWDtCxsFWDEJv", "title": "The economy of weirdness", "postedAt": "2015-03-09T06:00:52.754Z", "htmlBody": "<html><body><p>It is&#xA0;<a href=\"http://effective-altruism.com/ea/bg/you_have_a_set_amount_of_weirdness_points_spend/\">often</a>&#xA0;<a href=\"http://www.overcomingbias.com/2012/01/dear-young-eccentric.html\">said</a>&#xA0;<a href=\"https://en.wikipedia.org/wiki/Idiosyncrasy_credit\">that</a>&#xA0;you should spend your weirdness budget&#xA0;wisely.&#xA0;You should wear a gender-appropriate suit, and follow culture-appropriate sports, and&#xA0;use good grammar, and be&#xA0;non-specifically&#xA0;spiritual, and&#xA0;support moderate policies, and not have any tattoos around either of your eyes. And&#xA0;then on the odd occasion, when&#xA0;it happens to come up, you should gather up&#xA0;your entire weirdness budget&#xA0;and make a&#xA0;short, impassioned speech in favor of invertebrate equality. Or whatever you think is the&#xA0;very most&#xA0;effective use of&#xA0;weirdness. In short: you only get so much weirdness, so&#xA0;don&apos;t&#xA0;use it up&#xA0;dressing like a clown or popularizing alternative sleep schedules.&#xA0;</p>\n<p>While I agree the oddball&#xA0;activist will often&#xA0;get less airtime than her unassuming&#xA0;analog, and&#xA0;that weirdness is&#xA0;often&#xA0;a cost, the issue seems more&#xA0;complex. Let us&#xA0;better explore&#xA0;weirdness budgeting.</p>\n<p><strong>Model #1: Weirdness is&#xA0;badness</strong></p>\n<p>A first&#xA0;simple&#xA0;model is that&#xA0;people don&apos;t like weird things, so if you have any, they will like you less in expectation. Weirdness is a kind of badness.&#xA0;On this model, I suppose the reason you would want to be weird at all is that you just are weird, and it is hard or unpleasant to keep&#xA0;it under control.</p>\n<p>Some characteristics are certainly&#xA0;like this. For instance, being&#xA0;shockingly unable to open corkscrews, or tending to&#xA0;fart really loudly. These are just bad characteristics&#xA0;though, and don&apos;t seem like they need to be budgeted differently from other bad&#xA0;but not weird characteristics, like being lazy and stupid. I don&apos;t think&#xA0;this is what people have in mind when they say to spend your weirdness budget wisely.</p>\n<p><strong>Model #2:&#xA0;Weirdness is rarity is bad</strong></p>\n<p>Here is a closely related model. Weird traits are not&#xA0;inherently bad, but they are inherently unusual, and being unusual is inherently bad.&#xA0;On this model, the reason you want to have a weird trait&#xA0;could&#xA0;be&#xA0;that you like the trait, and&#xA0;so you want to make it less unusual.</p>\n<p>If many people feel that way, then on&#xA0;this model,&#xA0;weird traits are&#xA0;tragedies of the commons. e.g. If everyone could be naked in the street, the world would be a better place for everyone. But sadly, because&#xA0;nobody does it, anyone who starts is socially punished. So it is&#xA0;only the very&#xA0;altruistic person&#xA0;who&#xA0;will&#xA0;pull off&#xA0;their pants and&#xA0;be ostracized&#xA0;for the common good.&#xA0;</p>\n<p><strong>Model #3: Weirdness among the cool kids is bad</strong></p>\n<p>This is like the last model, but explains why you would want to budget your weirdness. In it, it doesn&apos;t matter how common a trait is, it matters how common it is among cool people (or perhaps how differentially common it is among cool people).&#xA0;So then you&#xA0;don&apos;t want to help popularize too many weird traits, because the more weird traits you have the&#xA0;less cool you seem, and thus the less&#xA0;your vote in favor of those traits counts.</p>\n<p>I think there is a hint of truth to these models so far. Kinds of unusualness are inherently bad, unusualness is often bad, and having traits&#xA0;makes those traits&#xA0;less unusual among people like you. However&#xA0;I highly doubt that people are mostly weird out of&#xA0;altruism, or even altruism combined with inability to control their weirdness. People love&#xA0;being weird. (Often.)</p>\n<p><strong>Model #4: Weirdness&#xA0;is&#xA0;divisive</strong></p>\n<p>Some weird traits are unambiguously bad. Some are unambiguously good, and empirically, these don&apos;t appear to use up weirdness budget.&#xA0;If you are weirdly hilarious&#xA0;this&#xA0;probably means you can get away with more other weirdness, not less.</p>\n<p>Many traits a bit good and a bit bad: they please&#xA0;some people while scaring off others. If a trait is &apos;weird&apos;, probably it displeases most&#xA0;people, and appeals to few. But this&#xA0;isn&apos;t necessarily a bad deal, even from a selfish perspective.</p>\n<p>For one thing,&#xA0;it might please the few a lot. Being into&#xA0;<a href=\"http://en.wikipedia.org/wiki/Temple_of_Heaven\">15th Century&#xA0;East Asian&#xA0;architecture</a>&#xA0;will&#xA0;seem&#xA0;merely not that interesting&#xA0;to the vast majority of people, while exceptionally exciting to the few&#xA0;who share your interest.</p>\n<p>For another thing, it matters how much you care about different levels of&#xA0;liking. For many circumstances, the big value is in having&#xA0;everyone think you are basically ok.&#xA0;If you are widely considered basically ok, you can be trusted&#xA0;on routine issues, you can have a job, you can have friends, you can&#xA0;be taken seriously. If you are basically ok and have one weird opinion, you can be a datapoint suggesting that weird opinion is ok for basically ok people&#xA0;to have.&#xA0;</p>\n<p>However if you want people to&#xA0;buy your book, or change continents&#xA0;to live with you, or fund&#xA0;your experimental research organization, then you need some people to&#xA0;<em>really</em>&#xA0;like you. But&#xA0;luckily, you don&apos;t need that many. And when&#xA0;the bar is high, and you only need to meet it a few times, you want high variance. If&#xA0;you can pick up a trait that&#xA0;90% of the population dislikes, but the remainder likes, you&#xA0;might&#xA0;take&#xA0;it.&#xA0;Because ten percent of people liking you can be way better than&#xA0;everyone being indifferent.&#xA0;And then you might do it again, and again. Until eventually,&#xA0;you marry the last person and ignore the rest.</p>\n<p>Of course, there are also traits that 60% of people are indifferent to, and 40% of people love, and these are a better deal, and you should start there, all things equal. But there are many other reasons to have&#xA0;particular traits, e.g. you already have them, and it would be effort to hide or destroy them. Generally, it&#xA0;is&#xA0;easy for a trait you want to have for other reasons to be&#xA0;positive value on social grounds in spite of being weird and seeming bad to many people.</p>\n<p>Causes and policy views tend to fit in this &apos;divisive&apos; category. If you&#xA0;advocate for abolishing the minimum wage, some people&#xA0;will love you more, and some people will hate you more. Causes are often political, which means that which people like you more and which people&#xA0;hate you more is correlated between them. This would make&#xA0;spending a bunch of weirdness an&#xA0;even better deal. Once you have advocated for abolishing the minimum wage, if you mostly care about some people liking you a lot, you may as well&#xA0;go on to support a slew of other free market policies,&#xA0;because the same people as liked you the first time will like you more, instead of&#xA0;you losing half of them at every step.</p>\n<p><strong>Model&#xA0;#4.1: Weirdness is divisive, the goal is spreading weird traits</strong></p>\n<p>So far we assumed you wanted to be liked or taken seriously a certain amount by other people. What if we suppose you have a set of weird traits you are in favor of, which you may choose to express or not, and&#xA0;your primary goal is to spread&#xA0;them? (As described in&#xA0;#2). For instance, suppose you&#xA0;care&#xA0;a lot&#xA0;about animal suffering, and also the far future, and think cryonics should be much more common, and think public displays of affection&#xA0;should be&#xA0;normal, and that polyphasic sleep is a thing everyone should try.</p>\n<p>As described in&#xA0;#4, variance gets you&#xA0;smaller numbers of&#xA0;people who&#xA0;feel more positively toward you, and sometimes this is worth it. For instance, if nobody will take any of your ideas seriously unless they think you are incredibly impressive. There are a couple of important features specific to the&#xA0;ambition of spreading weird traits&#xA0;however.</p>\n<p>One is that&#xA0;to spread a weird trait, you generally&#xA0;have to have it, or associate yourself with it somehow. That potentially makes expressing more of your traits better,&#xA0;aside from its effect on how&#xA0;well respected or liked you are.&#xA0;Suppose&#xA0;you want people to agree with you on&#xA0;cryonics and the far future.&#xA0;Then even if talking about&#xA0;both topics&#xA0;reduces&#xA0;much people are willing to listen to you, it might be worth it&#xA0;because now your small remaining group of admirers think about&#xA0;twice as many&#xA0;topics you want them to think about.&#xA0;This assumes&#xA0;they&#xA0;don&apos;t just reduce their attention to your first topic proportionally.</p>\n<p>Note that the incentives here are different for narrowly directed&#xA0;advocacy organizations&#xA0;and their members.&#xA0;You might do best advocating for whales and bad haircuts, but your whale organization would strongly prefer you just stick to the whales.</p>\n<p>Another feature of the divisiveness model when you care about spreading&#xA0;traits&#xA0;is that people disliking&#xA0;you has particularly negative effects when you are trying to spread&#xA0;traits.&#xA0;Often, causing half of humanity&#xA0;to mildly dislike you is&#xA0;not so bad, because it will just mean you don&apos;t interact with them on a personal basis much, and you weren&apos;t that socially ambitious&#xA0;anyway. However&#xA0;when&#xA0;people&#xA0;dislike&#xA0;you they will often associate your particular traits with dislike.&#xA0;It might still be worth trading some people disliking you for others liking you extra, but this consideration makes such trades worse than they would have been.</p>\n<p><strong>Model #5: Weirdness is local</strong></p>\n<p>It could be that most of what matters is weirdness relative to those around&#xA0;you, and that different groups find different things weird, and that you can change who is around you.&#xA0;This picture seems true for some kinds of traits, such as a weird sense of humor.&#xA0;In this case, you&#xA0;can either explicitly search for your people, or just act as you&#xA0;want to in the long run,&#xA0;scare&#xA0;away&#xA0;those who&#xA0;find it weird, and&#xA0;be left with a suitable&#xA0;group. In this model,&#xA0;being weird in a&#xA0;specific&#xA0;way has&#xA0;a one-time (though perhaps large and drawn out) cost, and then you can do it for free, forever. So&#xA0;in this model&#xA0;the wisest way to spend your so-called weirdness budget might be&#xA0;fast and completely.</p>\n<p><strong>Model #6 Weirdness as a signal</strong></p>\n<p>If weirdness is just a generic bad sign, or is a sign that you match with some groups of people or others, earlier models will perhaps&#xA0;suffice. But being weird often&#xA0;suggests other specific things about a person.</p>\n<p>As&#xA0;soon as being weird is probably a bad option, then it also becomes&#xA0;a sign&#xA0;of lack of awareness, or&#xA0;self-control.&#xA0;For instance, if someone wears a ripped&#xA0;shirt to a job interview, one probably&#xA0;infers that they are clueless about customs, don&apos;t own a nice shirt, or that have some other mysterious&#xA0;agenda that one probably&#xA0;doesn&apos;t want to be involved with.&#xA0;These kind of signals&#xA0;lead to the basic situation&#xA0;described in model 2,&#xA0;where things are not intrinsically bad become so&#xA0;by&#xA0;virtue of being weird. However this means that you can be more&#xA0;weird in certain ways without using up weirdness budget&#xA0;if you counteract&#xA0;the signaling&#xA0;on its own.&#xA0;For instance, if you&#xA0;enter a job interview and say &apos;I&apos;m sorry&#xA0;that my shirt is torn&#x2014;I actually&#xA0;got it caught on a shrubbery on my way in here&apos;, then the interviewer will no longer infer &#xA0;that you don&apos;t know about social customs, though may infer that you were interacting unusually with a&#xA0;shrubbery.</p>\n<p><strong>Model #7: Weirdness is&#xA0;honest</strong></p>\n<p>The usual consequence of advice to&#xA0;be thrifty&#xA0;with weirdness is that people end up with&#xA0;a&#xA0;collection&#xA0;of views and interests that they keep hidden from the world.&#xA0;Sometimes this&#xA0;might be actively deceptive, for instance&#xA0;when&#xA0;people with&#xA0;<a href=\"http://www.paulgraham.com/say.html\">unspeakable views</a>&#xA0;claim to have no views. But&#xA0;mostly avoiding being weird is just implicit misrepresentation.&#xA0;This suggests&#xA0;a range&#xA0;of considerations associated with honesty in general. Honesty has virtues and costs.&#xA0;</p>\n<p>The costs of honesty as they apply here are I think mostly covered above&#x2014;if you have&#xA0;traits that are widely acknowledged as bad, or make you seem like someone you don&apos;t want to be seen as, or whatever, it is costly to&#xA0;let them&#xA0;be seen.&#xA0;I think there are some&#xA0;benefits of honesty that haven&apos;t fit under other above models&#xA0;however.</p>\n<p>It&apos;s more interesting to&#xA0;know about a relatively complete, &apos;authentic&apos; person than a flat, disconnected one-issue front that an unknown person&#xA0;has&#xA0;chosen&#xA0;to erect. People are usually interested in hearing about people more than ideas, so if you present yourself as a person this will probably interest them more. And a person generally has an array of idiosyncrasies&#xA0;and unusual concerns, including some that are not the most effective thing to be concerned about, and some characteristics that everyone agrees are actively bad.</p>\n<p>Relatedly, revealing&#xA0;a relatively&#xA0;full array of your views and interests&#xA0;means people know&#xA0;you better, which tends to&#xA0;improve your&#xA0;relationship with them. I&apos;d guess this is true even for people who observe you from far away on the internet.&#xA0;I think I feel&#xA0;more sympathetic to an author&#xA0;who admits they have characteristics beyond an interest in the subject matter.&#xA0;</p>\n<p>Another virtue of honesty is that if people see the&#xA0;larger picture behind the particular&#xA0;view you are espousing, your behavior will make more sense, so you will seem more reasonable and interesting. For instance, if you advocate for developing world aid for a while, and then suddenly&#xA0;change to advocating for space travel, you might seem flakey. Whereas if you say all along that you care about doing the most cost-effective thing, and are open minded about causes, and are considering a bunch of them on an ongoing basis,&#xA0;and explain why you think these different causes are cost-effective,&#xA0;then this might&#xA0;seem consistent instead of actively inconsistent.&#xA0;Relatedly, as your views evolve&#xA0;it seems&#xA0;more natural for those who were interested before to remain interested if they&#xA0;understand the bigger picture of your&#xA0;motives.&#xA0;</p>\n<p>Relatedly, particular weird views will often make more sense in the&#xA0;context of&#xA0;your larger set of&#xA0;weird&#xA0;views. If you espouse cryonics on its own, and don&apos;t mention that you also think&#xA0;it will be possible to upload human minds&#xA0;onto computers,&#xA0;the cryonics will seem much more ambitious than it otherwise would.</p>\n<p>Then there is just the&#xA0;usual problem that dishonesty is confusing and&#xA0;tangly. Views on some topics strongly suggest views on other topics, so&#xA0;if&#xA0;topics are out of bounds, you have to make sure you don&apos;t imply anything about them. This is probably much easier in practice than it first seems, because&#xA0;people are&#xA0;not&#xA0;great&#xA0;at drawing inferences.&#xA0;I wouldn&apos;t be surprised if using&#xA0;abstract language&#xA0;was&#xA0;enough to successfully hide&#xA0;most controversial statements most of the time. However there&#xA0;are probably&#xA0;other things like this.&#xA0;</p>\n<p>If you tell people what you really care about, you can have more useful conversations with them, because they can give&#xA0;feedback and&#xA0;suggestions that actually matter to you. For instance, if&#xA0;I spend&#xA0;most&#xA0;of my time thinking about how to improve my life, but I write as if all I care about is resolving puzzles in social science, then your comments can only&#xA0;help me with puzzles in social science.</p>\n<p>It can feel better to be honest. However this might just be down to better relationships and avoiding the mental taxation associated with maintaining an inoffensive front.</p>\n<p>This is not an exhaustive account of the virtues of&#xA0;weirdness as honesty. Also note that none of the benefits&#xA0;I mentioned apply strongly all of the time. They are just considerations that sometimes matter, and sometimes&#xA0;make it better&#xA0;to&#xA0;be pretty&#xA0;weird.</p>\n<p>***</p>\n<p>Ok, those are all of my&#xA0;models of weirdness for now, and of how it is appropriate to splurge/invest in it. I suspect&#xA0;at least many of them&#xA0;have some truth, and apply to varying degrees&#xA0;to&#xA0;various weirdnesses in varying parts of the real world.&#xA0;There&#xA0;are probably other important dynamics I have missed. Overall, I&apos;m still not sure how weird it is good to be in general. It seems plausible that&#xA0;many people&#xA0;should&#xA0;be&#xA0;relatively weird across the board, rather than saving it all up for one issue.&#xA0;I suspect some people&#xA0;are best off being&#xA0;weird&#xA0;while others&#xA0;should be more&#xA0;normal&#xA0;overall, and it is harder to tell&#xA0;what is best on the current margin, where some people are weird and some are normal. My guess is that&#xA0;you should often&#xA0;treat weirdness&#xA0;differently depending on what you want to achieve (basic respectability? Fame? A boyfriend? A good relationship with your audience? A good relationship with your&#xA0;organization?),&#xA0;and&#xA0;the nature of the weirdness in question (How much do&#xA0;some people like it? How much do others not? Does it send specific signals? Is it just bad?).&#xA0;</p>\n<p><em>Also posted at <a href=\"https://meteuphoric.wordpress.com/2015/03/08/the-economy-of-weirdness/\">Meteuphoric</a></em></p></body></html>", "user": {"username": "Katja_Grace"}}, {"_id": "sKYbd9mZKM4rLY2pw", "title": "Bitton's 3-month Personal Review", "postedAt": "2015-03-09T01:17:59.561Z", "htmlBody": "<html><body><p><span>This post is inspired by Peter Hurford&apos;s <a href=\"/ea/d9/peters_personal_review_for_octdec_2014/\">3-month reviews</a>. Although I don&apos;t spend as much time on direct EA work as Peter does, I think people here might find this interesting as a case study of the usefulness of productivity techniques and rigorous organization on personal effectiveness. My feeling is that this 3 month period may well have been the most successful 3 months of my life in terms of career progress, personal development, wellbeing, and learning.</span></p>\n<p><span>Three months ago I started using a number of productivity apps and becoming more organized. Of these changes, the most important was my use of the app Toggl. With Toggl, I tracked everything that I did, every day. It took a couple of days to get the hang of but I quickly learned to start and stop my timer throughout the day with pretty little effort.</span></p>\n<p><span> Those first couple of days, I struggled because I was being too specific. I was naming activities things like &quot;helping [my roommate] write her email to quit her job&quot; and &quot;Working on my Response to Gwern blog post.&quot; But 3 months of specific activities like that would be a nightmare to sort through afterward. So I chose set categories to place every activity into.</span></p>\n<p><span> My categories were:</span></p>\n<ol>\n<li><span>Sleep</span></li>\n<li><span>Social</span></li>\n<li><span>Internet</span></li>\n<li><span>Food</span></li>\n<li><span>Transport</span></li>\n<li><span>Exercise</span></li>\n<li><span>Meditation</span></li>\n<li><span>Web Development</span></li>\n<li><span>Economics</span></li>\n<li><span>Meta</span></li>\n<li><span>Career</span></li>\n<li><span>Day Job</span></li>\n<li><span>Housework</span></li>\n<li><span>Shopping</span></li>\n<li><span>Reading</span></li>\n<li><span>Writing</span></li>\n<li><span>Creative Writing</span></li>\n<li><span>Art</span></li>\n<li><span>Break</span></li>\n<li><span>Other</span></li>\n</ol>\n<p><span>Many of these categories were additions that I only added in middle of this period.</span></p>\n<p>&#xA0;</p>\n<p><span><strong>Sleep</strong>: Time spent sleeping, including time where I&apos;m lying in my bed waiting to fall asleep and time where I&apos;ve just woken up but haven&apos;t got out of bed or started doing anything yet.</span><span>&#xA0;</span></p>\n<p><span><strong>Social</strong>: Everything that I do with another person for no reason other than to hang out or have fun.</span></p>\n<p><span><strong>Internet</strong>: &quot;Internet&quot; includes mostly unproductive time spent on Facebook, watching YouTube videos, or going on other websites such as this forum.</span></p>\n<p><span><strong>Food</strong>: Includes cooking, eating, and being at a restaurant. Any time spent not doing other things because I have to eat.</span></p>\n<p><span><strong>Transport</strong>: Time spent biking, walking from place to place, on public transit, and on the bus between Montreal and Toronto.&#xA0;I often switch to &quot;Transport&quot; a couple of minutes before or after I&apos;ve actually left or arrived somewhere, meaning that putting my shoes and coat on is usually considered &quot;Transport&quot; rather than &quot;Other.&quot;</span></p>\n<p><span><strong>Exercise</strong>: Self-explanatory. I was fortunate enough to have a slack retail job that allowed me to do copious amounts of sit ups while the store was empty. In the past couple of weeks, my routine has broken because I now have a different job and need to leave the house earlier. This period is the longest I&#x2019;ve ever been able to sustain a personal exercise routine.</span></p>\n<p><span><strong>Meditation</strong>: Ten minutes a day, first thing in the morning using Headspace until my free trial ran out (since then I&apos;ve changed sites a lot). I never noticed any direct benefits from this but it was useful for contributing to my morning victory spiral. I&#x2019;ve also only done 13 hours.</span></p>\n<p><span><strong> Web Development</strong>: One day, after finishing all my daily goals by ~4pm, I decided to start something new. I did the HTML &amp; CSS tutorials on Codecademy, Khan Academy, Shay Howe, and used a lot of other online resources to teach myself basic web development. After about a week of tutorials, I began giving myself challenges such as to code a perfect replica of my resume or a perfect replica of a specific website. The &quot;Web Development&quot; category includes any time I spent learning web development, whether I was doing a tutorial, working on a project, or looking up the answer to a question online.</span></p>\n<p><span><strong>Economics</strong>: On a whim, I decided to take the Khan Academy Microeconomics course. I went through about 55 videos in a couple of weeks and then found it difficult to continue. This is a pretty low priority for me but there were a couple of weeks of enthusiasm where I was teaching myself basic economics for an hour or two a night.</span></p>\n<p><span><strong>Meta</strong>: Shortly after beginning with Toggl, I began experimenting with other productivity apps. A lot of my time was spent reading lists of the most useful apps, writing myself lists for Workflowy, writing reminders in Evernote, monitoring my Beeminder, creating myself a homepage of my useful links, etc. All of this stuff I count as &quot;Meta&quot; because I&apos;m spending my time monitoring my own productivity. For the record, many apps I didn&apos;t find useful. In particular, mood and sleep tracking apps did nothing for me.</span></p>\n<p><span><strong>Career</strong>: Job hunting, sending emails for informational interviews, doing informational and job interviews, researching for my career, updating my cover letter and resume, etc. In order to prepare myself for a job interview at an animation studio, I watched kids TV shows every morning in my &quot;Career&quot; time.</span><span>&#xA0;</span></p>\n<p><span><strong>Day Job</strong>: Time spent at my day job. I started off by counting all my time spent at work, thinking that it would be awkward to Toggl in front of customers and my boss. Eventually, I realized how much I could get done while at work and so I began using &quot;Day Job&quot; to refer only to actual work and to time spent at work doing nothing else. On the job, I did a lot of exercise, reading, and taught myself web development. At my new job, I don&#x2019;t have time to fool around, so I&#x2019;m on &#x201C;Day Job&#x201D; for the full 10+ hours barring (sometimes) lunch.</span></p>\n<p><span><strong> Housework</strong>: Washing dishes, sweeping the floor, taking out the trash. Mostly dishes.</span></p>\n<p><span><strong>Shopping</strong>: Shopping for groceries, gifts, clothes, plants, loitering in stores and malls, etc.</span></p>\n<p><span><strong>Reading</strong>: This one is a bit of judgment call. Just about whenever I&apos;m on the Internet, I&apos;m reading but I&apos;m not necessarily in the &quot;Reading&quot; category. I&apos;m &quot;Reading&quot; when I&apos;m reading academic articles or books.</span></p>\n<p><span><strong>Writing</strong>: This includes my book summaries, blog posts, and posts on the EA Forum. It does not include creative writing, emails, or social media.</span></p>\n<p><span><strong> Creative Writing</strong>: I write little short pieces of Creative Writing. For 2-3 weeks, I included this in &quot;Art&quot;.</span></p>\n<p><span><strong>Art</strong>: Includes reading fiction, watching movies, listening to music, etc. Of course, if I listen to music while job hunting, that only gets credited as &quot;Career.&quot;</span></p>\n<p><span><strong>Break</strong>: Little breaks from working. I mainly use this category when I&apos;m using the Pomodoro technique.</span></p>\n<p><span><strong>Other</strong>: Mostly time spent in the bathroom: brushing teeth, showering, etc. Also, some random, unusual stuff: For Christmas, I was taking care of a friend&apos;s cat, so each night I spent about 30 minutes of &quot;Other&quot; time at their condo feeding and playing with it.</span></p>\n<p><span>&#xA0;</span></p>\n<p><span>My stats:</span></p>\n<table>\n<tbody>\n<tr>\n<td>\n<p><span>Art</span></p>\n</td>\n<td>\n<p><span>2.77%</span></p>\n</td>\n<td>\n<p><span>51:06:48</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Break</span></p>\n</td>\n<td>\n<p><span>0.21%</span></p>\n</td>\n<td>\n<p><span>3:48:53</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Career</span></p>\n</td>\n<td>\n<p><span>2.6%</span></p>\n</td>\n<td>\n<p><span>47:58:39</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Creative Writing</span></p>\n</td>\n<td>\n<p><span>0.35%</span></p>\n</td>\n<td>\n<p><span>6:27:50</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Day Job</span></p>\n</td>\n<td>\n<p><span>16.81%</span></p>\n</td>\n<td>\n<p><span>310:00:52</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Economics</span></p>\n</td>\n<td>\n<p><span>0.94%</span></p>\n</td>\n<td>\n<p><span>17:17:32</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Exercise</span></p>\n</td>\n<td>\n<p><span>0.95%</span></p>\n</td>\n<td>\n<p><span>17:31:22</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Food</span></p>\n</td>\n<td>\n<p><span>2.29%</span></p>\n</td>\n<td>\n<p><span>42:14:29</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Housework</span></p>\n</td>\n<td>\n<p><span>0.99%</span></p>\n</td>\n<td>\n<p><span>18:19:23</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Internet</span></p>\n</td>\n<td>\n<p><span>9.17%</span></p>\n</td>\n<td>\n<p><span>169:07:51</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Meditation</span></p>\n</td>\n<td>\n<p><span>0.74%</span></p>\n</td>\n<td>\n<p><span>13:39:42</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Meta</span></p>\n</td>\n<td>\n<p><span>1.4%</span></p>\n</td>\n<td>\n<p><span>25:50:55</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Other</span></p>\n</td>\n<td>\n<p><span>5.25%</span></p>\n</td>\n<td>\n<p><span>96:52:40</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Reading</span></p>\n</td>\n<td>\n<p><span>2.45%</span></p>\n</td>\n<td>\n<p><span>45:10:01</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Shopping</span></p>\n</td>\n<td>\n<p><span>0.5%</span></p>\n</td>\n<td>\n<p><span>9:09:44</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Sleep</span></p>\n</td>\n<td>\n<p><span>35.89%</span></p>\n</td>\n<td>\n<p><span>661:54:07</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Social</span></p>\n</td>\n<td>\n<p><span>6.95%</span></p>\n</td>\n<td>\n<p><span>128:08:39</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Transport</span></p>\n</td>\n<td>\n<p><span>4.47%</span></p>\n</td>\n<td>\n<p><span>82:20:41</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Web Development</span></p>\n</td>\n<td>\n<p><span>2.37%</span></p>\n</td>\n<td>\n<p><span>43:44:08</span></p>\n</td>\n</tr>\n<tr>\n<td>\n<p><span>Writing</span></p>\n</td>\n<td>\n<p><span>3.03%</span></p>\n</td>\n<td>\n<p><span>55:51:19</span></p>\n</td>\n</tr>\n</tbody>\n</table>\n<p><span>&#xA0;</span><span>&#xA0;</span></p>\n<p><span><strong>Sources of inaccuracy</strong>:</span></p>\n<p><span>Sometimes things are difficult to categorize. When I go to a restaurant with my friend, is that &quot;Social&quot; or &quot;Food?&quot; When I talk to my friend on Facebook, is it &quot;Social&quot; or &quot;Internet?&quot; If I watch a stand up comedy act with a friend is that &quot;Social&quot; or &quot;Art?&quot; When I wanted to do research for a job interview at an animation studio, I was waking up an hour early each morning to watch kids TV shows. I categorized this as &quot;Career&quot; but it could as easily have been categorized as &quot;Art.&quot;</span><span>&#xA0;</span></p>\n<p><span>Also, I often do two things at once. For the first of these three months, I had a day job that allowed me to &quot;slack off&quot; and be actually productive on the job. So whenever I was without supervision I&apos;d get some &quot;Reading,&quot; &quot;Writing,&quot; and &quot;Meta&quot; stuff done - and yet it was all categorized as &quot;Day Job.&quot; Sometimes I&apos;d exercise while listening to the kids shows and yet this all took place in a &quot;Career&quot; chunk of time.</span></p>\n<p><span>For the past 5 days, my Toggl app has been broken on my phone. As a result, I could only update my time tracker on my laptop and thus had to do some post hoc guesstimation.</span></p>\n<p><span><span>Finally, little things tend to get overlooked. When I stop my timer and then start a new act, there&apos;s usually a few seconds or minutes that get lost in the mix. Suppose I&apos;m in &quot;Internet&quot; mode, going through my favourite websites and then I find something really interesting, which leads me to click on something else, which leads me to click on something else. Before I know it, I&apos;ve transferred over into &quot;Reading&quot; but I&apos;m not going to switch from &quot;Internet&quot; into &quot;Reading&quot; if I&apos;m just reading one blog post. I have to read for a while before I go &quot;okay, it now seems unfair to call this &apos;Internet,&apos; it&apos;s time to toggle.&quot; So there are these little cracks in between toggles and it&apos;s easy to lose little &quot;Breaks&quot; and &quot;Others&quot; and &quot;Readings&quot; in those cracks. But with activities that you only do for a few minutes a day, it&apos;s important not to lose those few minutes a day in the cracks.</span></span></p>\n<p>&#xA0;</p>\n<p><span><strong>Lessons Learned</strong>:</span></p>\n<p><span>Looking at these stats, I don&#x2019;t feel like I see much about myself that I didn&#x2019;t already know. I don&#x2019;t get much out of scrutinizing my time use. Rather, I benefited from the <em>process</em> of organizing and monitoring myself.</span></p>\n<p><span>For instance, I quickly realized how much I can get done in a day. Once I started setting myself daily goals, I found that I could usually complete them with several hours left to spare. That&apos;s why early in this project, I realized that I could fit web development into my schedule and work on it every day.</span></p>\n<p><span> This process has made me really good at starting new habits immediately. After starting the Codecademy tutorial on a whim one night, I continued to teach myself HTML &amp; CSS every day from then on, for at least an hour a day, with few exceptions. When I decided to meditate for 10 minutes each day, I started and then never missed a day. When I decided to watch kids TV shows in order to prepare for my job interview, I scheduled it into my morning routine and watched 1 or 2 new shows each day. Same for when I decided to do 50 sit-ups and push-ups each morning as soon as I get out of bed. And then when I decided to do 500+ sit-ups every day while at work. And then when my sister showed me the posture exercises she does. I got a bit of reading done every day. I started about 6 new apps and routines within the first couple of days and stuck to all of them without difficulty. About 3 weeks later, I created myself a budget and started updating it every single day with the amount of money I&apos;ve spent. At one point, to prepare for my job interview, I began doing a mock expense report of my trip to Montreal and I updated that every day as well.</span></p>\n<p><span> In the past three months, I have barely had any bad moods at all and the ones I did have were very brief (~1-5 minutes). Mostly, I felt very excited and in control.</span></p>\n<p><span>Most of my bad moods are related to attending social events that I know I don&#x2019;t belong at. I&apos;ve noticed over these three months that most of the social activity I do is against my own will and interests. When people ask me to be social, I usually say yes even though I have other things I&apos;d like to get done in that time. One of my goals for the next three months is to say no to social requests more often. Now that I&apos;m organized and on track, the randomness of other people&apos;s goals and hang out plans just feels like a distraction. Many of the dollars I&apos;ve spent eating out can be directly attributed to somebody else asking me if I want to go out with them and me agreeing even though I know it&apos;s not a good way to spend my money or a productive way to spend my time. I also have this weird thing where I genuinely have more fun on the job than I do while &#x201C;having fun&#x201D;.</span></p>\n<p><span>The first thing I noticed about using Toggl is how aware it made me of the passage of time. I could constantly feel a ticking clock in the back of my head and that made it much more difficult to waste long hours of time. I had a constant sense of urgency. This was bolstered by all the other techniques I was using &#x2013; Pomodoro, Workflowy, HabitRPG, Evernote, Beeminder &#x2013; they create a self-reinforcing system. Skipping my morning workout is really unappealing when I know that that&#x2019;s what comes before meditation in my morning routine. And I don&#x2019;t give myself HabitRPG points until I&#x2019;ve completed my morning routine. And I won&#x2019;t be able to cross these off my Workflowy list of daily goals.</span><span>&#xA0;</span></p>\n<p><span>Finally, I was surprised at how helpful rigorous organization was to me. I was initially skeptical of quantified self stuff but I noticed a very immediate and drastic difference in my productivity and mood as soon as I started. I&#x2019;ve recently stopped doing most of these techniques because I got a new job that has completely changed my routine and I haven&#x2019;t yet been able to adjust. Maybe I will never be able to string together more than a couple of consecutive months of enthusiasm but even a couple of months like this a year is great. These may have been the 3 most successful months of my life.</span></p>\n<p><span>&#xA0;</span></p>\n<p><span><strong>Career Progress</strong>:</span></p>\n<p><span>In these 3 months, I saw significant career progress, going from unemployed to landing my first &#x201C;real&#x201D; job. I began this experiment shortly after completing work on a feature film and with no leads for future work. From there, I got a retail job in a furniture store. As far as retail jobs go, it was pretty good. I was left completely unattended and could use the time to read, practice web development, write fiction, and do 500 sit ups per shift. I stayed there for 6 weeks until I quit, knowing that I had several good leads for jobs in my field.</span></p>\n<p><span>I spent one week doing job interviews, informational interviews, and research. The informational interview I did this week was one of the most productive I&#x2019;d ever done (out of ~20) and I apparently only missed out on the job I interviewed for because the hiring had been rescheduled to the summer.</span></p>\n<p><span>I spent a second week writing essays for lazy college kids. In that work week, I churned out ~50 pages on various boring topics and earned the same money as I would have received at my retail job in, at most, the same number of hours worked.</span></p>\n<p><span>Finally, I was granted a one-week tryout shift as an executive assistant at an animation studio that creates kids TV shows. I have now finished my third week and, although I&#x2019;ve yet to sign a contract, I get the feeling that I&#x2019;m here to stay. This is big for me because it&#x2019;s my first &#x201C;real&#x201D; job that pays a real salary and that keeps me hired for (hopefully) longer than a couple of months.</span><span>&#xA0;</span></p>\n<p><span>In my first three weeks, I&#x2019;ve already learned a lot about the job, the office, the industry, and have been given an unusually good opportunity to improve my organizational skills. To provide some context, my job is basically The Devil Wears Prada and involves keeping the President and VP of a 250+ employee company prepared and on schedule. The job is so fast-paced and high pressure that I often ride an adrenaline rush from the start to the end of my shift.</span></p>\n<p><span>During these 3 months, I also continued talking to a writer-director about producing his short film. Although I&#x2019;ve been a &#x201C;production coordinator&#x201D; and a &#x201C;production manager&#x201D;, I&#x2019;ve never properly &#x201C;produced&#x201D; anything aside from my own crappy, student work so this is a good opportunity for me. It&#x2019;s paid, a good learning experience, a solid addition to my resume, and a chance for me to stay involved in production even while working as an executive assistant.</span></p>\n<p><span>I also wrote some basic, introductory posts for Effective Altruism Switzerland in this time, expanding the list of EA organizations I&#x2019;ve worked with. I think I may be on the verge of expanding that list further.</span></p>\n<p>&#xA0;</p>\n<p><span><br></span></p>\n<p><span>Questions, comments?</span></p></body></html>", "user": {"username": "Bitton"}}, {"_id": "tvBGG7gwa8BZBE38e", "title": "Figuring Good Out - February", "postedAt": "2015-03-09T00:39:42.178Z", "htmlBody": "<html><body><p>Last month there were only two contributions on the topic of explaining effective altruism. Hopefully, we can get that number back up to 6 this March. Let me know if I missed your post and you want it to be included.</p>\n<p>In February:</p>\n<p>I <a href=\"/ea/f8/motteandbailey_explanations_of_ea/\">wrote about</a> a possible motte-and-bailey-esque issue with effective altruism.</p>\n<p>weeatquince listed <a href=\"/ea/fg/tips_on_talking_about_effective_altruism/\">some tips</a> for talking about effective altruism.</p>\n<p>&#xA0;</p>\n<p>For March, I tried to choose a topic that I think might get more interest:&#xA0;<strong>selflessness</strong>.</p>\n<p>As usual, feel free to offer feedback and topic suggestions in the comments!</p></body></html>", "user": {"username": "Bitton"}}, {"_id": "GG6HiDFhKqG5whrHN", "title": "Neutral hours: a tool for valuing time", "postedAt": "2015-03-04T16:33:41.087Z", "htmlBody": "<html><body><p>Prioritisation is mostly about working out how to trade different  resources off against one another. Prioritisation problems come at  different scales: for individuals, for companies or organisations, for  the world at large. At the Global Priorities Project we&#x2019;re mostly  interested in the large-scale questions. But we sometimes have something  to say about smaller scale problems, too.</p>\n<p>I&#x2019;ve just tidied and released old research notes (mostly from 2013)  on the personal prioritisation problem of how to value time spent on  different activities. This is primarily of use for individuals making  decisions about how to spend their time, money, and mental energy.</p>\n<blockquote>\n<p><strong>Abstract:</strong> We get lots of opportunities  to convert between time and money, and it&#x2019;s hard to know which ones to  take, since they use up other mental resources. I introduce the neutral  hour as a tool for thinking about how to make these comparisons. A  neutral hour is an hour spent where your mental energy is the same level  at the start and the end. I work through some examples of how to use  this tool, look at implications for some common scenarios, and explore  the theory behind them.</p>\n</blockquote>\n<p>There may be benefits for broader prioritisation questions. Since  societies are comprised of individuals, it could help to know how to  value time savings or costs to individuals when performing cost-benefit  analysis on larger projects. And there may be techniques for comparing  between different resources that we could usefully apply in wider  contexts. However we think these benefits are secondary. We&#x2019;re releasing  this work now to let others take advantage of it: either for personal  benefit; or to build on it and release easier-to-use guidance or tools.</p>\n<p>You can <a title=\"Neutral hours: a tool for valuing time\" href=\"http://globalprioritiesproject.org/2015/03/neutral-hours-a-tool-for-valuing-time/\">find the full document here</a>. I&apos;m happy to answer questions and I&apos;d love to know if people have thoughts on this material.</p></body></html>", "user": {"username": "Owen_Cotton-Barratt"}}, {"_id": "4buQy94XWXvTFepPr", "title": "Meetup : Effective Altruism Meetup Switzerland", "postedAt": "2015-03-04T14:09:31.259Z", "htmlBody": "<html><body><h2>Discussion article for the meetup : <a href=\"/meetups/2b\">Effective Altruism Meetup Switzerland</a></h2>\n\t\t  <div>\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span>21 March 2015 06:00:00PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span>Efringerstrasse 25, 4057 Basel</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div>\n\t\t    <div><p>The Swiss Effective Altruism Movement (EACH) is holding an EA meetup in Basel. This is an event for people who are interested in Effective Altruism to meet up and get to know each other. There will be no formal program but a lot of talking, eating and having fun!</p>\n\n<p>Facebook event: <a href=\"https://www.facebook.com/events/1545987715672064/\">https://www.facebook.com/events/1545987715672064/</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href=\"/meetups/2b\">Effective Altruism Meetup Switzerland</a></h2></body></html>", "user": {"username": "SaraSavona"}}, {"_id": "v4ydsWX47vyBTRZzu", "title": "Maximizing long-term impact", "postedAt": "2015-03-03T19:50:01.524Z", "htmlBody": "<html><body><p><strong>Outline:</strong>&#xA0;I argue that interventions which affect the relative probabilities of humanity&apos;s long-term scenarios have much higher impact than all other interventions. I discuss some possible long-term scenarios and give a high-level classification of interventions.</p>\n<h1>Background</h1>\n<p>It is common knowledge in the Effective Altruism movement that different interventions often have vastly different <a href=\"https://en.wikipedia.org/wiki/Marginal_utility\">marginal utility</a>&#xA0;(per dollar or per some other unit of invested effort). Therefore, one of the most important challenges in maximizing impact is identifying interventions with marginal utility as high as possible. In the current post, I attack this challenge in the broadest possible scope: taking into account impact along the entire timeline of the future.</p>\n<p>One of the first questions that arise in this problem is the relative importance of short-term versus long-term impact. A detailed analysis of this question is outside the scope of the current post. I have argued <a href=\"http://lesswrong.com/lw/lo7/anatomy_of_multiversal_utility_functions_tegmark/\">elsewhere</a> that <a href=\"https://dl.dropboxusercontent.com/u/34639481/Updateless_Decision_Theory.pdf\">updateless decision theory</a> and Tegmark&apos;s <a href=\"https://en.wikipedia.org/wiki/Mathematical_universe_hypothesis\">mathematical universe hypothesis</a> imply a <a href=\"https://en.wikipedia.org/wiki/Time_preference\">time discount</a> falling much slower than exponentially and only slightly faster than [time since Big Bang]<sup>-1</sup>. This means that the timescale on which time discount becomes significant (at least about 14 billion years from today&apos;s standpoint) is much larger than the age of the human species, favoring interventions focused on the far long-term.</p>\n<p>The most evident factor affecting humanity&apos;s welfare in the long-term is scientific and technological progress. Progress has drastically transformed human society, increased life expectancy, life quality and total human population. The industrial revolution in particular has created a world in which the majority of people in developed countries enjoy a lifestyle of incredible bounty and luxury compared to the centuries which came before. Progress continues to advance in enormous steps, with total eradication of disease and death and full automation of labor required for a comfortable lifestyle being realistic prospects for the coming centuries.</p>\n<p>It might appear reasonable to conclude that the focus of long-term interventions has to be advancing progress as fast as possible. Such a conclusion would be warranted if progress was entirely 1-dimensional or at least possessing only one possible asymptotic trajectory in the far future. However, this is almost certainly not the case. Instead, there is a number of conceivable asymptotic trajectories (henceforth called &quot;future scenarios&quot;) with vastly different utility. Hence, interventions aiming to speed up progress appear much less valuable than interventions aiming to modify the relative probabilities of different scenarios. For example, it is very difficult to imagine even a lifetime of effort by the most suitably skilled person speeding up progress by more than 100 years. On the other hand it is conceivable that a comparable effort can lead to changing scenario probabilities by 1%. The value of the former intervention can be roughly quantified as 10<sup>2</sup> late-humanity-years whereas the value of the latter intervention is at least of the order of magnitude of (14 billion x 1% = 1.4 x 10<sup>8</sup>) late-humanity-years.</p>\n<h1>Future Scenarios</h1>\n<p>A precise description of scenario space is probably impossible at the current level of knowledge. Indeed, improving our understanding of this space is one type of intervention I will discuss in the following. In this post I don&apos;t even pretend to give a full classification of scenarios that are possible as far as we can know today. Instead, I only list the examples that currently seem to me to be the most important in order to give some idea of how scenario space might look like.</p>\n<p>Some of the scenarios I discuss cannot coexist as real physical possibilities since they rely on mutually contradictory assumptions on the feasibility of artificially creating and/or manipulating intelligence. Nevertheless, they all seem to be valid possibilities given our current state of knowledge the way I see it (other people have higher confidence than myself regarding the aforementioned assumptions). Also, there seems to be no set of reasonable assumptions under which only scenario is physically possible.</p>\n<p>I call &quot;dystopia&quot; those scenarios in which I&apos;m not sure I would want to wake up from <a href=\"https://en.wikipedia.org/wiki/Cryonics\">cryonic suspension</a>&#xA0;and &quot;utopia&quot; the other scenarios (the future is likely to be so different from the present that it will appear to be either horrible or amazing in comparison). This distinction is not of fundamental importance: instead, our decisions should be guided by the relative value of different scenarios. Also, some scenarios contain residual free parameters (scenario space <a href=\"https://en.wikipedia.org/wiki/Moduli_(physics)\">moduli</a>, so to speak) which affect their relative value with respect to other scenarios.</p>\n<h2>Dystopian Scenarios</h2>\n<h3>Total Extinction</h3>\n<p>No intelligent entities remain which are descendant from humanity in any sense. Possible causes include <a href=\"https://en.wikipedia.org/wiki/Nuclear_holocaust\">global thermonuclear war</a>, bioengineered pandemic, <a href=\"https://en.wikipedia.org/wiki/Grey_goo\">uncontrollable nanotechnology</a>&#xA0;and natural disasters such as <a href=\"https://en.wikipedia.org/wiki/Impact_event\">asteroid impact</a>. The last cause, however, seems unlikely since frequency of such events is low and defenses will probably be ready long before time.</p>\n<h3>Unfriendly Artificial Intelligence</h3>\n<p>According to a hypothesis known as &quot;AI foom&quot;,&#xA0;<a href=\"https://en.wikipedia.org/wiki/Recursive_self-improvement\">self-improving artificial intelligence</a> will reach a critical point in its development (somewhere below human intelligence) at which its intelligence growth will become so rapid that it quickly crosses into <a href=\"https://en.wikipedia.org/wiki/Superintelligence\">superintelligence</a> and becomes smarter than all other coexisting intelligent entities put together. The fate of the future will thus hinge on the goal system programmed into this &quot;singleton&quot;. If the goal system was not designed with safety in mind (a highly non-trivial challenge known as <a href=\"https://en.wikipedia.org/wiki/Friendly_artificial_intelligence\">friendly AI</a>), the resulting AI is likely to <a href=\"http://intelligence.org/files/AIPosNegFactor.pdf\">wipe out the human race</a>. The AI itself is likely to proceed with colonizing the universe, creating a future possibly more valuable than inanimate nature but still highly dystopian<sup>1</sup>.</p>\n<h3>Superdictatorship</h3>\n<p>A single person or a small group of people gains absolute power over the rest of humanity and proceeds to abuse this power. This may come about in a number of ways, for example:&#xA0;</p>\n<ul>\n<li>Dictators enhance their own intelligence. The risks of this process may lead to extremely immoral&#xA0;<a href=\"https://en.wikipedia.org/wiki/Transhumanism\">posthumans</a>&#xA0;even if the initial persons were moral.</li>\n</ul>\n<ul>\n<li>Creation of superintelligences that are completely loyal to the dictators. These superintelligences can be AI or enhanced humans. This scenario requires the malevolent group to solve the &quot;friendliness&quot; problem (maintaining a stable goal system through a process of extreme intelligence growth).</li>\n</ul>\n<ul>\n<li>Use of nanotechnology to forcibly <a href=\"https://en.wikipedia.org/wiki/Mind_uploading\">upload</a> the rest of humanity into a computer simulation where they are at the mercy of the dictators.</li>\n</ul>\n<ul>\n<li>Some sort of technology for complete mind control, e.g. involving genetically reprogramming humanity using a <a href=\"https://en.wikipedia.org/wiki/Retrovirus\">retrovirus</a>.</li>\n</ul>\n<p>The risk of these scenarios is elevated by concentration of resources and technological capacity in the hands of authoritarian governments.</p>\n<h3><span>Unhumanity</span></h3>\n<p>A large number of people undergo a sequence of mind modifications that make them more intelligent and economically competitive but lose important human qualities (e.g. love, compassion, curiosity, humor). The gradual nature of the process creates an <a href=\"http://lesswrong.com/lw/ase/schelling_fences_on_slippery_slopes/\">unalarming appearance</a>&#xA0;since the participants consider only the next step at any given moment instead of considering the ultimate result. The resulting posthumans use their superior intelligence and economic power to wipe out the remaining unmodified or weakly modified people. The value of this scenario can be as low as the <a href=\"http://wiki.lesswrong.com/wiki/Unfriendly_artificial_intelligence\">UFAI</a> scenario or somewhat higher, depending on the specifics of the mind modifications.</p>\n<h2>Utopian Scenarios</h2>\n<h3>Friendly Artificial Intelligence</h3>\n<p>The AI foom singleton is imbued with a goal system very close to human values, possibly along the lines of <a href=\"https://intelligence.org/files/CEV.pdf\">Coherent Extrapolated Volition</a> or the values of the specific person or group of persons from whose point of view we examine the desirability of scenarios. This is probably the most utopian scenario since it involves an immensely powerful superintelligence working towards creating the best universe possible. It is difficult to know the details of the resulting future (although there have been some <a href=\"http://lesswrong.com/lw/xy/the_fun_theory_sequence/\">speculations</a>) but it is guaranteed to be highly valuable.</p>\n<h3>Emulation Republic</h3>\n<p>All people exist as <a href=\"https://en.wikipedia.org/wiki/Mind_uploading\">whole brain emulations</a>&#xA0;or modified versions thereof. Each star system has a single government based on some form of popular sovereignty.</p>\n<p>Non-consensual physical violence doesn&apos;t exist since it is impossible to invade someone&apos;s virtual space without her permission and shared virtual spaces follow guaranteed rules of interaction. A fully automated infrastructure in which everyone are shareholders allows living comfortably without the necessity of labor. Disease is irrelevant, immortality is a given (in the sense of extremely long life; the <a href=\"https://en.wikipedia.org/wiki/Heat_death_of_the_universe\">heat death of the universe</a> might still pose a problem). People choose their own pseudo-physical form in virtual spaces for which reason physical appearance is not a factor in social rank, gender assignment at birth causes few problems and racism in the modern sense is a non-issue.</p>\n<p>People are free to create whatever virtual spaces they want, within the (weak) resource constraints as long as they don&apos;t contain morally significant entities. Brain emulations without full citizen status are forbidden up to allowances for raising children. Cloning oneself is allowed but making children is subject to regulation for the child&apos;s benefit.</p>\n<p>Access to the physical layer of reality is strictly regulated. It is allowed only for pragmatic reasons such as scientific research with the goal of extending the current civilization lifespan even more. All requests for access are reviewed by many people, only minimal necessary access is approved and the process is monitored in real-time. By these means, the threat of malevolent groups breaking the system through the physical layer is neutralized.</p>\n<h3>Superrational Posthumanity</h3>\n<p>Human intelligence is modified to be much more <a href=\"https://en.wikipedia.org/wiki/Superrationality\">superrational</a>. This effectively solves all <a href=\"http://slatestarcodex.com/2014/07/30/meditations-on-moloch/\">coordination problems</a>, removing the need in government as we understand it today. This scenario assumes strong modification of human intelligence is feasible which is a weaker assumption than the ability to create de novo AI but a stronger assumption than the ability to create whole brain emulations.</p>\n<h2>Other Scenarios</h2>\n<p>There are scenarios which are difficult to classify as &quot;dystopian&quot; and &quot;utopian&quot; due to strong effect of certain parameters and different imaginable &quot;cryonic wake up&quot; scenarios. Such scenarios can be constructed by mixing dystopian and utopian scenarios. This includes scenarios with several classes of people (e.g. free citizens and slaves, the latter existing as emulations for the entertainment of their masters) and scenarios with several &quot;species&quot; of people (people with differently modified minds).</p>\n<h1>Intervention Types</h1>\n<p>I distinguish between 4 types of interventions with long-term impact. The types of intervention available in practice depend on the point in which you are located on the progress timeline, with type I interventions available virtually always and type IV interventions available only next to a progress branching point. I give some examples of existing programmes within those categories, but the list is intended to be far from exhaustive. In fact, I would be glad if the readers suggest more examples and discuss their relative marginal utility.</p>\n<h2>Type I: Sociocultural Intervention</h2>\n<p>These are interventions that aim to &quot;raise the <a href=\"http://lesswrong.com/lw/1e/raising_the_sanity_waterline/\">sanity waterline</a>&quot; (improve the average rationality of mankind, with higher weight on more influential people) and/or improve the morality of human cultures. The latter is to be regarded from the point of view of the person or group doing the intervention. These interventions don&apos;t assume a specific model of long-term scenarios, instead striving to maximize the chance that humanity chooses the right path when it reaches the crossroads.</p>\n<p>Example of a type I interventions include&#xA0;<a href=\"http://rationality.org/\">CFAR</a>&#xA0;and the EA movement. Other examples might include educational programmes, atheist movements and human right movements.</p>\n<h2>Type II: Futures Research</h2>\n<p>These are interventions that aim to improve our understanding of the possible future scenarios, their relative value and the factors influencing their relative probability. They assume the current state of progress is sufficiently advanced to make discussion of future scenarios relevant. For example, in 1915 nobody would be able to envision whole brain emulation, AI or nanotechnology.</p>\n<p>Examples include <a href=\"http://www.fhi.ox.ac.uk/\">FHI</a>, <a href=\"http://cser.org/\">CSER</a>,&#xA0;<a href=\"http://futureoflife.org/\">FLI</a>&#xA0;and <a href=\"http://gcrinstitute.org/\">GCRI</a>.</p>\n<h2>Type III: Selective Progress</h2>\n<p>These are interventions that try to accelerate progress in selected areas with the aim of increasing probability of desirable scenarios. They assume the current understanding of future scenarios is sufficiently advanced to know the dependence of the relative probabilities of future scenarios on progress in different areas.</p>\n<p>One example is <a href=\"http://intelligence.org/\">MIRI</a> who try to accelerate progress in AGI safety relatively to progress in AGI in general. Other possible examples would be research programmes studying defense against bioengineered pandemics or nanoreplicators.</p>\n<h2>Type IV: Scenario Execution</h2>\n<p>These are interventions that aim at direct realization of a specific scenarios. They assume the relevant technology already exists.</p>\n<p>As far as I know, such interventions are still impossible today. Theoretical examples include an FAI construction project or a defense system against bioengineered pandemics.</p>\n<h1>Summary</h1>\n<p>Long-term thinking leads to somewhat counterintuitive conclusions regarding the most effective interventions. Interventions aiming to promote scientific and technological progress are not necessarily beneficial and can even be harmful. Effective interventions are focused on changing culture, improving our understanding of the future and accelerating progress in highly selected areas.</p>\n<p>Many questions remain, for example:</p>\n<ul>\n<li>What is the importance of cultural interventions in first world versus third world countries?</li>\n<li>Progress in which areas is beneficial / harmful, to the extent of our current ability to predict?</li>\n<li>What are the relative marginal utilities of existing programmes in the 4 categories above?</li>\n</ul>\n<p>&#xA0;</p>\n<p><sup>1</sup>&#xA0;There is a possibility that the <a href=\"http://wiki.lesswrong.com/wiki/Unfriendly_artificial_intelligence\">UFAI</a> will <a href=\"http://wiki.lesswrong.com/wiki/Acausal_trade\">bargain acausally</a> with a <a href=\"http://wiki.lesswrong.com/wiki/Friendly_artificial_intelligence\">FAI</a> in a different <a href=\"https://en.wikipedia.org/wiki/Many-worlds_interpretation\">Everett branch</a>, resulting in a Utopia. However, there is still an enormous incentive to increase the probability of the FAI scenario with respect to the UFAI scenario.</p></body></html>", "user": {"username": "Squark"}}, {"_id": "65HMSxa4FjX4NB2qX", "title": "I am Seth Baum, AMA!", "postedAt": "2015-03-03T19:38:19.141Z", "htmlBody": "<html><body><p>Hello Effective Altruism Forum,<br><br>I am <a href=\"http://sethbaum.com\">Seth Baum</a> and I will be here to answer your questions <strong>3 March 2015, 7-9 PM US ET</strong> (New York time). You can post questions in this thread in the meantime. Here is some more background:<br><br>I am Executive Director of the <a href=\"http://gcrinstitute.org/\">Global Catastrophic Risk Institute</a> (GCRI). I co-founded GCRI in 2011 with <a href=\"http://tony-barrett.com/\">Tony Barrett</a>. GCRI is an independent, nonprofit think tank studying major risks to the survival of human civilization. We develop practical, effective ways to reduce the risks.<br><br>There is often some confusion among effective altruists about how GCRI uses the term &#x201C;global catastrophic risk&#x201D;. The bottom line is that we focus on risk of catastrophes that could cause major permanent harm. This is similar to some use of &#x201C;existential risk&#x201D;. You can read more about that <a href=\"http://gcrinstitute.org/concept\">here</a>.<br><br>GCRI <a href=\"http://gcrinstitute.org/february-newsletter-new-directions-for-gcri\">just announced</a> major changes to GCRI&#x2019;s identity and direction. We are focusing increasingly on in-house research oriented towards assessing the best ways of reducing the risks. This is at the heart of our new flagship <a href=\"http://gcrinstitute.org/integrated-assessment\">integrated assessment project</a>, which puts all the gcrs into one study to learn the best risk reduction opportunities.<br><br>If you&#x2019;d like to stay up to date on GCRI, you can sign up for our monthly <a href=\"http://gcrinstitute.org/newsletter.html\">email newsletter</a>. You can also support GCRI by <a href=\"http://gcrinstitute.org/donate\">donating</a>.<br>And GCRI is not active on social media, but you can follow me on <a href=\"https://twitter.com/SethBaum\">Twitter</a>.<br><br>I am excited to have this chance to speak with the online effective altruism community. I was involved in the online utilitarianism community around 2006-2007 via my <a href=\"http://felicifia.blogspot.com\">Felicifia blog</a>. I&#x2019;m really impressed with how the community has grown. A lot of people have put a lot of work into this. Thanks go in particular to Ryan Carey for setting up today&#x2019;s AMA and for doing so much more.<br><br>There are also a few things I&#x2019;m hoping to learn from you:<br><br>First, I am considering a research project on what motivates people to take on major global issues and/or to act on altruistic principles more generally. I would be interested in any resources you know of about this. It could be research on altruism/global issues in general or research on what motivates people to pursue effective altruism.<br><br>Second, I am interested in what you think are major open questions in gcr/xrisk. Are you facing decisions to get involved in gcr/xrisk, or to take certain actions to reduce the risks? For these decisions, is there information that would help you figure out what to do? Your answers here can help inform the directions GCRI pursues for its research. We aspire to help people make better decisions to more effectively reduce the risks.</p></body></html>", "user": {"username": "SethBaum"}}, {"_id": "YiFdK2D8xq2YxyhNi", "title": "Can we set up a system for international donation trading?", "postedAt": "2015-03-03T13:47:07.747Z", "htmlBody": "<html><body><p>In the future I&apos;ll probably want to donate to a UK charity (<a href=\"http://reducing-suffering.org/why-i-support-the-humane-slaughter-association/\">Humane Slaughter Association</a>). Some people in the UK probably want to donate to a US charity like GiveWell or MIRI. Rather than both donating to foreign charities, we should trade donations so that we can both get tax deductibility / Gift Aid for our donations.</p>\n<p>Trading doesn&apos;t have to occur only between matched countries. There&apos;s a benefit to trading so long as just one side gets tax deductibility / Gift Aid where it didn&apos;t exist before. For example, if a UK donor was going to give to a Spanish charity, and if a US donor was going to give to a UK charity, the UK donor should give to the UK charity to get Gift Aid, while the US donor gives to the Spanish charity (without tax deductibility). Trading like what I just described even works for those in the US who have already donated 50% of their income and so can no longer get tax deductions in the current year from further US donations.</p>\n<p>We should set up a marketplace for trading donations.&#xA0;<a href=\"/ea/cc/help_a_canadian_give_with_a_taxdeduction_by/1wv\">According to Tom Ash</a>, trading donations is completely legal.</p>\n<p>I created an extremely low-tech platform for donation trading in this <a href=\"https://docs.google.com/spreadsheets/d/12Wl7T8_mAdM2OWAgoGHOVdVSChkCUd1PXqIYPP2JUII/edit#gid=0\">Google spreadsheet</a>. Feel free to add your info there, keeping in mind that it&apos;s shared publicly on the web.</p>\n<p>If something like this gets traction, perhaps we can create a website for the service, not just for EAs but for all donors around the world. I haven&apos;t been able to find any existing website for this. I&apos;m not sure if that&apos;s because large-scale coordination of donation trading is frowned upon or whether it&apos;s just because no one has scooped up this opportunity yet. I&apos;m normally skeptical of startup ideas, but this one seems promising to me.</p>\n<p>(See also an <a href=\"/ea/cc/help_a_canadian_give_with_a_taxdeduction_by/\">earlier post</a> by Robert Wiblin about donation trading. Giles <a href=\"/ea/cc/help_a_canadian_give_with_a_taxdeduction_by/1uu\">recommended</a> a system like I&apos;m proposing here.)</p></body></html>", "user": {"username": "Brian_Tomasik"}}, {"_id": "hQtayqi3r6bo3EPoh", "title": "The Counterfactual Validity of Donation Matching", "postedAt": "2015-03-02T22:02:40.295Z", "htmlBody": "<html><body><p>A foundation finds an organization doing good work with a <a href=\"http://en.wikipedia.org/wiki/Room_for_more_funding\">funding gap</a> of about $5M. They could just give the organization $5M, but instead they decide to try and help the organization find some small donors to spread its reach. The foundation offers to match donations up to $2.5M. This is a real match: they will give $1 for every $1 anyone else gives, up to their limit. When the match is over, however, if the funding gap still hasn&apos;t been met they plan to make up the difference.</p>\n<p>Let&apos;s consider some possiblities: <!-- td{text-align:right} --> \n<table>\n<tbody>\n<tr>\n<th>Amount Raised</th> <th>Match Given</th> <th>Makeup Contribution</th> <th>Total Received</th>\n</tr>\n<tr>\n<td>$0</td>\n<td>$0</td>\n<td>$5M</td>\n<td>$5M</td>\n</tr>\n<tr>\n<td>$100K</td>\n<td>$100K</td>\n<td>$4.8M</td>\n<td>$5M</td>\n</tr>\n<tr>\n<td>$200K</td>\n<td>$200K</td>\n<td>$4.6M</td>\n<td>$5M</td>\n</tr>\n<tr>\n<td>$1M</td>\n<td>$1M</td>\n<td>$3M</td>\n<td>$5M</td>\n</tr>\n<tr>\n<td>$2M</td>\n<td>$2M</td>\n<td>$1M</td>\n<td>$5M</td>\n</tr>\n<tr>\n<td>$2.5M</td>\n<td>$2.5M</td>\n<td>$0</td>\n<td>$5M</td>\n</tr>\n<tr>\n<td>$3M</td>\n<td>$2.5M</td>\n<td>$0</td>\n<td>$5.5M</td>\n</tr>\n<tr>\n<td>$4M</td>\n<td>$2.5M</td>\n<td>$0</td>\n<td>$6.5M</td>\n</tr>\n</tbody>\n</table>\nIf the organization raises less than $2.5M from small donors they end up with a total of $5M regardless of the amount the small donors give. This is described as a 1:1 match, but because their &quot;makeup contribution&quot; acts as a 1:-2 match the overall effect on the charity is actually a 1:-1 match: for every dollar you give they&apos;ll give one fewer! By donating to the organization you&apos;re effectively donating to the foundation, by leaving them with more money to do other things. [1]</p>\n<p>Most donation matching isn&apos;t this extreme, but this example shows the main consideration in donation matching: how is the world different if you do donate versus if you don&apos;t? This is counterfactual reasoning, and in the case of donation matching it&apos;s specifically a question of <a href=\"http://www.jefftk.com/p/counterfactual-trust\">counterfactual trust</a>. You trust them to match your donation if you give one, but do you trust that your donation is necessary to prompt them to give?</p>\n<p><a href=\"http://www.benkuhn.net/\">Ben Kuhn</a> recently ran a <a href=\"http://www.benkuhn.net/matching-results\">survey</a> to try to understand what people expect when they donate to a matching campaign. His questions looked like:</p>\n<blockquote>Good Ventures today announced $5M in matching funds for donations made to GiveDirectly from 2013-12-03 through 2014-01-31. All donations to GiveDirectly during the period, up to $100,000 per donor, will be counted toward the match. <br>...<br> Suppose that, over the time period the match was active, GiveDirectly raised $4.5M. If you had donated $10 to GiveDirectly at that time, how much <em>more money</em> would they have received than if you had not donated anything?</blockquote>\n<p>This is asking us how much we trust GiveDirectly&apos;s match to be counterfactually valid. If we think they would have just gone ahead and donated the $5M regardless then we&apos;d answer $10, while if we think they&apos;ll would only donate in response to our donation we&apos;d answer $20. If we weren&apos;t sure how much to trust the match we might say something between $10 and $20.</p>\n<p>Ben writes that $20 seems to have been accurate here:</p>\n<blockquote>Interestingly, for both the Good Ventures and HCEA matches, we can check people&apos;s beliefs against reality. For Good Ventures, we can look at <a href=\"http://blog.givewell.org/2013/12/03/good-ventures-matching-gift-to-givedirectly-and-grants-to-top-charities/\">GiveWell&apos;s blog post</a> on the match:\n<blockquote>If the full amount of the match is reached, we believe Good Ventures will be giving more in total to our top charities this year than they would have been had a match not been a possibility.</blockquote>\nThe wording &quot;If the full amount... is reached&quot; suggests that Good Ventures was in fact planning to donate only the amount matched, so at least on the margin the match was fully counterfactual.</blockquote>\n<p>Unfortunately &quot;fully counterfactual&quot; is too strong. Good Ventures has a bunch of money that they intend to give to the most effective charities they can, and this is great! But their plan to use the money as close to optimally as possible means this money can&apos;t actually be swayed very much. Say I give $10 to Give Directly and Good Ventures matches my donation with $10 they wouldn&apos;t otherwise donate this year. If I hadn&apos;t donated, however, they would have kept that $10 to spend in a later year on an opportunity they consider approximately as valuable.</p>\n<p>Why do I say &quot;approximately as valuable&quot;? Good Ventures is run by clear thinking people who want to have as big a positive impact on the world as they can. If they thought that Give Directly represented a better opportunity for giving than they were likely to see in the future they would donate more to it until that was no longer the case, and vice versa. The only reason they&apos;re willing to offer a match is that they don&apos;t have a precise target for Give Directly in mind and they think the benefit of bringing in more donors outweighs the benefit of being slightly more deliberate about which donations happen in one year vs another.</p>\n<p>There&apos;s one little gap here, however, which we can get a good bit of mileage out of. What I describe only holds if you and the matcher have approximately the same values. If you, say, think current people matter far more than future people, however, then taking Good Ventures up on their match is great, because it gets them to spend money now instead of delaying and spending it on others later. This situation is most apparent with &quot;general&quot; donation matches, like an employer offering to match donations to any 501(c)3 organization. If the size of the employer pool is not fixed or you plan to give to a charity you think is much more effective than the 501(c)3s the money would otherwise go to, the counterfactual effect of your donation really is doubled.</p>\n<p>There&apos;s a spectrum here, from &quot;funder negates your match&quot; through &quot;funder ignores your match&quot; through &quot;funder acts on your match but would otherwise fund something about as valuable (to you)&quot; up to &quot;funder acts on your match and would otherwise fund something much less valuable (to you)&quot;. A good guideline is to respect a match only when the match is untargeted, when the funder is willing to match donations to any charity: this matches up almost exactly with when matches are fully counterfactually valid. [2]</p>\n<p>(Similarly you shouldn&apos;t offer a fully general match, because charities <a href=\"http://www.jefftk.com/p/charity-variance-vision\">vary</a> <a href=\"http://www.jefftk.com/p/the-unintuitive-power-laws-of-giving\">dramatically</a> in their effectiveness. [3] If you would like something with the social proof benefits of matching but without the dishonesty of misleading people about the effects of their donation, consider making a donation and then <a href=\"http://www.benkuhn.net/matching-results#consider-running-a-challenge-instead-of-a-match\">challenging</a> others to do the same.)</p>\n<p><small><em>I also posted this <a href=\"http://www.jefftk.com/p/the-counterfactual-validity-of-donation-matching\">on my blog</a>.</em></small></p>\n<p><br> [1] Intent matters a lot here in figuring dishonesty. If the funder planned from the beginning to hit a target regardless of other people&apos;s actions that&apos;s bad, but if instead after failing to hit a target they decide to be generous and gill the gap that sounds good. Yet both are the same from a counterfactual reasoning perspective: they give one dollar fewer for every dollar you give.</p>\n<p>[2] This is the only situation in which I&apos;ll list a match on our <a href=\"http://www.jefftk.com/donations\">donations page</a>. I still don&apos;t count it toward my goal of <a href=\"http://www.jefftk.com/p/giving-half\">50%</a> for the year, but I think counting it that way would be defensible.)</p>\n<p>[3] Tomasik <a href=\"http://reducing-suffering.org/why-charities-dont-differ-astronomically-in-cost-effectiveness/\">claims to disagree</a>, but this is a matter of degree. While he rejects claims 1000x claims of variance he does &quot;suspect many charities differ by at most ~10 to ~100 times, and within a given field, the multipliers are probably less than a factor of ~5&quot; which is strong enough to argue against fully general matches, and probably field-restricted matches as well.</p></body></html>", "user": {"username": "Jeff_Kaufman"}}, {"_id": "2LLsLAWpJqGBaoSFg", "title": "March Open Thread", "postedAt": "2015-03-01T17:14:59.382Z", "htmlBody": "<html><body><p><span>Welcome to March&apos;s open thread on the Effective Altruism Forum. This is our place to discuss relevant topics that have not appeared in recent posts.</span></p></body></html>", "user": {"username": "Evan_Gaensbauer"}}, {"_id": "GQTgTtvja4toZHwrk", "title": "A call for ideas - EA Ventures", "postedAt": "2015-03-01T14:50:59.154Z", "htmlBody": "<html><body><p><span>EA Ventures&#xA0;</span><span>(</span><a href=\"http://eaventures.org/\">eaventures.org</a><span>)&#xA0;</span><span>is compiling a list of ideas that they </span><span>should consider funding. Add your own to this <a href=\"https://docs.google.com/document/d/13Hzde8wgfSUO2ij0lAUxztNsOM03RxD9plo5HaaXUmk/edit?usp=sharing\">Google doc</a>.</span></p></body></html>", "user": {"username": "RyanCarey"}}, {"_id": "GiMB54XKnGfX8k9Qx", "title": "Results from a survey of people's views on donation matching", "postedAt": "2015-03-01T07:30:55.575Z", "htmlBody": "<html><body><p>Since a lot of people lately have been discussing donation matching and the various issues about counterfactuals that surround it, I ran a survey a couple weeks ago to answer various of my questions about donation matching.</p>\n<p>You can read the full post <a href=\"http://www.benkuhn.net/matching-results\">here</a>. I&apos;m not going to cross-post the whole thing because it becomes difficult to keep the two versions in sync, but I&apos;ll include the &quot;conclusion for matching donors&quot; below to pique your interest. (Note that because it was only a survey of a small convenience sample, you should put limited weight on these conclusions! But I think they&apos;re useful nevertheless.)</p>\n<hr>\n<h2>Be transparent about your matching</h2>\n<p>Where will any unmatched funds go? Will they be donated to the same organization anyway? Given to a different charity? Burned? A strong majority thought that all matches were fully counterfactually valid, so if this isn&#x2019;t true of your match, you should say so. This could affect how much people donate, and how deceived they feel, so it&#x2019;s very important to be totally honest here.</p>\n<p>One thing that I didn&#x2019;t look at in this survey, but that merits future research, is another type of &#x201C;partial validity&#x201D; in which unmatched funds don&#x2019;t go to the same charity, but go to another charity, sometimes a quite similar one. It&#x2019;s hopefully clear that this always happens for foundations, but it&#x2019;s not clear for private donors like HEA&#x2019;s anonymous matcher or one&#x2019;s friends. It&#x2019;s probably wise to be transparent about this in your fundraiser as well.</p>\n<p>Separately from concerns about honesty, I think transparency in matching is great for other reasons as well. It seems to me that by far the biggest benefits of many EA fundraisers are not just that they raise additional funds&#x2014;the best part is the flow-through effects from getting people to be more public about their giving, to discuss effective altruism more, and to get their friends interested. From that standpoint, it seems like a huge win to use the matches to introduce people to two central practices of effective altruism, transparency and counterfactual reasoning. It would also make the campaigns stand out more from typical fundraisers.</p>\n<h2>Consider running a challenge instead of a match</h2>\n<p>The survey suggested that people found challenge fundraisers just as compelling as matches, and seemed to reduce their donations less when the challenge target was reached than when a match expired. Furthermore, with challenges, the counterfactual effects are much clearer: it&#x2019;s obvious where your money went, and the funding dynamics are much more intuitive.</p>\n<p>This is consistent with my interpretation of the donation matching literature, where I wrote that I expected matches to work mostly through social proof and urgency effects rather than through making people&#x2019;s donations bigger (and found, consistent with this, that changing the amount of the match tended not to matter). Challenge fundraisers don&#x2019;t make people&#x2019;s donations bigger like matches do, but they share the same urgency effect and function as stronger social proof. So it&#x2019;s not surprising that they work just as well.</p>\n<h2>Consider running a larger experiment</h2>\n<p>This survey produced some useful info, but it would be even better to have actual field experiments (and a larger sample size). The academic literature on matches is sparse enough, and the literature on challenges even more so. So any additional experiments could add a lot to our knowledge.</p>\n<hr>\n<p>Once again,&#xA0;<a href=\"http://www.benkuhn.net/matching-results\">check out the full post</a>&#xA0;if you&apos;re interested in learning more, or have questions that aren&apos;t answered above. I hope this is useful to those considering running matching campaigns!</p></body></html>", "user": {"username": "Ben_Kuhn"}}, {"_id": "s3i84SPuiezxyuE5q", "title": "Meetup : Frankfurt: \"Which charities should we donate to?\"", "postedAt": "2015-02-27T20:42:24.786Z", "htmlBody": "<html><body><h2>Discussion article for the meetup : <a href=\"/meetups/2a\">Frankfurt: &quot;Which charities should we donate to?&quot;</a></h2>\n\t\t  <div>\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span>20 March 2015 07:00:00PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span>Frankfurt, Adalbertstra&#xDF;e 36a</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div>\n\t\t    <div><p>We&apos;ll have our third meetup! You can also find us at: <a href=\"http://www.meetup.com/Frankfurt-Effective-Altruism-Doing-Good-Better/events/past/?scroll=true#upcoming\">http://www.meetup.com/Frankfurt-Effective-Altruism-Doing-Good-Better/events/past/?scroll=true#upcoming</a></p>\n\n<p>The focus will be charity choice for donations, but there&apos;ll be enough time to discuss other things as well. :)</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href=\"/meetups/2a\">Frankfurt: &quot;Which charities should we donate to?&quot;</a></h2></body></html>", "user": {"username": "Denise_Melchin"}}, {"_id": "TFDTKfemMnGbKp3YG", "title": "Announcing Effective Altruism Ventures", "postedAt": "2015-02-27T20:03:34.072Z", "htmlBody": "<html><body><p><span>Today we&#x2019;re launching</span><a href=\"http://www.eaventures.org/\"><span> </span><span>Effective Altruism Ventures</span></a><span>, a project of </span><a href=\"https://centreforeffectivealtruism.org/\"><span>CEA</span></a><span>&#x2019;s Effective Altruism Outreach initiative. The goal of Effective Altruism Ventures is to test the theory that we can stimulate the creation of new high impact organizations by simply signaling that funding is available.</span></p>\n<p>&#xA0;</p>\n<p><span>GiveWell has argued in</span><a href=\"http://blog.givewell.org/2014/05/14/the-importance-of-committing-to-causes/comment-page-1/\"><span> </span><span>multiple</span></a><a href=\"http://blog.givewell.org/2013/04/18/challenges-of-passive-funding/\"><span> </span><span>blog</span></a><a href=\"http://blog.givewell.org/2014/04/23/meta-research-innovation-centre-at-stanford-metrics/\"><span> </span><span>posts</span></a><span> that interesting projects often do not appear until a major funder signals an interest in funding a project. This aligns with my experience running the Technology and Innovation department at the</span><a href=\"http://arnoldfoundation.org/\"><span> </span><span>Laura and John Arnold Foundation</span></a><span> and with YCombinator&#x2019;s recently announced</span><a href=\"https://www.ycombinator.com/rfs/\"><span> </span><span>Requests for Startups</span></a><span>. We designed Effective Altruism Ventures to provide this signal for EA-aligned projects.</span></p>\n<p>&#xA0;</p>\n<p><span>For Projects</span></p>\n<p><span>New projects can </span><span><a href=\"http://www.eaventures.org/apply\">apply</a></span><span> and go through a systematic evaluation process (the details of which are available</span><a href=\"http://www.eaventures.org/our-method\"><span> </span><span>here</span></a><span>)</span><span>. We will introduce projects that pass the evaluation to our network of individual and institutional funders and help find new funders if needed. We also provide strategic guidance, recruiting help and more. We are both cause-neutral and neutral on organization type (e.g. nonprofit, for-profit, benefit corporation etc.) Applications are rolling, but we devote more time to evaluations at set intervals throughout the year. The next evaluation sprint will be </span><span>May 1</span><span>, so interested projects should apply by then.</span></p>\n<p><span> </span></p>\n<p><span>To get a better sense of our evaluation process and of Effective Altruism Ventures itself, we completed an evaluation of ourselves using the EA Ventures evaluation framework. You can read the evaluation <a href=\"https://drive.google.com/open?id=0B1qxem7YHEVweTNRSnBIMEJZT00&amp;authuser=0\">here</a>. The results of our evaluation indicate that there is insufficient evidence to recommend making donations directly to Effective Altruism Ventures at this time. This is consistent with our current plan of running the project on a volunteer basis for 3-6 months before fundraising to support operational costs.</span></p>\n<p><span> </span></p>\n<p><span>For Funders</span></p>\n<p><span>For funders Effective Altruism Ventures is a risk-free way of gaining access to higher quality projects. We will learn about your funding priorities and then introduce you to vetted projects that meet your priorities. If you don&#x2019;t like a project you are free to decline to fund it. We simply ask that you provide us with your reasons so we can improve our evaluation procedure.</span></p>\n<p><span><strong><br></strong></span></p>\n<p><span>We also help improve funder coordination for new projects. This helps funders get a clearer sense of whether their funding is fungible with that of other EA funders.</span></p>\n<p><span><strong><br></strong></span></p>\n<p><span>Want to get involved?</span></p>\n<p><span>If you&#x2019;re interested in getting involved in Effective Altruism Ventures, we&#x2019;re looking for the following:</span></p>\n<p><span> </span></p>\n<ul>\n<li>\n<p><span>Projects</span><span>, especially those that are working in areas that are</span><a href=\"https://80000hours.org/2013/12/a-framework-for-strategically-selecting-a-cause/\"><span> </span><span>important, tractable and uncrowded</span></a><span>.</span></p>\n</li>\n<li>\n<p><span>Funders</span><span> who are ideologically aligned with EA and are interested in seeing our deal flow.</span></p>\n</li>\n<li>\n<p><span>Experts</span><span> in fields of interest that are willing to help us evaluate projects.</span></p>\n</li>\n<li>\n<p><span>Entrepreneurs</span><span> without their own project, but who are interested in working on one of the projects we recommend.</span></p>\n</li>\n<li>\n<p><span>Partners</span><span> who have strong networks and want to work closely with us to evaluation projects, find funders and source new projects.</span></p>\n</li>\n</ul>\n<p><span> </span></p>\n<p>&#xA0;</p>\n<p><span>If you fall into one of the above groups and would like to chat more about Effective Altruism Ventures, feel free to schedule time to chat</span><a href=\"http://calendly.com/kerry-l-vaughan/ea-ventures-meeting\"><span> </span><span>here</span></a><span> or email me at kerry@eaventures.org.</span></p>\n<div><span><br></span></div></body></html>", "user": {"username": "Kerry_Vaughan"}}, {"_id": "6sNpy87SsRuedrJM7", "title": "Meetup : London drinks and/or dinner", "postedAt": "2015-02-27T11:46:02.094Z", "htmlBody": "<html><body><h2>Discussion article for the meetup : <a href=\"/meetups/29\">London drinks and/or dinner</a></h2>\n\t\t  <div>\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span>28 February 2015 07:00:00PM (+0000)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span>Coach and Horses Vegetarian Pub, 29 Greek St, London W1D 5DH, W1D 5DH London, United Kingdom</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div>\n\t\t    <div><p>While Tom Ash is visiting London to see people before returning to Vancouver. All welcome, do invite anyone! Some of us will be eating.</p>\n\n<p>Tom will be there with some people from a while before (at least 6), as they have to head off before 7, so feel free to come early.</p>\n\n<p>Facebook event (please indicate if you might come for the booking): <a href=\"https://www.facebook.com/events/653571028102061\">https://www.facebook.com/events/653571028102061</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href=\"/meetups/29\">London drinks and/or dinner</a></h2></body></html>", "user": {"username": "Tom_Ash"}}, {"_id": "2ZjdGTZv5QscFzJX6", "title": "$10k of Experimental EA Funding", "postedAt": "2015-02-25T19:54:29.881Z", "htmlBody": "<html><body><p>Over the course of 2015, we will be distributing $10,000 to <strong>completed</strong> projects which we believe will have a significant <strong>long-term&#xA0;</strong>humanitarian impact.</p>\n<p>These awards are being made in exchange for certificates of impact. Here&apos;s how it works: you tell us about something good you did. We offer you some money. Rather than considering a complicated counterfactual (&quot;How well will this money be spent if I don&apos;t take it?&quot;), we encourage you to accept our offer if and only if you would be willing to <strong>undo</strong> the humanitarian impact of your project in exchange for the money. For more details, see <a title=\"Certificates of impact\" href=\"http://impactpurchase.org/certificates-of-impact/\">here</a>.</p>\n<p>Why are we buying certificates instead of making grants? Just as market prices help coordinate and incentivize the efficient production of commercial products, they could also help coordinate and incentivize efficient altruism. We also think that <a title=\"Paying for effort vs. paying for results\" href=\"http://impactpurchase.org/why-certificates/paying-for-effort-vs-paying-for-results/\"> paying for performance </a> <a title=\"Projections vs. evaluations\" href=\"http://impactpurchase.org/why-certificates/prediction-vs-retrospective-evaluation/\">after the fact</a> has a number of big advantages. Not convinced yet? See a <a title=\"Why certificates?\" href=\"http://impactpurchase.org/why-certificates/\">more complete answer</a>.</p>\n<p>Applications will include an asking price, the minimum amount of money that would be enough to compensate you for undoing the humanitarian impact of the project. The actual awards will be determined by combining the asking prices with our<a title=\"Impact evaluations\" href=\"http://impactpurchase.org/evaluations/\">impact assessments</a> in <a title=\"The (reverse) auction\" href=\"http://impactpurchase.org/the-auction/\">a (truthful) auction</a>. Instead of buying 100% of your project&apos;s impact, we&apos;ll buy some a fraction less than 50% (at your discretion).</p>\n<p>The awards will be made in ten $1,000 rounds, spread over the course of the year. <strong>The deadline for the first round is March 25. </strong>We&apos;ll post the results of each round as they occur. New proposals can be made in between rounds. Once an application is submitted it will be considered in each round unless it is withdrawn.</p>\n<p>If you are interested, submit an application <a href=\"https://docs.google.com/forms/d/1D1PlHNi_7ya9iI1StsR5vSraDvcjTFk-fk-DIUYFtu4/viewform?usp=send_form\">here</a>. The application process is designed to be as straightforward as possible. <a title=\"Our funding priorities\" href=\"http://impactpurchase.org/what-we-fund/\">Learn about</a> the kind of work we are most interested in, and see our <a title=\"Restrictions\" href=\"http://impactpurchase.org/restrictions-2/\">other restrictions</a>. If you have other questions or comments, contact us at<a href=\"mailto:contact@impactpurchase.org\">contact@impactpurchase.org</a> or discuss the project at the effective altruism forum.</p>\n<p><a href=\"http://impactpurchase.org/\">impactpurchase.org</a> contains other information about the project, and will describe awards as they are made.</p>\n<p>&quot;We&quot; is currently Paul Christiano and Katja Grace. If you are interested in purchasing certificates of impact as part of this effort, we&apos;d love to hear from you.</p></body></html>", "user": {"username": "Paul_Christiano"}}, {"_id": "vwb4B6qxFGP59y9P8", "title": "Hope: How Far Humanity Has Come", "postedAt": "2015-02-25T15:06:46.013Z", "htmlBody": "<html><body><p><em>This was written for the wedding ceremony of Ruby Bloom and Miranda Dixon-Luinenburg, as part of a section dedicated to affirming their shared values. The aim was to convey a sense of just how much incredible progress humanity has made, how fortunate we all are, and to motivate a feeling of hope for the future. I found it really enjoyable and motivating to write, and thought others here might find it interesting and/or motivating to read.</em></p>\n<p>&#xA0;</p>\n<p>The world today isn&#x2019;t perfect - far from it. But it&#x2019;s also much, much, better than it used to be. Just as it&#x2019;s impossible for us to really feel the full extent of the suffering in the world today, we also can&#x2019;t really feel the full extent of the progress humanity has made.&#xA0;</p>\n<p>But it&#x2019;s vital that we do, because it&#x2019;s that sense of progress that will give us hope, hope that the future can be better.</p>\n<p>Having hope isn&#x2019;t always easy. We look to the past, and we see suffering. We look at the world today, and we also see suffering. It&#x2019;s hard for your brain to tell the difference. 100,000 people dying feels roughly as bad as 1,000,000 people dying. But 100,000 deaths is a lot less than 1,000,000, even if it doesn&#x2019;t seem it. It&#x2019;s incredible progress.</p>\n<p>To really see progress, first we have to look backwards. Imagine what your life would have been like had you been born just 300 years ago - &#xA0;as an average person living in the 1700s. There was no middle class back then, so chances are you&#x2019;d be poor - very poor. So poor that you stood a real chance of starving. If you were lucky, and managed to keep enough food on the table, you&#x2019;d still be severely malnourished - enough that you could easily be killed off by any one of the various common diseases of the time. And deadly diseases were common: if you were born in 1700 in Europe, by the age of ten you&#x2019;d have lived through two smallpox epidemics, a measles epidemic, and a famine. Add to this the constant threat of infection - without running water and soap, without antibiotics, a mere cut could easily kill you.</p>\n<p>You worked hard - not just long hours, but physically gruelling agricultural or industrial work. Not just physically demanding, but also physically dangerous. If you got injured, you&#x2019;d be on the streets, begging.</p>\n<p>As a woman, you&#x2019;d avoid this physically threatening labor of work, of course - replaced with your own special kind of physically threatening labor. You&#x2019;d probably be pregnant most of the time you weren&#x2019;t nursing. Infant and child mortality were ridiculously high, so you could expect to lose a lot of kids - maybe half or more. Your chances of dying during childbirth would be much, much higher than they are today - add to that the fact that you&#x2019;re giving birth about ten times as often, and childbirth is one of your biggest risks of dying.</p>\n<p>You couldn&#x2019;t vote - a privilege reserved only for landowners. You probably couldn&#x2019;t read - less than half the population could. There&#x2019;s no electricity or heating, obviously, so you just have to get used to those cold, winter, nights, and pray that the bad weather doesn&#x2019;t kill your crops - and your family. Your life expectancy is around 35.</p>\n<p>Now think about your own life: your warm house, electricity, clean, running water. Your smartphone, internet connection, maybe that holiday you&#x2019;ve got booked for a few months&#x2019; time. Sure, you have stresses and worries: that you might not achieve what you could, that you don&#x2019;t have time to do all the things you enjoy, that someone you care about could get a rare illness. But you&#x2019;re only able to worry about these things because of a whole host of other worries that don&#x2019;t take up your time: you don&#x2019;t have to worry about getting enough food, about getting a small cut, about keeping fifteen children alive.</p>\n<p>The progress we&#x2019;ve made over the past 300 years is immense. And 300 years is nothing - an absolutely miniscule amount of time in the hundreds of thousands of years of human history.</p>\n<p>We&#x2019;ve made insane amounts of progress. Sometimes I look at the world around me, remembering that once humans were hunter gatherers living in the natural environment, vulnerable to predators and extreme weather, and everything looks amazing. How did we get here? How did we manage to create these huge, intricate, buildings, interwoven with technology so complex most of us can&#x2019;t even begin to explain how it all works?</p>\n<p>Somehow, life developed on Earth from the most basic elements - and somehow incredibly, we, humans, evolved from that first basic life. We learned to hunt, to make fire, to use tools.</p>\n<p>We developed writing, allowing us to share and pass on knowledge from generation to generation. We learned to farm, leading to the agricultural revolution, and allowing people to spend their time doing things other than searching for food. Gradually, new, more complex societies were born: cities and states with different classes of people. We learned to create our own fuel from coal, built the steam engine, and began producing goods in factories. We developed more and more advanced methods of transportation, allowing us to explore the world, share ideas, and grow in wealth and power. We learned how to make vaccines, and eradicated deadly killers such as smallpox, saving 100 million lives. We invented electricity, cars, and human flight. We put a man on the moon. We built computers, and connected them all via the internet. We made these computers small enough that anyone could carry one round in their pocket at all times.</p>\n<p>We&#x2019;ve made extraordinary progress in understanding the world around us, in learning to control our environment and guard against threats - large and small, in treating and eradicating diseases and saving lives. Every second, people are dying - but every second people are also defying death, death that would have been inevitable just a century ago.</p>\n<p>Compared to almost everyone who has ever lived in all of history, your life is awesome.</p>\n<p>Of course, even today, we&#x2019;re the lucky ones. The average person today is much better off than the worst-off person. Millions of people in the world still aren&#x2019;t so lucky - millions still live in poverty, still struggle to get enough food to get by, still die from curable diseases. But we now have the power to help people who suffer today, even those living on the other side of the world, at little cost to ourselves. Incredible advances in transport and technology mean that someone living in the Western world can save a life in developing countries at the click of a button. We&#x2019;re much less violent, much more compassionate, empathetic and altruistic - we have not just the practical ability to help those worse off but also increasing levels of motivation to do so.</p>\n<p>We&#x2019;re going to face some serious challenges over the next century, that&#x2019;s for certain - and of course it&#x2019;s possible we won&#x2019;t make it. But we&#x2019;ve also got so much progress ahead of us in the next few decades, more progress than we can imagine. The world in 30 years is likely to be pretty unrecognisable to us now. Based on the patterns of the past, if we don&#x2019;t off ourselves, there&#x2019;s a chance it&#x2019;s going to be unrecognisably better - that we&#x2019;ll have eradicated the vast majority of suffering, that we&#x2019;ll have a drastically better understanding of our universe and the technology to exert much greater control over it, that we&#x2019;re going to have moved closer towards the light.</p>\n<p>One thing I don&#x2019;t doubt is that we&#x2019;re going to put up a hell of a fight. We&#x2019;re going to do everything we can to survive. We&#x2019;re not going to sit back and let this universe engulf us. Around me, I see so much drive to fight back: to eliminate suffering, to push humanity forwards into a bright and better future, and that drive only seems to be getting stronger. And that, above all, gives me hope.</p>\n<p><em>&#xA0;</em></p>\n<p>&#xA0;</p></body></html>", "user": {"username": "Jess_Whittlestone"}}, {"_id": "HuhC2MvW6a8DJvWnL", "title": "Meetup : EA Brighton", "postedAt": "2015-02-25T09:52:15.326Z", "htmlBody": "<html><body><h2>Discussion article for the meetup : <a href=\"/meetups/27\">EA Brighton</a></h2>\n\t\t  <div>\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span>19 March 2015 07:30:00PM (+0000)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span>Brighton, UK</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div>\n\t\t    <div><p><a href=\"https://www.facebook.com/events/1610550695843287\">https://www.facebook.com/events/1610550695843287</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href=\"/meetups/27\">EA Brighton</a></h2></body></html>", "user": {"username": "Tom_Ash"}}, {"_id": "on34kaRXfQXMFvE6N", "title": "Six Ways To Get Along With People Who Are Totally Wrong*", "postedAt": "2015-02-24T12:41:43.096Z", "htmlBody": "<p>* The people you think are totally wrong may not actually be totally wrong.</p>\n<p><strong>Effective altruism is a \u2018broad tent\u2019</strong></p>\n<p>As is obvious to anyone who has looked around here, effective altruism is based more on a shared interest in the question 'how can you do the most good' than a shared view on the answer. We all have friends who support:</p>\n<ul>\n<li><span>A wide range of different cause areas.<br> </span></li>\n<li><span>A wide range of different approaches to those causes.<br> </span></li>\n<li><span>Different values and moral philosophies regarding what it means to 'help others'.<br> </span></li>\n<li><span>Different political views on how best to achieve even shared goals. On economic policy for example, we have people covering the full range from far left to far right. In the CEA offices we have voters for every major political party, and some smaller ones too.<br> </span></li>\n</ul>\n<p><span>Looking beyond just stated beliefs, we also have people with a wide range of temperaments, from highly argumentative, confident and outspoken to cautious, idiosyncratic and humble.</span></p>\n<p><strong>Our wide range of views could cause problems</strong></p>\n<p>There is a popular saying that 'opposites attract'. But unfortunately, social scientists have found precisely the opposite to be true: <a href=\"https://en.wikipedia.org/wiki/Homophily\"><span>birds of a feather do in fact flock together</span></a>.</p>\n<p>One of the drivers of this phenomenon is that people who are different are more likely to get into conflicts with one another. If my partner and I liked to keep the house exactly the same way, we certainly wouldn't have as many arguments about cleaning (I'll leave you to speculate about who is the untidy one!). People who are different from you may initially strike you as merely amusing, peculiar or mistaken, but when you talk to them at length and they don't see reason, you may start to see them as stupid, biased, rude, impossible to deal with, unkind, and perhaps even outright bad people.</p>\n<p>A movement brought together by a shared interest in the question <em>\u2018what should we do?\u2019</em> will inevitably have a greater diversity of priorities, and justifications for those priorities, than a movement united by a shared answer. This is in many ways our core strength. Maintaining a diversity of views means we are less likely to get permanently stuck on the wrong track, because we can learn from one another's scholarship and experiences, and correct course if necessary.</p>\n<p>However, it also means we are necessarily committed to <a href=\"https://en.wikipedia.org/wiki/Pluralism_%28political_philosophy%29\"><span>ideological pluralism</span></a>. While it is possible to maintain \u2018Big Tent\u2019 social movements they face some challenges. The more people hold opinions that others dislike, the more possible points of friction there are that can cause us to form negative opinions of one another. There have already been strongly worded exchanges online demonstrating the risk.</p>\n<p>When a minority holds an unpopular view they can feel set upon and bullied, while the majority feels mystified and frustrated that a small group of people can't see the obvious truth that so many accept.</p>\n<p>My first goal with this post is to make us aware of this phenomenon, and offer my support for a culture of peaceful coexistence between people who, even after they share all their reasons and reflect, still disagree.</p>\n<p>My second goal is to offer a few specific actions that can help us avoid interpersonal conflicts that don't contribute to making the world a better place:</p>\n<p><strong>1. Remember that you might be wrong</strong></p>\n<p>Hard as it is to keep in mind when you're talking to someone who strongly disagrees with you, it is always possible that they have good points to make that would change your mind, at least a bit. Most claims are only <a href=\"https://en.wikipedia.org/wiki/Anekantavada\"><span>\u2018partially true or false\u2019</span></a>, and there is almost always something valuable you can learn from someone who disagrees with you, even if it is just an understanding of how they think.</p>\n<p>If the other person seems generally as intelligent and informed about the topic as you, it's not even clear why you should give more weight to <a href=\"http://tar.weatherson.org/2010/04/04/what-is-the-equal-weight-view-of-disagreement/\"><span>your own opinion than theirs</span></a>.</p>\n<p><strong>2. Be polite, doubly so if your partner is not</strong></p>\n<p>Being polite will make both the person you are talking to, and onlookers, more likely to come around to your view. It also means that you're less likely to get into a fight that will hurt others and absorb your precious time and emotional energy.</p>\n<p>Politeness has many components, some notable ones being: not criticising someone personally; interpreting their behaviour and statements in a <a href=\"https://en.wikipedia.org/wiki/Principle_of_charity\"><span>fairly charitable way</span></a>; not being a show-off, or patronising and publicly embarrassing others; respecting others as your equals, even if you think they are not; conceding when they have made a good point; and finally keeping the conversation focussed on information that can be shared, confirmed, and might actually prove persuasive.</p>\n<p><strong>3. Don't infer bad motivations</strong></p>\n<p>While humans often make mistakes in their thinking, it's uncommon for them to be straight out uninterested in the welfare of others or what is right, especially so in this movement. Even if they are, they are probably not aware that that is the case. And even if they are aware, you won't come across well to onlookers by addressing them as though they have bad motivations.</p>\n<p>If you really do become convinced the person you are talking to is speaking in bad faith, it's time to walk away. As they say: don't feed the trolls.</p>\n<p><strong>4. Stay cool</strong></p>\n<p>Even when people say things that warrant anger and outrage, expressing anger or outrage publicly will rarely make the world a better place. Anger being understandable or natural is very different from it being useful, especially if the other person is likely to retaliate with anger of their own.</p>\n<p>Being angry does not improve the quality of your thinking, persuade others that you're right, make you happier or more productive, or make for a more harmonious community.</p>\n<p>In its defence, anger can be highly motivating. Unfortunately it is indiscriminate about motivating you to do very valuable, ineffective and even harmful things.</p>\n<p>Any technique that can keep you calm is therefore useful. If something is making you unavoidably angry, it's typically best to walk away and let other people deal with it.</p>\n<p><strong>5. Pick your battles</strong></p>\n<p>Not all things are equally important to reach a consensus about. For good or ill, most things we spend our days talking about just aren't that 'action relevant'. If you find yourself edging towards interpersonal conflict on a question that i) isn't going to change anyone's actions much; ii) isn't going to make the world a much better place, even if it does change their actions; or iii) is very hard to persuade others about, maybe it isn't <span>worth the cost</span> of interpersonal tension to explore in detail.</p>\n<p>So if someone in the community says something unrelated or peripheral to effective altruism that you disagree with, which could develop into a conflict, you always have the option of not taking the bait. In a week, you and they may not even remember it was mentioned, let alone consider it worth damaging your relationship over.</p>\n<p><strong>6. Let it go</strong></p>\n<p><img src=\"http://imgs.xkcd.com/comics/duty_calls.png\" alt=\"\"></p>\n<p>The most important advice of all.</p>\n<p>Perhaps you <em>are</em> discussing something important. Perhaps you've made great arguments. Perhaps everyone you know agrees with you. You've been polite, and charitable, and kept your cool. But the person you're talking to still holds a view you strongly disagree with and believe is harmful.</p>\n<p>If that's the case, it's probably time for you both to walk away before your opinions of one another fall too far, or the disagreement spirals into sectarianism. If someone can't be persuaded, you can at least avoid creating an ill-will between you that ensures they never come around. You've done what you can for now, and that is enough.</p>\n<p>Hopefully time will show which of you is right, or space away from a public debate will give one of you the chance to change your mind in private without losing face. In the meantime maybe you can't work closely together, but you can at least remain friendly and respectful.</p>\n<p>It isn't likely or even desirable for us to end up agreeing with one another on everything. The world is a horribly complex place; if the questions we are asking had easy answers the research we are doing wouldn't be necessary in the first place.</p>\n<p>The cost of being part of a community that accepts and takes an interest in your views, even though many think you are pulling in the wrong direction, is to be tolerant of others in the same way even when you think their views are harmful.</p>\n<p>So, sometimes, you just have to <a href=\"http://youtu.be/moSFlvxnbgk?t=60s\"><span>let it go</span></a>.</p>\n<p>--</p>\n<p><span><strong>PS</strong></span></p>\n<p>If you agree with me about the above, you might be tempted to post or send it to people every time they aren\u2019t playing by these rules. Unfortunately, this is likely to be counterproductive and lead to more conflict rather than less. It\u2019s useful to share this post in general, but not trot it out as a way of policing others. The most effective way to promote this style of interaction is to exemplify it in the way you treat others, and not get into long conversations with people who have less productive ways of talking to others.</p>\n<p><em>Thanks to Amanda, Will, Diana, Michelle, Catriona, Marek, Niel, Tonja, Sam and George for feedback on drafts of this post.</em></p>", "user": {"username": "Robert_Wiblin"}}, {"_id": "9qqHu6fNsRLTA3QW9", "title": "Seth Baum AMA next Tuesday on the EA Forum", "postedAt": "2015-02-23T12:37:51.817Z", "htmlBody": "<html><body><p>Just announcing for those interested that Seth Baum from the <a href=\"http://gcrinstitute.org/\">Global Catastrophic Risks Institute (GCRI)</a> will be coming to the <a href=\"/\">Effective Altruism Forum</a> to answer a wide range of questions next week at 7pm on March 3.</p>\n<p>Seth is an interesting case - more of a &apos;mere mortal&apos; than Bostrom and Yudkowsky.&#xA0;<span>(Clarification: his background is more standard, and he&apos;s probably more emulate-able!)&#xA0;</span>He had a PhD in geography, and had come to a maximising consequentialist view, in which GCR-reduction is overwhelmingly important. So three years ago,&#xA0;&#xA0;with risk analyst Tony Barrett, he cofounded the Global Catstrophic Risks Institute - one of the handful of places working on these particularly important problems. Since then, it&apos;s done some academic outreach and have covered issues like <a href=\"http://sethbaum.com/ac/2013_DoubleCatastrophe.pdf\">double-catastrophe</a>/ <a href=\"http://sethbaum.com/ac/2013_AdaptationRecovery.html\">recovery from catstrophe</a>, bioengineering, food security and AI.</p>\n<p>Just last week, they&apos;ve updated their strategy, giving the following announcement:</p>\n<p>Dear friends,</p>\n<p>I am delighted to announce important changes in GCRI&#x2019;s identity and direction. GCRI is now just over three years old. In these years we have learned a lot about how we can best contribute to the issue of global catastrophic risk. Initially, GCRI aimed to lead a large global catastrophic risk community while also performing original research. This aim is captured in GCRI&#x2019;s original mission statement, to help mobilize the world&#x2019;s intellectual and professional resources to meet humanity&#x2019;s gravest threats.</p>\n<p>Our community building has been successful, but our research has simply gone farther. Our research has been published in leading academic journals. It has taken us around the world for important talks. And it has helped us publish in the popular media. GCRI will increasingly focus on in-house research.</p>\n<p>Our research will also be increasingly focused, as will our other activities. The single most important GCR research question is: What are the best ways to reduce the risk of global catastrophe? To that end, GCRI is launching a GCR Integrated Assessment as our new flagship project. The Integrated Assessment puts all the GCRs into one integrated study in order to assess the best ways of reducing the risk. And we are changing our mission statement accordingly, to develop the best ways to confront humanity&#x2019;s gravest threats.</p>\n<p>So <strong>7pm ET </strong><strong><strong>Tuesday</strong>, March 3</strong> is the time to come online to the EA Forum and post your questions about any topic you like, and Seth will remain online until at least 9 to answer as many questions as he can.</p>\n<p>On the topic of risk organisations, I&apos;ll also mention that i) <a href=\"http://cser.org/gain-of-function-influenza-research-lecture-online/\">video is available</a> from CSER&apos;s recent seminar, in which Mark Lipsitch and Derek Smith&apos;s discussed potentially pandemic pathogens, and ii) I&apos;m helping Sean to write up a more detailed update for LessWrong and effective altruists which will go online soon.</p></body></html>", "user": {"username": "RyanCarey"}}, {"_id": "p6YgPpdhMpajBZ2Lf", "title": "Tips on talking about effective altruism", "postedAt": "2015-02-21T00:43:28.703Z", "htmlBody": "<html><body><p>I noticed that, over the past few years, I have collected a number of tips and introspective thoughts on how best to talk about effective altruism.<br><br>I have written this up and I posted the list of tips below. I hope this is helpful to someone. I have also posted a slightly longer article inclduing these tips on the EA Wiki at: <a href=\"http://effective-altruism.wikia.com/wiki/Talking_about_effective_altruism\">http://effective-altruism.wikia.com/wiki/Talking_about_effective_altruism</a>.&#xA0;</p>\n<p>There is also an EA pitch guide now on the Wiki at:&#xA0;<a href=\"http://effective-altruism.wikia.com/wiki/The_EA_Pitch_Guide\">http://effective-altruism.wikia.com/wiki/The_EA_Pitch_Guide</a>.</p>\n<p>&#x2013;-&#x2013;-&#x2013;-&#x2013;-&#x2013;-&#x2013;-&#x2013;-&#x2013;-&#x2013;-&#x2013;-&#x2013;-&#x2013;-&#x2013;-&#x2013;-&#x2013;-&#x2013;-&#x2013;-&#x2013;-&#x2013;-&#x2013;-&#x2013;-&#x2013;-&#x2013;-&#x2013;-&#x2013;-&#x2013;-&#x2013;-</p>\n<h1>Tips on talking about effective altruism</h1>\n<h2><br></h2>\n<h2>Lead by example</h2>\n<p>Actions speak louder than words. The best way of influencing those around you is when they can see that you are donating time and money to a cause you believe in passionately &#x2013; and that doing so is making the world a better place.</p>\n<p>&#xA0;</p>\n<h2>Provide a personal story</h2>\n<p>If you can tie in your own personal story of exploration of these ideas into the narrative. How did you come across EA ideas? What inspired you? What things do you do? What changed you? Etc.</p>\n<p>If you cannot provide your own story a story of a friend will work too. Eg: &#x201C;my friend K was really nervous about giving 10% but then . . .&#x201D;</p>\n<p>&#xA0;</p>\n<h2>Show people how being EA can help them achieve their own goals</h2>\n<p>For example many people want to make the world better. The EA community can help them better achieve this goal. It can also help with many other common goals: provide friends / meaning / volunteering opportunities / happiness / a sense of superiority ;-p / etc. &#xA0;</p>\n<p>&#xA0;</p>\n<h2>Do not let people be on the defensive</h2>\n<p>Agree with the person you are talking to as much as you honestly can. If they express a belief agree it is a valid belief and then work within that framework. Eg: &#x201C;yes that makes sense as a reason to prioritise our community first, but for me personally when I realise how much good even tiny amount of donations to the developing world can . . . .&#x201D;&#xA0;</p>\n<p>Do not say &#x201C;no you are wrong&#x201D; unless it is a very clear factual inaccuracy where you are sure you have strong evidence that will make them update their views. Even then try to soften it with a phrase like &#x201C;that is a common myth actually there is current consensus is . . .&#x201D;</p>\n<p>It can be useful to begin introducing EA with a really basic uncontroversial definition that no one can reasonably disagree with, something like: &quot;<em>Effective Altruism is applying evidence, reason and rationality to the goal of making the world a better place.</em>&quot;</p>\n<p>&#xA0;</p>\n<h2>Customise</h2>\n<p>How exactly we should present stuff needs to be decided on a case by case basis. Stop and think: &apos;here is a new person, how best to present EA ideas to them, what do I know about them&apos;.&#xA0;</p>\n<p>&#xA0;</p>\n<h2>Do not be moralising</h2>\n<p>Ideally try to avoid telling people that they are obliged to do any particular action. Especially try not to tell people that what they are currently doing is bad.</p>\n<p>More generally you should shy away from subjective claims where you are unsure if the other person will agree with you. Such as &#x201C;x is immoral&#x201D; or &#x201C;rap is the best music&#x201D; etc.</p>\n<p>&#xA0;</p>\n<h2>Be confident and be a good speaker</h2>\n<p>All the tips here are focused on talking about EA to people. Being a good communicator in general would also help. Perhaps go do some general research into how to be a good speaker.</p>\n<p>&#xA0;</p>\n<h2><br></h2></body></html>", "user": {"username": "weeatquince"}}, {"_id": "GYEmaX99ikgXcSbFo", "title": "Creating a local effective altruist presence - in 52 new cities so far", "postedAt": "2015-02-21T00:13:53.034Z", "htmlBody": "<html><body><p><em>Updated on March 7th to add the cities and countries listed at the bottom. Since then the total&apos;s kept climbing and the groups have kept developing - for the latest, se</em><em>e the&#xA0;<span><a href=\"http://effectivealtruismhub.com/groups\">list (and map) of EA groups</a></span>.</em></p>\n<p><span>I&apos;ve been working on creating local effective altruist presences around the world, arranging a way for people interested in EA to meet others nearby so that they can find out more about it or feel more part of a community. To this end, I&#x2019;ve talked to a great many EAs I know around the world and created local presences in </span><span>52 cities</span><span>&#xA0;without previous EA groups (or in a few cases regions, or countries with their own language).</span></p>\n<p><span>Given past experience I thought it&#x2019;d make sense to start with something modest and undemanding that can easily be kept up. So I recruited people who others nearby interested in effective altruism can get in touch with. The idea is that they can meet up over a coffee, or simply talk by email. It often takes a fair bit of in-person communication for people to resolve any initial questions and the message to click. If you might be happy to do this for your own city then I&#x2019;d love to <a href=\"mailto:tog.ash@gmail.com\">hear from you</a>.</span></p>\n<p><span>I&#x2019;ve also discussed running group meetups with them, and a few are planning this already. To start with these could be occasional social meetups - often thought of as one of the most promising kinds - held as often as local people like. In many cases we only know of a few people nearby, but the hope is that these local presences will sometimes turn up others, and they provide seeds that can grow into full-blown groups.</span></p>\n<p><span>I&#x2019;m grateful to </span><span><a href=\"http://effectivealtruismhub.com/user/samuel-hilton\">Sam Hilton</a></span><span>&#xA0;for recently convincing me - from an initial position of some scepticism! - that work on local outreach might be highly valuable. I decided that this was a good quick way to test that out. Sam put me in touch with THINK (The High Impact Network), the longstanding coordinator of new EA meetups, and they&#x2019;re kindly letting me organise this now with this project. I&#x2019;ll be updating the THINK website to feature it soon.</span></p>\n<p><span>People will be able to find these local presences on the </span><span><a href=\"http://effectivealtruismhub.com/groups\">list (and map) of EA groups</a></span><span>. Without further ado, here they are:</span></p>\n<p><a href=\"http://effectivealtruismhub.com/groups/effective-altruism-buenos-aires\t\">Buenos Aires, Argentina</a> (pre-existing presence)<br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-adelaide\t\">Adelaide, Australia</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-perth\t\">Perth, Australia</a><br> <a href=\"http://effectivealtruismhub.com/node/234\t\">Bulgaria</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-waterloo\t\">Waterloo, Canada</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-beijing\t\">Beijing, China</a> (pre-existing presence - my brother)<br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-hong-kong\t\">Hong Kong, China</a><br> <a href=\"http://effectivealtruismhub.com/groups/efektivn%C3%AD-altruist%C3%A9-brno\t\">Brno, Czech Republic</a><br> <a href=\"http://effectivealtruismhub.com/groups/efektivn%C3%AD-altruist%C3%A9-praha\t\">Prague, Czech Republic</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-paris\t\">Paris, France</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-lyon\t\">Lyon, France</a> (pre-existing presence)<br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-kiel\t\">Kiel, Germany</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-leipzig\t\">Leipzig, Germany</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-munich\t\">Munich, Germany</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-ruhrgebiet\t\">Ruhrgebiet, Germany</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-ulm\t\">Ulm, Germany</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-india\t\">India</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-israel\t\">Israel</a><br> <a href=\"http://effectivealtruismhub.com/groups/altruismo-efficace-italia\t\">Italy</a><br> <a href=\"http://effectivealtruismhub.com/groups/altruismo-eficaz-m%C3%A9xico\t\">Mexico</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-amsterdam\t\">Amsterdam, Netherlands</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-christchurch\t\">Christchurch, New Zealand</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-russia\t\">Russia</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-singapore\t\">Singapore</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-goteborg\t\">Goteborg, Sweden</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-stockholm\t\">Stockholm, Sweden</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-brighton\t\">Brighton, United Kingdom</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-hertfordshire\t\">Hertfordshire, United Kingdom</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-south-bucks\t\">South Bucks, United Kingdom</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-yorkshire\t\">Yorkshire, United Kingdom</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-albany\t\">Albany, United States</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-ann-arbor\t\">Ann Arbor, United States</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-atlanta\t\">Atlanta, United States</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-austin\t\">Austin, United States</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-san-francisco\t\">Bay Area, United States</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-brown-university\t\">Brown, United States</a><br> <a href=\"http://effectivealtruismhub.com/groups/ea-central-illinois\t\">Central Illinois, United States</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-central-massachusetts\t\">Central Massachusetts, United States</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-central-virginia\t\">Central Virginia, United States</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-columbus\t\">Columbus, United States</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-cornell\t\">Cornell, United States</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-dallas\t\">Dallas, United States</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-houston\t\">Houston, United States</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-los-angeles\t\">Los Angeles, United States</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-minneapolis\t\">Minneapolis, United States</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-northwest-arkansas\t\">Northwest Arkansas, United States</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-oberlin-college\t\">Oberlin College, United States</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-phoenix\t\">Phoenix, United States</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-portland\t\">Portland, United States</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-reno\t\">Reno, United States</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-rochester\t\">Rochester, United States</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-sacramento\t\">Sacramento, United States</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-salt-lake-city\t\">Salt Lake City, United States</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-university-idaho\t\">University of Idaho, United States</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-western-mass\t\">Western Mass, United States</a></p>\n<p><em>Additions on March 7th:</em></p>\n<p><a href=\"http://effectivealtruismhub.com/groups/effective-altruism-buenos-aires\">Buenos Aires, Argentina</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-adelaide\">Adelaide, Australia</a><br> <a href=\"http://effectivealtruismhub.com/node/234\">Bulgaria</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-hong-kong\">Hong Kong, China</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-kiel\">Kiel, Germany</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-leipzig\">Leipzig, Germany</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-russia\">Russia</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-hertfordshire\">Hertfordshire, United Kingdom</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-yorkshire\">Yorkshire, United Kingdom</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-albany\">Albany, United States</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-central-massachusetts\">Central Massachusetts, United States</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-central-virginia\">Central Virginia, United States</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-dallas\">Dallas, United States</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-portland\">Portland, United States</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-sacramento\">Sacramento, United States</a><br> <a href=\"http://effectivealtruismhub.com/groups/effective-altruism-university-idaho\">University of Idaho, United States</a></p>\n<!-- how to update: PASTE IN LOCATION (NOT CITY), COUNTRY, EAP URL SORT BY COUNTRY THEN LOC FIND & REPLACE: (.*?)\\t(.*?)\\t(.*) WITH <a href=\"\\3\" mce_href=\"/\\3\">\\1, \\2</a><br /> PASTE IN --></body></html>", "user": {"username": "Tom_Ash"}}, {"_id": "HENbwrDYnTktRtNdE", "title": "Report -- Allocating risk mitigation across time", "postedAt": "2015-02-20T16:34:47.403Z", "htmlBody": "<html><body><p>I&apos;ve just released a Future of Humanity Institute technical report, written as part of the <a href=\"http://globalprioritiesproject.org/\">Global Priorities Project</a>.</p>\n<p>Abstract:</p>\n<blockquote>\n<p>This article is about priority-setting for work aiming to reduce existential risk. Its chief claim is that all else being equal we should prefer work earlier and prefer to work on risks that might come early. This is because we are uncertain about when we will have to face different risks, because we expect diminishing returns of extra work, and because we expect that more people will work on these risks in the future.</p>\n<p>I explore this claim both qualitatively and with explicit models. I consider its implications for two questions: first, &#x201C;When is it best to do different kinds of work?&#x201D;; second, &#x201C;Which risks should we focus on?&#x201D;.</p>\n<p>As a major application, I look at the case of risk from artificial intelligence. The best strategies for reducing this risk depend on when the risk is coming. I argue that we may be underinvesting in scenarios where AI comes soon even though these scenarios are relatively unlikely, because we will not have time later to address them.</p>\n</blockquote>\n<p>&#xA0;</p>\n<p>You can read the full report here:&#xA0;<a href=\"http://www.fhi.ox.ac.uk/Allocating-risk-mitigation.pdf\">Allocating risk mitigation across time</a>.</p></body></html>", "user": {"username": "Owen_Cotton-Barratt"}}, {"_id": "pRqhzr8bZCDtNh399", "title": "Meetup : Boston dinner/discussion", "postedAt": "2015-02-20T02:47:41.839Z", "htmlBody": "<html><body><h2>Discussion article for the meetup : <a href=\"/meetups/26\">Boston dinner/discussion</a></h2>\n\t\t  <div>\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span>21 February 2015 06:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span>Medford, MA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div>\n\t\t    <div><p>Please join us for informal dinner and discussion about all things related to effective altruism!</p>\n\n<p>6 pm\nJulia and Jeff&apos;s house (email juliadwise@gmail.com for address)\nSaturday, Feb 21</p>\n\n<p>Feel free to bring friends. Just let us know if you have any dietary needs, including if you&apos;re vegetarian or vegan.</p>\n\n<p>We can provide rides to the Red Line afterwards. Street parking is sadly absent due to the snow.</p>\n\n<p>Julia and Jeff</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href=\"/meetups/26\">Boston dinner/discussion</a></h2></body></html>", "user": {"username": "Julia_Wise"}}]