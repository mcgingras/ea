[{"_id": "wP6mbwaaQQGuYwta3", "postedAt": "2023-10-31T12:45:51.588Z", "postId": "RWipfDGigeeFFZFjK", "htmlBody": "<p><strong>Executive summary</strong>: The post responds to a paper on coordinated pausing for AI labs, arguing it has limitations around feasibility of a single auditor, legal risks of pausing, and issues with voluntary and contractual approaches. It suggests key research areas like evaluations, similarity measures, legal issues, reporting schemes, registers, and governance.&nbsp;</p><p><strong>Key points</strong>:</p><ol><li>A single mutual auditor for all AI labs is unlikely; competition means multiple auditors, undermining coordination.</li><li>Auditors face legal risks trying to enforce pauses, disincentivizing this.</li><li>Voluntary and contractual pausing have loopholes around private deployments and weak incentives.</li><li>Key research areas include evaluations, model similarity measures, legal issues, incident reporting, model registers and disclosure, preventing open sourcing, and corporate governance.</li><li>The paper has good intentions but organizational incentives often override individual intentions.</li><li>Intermediate voluntary and contractual approaches are positive steps but have limitations.</li><li>Strong industry governance is needed for policies like pausing to work.&nbsp;</li></ol><p>&nbsp;</p><p><i>This comment was auto-generated by the EA Forum Team. Feel free to point out issues with this summary by replying to the comment, and</i><a href=\"https://forum.effectivealtruism.org/contact\"><i>&nbsp;<u>contact us</u></i></a><i> if you have feedback.</i></p>", "parentCommentId": null, "user": {"username": "SummaryBot"}}]