[{"_id": "vHng7pXruHFkRDff5", "postedAt": "2015-05-12T03:01:29.341Z", "postId": "4nkyFGyoayjX9T7gB", "htmlBody": "<p>Is this post missing part of it?</p>\n", "parentCommentId": null, "user": {"username": "Ervin"}}, {"_id": "6rtdKBZn2vKJMpYqJ", "postedAt": "2015-05-12T04:47:42.642Z", "postId": "4nkyFGyoayjX9T7gB", "htmlBody": "<p>Thanks for noticing, fixed! </p>\n", "parentCommentId": "vHng7pXruHFkRDff5", "user": {"username": "Diego_Caleiro"}}, {"_id": "zyRBXbjQruKkcaTwN", "postedAt": "2015-05-12T05:17:36.197Z", "postId": "4nkyFGyoayjX9T7gB", "htmlBody": "<blockquote>\n<p>The world in which Bostrom did not publish Superintelligence, and therefore Elon Musk, Bill Gates, and Paul Allen didn't turn to &quot;our side&quot; yet.</p>\n</blockquote>\n<p>Has Paul Allen come round to advocating caution and AI safety? The sources I can find right now suggest Allen is not especially worried.</p>\n<p><a href=\"http://www.technologyreview.com/view/425733/paul-allen-the-singularity-isnt-near/\">http://www.technologyreview.com/view/425733/paul-allen-the-singularity-isnt-near/</a></p>\n", "parentCommentId": null, "user": {"username": "ESRogs"}}, {"_id": "FsRftHiAaZKeKcQmq", "postedAt": "2015-05-12T05:33:47.118Z", "postId": "4nkyFGyoayjX9T7gB", "htmlBody": "<p>Confused my techno-tycoons. Wozniak in mind. Fixed. </p>\n", "parentCommentId": "zyRBXbjQruKkcaTwN", "user": {"username": "Diego_Caleiro"}}, {"_id": "9at56cMzYwsFJfhnu", "postedAt": "2015-05-12T09:17:08.807Z", "postId": "4nkyFGyoayjX9T7gB", "htmlBody": "<blockquote>\n<p>Working on self-improvement can be tremendously useful, but some people use it to enter a cocoon from which they believe they will emerge butterflies long later.</p>\n</blockquote>\n<p>In my opinion, it's best to intermix self-improvement with working on object-level goals in order to make sure you are solving the right problems.  Instead of spending all your time on self-improvement, maybe take some self-improvement time at the end of each day.</p>\n", "parentCommentId": null, "user": {"username": "John_Maxwell_IV"}}, {"_id": "CfdM4pvLGRDJyeoWr", "postedAt": "2015-05-12T09:57:10.775Z", "postId": "4nkyFGyoayjX9T7gB", "htmlBody": "<p>Thumbs up. Love the use of stories. </p>\n<p>Assumption of exponential growth, and the ability to build a movement without major landmark successes, that the quality of the sociological institutions within the movement wont matter for growth and resilience much further down the line, that it wont be incredibly valuable to have people in different places across the economy that can only be got at through dedicated time, that the kinds of projects you can do within 2 years have the same marginal return to the kinds of projects you can do within 10 years...</p>\n<p>I agree with this about attracting people to the movement as a general principle, but I'm worried that short term focus blinkers us to some fantastic opportunities - which would in turn strengthen the movement as attractors / make us more interesting to outsiders.</p>\n", "parentCommentId": null, "user": {"username": "tomstocker"}}, {"_id": "5HeW2PeqBvHDR4ffL", "postedAt": "2015-05-12T11:16:52.330Z", "postId": "4nkyFGyoayjX9T7gB", "htmlBody": "<p>A good test might be: is it easier for you to double your own effectiveness on expectation or create 1 more EA just as thoughtful as effective as yourself on expectation?  In both cases, you are increasing the total capacity of the EA movement by the same amount.  In both cases, this capacity can be reinvested in recruiting further EAs, self-improvement of individual EAs, object-level EA projects, etc.</p>\n<p>By this test, your TED talk looks very attractive compared to almost any self-improvement effort you could do, since it created hundreds or thousands of EA equivalents to you on expectation.  The equivalent achievement of improving yourself by a factor of 100 or 1000 seems quite difficult... if you are spending 1/4 of your time and energy working towards your EA goals, for instance, you can only improve by a factor of 4 at most by getting yourself to work harder.  (Working smarter is another story.  In fact, this post you wrote just now could be considered advice on how to work smarter.  In general I'm more optimistic about opportunities to work smarter than work harder, because working harder is unlikely to get you more than a 4x multiplier in most cases.)</p>\n", "parentCommentId": null, "user": {"username": "xccf"}}, {"_id": "Buee2TfzyBCAPzxYm", "postedAt": "2015-05-12T19:11:57.318Z", "postId": "4nkyFGyoayjX9T7gB", "htmlBody": "<p>Thanks Diego!</p>\n<p>Matt Wage's old post on this topic is relevant: <a href=\"https://80000hours.org/2012/04/the-haste-consideration/\">https://80000hours.org/2012/04/the-haste-consideration/</a></p>\n", "parentCommentId": null, "user": {"username": "RyanCarey"}}, {"_id": "fgQLr6o6ggbi7SEkQ", "postedAt": "2015-05-12T21:54:45.027Z", "postId": "4nkyFGyoayjX9T7gB", "htmlBody": "<p>You seem to think that resources now are several times better than resources in a few years, which are presumably several times better than resources in a few more years, and so on. Let's say you think that it's a factor of 2 improvement every 2 years (it sounds like this understates your view).</p>\n<p>If you endorsed this logic between 1954 and now, you would conclude that resources in 1954 are about a billion times more valuable than resources now, i.e. that having a few million dollars in 1954 is roughly as valuable as controlling all of the world's resources today, or that a group of a dozen people in 1954 wield more influence than the whole world does today. This is conceivable, but would be pretty surprising.</p>\n", "parentCommentId": null, "user": {"username": "Paul_Christiano"}}, {"_id": "2djrSEJPMa22GzcmW", "postedAt": "2015-05-13T01:34:37.970Z", "postId": "4nkyFGyoayjX9T7gB", "htmlBody": "<p>My claim is a little narrower than the one you correctly criticize. </p>\n<p>I believe that for movements like EA, and for some other types of crucial consideration events (atomic bombs, FAI, perhaps the end of aging) there are windows of opportunity where resources have the sort of exponential payoff decay you describe. </p>\n<p>I have high confidence that the EA window of opportunity is currently in force. So EAs <em>en tant que telle</em> are currently in this situation. \nI think it is possible that AI's window is currently open as well, I'm far less confident in that. \nWith Bostrom, I think that the &quot;strategic considerations&quot; or &quot;crucial considerations&quot; time window is currently open. \nI believe the atomic bomb time window was in full force in 1954, and highly commend the actions of Bertrand Russell in convincing Einstein to sign the anti-bomb manifesto. Just like today I commend the actions of those who caused the anti-UFAI manifesto. \nThis is one way in which what I intend to claim is narrower. </p>\n<p>The other way is that all of this rests on a conditional: assuming that EA as a movement is right. Not that it is metaphysically right, but some simpler definition, where in most ways history unfolds, people would look back and say that EA was a good idea, like we say the Russell-Einstein manifesto was a good idea today. </p>\n<p>As for reasons to believe the EA window of opportunity is currently open, I offer the stories above (TED, Superintelligence, GWWC, and others...), the small size of the movement at the moment, the unusual level of tractability that charities have acquired in the last few years due to technological ingenuity, the globalization of knowledge - which increases the scope of what you <em>can</em> do a substantial amount - the fact that we have some, but not all financial tycoons yet, etc...    </p>\n<p>As to the factor of resource value decrease, I withhold judgement, but will say the factor could go down a lot from what it currently is, and the claim would still hold (which I tried to convey by Singer's 1972 example).</p>\n", "parentCommentId": "fgQLr6o6ggbi7SEkQ", "user": {"username": "Diego_Caleiro"}}, {"_id": "wLRFxobyt7PTXPPow", "postedAt": "2015-05-13T21:13:14.730Z", "postId": "4nkyFGyoayjX9T7gB", "htmlBody": "<p>We have financial tycoons?? Then why is there still room for funding with AMF GiveDirectly SCI and DwTW?? Presumably they're just flirting with us.</p>\n", "parentCommentId": "2djrSEJPMa22GzcmW", "user": {"username": "tomstocker"}}, {"_id": "QhRWGFtuGe2xPbTy4", "postedAt": "2015-05-14T15:58:39.897Z", "postId": "4nkyFGyoayjX9T7gB", "htmlBody": "<p>Many tycoon personality types favour other charities where they're the main patron. This is pure speculation but others may want to leave room for typical individual donors, as these charities are particularly well suited to them.</p>\n", "parentCommentId": "wLRFxobyt7PTXPPow", "user": {"username": "Vincent_deB"}}, {"_id": "sYTdNorpk3uLCEyiA", "postedAt": "2015-05-14T15:59:04.778Z", "postId": "4nkyFGyoayjX9T7gB", "htmlBody": "<p>Is there a link for Wozniak?</p>\n", "parentCommentId": "FsRftHiAaZKeKcQmq", "user": {"username": "Vincent_deB"}}, {"_id": "9S5ub2odWW9xBE93h", "postedAt": "2015-05-17T08:37:52.194Z", "postId": "4nkyFGyoayjX9T7gB", "htmlBody": "<p><a href=\"http://www.washingtonpost.com/blogs/the-switch/wp/2015/03/24/apple-co-founder-on-artificial-intelligence-the-future-is-scary-and-very-bad-for-people/\">http://www.washingtonpost.com/blogs/the-switch/wp/2015/03/24/apple-co-founder-on-artificial-intelligence-the-future-is-scary-and-very-bad-for-people/</a></p>\n", "parentCommentId": "sYTdNorpk3uLCEyiA", "user": {"username": "Diego_Caleiro"}}, {"_id": "eWeZfHGgAxSTG7XS2", "postedAt": "2015-05-28T00:05:04.580Z", "postId": "4nkyFGyoayjX9T7gB", "htmlBody": "<p>Nice; thanks.</p>\n", "parentCommentId": "9S5ub2odWW9xBE93h", "user": {"username": "Vincent_deB"}}, {"_id": "v7ePJpt88vYt2v6ec", "postedAt": "2017-03-03T06:22:48.540Z", "postId": "4nkyFGyoayjX9T7gB", "htmlBody": "<p>It's been less than two years and all the gaps have either been closed, or been kept open in purpose, which Ben Hoffman has been staunchly criticising. </p>\n<p>But anyway, it has been less than 2 years and Open Phil has way more money than it knows what to do with. </p>\n<p>QED. </p>\n", "parentCommentId": "wLRFxobyt7PTXPPow", "user": {"username": "Diego_Caleiro"}}, {"_id": "SfEwChLQtnin9vbCq", "postedAt": "2018-02-05T01:49:30.295Z", "postId": "4nkyFGyoayjX9T7gB", "htmlBody": "<p>It has been about 3 years, and only very specific talent still matters for EA now. Earning to Give to institutions is gone, only giving to individuals still makes sense. </p>\n<p>It is possible that there will be full scale repleaceability of non-researchers in EA related fields by 2020. </p>\n<p>But only if, until then, we keep doing things!</p>\n", "parentCommentId": "v7ePJpt88vYt2v6ec", "user": {"username": "Diego_Caleiro"}}]