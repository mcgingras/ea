[{"_id": "cBGHWvqjfC5QASRXH", "postedAt": "2022-10-28T09:55:31.518Z", "postId": "HKdNiNNta7FxEavjm", "htmlBody": "<p>I like this sort of initiative, thanks for sharing your draft!</p><p>To encourage more reviews, you may want to briefly summarise your claims on your post, and note that:</p><blockquote><p>This document is being made public for the purposes of openness and to general comments, critique, and discussion. It is unfinished at this time. If you leave a substantive comment, have suggestions, etc, please leave your name in the comments so you can be credited with your contribution.</p><p>In order to make this fair (i.e. not \u201ccheating\u201d by eliciting comments) and to encourage others to collaborate without reservation, I am forgoing my portion of any prize money that may be received from this essay (save for a reasonable time reimbursement for working time on this). Any contributors and collaborators have a say in which charities the remaining portion of the prize money will go. The goal is simply to make the best essay possible to address these issues by encouraging many contributors, regardless of winning or losing a prize money. The important part is making change.</p></blockquote>", "parentCommentId": null, "user": {"username": "vascoamaralgrilo"}}, {"_id": "yaSoqjWBykjqYDh7z", "postedAt": "2022-10-28T14:32:23.064Z", "postId": "HKdNiNNta7FxEavjm", "htmlBody": "<p>Good idea, thanks! I'll edit it in in a moment.</p>", "parentCommentId": "cBGHWvqjfC5QASRXH", "user": {"username": "noahhaber"}}, {"_id": "tXjdPLntBfKHCubT4", "postedAt": "2022-10-29T20:09:48.545Z", "postId": "HKdNiNNta7FxEavjm", "htmlBody": "<p>Good entry. I am worried that the bite of the quantitative conclusions is coming from the normal distribution assumption - that the true cost-effectiveness of programs is normally distributed around 1. This creates an enormous mass of programs around 1 with a small difference between them, so that measurement error can have a substantial influence.</p>\n<p>However, this assumption is implausible.</p>\n<ol>\n<li>it implies that GiveDirectly is the mean of the cost-effectiveness distribution - we know GiveDirectly is one of the best giving opportunities, and only looks bad compared to the very best.</li>\n<li>Cost-effectiveness is generated by the ratio of two random variables (benefits/costs), and the ratio of random variables tends to <a href=\"https://en.wikipedia.org/wiki/Ratio_distribution\">follow a heavy-tailed distribution</a>.</li>\n</ol>\n<p>Why does this matter? Because with heavy-tailed distributions, the gap between true cost-effectiveness of Program X vs Program Y can be <em>much</em> larger than if you assume normal distribution. For example, you do the exercise of simulating 2000 programs from a normal with a mean cost-effectiveness of 1 and a SD of 1.5. Then the difference between the 95th and the 99th percentile is 3.47 vs 4.48, a difference of 1 unit. <s>However, let's say we used the same parameters for a log-normal distribution. Then the difference between the 95th and 99th percentile is 20.38 vs 46.95, which is a whopping 26 units of difference!</s> This is an unreasonable distribution, so instead let's think about a more conservative lognormal distribution that maybe fits the data better: mean = 0.01, sd = 1.5. Then the difference between the 95th and 99th percentiles is 7.5 vs 17.5, which is still an enormous 10 units of difference.</p>\n<p>In the first case, measurement error can plausibly make the worse program look like it is better. In the second case, the gap between true cost-effectiveness is so large that normally-distributed measurement error can't possibly drive those differences.</p>\n<p>So while it's conceptually true that measurement error biases us to pick uncertain interventions over certain interventions, the actual harm that could cause is probably small if true cost-effectiveness follows a heavy-tailed distribution.</p>\n<p>Edit: this point is made more formally and demonstrated in <a href=\"https://eduardomazevedo.github.io/papers/azevedo-et-al-ab.pdf\">this paper</a>.</p>\n", "parentCommentId": null, "user": {"username": "therealslimkt"}}, {"_id": "RGapMvaDgbgioHAXF", "postedAt": "2022-10-30T12:19:11.424Z", "postId": "HKdNiNNta7FxEavjm", "htmlBody": "<p>Hi Karthik, Thanks! The selection of distributions is really important here. To be clear, the demonstration section is using normal distibutions for convenience and ease of understanding.&nbsp;</p><p>The actual implemented PSA, however, has no such restriction. In the mini PSA exercise, you can see that the resulting uncertainty distributions are not distributed normally, and are fat tailed as you say. In the full PSA, if implemented, I would strongly suspect that that resulting distributions will mostly be very fat tailed, and highly skewed rightward. The decision rules I suggested specifically combat this due to the decision rules not being sensitive to how heavy the right tail is, but very sensitive to the left tail.</p><p>I will see if I can add a note to clarify this, thanks!</p>", "parentCommentId": "tXjdPLntBfKHCubT4", "user": {"username": "noahhaber"}}]