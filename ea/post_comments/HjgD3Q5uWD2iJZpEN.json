[{"_id": "NCQpcgo4vYodHGC5i", "postedAt": "2023-11-17T21:31:43.301Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>Is this AI safety related?</p>", "parentCommentId": null, "user": {"username": "stinky p"}}, {"_id": "6KYwJdg2zr5jQKfik", "postedAt": "2023-11-17T22:20:40.253Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>Very interested to find out some of the details here:</p><ul><li>Why now? &nbsp;Was there some specific act of wrongdoing that the board discovered (if so, what was it?), or was now an opportune time to make a move that the board members had secretly been considering for a while, or etc?</li><li>Was this a pro-AI-safety move that EAs should ultimately be happy about (ie, initiated by the most EA-sympathetic board members, with the intent of bringing in more x-risk-conscious leadership)? &nbsp;Or is this a disaster that will end up installing someone much more focused on making money than on talking to governments and figuring out how to align superintelligence? &nbsp;Or is it relatively neutral from an EA / x-risk perspective? &nbsp;(Update: first speculation I've seen is <a href=\"https://twitter.com/ESYudkowsky/status/1725628554099216667?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Etweet\">this cautiously optimistic tweet</a> from Eliezer Yudkowsky)</li><li>Greg Brockman, president of the board, is also stepping down. &nbsp;How might this be related, and what might this tell us about the politics of the board members and who supported/opposed this decision?</li></ul>", "parentCommentId": null, "user": {"username": "Jackson Wagner"}}, {"_id": "ocvYSKg2FjLWqjvYA", "postedAt": "2023-11-17T23:09:10.015Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>Interesting. The press release defines the board's governance mission as \"ensure that artificial general intelligence benefits all humanity,\" and then asserts that Sam hindered that mission.</p><p>I suppose one could interpret that as a shift towards greater caution and governance in the name of AI safety, or a shift towards greater speed/open-sourcing if the board views their mission through a lens of accelerationism and accessibility.&nbsp;</p><p>Or something entirely different... we're digging into talmudic nuance here, and all of these are near-wild guesses.</p><p>It could be noteworthy that they chose to highlight Mira's governance experience.&nbsp;</p><p>The latter part of the press release (not quoted above, but visible in the original <a href=\"https://openai.com/blog/openai-announces-leadership-transition#:~:text=OpenAI%E2%80%99s%20board%20of,of%20its%20Charter.\">here</a>) also points out that the majority of board members hold no OpenAI equity, which could be a nod towards this being a move that sacrifices profitability for the sake of the mission. Again though, only a guess, and even if true it would still leave open the question of how the board is interpreting the mission.</p>", "parentCommentId": null, "user": {"username": "Steve"}}, {"_id": "5YdagnBLtZPvvjder", "postedAt": "2023-11-17T23:14:47.845Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>This is mere speculation, but another group I'm on posited this might be part of it:<br><a href=\"https://www.lesswrong.com/posts/QDczBduZorG4dxZiW/sam-altman-s-sister-annie-altman-claims-sam-has-severely)\">Sam Altman's sister, Annie Altman, claims Sam has severely abused her</a></p>", "parentCommentId": null, "user": {"username": "DaveC"}}, {"_id": "fjvJDRnqZGCbxtqpF", "postedAt": "2023-11-18T00:09:29.319Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>This doesn't seem impossible given the timing, but I'd still be very surprised if this was what the board's decision was about. (I'm especially skeptical that it would be <i>exclusively</i> about this.) For one thing, the board announcement uses the wording \"hindering [the board's] ability to exercise its responsibilities.\" This doesn't seem like the wording someone would choose if their decision was prompted by investigating events that happened more than twenty years ago and which don't directly relate to beneficial use of AI or running a company. (Even in the unlikely case where the board decided to open an investigation into abuse allegations and then caught Sam Altman lying about details related to that, it's not apparent why they would describe these hypothetical lies as \"hindering [the board's] ability to exercise its responsibilities,\" as opposed to using wording that's more just about \"lost the board's trust.\") Besides, I struggle to picture board members starting an investigation solely based on one accusation from when the person in question was still a teenager. I'm not saying that these accusations are for sure unimportant \u2013 in fact, I <a href=\"https://www.lesswrong.com/posts/QDczBduZorG4dxZiW/sam-altman-s-sister-annie-altman-claims-sam-has-severely?commentId=c2Cd9Ld5jdfywyvv6\">said the opposite</a> on that LW comment thread. It's just that... Despite the good advice <a href=\"https://forum.effectivealtruism.org/posts/jLaDP2aWxdDCzwBYy/takes-from-staff-at-orgs-with-leadership-that-went-off-the\">here</a> about how boards should keep a close eye on leadership, I don't think it's a board's role or comparative advantage to focus on investigating stuff like that. Especially once they already have confirmed their standing CEO and in the absence of more direct red flags. (It would maybe be a bit different if this was a CEO selection process and Sam Altman was a new applicant that board members had only little information about.) One option I can see is that, maybe if the board already had other reasons to be concerned, then learning about the accusations could give them further fuel for investigations. Alternatively, though, it seems much more likely to me that this was about other things entirely. (Perhaps something related to publicly announcing that OpenAI \"created AGI internally\" and then backpedaling it, while also saying that short AI timelines are best for humanity even though an alignment solution is far from in sight?)</p>", "parentCommentId": "5YdagnBLtZPvvjder", "user": {"username": "Lukas_Gloor"}}, {"_id": "pyQaEhZvJChxPYTMd", "postedAt": "2023-11-18T00:34:14.540Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>Regarding the second question, I made this prediction market: <a href=\"https://manifold.markets/JonasVollmer/in-a-year-will-we-think-that-sam-al?r=Sm9uYXNWb2xsbWVy\">https://manifold.markets/JonasVollmer/in-a-year-will-we-think-that-sam-al?r=Sm9uYXNWb2xsbWVy</a></p>", "parentCommentId": "6KYwJdg2zr5jQKfik", "user": {"username": "Jonas Vollmer"}}, {"_id": "BPFrdKhD7RxHfExrH", "postedAt": "2023-11-18T00:43:47.516Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>Nice! &nbsp;I like this a lot more than the chaotic multi-choice markets trying to figure out exactly why he was fired.</p>", "parentCommentId": "pyQaEhZvJChxPYTMd", "user": {"username": "Jackson Wagner"}}, {"_id": "psAs7Qyj24xq7atZj", "postedAt": "2023-11-18T01:02:59.001Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>Side note: Greg held two roles: chair of the board, and president. It sounds like he was fired from the former and resigned from the latter role.</p>\n", "parentCommentId": "6KYwJdg2zr5jQKfik", "user": {"username": "bec_hawk"}}, {"_id": "B8ovfZ2t9nFgaGgFv", "postedAt": "2023-11-18T01:52:12.628Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>If Holden or other folks in EA blew up OpenAI, that ain't gonna be good for the movement... fr fr</p>", "parentCommentId": null, "user": {"username": "kevinj"}}, {"_id": "R6Wvrrksiw5z3xQ3J", "postedAt": "2023-11-18T02:17:33.813Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>Found this on Reddit: <a href=\"https://www.reddit.com/r/OpenAI/comments/17xoact/sam_altman_is_leaving_openai/k9p7mpv/?context=3\">Anxious_Bandicoot126 comments on Sam Altman is leaving OpenAI (reddit.com)</a></p><blockquote><p>I feel compelled as someone close to the situation to share additional context about Sam and company.</p><p>Engineers raised concerns about rushing tech to market without adequate safety reviews in the race to capitalize on ChatGPT hype. But Sam charged ahead. That's just who he is. Wouldn't listen to us.</p><p>His focus increasingly seemed to be fame and fortune, not upholding our principles as a responsible nonprofit. He made unilateral business decisions aimed at profits that diverged from our mission.</p><p>When he proposed the GPT store and revenue sharing, it crossed a line. This signaled our core values were at risk, so the board made the tough decision to remove him as CEO.</p><p>Greg also faced some accountability and stepped down from his role. He enabled much of Sam's troubling direction.</p><p>Now our former CTO, Mira Murati, is stepping in as CEO. There is hope we can return to our engineering-driven mission of developing AI safely to benefit the world, and not shareholders.</p></blockquote><p>Obviously just speculation for now, but seems <i>plausible. </i>The moment the GPT store was released I thought:</p><p><i>\"wow that's really good for business ... wow that's really bad&nbsp;for&nbsp;alignment\"</i></p>", "parentCommentId": null, "user": {"username": "Minh Nguyen"}}, {"_id": "WdkJzspNA5gsBfaNS", "postedAt": "2023-11-18T02:58:17.879Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>Apropos of nothing, I'm reminded of this <a href=\"https://www.centreforeffectivealtruism.org/blog/announcing-a-change-of-leadership-at-cea\">old update from CEA</a>.</p>", "parentCommentId": null, "user": {"username": "Linch"}}, {"_id": "9rSdaXSRXMEPK4JhT", "postedAt": "2023-11-18T03:23:36.853Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<blockquote>\n<p>publicly announcing that OpenAI \"created AGI internally\" and then backpedaling it</p>\n</blockquote>\n<p>Wasn't that just a throwaway joke on Reddit?</p>\n", "parentCommentId": "fjvJDRnqZGCbxtqpF", "user": {"username": "Yarrow Bouchard"}}, {"_id": "Z8ALewbjfpYd6CLTS", "postedAt": "2023-11-18T05:21:47.285Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>Is Helen Toner CIA or just the kind of person who talks to Stare Department employees in secure locations several times a quarter? She has a degree in CIA from CIA university and works at an institute that is have in glove with USFEDGOV.</p>\n<blockquote>\n<p>Helen Toner is Director of Strategy and Foundational Research Grants at Georgetown\u2019s Center for Security and Emerging Technology (CSET). She also serves in an uncompensated capacity on the non-profit board of directors for OpenAI. She previously worked as a Senior Research Analyst at Open Philanthropy, where she advised policymakers and grantmakers on AI policy and strategy. Between working at Open Philanthropy and joining CSET, Helen lived in Beijing, studying the Chinese AI ecosystem as a Research Affiliate of Oxford University\u2019s Center for the Governance of AI. Helen has written for Foreign Affairs and other outlets on the national security implications of AI and machine learning for China and the United States, as well as testifying before the U.S.-China Economic and Security Review Commission. Helen holds an MA in Security Studies from Georgetown, as well as a BSc in Chemical Engineering and a Diploma in Languages from the University of Melbourne.</p>\n</blockquote>\n<p><a href=\"https://cset.georgetown.edu/staff/helen-toner/\">https://cset.georgetown.edu/staff/helen-toner/</a></p>\n<blockquote>\n<p>The Center for Security and Emerging Technology (CSET) is a think tank dedicated to policy analysis at the intersection of national and international security and emerging technologies, based at Georgetown University's School of Foreign Service. CSET's founding director is the former director of the Intelligence Advanced Research Projects Activity, Jason Gaverick Matheny.[1] Its current executive director is Dewey Murdick, former Chief Analytics Officer and Deputy Chief Scientist within the Department of Homeland Security.</p>\n</blockquote>\n<p><a href=\"https://en.m.wikipedia.org/wiki/Center_for_Security_and_Emerging_Technology\">https://en.m.wikipedia.org/wiki/Center_for_Security_and_Emerging_Technology</a></p>\n", "parentCommentId": null, "user": {"username": "Barry Cotter"}}, {"_id": "PqzM4BNjFdijufsYq", "postedAt": "2023-11-18T06:06:10.623Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>\"OpenAI\u2019s ouster of CEO Sam Altman on Friday followed internal arguments among employees about whether the company was developing AI safely enough, according to people with knowledge of the situation.</p><p>Such disagreements were high on the minds of some employees during an impromptu all-hands meeting following the firing. Ilya Sutskever, a co-founder and board member at OpenAI who was responsible for limiting societal harms from its AI, took a spate of questions.</p><p>At least two employees asked Sutskever\u2014who has been responsible for OpenAI\u2019s biggest research breakthroughs\u2014whether the firing amounted to a \u201ccoup\u201d or \u201chostile takeover,\u201d according to a transcript of the meeting. To some employees, the question implied that Sutskever may have felt Altman was moving too quickly to commercialize the software\u2014which had become a billion-dollar business\u2014at the expense of potential safety concerns.\"</p><p>Kara Swisher also tweeted:</p><p>\"More scoopage: sources tell me chief scientist Ilya Sutskever was at the center of this. Increasing tensions with Sam Altman and Greg Brockman over role and influence and he got the board on his side.\"</p><p>\"The developer day and how the store was introduced was in inflection moment of Altman pushing too far, too fast. My bet: [Sam will] have a new company up by Monday.\"</p><p>Apparently Microsoft was also blindsided by this and didn't find out until moments before the announcement.</p><p>\"You can call it this way,\" Sutskever said about the coup allegation. \"And I can understand why you chose this word, but I disagree with this. This was the board doing its duty to the mission of the nonprofit, which is to make sure that OpenAl builds AGI that benefits all of humanity.\" AGI stands for artificial general intelligence, a term that refers to software that can reason the way humans do.&nbsp;<br>When Sutskever was asked whether \"these backroom removals are a good way to govern the most important company in the world?\" he answered: \"I mean, fair, I agree that there is a not ideal element to it. 100%.\"&nbsp;</p><p><a href=\"https://twitter.com/AISafetyMemes/status/1725712642117898654\">https://twitter.com/AISafetyMemes/status/1725712642117898654</a></p>", "parentCommentId": null, "user": {"username": "Burnydelic"}}, {"_id": "wQwSCrKP4AfFmMY8z", "postedAt": "2023-11-18T07:31:58.901Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>What\u2019s the lore behind that update? This was before I followed EA community stuff</p>\n", "parentCommentId": "WdkJzspNA5gsBfaNS", "user": {"username": "Simon_Grimm"}}, {"_id": "rvyYEYPKEM3MjdkSG", "postedAt": "2023-11-18T08:45:43.576Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>I'm skeptical.<br><br>I've read their other comments. The initial comment sounded somewhat plausible, but their other comments sounded less like what I'd expect someone in that position to sound like.</p>", "parentCommentId": "R6Wvrrksiw5z3xQ3J", "user": {"username": "casebash"}}, {"_id": "2cfFsqxC8jcbQubRH", "postedAt": "2023-11-18T11:18:04.899Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>I very much doubt he was fired over the allegations. However, if the allegations are true, it would raise the likelihood that he engaged in other sketchy or unethical behaviour that we don't know about.&nbsp;</p><p>\"not consistently candid\" seems to be an implication that he was deceptive to the board about <i>something</i>, at least. It could have just been about strategy, or it could have involved personal misbehaviour as well.</p>", "parentCommentId": "fjvJDRnqZGCbxtqpF", "user": {"username": "titotal"}}, {"_id": "vSqP4CTetvdaB3DjM", "postedAt": "2023-11-18T11:39:11.838Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>Yeah, now that more information has come to light, it seems to be clearly about disagreements about how to pursue the OpenAI mission. I wonder if the board can point to at least one objectively outrageous thing that Altman was deceptive about, or whether it was more subtle stuff that added up but is hard to convey to outsiders. For instance, I could imagine that they got \"empty promises\" vibes from Altman where he was placating the most safety-concerned voices at OpenAI by saying he'll take such and such precautions later in the future, but then kept doing things that are at odds with taking safety seriously, until people had enough and felt deceived and like they could no longer trust his assurances. In this scenario, it's going to be difficult for the board and for Sutskever to convey that their decision wasn't some overreaction. (FWIW, I think it can be totally justifiable to fire someone over weasel-like assurances about mission alignment that never led to any visible actions \u2013 it's just tricky that there's always some plausible deniability where the CEO can say \"I was going to take action later, like I said; it's just that you people are insufficiently pragmatic and don't have experience dealing with investors like Microsoft; and anyway, the tech isn't risky enough yet and you all are freaking out.\")</p>\n", "parentCommentId": "2cfFsqxC8jcbQubRH", "user": {"username": "Lukas_Gloor"}}, {"_id": "E46KpcNtMytDJtLub", "postedAt": "2023-11-18T14:38:41.917Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<blockquote><p>Apparently Microsoft was also blindsided by this and didn't find out until moments before the announcement.</p></blockquote><p>Not sure how important this is: Judging from the behavior of Satya Nadella during OpenAI's dev day 12 days ago, Microsoft quite likely didn't see that coming at that moment.</p>", "parentCommentId": "PqzM4BNjFdijufsYq", "user": {"username": "tseyipfai@gmail.com"}}, {"_id": "f3C8H2q7hJEE4xmZx", "postedAt": "2023-11-18T15:55:19.207Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>It would seem like a bad move to openly say the \"not consistently candid\" and \"hindering responsibilities\" thing if there was no objective deception they could point to. Even if they don't state what happened publicly, the board has to be able to defend it's actions to it's employees and to it's partners at Microsoft.&nbsp;</p><p>My impression is that this type of public admonishment is rather rare for the ousting of a CEO, and it would be more typical to talk about a \"difference of vision\" or something similarly bland. I think either they have a clear cut case against him, or the board has mishandled the situation.&nbsp;</p>", "parentCommentId": "vSqP4CTetvdaB3DjM", "user": {"username": "titotal"}}, {"_id": "uvgZZAQMNiAXm9nNA", "postedAt": "2023-11-18T17:42:02.553Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>Worth noting that of the 4 remaining board members, 2 are associated with EA: Helen Toner (CSET) and Tasha McCauley (EV UK board member)</p>\n", "parentCommentId": null, "user": {"username": "SiebeRozendal"}}, {"_id": "4eH8BoS7zGnGjr9sw", "postedAt": "2023-11-18T17:58:44.707Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>This seems <s>the most plausible</s> speculation so far, though probably also wrong: <a href=\"https://twitter.com/dzhng/status/1725637133883547705\">https://twitter.com/dzhng/status/1725637133883547705</a></p>\n", "parentCommentId": "R6Wvrrksiw5z3xQ3J", "user": {"username": "Jonas Vollmer"}}, {"_id": "2SNx66rD44gaZ9wk3", "postedAt": "2023-11-18T18:10:51.494Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>My understanding, though I'm not sure the board ever publicly confirmed this, was they decided that Larissa was acting on behalf of Leverage Research, and hence contrary to the best interests of CEA, and they wanted to stop the entryism.</p>", "parentCommentId": "wQwSCrKP4AfFmMY8z", "user": {"username": "Larks"}}, {"_id": "DhJWt4wAKpdGHNvHi", "postedAt": "2023-11-18T18:13:38.254Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>This is a critically important point to hold in mind if the reason for the move seems to be due to safety concerns as opposed to personal malpractice/deceiving the board<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefcxnmrwnc7c\"><sup><a href=\"#fncxnmrwnc7c\">[1]</a></sup></span></p><p>I don't know what the hell happened. I guess further clarifications on the decision-making process and corporate landscape will be known tomorrow or, more likely, early next working week</p><p>I've <a href=\"https://forum.effectivealtruism.org/posts/GMnbdDYoEJiXcsGpp/jws-s-shortform?commentId=LyrfLCJfG4gDCpvDm\">voiced concerns</a> before that EA is unaware that it can be drawn into 'one-way fights' sometimes, and this feels like another such moment. The Silicon Valley tech-twitter scene<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref2nh59v723qi\"><sup><a href=\"#fn2nh59v723qi\">[2]</a></sup></span>&nbsp;has exploded over this, and so far EA is not coming out well in their eyes from what I can see. I think the days of \"e/acc\" being a meme movement are rapidly drawing to a close, and EA might find itself in a hostile atmosphere in what used to be one of the most EA-friendly places in the world.</p><p>Again, early speculations, but be careful out there Bay-Area EAs. Keep your wits about you.</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fncxnmrwnc7c\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefcxnmrwnc7c\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Really strange that, while this looks like the most likely reason, it's not really reflected in the language</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn2nh59v723qi\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref2nh59v723qi\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Perhaps one of the few cases where Twitter might be an accurate representation of thoughts on the ground</p></div></li></ol>", "parentCommentId": "uvgZZAQMNiAXm9nNA", "user": {"username": "JWS"}}, {"_id": "odkDCoAbAZpqpDkLz", "postedAt": "2023-11-18T18:44:38.337Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>IIRC the official reason (or at least the thing that caused stuff to come to a head) was that Larissa and Kerry had been dating for multiple months but had never told the rest of leadership or the board about it.</p>", "parentCommentId": "2SNx66rD44gaZ9wk3", "user": {"username": "Habryka"}}, {"_id": "FK4AonAnjKy3gHDmJ", "postedAt": "2023-11-18T18:53:45.487Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>If you think it's more plausible than misalignment with OpenAI's mission, you could make some mana on&nbsp;</p><figure class=\"media\"><div data-oembed-url=\"https://manifold.markets/sophiawisdom/why-was-sam-altman-fired\">\n\t\t\t\t<div class=\"manifold-preview\">\n\t\t\t\t\t<iframe src=\"https://manifold.markets/embed/sophiawisdom/why-was-sam-altman-fired\">\n\t\t\t\t</iframe></div>\n\t\t\t</div></figure>", "parentCommentId": "4eH8BoS7zGnGjr9sw", "user": {"username": "Lorenzo Buonanno"}}, {"_id": "3eJ5Gx2raMWrTpwfe", "postedAt": "2023-11-18T18:56:12.703Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>Adam D'Angelo also worked at Facebook with Moskovitz from 2004 to 2008 (incl. as CTO 2006-2008) and is on the board of Asana</p>", "parentCommentId": "uvgZZAQMNiAXm9nNA", "user": {"username": "Lorenzo Buonanno"}}, {"_id": "uytffW3pG6Bxknj4o", "postedAt": "2023-11-18T19:50:40.202Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>Yeah, the tech scene really seems to come down on the side of Sam Altman already. Let's hope the board had good grounds and will be able to demonstrate evidence of dishonesty soon</p>\n", "parentCommentId": "DhJWt4wAKpdGHNvHi", "user": {"username": "SiebeRozendal"}}, {"_id": "hvrvuFr5X8cSonnrd", "postedAt": "2023-11-18T19:51:07.583Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>This isn't true.</p>\n<p>Larissa and I did start dating shortly before we left CEA but we were told repeatedly and in writing that this was not a factor in Larissa's departure.</p>\n<p>We believe we followed CEAs policy around co-workers dating and have never received any indication to the contrary from CEA.</p>\n", "parentCommentId": "odkDCoAbAZpqpDkLz", "user": {"username": "Kerry_Vaughan"}}, {"_id": "uSCDtZu2L27h9372c", "postedAt": "2023-11-18T19:52:20.611Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>I do enjoy the secret Leverage spy stories as it makes my life seem more exciting than it is but they don't ever make me feel very optimistic about EA epistemics.</p>\n", "parentCommentId": "2SNx66rD44gaZ9wk3", "user": {"username": "LarissaHeskethRowe"}}, {"_id": "jzv2yBj9FiY7FsinE", "postedAt": "2023-11-18T20:02:45.150Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<blockquote><p>This is a critically important point to hold in mind if the reason for the move seems to be due to safety concerns as opposed to personal malpractice/deceiving the board</p></blockquote><blockquote><p>Really strange that, while this looks like the most likely reason, it's not really reflected in the language.</p></blockquote><p>Do these explanations seem at odds to you for some reason? The language used in the statement does not say anything about <i>personal</i> malpractice/deception, just that he was \"not consistently candid in his communications with the board\". It seems entirely possible to me, and indeed probably most likely given what else we now know, that the board is alleging dishonesty re: safety-related commitments he made, or something like this.&nbsp;</p>", "parentCommentId": "DhJWt4wAKpdGHNvHi", "user": {"username": "Ben Chancey"}}, {"_id": "zWn4HevduXbgy2fLN", "postedAt": "2023-11-18T20:24:23.898Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>Thanks for the response; would you mind sharing the reason the board gave for firing you?</p>", "parentCommentId": "uSCDtZu2L27h9372c", "user": {"username": "Larks"}}, {"_id": "rANA3QDRBSmFZSjp2", "postedAt": "2023-11-18T20:55:07.291Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>Can someone who downvoted explain why they downvoted?&nbsp;</p>", "parentCommentId": "WdkJzspNA5gsBfaNS", "user": {"username": "Linch"}}, {"_id": "7r4pfJgicYWGKMqxt", "postedAt": "2023-11-18T21:11:18.658Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>did you declare to the rest of CEA that you were dating as soon as you started dating? If not, how long was the gap?</p>", "parentCommentId": "hvrvuFr5X8cSonnrd", "user": null}, {"_id": "duLGy8Mvk9rNvbuoJ", "postedAt": "2023-11-18T21:49:57.224Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>Twitter is full of people laying into EA for being behind Sam Altman's firing. However, if it's true that this happened because the board thought Altman was trying to take the company in an 'unsafe' direction then I'm glad they did this. And I'm glad that for the time being considerations other than 'shareholder value' are not the defining motivation behind AI development.</p>", "parentCommentId": null, "user": {"username": "andrewpei"}}, {"_id": "x8xDp7noZbyDGzW6t", "postedAt": "2023-11-18T23:10:09.148Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>Seemed not relevant enough to the topic, and too apt to be highly inflammatory, to be worthwhile to bring up.&nbsp;</p>", "parentCommentId": "rANA3QDRBSmFZSjp2", "user": {"username": "Gregory_Lewis"}}, {"_id": "pNy7kKJWvTqzXEx8r", "postedAt": "2023-11-19T02:19:16.688Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>I've shared very similar concerns for a while. The risk of successful <a href=\"https://forum.effectivealtruism.org/posts/uxrAdXdYpXodrggto/an-elephant-in-the-community-building-room#Narrow_EA__2_\">narrow EA</a> endeavors that lack transparency backfiring in this manner feels very predictable to me, but many seem to disagree.</p>", "parentCommentId": "DhJWt4wAKpdGHNvHi", "user": {"username": "jelle-donders"}}, {"_id": "hhHf9t2rMLyPxeNep", "postedAt": "2023-11-19T02:54:19.892Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>Yeah, this is one of the few times where I believe that the EAs on the board likely overreached here, because they probably didn't give enough evidence to justify their excoriating statement there that Sam Altman was dishonest, and he might be coming back to lead the company.</p>\n<p>I'm not sure how to react to all of this, though.</p>\n<p>Edit: My reaction is just WTF happened, and why did they completely play themselves? Though honestly, I just believe that they were inexperienced.</p>\n", "parentCommentId": "DhJWt4wAKpdGHNvHi", "user": {"username": "Sharmake"}}, {"_id": "dx4Croy6K9v7kPmpp", "postedAt": "2023-11-19T03:19:38.650Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>There's some related discussion <a href=\"https://www.lesswrong.com/posts/vFqa8DZCuhyrbSnyx/integrity-in-ai-governance-and-advocacy?commentId=BNr55p4qwF4PRri4L\">here on LW</a>.</p>", "parentCommentId": "pNy7kKJWvTqzXEx8r", "user": {"username": "Lukas_Gloor"}}, {"_id": "mFKgqeADDr6NcEpdH", "postedAt": "2023-11-19T03:19:56.272Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>This is incredibly short-sighted. The board\u2019s behavior was grossly unprofessional and the accompanying blog post was borderline defamatory. And Altman is one of the most highly-connected and competent people in the Bay Area tech scene. Altman can easily start another AI company; in fact, media outlets are now reporting that he's considering doing just that, or might even return to OpenAI by pressuring the board to resign.&nbsp;</p><p>In fact, Manifold is at <a href=\"https://manifold.markets/EliLifland/who-will-be-the-next-permanent-ceo\">50%</a> that Altman will return as CEO, and at <a href=\"https://manifold.markets/Ernie/what-will-sam-altman-be-doing-on-fe\">38%</a> that he'll start another AI company. It seems that the board was unable to think even just two steps ahead if they thought this would end well.</p>", "parentCommentId": "duLGy8Mvk9rNvbuoJ", "user": {"username": "Fermi\u2013Dirac Distribution"}}, {"_id": "XqJqqjxQTL3s7ogCD", "postedAt": "2023-11-19T04:31:35.133Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>No, Sam Altman and the members of the OpenAI board all don't work at MIRI/SIAI or FHI, so it doesn't seem to have anything to do with AI safety.</p>", "parentCommentId": "NCQpcgo4vYodHGC5i", "user": {"username": "trevorw96"}}, {"_id": "YoavxZxKTH9YitLha", "postedAt": "2023-11-19T08:51:16.375Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>I was told this dozens of times by many different employees. None of them were board members, but they all seemed to agree it was the thing that caused the conflict to escalate.</p>", "parentCommentId": "hvrvuFr5X8cSonnrd", "user": {"username": "Habryka"}}, {"_id": "oT5zaZDNdKgXbB6b5", "postedAt": "2023-11-19T10:02:41.060Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>Ironically, this particular set of comments is doing the rounds on Twitter with some banal commentary.\n<a href=\"https://twitter.com/tobi/status/1726132247227740623?t=Qu5UR4QKDz5anypwmuANwQ&amp;s=19\">https://twitter.com/tobi/status/1726132247227740623?t=Qu5UR4QKDz5anypwmuANwQ&amp;s=19</a></p>\n", "parentCommentId": "DhJWt4wAKpdGHNvHi", "user": {"username": "SiebeRozendal"}}, {"_id": "6hbSiZKY7n6Da6bpu", "postedAt": "2023-11-19T10:46:54.744Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>From <a href=\"https://www.nytimes.com/2023/11/18/technology/sam-altman-open-ai.html\">this article</a>:</p><blockquote><p>Brad Lightcap, an OpenAI executive, told employees on Saturday morning that the company had been talking with the board to \u201cbetter understand the reason and process behind their decision,\u201d according to an internal message I obtained.</p><p>\u201cWe can say definitively that the board\u2019s decision was not made in response to malfeasance or anything related to our financial, business, safety or security/privacy practices,\u201d he wrote. \u201cThis was a breakdown in communication between Sam and the board.\u201d</p></blockquote><p>If this is true, then I think the board has made a huge mess of things. They've taken a shot without any ammunition, and not realised that the other parties can shoot back. Now there are mass resignations, Microsoft is furious, seemingly all of silicon valley has turned against EA, and it's even looking likely that <a href=\"https://www.theverge.com/2023/11/18/23967199/breaking-openai-board-in-discussions-with-sam-altman-to-return-as-ceo\">Altman comes back</a>.</p><p>It seems like they didn't think they had to act like the boards of other billion dollar companies (notifying your partners of big decisions, being literal instead of euphemistic when discussing reasons for firing, selling your decisions with PR, etc). But often norms and customs happen for a reason, and corporate governance seems to be no exception.&nbsp;</p>", "parentCommentId": null, "user": {"username": "titotal"}}, {"_id": "Zc4ddo3A5LH7pcTjM", "postedAt": "2023-11-19T11:50:03.062Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>I think it's premature to judge things based on the little information that's currently available. I would be surprised if there weren't reasons for the board's unconventional choices. (I'm not ruling it out though, that what you say ends up being right)</p>\n", "parentCommentId": "6hbSiZKY7n6Da6bpu", "user": {"username": "SiebeRozendal"}}, {"_id": "cfgwGaY8xDCNr94da", "postedAt": "2023-11-19T13:04:37.151Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<blockquote><p>I'm not sure how to react to all of this, though.</p></blockquote><p>Kudos for being uncertain, given the limited information available.</p><p>(Not something one cay say about many of the other comments to this post, sadly.)</p>", "parentCommentId": "hhHf9t2rMLyPxeNep", "user": {"username": "Pablo_Stafforini"}}, {"_id": "HW8gQDkzzjNbaJxDe", "postedAt": "2023-11-19T14:29:56.441Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>Altman starting a new company could still slow things down a few months. Which could be critically important if AGI is imminent. In those few months perhaps government regulation with teeth could actually come in, and then shut the new company down before it ends the world.</p>", "parentCommentId": "mFKgqeADDr6NcEpdH", "user": {"username": "Greg_Colbourn"}}, {"_id": "m2NDzvGC65Dq3dFdg", "postedAt": "2023-11-19T16:06:02.390Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>I think the disagreement here is that we followed the CEA policy and were told explicitly and in writing at the time by the board that our dating had nothing to do with their decision. That doesn't mean staff weren't upset.</p>\n", "parentCommentId": "YoavxZxKTH9YitLha", "user": {"username": "Kerry_Vaughan"}}, {"_id": "yAgNNDXbqpiFTgjHZ", "postedAt": "2023-11-19T17:57:22.237Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>Thought this was a good article on Microsoft's power:\n<a href=\"https://archive.li/soZMQ\">https://archive.li/soZMQ</a></p>\n<blockquote>\n<p>It is unclear if OpenAI could continue as a going concern without continual cash inflows from Microsoft. While OpenAI is, according to reports, making about $80 million per month currently and may be on track to make $1 billion in revenue in 2023\u2014ten times more than it anticipated when it secured an additional $10 billion funding commitment from Microsoft in January\u2014it is not known if the company is profitable or what its burn rate it is. But it is likely to be fast. The company lost $540 million dollars in 2022 on revenue of less than $30 million for the entire year, according to documents seen by Fortune. If its costs have also ramped up in line with revenues, the company would need continual support from Microsoft just to keep operating.</p>\n</blockquote>\n<blockquote>\n<p>Furthermore, OpenAI is entirely dependent on Microsoft\u2019s cloud computing datacenters to both train and run its models. The global shortage of graphic processing units (GPUs), the specialized computer chips needed to train and run large AI models, and the size of OpenAI\u2019s business, with tens of millions of paying customers dependent on those models, mean that the San Francisco AI company cannot easily port its business to another cloud service provider.</p>\n</blockquote>\n", "parentCommentId": null, "user": {"username": "SiebeRozendal"}}, {"_id": "zXyYsjAApWLqYmzHw", "postedAt": "2023-11-19T18:26:58.068Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<blockquote><p>If this is true, then I think the board has made a huge mess of things. They've taken a shot without any ammunition, and not realised that the other parties can shoot back. Now there are mass resignations, Microsoft is furious, seemingly all of silicon valley has turned against EA, and it's even looking likely that <a href=\"https://www.theverge.com/2023/11/18/23967199/breaking-openai-board-in-discussions-with-sam-altman-to-return-as-ceo\">Altman comes back</a>.</p></blockquote><p>How much of this is \"according to anonymous sources\"?</p><p>The Board was deeply aware of intricate details of other parties's will and ability to shoot back. Probably nobody was aware of all of the details, since webs of allies are formed behind closed doors and rearrange during major conflicts, and since investors have a wide variety of retaliatory capabilities that they might not have been open about during the investment process.</p>", "parentCommentId": "6hbSiZKY7n6Da6bpu", "user": {"username": "trevorw96"}}, {"_id": "yh2C593FrgiXWuiH9", "postedAt": "2023-11-19T19:24:10.902Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>I don't know what \"nothing to do\" means. I do now believe that it had nothing legally to do with the firing, but it still seems like the thing that \"brought things to a head\".</p>\n", "parentCommentId": "m2NDzvGC65Dq3dFdg", "user": {"username": "Habryka"}}, {"_id": "TKtwaKtQWDp69Pu32", "postedAt": "2023-11-19T22:10:05.182Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>I agree. At first I thought there must be a sex scandal or embezzlement or something. But if there's no malfeasance here, the board has made a huge mess of things.</p><p>It's embarassing for the EA movement, too. It's another SBF situation. Some EAs get control over billions of dollars, and act completely irresponsibly with that power.</p>", "parentCommentId": "6hbSiZKY7n6Da6bpu", "user": {"username": "Kevin Lacker"}}, {"_id": "9BqYdTNsf4yT2pwfJ", "postedAt": "2023-11-19T23:03:57.567Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<blockquote><p>It's embarassing for the EA movement, too. It's another SBF situation. Some EAs get control over billions of dollars, and act completely irresponsibly with that power.</p></blockquote><p>Probably disagree? Hard to say for sure since we lack details, but it's not obvious to me that the board acted irresponsibly, let alone to the degree that SBF did. I guess one, it seems fairly likely that Ilya Sutskever initiated the whole thing, not the EAs on the board. And two, the board members have fiduciary duties to further the OAI nonprofit's mission, i.e., to ensure that AGI benefits all of humanity. (They do not have a duty to ensure OAI is valued at billions of dollars, except in so far as that helps further its mission.)&nbsp;</p><p>If the board members had reason to believe that Sam Altman was acting contrary to OAI's mission of ensuring that AGI benefits all humanity, perhaps moving to fire him was the responsible thing to do (even if it turns out to be bad ex post), and what has been irresponsible are the efforts of investors and others to try to reinstate him. I guess we will know better within the next weeks, but I think it's premature to say that the board acted irresponsibly right now.</p>", "parentCommentId": "TKtwaKtQWDp69Pu32", "user": {"username": "Erich_Grunewald"}}, {"_id": "3bJzfhe3WJZXwArgD", "postedAt": "2023-11-20T00:12:33.524Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>This could end up also having really bad consequences for the goals of EA, so it's perhaps similar to FTX in that way (but things are still developing and it might somehow turn out well).</p><p>Or maybe you feel like the board displayed inexperience and that they were in over their heads. I can probably get behind that based on how things look right now (but there's a chance we learn more details later that put things into a different light).</p><p>Still, I feel like inexperience is only unforgivable if it comes combined with hubris. Many commenters seem to think that there <i>must have been</i> hubris involved on the board's part. To me, that feels like it's why people seem so mad about this. \"Why else would the board have the audicity to oust such a successful and respected CEO, if they cannot point to any smoking-gun-type thing that justifies firing him to the world?\"</p><p>But notice how that attitude \u2013 being risk averse and inclined to just let the experienced tech CEO do his thing without pushback (and possibly amass leverage over the rest of the company and the board by starting or investing into compute startups or stuff like that, as some of the rumors seem to indicate) \u2013 &nbsp;is <i>also</i> dangerous and potentially \"irresponsible.\" It's not the by-default safe option, after forming concerns about his suitability, to let Sam Altman continue to cash in from the reputational benefits of running OpenAI with the seal of approval from this public good, non-profit, beneficial-mission-focused board structure that OpenAI has installed. This board structure has, from the very start, served as a kind of seal of approval that guarantees a significant amount of goodwill to people who would look at OpenAI skeptically and think \"these tech people put the world at risk to attain power/money/the top spot in history.\" EAs were arguably quite crucial (via getting Elon Musk to think about AI risk as well as some other pathways) in helping to set up OpenAI with such a board structure and the reputational protection against scrutiny from a concerned public (especially now that AI risk is gaining traction after chat-gpt spooked a bunch of people) that comes with that. So, I mainly want to point out that it's not obviously \"the responsible choice\" to <i>not</i> step in when Sam Altman would otherwise de facto keep benefitting from this board structure's seal of approval, especially if the board that was put in place no longer feels comfortable with his leadership.</p><p>To be clear, even if I'm right about the above, this isn't saying that there wouldn't have been better ways to handle this. Also, I want to flag that I don't know what the board members were actually thinking \u2013 maybe they did think of this more as coup and less as a \"if we put on our board members hats and try to serve our role as well as possible, what should we do?.\" In that case, I would disapprove. I don't know which one applies.</p>", "parentCommentId": "TKtwaKtQWDp69Pu32", "user": {"username": "Lukas_Gloor"}}, {"_id": "SdeHWHtRtBximCnDX", "postedAt": "2023-11-20T00:58:34.873Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>Here\u2019s a Bloomberg article with a few more details.</p>\n<p><a href=\"https://archive.ph/sv8SH\">https://archive.ph/sv8SH</a></p>\n", "parentCommentId": null, "user": {"username": "Ian Turner"}}, {"_id": "LcDBKfWqEK5tTsYta", "postedAt": "2023-11-20T02:01:35.214Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>The board must have thought things through in detail before pulling the trigger, so I'm still putting some credence on there being good reasons for their move and the subsequent radio silence, which might involve crucial info they have and we don't.<br><br>If not, all of this indeed seems like a very questionable move.</p>", "parentCommentId": "6hbSiZKY7n6Da6bpu", "user": {"username": "jelle-donders"}}, {"_id": "B8f8ZKtFjYXhuT6ph", "postedAt": "2023-11-20T02:32:47.504Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>inb4 OpenAI board put their whole bankroll short on Microsoft stock, will sell on Monday for XX billion and build their own chip factory. \ud83d\ude01</p>", "parentCommentId": null, "user": {"username": "J\u00e1chym Fib\u00edr"}}, {"_id": "a4D6P7AKdDwmQfEzw", "postedAt": "2023-11-20T03:48:22.267Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>Wow, that article is seriously dishonest and misleading throughout. What a mess.</p>", "parentCommentId": "SdeHWHtRtBximCnDX", "user": {"username": "Odd anon"}}, {"_id": "wb6qwrHFH5x7cLxiT", "postedAt": "2023-11-20T06:55:23.697Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>\ud83d\ude44\ud83d\ude44</p>", "parentCommentId": "oT5zaZDNdKgXbB6b5", "user": {"username": "evelynciara"}}, {"_id": "CjzCH5WkzBbLJL8sW", "postedAt": "2023-11-20T06:59:11.247Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>Latest (48 hours in): <a href=\"https://www.nytimes.com/2023/11/20/technology/openai-altman-board.html\"><strong>OpenAI Board Stands by Decision to Force Sam Altman Out of C.E.O. Role</strong></a><br><i>After 48 hours of furious negotiations, the A.I. company said Mr. Altman would not return to his job and that former Twitch C.E.O. Emmett Shear would be its interim boss.&nbsp;</i></p><blockquote><p>The board of directors at OpenAI, the high-flying artificial intelligence start-up, stood by its decision to push out its former chief executive Sam Altman, according to an internal memo sent to the company\u2019s staff on Sunday night.</p><p>OpenAI named Emmett Shear, a former executive at Twitch, as the new interim chief executive, pushing aside Mira Murati, a longtime OpenAI executive who was named interim chief executive after Mr. Altman\u2019s ouster. The board said Mr. Shear has a \u201cunique mix of skills, expertise and relationships that will drive OpenAI forward,\u201d according to the memo viewed by The New York Times.</p><p>\u201cThe board firmly stands by its decision as the only path to advance and defend the mission of OpenAI,\u201d said the memo, referring to Mr. Altman\u2019s ouster on Friday. It was signed by each of the four directors on the company\u2019s board; Adam D\u2019Angelo, Helen Toner, Ilya Sutskever, and Tasha McCauley.</p><p>\u201cPut simply, Sam\u2019s behavior and lack of transparency in his interactions with the board undermined the board\u2019s ability to effectively supervise the company in the manner it was mandated to do,\u201d the memo said.</p></blockquote>", "parentCommentId": null, "user": {"username": "Luke Freeman"}}, {"_id": "tfTvpXgoYMYhvFT3C", "postedAt": "2023-11-20T08:49:45.526Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>Oh wow, that last paragraph seems like a good sign that they have good grounds for these statements they're not walking back</p>\n", "parentCommentId": "CjzCH5WkzBbLJL8sW", "user": {"username": "SiebeRozendal"}}, {"_id": "wJWHchB4ZB9YjekiK", "postedAt": "2023-11-20T09:28:08.153Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p><s>It seems odd for them to say that given that there were relatively credible rumours that the board was negotiating with Sam about a potential return (which we can assume broke down as they looked for an alternative CEO).</s></p><p>[I've retracted the above, as it seems inaccurate with the new hiring of Shear and reports that the <a href=\"https://nitter.net/ashleevance/status/1726469283734274338#m\">board just went silent </a>in response to pressure from investors and Microsoft]</p><p>Can they not share some of the reasoning though? Like, sure, some of it may involved corporate propreitary knowledge and NDAs, but part of the reason there was such a blowback to the decision was that it seemed to come out of nowhere. <a href=\"https://nitter.net/molly0xFFF/status/1725631590288461832#m\">People assumed another shoe was going to drop</a> because of the manner of the board's decision, and then it just hasn't?</p><p>The new CEO has <a href=\"https://nitter.net/eshear/status/1726526112019382275#m\">literally just promised to</a>:</p><blockquote><p>- Hire an independent investigator to dig into the entire process leading up to this point and generate a full report.&nbsp;</p><p>- Continue to speak to as many of our employees, partners, investors, and customers as possible, take good notes, and share the key takeaways.&nbsp;</p><p>- Reform the management and leadership team in light of recent departures into an effective force to drive results for our customers.</p></blockquote><p><s>So he's accepted the position without even knowing why they did what they did at a high level. </s>[seems false, see Joshua's reply below]</p><p>While the board probably have the right to do what they did via the OpenAI Charter, the fact they are not sharing the reasons for doing so, at either a high or low level, internally or externally, means that they have lost and are continuing to lose a lot of credibility and legitimacy, regardless of the legal facts of the case.</p>", "parentCommentId": "tfTvpXgoYMYhvFT3C", "user": {"username": "JWS"}}, {"_id": "qFbYt2EXHwnGvtnvj", "postedAt": "2023-11-20T10:44:19.771Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>Why do you think that the rumors that the board was negotiating with Sam was \"relatively credible?\" At this point, seems more likely than not to be false, eg either random fake news or a PR spin by pro-Altman VCs.&nbsp;</p>", "parentCommentId": "wJWHchB4ZB9YjekiK", "user": {"username": "Linch"}}, {"_id": "k2WQzbctR9HwMFbxL", "postedAt": "2023-11-20T11:03:32.774Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>I mean I definitely agree that there's a fog-of-war situation going on. Given some new updates here, I've retracted that paragraph.</p><p>Some original points were:</p><ul><li>Things like this <a href=\"https://nitter.net/emilychangtv/status/1726337590901796927#m\">https://nitter.net/emilychangtv/status/1726337590901796927#m</a>. - yes distrust the media etc etc but it seemed the main state of play</li><li>Altman's <a href=\"https://nitter.net/sama/status/1726345564059832609#m\">photo wearing the guest pass</a> - seems like an obvious \"i'm coming back to return as a CEO or not at all implication\". Like he was obviously in the OpenAI offices for some reason, seems weird for it not to be negotiations with the board over something as opposed to collecting his belongings</li><li>Roon had a now-deleted tweet along the lines of \"crossed the rubicon troops marching on rome\" which again, implies there was an internal open-ai move to get sam back</li></ul><p>It still find the board silence is pretty weird, and the big missing piece here.</p><p>I stand by my current belief that the radio-silence is currently damaging for the perception and support of the AI Safety cause</p><p><strong>Update on point 2: </strong><a href=\"https://nitter.net/ashleevance/status/1726457222169829838#m\">https://nitter.net/ashleevance/status/1726457222169829838#m</a></p><p>It seems that the board wasn't present when he visited. I guess what seemed to be going on were two different factions: 1) Mira Murati as interim CEO was trying to find some way to get Altman and Brockman back 2) The board was trying to find its own new CEO choice asap to foreclose any chance of Sam returning to the position</p>", "parentCommentId": "qFbYt2EXHwnGvtnvj", "user": {"username": "JWS"}}, {"_id": "3dHsiMxepfmY3ykNr", "postedAt": "2023-11-20T11:28:59.196Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<blockquote>\n<p>he's accepted the position without even knowing why they did what they did at a high level</p>\n</blockquote>\n<p>I don't think this is correct, from the same statement:</p>\n<blockquote>\n<p>Before I took the job, I checked on the reasoning behind the change. The board did <em>not</em> remove Sam over any specific disagreement on safety, their reasoning was completely different from that. I'm not crazy enough to take this job without board support for commercializing our awesome models.</p>\n</blockquote>\n", "parentCommentId": "wJWHchB4ZB9YjekiK", "user": {"username": "jooke"}}, {"_id": "AuaQjSHmYBgTaSErr", "postedAt": "2023-11-20T11:47:48.174Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>I think you are over-responding when we basically have no good information, as illustrated by the fact that you keep having to walk back claims you have made only a short time before</p>", "parentCommentId": "k2WQzbctR9HwMFbxL", "user": null}, {"_id": "o2M6jj6heEbEd4v3u", "postedAt": "2023-11-20T11:49:28.355Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>What is your current view given how things have developed? Why do you keep putting forward strong views that are based on very bad information?</p>", "parentCommentId": "6hbSiZKY7n6Da6bpu", "user": null}, {"_id": "nG4LNNZ4oST3y7jR3", "postedAt": "2023-11-20T11:52:04.617Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>So did you do something wrong then, even if that wasn't why you left? How long did it take you to tell the organisation that you were dating?</p>", "parentCommentId": "m2NDzvGC65Dq3dFdg", "user": null}, {"_id": "D2rATXLxbMZEN3f2p", "postedAt": "2023-11-20T11:57:52.354Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>Thanks for this, have retracted that sentence.</p><p>Feels like some version of the reasoning should be made available to investors/microsoft/the public is some short-term timeframe though? I feel like that would do a fair amount to quell some of the reactions</p>", "parentCommentId": "3dHsiMxepfmY3ykNr", "user": {"username": "JWS"}}, {"_id": "jMk9CnEETDq5PyJ5q", "postedAt": "2023-11-20T12:15:09.414Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>I take your point here John. There's a lot that's still to come out about the events of the weekend, and I've probably been a bit trigger-happy with responses. I'm going to step back from this thread and possibly the Forum as a whole for a little bit.</p><p>I do want to note that I picked up a somewhat hostile/adversarial tone to your comment (I'm not saying this was intentional). To 'keep having to walk back claims' seems a bit of an implied overclaim to me, especially as from my PoV it only happened twice - once seeing Ashlee Vance's updated reporting, and the other with Joshua's comment.</p><p>'Walking back' seems to also be more adversarial than just 'corrected mistakes' too (compare 'you keep having to walk back claims' vs 'you made corrections twice'. In any case, while the reporting has changed, a lot of my intuitions and feelings haven't shifted much. I still find the board's complete silence strange, and think this could be a precarious moment for AI Safety.</p>", "parentCommentId": "AuaQjSHmYBgTaSErr", "user": {"username": "JWS"}}, {"_id": "zdzmGSz5DPgbqTfmu", "postedAt": "2023-11-20T12:52:57.698Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>I would like that, however, how much they care about external reactions is unclear to me</p>\n", "parentCommentId": "D2rATXLxbMZEN3f2p", "user": {"username": "jooke"}}, {"_id": "CJHKC9myxMuE4dudA", "postedAt": "2023-11-20T14:31:33.930Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p><a href=\"https://twitter.com/karaswisher/status/1726599700961521762/photo/1\">An open letter from 500 of ~700 OpenAI employees to the board, calling on them to resign</a> (also on <a href=\"https://www.theverge.com/2023/11/20/23968988/openai-employees-resignation-letter-microsoft-sam-altman\">The Verge</a>).</p><p>Suggests there's an enormous amount of bad feeling about the decision internally. It also seems like a bad sign that the board was unwilling to provide any 'written evidence' of wrongdoing, though maybe something will appear in the coming days.</p><p>But all told it looks pretty bad for EA. Seems like there's an enormous backlash online - initially against OpenAI for firing everyone\u2019s favourite AI CEO, and now against \u201cEA\u201d \u201cwoke\u201d \u201cdecelerationist\u201d types.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref6e7extp9qgr\"><sup><a href=\"#fn6e7extp9qgr\">[1]</a></sup></span><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefx0g1kmpyh8\"><sup><a href=\"#fnx0g1kmpyh8\">[2]</a></sup></span></p><p>It\u2019s also seemed to trigger a <a href=\"https://x.com/nickcammarata/status/1725933595318268223?s=46\">flurry of tweets from Nick Cammarata</a>, saying that EAs are overwhelmingly self-flagellating and self-destructive and that EA caused him and his friends enormous harm. I think his claims are flatly wrong (though they may be true for him and his friends), and some of the replies seem to agree, but it has 500K views as I publish.</p><p>Seems like the whole episode (combined with at least one prominent EA seemingly saying it\u2019s emblematic dreadful and toxic) has the potential to cause a lot of reputational damage, especially if the board chooses not to clarify its actions (although it's possibly too late for that).</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn6e7extp9qgr\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref6e7extp9qgr\">^</a></strong></sup></span><div class=\"footnote-content\"><p>https://x.com/brian_armstrong/status/1725924114190536825?s=46</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnx0g1kmpyh8\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefx0g1kmpyh8\">^</a></strong></sup></span><div class=\"footnote-content\"><p>https://x.com/atroyn/status/1725937945444757720?s=46</p></div></li></ol>", "parentCommentId": null, "user": {"username": "HenryStanley"}}, {"_id": "KvB4GXTLZFJgEgQoh", "postedAt": "2023-11-20T14:43:55.312Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>We are at a critical time as we stand; either we have the Board yielding to the plea/threat of the worker or we have inexperienced actors being at the helm of the driving force in AI. What do you think organizations like EA can do in this regard, should we just sit and watch or should we regard the threat as non-existent because to me, having this sort of people managing the AI space is a ticking time bomb</p>", "parentCommentId": null, "user": {"username": "Adebayo Mubarak"}}, {"_id": "dSk6raZPPXwWstCDG", "postedAt": "2023-11-20T14:47:18.256Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>I make this speculative comment with no inside information</p>\n<p>There may be a world in which this is net positive. If EAs have been wrong the whole time about the best approach being the \"narrow\" or \"inside\" game, this might force EAs into being mostly adversarial vs. Tech accelerationists and many in silicon valley in general. This could be more effective at stopping or slowing doom in the medium to long term than trying to force safety from the inside against strong market forces.</p>\n<p>It could even help the EA AI risk crowd come more alongside the sentiment of the general public, after the initial reputational loss simmers down.</p>\n<p>I'm not saying this is even likely, it's just a different take.</p>\n", "parentCommentId": null, "user": {"username": "NickLaing"}}, {"_id": "bCQwqQydDf53THG38", "postedAt": "2023-11-20T15:54:54.744Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>No, we didn't do anything wrong. Like I said, we followed the policy.</p>\n<p>People were upset that we were dating but not because there was some coverup or anything. Some folks had strategic disagreements with me and us dating made that a larger problem.</p>\n", "parentCommentId": "nG4LNNZ4oST3y7jR3", "user": {"username": "Kerry_Vaughan"}}, {"_id": "kytRtTJBZDAt7KKAz", "postedAt": "2023-11-20T16:31:10.278Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>It seems like the board did not fire Sam Altman for safety reasons, but instead for other reasons instead. Utterly confusing, and IMO demolishes my previous theory, though a lot of other theories also lost out.</p>\n<p>Sources below, with their archive versions included:</p>\n<p><a href=\"https://twitter.com/norabelrose/status/1726635769958478244\">https://twitter.com/norabelrose/status/1726635769958478244</a></p>\n<p><a href=\"https://twitter.com/eshear/status/1726526112019382275\">https://twitter.com/eshear/status/1726526112019382275</a></p>\n<p><a href=\"https://archive.is/dXRgA\">https://archive.is/dXRgA</a></p>\n<p><a href=\"https://archive.is/FhHUv\">https://archive.is/FhHUv</a></p>\n", "parentCommentId": null, "user": {"username": "Sharmake"}}, {"_id": "xvKdBJaQBQHW2vHqx", "postedAt": "2023-11-20T18:58:26.597Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>How on earth does one reconcile this with the fact that Ilya has now publicly tweeted that he deeply regrets his involvement in the board\u2019s actions, <em>and</em> that he has signed the open letter threatening to quit unless the board resigns?</p>\n", "parentCommentId": "CjzCH5WkzBbLJL8sW", "user": {"username": "Ben Chancey"}}, {"_id": "64KrBJXCJuSsxAJzf", "postedAt": "2023-11-20T19:28:45.074Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>how long did it take you to tell the organisation that you were dating?</p>", "parentCommentId": "bCQwqQydDf53THG38", "user": null}, {"_id": "gmZBKdcdtXAsxnNDu", "postedAt": "2023-11-20T21:16:55.516Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>It was a short timeline. I don't remember exactly but we told senior leadership and the board quite soon after we decided to start dating.</p>\n", "parentCommentId": "64KrBJXCJuSsxAJzf", "user": {"username": "Kerry_Vaughan"}}, {"_id": "bhJ7bBg4JftfKAimp", "postedAt": "2023-11-20T21:21:10.382Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>Less than a month?</p>", "parentCommentId": "gmZBKdcdtXAsxnNDu", "user": null}, {"_id": "hoiuT8FReZzY4WodM", "postedAt": "2023-11-20T21:31:58.916Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>It is a disaster for EA. We need the EAs on the board to explain themselves, and if they made a mistake, just admit that they made a mistake and step down.</p><p>\"Effective altruism\" depends on being effective. If EA is just putting people in charge of other peoples' money, they make decisions that seem like bad decisions, they never explain why, refuse to change their mind whatever happens... that's no better than existing charities! This is what EA was supposed to prevent! We are supposed to be <i>effective</i>. Not to fire the best employees and destroy a company that is putting an incredible amount of effort into doing responsible things.</p><p>I might as well give my money to the San Francisco Symphony. At least they won't spend it ruining things that I care about.</p><p>Please, anyone who knows Helen or Tasha, ask them to reconsider.</p>", "parentCommentId": "CJHKC9myxMuE4dudA", "user": {"username": "Kevin Lacker"}}, {"_id": "hjPDC82iJs3NLHWvc", "postedAt": "2023-11-20T21:34:40.617Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>Yes</p>\n", "parentCommentId": "bhJ7bBg4JftfKAimp", "user": {"username": "Kerry_Vaughan"}}, {"_id": "AzychgAu8cFCDBWor", "postedAt": "2023-11-21T10:04:24.458Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>If you both leaving was performance-related, it's sort of weird for you both to leave at the same time. Was both of you leaving performance-related? Or did you both leave the same time because you were dating? Can you say more about why you both left at the same time?</p>", "parentCommentId": "hjPDC82iJs3NLHWvc", "user": null}, {"_id": "iWuyc6PporN7Hox2g", "postedAt": "2023-11-21T10:09:21.519Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>Regarding epistemics, is Leverage still operating according to <a href=\"https://docs.google.com/file/d/0BxADVDGSaIVZNnppbG45NDIyU2M/edit?resourcekey=0-hO82wwC14XqU9zCLiVVJIw\">this plan</a>, with samples below:</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/iWuyc6PporN7Hox2g/mtfu8ln1lvovj6pusfvd\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/iWuyc6PporN7Hox2g/a7mu70ngdms8kefus1pf 154w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/iWuyc6PporN7Hox2g/swejucevg9slp17xgt0c 234w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/iWuyc6PporN7Hox2g/jidcrgh00kv49nkfye2s 314w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/iWuyc6PporN7Hox2g/lbisnr0re0adjoxgrcua 394w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/iWuyc6PporN7Hox2g/bwziltjhuklubrfmhbfq 474w\"></figure><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/iWuyc6PporN7Hox2g/spvf0nans4dpdyhcispo\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/iWuyc6PporN7Hox2g/gdvxilms2mfhylrogl6e 210w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/iWuyc6PporN7Hox2g/mw8vbq4gl85odaxmztcv 420w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/iWuyc6PporN7Hox2g/grltv0fu3vmrhh1a4y4k 630w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/iWuyc6PporN7Hox2g/m1s9ifquak0ovuen68wr 840w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/iWuyc6PporN7Hox2g/c0yoya1ko2dgil7igqw1 1050w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/iWuyc6PporN7Hox2g/kqa57ghads7dsjk5yfuj 1260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/iWuyc6PporN7Hox2g/umam8iewdvuloijii5nz 1470w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/iWuyc6PporN7Hox2g/fwaunr6hsnbv62jtdm4q 1680w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/iWuyc6PporN7Hox2g/aodub535nv0a8dvif8ru 1890w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/iWuyc6PporN7Hox2g/y7j52khczcrupplttn9r 2036w\"></figure>", "parentCommentId": "uSCDtZu2L27h9372c", "user": null}, {"_id": "aeWnq5NqNGnkCKwuY", "postedAt": "2023-11-21T10:27:28.497Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>I don\u2019t know that this requires further scrutiny - not wanting to continue working at an organisation that fired your girlfriend seems like the default response.</p>\n", "parentCommentId": "AzychgAu8cFCDBWor", "user": {"username": "bec_hawk"}}, {"_id": "44JdBybjpX9hHqRHm", "postedAt": "2023-11-21T11:25:28.916Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>I don't think that they own the EA community an explanation (it would be nice, but they don't have to). The only people that can have a right to <i>demand</i> that are the people that have appointed them there and the OAI staff.<br><br><a href=\"https://forum.effectivealtruism.org/posts/zuqpqqFoue5LyutTv/the-ea-community-does-not-own-its-donors-money\">https://forum.effectivealtruism.org/posts/zuqpqqFoue5LyutTv/the-ea-community-does-not-own-its-donors-money</a><br><br>&gt;I might as well give my money to the San Francisco Symphony. At least they won't spend it ruining things that I care about.<br><br>It is your right, but I don't know how this is related? How have they spent EA donors' money? If you are referring to the Open Phil $30M grant, Open Phil doesn't take donations so they can donate to whoever they want and don't need to explain themselves. It would have been different if Open AI was spending GiveWell's money.<br>&nbsp;</p>", "parentCommentId": "hoiuT8FReZzY4WodM", "user": {"username": "m(E)t(A)"}}, {"_id": "2em9ArLguPJkn4co8", "postedAt": "2023-11-21T11:34:31.340Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>Uggh I'm sorry. I didn't mean to bring up conversations about current Leverage in this thread, as it's very off-topic. I just thought it'd be instructive to include a link for the only other time I remember in recent memory about a board very clearly firing a CEO, when the much more normal thing to do in that context is pretend the CEO resigned, or leaving it ambiguous.<br><br>I thought there were interesting parallels, that's all. Didn't mean to draw so much heat.</p>", "parentCommentId": "iWuyc6PporN7Hox2g", "user": {"username": "Linch"}}, {"_id": "cnadrieH4c2ygxDS2", "postedAt": "2023-11-21T11:58:55.749Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>Just saw this on hacker news as a response to <a href=\"https://www.bloomberg.com/opinion/articles/2023-11-20/openai-sam-altman-exposes-the-charade-of-ai-accountability\">Sam Altman Exposes the Charade of AI Accountability</a>. The damage for EA's reputation is hard to estimate but perhaps real.</p>\n<blockquote>\n<p>I think people have yet to realize that this whole AI Safety thing is complete BS. It's just another veil, like Effective Altruism, to get good PR and build a career around. The only people who truly believe this AI safety stuff are those with no technical knowledge or expertise.</p>\n</blockquote>\n", "parentCommentId": null, "user": {"username": "newptcai"}}, {"_id": "HPxwH7GYzCJjMv7bG", "postedAt": "2023-11-22T19:53:39.848Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>FYI \u2014 lots of relevant links collected here: <a href=\"https://www.lesswrong.com/posts/sGpBPAPq2QttY4M2H/openai-the-battle-of-the-board\">OpenAI: The Battle of the Board</a> &nbsp;and <a href=\"https://www.lesswrong.com/posts/KXHMCH7wCxrvKsJyn/openai-facts-from-a-weekend\">OpenAI: Facts from a Weekend</a>&nbsp;</p>", "parentCommentId": null, "user": {"username": "Lizka"}}, {"_id": "cjjskKKN5YeLxJYxK", "postedAt": "2023-11-24T13:27:39.653Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<blockquote><p>The board\u2019s behavior was grossly unprofessional</p></blockquote><p>You had no evidence to justify that claim back when you made it, and as new evidence is released, it looks increasingly likely that the claim was not only unjustified but also wrong (see e.g. <a href=\"https://www.lesswrong.com/posts/KXHMCH7wCxrvKsJyn/openai-facts-from-a-weekend?commentId=E7rEuPdmsSKSYWnPz\">this comment by Gwern</a>).</p>", "parentCommentId": "mFKgqeADDr6NcEpdH", "user": {"username": "Pablo_Stafforini"}}, {"_id": "m457vF3k5kRAXcC94", "postedAt": "2023-11-24T15:47:46.033Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": "<p>Not too long an unemployment period of 5 days, but on the other hand, not a bad endorsement.</p><p>The reinstatement of Altman as head of OpenAI took place under truly revolutionary circumstances. Reportedly, 650 employees threatened to leave immediately and investors threatened legal action against the ChatGPT creator. Unsurprisingly, <a href=\"https://www.webhosting1st.com/\">Microsoft</a>, the largest investor, owning 49% of the shares and pumping huge amounts of money into the company, had the most at stake. It was the tech giant that first expressed great dissatisfaction with Altman's dismissal and even offered him the creation of an AI division within Microsoft, should OpenAI's board of directors nonetheless relent.</p>", "parentCommentId": null, "user": {"username": "KaliCorte"}}, {"_id": "4qHh6ZNXWmag8EhGD", "postedAt": "2023-11-18T03:59:55.391Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": null, "parentCommentId": null, "user": null}, {"_id": "uviPsKCY8ZkowmbJA", "postedAt": "2023-11-18T07:30:52.182Z", "postId": "HjgD3Q5uWD2iJZpEN", "htmlBody": null, "parentCommentId": "WdkJzspNA5gsBfaNS", "user": null}]