[{"_id": "AX6FjsWpSDoinsHwo", "postedAt": "2018-02-15T23:12:16.231Z", "postId": "X2n6pt3uzZtxGT9Lm", "htmlBody": "<p>I would add something likes &quot;Sensitivity&quot; to the list of attributes needed to navigate the world.</p>\n<p>This is different from Predictive Power. You can imagine two ships, with the exact same compute power and Predictive Power. One with cameras on the outside and long range sensors, one blind without. You'd expect the first to do a lot better moving about the world</p>\n<p>In Effective Altruism's case I suspect this would be things like the basic empirical research about the state of the world and the things important to their goals. </p>\n", "parentCommentId": null, "user": {"username": "WillPearson"}}, {"_id": "cgNMW6QBGBKfWmpRk", "postedAt": "2018-02-19T14:38:28.378Z", "postId": "X2n6pt3uzZtxGT9Lm", "htmlBody": "<p>I like this post Milan, I think it's the best of your series. I think that you rightly picked a very important topic to write about (cluelessness) that should receive more attention than it currently does. I do have some comments:</p>\n<p>Although I admire new ways to think about prioritisation, I have two worries: \n<em>Conceptual distinction.</em> Wisdom and predictive power seem not conceptually distinct. Both are about our ability to identifying and predicting the probability of good and bad outcomes. Intent also seems a little tangled up in wisdom, although I can see that we want to seperate those. Furthermore, intent influences coordination capability: the more different the intentions are of a population, the more difficult coordination becomes.</p>\n<p>This creates the second worry that this model adds only one dimension (Intent) to the 3-dimensional model of Bostrom's Technology [Capacity] - Insight [Wisdom] - Coordination. Do you think this increases to usefulness of the model enough? The advantage of Bostrom's model is that it allows for differential progress (wisdom &gt; coordination &gt; capacity), while you don't specify the interplay of attributes. Are they supposed to be multiplied, or are some combinations better than others, or do we want differential progress?</p>\n<p>I was a bit confused that you write about things to prioritise, but don't refer back to the 5 attributes of the steering capacity. Some relate more strongly to specific attributes, and some attributes are not discussed much (coordination) or at all (capability).</p>\n<blockquote>\n<p>Further our understanding of what matters</p>\n</blockquote>\n<p>This seems to be Intent in your framework. I totally agree that this is valuable. I would call this moral (or more precisely: axiological) uncertainty, and people work on this outside of EA as well. By the way, besides resolving uncertainty, another pathway is to improve our methods to deal with moral uncertainty. (<a href=\"https://80000hours.org/2018/01/will-macaskill-moral-philosophy/\">Like MacAskill argues for</a>)</p>\n<blockquote>\n<p>Improve governance</p>\n</blockquote>\n<p>I am not sure to which this concept this relates to, though I suppose it is Coordination. I find the discussion a bit shallow here as it discusses only institutions, and not the coordination of individuals in e.g. the EA community, or the coordination between nation states.</p>\n<blockquote>\n<p>Improve prediction-making &amp; foresight</p>\n</blockquote>\n<p>This seems to be the attribute predictive power. I agree with you that this is very important. To a large extent, this is also what science in general is aiming to do: improving our understanding so that we can better predict and alter the future. However, straight up forecasting seems more neglected. I think this could also just be called &quot;reducing empirical uncertainty&quot;? If we call it that, we can also consider other approaches, such as researching effects in complex systems.</p>\n<blockquote>\n<p>Reduce existential risk</p>\n</blockquote>\n<p>I'm not sure this was intended to relate to a specific attribute. Guess not.</p>\n<blockquote>\n<p>Increase the number of well-intentioned, highly capable people</p>\n</blockquote>\n<p>This seems to relate mostly to &quot;Intent&quot;as well. I wanted to remark that this can either be done by increasing capability and knowledge of well-intentioned people, or by improving intentions of capable (and knowledgeable) people. My observation is that so far, the focus has been on the latter in term of growth and outreach, and only some effort has been expended to develop the skills of effective altruists. (<a href=\"https://app.effectivealtruism.org/groups/resources/effective-altruism-community-building\">Although this is noted as a comparative advantage for EA Groups</a>)</p>\n<p>Lastly, I wanted to remark that hits-based giving does not imply a portfolio approach in my opinion. It just implies being more or less risk-neutral in altruistic efforts. What drives the diversification in OPP's grants seems to be <a href=\"https://www.openphilanthropy.org/blog/worldview-diversification\">worldview diversification</a>, option value, and the possibility that high-value opportunities are spread over cause areas, rather than concentrated in one cause area. I think what would support the conclusion that we need to diversify could be that we need to hit a certain value on each of the attributes otherwise the project fails (a bit like that power-laws arise from success needing A<em>B</em>C instead of A+B+C).</p>\n<p>All in all, an important project, but I'm not sure how much novel insight it has brought (yet). This is quite similar to my own experience in that I wrote a philosophy essay about cluelessness and arrived at not-so-novel conclusion. Let me know if you'd like to read the essay :)</p>\n", "parentCommentId": null, "user": {"username": "SiebeRozendal"}}, {"_id": "ZMFuKmQfhTuT6gei5", "postedAt": "2018-02-19T16:46:33.184Z", "postId": "X2n6pt3uzZtxGT9Lm", "htmlBody": "<blockquote>\n<p>Wisdom and predictive power seem not conceptually distinct.</p>\n</blockquote>\n<p>I'm using &quot;predictive power&quot; as something like &quot;ability to see what's coming down the pipe&quot; and &quot;wisdom&quot; as something like &quot;ability to assess whether what's coming down the pipe is good or bad, according to one's value system.&quot;</p>\n<p>On your broader point, I agree that these attributes are all tangled up in each other. I don't think there's a useful way to draw clean distinctions here.</p>\n<blockquote>\n<p>I was a bit confused that you write about things to prioritise, but don't refer back to the 5 attributes of the steering capacity.</p>\n</blockquote>\n<p>This is a good point, I'll think about this more &amp; get back to you.</p>\n<blockquote>\n<p>quite similar to my own experience in that I wrote a philosophy essay about cluelessness</p>\n</blockquote>\n<p>I'd like to read this. Could you link to it here, or (if private) send it to the email address on this page? <a href=\"https://flightfromperfection.com/pages/about.html\">https://flightfromperfection.com/pages/about.html</a></p>\n", "parentCommentId": "cgNMW6QBGBKfWmpRk", "user": {"username": "Milan_Griffes"}}, {"_id": "FMzdB34YThcwbonY2", "postedAt": "2018-02-20T10:32:37.705Z", "postId": "X2n6pt3uzZtxGT9Lm", "htmlBody": "<p>Sure! <a href=\"http://www.sieberozendal.com/wp-content/uploads/2018/02/The-Problem-of-Complex-Cluelessness-Siebe-Rozendal.pdf\">Here it is</a>.</p>\n", "parentCommentId": "ZMFuKmQfhTuT6gei5", "user": {"username": "SiebeRozendal"}}, {"_id": "Pt3hPS4TfigxYur48", "postedAt": "2019-03-12T16:58:00.676Z", "postId": "X2n6pt3uzZtxGT9Lm", "htmlBody": "<p><a href=\"https://www.metaculus.com/questions/\">Metaculus</a> is an EA project worth a mention in the &quot;improving foresight&quot; area.  I&#x27;m also excited by what the Less Wrong 2 team is doing.  And <a href=\"https://www.clearerthinking.org/\">Clearer Thinking</a> is cool.</p><p>I think steering capacity is valuable, but there has to be a balance between building steering capacity and taking object-level action.  In many cases, object-level actions are likely to be time-sensitive.  Delaying object-level action <a href=\"https://forum.effectivealtruism.org/posts/Q8isNAMsFxny5N37Y/how-tractable-is-cluelessness#XEPfTfWi8P3eaRfEm\">only makes sense</a> insofar as we can usefully resolve our cluelessness.  (But as you say, we tend to become less cluelessness about things as they move from the far future to the near future.  So object-level actions which destroy option value can be bad.)</p><p>Remember also that acting in the world is sometimes the best way to gather information (which can help resolve cluelessness).</p>", "parentCommentId": null, "user": {"username": "John_Maxwell_IV"}}, {"_id": "XRm4ziMwLZ2AAGiCt", "postedAt": "2019-06-02T22:53:07.307Z", "postId": "X2n6pt3uzZtxGT9Lm", "htmlBody": "<blockquote>Therefore, we ought to prioritize interventions that improve the wisdom, capability, and coordination of future actors.</blockquote><p>If we operate under the &quot;ethical precautionary principle&quot; you laid out in the previous post (always behave as if there was another crucial consideration yet to discover), how do we do this? We might think that some intervention will increase the wisdom of future actors, based on our best analysis of the situation. But we fear a lurking crucial consideration that will someday pounce and reveal that actually the intervention did nothing, or did the opposite.</p><p>In other words, don&#x27;t we need to be *somewhat* clueful already in order to bootstrap our way into more cluefulness?</p>", "parentCommentId": null, "user": {"username": "reallyeli"}}, {"_id": "RpF3BmdRKsqLczusg", "postedAt": "2021-12-03T05:48:16.946Z", "postId": "X2n6pt3uzZtxGT9Lm", "htmlBody": "<p>This post helped clarify to me which causes ought to be prioritized from a longtermist standpoint. Although we don't know the long-term consequences of our actions (and hence are <i>clueless</i>), we can take steps to reduce our uncertainties and reliably do good over the long term. These include:</p><ul><li><a href=\"https://forum.effectivealtruism.org/tag/global-priorities-research\">Global priorities research</a> - to improve our understanding of what's morally important and of the risks and opportunities facing humanity.</li><li>Improving <a href=\"https://forum.effectivealtruism.org/tag/institutional-decision-making\">institutional decision-making</a> at the <a href=\"https://forum.effectivealtruism.org/tag/global-governance\">global level</a> - to improve humanity's \"ability to mediate diverse preferences, decide on collectively held goals, and work together towards those goals.\"</li><li>Improving <a href=\"https://forum.effectivealtruism.org/tag/forecasting\">foresight</a> - \"The further we can see [into the future], the more information we can incorporate into our decision-making, which in turn leads to higher quality outcomes with fewer surprises.\"</li><li>Reducing <a href=\"https://forum.effectivealtruism.org/tag/existential-risk\">existential risks</a> - \"Avoiding extinction and \u201clock-in\u201d of suboptimal states is necessary for realizing the full potential benefit of the future.\"</li><li>\"Increasing the number of well-intentioned, highly capable people,\" including through <a href=\"https://forum.effectivealtruism.org/tag/building-effective-altruism-1\">building effective altruism</a> and training people to <a href=\"https://forum.effectivealtruism.org/tag/rationality\">think more clearly</a>.</li></ul><p>Although we don't necessarily know where humanity will end up in the very long term, these interventions help us increase our steering capacity - humanity's ability to navigate risks and opportunities along the way.</p><p>I recommend this post to anyone interested in longtermism, as it's one of the few systematic attempts at longtermist cause prioritization that I've seen. There are things I'd add: Perhaps <a href=\"https://forum.effectivealtruism.org/tag/economic-growth\">economic growth</a> would augment humanity's steering capacity by increasing the amount of resources available to us to avoid risks and pursue opportunities (see also \"<a href=\"https://forum.effectivealtruism.org/posts/xh37hSqw287ufDbQ7/existential-risk-and-economic-growth-1\">Existential Risk and Growth</a>\"). And perhaps promoting effective altruism to a <a href=\"https://forum.effectivealtruism.org/tag/diversity-and-inclusion\">culturally and intellectually diverse</a> audience would help us make more robust decisions through exposure to more ideas on what matters and how to do good.</p><p>I'm heartened to have seen progress in the areas identified in this post. For example, the <a href=\"https://forum.effectivealtruism.org/tag/effective-institutions-project\">Effective Institutions Project</a> was created in 2020 to work systematically on IIDM. Also, I've seen posts calling attention to the <a href=\"https://forum.effectivealtruism.org/posts/MSYhEatxkEfg46j3D/the-case-of-the-missing-cause-prioritisation-research\">inadequacy of existing cause prioritization research</a>.</p><p>Going forward, I'd like to see more systematic attempts at cause prioritization from a longtermist perspective, perhaps building on this post. 80,000 Hours' list of problem profiles currently includes <a href=\"https://80000hours.org/problem-profiles/#potentially_promising\">17 problems</a> that they claim might be as pressing as their current priority problems (artificial intelligence, biosecurity, etc.). I'd like to see more research clarifying and evaluating these problems, and drawing quantitative comparisons between them.</p>", "parentCommentId": null, "user": {"username": "evelynciara"}}, {"_id": "rtqxcBkjSABG7nZbC", "postedAt": "2022-06-27T00:23:48.533Z", "postId": "X2n6pt3uzZtxGT9Lm", "htmlBody": "<p>For what it's worth, <a href=\"https://existential-risk.org/concept\">Bostrom (2013)</a> does distinguish between insight and good values:</p><blockquote><p>We thus want to reach a state in which we have (<i>a</i>) far greater intelligence, knowledge, and sounder judgment than we currently do; (<i>b</i>) far greater ability to solve global-coordination problems; (<i>c</i>) far greater technological capabilities and physical resources; and such that (<i>d</i>) our values and preferences are not corrupted in the process of getting there (but rather, if possible, improved). Factors <i>b</i> and <i>c</i> expand the option set available to humanity. Factor <i>a</i> increases humanity's ability to predict the outcomes of the available options and understand what each outcome would entail in terms of the realization of human values. Factor <i>d</i>, finally, makes humanity more likely to want to realize human values.</p></blockquote>", "parentCommentId": "cgNMW6QBGBKfWmpRk", "user": {"username": "evelynciara"}}]