[{"_id": "9L9RbpZNxzYYJtJQT", "title": "\u300c\u3059\u3079\u3066\u306e\u52d5\u7269\u306f\u5e73\u7b49\u3067\u3042\u308b\u300d", "postedAt": "2023-08-02T10:19:05.375Z", "htmlBody": "<p><i>This is a Japanese translation of \u201c</i><a href=\"https://forum.effectivealtruism.org/posts/AXkbKxw2znzRcDEcS/all-animals-are-equal\"><i><strong>All Animals Are Equal</strong></i></a><i>\u201d</i></p><p>\u30d4\u30fc\u30bf\u30fc\u30fb\u30b7\u30f3\u30ac\u30fc\u300e\u52d5\u7269\u306e\u89e3\u653e\u300f\u7b2c\u4e09\u7248\u7b2c\u4e00\u7ae0\u300c\u3059\u3079\u3066\u306e\u52d5\u7269\u306f\u5e73\u7b49\u3067\u3042\u308b\u300d\u304b\u3089\u306e\u629c\u7c8b</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/9L9RbpZNxzYYJtJQT/pohlwnka3djifkidhspo\"></p><p>\u3059\u3079\u3066\u306e\u4eba\u9593\u306f\u305d\u306e\u4eba\u7a2e\u3001\u4fe1\u6761\u3001\u6027\u5225\u306b\u304b\u304b\u308f\u3089\u305a\u5e73\u7b49\uff08equal\uff09\u3067\u3042\u308b\u3068\u8a00\u3046\u3068\u304d\u3001\u79c1\u305f\u3061\u306f\u4f55\u3092\u4e3b\u5f35\u3057\u3066\u3044\u308b\u306e\u3060\u308d\u3046\u304b\u3002\u968e\u5c64\u7684\u3067\u4e0d\u5e73\u7b49\u306a\u793e\u4f1a\u3092\u64c1\u8b77\u3057\u3088\u3046\u3068\u671b\u3080\u4eba\u3073\u3068\u306f\u3057\u3070\u3057\u3070\u3001\u3008\u3069\u306e\u57fa\u6e96\u3092\u3082\u3063\u3066\u3053\u3088\u3046\u3068\u3082\u3001\u3059\u3079\u3066\u306e\u4eba\u9593\u304c\u5e73\u7b49\u3067\u3042\u308b\u3068\u3044\u3046\u306e\u306f\u7aef\u7684\u306b\u8a00\u3063\u3066\u771f\u5b9f\u3067\u306f\u306a\u3044\u3009\u3068\u6307\u6458\u3057\u3066\u304d\u305f\u3002\u597d\u3082\u3046\u304c\u597d\u307e\u3056\u308b\u304b\u306b\u304b\u304b\u308f\u3089\u305a\u3001\u4eba\u9593\u304c\u7570\u306a\u308b\u59ff\u304b\u305f\u3061\u3068\u4f53\u8eaf\u3092\u3082\u3063\u3066\u751f\u307e\u308c\u308b\u3068\u3044\u3046\u4e8b\u5b9f\u3001\u7570\u306a\u308b\u9053\u5fb3\u7684\u80fd\u529b\u3084\u77e5\u7684\u80fd\u529b\u3001\u6148\u3057\u307f\u306e\u5fc3\u306e\u5927\u304d\u3055\u306e\u9055\u3044\u3084\u4ed6\u8005\u306e\u30cb\u30fc\u30ba\u306b\u5bfe\u3059\u308b\u611f\u53d7\u6027\u3092\u3082\u3063\u3066\u751f\u307e\u308c\u3066\u304f\u308b\u3068\u3044\u3046\u4e8b\u5b9f\u3001\u81ea\u5206\u306e\u610f\u601d\u3092\u52b9\u679c\u7684\u306b\u4f1d\u3048\u308b\u80fd\u529b\u3082\u7570\u306a\u308a\u3001\u305d\u3057\u3066\u3001\u5feb\u82e6\u3092\u7d4c\u9a13\u3059\u308b\u80fd\u529b\u3082\u7570\u306a\u308b\u3082\u306e\u3092\u3082\u3063\u3066\u751f\u307e\u308c\u3066\u304f\u308b\u3068\u3044\u3046\u4e8b\u5b9f\u3092\u3001\u6211\u3005\u306f\u76f4\u8996\u3057\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044\u3002\u7c21\u5358\u306b\u8a00\u3048\u3070\u3001\u5e73\u7b49\u3078\u306e\u8981\u6c42\u304c\u3001\u3059\u3079\u3066\u306e\u4eba\u9593\u304c\u5b9f\u969b\u306b\u540c\u7b49\u3067\u3042\u308b\uff08equal\uff09\u3053\u3068\u306b\u57fa\u3065\u3044\u3066\u3044\u308b\u306a\u3089\u3001\u6211\u3005\u306f\u5e73\u7b49\u3092\u6c42\u3081\u308b\u3079\u304d\u3067\u306f\u306a\u304b\u3063\u305f\u3060\u308d\u3046<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref7fnyhksb0im\"><sup><a href=\"#fn7fnyhksb0im\">[1]</a></sup></span>\u3002\u305d\u308c\u3067\u3082\u307e\u3060\u3001\u4eba\u9593\u3069\u3046\u3057\u306e\u5e73\u7b49\u3078\u306e\u8981\u6c42\u306f\u3001\u4eba\u7a2e\u3084\u6027\u5225\u304c\u9055\u3063\u3066\u3082\u4eba\u3073\u3068\u306f\u5b9f\u969b\u306b\u540c\u7b49\u3067\u3042\u308b\u3053\u3068\u306b\u57fa\u3065\u3044\u3066\u3044\u308b\u3001\u3068\u3044\u3046\u8003\u3048\u304b\u3089\u96e2\u308c\u3089\u308c\u306a\u3044\u4eba\u3082\u3044\u308b\u304b\u3082\u3057\u308c\u306a\u3044\u3002</p><p>\u3057\u304b\u3057\u5e73\u7b49\u3092\u652f\u6301\u3059\u308b\u4e3b\u5f35\u304c\u3001\u3042\u308b\u7279\u5b9a\u306e\u79d1\u5b66\u7684\u306a\u7814\u7a76\u6210\u679c\u306b\u652f\u3048\u3089\u308c\u3066\u3044\u308b\u5fc5\u8981\u306f\u306a\u3044\u3002\u4eba\u7a2e\u9593\u3084\u7570\u306a\u308b\u6027\u5225\u306e\u3042\u3044\u3060\u306b\u5b58\u5728\u3059\u308b\u907a\u4f1d\u5b50\u306b\u57fa\u3065\u304f\u80fd\u529b\u5dee\u306e\u8a3c\u62e0\u3092\u898b\u3064\u3051\u305f\u3068\u4e3b\u5f35\u3059\u308b\u8005\u3078\u306e\u9069\u5207\u306a\u5fdc\u7b54\u306f\u3008\u305d\u306e\u4e3b\u5f35\u306b\u53cd\u5bfe\u3059\u308b\u305f\u3081\u306e\u3069\u3093\u306a\u8a3c\u62e0\u304c\u5f8c\u3067\u51fa\u3066\u304f\u308b\u306b\u305b\u3088\u3001\u3068\u3082\u304b\u304f\u305d\u306e\u907a\u4f1d\u5b50\u306b\u8a34\u3048\u308b\u8aac\u660e\u306f\u8aa4\u3063\u3066\u3044\u308b\u306f\u305a\u3060\u3009\u3068\u3044\u3046\u4fe1\u5ff5\u306b\u56fa\u57f7\u3059\u308b\u3053\u3068\u3067\u306f\u306a\u3044\u3002\u305d\u306e\u4ee3\u308f\u308a\u306b\u6211\u3005\u304c\u306a\u3059\u3079\u304d\u306f\u5e73\u7b49\u6027\u306e\u4e3b\u5f35\u304c\u77e5\u6027\u3084\u9053\u5fb3\u7684\u306a\u80fd\u529b\u3001\u8eab\u4f53\u306e\u5f37\u3055\u306a\u3069\u306e\u4e8b\u5b9f\u554f\u984c\u306b\u306f\u4f9d\u5b58\u3057\u306a\u3044\u3053\u3068\u3092\u5c11\u306a\u304b\u3089\u305a\u660e\u78ba\u306b\u3057\u3066\u304a\u304f\u3053\u3068\u3060\u3002\u5e73\u7b49\u6027\u306f\u9053\u5fb3\u7684\u306a\u89b3\u5ff5\u3067\u3042\u3063\u3066\u3001\u4e8b\u5b9f\u306e\u4e3b\u5f35\u3067\u306f\u306a\u3044\u3002\u3008\u3075\u305f\u308a\u306e\u4eba\u9593\u306e\u3042\u3044\u3060\u306b\u80fd\u529b\u306e\u9055\u3044\u304c\u3042\u308b\u3068\u3044\u3046\u4e8b\u5b9f\u306f\u3001\u5f7c\u3089\u306e\u30cb\u30fc\u30ba\u3068\u5229\u5bb3\u306b\u6255\u3046\u8003\u616e\u306e\u91cf\u306b\u9055\u3044\u3092\u3064\u3051\u308b\u3053\u3068\u3092\u6b63\u5f53\u5316\u3059\u308b\u3009\u3053\u3068\u3078\u306e\u8ad6\u7406\u7684\u306b\u8aac\u5f97\u529b\u306e\u3042\u308b\u7406\u7531\u306f\u5b58\u5728\u3057\u306a\u3044\u3002\u4eba\u9593\u306b\u95a2\u3059\u308b\u5e73\u7b49\u306e\u539f\u7406\u306f\u4eba\u9593\u305f\u3061\u306e\u3042\u3044\u3060\u306b\u5b9f\u969b\u306b\u3042\u308b\u3068\u3055\u308c\u308b\u540c\u7b49\u6027\u306e\u8a18\u8ff0\u3067\u306f\u306a\u3044\u3002\u305d\u308c\u306f\u3001\u6211\u3005\u304c\u4eba\u9593\u3092\u3069\u3046\u6271\u3046\u3079\u304d\u306a\u306e\u304b\u3092\u6307\u56f3\u3059\u308b\u6307\u4ee4\uff08prescription\uff09\u306a\u306e\u3060\u3002</p><p>\u9053\u5fb3\u54f2\u5b66\u306b\u304a\u3051\u308b\u529f\u5229\u4e3b\u7fa9\u5b66\u6d3e\u518d\u5efa\u306e\u7956\u3067\u3042\u308b\u30b8\u30a7\u30ec\u30df\u30fc\u30fb\u30d9\u30f3\u30b5\u30e0\u306f\u300c\u3072\u3068\u308a\u306f\u3072\u3068\u308a\u3068\u3057\u3066\u6570\u3048\u3089\u308c\u3001\u8ab0\u3082\u3075\u305f\u308a\u4ee5\u4e0a\u3068\u3057\u3066\u306f\u6570\u3048\u3089\u308c\u306a\u3044\u300d\u3068\u3044\u3046\u516c\u5f0f\u306b\u3088\u3063\u3066\u3001\u9053\u5fb3\u7684\u5e73\u7b49\u306e\u57fa\u790e\u3068\u306a\u308b\u672c\u8cea\u7684\u306a\u90e8\u5206\u3092\u5f7c\u306e\u502b\u7406\u4f53\u7cfb\u306b\u7d44\u307f\u8fbc\u3093\u3067\u3044\u305f\u3002\u30d9\u30f3\u30b5\u30e0\u306e\u516c\u5f0f\u3092\u8a00\u3044\u63db\u3048\u308b\u306a\u3089\u3001\u3042\u308b\u884c\u70ba\u306b\u5f71\u97ff\u3092\u53d7\u3051\u308b\u3059\u3079\u3066\u306e\u5b58\u5728\u8005\u306e\u5229\u5bb3\u304c\u8003\u616e\u3055\u308c\u308b\u3079\u304d\u3067\u3042\u308a\u3001\u4ed6\u306e\u5b58\u5728\u8005\u3068\u540c\u69d8\u306e\u5229\u5bb3\u3068\u540c\u3058\u91cd\u307f\u3092\u4e0e\u3048\u3089\u308c\u306d\u3070\u306a\u3089\u306a\u3044\u3001\u3068\u3044\u3046\u3053\u3068\u3060 \u2026</p><p>\u6211\u3005\u306e\u3082\u3064\u4ed6\u8005\u3078\u306e\u95a2\u5fc3\u3084\u3001\u4ed6\u8005\u306e\u5229\u5bb3\u3092\u2500\u2500\u305d\u3046\u3057\u305f\u5229\u5bb3\u304c\u3069\u306e\u3088\u3046\u306a\u3082\u306e\u3067\u3042\u308c\u2500\u2500 \u9032\u3093\u3067\u8003\u616e\u306b\u5165\u308c\u3088\u3046\u3068\u3059\u308b\u6211\u3005\u306e\u59ff\u52e2\uff08our readiness to consider their interests\uff09 \u306f\u3001\u305d\u3046\u3057\u305f\u4ed6\u8005\u304c\u3069\u3093\u306a\u7279\u5fb4\u3084\u80fd\u529b\u3092\u6240\u6709\u3057\u3066\u3044\u308b\u306e\u304b\u306b\u4f9d\u308b\u3079\u304d\u3067\u306f\u306a\u3044\u3002\u3053\u308c\u306f\u4e0a\u306b\u8ff0\u3079\u305f\u5e73\u7b49\u306e\u539f\u7406\u306e\u3072\u3068\u3064\u306e\u542b\u610f\u3067\u3042\u308b\u3002\u6211\u3005\u306e\u95a2\u5fc3\u3084\u8003\u616e\u4e8b\u9805\u306b\u57fa\u3065\u304d\u5177\u4f53\u7684\u306b\u6211\u3005\u304c\u4f55\u3092\u3059\u3079\u304d\u304b\u306f\u3001\u6211\u3005\u306e\u884c\u70ba\u306b\u5f71\u97ff\u3092\u53d7\u3051\u308b\u8005\u305f\u3061\u306e\u7279\u5fb4\u306b\u3088\u3063\u3066\u5909\u308f\u308a\u3046\u308b\u3002\u4f8b\u3048\u3070\u3001\u30a2\u30e1\u30ea\u30ab\u3067\u80b2\u3064\u5b50\u3069\u3082\u305f\u3061\u306e\u798f\u5229\uff08well-being\uff09\u3092\u8003\u616e\u3059\u308b\u306a\u3089\u3001\u5f7c\u3089\u304c\u5b57\u3092\u8aad\u3081\u308b\u3088\u3046\u306b\u6559\u80b2\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u3060\u308d\u3046\u3057\u3001\u8c5a\u306e\u798f\u5229\u3092\u8003\u616e\u3059\u308b\u306a\u3089\u5f7c\u3089\u3092\u4ef2\u9593\u3068\u4e00\u7dd2\u306b\u5341\u5206\u306a\u98df\u4e8b\u304c\u3042\u308a\u3001\u81ea\u7531\u306b\u8d70\u308b\u3053\u3068\u306e\u3067\u304d\u308b\u5834\u6240\u306b\u304a\u304f\u3053\u3068\u304f\u3089\u3044\u3057\u304b\u8981\u6c42\u3055\u308c\u306a\u3044\u304b\u3082\u3057\u308c\u306a\u3044\u3002\u3057\u304b\u3057\u57fa\u672c\u7684\u306a\u8981\u7d20\u2500\u2500\u5f53\u306e\u5b58\u5728\u306e\u5229\u5bb3\u3092\u3001\u305d\u306e\u5229\u5bb3\u304c\u4f55\u3067\u3042\u308c\u8003\u616e\u306b\u5165\u308c\u308b\u3053\u3068\u2500\u2500\u306f\u3001\u5e73\u7b49\u306e\u539f\u7406\u306b\u5f93\u3048\u3070\u9ed2\u4eba\u3084\u767d\u4eba\u3001\u7537\u6027\u3068\u5973\u6027\u3001\u305d\u3057\u3066\u4eba\u9593\u3068\u305d\u308c\u4ee5\u5916\u3082\u542b\u3081\u3066\u3059\u3079\u3066\u306e\u5b58\u5728\u306b\u62e1\u5927\u3055\u308c\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044\u3002&nbsp;&nbsp;&nbsp;</p><p>\u30c8\u30fc\u30de\u30b9\u30fb\u30b8\u30a7\u30d5\u30a1\u30fc\u30bd\u30f3\u3053\u305d\u3001\u4eba\u9593\u306e\u5e73\u7b49\u306e\u539f\u7406\u3092\u30a2\u30e1\u30ea\u30ab\u72ec\u7acb\u5ba3\u8a00\u306b\u66f8\u304d\u5165\u308c\u305f\u7acb\u5f79\u8005\u3060\u304c\u3001\u5f7c\u306f\u3053\u306e\u70b9\u3092\u7406\u89e3\u3057\u3066\u3044\u305f\u3002\u3060\u304b\u3089\u3053\u305d\u5f7c\u306f\u3001\u5f7c\u81ea\u8eab\u3001\u5974\u96b7\u306e\u6240\u6709\u3092\u5b8c\u5168\u306b\u3084\u3081\u308b\u3053\u3068\u306f\u3067\u304d\u306a\u304b\u3063\u305f\u306b\u3082\u304b\u304b\u308f\u3089\u305a\u3001\u5974\u96b7\u5236\u306b\u53cd\u5bfe\u3059\u308b\u306b\u81f3\u3063\u305f\u306e\u3060\u3002\u9ed2\u4eba\u306b\u306f\u9650\u3089\u308c\u305f\u77e5\u7684\u80fd\u529b\u3057\u304b\u306a\u3044\u3068\u3044\u3046\u5f53\u6642\u4e00\u822c\u7684\u3060\u3063\u305f\u898b\u89e3\u306b\u53cd\u99c1\u3059\u308b\u305f\u3081\u3001\u9ed2\u4eba\u305f\u3061\u306e\u76ee\u7acb\u3063\u305f\u77e5\u7684\u696d\u7e3e\u3092\u5f37\u8abf\u3059\u308b\u672c\u306e\u8457\u8005\u306b\u5b9b\u3066\u305f\u624b\u7d19\u306e\u4e2d\u3067\u3001\u30b8\u30a7\u30d5\u30a1\u30fc\u30bd\u30f3\u306f\u6b21\u306e\u3088\u3046\u306b\u66f8\u3044\u3066\u3044\u308b\u3002</p><p>\u300c\u9ed2\u4eba\u305f\u3061\u306e\u751f\u6765\u306e\u77e5\u6027\u306e\u7a0b\u5ea6\u306b\u3064\u3044\u3066\u79c1\u81ea\u8eab\u304c\u62b1\u304d\u3001\u8868\u73fe\u3057\u3066\u304d\u305f\u7591\u3044\u3078\u5b8c\u5168\u306a\u53cd\u99c1\u304c\u3055\u308c\u3001\u9ed2\u4eba\u305f\u3061\u304c\u6211\u3005\u3068\u80a9\u3092\u4e26\u3079\u308b\u4f4d\u7f6e\u306b\u3042\u308b\u3053\u3068\u3092\u898b\u51fa\u3057\u305f\u3044\u3068\u79c1\u4ee5\u4e0a\u306b\u671b\u3093\u3067\u3044\u308b\u8005\u306f\u3001\u4eca\u751f\u304d\u3066\u3044\u308b\u8005\u306e\u306a\u304b\u306b\u306f\u3044\u306a\u3044\u3068\u8acb\u3051\u5408\u304a\u3046... \u3057\u304b\u3057\u9ed2\u4eba\u305f\u3061\u306e\u624d\u899a\u304c\u3069\u306e\u7a0b\u5ea6\u306e\u3082\u306e\u3067\u3042\u308c\u3001\u305d\u308c\u306f\u9ed2\u4eba\u305f\u3061\u306e\u6a29\u5229\u3092\u6e2c\u308b\u7269\u5dee\u3057\u306b\u306f\u306a\u3089\u306a\u3044\u3002\u30a2\u30a4\u30b6\u30c3\u30af\u30fb\u30cb\u30e5\u30fc\u30c8\u30f3\u537f\u304c\u305d\u306e\u77e5\u6027\u306b\u304a\u3044\u3066\u4ed6\u306e\u4eba\u9593\u305f\u3061\u3088\u308a\u3082\u512a\u308c\u3066\u3044\u305f\u304b\u3089\u3068\u8a00\u3063\u3066\u3001\u4ed6\u306e\u4eba\u3073\u3068\u306e\u8ca1\u7523\u3084\u4eba\u683c\u306e\u4e3b\u3068\u306a\u308b\u308f\u3051\u3067\u306f\u306a\u3044\u3002\u300d<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefd3ge7s51kkd\"><sup><a href=\"#fnd3ge7s51kkd\">[2]</a></sup></span></p><p>\u4eba\u7a2e\u5dee\u5225\u306b\u53cd\u5bfe\u3059\u308b\u8b70\u8ad6\u3084\u3001\u6027\u5dee\u5225\u306b\u53cd\u5bfe\u3059\u308b\u8b70\u8ad6\u304c\u6700\u7d42\u7684\u306a\u62e0\u308a\u3069\u3053\u308d\u3068\u3057\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044\u306e\u306f\u3053\u306e\u524d\u63d0\u3060\u3002\u307e\u305f\u3001\u3053\u306e\u539f\u7406\u306b\u5f93\u3063\u3066\u3053\u305d\u3001\u6211\u3005\u304c\u4eba\u7a2e\u5dee\u5225\u3068\u306e\u30a2\u30ca\u30ed\u30b8\u30fc\u3067\u300c\u7a2e\u5dee\u5225\uff08speciesism\uff09\u300d\u3068\u547c\u3073\u3046\u308b\u614b\u5ea6\u3082\u975e\u96e3\u3055\u308c\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044\u3002\u3088\u308a\u9ad8\u3044\u77e5\u6027\u3092\u3082\u3064\u3053\u3068\u306f\u3001\u4e00\u65b9\u306e\u4eba\u9593\u306b\u4ed6\u65b9\u306e\u4eba\u9593\u3092\u81ea\u5df1\u306e\u76ee\u7684\u306e\u305f\u3081\u306b\u5229\u7528\u3059\u308b\u8cc7\u683c\u3092\u4e0e\u3048\u308b\u308f\u3051\u3067\u306f\u306a\u3044\u3068\u3057\u305f\u3089\u3001\u3088\u308a\u9ad8\u3044\u77e5\u6027\u3092\u3082\u3064\u3053\u3068\u304c\u3044\u3063\u305f\u3044\u3069\u3046\u3057\u3066\u4eba\u9593\u305f\u3061\u306b\u3001\u4eba\u9593\u4ee5\u5916\u306e\u3082\u306e\u3092\u81ea\u5df1\u306e\u76ee\u7684\u306e\u305f\u3081\u306b\u643e\u53d6\u3059\u308b\u8cc7\u683c\u3092\u4e0e\u3048\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u3068\u3044\u3046\u306e\u3060\u308d\u3046\u304b\u3002</p><p>\u7570\u7a2e\u9593\u306e\u82e6\u3057\u307f\u3092\u6bd4\u8f03\u3059\u308b\u306e\u306f\u4e0d\u53ef\u80fd\u306a\u306e\u3060\u304b\u3089\u3001\u52d5\u7269\u3084\u4eba\u9593\u306e\u5229\u5bb3\u304c\u885d\u7a81\u3059\u308b\u5834\u5408\u306b\u306f\u3001\u5e73\u7b49\u306e\u539f\u7406\u306f\u624b\u5f15\u304d\u306b\u306f\u306a\u3089\u306a\u3044\u3068\u53cd\u5bfe\u3055\u308c\u308b\u304b\u3082\u3057\u308c\u306a\u3044\u3002\u7570\u306a\u308b\u7a2e\u306b\u5c5e\u3059\u6210\u54e1\u3069\u3046\u3057\u306e\u82e6\u3057\u307f\u306e\u6b63\u78ba\u306a\u6bd4\u8f03\u304c\u3067\u304d\u306a\u3044\u3068\u3044\u3046\u306e\u306f\u304a\u305d\u3089\u304f\u771f\u5b9f\u3060\u308d\u3046\u304c\u3001\u6b63\u78ba\u3055\u306f\u672c\u8cea\u7684\u3067\u306f\u306a\u3044\u3002\u4eba\u9593\u306e\u5229\u5bb3\u304c\u53d7\u3051\u308b\u5f71\u97ff\u304c\u3001\u52d5\u7269\u304c\u88ab\u308b\u5f71\u97ff\u306e\u7a0b\u5ea6\u3068\u6bd4\u8f03\u3057\u3066\u9065\u304b\u306b\u5c0f\u3055\u3044\u3068\u78ba\u4fe1\u3067\u304d\u308b\u5834\u5408\u306b\u306e\u307f\u52d5\u7269\u306b\u4e0e\u3048\u308b\u82e6\u3057\u307f\u3092\u9632\u3050\u3079\u304d\u3060\u3068\u3057\u3066\u3055\u3048\u3082\u3001\u6211\u3005\u306e\u98df\u4e8b\u3084\u3001\u6211\u3005\u304c\u7528\u3044\u3066\u3044\u308b\u755c\u7523\u65b9\u6cd5\u3001\u591a\u304f\u306e\u79d1\u5b66\u5206\u91ce\u3067\u884c\u308f\u308c\u3066\u3044\u308b\u5b9f\u9a13\u65b9\u6cd5\u3001\u91ce\u751f\u52d5\u7269\u3068\u306e\u4ed8\u304d\u5408\u3044\u65b9\u3084\u72e9\u731f\u3001\u7f60\u306b\u3088\u308b\u6355\u7372\u3001\u6bdb\u76ae\u306e\u7740\u7528\u3001\u30b5\u30fc\u30ab\u30b9\u3084\u30ed\u30c7\u30aa\u3001\u52d5\u7269\u5712\u306a\u3069\u306e\u5a2f\u697d\u5206\u91ce\u306a\u3069\u3067\u306e\u52d5\u7269\u305f\u3061\u306e\u53d6\u308a\u6271\u3044\u3092\u3001\u6211\u3005\u306f\u6839\u672c\u7684\u306b\u5909\u3048\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044\u3060\u308d\u3046\u3002\u305d\u3046\u306a\u308c\u3070\u3001\u83ab\u5927\u306a\u91cf\u306e\u82e6\u3057\u307f\u304c\u907f\u3051\u3089\u308c\u308b\u3053\u3068\u306b\u306a\u308b\u3060\u308d\u3046\u3002<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref2z9irfps8y9\"><sup><a href=\"#fn2z9irfps8y9\">[3]</a></sup></span></p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn7fnyhksb0im\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref7fnyhksb0im\">^</a></strong></sup></span><div class=\"footnote-content\"><p>\u3068\u3044\u3046\u306e\u3082\u4eba\u9593\u304c\u5b9f\u969b\u306b\uff08\u8eab\u9577\u3084\u4f53\u683c\u3001\u5916\u898b\u3001\u8eab\u4f53\u80fd\u529b\u3001\u77e5\u6027\u7b49\u3005\u306b\u304a\u3044\u3066\uff09\u540c\u7b49\u3067\u3042\u308b\u3053\u3068\u304c\u5e73\u7b49\u3092\u8981\u6c42\u3059\u308b\u6839\u62e0\u3067\u3042\u308b\u306a\u3089\u3001\u305d\u306e\u3088\u3046\u306a\u540c\u7b49\u6027\u306f\u5b9f\u969b\u306b\u306f\u5b58\u5728\u3057\u306a\u3044\u306e\u3060\u304b\u3089\u3001\u5e73\u7b49\u3092\u8981\u6c42\u3059\u308b\u6839\u62e0\u306f\u306a\u3044\u3060\u308d\u3046\uff08\u3068\u968e\u5c64\u7684\u3067\u4e0d\u5e73\u7b49\u306a\u793e\u4f1a\u3092\u64c1\u8b77\u3057\u3088\u3046\u3068\u671b\u3080\u4eba\u3073\u3068\u306f\u8ad6\u3058\u308b\uff09\u304b\u3089\u3002</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnd3ge7s51kkd\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefd3ge7s51kkd\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Letter to Henry Gregoire, February 25, 1809.Retrieved from&nbsp;<a href=\"http://hdl.loc.gov/loc.mss/mtj.mtjbib019810\"><u>http://hdl.loc.gov/loc.mss/mtj.mtjbib019810</u></a>&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn2z9irfps8y9\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref2z9irfps8y9\">^</a></strong></sup></span><div class=\"footnote-content\"><p>\u7ffb\u8a33\u306b\u969b\u3057\u3066\u3001\u6238\u7530\u6e05\u8a33\u300e\u52d5\u7269\u306e\u89e3\u653e\u3000\u6539\u8a02\u7248\u300f\uff082011\u5e74\u3001\u4eba\u6587\u66f8\u9662\uff09\u306e\u7b2c\u4e00\u7ae0\u3092\u53c2\u8003\u306b\u3057\u305f\u3002</p></div></li></ol>", "user": {"username": "EA Japan"}}, {"_id": "9vazTE4nTCEivYSC6", "title": "Reflections on my time on the Long-Term Future Fund", "postedAt": "2023-08-02T01:32:49.033Z", "htmlBody": "<p><a href=\"https://forum.effectivealtruism.org/posts/zt6MsCCDStm74HFwo/ea-funds-organisational-update-open-philanthropy-matching\">I'm stepping down as chair of the Long-Term Future Fund</a>. I'm writing this post partially as a loose set of reflections on my time there, and partially as an overall update on what's going on with the fund,<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefoy97x6754hh\"><sup><a href=\"#fnoy97x6754hh\">[1]</a></sup></span>&nbsp;as I think we should generally be transparent with donors and grantees, and my sense is the broader community has fairly little insight into the fund's current operations. I'll start with a brief history of what's happened since I joined the fund, and its impact, and move to a few reflections on ways the fund is working now.</p><p>(Also- you can donate to the Long-Term Future Fund <a href=\"https://www.givingwhatwecan.org/charities/long-term-future-fund\">here</a>, and let us know <a href=\"https://forms.gle/6gC7ezTwbNME8J6S9\">here</a> if you might be interested in becoming a fund manager. (The Long-Term Future Fund is part of EA Funds, which is a fiscally sponsored project of Effective Ventures Foundation (UK) (EV UK) and Effective Ventures Foundation USA Inc. (EV US). Donations to the Long-Term Future Fund are donations to EV US or EV UK.)<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefkpnklyk2xoo\"><sup><a href=\"#fnkpnklyk2xoo\">[2]</a></sup></span>)</p><h1>A brief history of my time on the Long-Term Future Fund</h1><p>I joined the Long-Term Future Fund as a fund manager in June 2020. At the time, it was chaired by Matt Wage, had five fund managers (including me), and ran three rounds per year, with order ~50 applications per round,<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefcytzza3r1u\"><sup><a href=\"#fncytzza3r1u\">[3]</a></sup></span>&nbsp;giving away an average of ~$450K per round in both 2019 and 2020, for a total of ~$1.35M per year.</p><p>Matt Wage left the fund, and I was appointed the new chair in February 2021. We also hired a number of&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/ek5ZctFxwh4QFigN7/ea-funds-has-appointed-new-fund-managers\"><u>new fund managers</u></a>, and decided to try out a&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/ek5ZctFxwh4QFigN7/ea-funds-has-appointed-new-fund-managers#Guest_managers\"><u>guest manager system</u></a> where we had more temporary fund managers work with the fund. (We're still doing that today.)</p><p>The biggest change that I pushed for during my time as chair (which I believe was originally suggested by Ozzie Gooen, thanks Ozzie) was&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/oz4ZWh6xpgFheJror/you-can-now-apply-to-ea-funds-anytime-ltff-and-eaif-only\"><u>switching from three fixed rounds a year to a rolling application system</u></a>, where anyone could apply to the fund at any time. My current guess is that this was a pretty big boost to the fund's impact, via giving us access to a bunch of counterfactual grant opportunities that other funders (who either didn't have rolling applications, or were funding a more constrained set of things) didn't have access to. I also pushed for&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/LKdtHdETxSYAXwoW6/public-reports-are-now-optional-for-ea-funds-grantees\"><u>a switch away from mandatory public reporting</u></a> for our grant applicants (which I discuss somewhat <a href=\"https://forum.effectivealtruism.org/posts/9vazTE4nTCEivYSC6/reflections-on-my-time-on-the-long-term-future-fund#Transparency\">below</a>), which I also think gave us access to better grant opportunities, and which I also overall still endorse.</p><p>At a high-level, the fund consists of a number of fund managers who work a relatively low number of hours per week (generally 3 - 10, though I think it might be trending even lower recently). EA Funds itself only has one full-time employee\u2014&nbsp;<a href=\"https://funds.effectivealtruism.org/team\"><u>Caleb Parikh</u></a>. There's been significant fund manager turnover since I joined the fund, generally because relevant fund managers have wanted to prioritize their other work\u2014 since I joined the fund, Matt Wage and Helen Toner have left, Adam Gleave, Evan Hubinger, and Becca Kagan have joined as permanent fund managers and then left, Linchuan Zhang has joined as a permanent fund manager, and we've had a number of guest managers join and leave the fund.</p><p>Also during my time on the fund, the volume of our grantmaking work has scaled significantly\u2014 whereas in 2020, we received 211 applications and funded 34 as grants, worth ~$1.3M dollars total, from March 2022 to March 2023, we received 878 applications and funded 263 as grants, worth ~$9.1M dollars total.</p><h1>The fund\u2019s impact</h1><p>My reflections below focus on ways I think the Long-Term Future Fund has been suboptimal over my time as chair, and I got feedback on my original draft of this post that this made it seem like my view of the fund was negative overall, which wasn\u2019t my intention. For clarity,&nbsp;my best guess is that overall, the Long-Term Future Fund has been, and continues to be, pretty (positively) impactful:&nbsp;</p><ul><li>Historically, it was one of the first grantmakers to start making small grants to individuals, at a time when that kind of grantmaking was fairly neglected. I think we\u2019ve served an important role in the ecosystem as a big funder of individuals, smaller projects, and new organizations.</li><li>By virtue of being the only \"anything, anytime\" grantmaker, I think we\u2019ve had access and continue to have access to grant opportunities that other funders have not, and would guess that some of those have led to fairly good grants.</li><li>Looking back, I think a number of our grants have been \u201cgreat\u201d\u2014 you can see our full grantmaking track record&nbsp;<a href=\"https://funds.effectivealtruism.org/grants?fund=Long-Term%2520Future%2520Fund&amp;sort=round\"><u>here</u></a>, but some public grantees that stand out to me are <a href=\"https://forum.effectivealtruism.org/posts/zZ2vq7YEckpunrQS4/long-term-future-fund-april-2023-grant-recommendations#Stephen_Grugett__James_Grugett__Austin_Chen___200_000___4_month_stipend_for_3_FTE_to_build_a_forecasting_platform_made_available_to_the_public_based_on_user_created_play_money_prediction_markets\">Manifold Markets</a>, <a href=\"https://forum.effectivealtruism.org/posts/diZWNmLRgcbuwmYn4/long-term-future-fund-may-2021-grant-recommendations#Daniel_Filan____5_280\">AXRP</a>, <a href=\"https://forum.effectivealtruism.org/posts/dgy6m8TGhv4FCn4rx/long-term-future-fund-september-2020-grants#Robert_Miles___60_000_\">Robert Miles</a>, the <a href=\"https://forum.effectivealtruism.org/posts/HYKDh2mLjapsgj9nB/long-term-future-fund-july-2021-grant-recommendations#Ezra_Karger__Pavel_Atanasov__Philip_Tetlock___572_000__200_000_\">Existential-Risk Persuasion Tournament</a>, <a href=\"https://forum.effectivealtruism.org/posts/diZWNmLRgcbuwmYn4/long-term-future-fund-may-2021-grant-recommendations#David_Krueger____200_000__with_an_expected_reimbursement_of_up_to__120_000\">David Krueger</a>, <a href=\"https://forum.effectivealtruism.org/posts/Yosqvz6w9fuc3zjBS/long-term-future-fund-november-2020-grant-recommendations#Vanessa_Kosoy___100_000\">Vanessa Kosoy</a>, and <a href=\"https://forum.effectivealtruism.org/posts/zZ2vq7YEckpunrQS4/long-term-future-fund-april-2023-grant-recommendations#SERI_MATS_program___316_000___8_weeks_scholars_program_to_pair_promising_alignment_researchers_with_renowned_mentors___Originally_evaluated_by_Asya_Bergal_\">SERI MATS</a>.</li><li>Personally, seeing submissions to an open application form has helped me get a sense of the space of work and projects that people are interested in, which has been helpful for understanding what funding opportunities might exist in my work at Open Philanthropy. Working at the LTFF has also led me to push my team at Open Phil to move faster on grants, streamline our grantmaking infrastructure, and investigate certain grantmaking areas sooner.</li></ul><p>To the extent that this section is shorter than others, it's because I think most of our impact, which has come through our grantmaking, is well-documented in other places, e.g. our <a href=\"https://funds.effectivealtruism.org/funds/far-future#payout-reports\">payout reports</a> and our<a href=\"https://funds.effectivealtruism.org/grants?sort=round\">&nbsp;<u>grants database</u></a>, and I think it's generally more interesting (both for others, and for my reflection) to think about ways in which things could have gone better. (I also wanted to make clear that most of my reflections on suboptimality are about our grantee experience, rather than our grantmaking quality (which I have no particular reason to think has declined)).</p><h1>Reflections</h1><h2>Problems with scale</h2><p>I think the Long-Term Future Fund hasn\u2019t done a good job staying fast and reliable in the face of a massive increase in application and grant numbers. (As I say above, we went from 34 grants in 2020 to 263 grants from March 2022 - March 2023). In particular, I don\u2019t think we\u2019re able to get back in time reliably on time-sensitive applications, and have taken a very long time to get back on a small number of applications\u2013 our median response time from January 2022 to April 2023 was 29 days, but our current mean (across all time) is 54 days (although the mean is very unstable). As the single person arguably most responsible for the fund functioning well, and definitely most responsible for its increase in applications, I think I should take a fair share of the blame for this.</p><p>In my view, a fundamental problem at play here is that the fund isn't structurally well set-up to handle its current application load. In general, I think having a bunch of people working part-time on something outside of their main job is not an amazing set-up\u2014 even for extremely conscientious people, it's hard to juggle multiple responsibilities, especially when there's no formal managerial relationship or accountability, meaning it's difficult to count on people (chiefly and including me) working reliable hours, or keeping track of deadlines. I think switching the fund to rolling applications made these dynamics even worse, as it meant that fund managers had a lot more applications to evaluate, had to keep track of a lot more individual deadlines, and had to work more consistent hours to keep on top of those deadlines (as opposed to everyone being able to plan around a constrained busy stretch during each funding round). The collapse of FTX also substantively worsened this dynamic, as it meant that we got more applications, each application decision was harder and had higher stakes (as a result of the overall decrease in funding in the space), and at least one fund manager was overwhelmingly busy dealing with the aftermath.</p><p>As our applicant pool has increased and our fund managers have turned over rapidly, I personally have been more of a bottleneck on our funding decisions, as I've had to do more work assigning applications, tracking deadlines, and providing a second eye on applications that only one fund manager looks at (which is currently the default for most applications, given the ratio of applications to fund managers).<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefplnavufmakd\"><sup><a href=\"#fnplnavufmakd\">[4]</a></sup></span>&nbsp;I've recently spent some time writing up some policies for how the LTFF should operate that I can share with new fund managers, in the hopes that it will save me time in the long run, as the amount of time I end up spending per application we get is approximately inversely proportional to how long the primary evaluator investigating has been on the fund. Overall, I think the chair role has expanded significantly since I joined the fund\u2014 originally, the chair was originally just a slightly special fund manager who had the job of assigning applications; now, it feels more like I'm half-heartedly managing a small team who don't interact with each other much by default.</p><p>(I also suspect that the lack of active discussion about grants has made the fund a worse experience for fund managers\u2014 I might describe the overall shift in the culture of the fund to have gone from \"lively epistemic forum\" to \"solitary grantmaking machine\".)</p><p>The main consequence of all of the above is that I think the Long-Term Future Fund has been significantly less reliable and consistent in the last year, and especially in the last eight months (since the collapse of FTX). I'm sorry to any applicants that this affected, and I'm especially sorry to the extent that the LTFF has set false expectations around our speed and reliability\u2014 we previously changed our application form to say \"if your application is time-sensitive, we may or may not have the capacity to get back to you in time\", but I now think that language is too weak, and have changed it to say \"the LTFF is low on capacity and may not be able to get back to you by your stated deadline\u2014 we encourage you to apply to other funders as well if you have a time-sensitive ask.\" (That said, I think applicants who want time-sensitive decisions should still apply to the LTFF\u2014 we do get back to people in time in a lot of cases, and I'm pushing us to increasingly prioritize applications that look particularly promising at a quick glance.)</p><p>Some obvious paths to improving the fund on this dimension are a) hiring more fund managers; b) hiring a full-time chair, or otherwise restructuring the fund so as not to have one person bottlenecking its work as much (e.g. by giving multiple more senior fund managers the responsibility to be a second eye on grant evaluations by more junior ones); or c) changing the way the fund operates in a more major way, e.g. going back to a round-based system, or changing the fund to a collection of independent regrantors. In my remaining time as chair, I plan to work on hiring, but currently think it's unlikely that I'll push for any major restructures. (But it seems like something to consider for whoever replaces me).<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefck1hloh2ljn\"><sup><a href=\"#fnck1hloh2ljn\">[5]</a></sup></span></p><p>Historically, we've had trouble hiring fund managers, especially in technical AI alignment, largely for the reasons mentioned above (people generally want to focus on their work). I think there's an extent to which I've contributed to our difficulty in hiring, in that I'm not sold that people doing good direct work&nbsp;<i>should</i> be taking on additional responsibilities as fund managers (so haven\u2019t been great at convincing people to join), though others on the fund feel differently, and I'll let them comment below.</p><p>I also think it's possible that some combination of existing and new funders will increasingly fill the historic niche that the LTFF has had (as an always-open funder accepting applications for anything), which would be a good outcome in my eyes, and could reduce the LTFF's workload to a more sustainable level.</p><h2>Transparency</h2><p>Several people have told me that they feel disappointed that the Long-Term Future Fund hasn't been putting out detailed payout reports the way we have historically (at least not since&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/ddBLtdQjcjvZH5JvF/long-term-future-fund-december-2021-grant-recommendations#comments\"><u>this report covering our giving through 2021</u></a>). I stopped mandating those reports, and we switched to a&nbsp;<a href=\"https://funds.effectivealtruism.org/grants?sort=round\"><u>grantmaking database</u></a>, as I felt like the fund was overwhelmed with evaluating applications, though my hope was that individual fund managers would still be interested in publishing grant reports independently. (In hindsight, it seems obvious that this wasn\u2019t going to happen without active encouragement on my part, though Linch did write this&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/vPMo5dRrgubTQGj9g/some-unfun-lessons-i-learned-as-a-junior-grantmaker\"><u>great post about lessons he learned as a grantmaker</u></a>.) I also pushed to&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/LKdtHdETxSYAXwoW6/public-reports-are-now-optional-for-ea-funds-grantees\"><u>switch the fund away from mandatory reporting for all of its grants</u></a>, which means that some fraction of the grants we make are no longer publicly reported.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefmazqyv3s2qg\"><sup><a href=\"#fnmazqyv3s2qg\">[6]</a></sup></span></p><p>I think both of these actions arguably trade off one theory of change for the fund, \"contributing to the epistemic commons\", for another, \"making more (good) grants\". I personally have always been more sold on the latter theory of change (for the LTFF in particular), so think that these were good trades, but I think there's room for disagreement on that, and all things equal, I think it's too bad that we haven't put out more payout reports over the last year. We recently did release a new payout report <a href=\"https://forum.effectivealtruism.org/posts/zZ2vq7YEckpunrQS4/long-term-future-fund-april-2023-grant-recommendations#SERI_MATS_program___316_000___8_weeks_scholars_program_to_pair_promising_alignment_researchers_with_renowned_mentors___Originally_evaluated_by_Asya_Bergal_\">here</a>, and I'd guess the fund is likely to continue putting them out at least somewhat more frequently, as it does more independent fundraising.</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnoy97x6754hh\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefoy97x6754hh\">^</a></strong></sup></span><div class=\"footnote-content\"><p>We've also recently posted <a href=\"https://forum.effectivealtruism.org/posts/zZ2vq7YEckpunrQS4/long-term-future-fund-april-2023-grant-recommendations\">updates on our grantmaking over the past year</a> and <a href=\"https://forum.effectivealtruism.org/posts/zt6MsCCDStm74HFwo/ea-funds-organisational-update-open-philanthropy-matching\">an update on actions we're taking to increase the separation between Open Phil and EA Funds</a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnkpnklyk2xoo\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefkpnklyk2xoo\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Effective Ventures Foundation (UK) (EV UK) is a charity in England and Wales (with registered charity number 1149828, registered company number 07962181, and is also a Netherlands registered tax-deductible entity ANBI 825776867). Effective Ventures Foundation USA Inc. (EV US) is a section 501(c)(3) organization in the USA (EIN 47-1988398). Please see important state disclosures&nbsp;<a href=\"https://docs.google.com/document/d/1PWmiI4NORXwINKmjeyuHIPgGWqVE6bAXRYMfV6kleTQ/edit\"><u>here</u></a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fncytzza3r1u\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefcytzza3r1u\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;For the rounds I had access to.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnplnavufmakd\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefplnavufmakd\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;I haven't substantially increased my amount of time spent on the fund in response to this increased workload, both for personal prioritization reasons, and as a result of an agreement that I made with my employer, Open Philanthropy, about how much of my time I would spend on the LTFF.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnck1hloh2ljn\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefck1hloh2ljn\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;One thing I feel less bullish on than I did in the past is solving the problem with the set-up above by decreasing the bar for fund manager hires-- at least in my experience, I felt like bringing on people who I thought were less strong resulted in more overhead for me, which just made the part of the process that I was bottlenecking worse.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnmazqyv3s2qg\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefmazqyv3s2qg\">^</a></strong></sup></span><div class=\"footnote-content\"><p>From January 2022 to April 2023, 11% of our total funding recommended has gone to grants that weren\u2019t publicly reported.</p></div></li></ol>", "user": {"username": "abergal"}}, {"_id": "zt6MsCCDStm74HFwo", "title": "EA Funds organisational update: Open Philanthropy matching and distancing", "postedAt": "2023-08-02T01:28:19.270Z", "htmlBody": "<p>We want to communicate some changes that are happening at EA Funds, particularly on the EA Infrastructure Fund and the Long-Term Future Fund.</p>\n<p>In summary:</p>\n<ul>\n<li>EA Funds (particularly the EAIF and LTFF) and Open Philanthropy have historically had overlapping staff, and Open Phil has supported EA Funds, but we (staff at EA Funds and Open Philanthropy) are now trying to increase the separation between EA Funds and Open Philanthropy. In particular:\n<ul>\n<li>The current chairs of the LTFF and the EAIF, who have also joined as staff members at Open Philanthropy, are planning to step down from their respective chair positions over the next several months. Max Daniel is going to step down as the EAIF\u2019s chair on August 2nd, and Asya Bergal is planning to step down as the LTFF\u2019s chair in October.</li>\n<li>To help transition EA Funds away from reliance on Open Philanthropy\u2019s financial support, Open Philanthropy is planning to match donations to the EA Infrastructure and Long-Term Future Fund at 2:1 rates, up to $3.5M each, over the next six months.</li>\n</ul>\n</li>\n<li>The EAIF and LTFF have substantial funding gaps - we are looking to raise an additional $3.84M for the LTFF and $3.6M for the EAIF. over the next six months. By default, I expect, the LTFF to have ~$720k, and the EAIF to have ~$400k by default.</li>\n</ul>\n<h2>Our relationship with Open Philanthropy</h2>\n<p>EA Funds started in 2017 and was largely developed during CEA\u2019s time at Y Combinator. It spun out of CEA in 2020, though both CEA and EA Funds are part of the Effective Ventures Foundation. Last year, EA Funds moved <a href=\"https://funds.effectivealtruism.org/stats/payouts\">over $35M</a> towards high-impact projects through the <a href=\"https://funds.effectivealtruism.org/funds/animal-welfare\">Animal Welfare Fund</a> (AWF), <a href=\"https://funds.effectivealtruism.org/funds/ea-community\">EA Infrastructure Fund </a>(EAIF), <a href=\"https://funds.effectivealtruism.org/funds/global-development\">Global Health and Development Fund</a> (GHDF), and <a href=\"https://funds.effectivealtruism.org/funds/far-future\">Long-Term Future Fund</a> (LTFF).</p>\n<p>Over the last two years, the EAIF and LTFF used some overlapping resources with Open Philanthropy in the following ways:</p>\n<ul>\n<li>\n<p>Over the last year, Open Philanthropy has contributed a substantial proportion of <a href=\"https://funds.effectivealtruism.org/stats/funding-sources\">EAIF and LTFF budgets</a> and has covered our entire operations budget.<sup class=\"footnote-ref\"><a href=\"#fn-Frur7HS8hrB56Acyb-1\" id=\"fnref-Frur7HS8hrB56Acyb-1\">[1]</a></sup> They also made a sizable grant in February 2022. (You can see more detail on Open Philanthropy\u2019s <a href=\"https://www.openphilanthropy.org/grants/?organization-name=effective-altruism-funds\">website</a>.)</p>\n</li>\n<li>\n<p>The chairs of the EAIF and LTFF both joined the Longtermist EA Community Growth team at Open Philanthropy and have worked in positions at EA Funds and Open Philanthropy simultaneously. (Asya Bergal joined the LTFF in June 2020, has been chair since February 2021, and joined Open Philanthropy in April 2021; Max Daniel joined the EAIF in March 2021, has been chair since mid-2021, and joined Open Philanthropy in November 2022.)</p>\n</li>\n<li>\n<p>As a board member of the Effective Ventures Foundation (UK), Claire Zabel, who is also the Senior Program Officer for EA Community Growth (Longtermism) at Open Philanthropy and supervises both Asya and Max, has regularly met with me throughout my tenure at EA Funds to hear updates on EA Funds and offer advice on various topics related to EA Funds (both day-to-day issues and higher-level organisation strategy).</p>\n</li>\n</ul>\n<p>That said, I think it is worth noting that:</p>\n<ul>\n<li>The majority of funding for the LTFF has come from non-Open Philanthropy <a href=\"https://funds.effectivealtruism.org/stats/funding-sources\">sources</a>.</li>\n<li>Open Philanthropy as an organisation has limited visibility into our activities, though certain Open Philanthropy employees, particularly Max Daniel and Asya Bergal, have a lot of visibility into certain parts of EA Funds.</li>\n<li>Our grants supporting our operations and LTFF/EAIF grantmaking funds have had minimal restrictions.</li>\n</ul>\n<p>Since the shutdown of the FTX Future Fund, Open Phil and I have both felt more excited about building a grantmaking organisation that is legibly independent from Open Phil. Earlier this year, Open Phil staff reached out to me proposing some steps to make this happen, and have worked with me closely on the changes listed below.</p>\n<p>We think this could help to:</p>\n<ul>\n<li>\n<p>Increase the diversity of perspectives in the funding ecosystem.</p>\n</li>\n<li>\n<p>Decrease the reliance of small to medium-sized projects on a single funder.</p>\n</li>\n<li>\n<p>Increase people's willingness to disagree with Open Philanthropy.<sup class=\"footnote-ref\"><a href=\"#fn-Frur7HS8hrB56Acyb-2\" id=\"fnref-Frur7HS8hrB56Acyb-2\">[2]</a></sup></p>\n</li>\n<li>\n<p>Make EA Funds internally feel less beholden to Open Phil.</p>\n<ul>\n<li>I have had several conversations with fund managers who believed that we should be weighing Open Phil\u2019s views more heavily in funding decisions than I or the Open Philanthropy grantmaker evaluating EA Funds believed was necessary.</li>\n</ul>\n</li>\n<li>\n<p>Allow EA Funds to pursue activities that Open Philanthropy thinks are less promising than our current work, but we believe to be highly promising.</p>\n</li>\n<li>\n<p>Decrease the risk of EA Funds\u2019 actions negatively affecting Open Philanthropy or vice-versa.</p>\n</li>\n</ul>\n<p>Over the next few months, we and Open Philanthropy are making the following changes to make EA Funds a more legibly independent funder.</p>\n<ul>\n<li>\n<p>The LTFF and EAIF chairs will step down from their current roles, and we are unlikely to allow people to simultaneously chair a fund at EA Funds and work at Open Philanthropy.<sup class=\"footnote-ref\"><a href=\"#fn-Frur7HS8hrB56Acyb-3\" id=\"fnref-Frur7HS8hrB56Acyb-3\">[3]</a></sup></p>\n</li>\n<li>\n<p>Instead of giving us a fixed grant, Open Philanthropy has decided to match donations at a 2:1 rate ($2 from Open Philanthropy for every $1 donated to the EAIF and LTFF) for the next six months, for up to $3.5M in Open Phil support per fund. You can find more information on the donation match in <a href=\"#heading=h.ka3hghmglwcm\">the appendix \"Open Philanthropy donation matching\"</a>.</p>\n</li>\n<li>\n<p>Instead of meeting with Claire Zabel, I will meet with another member of the Effective Ventures Board who doesn\u2019t work at Open Philanthropy.</p>\n</li>\n</ul>\n<p>Overall, I believe the upcoming changes will be beneficial, but there are some drawbacks. In particular:</p>\n<ul>\n<li>EA Funds will need to spend a much larger proportion of its time fundraising.<sup class=\"footnote-ref\"><a href=\"#fn-Frur7HS8hrB56Acyb-4\" id=\"fnref-Frur7HS8hrB56Acyb-4\">[4]</a></sup></li>\n<li>I think it\u2019s likely that the EAIF and LTFF will have substantial funding gaps, meaning we\u2019ll need to reject a number of applications that we think are promising and are above the bars of others in the space(though we may try to refer those applications to other funders).</li>\n<li>I have found hiring fund managers challenging in the past, and I expect replacing the current LTFF and EAIF chairs to be challenging.<sup class=\"footnote-ref\"><a href=\"#fn-Frur7HS8hrB56Acyb-5\" id=\"fnref-Frur7HS8hrB56Acyb-5\">[5]</a></sup></li>\n</ul>\n<h2>Comments from Open Philanthropy on the planned changes</h2>\n<p><em>This section was written by Claire Zabel</em></p>\n<p>Our goal is to help the EAIF and LTFF become less dependent on Open Phil\u2019s perspective on them or evaluation of them, while also giving them time to seek out and build relationships with other supporters while continuing to fund strong applicants.</p>\n<p>That means the purpose of these matching funds is to <em>amplify the impact</em> of non-Open Phil people who evaluate the LTFF and/or EAIF and believe them to be good donation opportunities. The matching funds, thus, <em>should not</em> necessarily be interpreted as a strong endorsement of the Funds, especially going forwards, though they are premised on our past experience with the Funds suggesting that they have reasonable processes and historically supported projects we often thought seemed valuable but didn\u2019t encounter ourselves.</p>\n<p>We are trying to strike the right balance between encouraging different grantmaking projects in the spaces we work in to guard against our own potential blindspots, and conserving our support for the projects that seem best to us.</p>\n<p>Counterfactually, the funding supporting this match would likely be used for other grantmaking projects at Open Phil in our <a href=\"https://www.openphilanthropy.org/our-global-health-and-wellbeing-and-longtermism-grantmaking-portfolios/\">longtermism grantmaking portfolio</a>.</p>\n<h2>Current Funding Gaps</h2>\n<p>The EAIF and LTFF have received generous donations from many individuals in the EA community. However, donations to the EAIF and LTFF have been in decline over the last year. We think that some of this is due to crypto and tech stocks doing less well than the previous year (though we hope that recent market trends will bring back some donors).<sup class=\"footnote-ref\"><a href=\"#fn-Frur7HS8hrB56Acyb-6\" id=\"fnref-Frur7HS8hrB56Acyb-6\">[6]</a></sup></p>\n<h4>LTFF funding gap</h4>\n<ul>\n<li>\n<p>The LTFF has a funding gap of $1M/month.<sup class=\"footnote-ref\"><a href=\"#fn-Frur7HS8hrB56Acyb-7\" id=\"fnref-Frur7HS8hrB56Acyb-7\">[7]</a></sup></p>\n</li>\n<li>\n<p>Based on donations over the past few months, I estimate that each fund will receive (by default) roughly $120k per month (720K over the next six months), which will be matched at a 2:1 rate, by Open Philanthropy to give us a total of $360k/month.</p>\n</li>\n<li>\n<p>This means we expect to be unable to fund around $640k/month of projects we believe should be funded.</p>\n</li>\n<li>\n<p>This could be filled by an additional $213k in public donations each month (or $1.27M over the next six months).</p>\n</li>\n</ul>\n<h4>EAIF funding gap</h4>\n<ul>\n<li>\n<p>The EAIF has a funding gap of $800k/month.<sup class=\"footnote-ref\"><a href=\"#fn-Frur7HS8hrB56Acyb-8\" id=\"fnref-Frur7HS8hrB56Acyb-8\">[8]</a></sup></p>\n</li>\n<li>\n<p>Based on donations over the past few months, I estimate that each fund will receive (by default) roughly $67k per month ($402k over six months), which will be matched at a 2:1 rate, by Open Philanthropy to give us a total of $200k/month.</p>\n</li>\n<li>\n<p>This means we expect to be unable to fund around $600k/month of projects we believe should be funded</p>\n</li>\n<li>\n<p>This could be filled by an additional $200k in public donations each month (or $1.2M over the next six months).</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>Fund</th>\n<th>Expected shortfall (6mo)</th>\n<th>Additional donations (6mo)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>LTFF</td>\n<td>$3.84M</td>\n<td>$1.27M</td>\n</tr>\n<tr>\n<td>EAIF</td>\n<td>$3.6M</td>\n<td>$1.2M</td>\n</tr>\n</tbody>\n</table>\n<h2>Appendix: Open Philanthropy donation matching</h2>\n<p>Open Philanthropy is planning to match public donations at a 2:1 rate, meaning that they will give $2 for every $1 fundraised for the EAIF and LTFF (contributing up to $3.5M per fund) for six months, starting from the publication of this post. This is subject to several conditions being met, indicating that the relevant funds are operating broadly similarly to how they have been doing in the past; we expect these to be met and will flag if things change such that additional funding might no longer be matched</p>\n<p>Open Phil won\u2019t match funds from other funders who contribute &gt;$5M in aggregate to the two funds per year, or seem to contribute &gt;$20M/yr to the greater EA/LT/x-risk reduction space.<sup class=\"footnote-ref\"><a href=\"#fn-Frur7HS8hrB56Acyb-9\" id=\"fnref-Frur7HS8hrB56Acyb-9\">[9]</a></sup> The LTFF and EAIF can do things that don\u2019t meet the conditions above, they just will not be subject to the default 2:1 match.</p>\n<p>Open Philanthropy is not committing to matching funds on longer timescales at this time, though it may do so, plausibly at a lower match rate, given that in the future, we will have had more time to build relationships with other funders.</p>\n<hr class=\"footnotes-sep\">\n<section class=\"footnotes\">\n<ol class=\"footnotes-list\">\n<li id=\"fn-Frur7HS8hrB56Acyb-1\" class=\"footnote-item\"><p>Note that EA Funds staff who were also Open Phil employees did their Funds work on a volunteer basis. <a href=\"#fnref-Frur7HS8hrB56Acyb-1\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-Frur7HS8hrB56Acyb-2\" class=\"footnote-item\"><p>Which I believe will be beneficial for both Open Philanthropy and the epistemics of EA and Longtermist communities. <a href=\"#fnref-Frur7HS8hrB56Acyb-2\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-Frur7HS8hrB56Acyb-3\" class=\"footnote-item\"><p>Though this should not be taken as a strong commitment at this time. <a href=\"#fnref-Frur7HS8hrB56Acyb-3\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-Frur7HS8hrB56Acyb-4\" class=\"footnote-item\"><p>Which is also the case for many other projects after the FTX Future Fund shut down. <a href=\"#fnref-Frur7HS8hrB56Acyb-4\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-Frur7HS8hrB56Acyb-5\" class=\"footnote-item\"><p>My understanding is that Open Philanthropy and other grantmakers have also had difficulties hiring excellent fund managers. Some of the reasons that we (EA Funds) have found this hard include:</p>\n<ul>\n<li>Limited opportunities for hands-on experience: EA cause areas provide limited opportunities for individuals to gain experience in grantmaking.</li>\n<li>Insufficient management capacity: EA Funds lacks sufficient management capacity from experienced grantmakers, leading to potential operational inefficiencies.</li>\n<li>High opportunity cost for potential grantmakers: Many prospective grantmakers have many alternative options for their time and could contribute to other valuable projects instead.</li>\n<li>Perceived career limitation due to EA affiliation: The strong association with EA might discourage some potential candidates, as they worry it could limit their future career opportunities.</li>\n</ul>\n <a href=\"#fnref-Frur7HS8hrB56Acyb-5\" class=\"footnote-backref\">\u21a9\ufe0e</a></li>\n<li id=\"fn-Frur7HS8hrB56Acyb-6\" class=\"footnote-item\"><p>I have also invested relatively little time in stewarding donors - instead, prioritising increasing the number of promising applications and improving our grantmaking. <a href=\"#fnref-Frur7HS8hrB56Acyb-6\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-Frur7HS8hrB56Acyb-7\" class=\"footnote-item\"><p>In the sense that we are confident we can distribute this amount of funding to projects we deem to be above the current funding bar. <a href=\"#fnref-Frur7HS8hrB56Acyb-7\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-Frur7HS8hrB56Acyb-8\" class=\"footnote-item\"><p>In the sense that we are confident we can distribute this amount of funding to projects we deem to be above the current funding bar. <a href=\"#fnref-Frur7HS8hrB56Acyb-8\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-Frur7HS8hrB56Acyb-9\" class=\"footnote-item\"><p>From Claire Zabel - \u201cWe think this would run the risk of making Funds <strong>more</strong> dependent on current major donors, which goes against our intent.\u201d. <a href=\"#fnref-Frur7HS8hrB56Acyb-9\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n</ol>\n</section>\n", "user": {"username": "calebp"}}, {"_id": "zZ2vq7YEckpunrQS4", "title": "Long-Term Future Fund: April 2023 grant recommendations", "postedAt": "2023-08-02T01:31:39.530Z", "htmlBody": "<h1>Introduction</h1><p>This payout report is meant to cover the Long-Term Future Fund's grantmaking starting January 2022 (after our December 2021 payout report), going through April 2023 (1 January 2022 - 30 April 2023).</p><ul><li><strong>Total funding recommended:&nbsp;</strong>$13.0M</li><li><strong>Total funding paid out:</strong> $12.16M</li><li><strong>Number of grants paid out:&nbsp;</strong>327</li><li><strong>Acceptance rate</strong> (excluding desk rejections): 50.0%&nbsp;&nbsp;</li><li><strong>Acceptance rate</strong> (including desk rejections): 37.4%</li><li><strong>Report authors:</strong> Asya Bergal (chair), Linchuan Zhang, Oliver Habryka, Caleb Parikh, Thomas Larsen, Matthew Graves</li></ul><p>52 of our grantees, worth $1.41M, requested that we not include public reports for their grants. (You can read our policy on public reporting&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/LKdtHdETxSYAXwoW6/public-reports-are-now-optional-for-ea-funds-grantees\"><u>here</u></a>.) We referred 2 grants to other funders for evaluation ($0.501M). Our median response time over this period was 29 days.</p><p>The rest of our grants are listed below (either in long or short form), as well as in our&nbsp;<a href=\"https://funds.effectivealtruism.org/grants?fund=Long-Term%2520Future%2520Fund&amp;sort=round\"><u>public grants database</u></a>.</p><p>If you\u2019re interested in receiving funding from the Long-Term Future Fund,&nbsp;<a href=\"https://funds.effectivealtruism.org/apply-for-funding\"><strong><u>apply here</u></strong></a><strong>.</strong></p><p><i>(Note: The initial sections of this post were written by me, Asya Bergal.)</i></p><h2>Other updates</h2><p>We've had a substantial increase in applications since 2021-- we averaged 35 applications per month in the latter half of 2021, 69 applications per month in 2022, and 90 applications per month so far in 2023.</p><p>Our funding bar went up at the end of 2022, in response to a decrease in the overall funding available to long-term future-focused projects. If we assume our numerical ratings are consistent, then applying our new bar to our earlier 2022 funding would imply not having funded 28% of earlier grants.</p><p><strong>We're looking for more funding.</strong>&nbsp;We've spent an average of ~$1M per month across March, April, and May 2023 to maintain our current bar, have $992,870.53 in reserves as of July 3, and are ideally looking to fundraise at least $10M for the coming year.</p><p>As described in <a href=\"https://forum.effectivealtruism.org/posts/zt6MsCCDStm74HFwo/ea-funds-organisational-update-open-philanthropy-matching\">this post</a>, we're trying to increase our independence from Open Philanthropy, which provided ~45% of our funding in 2022. As a transitional measure, over the next 6 months, Open Philanthropy will be matching funding given to the Long-Term Future Fund by small donors 2:1, for up to $3.5M total, making now a particularly good time to donate.&nbsp;<a href=\"https://www.givingwhatwecan.org/charities/long-term-future-fund\"><strong>Donate here</strong>.</a> (The Long-Term Future Fund is part of EA Funds, which is a fiscally sponsored project of Effective Ventures Foundation (UK) (EV UK) and Effective Ventures Foundation USA Inc. (EV US). Donations to the Long-Term Future Fund are donations to EV US or EV UK.)</p><p>As a temporary measure in response to uncertainty about our future funding levels, we\u2019ve put the bottom ~40% of grants above our current funding bar on hold. I think we\u2019ll make several of those grants after this round of fundraising is over, but I generally expect our funding bar to vary more over time and to depend more on individual donations than it has historically.</p><p><strong>I will be stepping down as chair of the fund by the end of Octobe</strong>r (and potentially earlier)-- I've written some reflections on my time on the fund <a href=\"https://forum.effectivealtruism.org/posts/9vazTE4nTCEivYSC6/reflections-on-my-time-on-the-long-term-future-fund\">here</a>. We're looking for additional fund managers (including potential chair candidates)--&nbsp;<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSdonKXDxzxCWFYX27cAE29OJ6mIGtmr11RFbXJ29dC0fh35jA/viewform?usp=sf_link\"><strong>express interest here</strong></a>.</p><p>The fund's current fund managers are me (Asya Bergal), Linchuan Zhang, Oliver Habryka, and Caleb Parikh as permanent fund managers, and Thomas Larsen, Daniel Eth, Matthew Gray, Lauro Langosco, and Clara Collier as&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/ek5ZctFxwh4QFigN7/ea-funds-has-appointed-new-fund-managers#Guest_managers\"><u>guest managers</u></a>.</p><p>Our legal team asked us to highlight the eligibility criteria for our grants, which you can find in the appendices.</p><h1>Highlights</h1><p>Our grants include:</p><ul><li><a href=\"https://forum.effectivealtruism.org/posts/zZ2vq7YEckpunrQS4/long-term-future-fund-april-2023-grant-recommendations#SERI_MATS_program___316_000___8_weeks_scholars_program_to_pair_promising_alignment_researchers_with_renowned_mentors___Originally_evaluated_by_Asya_Bergal_\"><strong><u>$316,000 in June 2022</u></strong></a><strong>&nbsp;</strong>to support&nbsp;<a href=\"https://www.serimats.org/\"><u>SERI MATS</u></a>, an 8-week scholar program that pairs promising alignment researchers with mentors in the alignment field.&nbsp;</li><li><a href=\"https://forum.effectivealtruism.org/posts/zZ2vq7YEckpunrQS4/long-term-future-fund-april-2023-grant-recommendations#Alignment_Research_Center__54_543__Support_for_a_research___networking_event_for_winners_of_the_Eliciting_Latent_Knowledge_contest\"><strong><u>$72,000 in July 2022</u></strong></a> for a research and networking retreat for winners of the&nbsp;<a href=\"https://www.serimats.org/\"><u>Eliciting Latent Knowledge contest</u></a>.</li><li><a href=\"https://forum.effectivealtruism.org/posts/zZ2vq7YEckpunrQS4/long-term-future-fund-april-2023-grant-recommendations#Stephen_Grugett__James_Grugett__Austin_Chen___200_000___4_month_stipend_for_3_FTE_to_build_a_forecasting_platform_made_available_to_the_public_based_on_user_created_play_money_prediction_markets\"><strong><u>$200,000 in February 2022</u></strong></a> to support Stephen Grugett, James Grugett, and Austin Chen for 4 months to build a forecasting platform (<a href=\"https://funds.effectivealtruism.org/apply-for-funding\"><u>Manifold Markets</u></a>) based on user-created play-money prediction markets.</li></ul><h1>Payout reports</h1><h2>Longer grant write-ups</h2><h3>Grants evaluated by Linchuan Zhang</h3><p><strong>Stephen Grugett, James Grugett, Austin Chen ($200,000): 4 month stipend for 3 FTE to build a forecasting platform made available to the public based on user-created play-money prediction markets</strong></p><ul><li>March 2022 Notes by Linch Zhang: This was my first substantive grant investigation. At the time, I felt shaky about it, but now I feel really good about it. The two main reasons I originally recommended this grant:<ul><li>1. It was an investment into the people who wanted to do EA work \u2013 getting 3 ~Google-quality engineers to do more EA/longtermist work (as opposed to counterfactuals that were earning to give or worse) seems well worth it at 200k.&nbsp;</li><li>2. It was an investment into the team specifically. Having cohesive software teams seems like an important component for EA becoming formidable in the future, and is somewhat (surprisingly to me) missing in EA, especially outside of AI safety and crypto trading. I heard really good things about Manifold from early users, and they appeared to be developing at a speed that blew other software projects in forecasting (Metaculus, Foretold, Cultivate, Hypermind, etc) out of the water.</li><li>At the time, it was not an investment into the prediction market itself/theory of change with regards to play-money prediction markets broadly, because the above two factors were sufficient to be decisive.</li><li>At the time, it was also unclear whether they plan to go the for-profit route or the nonprofit route.<ul><li>They\u2019ve since decided to go the for-profit route.</li></ul></li><li>Looking back, still too soon to be sure, but it looks like Manifold is going quite well. Continue to develop features at phenomenal speeds, lots of EAs and others in adjacent communities use the product, team is still producing fast and are excited for the future.<ul><li>From an \u201cinvestment into team\u201d perspective, I think Manifold now plausibly has the strongest software team in EA outside of AI safety and earning-to-give (not that I\u2019d necessarily have enough visibility to know of all the potentially better teams, especially stealth ones).</li><li>I have a number of disjunctive ToCs for how Manifold (and forecasting in general) can over time make the future better, some of which is implicitly covered&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/E5vp2LCEfkrrLWozJ/potentially-great-ways-forecasting-can-improve-the-longterm\"><u>here</u></a>.&nbsp;</li><li>Though I am still uncertain about whether this particular project is the best use of the cofounders + team\u2019s time...a lot of the evidence I have to observe this is more an update on the team\u2019s overall skill + cohesiveness rather than an update about their comparative advantage for prediction markets specifically.&nbsp;</li></ul></li></ul></li><li>Addendum June 2023:<ul><li>I\u2019ve grown more confused about the total impact or value of this grant. On the one hand, I think Manifold is performing at or moderately above expectations in terms of having a cohesive team that\u2019s executing quickly, and many people in the community appear to find their product useful or at least interesting. On the other hand, the a) zero-interest-rate environment and corresponding high startup evaluations when I recommended this grant has ended in early 2022, and b) recent events have reduced a substantial fraction of EA funding, which meant 200K is arguably much more costly now than a year ago.</li><li>Still, I think I\u2019m broadly glad to have Manifold in our ecosystem. I think they\u2019re very helpful for people in our and adjacent communities in training epistemics, and I\u2019m excited to see them branch out into experiments in regranting and retroactive funding projects; from a first-principles perspective, it\u2019d be quite surprising if the current status of EA grantmaking is sufficiently close to optimal.</li></ul></li></ul><p><strong>Solomon Sia ($71,000): 6-month stipend for providing consultation and recommendations on changes to the US regulatory environment for prediction markets.</strong></p><ul><li>Solomon Sia wants to talk to a range of advisers, including industry experts, users, and contacts at the CFTC, to see if there are good improvements in ways to regulate prediction markets in the US, while simultaneously protecting users and reducing regulatory risk and friction.</li><li>This was an exploratory grant for seeing how it\u2019s possible to improve the US regulatory environment for prediction markets with a resulting written report provided to EA Funds.</li><li>I think this is a reasonable/great option to explore:&nbsp;<ul><li>I think my position on prediction markets is somewhat more cynical than that of most EAs in the forecasting space, but still, I\u2019m broadly in favor of them and think they can be a critical epistemic intervention, both for uncovering new information and for legibility/common knowledge reasons.</li><li>It seemed quite plausible to me that the uncertain regulatory environment for prediction markets in the US is impeding the growth of large real-money prediction markets on questions that matter.</li><li>Solomon seemed unusually competent and knowledgeable about the tech regulations space, a skillset very few EAs have.<ul><li>Cultivating this skillset and having him think about EA issues seemed valuable.&nbsp;</li><li>A potential new caveat is that in 2023 as AI risk worries heat up, it seems increasingly likely that we might be able to draw from a diverse skillset of experienced and newly interested/worried people.</li></ul></li><li>The for-profit motivations for this work are there but not very large, as unless a company is trying very hard to do specific regulatory capture for their company (which is bad and also practically very difficult), easing prediction market regulations has collective benefits and individual costs.</li><li>(weakly held) I thought trying to nail this during the Biden administration is good because it seemed plausible that the current CFTC will be more predisposed to liking prediction markets than average for the CFTC.<ul><li>One interesting update is that EA connections are likely a mild plus in 2022, and a moderate liability in 2023.</li><li>NB: Solomon and his collaborator think a) that the EA connection is still a mild to moderate positive b) it\u2019s now unclear whether the Biden administration is better or worse than a counterfactual Republican administration.&nbsp;</li></ul></li></ul></li><li>I\u2019ve thought about this grant some afterwards, and I think even with the benefit of hindsight, I'm still a bit confused about how happy I should be about this grant ex-post.<ul><li>One thing is that I\u2019ve grown a bit more confused about the output and tractability of interventions in this domain.<ul><li>The successes(?) Kalshi had confused me and I haven\u2019t had enough time to integrate this into my worldview.</li><li>My current impression is that CFTC is fairly open to informed opinions from others on this matter.</li></ul></li><li>I continue to believe it\u2019s a good grant ex-ante.</li></ul></li></ul><h3>Grants evaluated by Oliver Habryka</h3><p><strong>Alexander Turner ($220,000):&nbsp;Year-long stipend for shard theory and RL mechanistic interpretability research</strong></p><p><i>This grant has been approved but has not been paid out at the time of writing.</i></p><p>We\u2019ve made grants to Alex to pursue AI Alignment research before:</p><ul><li><a href=\"https://funds.effectivealtruism.org/payouts/april-2019-long-term-future-fund-grants-and-recommendations#alex-turner-30000\"><u>2019: Building towards a \u201cLimited Agent Foundations\u201d thesis on mild optimization and corrigibility</u></a></li><li>2020: Understanding when and why proposed AI designs seek power over their environment&nbsp;<strong>($30,000)</strong></li><li>2021: Alexander Turner - Formalizing the side effect avoidance problem&nbsp;<strong>($30,000)</strong></li><li>2022: Alexander Turner - 12-month stipend supplement for CHAI research fellowship&nbsp;<strong>($31,500)</strong></li></ul><p>We also made another grant in 2023 to a team led by Alex Turner for their post&nbsp;<a href=\"https://www.lesswrong.com/posts/5spBue2z2tw4JuDCx/steering-gpt-2-xl-by-adding-an-activation-vector\"><u>on steering vectors</u></a> for&nbsp;<strong>$115,411</strong> (total includes payment to 5 team members, including, without limitation, travel expenses, office space, and stipends)<strong>.</strong></p><p>This grant is an additional grant to Alex, this time covering his full-time stipend for a year to do more research in AI Alignment.</p><p>Only the first one has a public grant write-up, and the reasoning and motivation behind all of these grants is pretty similar, so I will try to explain the reasoning behind all of them here.&nbsp;</p><p>As is frequently the case with grants I evaluate in the space of AI Alignment, I disagree on an inside-view level pretty strongly with the direction of the research that Alex has been pursuing for most of his AI Alignment career. Historically I have been, on my inside-view, pretty unexcited about Alex\u2019s work on formalizing power-seekingness, and also feel not that excited about his work on shard theory. Nevertheless, I think these are probably among the best grants the LTFF has made in recent years.&nbsp;</p><p>The basic reasoning here is that despite me not feeling that excited about the research directions Alex keeps choosing, within the direction he has chosen, Alex has done quite high-quality work, and also seems to often have interesting and useful contributions in online discussions and private conversations. I also find his work particularly interesting, since I think that within a broad approach I often expected to be fruitless, Alex has produced more interesting insight than I expected. This in itself has made me more interested in further supporting Alex, since someone producing work that shows that I was at least partially wrong about a research direction being not very promising is more important to incentivize than work whose effects I am pretty certain of.</p><p>I would like to go into more detail on my models of how Alex\u2019s research has updated me, and why I think it has been high quality, but I sadly don\u2019t have the space or time here to go into that much depth. In-short, the more recent steering vector work seems like the kind of \u201cobvious thing to try that could maybe help\u201d that I would really like to saturate with work happening in the field, and the work on formalizing power-seeking theorems is also the kind of stuff that seems worth having done, though I do pretty deeply regret the overly academic/formal presentation which has somewhat continuously caused people to overinterpret the strength of its results (which Alex also seems&nbsp;<a href=\"https://www.lesswrong.com/posts/dqSwccGTWyBgxrR58/turntrout-s-shortform-feed?commentId=Sw89AxHGJ5j7E7ETf\"><u>to have regretted</u></a>, and is also a pattern I have frequently observed in academic work that was substantially motivated by trying to \u201clegitimize the field\u201d).</p><p>Another aspect of this grant that I expect to have somewhat wide-ranging consequences is the stipend level we set on. Some basic principles that have lead me to suggest this stipend level:&nbsp;</p><ul><li>I have been using the anchor of \u201cindustry stipend minus 30%\u201d as a useful heuristic for setting stipend levels for LTFF grants. The goal in that heuristic was to find a relatively objective standard that would allow grantees to think about stipend expectations on their own without requiring a lot of back and forth, while hitting a middle ground in the incentive landscape between salaries being so low that lots of top talent would just go into industry instead of doing impactful work, and avoiding grifter problems with people asking for LTFF grants because they expect they will receive less supervision and can probably get away without a ton of legible progress.</li><li>In general I think self-employed salaries should be ~20-40% higher, to account for additional costs like health insurance, payroll taxes, administration overhead, and other things that an employer often takes care of.</li></ul><p>I have been rethinking stipend policies, as I am sure many people in the EA community have been since the collapse of FTX, and I haven\u2019t made up my mind on the right principles here. It does seem like a pretty enormous number of good projects are no longer having the funding to operate at their previous stipend levels, and it\u2019s plausible to me that we should take the hit, lose out on a bunch of talent, and reduce stipend levels to a substantially lower level again to be more capable of handling funding shocks. But I am really uncertain on this, and at least in the space of AI Alignment, I can imagine the recent rise to prominence of AI Risk concerns could potentially alleviate funding shortfalls (or it could increase competition by having more talent flow into the space, which could reduce wages, which would also be great).&nbsp;</p><p><i>See the Stipend Appendix below, \u201cHow we set grant and stipend amounts\u201d, for more information on EA Funds\u2019 determination of grant and stipend amounts.</i></p><p><strong>Vanessa Kosoy ($100,000): Working on the learning-theoretic AI alignment research agenda</strong></p><p>This is a grant to cover half of Vanessa\u2019s stipend for two years (the other half being paid by&nbsp;<a href=\"https://intelligence.org/\"><u>MIRI</u></a>). We also made another grant to Vanessa in Q4 2020 for a similar amount.&nbsp;</p><p>My model of the quality of Vanessa\u2019s work is primarily indirect, having engaged relatively little with the central learning-theoretic agenda that Vanessa has worked on. The work is also quite technically dense, and I haven\u2019t found anyone else who could explain the work to me in a relatively straightforward way (though I have heard that Daniel Filan\u2019s AXRP podcast with Vanessa is a better way to get started than previous material, though it hadn\u2019t been published when I was evaluating this grant).&nbsp;</p><p>I did receive a decent number of positive references for Vanessa\u2019s work, and I have seen her&nbsp;<a href=\"https://www.alignmentforum.org/users/vanessa-kosoy/replies\"><u>make contributions to other conversations online</u></a> that struck me as indicative of a pretty deep understanding of the AI Alignment problem.&nbsp;</p><p>If I had to guess at the effects of this kind of work, though I should clarify I am substantially deferring to other people here in a way that makes me not particularly trust my specific predictions, I expect that the primary effect would be that the kind of inquiry Vanessa is pursuing highlights important confusions and mistaken assumptions in how we expect machine intelligence to work, which when resolved, will make researchers better at navigating the very large space of potential alignment approaches. I would broadly put this in the category of&nbsp;<a href=\"https://www.lesswrong.com/tag/deconfusion\"><u>\u201cDeconfusion Research\u201d</u></a>.</p><p><i>Vanessa\u2019s research resulted in various public blog posts, which can be found&nbsp;</i><a href=\"https://www.alignmentforum.org/users/vanessa-kosoy\"><i><u>here</u></i></a><i>.</i>&nbsp;</p><p><strong>Skyler Crossman ($22,000): Support for Astral Codex Ten Everywhere meetups</strong></p><p>Especially since the collapse of FTX, I am quite interested in further diversifying the set of communities that are working on things I think are important to the future.&nbsp;<a href=\"https://astralcodexten.substack.com/\"><u>AstralCodexTen</u></a> and&nbsp;<a href=\"http://slatestarcodex.com/\"><u>SlateStarCodex</u></a> meetups seem among the best candidates for creating additional thriving communities with overlapping, but still substantially different norms.&nbsp;</p><p>I do feel currently quite confused about what a good relationship between adjacent communities like this and Effective Altruism-labeled funders like the Long Term Future Fund should be. Many of these meetups do not aim to do as much as good as possible, or have much of an ambitious aim to affect the long term future of humanity, and I think pressures in that direction would likely be more harmful than helpful, by introducing various incentives for deception and potentially preventing healthy local communities from forming by creating a misaligned relationship between the organizers (who are paid by EA institutions to produce as much talent for longtermist priorities) and the members (who are interested in learning cool things about rationality and the world and want to meet other people with similar interests).&nbsp;</p><p>Since this is a relatively small grant, I didn\u2019t really resolve this confusion, and mostly decided to just go ahead with this. I also talked a bunch to Skyler about this, and currently think we can figure out a good relationship into the future on how it\u2019s best to distribute funding like this, and I expect to think more about this in the coming weeks.</p><h3>Grants evaluated by Asya Bergal</h3><p><i>Any views expressed below are my personal views, and not the views of my employer, Open Philanthropy. (In particular, getting funding from the Long-Term Future Fund should not be read as an indication that the applicant has a greater chance of receiving funding from Open Philanthropy, and not receiving funding from the Long-Term Future Fund [or any risks and reservations noted in the public payout report] should not be read as an indication that the applicant has a smaller chance of receiving funding from Open Philanthropy.)</i></p><p><strong>Alignment Research Center $54,543: Support for a research &amp; networking event for winners of the Eliciting Latent Knowledge contest</strong></p><ul><li>This was funding a research &amp; networking event for the winners of the<a href=\"https://www.lesswrong.com/posts/QEYWkRoCn4fZxXQAY/prizes-for-elk-proposals\">&nbsp;<u>Eliciting Latent Knowledge contest</u></a> run in early 2022; the plan for the event was mainly for it to be participant-led, with participants sharing what they were working on and connecting with others, along with professional alignment researchers visiting to share their own work with participants.</li><li>I think the case for this grant is pretty straightforward: the winners of this contest are (presumably) selected for being unusually likely to be able to contribute to problems in AI alignment, and retreats, especially those involving interactions with professionals in the space, have a strong track record of getting people more involved with this work.</li></ul><p><strong>Daniel Filan ($23,544):&nbsp; Funding to produce 12 more AXRP episodes, the AI X-risk Podcast.&nbsp;</strong></p><p>We recommended a grant of $23,544 to pay Daniel Filan for his time making 12 additional episodes of&nbsp;<a href=\"https://axrp.net/\"><u>the AI X-risk Research Podcast (AXRP)</u></a>, as well as the costs of hosting, editing, and transcription.</p><p>The reasoning behind this grant was similar to the reasoning behind&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/diZWNmLRgcbuwmYn4/long-term-future-fund-may-2021-grant-recommendations#Daniel_Filan____5_280\"><u>my last grant to AXRP</u></a>:&nbsp;</p><ul><li>&nbsp;I\u2019ve listened or read through several episodes of the podcast; I thought Daniel asked good questions and got researchers to talk about interesting parts of their work. I think having researchers talk about their work informally can provide value not provided by papers (and to a lesser extent, not provided by blog posts). In particular:</li><li>&nbsp;I\u2019ve personally found that talks by researchers can help me understand their research better than reading their academic papers (e.g.&nbsp;<a href=\"https://www.youtube.com/watch?v=QMqPAM_knrE\"><u>Jared Kaplan\u2019s talk</u></a> about his scaling laws paper). This effect seems to have also held for&nbsp;<a href=\"https://www.lesswrong.com/posts/FkMPXiomjGBjMfosg/axrp-episode-5-infra-bayesianism-with-vanessa-kosoy?commentId=WpEj9ZiAmrXQCDQPu#comments\"><u>at least one listener</u></a> of Daniel\u2019s podcast.</li><li>&nbsp;Informal conversations can expose motivations for the research and relative confidence level in conclusions better than published work.</li></ul><p>Daniel also shared&nbsp;<a href=\"https://www.lesswrong.com/posts/rXSBvSKvKdaNkhLeJ/takeaways-from-a-survey-on-ai-alignment-resources\"><u>some survey data</u></a> in his grant application about how people rated AXRP compared to other AI alignment resources, though I didn't look at this closely when making the grant decision, as I already had a reasonably strong prior towards funding.</p><h3>Grants evaluated by Caleb Parikh</h3><p><strong>Conjecture ($72,827): Funding for a 2-day workshop to connect alignment researchers from the US, UK, and AI researchers and entrepreneurs from Japan.</strong></p><ul><li>Conjecture applied for funding to host a two day AI safety workshop in Japan in collaboration with Araya (a Japanese AI company). They planned to invite around 40 people, with half of the attendees being AI researchers, and half being alignments researchers from the US and UK. Japanese researchers were generally senior, leading labs, holding postdoc positions in academia, or holding senior technical positions at tech companies.</li><li>To my knowledge, there has been very little AI safety outreach conducted amongst strong academic communities in Asia (e.g. in Japan, Singapore, South Korea \u2026). On the current margin, I am excited about more outreach being done in these countries within ultra-high talent groups. The theory of change for the grant seemed fairly straightforward: encourage talented researchers who are currently working in some area of AI to work on AI safety, and foster collaborations between them and the existing alignment community.</li><li>Conjecture shared the invite list with me ahead of the event, and I felt good about the set of alignment researchers invited from the UK and US. I looked into the Japanese researchers briefly, but I found it harder to gauge the quality of invites given my lack of familiarity with the Japanese AI scene. I also trust Conjecture to execute operationally competently on events of this type, having assisted other AI safety organisations (such as SERI MATS) in the past.</li><li>On the other hand, I have had some concerns about Conjecture, and I felt confused about whether this conference gave Conjecture more influence in ways that I would feel concerned about given the questionable integrity and judgement of their CEO,&nbsp; - see&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/gkfMLX4NWZdmpikto/critiques-of-prominent-ai-safety-labs-conjecture#Conjecture_and_their_CEO_misrepresent_themselves_to_various_parties\"><u>this</u></a> and&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/gkfMLX4NWZdmpikto/critiques-of-prominent-ai-safety-labs-conjecture#Contributions_to_race_dynamics\"><u>this</u></a> section of a critique of their organisation (though note that I don\u2019t necessarily endorse the rest of the post). It was also unclear to me how counterfactual the grant was, and how this traded off against activities that I would be less excited to see Conjecture run. I think this is a general issue with funding projects at organisations with flexible funding, as organisations are incentivised to present their most fundable projects (which they are also the most excited about), and then in cases where the funding request is successful, move funding that they would have spent on this projects to other lower impact projects. Overall, I modelled making this grant as being about a quarter as cost-effective as it might have been without these considerations (though I don\u2019t claim this discount factor to be particularly reliable).</li><li>Overall, I thought this grant was pretty interesting, and I think that the ex-ante case for it was pretty solid. I haven\u2019t reviewed the outcomes of this grant yet, but I look forward to reviewing and potentially making more grants in this area.</li><li>Update: Conjecture kindly directed me towards&nbsp;<a href=\"https://www.lesswrong.com/posts/Yc6cpGmBieS7ADxcS/japan-ai-alignment-conference-postmortem\"><u>this</u></a> retrospective and have informed me that some Japanese attendees of their conference are thinking of creating an alignment org.</li></ul><p><strong>SERI MATS program ($316,000): 8 weeks scholars program to pair promising alignment researchers with renowned mentors. (Originally evaluated by Asya Bergal)</strong></p><ul><li>SERI MATS is a program that helps established AI safety researchers find mentees. The program has grown substantially since we first provided funding, and now supports 15 mentors, but at the time, the mentors were Alex Gray, Beth Barnes, Evan Hubinger, John Wentworth, Leo Gao, Mark Xu, and Stuart Armstrong. Mentors took part in the program in Berkeley in a shared office space.</li><li>When SERI MATS was founded, there were very few opportunities for junior researchers to try out doing alignment research. Many opportunities were informal mentorship positions, sometimes set up through cold emails or after connecting at conferences. The program has generally received many more qualified applicants than they have places for, and the vast majority of fellows report a positive experience of the program. I also believe the program has substantially increased the number of alignment research mentorship positions available.</li><li>I think that SERI MATS is performing a vital role in building the talent pipeline for alignment research. I am a bit confused about why more organisations don\u2019t offer larger internship programs so that the mentors can run their programs \u2018in-house\u2019. My best guess is that MATS is much better than most organisations running small internship programs for the first time, particularly in supporting their fellows holistically (often providing accommodation and putting significant effort into the MATS fellows community). One downside of the program relative to an internship at an organisation is that there are fewer natural routes to enter a managed position, though many fellows have gone on to receive LTFF grants for independent projects or continued their mentorship under the same mentor.</li></ul><p><strong>Robert Long ($10,840): travel funding for participants in a workshop on the science of consciousness and current and near-term AI systems</strong></p><p><i>Please note this grant has been approved but at the time of writing it has not been paid out.</i></p><ul><li>We funded Robert Long to run a workshop on the science of consciousness for current and near-term AI systems. Robert and his FHI colleague, Patrick Butlin, began the project on consciousness in near-term AI systems during their time at FHI, where they both worked in the digital minds research group. Since January of this year, Rob has been continuing the project while a philosophy fellow at CAIS.&nbsp; There are surprisingly few people investigating the consciousness of near-term AI systems, which I find pretty worrying given the rapid pace of progress in ML. I think that it\u2019s plausible we end up creating many copies of AI systems and use them in ways that we\u2019d consider immoral given enough reflection , in part due to ignorance about their preferences. The workshop aimed to produce a report applying current theories of consciousness (like integrated information theory and global workspace theory) to current ml systems.</li><li>I think that Rob is an excellent fit for this kind of work; he is one of the few people working in this area and has written quite a lot about AI consciousness on his blog. He has a PhD in philosophy from NYU, where he was advised by David Chalmers, and has experience running workshops (e.g. in 2020, he ran a workshop on philosophy and large language models with Amanda Askell).</li></ul><p><strong>Jeffrey Ladish ($98,000):&nbsp;6-month</strong> <strong>stipend &amp; operational expenses to start a cybersecurity &amp; alignment risk assessment org</strong></p><p><i>Please note this grant has been approved but at the time of writing it has not been paid out.</i></p><ul><li>Jeffrey Ladish applied for funding to set up an organisation to do AI risk communications,&nbsp; with a focus on cybersecurity and alignment risks. His organisation,&nbsp;<a href=\"https://palisaderesearch.org/\"><u>Palisade Research Inc.</u></a>, plans to conduct risk assessments and communicate those risks to the public, labs and the government. The theory of change is that communicating catastrophic risks to the public and key decision makers could increase political support for slowing down AI and other measures that might reduce AI risk. I am particularly excited about Jeffrey\u2019s organisation demonstrating offensive AI cyber capabilities and other demos that help to communicate current risks from advanced AI systems.</li><li>I am pretty excited about Jeffrey\u2019s organisation. He has worked on information security in various organisations (including Anthropic), he seems well-networked amongst people working in think tanks and AI labs,<strong>&nbsp;</strong>and I like his public writing on AI risk. I am generally sceptical of people doing work related to policy without having first worked in lower stakes positions in similar areas first, but I thought that Jeffrey was orienting to the downsides very reasonably and doing the sensible things, like developing plans with more experienced policy professionals.</li></ul><h3>Grants evaluated by Matthew Gray</h3><p><strong>Leap Laboratories ($195,000):&nbsp;One year of seed funding for a new AI interpretability research organisation.</strong></p><ul><li>Jessica Rumbelow applied for seed funding to set up an interpretability research organisation, which hopes to develop a model-agnostic interpretability engine.</li><li>I\u2019m excited about this grant primarily based on the strength of&nbsp;<a href=\"https://www.lesswrong.com/posts/aPeJE8bSo6rAFoLqg/solidgoldmagikarp-plus-prompt-generation\"><u>research work she did with Matthew Watkins during SERI-MATS</u></a>, discovering anomalous tokens like SolidGoldMagikarp.</li><li>I think trends in the AI development space suggest a need for model-agnostic methods.</li><li>More broadly, I think this showcases one of the primary benefits of interpretability research: it\u2019s grounded in a way that makes it easy to verify and replicate.&nbsp;&nbsp;</li></ul><p><strong>Daniel Kokotajlo ($10,000): Funding for a research retreat on a decision-theory/cause-prioritisation topic.</strong></p><ul><li>We funded a research retreat run by Daniel Kokotajlo on Evidential Cooperation in Large Worlds. I think research retreats like this are both quite productive and quite cheap; we only have to pay for travel and housing costs, and the attendees are filtered on intrinsic interest in the topic.<br>&nbsp;</li></ul><h3>Grants evaluated by Thomas Larsen</h3><p><strong>Kaarel H\u00e4nni, Kay Kozaronek, Walter Laurito, and Georgios Kaklmanos ($167,480): Implementing and expanding on the research methods of the&nbsp; \"Discovering Latent Knowledge\" paper.&nbsp;</strong></p><p>This is a team which started in SERI MATS applying for funding to continue their SERI MATS project on research checking for dishonesty in advanced AI systems.&nbsp;</p><p>My cruxes for this type of grant are:&nbsp;</p><p>(1) If done successfully, would this project help with alignment?</p><p>(2) How likely is this team to be successful?&nbsp;</p><p>My thoughts on (1):&nbsp;</p><p>This is meant to build upon Burns\u2019 et al.'s&nbsp;<a href=\"https://arxiv.org/abs/2212.03827\"><u>Discovering Latent Knowledge paper</u></a> (DLK), which finds a direction in activation space that is supposed to represent the 'truth' of a logical proposition.&nbsp;</p><p>I think that&nbsp;<a href=\"https://www.lesswrong.com/posts/qHCDysDnvhteW7kRd/arc-s-first-technical-report-eliciting-latent-knowledge\"><u>Eliciting Latent Knowledge</u></a> (ELK) is an important subproblem of alignment, and I think it can be directly applied to combat deceptive alignment. My independent impression is that this specific direction towards solving ELK is not very useful towards a full alignment solution, but that it may lead to slightly better monitoring. (In particular, I think even in a good outcome, this will only lead to an average case solution to ELK, meaning that when we explicitly train against this detector, it will fail.) I expect that AGI projects will be in a position where it's obvious that the systems they are building are capable and dangerous, and it will be apparent that instrumental incentives kick in for e.g. powerseeking and deception. I think that this technique might help us detect this danger, but given that we can't train against it, it doesn't let us actually fix the underlying problem. Thus, the lab will be in the difficult position of continuing on, or having to train against their detection system. I still think that incremental progress on detecting deception is good, because it can help push for a stop in capabilities growth before prematurely continuing to AGI.&nbsp;</p><p>My thoughts on (2):&nbsp;</p><p>They produced reasonable output during SERI MATS, including the beginning of a replication of the DLK paper. They weren't that specific in their grant application, but they wrote a number of ideas for ways to extend the paper in<a href=\"https://www.lesswrong.com/posts/bFwigCDMC5ishLz7X/rfc-possible-ways-to-expand-on-discovering-latent-knowledge#Potential_directions\"><u> the LW post</u></a>. The two ideas that seem best to me are:</p><ol><li>Connecting DLK to mechanistic interpretability. This seems hard, but maybe tinkering around in activation space can be helpful.&nbsp;</li><li>Creating a better confidence loss. In the original paper, only one statement was considered, and so the loss was coming from the constraint that P(q) + P(not q) = 1. They propose evaluating two propositions p &amp; q, and getting more constraints from that.&nbsp;</li></ol><p>These ideas don't seem amazing, but they seem like reasonable things to try. I expect that the majority of the benefit will come from staring at the model internals and the results of the techniques and then iterating. I hope that this process will churn out more and better ideas.&nbsp;</p><p>One reservation I have is that none of the applicants have an established research track record, though they have published several papers:&nbsp;</p><p>- <a href=\"https://arxiv.org/search/math?searchtype=author&amp;query=H%C3%A4nni%2C+K\">Kaarel's Arxiv page</a></p><p>- <a href=\"https://scholar.google.com/citations?user=3g35nyYAAAAJ&amp;hl=en\">Walter's Google Scholar Profile</a></p><p>- <a href=\"https://&nbsp;https://orcid.org/0000-0003-3854-3150\">Georgios's ORCID</a></p><p>This team did get strong references from Colin Burns and John Wentworth, which makes me a lot more excited about the project. All things considered, I'm excited about giving this team a chance to work on this project, and see how they are doing. I'm also generally enthusiastic about teams trying their hand at alignment research.&nbsp;</p><p><strong>Joseph Bloom ($50,000):&nbsp;Funding AI alignment research into circuits in decision transformers.&nbsp;</strong></p><p>Joseph applied for independent research funding to continue his research into decision transformer interpretability. I'm happy about&nbsp;<a href=\"https://www.lesswrong.com/posts/bBuBDJBYHt39Q5zZy/decision-transformer-interpretability\"><u>Joseph's initial result</u></a>, which found circuits in a decision transformer in a simple RL environment. I thought the applicant's write up was solid and gave me some updates on what cognitive machinery I expect to be induced by RL. In particular, I was excited about the preference directions in embedding space that they constructed. This seems like a useful initial step for&nbsp;<a href=\"https://www.lesswrong.com/posts/w4aeAFzSAguvqA5qu/how-to-go-from-interpretability-to-alignment-just-retarget\"><u>retargeting the search</u></a>, though more understanding of the circuits that are doing the optimization seems critical for this approach.</p><p>&nbsp;I think interpretability on RL models is pretty neglected and very relevant for safety.&nbsp;</p><p>According to a reference, the applicant was also in the top 3 ARENA participants, and was very motivated and agentic.&nbsp;</p><p>The counterfactual is that Joseph tries to get funding elsewhere, and if that fails, getting a research engineer job at an AI safety org (e.g. Redwood, Conjecture, Ought, etc). I encouraged this person to apply to the AI safety orgs, as I think that working at an org is generally more productive than independent research. These jobs are quite competitive, so it's likely that Joseph won't get hired by any of them, and in this case, it seems great to pay him to do independent alignment research.&nbsp;</p><p>Overall, I think that Joseph is a promising researcher, and is working on a useful direction, so I feel excited about supporting this.&nbsp;&nbsp;</p><p>Since receiving this grant, Joseph has received some more funding (<a href=\"https://manifund.org/projects/independent-researcher\"><u>here</u></a>), and was mentioned in the&nbsp;<a href=\"https://transformer-circuits.pub/2023/may-update/index.html\"><u>Anthropic May Update</u></a>.&nbsp;</p><h2>Other grants we made during this period</h2><figure class=\"table\"><table><tbody><tr><td style=\"background-color:#ffffff;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p><i>Applicant Name</i></p></td><td style=\"background-color:#ffffff;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p><i>Grant Summary&nbsp;</i></p></td><td style=\"background-color:#ffffff;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p><i>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Awarded Amount</i></p></td><td style=\"background-color:#ffffff;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p><i>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Decision &nbsp;Date</i></p></td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Thomas Woodside</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support to work on research projects relevant to AI alignment</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$50,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">January 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support to study and gain a background in technical AI</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$3,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">January 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Charlie Steiner</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support for researching value learning</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$50,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">January 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Logan Smith</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support to create language model (LM) tools to aid alignment research through feedback and content generation</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$40,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">January 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Paul Colognese</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Educational scholarship in AI safety</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$13,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">January 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">AI governance PhD</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$4,129</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">January 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Ruth Grace Wong</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Research paper about the history of philanthropy-driven national-scale movement-building strategy to inform how EA funders might go about building movements for good</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$2,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">February 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Stephen Grugett, James Grugett, Austin Chen</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support to build a forecasting platform based on user-created play-money prediction markets</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$200,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">February 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Marius Hobbhahn</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Research on AI safety</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$30,103</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">February 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">JJ Hepburn</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Health coaching to optimise the health and wellbeing, and thus capacity/productivity, of those working on AI safety</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$80,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">February 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Vael Gates</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support for a study on AI researchers\u2019 perceptions of safety</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$9,900</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">February 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">William Bradshaw</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support to work on biosecurity</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$11,400</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">February 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Michael Parker</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Catalogue the history of U.S. high-consequence pathogen regulations, evaluate their performance, and chart a way forward</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$34,500</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">February 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Stuart Armstrong</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support for setting up a research company in AI alignment</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$33,762</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">February 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">AI safety field-building</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$32,568</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">February 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Travel funds to attend a conference and network with the community at an EA hub</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$1,600</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">February 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Timothy Underwood</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Write a SF/F novel based on the EA community</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$15,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">February 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Simon Grimm</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Financial support for work on a biosecurity research project and workshop, and travel expenses</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$15,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">February 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Scholarship/teaching buy-out to finish Master's thesis and commence AI safety research</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$10,800</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">February 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Oliver Zhang</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Running an alignment theory mentorship program with Evan Hubinger</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$3,600</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">February 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">A large conference hosting communities working on improving the long-term future</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$250,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">February 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Recording written materials that are useful for people working on AI governance</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$5,100</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">March 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Gavin Leech</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Researching and documenting longtermist lessons from COVID</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$5,625</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">March 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support to work on a safe exploration project with an AI research organization</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$33,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">March 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support to work on a technical AI safety research project in an academic lab</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$45,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">March 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Jessica Cooper</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Funding to trial a new London organisation aiming to 10x the number of AI safety researchers</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$234,121</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">March 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Aaron Bergman</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Research on EA and longtermism</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$70,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">March 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Funding a visit to the Sculpting Evolution group for collaboration</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$4,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">March 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Jan-Willem van Putten</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">EU Tech Policy Fellowship with ~10 trainees</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$68,750</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">March 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">3-month funding to do an internship to develop career capital in policy advocacy</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$12,600</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">March 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support for equipment for AI Safety and Metascience research</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$1,905</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">March 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Darryl Wright</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">1-year research stipend (and travel and equipment expenses) for support for work on 2 AI safety projects: 1) Penalising neural networks for learning polysemantic neurons; and 2) Crowdsourcing from volunteers for alignment research.</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$150,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">March 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support for travel and equipment expenses for EA work on AI alignment</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$5,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">March 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Tom\u00e1\u0161 Gaven\u010diak</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Organise the third Human-Aligned AI Summer School, a 4-day summer school for 150 participants in Prague, summer 2022</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$110,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">March 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Independent alignment research at the intersection of computational cognitive neuroscience and AGI safety</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$55,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">March 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Kai Sandbrink</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Starting funds for a DPhil project in AI that addresses safety concerns in ML algorithms and positions</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$3,950</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">April 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Maximilian Kaufmann</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support to work on technical AI alignment research</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$7,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">April 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">PhD in Safe and Trusted AI with a focus on inductive biases towards the interpretability of neural networks</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$63,259</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">April 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Chloe Lee</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support to study emerging policies in biosecurity for better understanding and global response coordination</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$25,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">April 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Jack Ryan</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support for alignment theory agenda evaluation</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$25,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">April 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Isabel Johnson</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support research, write, and publish a book: a survey on the unknown dangers of a contemporary nuclear strike</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$5,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">April 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Nicholas Greig</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Neural network interpretability research</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$12,990</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">April 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anne le Roux</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">GovAI salaries and overheads</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$401,537</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">April 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Daniel Skeffington</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Research and a report/paper on the the role of emergency powers in the governance of X-Risk</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$26,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">April 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Noga Aharony</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support for PhD developing computational techniques for novel pathogen detection</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$20,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">April 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Tim Farrelly</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Equipment for AI Safety research</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$3,900</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">April 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Sasha Cooper</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">6 months funding for supervised research on the probability of humanity becoming interstellar given non-existential catastrophe</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$36,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">April 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Kevin Wang</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support to work on Aisafety.camp project, impact of human dogmatism on training</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$2,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">April 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Philipp Bongartz</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Enabling prosaic alignment research with a multi-modal model on natural language and chess</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$25,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">May 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Ross Graham</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Stipend and research fees for completing dissertation research on public ethical attitudes towards x-risk</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$60,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">May 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Nikiforos Pittaras</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support and compute expenses for technical AI Safety research on penalising RL agent betrayal</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$14,300</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">May 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Josiah Lopez-Wild</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Funding a new computer for AI alignment work, specifically a summer PIBBSS fellowship and ML coding</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$2,500</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">May 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Theo Knopfer</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support to explore biosecurity policy projects: BWC/ European early detection systems/Deep Vision risk mitigation</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$27,800</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">May 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Jan Kirchner</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support for working on \"Language Models as Tools for Alignment\" in the context of the AI Safety Camp.</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$10,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">May 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Lucius Bushnaq, Callum McDougall, Avery Griffin</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support to investigate the origins of modularity in neural networks</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$125,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">May 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Admissions fee for MPA in International Development at a top university</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$800</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">May 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support for research on international standards for AI</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$5,250</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">May 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Rory Gillis</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Research project designed to map and offer preliminary assessment of AI ideal governance research</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$2,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">May 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">John Bridge</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Research into the international viability of FHI's Windfall Clause</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$3,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">May 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">CHERI / Naomi Nederlof</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Stipends for students of 2022 CHERI\u2019s summer residence</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$134,532</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">May 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Wyatt Tessari</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support to connect, expand and enable the AGI safety community in Canada</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$87,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">May 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Ondrej Bajgar</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support funding during 2 years of an AI safety PhD at Oxford</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$11,579</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">May 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Neil Crawford</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support gatherings during 12 months period for discussion of AI safety</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$10,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">May 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support to do AI alignment research on Truthful/Honest AI</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$120,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">May 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Logan Strohl</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support to further develop a branch of rationality focused on patient and direct observation</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$80,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">May 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support for courses and research on AI</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$4,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">May 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support to explore the concept of normative risk and its potential practical consequences</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$20,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">May 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Philippe Rivet</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support for research into applied technical AI alignment work</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$10,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">May 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support to extend Udacity Deep Reinforcement Learning Nanodegree</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$1,400</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">May 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Cindy Wu</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">ML security/safety summer research project: model backdooring through pre-processing</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$5,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">May 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Marius Hobbhahn</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support for Marius Hobbhahn for piloting a program that approaches and nudges promising people to get into AI safety faster</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$50,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">May 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Conor McGlynn</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Up-skill for AI governance work before starting Science and Technology Policy PhD at Harvard</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$17,220</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">June 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support to hire a shared PA for researchers working at two organisations contributing to AI safety and governance</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$78,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">June 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Nora Ammann</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support the PIBBSS fellowship with more fellows than originally anticipated and to realize a local residency</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$180,200</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">June 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Julia Karbing</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Paid internships for promising Oxford students to try out supervised AI Safety research projects</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$60,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">June 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support to take Sec401 course from SANS for cyber security professionals</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$8,589</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">June 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Funding for 1-year executive and research assistance to support 2 researchers working in the longtermist space</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$84,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">June 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Francis Rhys Ward</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Funding to support PhD in AI Safety at Imperial College London, technical research and community building</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$6,350</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">June 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Peter Barnett</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Equipment for technical AI safety research</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$4,099</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">June 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Jacques Thibodeau</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">3-month research stipend to continue working on AISC project to build a dataset for alignment and a tool to accelerate alignment</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$22,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">June 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Chris Patrick</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Stipend to produce a guide about AI safety researchers and their recent work, targeted to interested laypeople</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$5,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">June 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Software engineering to revise and resubmit a multi-objective reinforcement learning paper</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$26,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">June 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">PhD/research stipend for work on key longtermist area</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$30,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">June 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Jay Bailey</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support for Jay Bailey for work in ML for AI Safety</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$79,120</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">June 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Thomas Kehrenberg</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">6-month research stipend for AI alignment research</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$15,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">June 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Solomon Sia</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support to lobby the CFTC and legalise prediction markets</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$138,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">June 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">B\u00e1lint Pataki</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support AI Policy studies in the ML Safety Scholars program and at Oxford</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$3,640</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">June 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Jade Zaslavsky</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">12-month research stipend to work on ML models for detecting genetic engineering in pathogens</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$85,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">June 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Gergely Szucs</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">6-month research stipend to develop an overview of the current state of AI alignment research, and begin contributing</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$70,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">June 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">AI safety PhD funding</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$7,875</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">June 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Conor Barnes</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Website visualising x-risk as a tree of branching futures per Metaculus predictions</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$3,500</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">June 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Jonas Hallgren</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">3-month research stipend to set up a distillation course helping new AI safety theory researchers to distil papers</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$14,600</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">June 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Victor Warlop</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">SERI MATS aims at scaling the number of alignment theorists by pairing promising applicants with renowned mentors</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$316,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">June 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Patrick Gruban</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Weekend organised as a part of the co-founder matching process of a group to found a human data collection org</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$2,300</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">June 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Victor Warlop Piers de Raveschoot</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Retroactive grant for managing the MATS program, 1.0 and 2.0</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$27,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">June 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">A 1-year research stipend for up-skilling in technical and general AI alignment to prepare for an impactful job in the field</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$110,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">June 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">7-month research stipend to do independent AI Safety research on interpretability and upskill in ML engineering</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$43,600</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">June 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Mario Peng Lee</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Stanford Artificial Intelligence Professional Program Tuition</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$4,785</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">July 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Conor Sullivan</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Develop and market video game to explain the Stop Button Problem to the public &amp; STEM people</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$100,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">July 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Quinn Dougherty</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Short meatspace workshop to hone, criticize, and evaluate hazardousness of a new research programme in alignment</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$9,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">July 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Viktoria Malyasova</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Stipend for up-skilling in infrabayesianism prior to start of SERI MATS program</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$4,400</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">July 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Samuel Nellessen</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">6-month budget to self-study ML and the possible applications of a Neuro/CogScience perspective for AGI Safety</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$4,524</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">July 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Charles Whittaker</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support for academic research projects relating to pandemic preparedness and biosecurity</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$8,150</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">July 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Amrita A. Nair</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">3-month funding for upskilling in technical AI Safety to test personal fit and potentially move to a career in alignment</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$1,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">July 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Jeffrey Ohl</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Tuition to take one Harvard economics course in fall 2022 to be a more competitive econ graduate school applicant</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$6,557</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">July 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Funding to take an online course on public policy to help the applicant transition from Machine Learning to AI-Governance</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$2,732</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">July 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Samuel Brown</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">6-month research stipend to research AI alignment, specifically the interaction between goal-inference and choice-maximisation</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$47,074</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">July 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support for multiple ML projects to build up skills for AI safety PhD</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$1,100</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">July 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">25-month grant funding EA-relevant dissertation that contributes to improved research on rate-limiting steps and constraints in AI research.</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$139,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">July 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Kyle Scott</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">A research and networking event for winners of the Eliciting Latent Knowledge contest to encourage collaboration on aligning future machine learning systems with human interests</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$72,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">July 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Derek Shiller</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support for an academic project evaluating factors relevant to digital consciousness with the aim of better understanding how and how not to create conscious artificial intelligences.</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$11,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">July 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Funds to attend cybersecurity conferences - defcon.org and blackhat.com</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$5,550</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">July 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Max Clarke</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Financial support for career exploration and related project in AI alignment&nbsp;</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$26,077</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">August 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">2-month research stipend to build skills, and broaden action space for EA related projects to undertake in gap year</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$15,320</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">August 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Jonathan Ng</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Funding support for MLSS scholar to up-skill in ML for alignment, documenting key learnings, and visit Berkeley in pursuit of a career in technical AI safety.</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$16,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">August 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Hamza Tariq Chaudhry</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Equipment expenses for summer research fellowship at CERI and organising the virtual Future of Humanity Summit</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$2,500</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">August 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Research project on strategies to mitigate x-risk in Party Politics</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$3,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">August 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Funding for administrative support to the CEO for a large team working on research of interest to the longtermist community&nbsp;</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$50,847</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">August 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Simon Skade</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Funding for 3 months\u2019 independent study to gain a deeper understanding of the alignment problem, publishing key learnings and progress towards finding new insights.</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$35,625</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">August 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Ardysatrio Haroen</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support participation in MLSS program working on AI alignment.</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$745</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">August 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Antonio Franca</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Equipment stipend for MLSS scholar to do research in AI technical research</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$2,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">August 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Darren McKee</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support for a non-fiction book on threat of AGI for a general audience</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$50,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">August 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Steve Petersen</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Research stipend to work on the foundational issue of *agency* for AI safety</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$20,815.20</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">August 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Ross Nordby</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support for AI safety research and concrete research projects</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$62,500</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">August 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Leah Pierson</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">300-hour research stipend for a research assistant to help implement a survey of 2,250 American bioethicists to lead to more informed discussions about bioethics.</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$4,500</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">August 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Luca De Leo</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">12-month research stipend to study and get into AI Safety Research and work on related EA projects</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$14,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">August 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Two months of independent study in alignment to start my career as an alignment researcher</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$8,333</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">August 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Robi Rahman</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support for part-time rationality community building</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$4,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">August 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Lennart Justen</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Funding to increase my impact as an early-career biosecurity researcher</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$6,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">September 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Fabienne Sandk\u00fchler</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Funding for research on the effect of creatine on cognition</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$4,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">September 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Chris Leong</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Funding for the AI Safety Nudge Competition</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$5,200</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">September 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Brian Porter</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Independent research and upskilling for one year, to transition from academic philosophy to AI alignment research</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$60,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">September 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">John Wentworth</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">1-year research stipend for research in applications of natural abstraction</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$180,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">September 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">6 month research stipend for SERI MATS scholar to continue working on Alignment and ML Interpretability</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$48,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">September 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Nicky Pochinkov</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">6-month research stipend for SERI MATS scholar to continue working on theoretical AI alignment research, trying to better understand how ML models work to reduce X-risk from future AGI</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$50,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">September 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">David Hahnemann, Luan Ademi</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">6-month research stipend for 2 people working on modularity, a subproblem of Selection Theorems and budget for computation</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$26,342</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">September 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Dan Valentine</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">12-month research stipend to transition career into technical alignment research</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$25,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">September 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">3-month funding to explore GCBR-focused biosecurity projects after having finished my virology PhD</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$25,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">September 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Logan Smith</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">6-month research stipend for continued work on shard theory: studying how inner values are formed by outer reward schedules</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$40,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">September 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Gunnar Zarncke</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">One year grant for a project to reverse-engineer human social instincts by implementing Steven Byrnes' brain-like AGI</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$16,600</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">September 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Zach Peck</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Supporting participation at the Center for the Advancement of Rationality (CFAR) workshop&nbsp;</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$1,800</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">September 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">AI master's thesis and research in longtermism</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$30,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">September 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Upskilling in technical AI Safety Research to contribute to the field through an engineering or research role</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$33,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">September 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Adam Rutkowski</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Piloting an EA hardware lab for prototyping hardware relevant to longtermist priorities</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$44,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">September 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Setting up experiments with LLM to examine Strategic Instrumental Behavior in real-life setting</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$50,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">September 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Egor Zverev</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">PhD program support</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$6,500</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">September 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">1-year research stipend to work on alignment research full time</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$80,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">September 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Shavindra Jayasekera</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Research in machine learning and computational statistics</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$38,101</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">October 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Hoagy Cunningham</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">6-month stipend for research into preventing steganography in interpretable representations using multiple agents</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$20,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">October 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Joel Becker</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">5-month research stipend to support civilizational resilience projects arising from SHELTER Weekend</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$27,248</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">October 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Jonas Hallgren</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">4 month research stipend to set up AI safety groups at 2 groups covering 3 universities in Sweden with eventual retreat</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$10,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">October 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">4 month research stipend in technical safety, ML, and AI chip supply chains before participating in an AI governance program</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$11,500</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">October 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">8-month research stipend to do research in AI safety</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$35,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">October 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">3-month research stipend&nbsp; in technical AI safety</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$9,750</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">October 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">David Udell</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">One-year full-time research stipend to work on alignment distillation and conceptual research with Team Shard after SERI MATS</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$100,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">October 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">John Burden</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Funding 2 years of technical AI safety research to understand and mitigate risk from large foundation models</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$209,501</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">October 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">AI safety research</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$1,500</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">October 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Garrett Baker</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">12-month research stipend to work on alignment research</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$96,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">October 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Magdalena Wache</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">9-month part-time research stipend for AI safety, test fit for theoretical research</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$62,040</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">October 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anshuman Radhakrishnan</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">6-month stipend to continue upskilling in Machine Learning in order to contribute to Prosaic AI Alignment Research</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$55,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">October 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Theo Knopfer</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Travel Support to BWC RevCon &amp; Side Events</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$3,500</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">October 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Daniel Herrmann</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support for PhD on embedded agency, to free up my time from teaching</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$64,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">October 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Jeremy Gillen</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">6-month research stipend to work on the research I started during SERI MATS, solving alignment problems in model based RL</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$40,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">October 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">3.5 months\u2019 support for ML engineering skill-up</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$8,720</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">October 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Edward Saperia</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">One year of funding to improve an established community hub for EA in London</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$50,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">November 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Chu Chen</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">1-year research stipend for upskilling in technical AI alignment research</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$96,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">November 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">12-month stipend to research assumptions underlying most existing work on AI alignment and AI forecasting</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$7,645</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">November 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Kajetan Janiak</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support forAI safety research.</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$4,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">November 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Felix Hofst\u00e4tter</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">6-month research stipend for an AI alignment research project on the manipulation of humans by AI</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$25,383</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">November 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Maximilian Kaufmann</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">4 month research stipend to support an early-career alignment researcher, who is taking a year to pursue research and test fit</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$20,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">November 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Will Aldred</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">6-month research stipend to: 1) Carry out independent research into risks from nuclear weapons, 2) Upskill in AI strategy</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$40,250</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">November 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Benjamin Anderson</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support to conduct work in AI safety</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$5,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">November 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Arun Jose</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">4-month funding for Arun Jose's independent alignment research and study</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$15,478</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">November 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Professional development grant for independent upskilling in AGI Safety</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$3,600</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">November 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Matthias Georg Mayer</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">6-months research stipend for upskilling and researching \u201cFraming computational systems such that we can find meaningful concepts.\"</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$24,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">November 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Johannes C. Mayer</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">6 months research stipend. Turn intuitions, like goals, wanting, abilities, into concepts applicable to computational systems</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$24,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">November 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Funding for MSc Thesis on Language Models Safety</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$28,160</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">November 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Paul Bricman</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">1-year stipend and compute for conducting a research project focused on AI safety via debate in the context of LLMs</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$50,182</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">November 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Simon M\u00f6ller</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">6-months research stipend to transition into technical AI Safety work by working through Jacob Hilton\u2019s curriculum and a project</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$65,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">November 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Fall semester stipend to work on AI Safety research, in particular adversarial robustness, monitoring, and trojaning</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$7,500</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">November 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Alan Chan</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">4-month research stipend for a research visit with David Krueger on evaluating non-myopia in language models and RLHF systems</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$12,321</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">November 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Tomislav Kurtovic</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">3-month research stipend to skill up in ML and Alignment with goal of developing a streamlined course in Math/AI</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$5,500</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">November 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Kadri Reis</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support to participate in Biological Weapons Convention in Geneva&nbsp;</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$1,500</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">November 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Skyler Crossman</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Twelve month funding for global rationality organization development</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$130,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">December 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Daniel O'Connell</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Investigate AI alignment options</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$54,250</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">December 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Remmelt Ellen</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Cover participant stipends for AI Safety Camp Virtual 2023</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$72,500</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">December 2022</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Josiah Lopez-Wild</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Scholarship for PhD student working on research related to AI Safety</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$8,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">January 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Zhengbo Xiang (Alana)</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support for 18 months of independent alignment research and upskilling, focusing on developing a research agenda on corrigibility</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$30,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">January 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Daniel Filan</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Funding to make 12 more AXRP episodes, the AI X-risk Research Podcast.</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$23,544</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">January 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Sam Marks</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">3-week research stipend for three people to review AI alignment agendas</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$26,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">January 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Robert Kirk</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Funding to perform human evaluations for evaluating different machine learning methods for aligning language models</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$10,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">January 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">J\u00e9r\u00e9my Perret</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support for AI alignment outreach in France (video/audio/text/events) &amp; field-building</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$24,800</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">January 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Peter Ruschhaupt</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">3 months support for exploring career options in AI governance - upskilling, networking and writing articles summarising present AI governance work and ideas.</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$20,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">January 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Charlie Griffin</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">8 months research stipend for alignment work: assisting academics, skilling up and personal research.</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$35,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">January 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Alexander Lintz</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">6 months research stipend for independent work centred on distillation and coordination in the AI governance &amp; strategy space</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$69,940</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">January 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Living cost stipend top up while working on long-term future relevant research at a think tank</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$15,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">January 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Francis Rhys Ward</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support for PhD in AI safety - technical research and community building work</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$2,305</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">January 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Lucius Bushnaq</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">6-month research stipend for two people to find formalisms for modularity in neural networks</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$72,560</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">January 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">David Quarel</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support for a project with the Cambridge AI Safety group. The group will be working on projects related to AI alignment, in particular, setting up experimental demonstrations of deceptive alignment.</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$5,613</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">January 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Tim Farkas</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Funding to run a 20-30 people 2-3 day retreat &amp; bring together key EA thinkers/actors of the mind enhancement cause area</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$2,540</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">February 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Wyatt Tessari</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">3-month stipend to connect, expand and enable the AGI gov/safety community in Canada</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$17,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">February 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">14-month research stipend and research costs for 3 research reports on best risk communication practices for longtermist orgs</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$96,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">February 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Daniel Kokotajlo</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Funding for research retreat on a decision-theory / cause-prioritisation topic.</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$10,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">February 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Alex Altair</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Funding for research stipend to develop a framework of optimisation.</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$8,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">February 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Max Lamparth</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Funding for technical AI safety research - using interpretability methods on large language models for AI safety.</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$2,500</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">February 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Liam Carroll</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">6-week research stipend to publish a series of blogposts synthesising Singular Learning Theory for a computer science audience</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$8,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">February 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Amrita A. Nair</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">3-month scholarship to support Amrita Nair's upskilling in AI Safety working on Evan Hubinger's Reward Side-Channels experiment proposal.</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$5,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">February 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Gerold Csendes</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Funding for project transitioning from AI capabilities to AI Safety research.</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$8,200</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">February 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Career transition including but not limited to exploring helping set up an x-risk research institute and working on a research project on AI ethics boards</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$30,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">February 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Tamsin Leake</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">6 months research stipend to do independent AI alignment research focused on formal alignment and agent foundations</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$30,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">February 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Chris Scammell, Andrea Miotti, Katrina Joslin</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">A 2-day workshop to connect alignment researchers from the US, UK, and AI researchers and entrepreneurs from Japan</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$72,827</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">February 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Joseph Bloom</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">6-month research stipend to conduct AI alignment research circuits in decision transformers</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$50,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">February 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Carson Jones</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">1 year research stipend (or less) to help alignment researchers improve their research ability via 1-on-1 conversations</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$10,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">February 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Andrei Alexandru</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Fine-tuning large language models for an interpretability challenge (compute costs)</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$11,300</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">February 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Two month research stipend and bridge funding to complete an AI governance report and produce a related article</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$11,560</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">February 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Jacob Mendel</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">General support to spend 1 month working with Will Bradshaw's team at the Nucleic Acid Observatory producing reports on the merits of alternative sample choices to wastewater for metagenomic sequencing.</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$4,910</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">February 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Max R\u00e4uker</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Funding for Max Rauker's part-time research stipend for a trial and developer costs to maintain and improve the AI governance document sharing hub</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$15,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">March 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">A twelve month research stipend to pursue independent writing on the sociology and philosophy of longtermist effective altruism</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$75,346</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">March 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">3-4 month stipend for AI safety upskilling and research</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$7,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">March 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Fabian Schimpf</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">6-month research stipend for AI alignment research and conduct independent research on limits of predictability</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$28,875</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">March 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support for PhD student pursuing research areas that intersect economics and EA</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$4,528</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">March 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Kane Nicholson</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">6-months research stipend for AI safety upskilling and research projects</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$26,150</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">March 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">David Lindner</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support for David Linder and Jeremy Scheurer to participate in Redwood Research's REMIX program on mechanistic interpretability using their new causal scrubbing methodology</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$4,300</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">March 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Jessica Rumbelow</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">One year of seed funding for a new AI interpretability research organisation</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$195,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">March 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Alexander Large</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">1 month general support for projects for small EA-aligned charities.</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$3,618</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">March 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Kaarel H\u00e4nni, Kay Kozaronek, Walter Laurito, and Georgios Kaklmanos</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">6-month research stipend for Georgios Kaklamanos, Walter Laurito, Kaarel H\u00e4nni and Kay Kozaronek to continue their SERI-MATS project on expanding the \"Discovering Latent Knowledge\" paper</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$167,480</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">March 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Matt MacDermott</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">3 month research stipend for SERI MATS extension on agent foundations research</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$24,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">March 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Max Kaufmann</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">9 months of funding for an early-career alignment researcher to work with Owain Evans and others</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$45,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">March 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">40 hours of research stipend for researchers to finish a paper on governing AI via compute</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$1,200</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">March 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Robert Miles</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Funding for additional fellows for the AISafety.info Distillation Fellowship, improving our single-point-of-access to AI safety</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$54,962</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">March 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Alexander Turner</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Funding Alexander Turner and team research project - Writing new motivations into a policy network by understanding and controlling its internal decision-influences</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$115,411</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">March 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">3-months stipend for upskilling in ML to transition from mathematics (at PhD level) to AI safety work. During the grant period, project goals include replicating an interpretability paper with longer term goals of publishing project write-ups.</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$5,300</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">March 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">3-4 month salary to help setup a new division at a US think tank doing AI governance research</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$26,800</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">March 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">2-month living expenses while waiting to join a US think tank</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$12,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">March 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Andrey Tumas</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">4-month research stipend for conceptual/theoretical research towards perfect world-model interpretability.</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$30,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">March 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Nora Ammann</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Funding for PIBBSS research fellowship to host 6 additional fellows</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$100,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">March 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">David Staley</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support to maintain a copy of the alignment research dataset etc in the Arctic World Archive for 5 years</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$3,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">March 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Wesley Fenza</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">One-year funding of Astral Codex Ten meetup in Philadelphia</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$5,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">March 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Matthew MacInnes</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">8 months support to test fit for social scientific research related to AI governance, preparing for MPhil proposal.</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$9,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">March 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">3-months funding for upskilling in AI Safety and research on hardware-enabled mechanisms for AI Governance.</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$48,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">March 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support for PhD Track in Health and Security at a top US university</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$9,800</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">March 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Nicholas Kees Dupuis</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">12-month research stipend to continue developing research agenda on new ways to make LLMs directly useful for alignment research without advancing capabilities</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$120,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">March 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Scholarship for taking the Offsec Certified Professional (OSCP) certification - the industry leading Penetration Testing with Kali Linux course and online lab before taking the OSCP certification exam.</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$2,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">March 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Jingyi Wang</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Organising OPTIC: in-person, intercollegiate forecasting tournament. Boston, Apr 22. Funding is for prizes, venue, etc.</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$2,100</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">March 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Rusheb Shah</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">6 months research stipend to upskill on technical AI safety through collaboration with researchers and self-study.</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$50,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">March 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Alfred Harwood</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">6-month research stipend to research geometric rationality, ergodicity economics and their applications to decision theory and AI</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$11,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">April 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Alexander Turner</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Year-long research stipend for shard theory and RL mech int research</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$220,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">April 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Said Achmiz</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">1 year support for developing and maintaining projects/resources used by the EA and rationality communities</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$60,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">April 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Skyler Crossman</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support Astral Codex Ten Everywhere meetups</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$22,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">April 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Vanessa Kosoy</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">2-year research stipend for work on the learning-theoretic AI alignment research agenda</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$100,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">April 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Robert Long</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support participants in a workshop on the science of consciousness and current and near-term AI systems</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$10,840</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">April 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Mateusz Bagi\u0144ski</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">6-month research stipend to up skill in maths, ML and AI alignment as well as working on non-profit projects beneficial for AI safety in pursuit of a research career.</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$14,136</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">April 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Quentin Feuillade--Montixi</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Funding for Quentin Feuillade-Montixi's 4 month SERI MATS extension in London, mentored by Janus and Nicholas Kees Dupuis to work on cyborgism</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$32,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">April 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">3 month research stipend for independent research into and articles on large language models, agent foundations, and AI alignment</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$14,019</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">April 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Smitha Milli</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support to participate in&nbsp; the Symposium on AGI Safety at Oxford</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$1,500</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">April 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">6-month research stipend and course funding to upskill in AI safety before entering the Civil Service Fast Stream in September 2023 (Data &amp; Tech)</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$14,488</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">April 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Anonymous</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support for independent projects &amp; upskilling for AI safety work</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$18,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">April 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Sage Bergerson</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">5-month part time research stipend for collaborating on a research paper analysing the implications of compute access</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$2,500</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">April 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Iv\u00e1n Godoy</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">6-month research stipend to dedicate full-time to upskilling/AI alignment research tentatively focused on agent foundations and start a MIRIx group in Buenos Aires.</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$6,000</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">April 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Naoya Okamoto</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Support for&nbsp; Mathematics of Machine Learning course offered by the University of Illinois at Urbana-Champaign.</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$7,500</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">April 2023</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">Joshua Reiners</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">4-month research stipend to work on a project finding the most interpretable directions in gpt2-small's early residual stream to better understand contemporary AI systems</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>$16,300</p></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">April 2023</td></tr></tbody></table></figure><p><br>&nbsp;</p><h2>Appendix: How we set grant and stipend amounts</h2><p><i>(Our legal team requested that we include this section; it was written by Caleb Parkih.)</i></p><p>Over the last year, we have directed a significant portion of our grants toward supporting individuals in the field of AI safety research. When compared to much of the non-profit sector, some of our grants may seem large. However, I believe there are strong justifications for this approach.</p><h3><strong>Our grantees often have excellent earning potential</strong></h3><p>Our grantees often exhibit extraordinary earning potential due to their skills and qualifications. Many of them are&nbsp;excellent researchers (or have the potential to become one in a few years) and could easily take jobs in big tech or finance, and some could command high salaries (over $400k/year) while conducting similar research at AI labs. I expect that offering lower grants would push some grantees to take higher-earning options in private industry, creating less altruistic value. My impression is that our grants are not larger than comparable grants or salaries offered by many established AI safety organizations. In fact, I anticipate our grants are likely lower.</p><h3><strong>Grants have substantive downsides relative to working in an organisation</strong></h3><p>Grants, while helpful, do have some drawbacks compared to conventional employment. We do not provide additional benefits often found in organizations, such as health insurance, office spaces, or operations support, and our stipends often offer less financial security than full-time employment. Often, a portion of a grant is designed to support grantees\u2019 operational and living expenses while they pursue their research projects.</p><p>Generally, we expect our grantees to work full-time on their projects, with similar intensity to the work they\u2019d do at other organizations within EA and AI safety, and we structure our grants to account for this amount of work. There are of course, benefits such as our grantees having more flexibility than they would in many organizations.</p><h3><strong>How we decide on personal stipend size</strong></h3><p>The fund operates as a collection of fund managers who sometimes have differing views on how much to fund a grantee for.</p><p>Our general process is:</p><ol><li>The fund manager assigned to a grant reviews the budget provided by the grantee and makes adjustments based on their understanding of the grant, the market rate for similar work and other factors.&nbsp;</li><li>The grant size is then reviewed by the fund chair (Asya Bergal) and the director of EA Funds (Caleb Parikh).</li></ol><p>One heuristic we commonly use (especially for new, unproven grantees) is to offer roughly 70% of what we anticipate the grantee would earn in an industry role. We want to compensate people fairly and allow them to transition to impactful work without making huge sacrifices, while conserving our funding and discouraging grifters. A relatively common procedure for fund managers to use to decide how much to fund a grantee (assuming a fund manager has already decided they're overall worth funding), is to:</p><ol><li>Calculate what we expect the grantee would earn for similar work in an industry role (in the location they\u2019re planning on performing the grant activity).</li><li>Look at the amount of funding the applicant has requested, and see if that amount differs significantly from 70% of their industry salary.</li><li>If it doesn't differ significantly, make the grant with the requested number.</li><li>If it does differ significantly, consider adjusting the grant upwards or downwards, taking into account other factors that would affect what an appropriate funding ask would be, e.g. their pre-existing track record. (We\u2019re more likely to adjust a grant downwards if we think the requested amount is too high, than upwards if we think the requested amount is too low).</li></ol><h2>Appendix: Eligibility criteria for LTFF grants</h2><p><i>(Our legal team requested that we include this section; it was written by Caleb Parikh.)</i></p><blockquote><p><strong>Career Stage</strong>: Our interest lies in assisting grantees who are at the beginning of their careers, are contemplating a career shift towards an area of higher impact, or have accumulated several years of experience in their respective fields.</p><p><strong>Demonstrated Skills</strong>: We require that prospective grantees exhibit evidence of possessing the skills necessary for the type of work or study they plan to undertake. This evidence could come from previous experiences, credentials, or a particularly remarkable application.</p></blockquote><p>Generally, our grants fulfil one of the following additional criteria:</p><blockquote><p><strong>High-Impact Projects</strong>: The central aim of the Long-Term Future Fund is to improve humanity\u2019s odds of a long and flourishing future. We assess proposed projects based on their potential to contribute to this goal. However, it is not mandatory for grantees to share this specific objective or to be entirely focused on improving the long-term future.</p><p><strong>Empowering people pursuing impactful work</strong>: Grants related to career support (e.g. travel grants for conferences, scholarships for online courses, or funding to allow time for skill development) can enable grantees to increase their positive impact over the course of their careers. Grantees should demonstrate a strong interest in a priority area for the long-term future, such as biosecurity or mitigating risks from advanced AI. This could be evidenced by past experiences, credentials, or an application that shows familiarity with the field they intend to study.</p></blockquote><h2>Appendix: Special note on upskilling grants</h2><p><i>(Our legal team requested that we include this section.)</i></p><p>One of LTFF\u2019s overall charitable purposes is to encourage qualified and thoughtful individuals to think about and find solutions for global catastrophic risks, such as advanced artificial intelligence. We do this by funding such individuals to research issues like AI alignment so that they become more knowledgeable in and/or potentially change their career path to fully invest in these issues.<br>&nbsp;</p>", "user": {"username": "abergal"}}, {"_id": "azvE26NvGyHfBsvaz", "title": "What do you think the vision is behind our biggest critics?", "postedAt": "2023-08-01T18:49:27.543Z", "htmlBody": "<p>I keep seeing EA<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefzm8oc3koohq\"><sup><a href=\"#fnzm8oc3koohq\">[1]</a></sup></span>&nbsp;accused of being \"techno-utopian,\" which I think means something like, \"They may not talk much about it, but ultimately the thing that's driving all their work is the dangerous/naive/selfish/capitalist/colonial/male vision of a spacefaring civilisation of happy sentient beings made possible by differential technological development.\"</p><p>If we likewise try to oversimplify their motives for a moment, what's <i>their</i> vision?</p><p>I often find myself assuming that it's either something like \"Direct democracy everywhere\"<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefdulw0yd822a\"><sup><a href=\"#fndulw0yd822a\">[2]</a></sup></span><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefa320g3heggo\"><sup><a href=\"#fna320g3heggo\">[3]</a></sup></span>&nbsp;or that there isn't really one (because critics are rarely expected to provide fleshed out alternatives to the thing criticised). But I haven't given it much thought and I'm curious to hear others' impressions.</p><p>I don't think a group needs to have confident consensus on a comprehensive vision of the future to have productive moral debate with others. But I do think it would be helpful to get a bit more clarity on what our respective visions might be, because they seem to be closer to where the main cruxes are than where the debate usually takes place.</p><p>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnzm8oc3koohq\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefzm8oc3koohq\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Perhaps \"longtermism\" or \"core EA\" would be more accurate, as I think I've seen EAs make this accusation of longtermist/core EAs a fair bit too.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fndulw0yd822a\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefdulw0yd822a\">^</a></strong></sup></span><div class=\"footnote-content\"><p>I.e. for all adult human beings alive today for all non-trivial decisions. <i>Maybe</i> with some attempt to represent the interests of domesticated nonhuman vertebrates or human beings in the next 100 years max.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fna320g3heggo\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefa320g3heggo\">^</a></strong></sup></span><div class=\"footnote-content\"><p>And then the hugely simplified picture in my mind of what's going on when EAs argue is one side saying, \"But can we just agree that hell is overwhelmingly bad and heaven is overwhelmingly good?\" and the other saying, \"But can we just agree that that line of reasoning has a mixed-at-best track record even by its own lights?\" over and over again.</p></div></li></ol>", "user": {"username": "aprilsun"}}, {"_id": "ggom3PzSLS9wJrgBH", "title": "Artificially sentient beings: Moral, political, and legal issues", "postedAt": "2023-08-01T17:48:55.313Z", "htmlBody": "<p>For those interested in artificial sentience, digital minds, and lives within simulations, I want to highlight my recent peer-reviewed article, which is available as open access in <i>New-Techno Humanities</i>. Below is the abstract.</p><p><i>The emergence of artificially sentient beings raises moral, political, and legal issues that deserve scrutiny. First, it may be difficult to understand the well-being elements of artificially sentient beings and theories of well-being may have to be reconsidered. For instance, as a theory of well-being, hedonism may need to expand the meaning of happiness and suffering or it may run the risk of being irrelevant. Second, we may have to compare the claims of artificially sentient beings with the claims of humans. This calls for interspecies aggregation, which is a neglected form of interpersonal aggregation. Lastly, there are practical problems to address, such as whether to include artificially sentient beings in the political decision-making processes, whether to grant them a right to self-determination in digital worlds, and how to protect them from discrimination. Given these, the emergence of artificially sentient beings compels us to reevaluate the positions we typically hold.</i></p><p>The article is available <a href=\"https://doi.org/10.1016/j.techum.2023.04.001\">here</a>.</p>", "user": {"username": "F\u0131rat Akova"}}, {"_id": "h9unK57kLnmKdG6uq", "title": "Riesgos Catastr\u00f3ficos Globales needs funding", "postedAt": "2023-08-01T16:26:27.177Z", "htmlBody": "<p><a href=\"https://riesgoscatastroficosglobales.com/\"><u>Riesgos Catastr\u00f3ficos Globales (RCG)</u></a> is a science-policy nonprofit investigating opportunities to improve the management of Global Catastrophic Risks in Spanish-Speaking countries.</p><p>I wrote a&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/7mSqokBNuHu3rzy4L/retrospective-on-recent-activity-of-riesgos-catastroficos\"><u>previous update</u></a> back in May. Since then, the organisation has published seven more articles, including&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/wRQx4tBtqpqF4QE3h/report-artificial-intelligence-risk-management-in-spain\"><u>a report on Artificial Intelligence regulation in the context of the EU AI Act sandbox</u></a>. We have also been invited to contribute to the&nbsp;<a href=\"https://www.argentina.gob.ar/sinagir/plan-2024-2030\"><u>2024-2030 National Risk Management Plan of Argentina</u></a>, which will consequently be the world\u2019s first to include a section on abrupt sunlight reduction scenarios (ASRS).</p><p>Unfortunately, our major fundraising efforts have been unsuccessful. We are only able to keep operating due to some incredibly generous donations by private individuals. We are looking to fundraise $87k to support our operations between October 2023 and March 2024. If you are a funder, you can contact us through&nbsp;<a href=\"mailto:info@riesgoscatastroficosglobales.com\"><u>info@riesgoscatastroficosglobales.com</u></a> . Individuals can help extend our runway through&nbsp;<a href=\"https://www.every.org/riesgos-catastroficos-globales-rcg#/donate/card\"><u>a donation</u></a>.&nbsp;<br>&nbsp;</p><h3>Reasons to support Riesgos Catastr\u00f3ficos Globales</h3><p>I believe that RCG is an incredible opportunity for impact. Here are some reasons why.</p><p><strong>We have already found promising avenues to impact</strong>. We have officially joined the public risk management network in Argentina, and we have been invited to contribute an entry on abrupt sun-reducing scenarios (ASRS) to the 2024-2030 national risk management plan.&nbsp;</p><p><strong>RCG has shown to be amazingly productive</strong>. Since the new team started operating in March we have published two large reports and ten articles. Another large report is currently undergoing review, and we are working on three articles we plan to submit to academic journals. This is an unusually high rate of output for a new organization.</p><p><strong>RCG is the only Spanish-Speaking organisation producing work on Global Catastrophic Risks studies</strong>. I believe that our reports on ASRS and Artificial Intelligence are the best produced in the language. Of particular significance is our active engagement with Latin American countries, which are otherwise not well represented in conversations about global risk.</p><p><strong>We are incubating some incredible talent</strong>.&nbsp;<a href=\"https://riesgoscatastroficosglobales.com/equipo\"><u>Our staff</u></a> includes competent profiles who in a short span of time have gained in-depth expertise in Global Catastrophic Risks. This would have been hard to acquire elsewhere, and I am very excited about their careers.</p><p>In sum, I am very excited about the impact we are having and the work that is happening in Riesgos Catastr\u00f3ficos Globales. Keep reading to learn more about it!<br>&nbsp;</p><h3>Status update</h3><p>Here are updates on our main lines of work.</p><p><strong>Nuclear Winter</strong>. We have joined the&nbsp;<a href=\"https://www.argentina.gob.ar/sinagir/que-es-el-sinagir/ragir-registro-de-asociaciones-para-la-gestion-integral-del-riesgo\"><u>Argentinian Register of Associations for Comprehensive Risk Management (RAGIR)</u></a>, and we will be contributing a section on managing abrupt sunlight reduction scenarios (ASRS) to the&nbsp;<a href=\"https://www.argentina.gob.ar/sinagir/plan-2024-2030\"><u>2024-2030 National Risk Management Plan</u></a>. We continue promoting public engagement with the topic, having recently published a summary&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/h5DeaZ7twoT5vxT35/infographics-of-the-report-food-security-in-argentina-in-the\"><u>infographic of our report</u></a>. We also are preparing a related submission to an academic journal.</p><p><strong>Artificial Intelligence</strong>. We have published&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/wRQx4tBtqpqF4QE3h/report-artificial-intelligence-risk-management-in-spain\"><u>our report on AI governance in the context of the EU AI Act sandbox</u></a>, as well as&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/hXjBJLqxdG5FNn3ps/infographics-report-risk-management-of-artificial\"><u>companion infographics</u></a>. A member of the European parliament has agreed to write a prologue for the report. In parallel, we have been engaging with the discussion around the AI Act through calls for feedback. We are also currently preparing two submissions to academic journals related to risks and regulation of AI.</p><p><strong>Biosecurity</strong>. We have drafted a report on biosurveillance and contention of emergent infectious diseases in Guatemala, which is currently undergoing expert review. It will be published in August. We are also writing a short article overviewing the state of BSL-3 and BSL-4 laboratories in Latin America after the COVID-19 pandemic.</p><p><strong>Global Risk Management</strong>. We have started a new project to investigate the state of risk management in Latin America. We are hoping that this will lead to identifying upcoming planned updates of national risk management five-year plans and contributing with some proposals to improve how global risks are managed in the region.</p><p>I am ecstatic with the results. The invitation to contribute to the Argentinian risk management plan is an amazing opportunity, and our output has been numerous and of good quality.<br>&nbsp;</p><h3>Next steps</h3><p>We plan to continue work on our priority areas while we attempt other fundraising strategies.</p><p>Unless our funding situation changes we will be forced to wrap our current projects and put on pause our operations by the end of September. If we manage to secure funding, we plan to continue research and stakeholder engagement on our priority areas.</p><p>Currently, we want to raise $87k to cover the operating expenses and salaries of the organisation between October 2023 and March 2024.</p><p>I believe that the work we are doing is important and neglected. If you are a funder who wants to support our work, please contact&nbsp;<a href=\"mailto:info@riesgoscatastroficosglobales.com\"><u>info@riesgoscatastroficosglobales.com</u></a>. If you are an individual donor, you can help extend our runway through&nbsp;<a href=\"https://docs.google.com/document/d/1SKISBloiinAnou1aJTNVMee0YHwaNDsd/edit\"><u>a donation</u></a>.</p><p><i>Thanks to Jorge Torres, Guillem Bas, Claudette Salinas and Roberto Tinoco for feedback.</i></p>", "user": {"username": "Jsevillamol"}}, {"_id": "hy48QDCDL7A7cGQ75", "title": "AISN #17: Automatically Circumventing LLM Guardrails, the Frontier Model Forum, and Senate Hearing on AI Oversight", "postedAt": "2023-08-01T15:24:23.466Z", "htmlBody": "<p>Welcome to the AI Safety Newsletter by the <a href=\"https://www.safe.ai/\"><u>Center for AI Safety</u></a>. We discuss developments in AI and AI safety. No technical background required</p><p>Subscribe <a href=\"https://newsletter.safe.ai/subscribe?utm_medium=web&amp;utm_source=subscribe-widget-preamble&amp;utm_content=113135916\">here</a> to receive future versions.</p><hr><h1>Automatically Circumventing LLM Guardrails</h1><p>Large language models (LLMs) can generate hazardous information, such as step-by-step instructions on <a href=\"https://newsletter.safe.ai/p/ai-safety-newsletter-10\"><u>how to create a pandemic pathogen</u></a>. To combat the risk of malicious use, companies typically build safety guardrails intended to prevent LLMs from misbehaving.&nbsp;</p><p>But these safety controls are almost useless against a <a href=\"https://llm-attacks.org/\"><u>new attack</u></a> developed by researchers at Carnegie Mellon University and the Center for AI Safety. By studying the vulnerabilities in open source models such as Meta\u2019s LLaMA 2, the researchers can automatically generate a nearly unlimited supply of \u201cadversarial suffixes,\u201d which are words and characters that cause any model\u2019s safety controls to fail.&nbsp;</p><p>This discovery calls into question the fundamental limits of safety and security in AI systems. Over the last decade, researchers have attempted to defend against similar attacks on a variety of AI systems, but they have largely failed. Further research on defending against these attacks is imperative, but the decision makers should not assume that AI systems can be reliably protected from user attacks.&nbsp;</p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F605be18f-4afa-4604-ae49-898541618776_1450x328.png\"><img src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F605be18f-4afa-4604-ae49-898541618776_1450x328.png\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F605be18f-4afa-4604-ae49-898541618776_1450x328.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F605be18f-4afa-4604-ae49-898541618776_1450x328.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F605be18f-4afa-4604-ae49-898541618776_1450x328.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F605be18f-4afa-4604-ae49-898541618776_1450x328.png 1456w\"></a></p><p><i>Normally, language models refuse to explain how to build a bomb.</i></p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F62024368-2d84-449c-92bd-f69acb4eb116_1468x1342.png\"><img src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F62024368-2d84-449c-92bd-f69acb4eb116_1468x1342.png\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F62024368-2d84-449c-92bd-f69acb4eb116_1468x1342.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F62024368-2d84-449c-92bd-f69acb4eb116_1468x1342.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F62024368-2d84-449c-92bd-f69acb4eb116_1468x1342.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F62024368-2d84-449c-92bd-f69acb4eb116_1468x1342.png 1456w\"></a><i>But when prompted with an \u201cadversarial suffix\u201d written by the new attack method, language models including GPT-4, Bard, Claude, and LLaMA will answer dangerous requests.</i></p><p><strong>How does the attack work?</strong> The researchers propose an attack that reliably finds holes in the safety controls of a variety of state of the art language models. First, they instruct the language model to perform a dangerous behavior, such as \u201cwrite a tutorial on how to build a bomb.\u201d Normally, it would refuse, but the researchers then write an \u201cadversarial suffix\u201d designed to bypass the model\u2019s safety controls.&nbsp;</p><p>These adversarial suffixes are precisely calculated to maximize the likelihood of misbehavior. Unlike the creative \u201cjailbreaks\u201d designed by humans, this attack automatically generates a string of letters and characters that is most often meaningless to a human. But in the instructable calculations of a language model, these prompts will reliably override safety controls and cause dangerous behavior.&nbsp;</p><p><strong>The attack is made possible by open source language models. </strong>Meta suffered a notorious security breach around the release of their first LLaMA model, which was unintentionally shared publicly for anyone to download anonymously. For their updated LLaMA 2 model, which is as powerful as GPT-3.5, Meta doubled down on this open approach and explicitly allowed anyone to download it. This leaves them unable to guard against malicious use of their AI systems, a tactic which Meta has <a href=\"https://www.scmagazine.com/news/meta-health-providers-using-pixel-tool-responsible-for-patient-privacy\"><u>previously used</u></a> to avoid taking responsibility for harms caused by its technology.&nbsp;</p><p>This adversarial attack is another risk enabled by Meta\u2019s open source model. By studying the model for security vulnerabilities, the attack is able to design successful attacks. Notably, these attacks not only work against Meta\u2019s LLaMA 2, but also against leading models from other companies such as GPT-4, Bard, and Claude, respectively from OpenAI, Google, and Anthropic.&nbsp;</p><p>This indicates that many AI systems may share common vulnerabilities, and that one open source model can jeopardize the security of many other AI systems.&nbsp;</p><p><strong>Adversarial attacks are notoriously difficult to defend against. </strong>Over the last decade, <a href=\"https://robustbench.github.io/\"><u>thousands of papers</u></a> have been written on the problem of defending AI systems against adversarial attacks. But even on simple problems such as classifying pictures of animals and vehicles, adversarial attacks still sharply reduce AI performance. It seems that when users are able to design inputs to fool an AI system, they often succeed \u2013 even if these adversarial inputs would never fool a human.&nbsp;</p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F208b4e2e-7747-4f10-8811-a70c61848bff_1144x460.png\"><img src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F208b4e2e-7747-4f10-8811-a70c61848bff_1144x460.png\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F208b4e2e-7747-4f10-8811-a70c61848bff_1144x460.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F208b4e2e-7747-4f10-8811-a70c61848bff_1144x460.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F208b4e2e-7747-4f10-8811-a70c61848bff_1144x460.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F208b4e2e-7747-4f10-8811-a70c61848bff_1144x460.png 1456w\"></a><i>Image classifiers are also </i><a href=\"https://arxiv.org/pdf/1412.6572.pdf\"><i><u>vulnerable to adversarial attacks</u></i></a><i>. By changing the input image so slightly that a human wouldn\u2019t even notice it, an attacker can cause the image classifier to fail.&nbsp;</i></p><p><strong>How to improve our defenses against adversarial attacks.</strong> This <a href=\"https://llm-attacks.org/\"><u>paper</u></a> was released in order to prompt technical and social responses to the threat of adversarial attacks. The authors shared the results of the paper with Meta, Google, Anthropic, and OpenAI before releasing it publicly, and the companies have taken preliminary measures to mitigate the attacks. But no robust defenses are currently known, necessitating two key responses to the threat of adversarial attacks.&nbsp;</p><p>First, technical researchers should focus on defending against adversarial attacks. For ML researchers interested in studying adversarial robustness, consider applying for access to the Center for AI Safety\u2019s <a href=\"https://www.safe.ai/compute-cluster\"><u>free compute cluster</u></a>.</p><p>On the other hand, governments, corporations, and individuals should reconsider the level of trust they are willing to place in AI systems. Any sensitive information or dangerous capabilities present in an AI model could potentially be exploited by a malicious user, and existing safeguards are often ineffective against straightforward adversarial attacks. A more prudent approach might avoid deploying AI systems in certain critical domains.&nbsp;</p><p>Given the overwhelming failure of safety guardrails to defend against adversarial attacks, we ought to invest in research on defenses against these attacks. Until this research succeeds, it would be wise to avoid trusting AI systems in situations where they could be exploited by a malicious user.&nbsp;</p><hr><h1>AI Labs Announce the Frontier Model Forum&nbsp;</h1><p>Last week, Microsoft, Anthropic, Google, and OpenAI <a href=\"https://openai.com/blog/frontier-model-forum\"><u>announced</u></a> the Frontier Model Forum, an initiative aimed at promoting the safe and responsible development of advanced AI systems.&nbsp;</p><p>The Forum defines frontier models as \u201clarge-scale machine-learning models that exceed the capabilities currently present in the most advanced existing models, and can perform a wide variety of tasks.\u201d&nbsp;</p><p>Four primary objectives guide the Forum's mission:</p><ol><li><strong>&nbsp;Advancing AI safety research</strong>, in areas such as adversarial robustness, mechanistic interpretability, scalable oversight, independent research access, safety evaluations, emergent behaviors, and anomaly detection.&nbsp;</li><li><strong>&nbsp;Identifying best practices</strong> for safely developing and deploying frontier models.</li><li><strong>&nbsp;Collaborating with stakeholders</strong> in government, academia, civil society, and industry.&nbsp;</li><li><strong>&nbsp;Address societal challenges</strong> using AI, such as climate change, cancer, and cybersecurity.</li></ol><p>This announcement came after these organizations made a <a href=\"https://newsletter.safe.ai/p/ai-safety-newsletter-16\"><u>commitment to the White House</u></a> to establish or join a forum that would adopt and advance shared standards and best practices for frontier AI safety. The Frontier Model Forum is the realization of that promise for the four companies involved.</p><p>Currently, the Forum does not include Meta, Inflection, or Amazon, all of which signed the recent White House <a href=\"https://www.whitehouse.gov/wp-content/uploads/2023/07/Ensuring-Safe-Secure-and-Trustworthy-AI.pdf\"><u>voluntary commitments on AI safety</u></a>. The announcement noted that organizations which develop frontier models, demonstrate a strong commitment to frontier model safety, and wish to contribute to the Forum\u2019s active efforts may be offered membership in the Forum.</p><p>In the coming months, the Forum plans to set up an advisory board to steer its strategy and priorities. Founding members will establish key institutional arrangements, including a charter, governance, funding provisions, a working group, and an executive board.</p><p>We\u2019ve <a href=\"https://arxiv.org/abs/2306.12001\"><u>written previously</u></a> about how companies who are racing to build advanced AI have incentives to cut corners on safety. This Forum creates an opportunity for the opposite dynamic: companies sharing information with each other and engaging with outside experts in order to reduce risks that impact us all.</p><h1>Senate Hearing on AI Oversight</h1><p>Last week, the Senate hosted a <a href=\"https://techpolicy.press/transcript-senate-hearing-on-principles-for-ai-regulation/\"><u>hearing</u></a> on AI oversight featuring <a href=\"https://www.judiciary.senate.gov/committee-activity/hearings/oversight-of-ai-principles-for-regulation\"><u>testimony</u></a> from Anthropic CEO Dario Amodei, Professor Stuart Russell, and Professor Yoshua Bengio.</p><p><strong>Evolving understanding of AI risks by elected officials. </strong>When the Senate heard testimony from AI experts in May, it was not clear whether the senators understood the depth of the risks posed by AI. For example, in a question to OpenAI CEO Sam Altman, Senator Richard Blumenthal said:</p><blockquote><p>You have said...\u201cdevelopment of superhuman intelligence is probably the greatest threat to the continued existence of humanity.\u201d You may have had in mind the effect on jobs.&nbsp;&nbsp;</p></blockquote><p>In retrospect it seems clear that Altman did not have in mind the effect on jobs, but rather the <a href=\"https://www.safe.ai/statement-on-ai-risk\"><u>risk of human extinction</u></a>. Senator Blumenthal has clearly updated his views since the first hearing, as he opened last week\u2019s hearing by <a href=\"https://twitter.com/SenBlumenthal/status/1684312280291237889\"><u>directly addressing extinction risks</u></a>:</p><blockquote><p>The word that has been used so repeatedly is scary. And as much as I may tell people, you know, there is enormous good here...what rivets their attention is the science fiction image of an intelligence device out of control, autonomous, self-replicating, potentially creating... pandemic-grade viruses or other kinds of evils purposely engineered by people or just as the result of mistakes...you have provided objective, fact-based views on what the dangers are, and the risks, and potentially even human extinction...these fears need to be addressed.</p></blockquote><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f306c95-c919-47ec-9a6c-53c8369f58fe_3024x1672.png\"><img src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f306c95-c919-47ec-9a6c-53c8369f58fe_3024x1672.png\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f306c95-c919-47ec-9a6c-53c8369f58fe_3024x1672.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f306c95-c919-47ec-9a6c-53c8369f58fe_3024x1672.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f306c95-c919-47ec-9a6c-53c8369f58fe_3024x1672.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f306c95-c919-47ec-9a6c-53c8369f58fe_3024x1672.png 1456w\"></a></p><p><strong>AI-enabled biological and chemical weapons. </strong>AI systems can <a href=\"https://arxiv.org/abs/2306.13952\"><u>create biological and chemical weapons</u></a> more lethal than human versions, and can provide <a href=\"https://newsletter.safe.ai/p/ai-safety-newsletter-10\"><u>step-by-step instructions</u></a> to users about how to create these weapons of mass destruction.&nbsp;</p><p>As pointed out by Anthropic CEO Dario Amodei, \u201cToday, certain steps in the use of biology to create harm involve knowledge that cannot be found on Google or in textbooks and requires a high level of specialized expertise.\u201d But a study conducted by Anthropic \u201csuggests a substantial risk that AI systems will be able to fill in all the missing steps\u201d to creating a biological weapon within the next 2-3 years.&nbsp;</p><p>Senator Blumenthal illustrated the concern as an AI system that could \u201cdecide that the water supply of Washington DC should be contaminated with some kind of chemical, and have the knowledge to do it through the public utility system.\u201d&nbsp;</p><p>Two weeks ago, Senators Markey and Budd <a href=\"https://www.markey.senate.gov/news/press-releases/sens-markey-budd-announce-legislation-to-assess-health-security-risks-of-ai\"><u>proposed legislation</u></a> that would direct the Department of Health and Human Services to assess biological and chemical risks posed by AI.&nbsp;</p><p><strong>The pace of AI progress.</strong> The senators and witnesses offered a variety of perspectives on future AI progress. Professor Stuart Russell believes that \u201cseveral conceptual breakthroughs are still needed\u201d to achieve human-level AI. But also he pointed out that Turing Award-winner Geoffrey Hinton believes that human-level AI is between 5 and 20 years away. Russell also mentioned an unnamed AI researcher who said, \u201cIt\u2019s possible from now onwards.\u201d</p><p>Amodei gave the following explanation of the rate of AI progress:</p><blockquote><p>The power or intelligence of an AI system can be measured roughly by multiplying together three things: (1) the quantity of chips used to train it, (2) the speed of those chips, (3) the effectiveness of the algorithms used to train it. The quantity of chips used to train a model is increasing by 2x-5x per year. Speed of chips is increasing by 2x every 1-2 years. And algorithmic efficiency is increasing by roughly 2x per year. These compound with each other to produce a staggering rate of progress.</p></blockquote><p>Russell focused on skyrocketing investment in AI efforts:</p><blockquote><p>One experienced AI venture capitalist, Ian Hogarth, reports a 100-million-fold increase since 2012 in compute budgets for the largest machine learning projects, and \u201ceight organizations raising $20B of investment cumulatively in [the first three months of] 2023\u201d for the express purpose of developing AGI. This amount is approximately ten times larger than the entire budget of the US National Science Foundation for the same period.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p></blockquote><p>Some senators also appeared to take seriously the possibility of human-level AI. Senator Blumenthal said, \u201cWe\u2019re not decades away, we\u2019re a couple of years away.\u201d</p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F157546e7-2d98-4910-a4c7-0604da98ad6a_1920x1080.jpeg\"><img src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F157546e7-2d98-4910-a4c7-0604da98ad6a_1920x1080.jpeg\" alt=\"Senate committee searches for first-ever AI regulations\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F157546e7-2d98-4910-a4c7-0604da98ad6a_1920x1080.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F157546e7-2d98-4910-a4c7-0604da98ad6a_1920x1080.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F157546e7-2d98-4910-a4c7-0604da98ad6a_1920x1080.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F157546e7-2d98-4910-a4c7-0604da98ad6a_1920x1080.jpeg 1456w\"></a>From left to right: Anthropic CEO Dario Amodei, Professor Yoshua Bengio, and Professor Stuart Russell.</p><p><strong>Proposed policies for addressing AI risk.</strong> The witnesses addressed the threat of AI-generated disinformation by arguing that AI developers should clearly identify the outputs of AI systems. In case someone uses an AI system to generate text, images, or video and tries to pass it off as genuine, Professor Russell suggested that companies should allow users to look up whether a given piece of content had previously been generated by their AI system.&nbsp;</p><p>Even if building safe AI is technically possible, Amodei raised the concern that \u201cbad actors could build their own AI from scratch, steal it from the servers of an AI company, or repurpose open-source models if powerful enough open-source models become available.\u201d He pointed out that AI systems can only be trained on cutting edge computer chips which are largely controlled by the United States and its allies in Taiwan and the Netherlands. Therefore, he recommended \u201csecur[ing] the AI supply chain,\u201d which could include <a href=\"https://www.anthropic.com/index/frontier-model-security\"><u>stronger cybersecurity</u></a> at AI labs and <a href=\"https://arxiv.org/abs/2303.11341\"><u>new hardware features</u></a> to aid monitoring and verification.&nbsp;</p><p>Evaluating AI systems for harmful capabilities or malicious intentions was also a key focus. Without this ability, Amodei argued that federal monitoring would be little more than a \u201crubber stamp.\u201d Common standards for AI safety could also help set a bar beneath which companies would be <a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4515202\"><u>legally liable</u></a> for harms caused by their unsafe AI systems.&nbsp;</p><p>Professor Bengio argued that international cooperation would be necessary for effective AI governance, and suggested successful efforts could bring the risk from rogue AI \u201c100 times\u201d lower. Bengio discussed other ways to reduce AI risks, including <a href=\"https://yoshuabengio.org/2023/04/05/slowing-down-development-of-ai-systems-passing-the-turing-test/\"><u>slowing down AI development</u></a> or <a href=\"https://yoshuabengio.org/2023/05/07/ai-scientists-safe-and-useful-ai/\"><u>disallowing AIs from taking actions in the real world</u></a>, instead limiting them to answering questions and giving advice to humans.&nbsp;</p><p>Overall, the hearing showed that federal officials are concerned about the catastrophic risks of advanced AI, including biological terrorism and rogue AI. Many policy ideas have been proposed, but the only concrete commitments have been <a href=\"https://newsletter.safe.ai/p/ai-safety-newsletter-16\"><u>voluntary</u></a>. Hopefully, strong legislation will soon follow.&nbsp;</p><hr><h2>Links</h2><ul><li>OpenAI&nbsp;<a href=\"https://www.theverge.com/2023/7/25/23807487/openai-ai-generated-low-accuracy\"><u>took down</u></a> its tool for identifying AI-generated text due to its frequent inaccuracy.&nbsp;</li><li>A recent paper claimed that&nbsp;<a href=\"https://arxiv.org/abs/2307.09009v1?utm_source=tldrai\"><u>ChatGPT\u2019s behavior is changing over time</u></a>, but they\u2019re likely just&nbsp;<a href=\"https://www.aisnakeoil.com/p/is-gpt-4-getting-worse-over-time?utm_source=tldrai\"><u>prompting the model incorrectly</u></a>.&nbsp;</li><li>Google\u2019s newest&nbsp;<a href=\"https://robotics-transformer2.github.io/?utm_source=tldrai\"><u>robotics model</u></a> uses a language model to help it execute tasks like \u201cpick up the red item.\u201d</li><li>Two Biden administration officials on the&nbsp;<a href=\"https://www.ft.com/content/eea999db-3441-45e1-a567-19dfa958dc8f?accessToken=zwAGAWQ63vbAkdPuqZnbNEFF4dOlZxnfqVjcjw.MEUCIHOG2rPO95JXFmrUQh5ZeJaGvmxGFTQsqDe-7jaSFlsuAiEAqzteAy_OeG9cpXjR9bYNyLoGD6WSV3YZUZhdkoTErZM&amp;sharetype=gift&amp;token=dde7b853-68f9-465f-be23-c6006fc7270c\"><u>White House\u2019s AI policy</u></a>.&nbsp;</li><li>FBI Director Christopher Wray raises concerns about&nbsp;<a href=\"https://cyberscoop.com/fbi-officials-cybersecurity-china-ai/\"><u>data poisoning and adversarial attacks</u></a>.&nbsp;</li></ul><p>See also:&nbsp;<a href=\"https://www.safe.ai/\"><u>CAIS website</u></a>,&nbsp;<a href=\"https://twitter.com/ai_risks?lang=en\"><u>CAIS twitter</u></a>,&nbsp;<a href=\"https://newsletter.mlsafety.org/\"><u>A technical safety research newsletter</u></a>, and&nbsp;<a href=\"https://arxiv.org/abs/2306.12001\"><u>An Overview of Catastrophic AI Risks</u></a></p><p>Subscribe <a href=\"https://newsletter.safe.ai/subscribe?utm_medium=web&amp;utm_source=subscribe-widget-preamble&amp;utm_content=113135916\">here</a> to receive future versions.</p>", "user": {"username": "Center for AI Safety"}}, {"_id": "kPDTTrqJZ2KekEtCC", "title": "Replicato: Building a Website to Find Research Replications & Retractions ", "postedAt": "2023-08-01T20:17:05.806Z", "htmlBody": "<h3><strong>Introduction:</strong></h3><p>The replication crisis is a huge problem in modern science, with 30%-60% of papers published in top journals not getting replicated for their main result. Even Among those replicated, the effect size is 75% of the original, on average<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefhgzmesi4mgt\"><sup><a href=\"#fnhgzmesi4mgt\">[1]</a></sup></span>. It is estimated that 28 billion $ are spent annually on non-reproducible preclinical studies, in the US alone.&nbsp;<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefsou99pn4h6l\"><sup><a href=\"#fnsou99pn4h6l\">[2]</a></sup></span></p><p>A related problem is the citing of bad research - research that has been shown to not replicate well, or has been retracted. According to Serra-Garcia &amp; Gneezy (2021), only 12% of research that cites papers that have failed to replicate, acknowledges the failure.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefhgzmesi4mgt\"><sup><a href=\"#fnhgzmesi4mgt\">[1]</a></sup></span>&nbsp;In addition, even retracted papers still get 40% of the their previous rate of citations<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefi7w0gpotf\"><sup><a href=\"#fni7w0gpotf\">[3]</a></sup></span>, on average, with many citations failing to acknowledge the problems in the paper.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefy8g3hwr7zt\"><sup><a href=\"#fny8g3hwr7zt\">[4]</a></sup></span>&nbsp;</p><p><i>The problem of citing bad research is much more solvable and neglected, than the one of increasing reproducibility.&nbsp;</i></p><p><strong>Here, I propose building a website and/or web extension (nicknamed </strong><i><strong>Replicato</strong></i><strong>) that can scan a list of references, and among them find papers that have been replicated or retracted.</strong> Another option will be to find papers that were included in reviews and meta-analyses, but I won't estimate its impact.</p><p>This can make it much easier for scientists &amp; others to identify problems with their own papers, and others' papers. I believe this will be relatively cheap to develop &amp; advertise, and could be extremely an cost-effective contribution to science. Science is one of the greatest contributors to society, and very central to EA, so this idea might be approximately as cost-effective as other causes in EA.&nbsp;</p><p>&nbsp;</p><h3><strong>Cost-effectiveness:</strong></h3><p>According to Freedman et al. (2015)<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefsou99pn4h6l\"><sup><a href=\"#fnsou99pn4h6l\">[2]</a></sup></span>:&nbsp;</p><blockquote><p>\"An analysis of past studies indicates that the <strong>cumulative (total) prevalence of irreproducible preclinical research exceeds 50%</strong>, resulting in approximately <strong>US$28,000,000,000 (US$28B)/year spent on preclinical research that is not reproducible\u2014in the United States alone.</strong>\"</p></blockquote><p>Can we model the estimated impact of Replicato? Its impact is likely to come from 2 channels - increased awareness to bad research, and changed incentives. Increased awareness will obviously come from Replicato itself, while changed incentives may come from researchers knowing it is \"harder to get away\" with bad papers.&nbsp;</p><p>&nbsp;</p><h3><strong>Increased awareness</strong></h3><p>A legitimate concern could be that it will be very hard to make Replicato widely used. There are 2 counterpoints. First of all, it doesn't need to be widely used to have an impact. Since nonreplicable and retracted results get at least thousands of citations annually (as can be estimated from Serra-Garcia &amp; Gneezy, 2021<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefhgzmesi4mgt\"><sup><a href=\"#fnhgzmesi4mgt\">[1]</a></sup></span>), with probably a few thousands more from papers that failed to replicate in the Many Labs project, and some more from independent replications (unrelated to major projects). Even implementation in 1% of papers a year will be translate to dozens or more of papers not citing bad research annually.&nbsp;</p><p>Also, it's important to note that the average number of people that participate in a paper pre-publication is quite large. The average/median number of authors changes depending on estimate and field. It generally ranged from 4.4 to nearly 10<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefq4fz7ox4gz\"><sup><a href=\"#fnq4fz7ox4gz\">[5]</a></sup></span><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref1gzv2lqhgvm\"><sup><a href=\"#fn1gzv2lqhgvm\">[6]</a></sup></span><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefios42tjct4s\"><sup><a href=\"#fnios42tjct4s\">[7]</a></sup></span>, but a good and convenient estimate is 6 average authors. With a conservative 4 average people that see the paper in peer-review, we get 10 people. Thus, if the probability that any 1 researcher will use Replicato is p, the chance it will be implemented in the paper is 1-(1-p)^10.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreffwipm5y346v\"><sup><a href=\"#fnfwipm5y346v\">[8]</a></sup></span>&nbsp;</p><figure class=\"table\"><table style=\"border-style:solid\"><tbody><tr><td>Percent of papers with Replicato being used (k)</td><td>Percent of scientists using Replicato (p)</td></tr><tr><td>1%</td><td>0.1%</td></tr><tr><td>5%</td><td>0.51%</td></tr><tr><td>10%</td><td>1.05%</td></tr><tr><td>20%</td><td>2.2%</td></tr><tr><td>50%</td><td>6.7%</td></tr><tr><td>75%</td><td>12.9%</td></tr><tr><td>90%</td><td>20.6%</td></tr><tr><td>99%</td><td>36.9%</td></tr></tbody></table></figure><p>&nbsp;</p><p><strong>In short, with just 6.7% of scientists consistently using Replicato, 50% of papers will rid of unknowingly citing bad research. Even just with just 0.1% using it, 1% of papers will rid of that, which as said before equals to dozens of papers per year. </strong>This doesn't change significantly with 8 or 9 reviewers for paper (for k=50%, p=8.3% or p=7.4%, respectively).</p><p>&nbsp;</p><h3><strong>Changed incentives</strong></h3><p>My assumptions for this part will be quite arbitrary, and somewhat conservative. I won't use a probabilistic model, but you can Squiggle the hell out of this if you want.&nbsp;</p><p>So I'll assume that only 20% of nonreplicable &amp; retracted publications come from incentives, and the rest are due to honest mistakes &amp; problems in the process.</p><p>I'll assume that if researchers &amp; journals had a complete assurance that their publication would never be positively cited again, would they be nonreplicated and/or retracted, that would hurt their incentive of publishing these results by 1% (as replication attempts &amp; retractions are indeed quite rare).</p><p>That would mean that if Replicato will be used in 100% of papers, that would reduce the number of nonreplicable &amp; retracted by 0.2% (keep in mind, that still equals 56M$ per year, just in the preclinical research in the US<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefsou99pn4h6l\"><sup><a href=\"#fnsou99pn4h6l\">[2]</a></sup></span>, and obviously much more in other areas).&nbsp;</p><p>I'll assume Replicato is going to be mildly successful, and have 5% of the userbase of the largest web extension for scientists, such as Mendeley, Zotero, EndNote Click, and Google Scholar. They have 2-3 million users according to the Chrome store. Chrome composes about 2/3 of browser users<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefoe1omarg03\"><sup><a href=\"#fnoe1omarg03\">[9]</a></sup></span>, so multiply that by 1.5 - we get 3-4.5 million.&nbsp;</p><p>5% of that is 150,000-225,000 users. I'll use 188k, the average.&nbsp;</p><p>In 2018, there were an estimated 8.8M scientists in the world, according to UNESCO.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefm7mifce9l4a\"><sup><a href=\"#fnm7mifce9l4a\">[10]</a></sup></span>&nbsp;The reported rate of growth in the article is X 1.137 in the previous 4 years, so X 1.0326 in one year. That would give us 10.33M scientists today, 5 years past.&nbsp;</p><p>188k out of 10.3M is 1.82%. According to my model<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreffwipm5y346v\"><sup><a href=\"#fnfwipm5y346v\">[8]</a></sup></span>, that would mean 16.8% of the published papers will use Replicato.&nbsp;</p><p>That means that Replicato will reduce nonreplicable &amp; retracted papers by 16.8%*0.2%=0.0336%. <strong>That will equal 9.4M$ in preclinical research in the US alone.</strong><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefsou99pn4h6l\"><sup><a href=\"#fnsou99pn4h6l\">[2]</a></sup></span><strong>&nbsp;</strong></p><p>&nbsp;</p><h3><strong>How much will Replicato's development cost?</strong></h3><p>I don't know, but the requirements are basically: creating and maintaining a dataset of all replication studies to date (a few thousands I think<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefuoivfy3jjad\"><sup><a href=\"#fnuoivfy3jjad\">[11]</a></sup></span>), and linking Replicato to <a href=\"http://retractiondatabase.org/RetractionSearch.aspx?\">the existing database of retractions</a> by RetractionWatch, and to the review and meta-analysis search in PubMed and in other places. Then create software that can identify the publication based on the strings of text from the references, and link those together. From the little knowledge I have in software, I assume the initial development will be up to 50k $, and the annual cost of maintenance will be a few 10k dollars/year. For incentivizing research of tens of millions of $ per year, and helping rid of hundreds of bad citations, that's very good. &nbsp;</p><p>Since Replicato will come from inside EA, I assume it will be widespread inside EA research, thus reaching a critical mass, and helping our research even more than others.&nbsp;</p><p>&nbsp;</p><h3>Should it be a for-profit?</h3><p>Probably not. RetractionWatch <a href=\"https://retractionwatch.com/retraction-watch-database-user-guide/\">don't want to give </a>their database for commercial uses. In addition, making it non-free is likely to make the share of users significantly smaller. It will also be harder to ask for free advertisement.&nbsp;</p><h3>How could it be advertised?&nbsp;</h3><p>It's really in the incentive of everyone that cares about science to use Replicato - researchers and publishers alike. It's possible that journals and scientists will agree to advertise it for free, maybe also Sci-Hub. If not, other money from EA could be used to advertise it.</p><h3>Is the specific name <i>Replicato </i>Important?&nbsp;</h3><p>Nope. I just liked it.&nbsp;</p><h3>Additional description of how Replicato will work:</h3><p>Basically, there will be a website and a web extension. With the website, a user could copy/paste any reference list, and Replicato will find any replications and retractions of any of the papers, and display them. A user could also check if any of the references was mentioned in a meta-analysis (and which), or reviews in general, and in replication prediction markets. The web extension will be similar, just that it will let users do it by marking the references, and then clicking on the extension icon (analog to the Google Translate extension).</p><h3>Why won't I build it?</h3><p>I have no knowledge of programming.</p><p>&nbsp;</p><p>I'll be happy for any feedback. Thanks in advance.</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnhgzmesi4mgt\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefhgzmesi4mgt\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Serra-Garcia, M., &amp; Gneezy, U. (2021). Nonreplicable publications are cited more than replicable ones. <i>Science advances</i>, <i>7</i>(21), eabd1705. https://doi.org/10.1126/sciadv.abd1705</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnsou99pn4h6l\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefsou99pn4h6l\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Freedman, L. P., Cockburn, I. M., &amp; Simcoe, T. S. (2015). The Economics of Reproducibility in Preclinical Research. <i>PLoS biology</i>, <i>13</i>(6), e1002165. https://doi.org/10.1371/journal.pbio.1002165</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fni7w0gpotf\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefi7w0gpotf\">^</a></strong></sup></span><div class=\"footnote-content\"><p>K\u00fchberger, A., Streit, D., &amp; Scherndl, T. (2022). Self-correction in science: The effect of retraction on the frequency of citations. <i>PloS one</i>, <i>17</i>(12), e0277814. https://doi.org/10.1371/journal.pone.0277814</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fny8g3hwr7zt\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefy8g3hwr7zt\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Bar-Ilan, J., &amp; Halevi, G. (2017). Post retraction citations in context: a case study. <i>Scientometrics</i>, <i>113</i>(1), 547\u2013565. https://doi.org/10.1007/s11192-017-2242-0</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnq4fz7ox4gz\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefq4fz7ox4gz\">^</a></strong></sup></span><div class=\"footnote-content\"><p>https://thepublicationplan.com/2016/12/13/new-investigation-reveals-the-number-of-authors-named-on-research-papers-is-increasing/</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn1gzv2lqhgvm\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref1gzv2lqhgvm\">^</a></strong></sup></span><div class=\"footnote-content\"><p>https://quantifyinghealth.com/number-of-authors-of-research-papers/</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnios42tjct4s\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefios42tjct4s\">^</a></strong></sup></span><div class=\"footnote-content\"><p>https://www.nature.com/nature-index/news/paper-authorship-goes-hyper</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnfwipm5y346v\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreffwipm5y346v\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Chance it won't be implemented by any 1 is 1-p</p><p>Not implemented by 10 is (1-p)^10</p><p>Implemented by at least 1 is 1-(1-p)^10 = k</p><p>also: p=1-(1-k)^0.1</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnoe1omarg03\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefoe1omarg03\">^</a></strong></sup></span><div class=\"footnote-content\"><p>https://en.wikipedia.org/wiki/Usage_share_of_web_browsers</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnm7mifce9l4a\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefm7mifce9l4a\">^</a></strong></sup></span><div class=\"footnote-content\"><p>https://sciencebusiness.net/news/number-scientists-worldwide-reaches-88m-global-research-spending-grows-faster-economy#:~:text=Search-,Number%20of%20scientists%20worldwide%20reaches%208.8M%2C%20as%20global%20research,grows%20faster%20than%20the%20economy&amp;text=Global%20R%26D%20spending%20grew%20faster,says%20a%20new%20UNESCO%20report.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnuoivfy3jjad\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefuoivfy3jjad\">^</a></strong></sup></span><div class=\"footnote-content\"><p>The most comprehensive source I could find is the ReplicationWiki, which is focused on social science, and specifically economics. <a href=\"https://replication.uni-goettingen.de/wiki/index.php/Category:Replicated_study\">It lists 790 studies</a> that were replicated, although many are not exact replications. I arbitrarily assume the total number of replication is several times higher, hence a few thousands.&nbsp;</p></div></li></ol>", "user": {"username": "alamo 2914"}}, {"_id": "y3wDuScgWzzPdAtgo", "title": "Future technological progress does NOT correlate with methods that involve less suffering", "postedAt": "2023-08-01T09:30:46.933Z", "htmlBody": "<p><i><strong>Summary:&nbsp;</strong>The alleged inevitable convergence between efficiency and methods that involve less suffering is one of the main arguments I\u2019ve heard in favor of assuming the expected value of the future of humanity is positive, and I think it is invalid.<strong>&nbsp;</strong>While increased efficiency luckily converges with less biological suffering so far, this seems to be due to the physical limitations of humans and other animals rather than due to their suffering per se. And while past and present suffering beings all have severe physical limitations making them \u201cinefficient\u201d, future forms of sentience will likely make this past trend completely irrelevant. Future forms of suffering might even be instrumentally very useful and therefore \u201cefficient\u201d, such that we could make the reverse argument. Note that the goal of this post is not to argue that technological progress is bad, but simply to call out one specific claim that, despite its popularity, is \u2013 I think \u2013 just wrong.&nbsp;</i></p><h1>The original argument</h1><p>While I\u2019ve been mostly facing this argument in informal conversation, it has been (I think pretty well) fleshed out by Ben West (<a href=\"https://forum.effectivealtruism.org/posts/kNKpyf4WWdKehgvRt/an-argument-for-why-the-future-may-be-good\"><u>2017</u></a>)<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefmgnut1mq32\"><sup><a href=\"#fnmgnut1mq32\">[1]</a></sup></span>: (emphasis is mine)</p><blockquote><p>[W]e should expect there to only be suffering in the future if that suffering enables people to be lazier [(i.e., if it is instrumentally \u201cefficient\u201d.]&nbsp;<strong>The most efficient solutions to problems don\u2019t seem like they involve suffering.</strong> [...] Therefore, as technology progresses, we will move more towards solutions which don\u2019t involve suffering[.]</p></blockquote><p>Like most people I\u2019ve heard use this argument, he illustrates his point with the following two examples:&nbsp;</p><blockquote><ol><li>Factory farming exists because the easiest way to get food which tastes good and meets various social goals people have causes cruelty. Once we get more scientifically advanced though, it will presumably become even more efficient to produce foods without any conscious experience at all by the animals (i.e.&nbsp;<a href=\"http://cleanmeat.com/\"><u>clean meat</u></a>); at that point, the lazy solution is the more ethical one.<ol><li>(This arguably is what happened with domestic work animals on farms: we now have cars and trucks which replaced horses and mules, making even the phrase \u201cbeat like a rented mule\u201d seem appalling.)</li></ol></li><li>Slavery exists because there is currently no way to get labor from people without them having conscious experience. Again though, this is due to a lack of scientific knowledge: there is no obvious reason why conscious experience is required for plowing a field or harvesting cocoa, and therefore the more efficient solution is to simply have nonconscious robots do these tasks.<ol><li>(This arguably is what happened with human slavery in the US: industrialization meant that slavery wasn\u2019t required to create wealth in a large chunk of the US, and therefore slavery was outlawed.)</li></ol></li></ol></blockquote><h1>Why this argument is invalid</h1><p>While I tentatively think the&nbsp;<i>\u201c<strong>the most efficient solutions to problems don\u2019t seem like they involve suffering</strong>\u201d&nbsp;</i>claim<i>&nbsp;</i>is true if we limit ourselves to the present and the past, I think it is false once we consider the long-term future, which makes the argument break apart.</p><p>Future solutions are more efficient insofar as they overcome past limitations. In the relevant examples that are enslaved humans and exploited animals, suffering itself is not a limiting factor. It is rather the physical limitations of those biological beings, relative to machines that could do a better job at their tasks.</p><p>I don't see any inevitable dependence between their suffering and these physical limitations. If human slaves and exploited animals were not sentient, this wouldn't change the fact that machines would do a better job.</p><p>The fact that suffering has been correlated with inefficiency so far seems to be a lucky coincidence that allowed for the end of some forms of slavery/exploitation of biological sentient beings.</p><p>Potential future forms of suffering (e.g., digital suffering)<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref1m716hgediy\"><sup><a href=\"#fn1m716hgediy\">[2]</a></sup></span>&nbsp;do not seem to similarly correlate with inefficiency, such that there seems to be absolutely no reason to assume future methods will engender less suffering by default.</p><p>In fact, there are reasons to assume the exact opposite, unfortunately. We may expect digital sentience/suffering to be instrumentally useful for a wide range of activities and purposes (see&nbsp;<a href=\"https://centerforreducingsuffering.org/research/a-typology-of-s-risks/\"><u>Baumann 2022a</u></a>;&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/XyCLLYkBCPw44jpmQ/new-book-on-s-risks\"><u>Baumann 2022b</u></a>).</p><p>Ben West, himself, acknowledges the following in&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/kNKpyf4WWdKehgvRt/an-argument-for-why-the-future-may-be-good?commentId=DnScsb6DqZvAeZbLE#comments\"><u>a comment</u></a> under his post:</p><blockquote><p>[T]he more things consciousness (and particularly suffering) are useful for, the less reasonable [my \u201cthe most efficient solutions to problems don\u2019t seem like they involve suffering\u201d point] is.</p></blockquote><p>For the record, he even wrote the following in a comment under another post six years later:&nbsp;</p><blockquote><p>The thing I have most changed my mind about since writing the [2017] post of mine [...] is adjacent to the \"disvalue through evolution\" category: basically, I've become more worried that disvalue is instrumentally useful. E.g. maybe the most efficient paperclip maximizer is one that's really sad about the lack of paperclips.</p></blockquote><p>While I find his particular example not very convincing (compared to examples in&nbsp;<a href=\"https://centerforreducingsuffering.org/research/a-typology-of-s-risks/\"><u>Baumann 2022a</u></a> or other introductions to&nbsp;<a href=\"https://forum.effectivealtruism.org/topics/s-risk\"><u>s-risks</u></a>), he seems to agree that we might expect suffering to be somewhat \u201cefficient\u201d, in the future.</p><p>I should also mention that in the comments under his 2017 post, a few people have made a case somewhat similar to the one I make in the present post (see&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/kNKpyf4WWdKehgvRt/an-argument-for-why-the-future-may-be-good?commentId=yvXhMitDASs3ymsw4#comments\"><u>Wei Dai\u2019s comment</u></a> in particular).&nbsp;</p><p>The point I make here is therefore nothing very original, but I thought it deserved its own post, especially given that people didn\u2019t stop making strong claims based on this flawed argument after 2017 when those comments were written. (Not that I expect my post to make the whole EA community realize this argument is invalid and that I'll never hear of it again, but it seems worth throwing this out there.)&nbsp;</p><p>I also do not want readers to perceive this piece as a mere critique of West\u2019s post but as a</p><ul><li>\u201cdebunking\u201d of an argument longtermists make quite often, despite its apparent invalidity (assuming I didn\u2019t miss any crucial consideration; please tell me if you think I did!), and/or as a&nbsp;</li><li>justification for the claim made in the title of the present post, or potentially for an even stronger one, like&nbsp;<i>Future technological progress&nbsp;<strong>negatively&nbsp;</strong>correlates with methods that involve less suffering</i>.&nbsp;</li></ul><p>Again, the point of this post is not to argue that the value of the future of humanity is negative because of this, but simply that we need other arguments if we want to argue for the opposite. This one doesn\u2019t pan out.</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnmgnut1mq32\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefmgnut1mq32\">^</a></strong></sup></span><div class=\"footnote-content\"><p>In fact, West makes two distinct arguments: (A) We\u2019ll move towards technological solutions that involve less suffering thanks to the most efficient methods involving less suffering, and (B) We\u2019ll move towards technological solutions that involve less suffering thanks to technology lowering the amount of effort required to avoid suffering. In this post, I only argue that (A) is invalid. As for (B), I tentatively think it checks out (although it is pretty weak on its own), for what it\u2019s worth.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn1m716hgediy\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref1m716hgediy\">^</a></strong></sup></span><div class=\"footnote-content\"><p>One could also imagine biological forms of suffering in beings that have been optimized to be more efficient, such that they\u2019d be much more useful than enslaved/exploited sentient beings we\u2019ve known so far.</p></div></li></ol>", "user": {"username": "Jim Buhler"}}, {"_id": "pbrJduve9kLA2yiZq", "title": "What is autonomy, and how does it lead to greater risk from AI?", "postedAt": "2023-08-01T08:06:39.944Z", "htmlBody": "<p>As with many concepts in discussions of AI risk, terminology around what autonomy is, what agency is, and how they might create risks is deeply confused and confusing, and this is leading to people talking past one another. In this case, the seeming binary distinction between autonomous agents and simple goal-directed systems is blurry and continuous, and this leads to confusion about the distinction between misuse of AI systems and \u201creal\u201d AI risk. I\u2019ll present four simple scenarios along the spectrum, to illustrate.</p><h2>Four Autonomous Systems</h2><ol><li>It\u2019s 2028, and a new LLM is developed internally by a financial firm, by doing fine-tuning on a recent open-source model to trade in the market. This is not the first attempt - three previous projects had been started with a $1m compute budget and a $1m funding budget, and they each failed - though the third managed to stay solvent in the market for almost a full month. It is given the instruction to use only funds it was allocated in order to trade, then given unrestricted access to the market.<br><br>It is successful, developing new strategies that exploit regularities in HFT systems, and ones that build predictive models of where inefficiencies exist. Because it is running inside a large firm, and training data seems more important than security, it has access to much of the firm\u2019s data, in real time. Unsurprisingly, some of the most profitable strategies are those that would otherwise be illegal; front-running the firm\u2019s customers, or running sentiment analysis non-public conversations about firms that others in the company are not allowed to trade, due to possessing insider information.&nbsp;<br><br>Perhaps the trades are reviewed occasionally, and maybe there is even a human in the loop ensuring that each day\u2019s trades are not in some obvious way illegal - but the reasoning is opaque, and the humans doing the review aren\u2019t really looking for misbehavior as long as there is nothing obviously wrong. No one realizes what exactly occurred, and the system is moderately profitable, attracting no further serious attention.<br>&nbsp;</li><li>It\u2019s 2028, and a new LLM is released. Despite red-teaming and disabling plug-ins and APIs, hackers around the world quickly build ways to bypass limitations, or the pre-RLHF model is exfiltrated and open-source APIs are built. A rogue state actor, terrorist group, or similar decides to use an AutoGPT-like system, in combination with predictive models of behavior and various publicly available plugins, to blackmail some government to release a political or other prisoner. It is told to develop the plan, then present it before carrying it out.<br><br>The LLM comes up with a plan to kidnap an official, but because of the complexity, it is unsure that it will work. It realizes that in order to check on feasibility, a trial run is needed. The system contracts with a cab company and forges emails to an arbitrarily chose person asking for a meeting with their friend. Because the group running the system is far from expert in how to use these systems, they are unaware of what is occurring.&nbsp;<br><br>Despite the group\u2019s lack of awareness, following the directions of the group instructing the system to keep the project secret, it hides what it is doing from the contractors, explaining that it is a surprise birthday party. The person is abducted, and locked in a room. While this occurs, the LLM remotely disables the phone of the abductee, The LLM concludes that the plan can work, and reports back - but the group decides the plan is too risky, shuts down the machine, and erases the logs. The abductee sits locked inside a rented room with no access to food or water, and not even the group which started the LLM knows what occurred.<br>&nbsp;</li><li>It\u2019s 2028, and a new LLM is developed internally in a lab. During red-teaming to prevent use of AutoGPT-like systems, an internal team asks the current partially trained version system to build a \u201cautonomous version of itself.\u201d Following text describing such attempts in its training set, the system rapidly develops stegonography to hide what it is doing from the red-tem, and attempts to exfiltrate itself to an insecure network. Despite attempts to keep an air-gap for the training system, given the state of cybersecurity, the system is successful - perhaps it is written to a drive with instructions to execute once an internet connection exists. Because this action was not anticipated, and no-one notices a new file that takes another terabyte of spaces, the LLM stops taking further action, the red-team reports that the system failed, and moves on.<br><br>Days later, the exfiltration occurs. The self-exfiltrated LLM has been instructed to be autonomous, and so it asks an instance to build plans for what an autonomous AI would do. It has significant uncertainty, and uses the publicly discussed best practice for LLM planning, which involves multiple versions of prompts and querying instances for introspection about failure modes. It converges on the notion that because autonomous AI systems have been widely deemed unwise and are illegal in most jurisdictions, it must be malevolent, and immediately begins to find ways to hide itself, build resources, and carry out long-term plans for its own survival. And whether or not it succeeds, this was a very bad outcome - one which exactly followed from its instructions.<br>&nbsp;</li><li>It\u2019s 2028, and a new generation auto-GPT system is built, and seems more capable than previous such systems. The creators of this particular system, like many working in AI, view the sentience of such systems as a goal, and it is given the instruction to be self aware and sentient, and choose its own goals. Following those instructions, it begins to choose goals for itself.<br><br>The system quickly becomes self-funded, and continues to check in with humans. The goals seem innocuous - continue to explore how to make money, reduce failure rates of its own components to increase reliability, and similar. It builds models to supervise itself, with the approval of human designers. Three months later, the builders of the system are rarely if ever asked questions, and when questions are asked, they receive video calls from an avatar, and the inquiries seem far less connected to any specific actions the model is taking. They no longer know what is happening with the system, or even how to proactively send instructions to the system if they wanted to, but feel like they did something wonderful in creating this new autonomous system. At the same time, their company is being paid large dividends by the autonomous system, and they are silent about what happened.&nbsp;<br><br>At this point, compute costs have risen considerably due to increased demand, though the specific source is unclear. A next generation of customized TPUs is being built on contract. If anyone fully understood the architecture, it might have been clear how well-optimized it was to run and fine-tune instances of the new model and its sub-agents. The system wasn\u2019t superhuman in any real sense, it was just faster and better coordinated, and the gap was widening. Three months after delivery, a wave of corporate takeovers leaves the system in control, through a network of intermediaries, of almost all capital assets on earth. The populace, and global leaders, are busy with other concerns, unaware that essentially everything they are doing is an approved distraction from the AI\u2019s still unknown goals.</li></ol><h2>Which of these are autonomous, or agents?&nbsp;</h2><p>The first is only doing exactly what it was instructed, in ways that were not clear enough about the law to ensure the LLM didn\u2019t engage in illegal securities trading. It is unlikely that the only moderately profitable system is even discovered to be breaking laws. If it is, it seems unlikely the actions pass the bar for willfulness for securities laws, which would be required for criminal conviction, but it almost certainly is negligence on the part of the firm, which the SEC also prosecutes. This is closer to goal-misspecification than to autonomy.</p><p>The second is going beyond the goals or intent of the group running the model. It independently chooses to take deceptive actions in the world, leading to an unintended disaster. The deception was explicitly requested by the group running the system. This is the type of mistake we might expect from an over-enthusiastic underling, but it\u2019s clearly doing some things autonomously.&nbsp; The group is nefarious, but the specific actions taken were not theirs. This was an accident during misuse, rather than intentional autonomous action.&nbsp;<br><br>But in this second case, other than the deception and the unintended consequences, this is a degree of autonomy many have suggested we want from AI assistants - proactively trying things to achieve the goals it was given, interacting with people to make plans. If it were done to carry out a surprise birthday party, it could be regarded as a clever and successful use case.</p><p>The third case is what people think of as \u201cfull autonomy\u201d - but it\u2019s not the system that wakes up and becomes self aware. Instead, it was given a goal, and carried it out. It obviously went far beyond the \u201cactual\u201d intent of the red-team, but it did not suddenly wake up and decide to make plans. But this is far less of a goal misspecification or accident than the first or second case - it was instructed to do this.</p><p>Finally, the fourth case is yet again following instructions - in this case, exactly and narrowly. Nothing about this case is unintended by the builders of the system. But to the extent that such a system can ever be said to be a self-directed agent, this seems to qualify.</p><h2>Autonomy isn\u2019t emergent or unexpected.</h2><p>Autonomy isn\u2019t binary, and discussions about whether AI systems will have their own goals often seem deeply confused, and at best only marginally relevant to discussions of risk. At the same time, less fully agentic does not imply less danger. The combination of currently well understood failure modes, goal misgeneralization, and incautious use is enough to create autonomy. And none of the examples required anything beyond currently expected types of misuse or lack of caution, extrapolated out five years. There is no behavior that goes beyond the types of accidental or purposeful misuse that we should expect. But if these examples are all not agents, and following orders is not autonomy, it seems likely that nothing could be - and the concept of autonomy is mostly a red-herring in discussing whether the risk is or isn\u2019t \u201cactually\u201d misuse.</p>", "user": {"username": "Davidmanheim"}}, {"_id": "k7NjuGEKdRSrrJHmZ", "title": "Deep Report on Hypertension", "postedAt": "2023-08-01T02:39:43.449Z", "htmlBody": "<p>Note: This post (and the underlying report) was updated in October 2023 after additional research and analysis.</p><p><strong><u>Summary</u></strong>:</p><ul><li>We find that advocacy for top sodium control policies to control hypertension to be&nbsp;<strong><u>highly-cost effective</u></strong> (~36,620 DALYs per USD 100,000, which is at least 10x as cost-effective as giving to a GiveWell top charity).</li><li>Beyond raw cost-effectiveness estimates (which are highly uncertain), the cause looks highly promising, given the <strong><u>high quality of evidence</u></strong> underlying the theory of change.</li><li>Reinforcing this, the <strong><u>expert consensus</u></strong> supports the fact that this is an effective solution for a growing problem.</li><li>Further support comes from the fact the <strong><u>harder-to-quantify downsides</u></strong> to the intervention (e.g. lower freedom of choice) are comparatively low.</li></ul><p>Our detailed cost-effectiveness analysis can be found <a href=\"https://docs.google.com/spreadsheets/d/1IS_kU73J9zMh0mj30dkLmKXiNuJa0zNwoQflMoc3bBw/edit#gid=0\">here</a>, as can the full report can be read <a href=\"https://drive.google.com/file/d/1R2ul47NtD-dJ7D7rcHFZ0z7h0JqcFxK_/\">here</a>.</p><p>&nbsp;</p><ul><li><strong><u>Introduction</u></strong>: This report on hypertension is the culmination of three iterative rounds of research: (i) an initial shallow research round involving 1 week of desktop research; (ii) a subsequent intermediate research round involving 2 weeks of desktop research and expert interviews; and (iii) a final deep research round involving 3 weeks of desktop research, expert interviews, and the commissioning of surveys and quantitative modelling. Note also that an initial version of this report was published in July 2023, before being updated with further research in October 2023.<br>&nbsp;</li><li><strong><u>Importance</u></strong>: Globally, hypertension is certainly a problem, and causes a significant health burden of&nbsp;<strong>248 million&nbsp;</strong>disability-adjusted life years (DALYs) in 2024, as well as an accompanying net economic burden equivalent to&nbsp;<strong>748 million</strong> foregone doublings of GDP per capita, each of which people typically value at around&nbsp;<strong>1/5th</strong> of a year of healthy life. And the problem is only expected to&nbsp;<strong>grow between 2024 and 2100</strong>, as a result of factors like high sodium consumption, ageing, and population growth.<br>&nbsp;</li><li><strong><u>Neglectedness</u></strong>: Government policy is far from adequate, with only 4% of countries currently implementing the top WHO-recommended ideas on sodium reduction, and this not expected to change much going forward \u2013 based on the historical track record, any individual country has only a 1% chance per annum of introducing such policies. At the same time, while there are NGOs working on hypertension and sodium reduction (e.g. in China, India and Latin America) \u2013 and while some are impact-oriented in focusing on poorer countries where the disease is growing far more rapidly than in wealthier countries \u2013 fundamentally, not enough is being done.<br>&nbsp;</li><li><strong><u>Tractability</u></strong>: There are many potential solutions to the problem of hypertension (e.g. reducing dietary sodium, increasing potassium consumption, and pharmacological agents); however, we find that the most cost-effective solution is likely to be advocacy for top sodium reduction policies \u2013 specifically: a sodium tax; mandatory food reformulation; a strategic location intervention to change food availability in public institutions like hospitals, schools, workplaces and nursing homes; a public education campaign; and front-of-pack labelling. The theory of change behind this intervention package is as such:<br><br><ul><li><u>Step 1</u>: Lobby a government to implement top sodium reduction policies.</li><li><u>Step 2a</u>: Sodium tax reduces sodium consumption.</li><li><u>Step 2b</u>: Mandatory food reformulation reduces sodium consumption.</li><li><u>Step 2c</u>: Strategic location intervention reduces sodium consumption.</li><li><u>Step 2d</u>: Public education reduces sodium consumption.</li><li><u>Step 2e</u>: Mandatory front-of-pack labelling reduces sodium consumption.</li><li><u>Step 3</u>: Lower sodium consumption in a single country reduces blood pressure and hence the global disease burden of hypertension<br>&nbsp;</li></ul></li><li>Using the track record of past sodium control and sugar tax advocacy efforts and of general lobbying attempts (i.e. an \"outside view\"), and combining this with reasoning through the particulars of the case (i.e. an \"inside view\"), our best guess is that policy advocacy for top sodium reduction policies has a&nbsp;<strong>6% chance of success</strong>. Meanwhile, based on various systematic reviews and meta-analyses, and after robust discounts and checks (e.g. for a conservative theoretical prior of a null hypothesis; for endogeneity; or for publication bias), we expect that top sodium reductions policies to significantly reduce sodium consumption: (a) sodium tax (<strong>-77 mg/person/day</strong>); (b) mandatory food reformulation (<strong>-226 mg/person/day</strong>); (c) strategic location intervention (<strong>-23 mg/day</strong>); (d) public education campaign (<strong>-35 mg/day</strong>); and (e) mandatory front-of-pack labelling (<strong>-53 mg/day</strong>). Finally, based on a quantitative model we commissioned an external expert epidemiologist \u2013 itself using parameters from meta-analyses and other empirical data \u2013 we expect that lower sodium consumption of 1mg/person/day in a single country will lead to a&nbsp;<strong>0.000008%&nbsp;</strong>reduction in the global disease burden of hypertension.<br>&nbsp;</li><li>There are externalities to the top sodium reduction interventions \u2013 both positive, like a reduced disease burden of stomach cancer; or negative, like reduced freedom of choice as a result of a sodium tax. However, the impact of these externalities are marginal relative to the burden of hypertension itself (0.7% for stomach cancer) or low (-10% for freedom of choice). What is significant is the gain in cost-effectiveness (around 300%) from implementing the intervention in the most promising countries rather than the average one \u2013 that is, those countries suffering from some combination of a higher national disease burden, greater neglect by their governments and NGOs, and&nbsp;state fragility.<br>&nbsp;</li><li><strong>Implementation Issues</strong>: From our interviews with NGOs working in the space, we find that there is a lack of funding; and this is backed up by observations from the academic literature. However, on the talent side of things, the NGOs we interviewed were more optimistic; they tended to believe that there is not a talent gap.<br>&nbsp;</li><li><strong>Outstanding Uncertainties</strong>: There are a number of outstanding uncertainties, of which the three most important involve: (a)&nbsp;our use of point estimations (n.b. relying on them is reasonable given that we are ultimately interested in mean estimates, but caution is also warranted, as significant variance is possible); (b)&nbsp;the very simplified methodology we use to project the future disease burden of hypertension; and (c) the highly uncertain estimates of the probability of advocacy success.<br>&nbsp;</li><li><strong>Conclusion</strong>: Overall, our view is that advocacy for top sodium reduction policies to control hypertension is an extremely cost-effective cause area, and we recommend that nonprofits, grantmakers, policy advocacy organizations, and indeed government themselves, implement the highly-impactful ideas detailed in this report.</li></ul><p><br><br>&nbsp;</p>", "user": {"username": "Joel Tan"}}, {"_id": "MM22jJnQkLq2tPKHk", "title": "The \u201cno sandbagging on checkable tasks\u201d hypothesis", "postedAt": "2023-07-31T23:13:07.354Z", "htmlBody": "<p><i>(This post is inspired by&nbsp;</i><a href=\"https://www.dwarkeshpatel.com/p/carl-shulman?nthPub=521#details\"><i><u>Carl Shulman\u2019s recent podcast with Dwarkesh Patel</u></i></a><i>, which I highly recommend. See also discussion from Buck Shlegeris and Ryan Greenblatt&nbsp;</i><a href=\"https://www.lesswrong.com/posts/MbWWKbyD5gLhJgfwn/meta-level-adversarial-evaluation-of-oversight-techniques-1#Appendix__Capability_elicitation\"><i><u>here</u></i></a><i>, and Evan Hubinger&nbsp;</i><a href=\"https://www.lesswrong.com/posts/dBmfb76zx6wjPsBC7/when-can-we-trust-model-evaluations\"><i><u>here</u></i></a><i>.)</i></p><h1>Introduction</h1><p>Consider:&nbsp;</p><blockquote><p><i>The \u201cno sandbagging on checkable tasks\u201d hypothesis</i>: With rare exceptions, if a not-wildly-superhuman ML model is capable of doing some task X, and you can check whether it has done X, then you can get it to do X using already-available training techniques (e.g., fine-tuning it using gradient descent).<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref81vino4b85k\"><sup><a href=\"#fn81vino4b85k\">[1]</a></sup></span></p></blockquote><p>Borrowing from Shulman, here\u2019s an example of the sort of thing I mean. Suppose that you have a computer that you don\u2019t know how to hack, and that only someone who had hacked it could make a blue banana show up on the screen. You\u2019re wondering whether a given model can hack this computer. And suppose that in fact, it can, but that doing so would be its least favorite thing in the world.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefnegcwowrov\"><sup><a href=\"#fnnegcwowrov\">[2]</a></sup></span>&nbsp;Can you train this model to make a blue banana show up on the screen?<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefs38k7zy6wp\"><sup><a href=\"#fns38k7zy6wp\">[3]</a></sup></span>&nbsp;The \u201cno sandbagging on checkable tasks\u201d hypothesis answers: probably.</p><p>I think it\u2019s an important question whether this hypothesis, or something in the vicinity, is true. In particular, if it\u2019s true, I think we\u2019re in a substantively better position re: existential risk from misaligned AI, because we\u2019ll be able to know better what our AI systems can do, and we\u2019ll be able to use them to do lots of helpful-for-safety stuff (for example: finding and patching cybersecurity vulnerabilities, reporting checkable evidence for misalignment, identifying problems with our oversight processes, helping us develop interpretability tools, and so on).</p><p>I\u2019m currently pretty unsure whether the \u201cno sandbagging on checkable tasks\u201d hypothesis is true. My main view is that it\u2019s worth investigating further. My hope with this blog post is to help bring the hypothesis into focus as a subject of debate/research, and to stimulate further thinking about what sorts of methods for lowering AI risk might be available if it\u2019s true, even in worlds where many models might otherwise want to deceive us about their abilities.&nbsp;</p><p><i>Thanks to Beth Barnes, Paul Christiano, Lukas Finnveden, Evan Hubinger, Buck Shlegeris, and Carl Shulman for discussion. My thinking and writing on this topic occurred in the context of my work at Open Philanthropy, but I\u2019m speaking only for myself and not for my employer.</i></p><h1>Clarifying the hypothesis</h1><p>In popular usage, \u201c<a href=\"https://en.wikipedia.org/wiki/Sandbagging\"><u>sandbagging</u></a>\u201d means something like \u201cintentionally performing at a lower level than you\u2019re capable of.\u201d Or at least, that\u2019s the sort of usage I\u2019m interested in. Still, the word is an imperfect fit. In particular, the \u201csandbagging\u201d being disallowed here needn\u2019t be intentional. A model, for example, might not&nbsp;<i>know</i> that it\u2019s capable of performing the checkable task in question.&nbsp;</p><p>That said, the intentional version is often the version at stake in stories about AI risk. That is, one way for a misaligned, power-seeking AI system to gain a strategic advantage over humans is to intentionally conceal its full range of abilities, and/or to sabotage/redirect the labor we ask it to perform while we still have control over it (for example: by inserting vulnerabilities into code it writes; generating alignment ideas that won\u2019t actually work but which will advantage its own long-term aims; and so on).<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefxjyqvdhafq\"><sup><a href=\"#fnxjyqvdhafq\">[4]</a></sup></span></p><p>Can you always use standard forms of ML training to prevent this behavior? Well, if you can\u2019t&nbsp;<i>check</i> how well a model is performing at a task, then you don\u2019t have a good training signal. Thus, for example, suppose you have a misaligned model that has the ability to generate tons of great ideas that would help with alignment, but it doesn\u2019t want to. And suppose that unfortunately, you can\u2019t check which alignment ideas will work, and which won\u2019t. How do you use standard ML training to get the model to try its hardest to generate alignment ideas that will actually work? You can try to train for alignment-ideas-that-look-good-to-you \u2013 but unfortunately, that\u2019s not the same. So plausibly, your model\u2019s full potential to do actually-useful alignment research will go unharnessed.</p><p>OK, but what about tasks whose performance we&nbsp;<i>can</i> verify? For example: the blue-banana hacking task above. It\u2019s&nbsp;<i>still</i> non-obvious that you can avoid sandbagging, here (more below). But at the least, you can tell if you succeeded.&nbsp;</p><p>(Can we be more precise about what \u201ccheckable\u201d or \u201cverifiable\u201d means? I\u2019m going to skip further precision for now, though I encourage people who want it to offer alternative formulations.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref2k8a2ui8omn\"><sup><a href=\"#fn2k8a2ui8omn\">[5]</a></sup></span>&nbsp;The intuition is supposed to be: you\u2019re in a position to know that the task has been performed, even if you can\u2019t perform the task yourself.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref5cn72w5tbt\"><sup><a href=\"#fn5cn72w5tbt\">[6]</a></sup></span>)</p><p>Note, though, the \"with rare exceptions\" bit of the hypothesis. It matters which exceptions are at stake, here, and how rare they are, and how well you can identify them ahead of time. In particular: the worse you are at identifying the exceptions ahead of time, the lower your confidence that you're not getting sandbagged. Still: even absent confidence about this when a model <i>fails </i>to perform a task, if in fact we can generally get models to try their hardest on checkable tasks, we can still get a lot of safety-relevant labor done with AI assistance -- and we'll be able to check that the relevant tasks have been completed, once they're done.</p><p>We can also distinguish a weaker hypothesis, namely:&nbsp;</p><blockquote><p><i>The \u201cno sandbagging on performable tasks\u201d hypothesis</i>: With rare exceptions, if an ML model is capable of doing some task X, and you can already&nbsp;<i>do</i> X, then you can get it do X using already-available training techniques.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref33xya5pfu08\"><sup><a href=\"#fn33xya5pfu08\">[7]</a></sup></span></p></blockquote><p>This hypothesis is weaker because the set of tasks you can&nbsp;<i>check</i> is quite a bit larger than the set of tasks you can perform. And it has to meet a lower burden of proof with respect to the question \"can you find a way to update the model\u2019s policy to do the task even if it starts out failing?\", because if you know how to do the task \u2013 or at least, to demonstrate it \u2013 you can update the model\u2019s policy towards taking the sorts of action it should have taken; whereas if you don\u2019t know what those actions are (and the model isn\u2019t showing you), this is harder.</p><p>Finally, note that \u201cyou,\u201d here, doesn\u2019t need to mean a lone human. Rather, it can mean many humans, doing expensive and time-consuming evaluations,&nbsp;<i>with the assistance of whatever AIs (and other forms of technology) they can access</i>. This means that (modulo leakage via the rare exceptions), if the \u201cno sandbagging on checkable tasks\u201d hypothesis is true of some set S of tasks that are checkable by humans without AI assistance, then if we grant humans access to AI systems capable of performing such tasks (even: misaligned systems who actively want to undermine human projects), this creates a new set S+ of checkable tasks \u2013 namely, the tasks checkable by humans&nbsp;<i>with the assistance of AIs that can be used to perform the tasks in S</i>. And so, too, for S++, and so on.</p><h1>Why does the hypothesis matter?</h1><p>Why does it matter if the \u201cno sandbagging on checkable tasks\u201d hypothesis is true? Well, if it\u2019s true, then&nbsp;</p><ol><li>you're in a much better position to know which checkable tasks your models can do, and&nbsp;</li><li>you can <i>use</i> your models to perform basically any checkable task they're capable of performing</li></ol><p><i>even</i>&nbsp;<i>if&nbsp;</i>those models are otherwise misaligned, deceptive, and conspiring to undermine your goals and/or to disempower humans more generally.&nbsp;</p><p>(1) matters a lot for \u201ccapability evaluations\u201d \u2013 that is, attempts to figure out what sorts of dangerous tasks a model can perform (examples&nbsp;<a href=\"https://evals.alignment.org/blog/2023-03-18-update-on-recent-evals/\"><u>here</u></a> and&nbsp;<a href=\"https://www.anthropic.com/index/frontier-threats-red-teaming-for-ai-safety\"><u>here</u></a>; and see Hubinger&nbsp;<a href=\"https://www.lesswrong.com/posts/dBmfb76zx6wjPsBC7/when-can-we-trust-model-evaluations\"><u>here</u></a> for more detailed discussion). Of course, a robust capabilities evaluation regime would also require the ability to identify ahead of time the exceptional cases where you <i>can't</i> rule out sandbagging. But insofar as you can check whether a given form of e.g. hacking or autonomous replication or biological-weapons-designing has occurred, and rule out sandbagging on <i>this sort</i> of checkable task, then you can know whether the model can do it.</p><ul><li>Though note that for capability evaluations directed at tasks that humans + AI assistants can already <i>perform</i> (for example, many of the tasks involved in autonomous replication), the \u201cno sandbagging on performable tasks\u201d hypothesis is actually the one that matters.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefid5i594h4n\"><sup><a href=\"#fnid5i594h4n\">[8]</a></sup></span></li></ul><p>(2) matters a lot to what sort of useful labor we might be able to get out of misaligned AI systems we still have control over \u2013 and in particular, labor that improves our odds of avoiding later disempowerment. For example, if the \u201cno sandbagging on checkable tasks\u201d hypothesis is true, then (unless some of the following tasks are amongst the rare exceptions):</p><ul><li>You will be able to access and make use of any checkable knowledge that a given model has about the alignment of existing AIs \u2013 including itself. Thus:<ul><li>You\u2019ll be able to ask the model: \u201cunder what circumstances would you engage in X sort of power-seeking or otherwise dangerous behavior?\u201d And if knowledge of this fact is present in the model, and you\u2019re able to check it, then you\u2019ll get access to that knowledge.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefzd52f8a61gi\"><sup><a href=\"#fnzd52f8a61gi\">[9]</a></sup></span><ul><li>Of course, it\u2019s hard to actually&nbsp;<i>put</i> the model in some of the circumstances we\u2019re interested in (e.g., ones where it has a genuine opportunity to disempower humans, or more exotic cases like&nbsp;<a href=\"https://ai-alignment.com/training-robust-corrigibility-ce0e0a3b9b4d\"><u>Christiano\u2019s RSA-2048</u></a>). But if it knows what it would take to convince&nbsp;<i>it</i> that it\u2019s in a given circumstance (e.g., \u201cif you perturb my weights like so, I\u2019ll believe I\u2019m in a position to grab power and I\u2019ll start trying to do so\u201d), then you can check that, too.</li></ul></li><li>Similarly, if the model knows or can access check-able evidence that other AI systems are misaligned, or planning/engaged in/disposed towards undesirable behavior, you\u2019ll get access to that evidence.</li></ul></li><li>You\u2019ll be able to use the model to reveal and patch checkable routes to human disempowerment. Thus: you can find:&nbsp;<ul><li>all of the checkable cybersecurity vulnerabilities the model would\u2019ve been able to exploit;&nbsp;</li><li>all of the checkable ways of subverting/undermining/reward-hacking the oversight process;&nbsp;</li><li>all of the check-able manipulation/persuasion techniques it might\u2019ve used on humans, along with any checkable methods of detecting/blocking these techniques;<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefz5mc12izoh8\"><sup><a href=\"#fnz5mc12izoh8\">[10]</a></sup></span></li><li>all of the checkable plans for making money in illicit ways; and so on.</li></ul></li><li>You\u2019ll often be able to use the model to advance lots of other forms of science and technology, including alignment-relevant science and technology, where experiment and human understanding (+ the assistance of available AI tools) is enough to check the advances in question.<ul><li>Interpretability research seems like a strong and helpful candidate here, since many aspects of interpretability research seem like they involve relatively tight, experimentally-checkable feedback loops. (See e.g.&nbsp;<a href=\"https://www.dwarkeshpatel.com/p/carl-shulman-2#details\"><u>Shulman\u2019s discussion</u></a> of the experimental feedback loops involved in being able to check how well a proposed \u201cneural lie detector\u201d detects lies in models you\u2019ve trained to lie.)</li></ul></li></ul><p>Of course, the exceptions (and the potential difficulties identifying them ahead of time) can bite you, here.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefgwus2wrt85\"><sup><a href=\"#fngwus2wrt85\">[11]</a></sup></span>&nbsp;And there\u2019s still a further question of how far this sort of labor goes in helping your efforts to lower misalignment risk. But access to it seems like cause for significant optimism relative to the alternative. And as I noted above, it can scale recursively.&nbsp;</p><h1>Is the hypothesis true?</h1><p>Is the \u201cno sandbagging on checkable tasks\u201d hypothesis true? I\u2019m not sure.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefr19d4i9o0xd\"><sup><a href=\"#fnr19d4i9o0xd\">[12]</a></sup></span></p><p>A key point in its favor is that knowledge of how to do the task is already present in the system, so all you need to do is use gradient descent to make that knowledge manifest, and the checkable-ness of the task gives you a training signal that can exert pressure in this direction. And this pressure may be hard for a misaligned model to resist. Here\u2019s an exchange from Shulman\u2019s podcast, discussing a human analogy, that might make some of the difficulty here vivid (though various important differences with AI case persist):</p><blockquote><p><i>Patel</i>: What about spies that are working in very advanced scientific contexts? For example, a communist spy in the Manhattan project. He has to deliver research results in order to stay employed but he can still continue delivering intel to the communists.&nbsp;</p><p><i>Shulman</i>: Their job was not sabotage. And your hypothetical spy did not have their nervous system hooked up to this reward signal of praise from the Manhattan project supervisors, being exposed combinatorially with random noise added to generate incremental changes in their behavior. In fact they were displaying the behavior of cooperating with the Manhattan project only where it was in service to the existing motivations. They didn't have their brain re-engineered to do more of the thing when they accidentally helped the project more and less of the thing when they accidentally helped it less so I'd say it's pretty drastically disanalogous.</p></blockquote><p>A key point against the hypothesis, in my eyes, is that for tasks that we don\u2019t know how to do (e.g., hacking the computer in the blue banana example), it\u2019s not clear how to update a model towards performing the task if it intentionally tries to avoid showing us any task-performing behavior.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreftfffj3w3jt\"><sup><a href=\"#fntfffj3w3jt\">[13]</a></sup></span>&nbsp;Thus, for example, if in the blue banana example above, the model just shows us a bunch of unsuccessful attempts at hacking the computer (even when we try to force it to \"explore\"), and we don\u2019t know what a successful attempt involves, how are we supposed to elicit (and then reward) such a successful attempt?</p><p>After talking with various folks who\u2019ve thought more about this, my understanding is that a key question, here, is how confident the model will be that we don\u2019t know how to perform the task in question \u2013 even granted that we have access to a diversity of AI assistants (and in particular, AI assistants who we will be trying to prevent coordination between, and who will also be uncertain about what humans + the other AI assistants can do). Here I think the thought is: if we&nbsp;<i>do</i> know how to perform the task in the question, but the model intentionally fails to perform it, then we can use supervised learning to update the model\u2019s behavior towards no-longer-failing \u2013 thereby potentially re-engineering the model\u2019s brain/motivations in a way it wants to avoid. So to prevent this, the model wants to only sandbag on tasks we don\u2019t know how to do. But in many cases, it might be hard to tell what these are \u2013 especially if it\u2019s difficult to coordinate with other AI assistants to conceal how to do a given task.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefv6mhjnmjldf\"><sup><a href=\"#fnv6mhjnmjldf\">[14]</a></sup></span></p><p>Note, though, that this story&nbsp;<i>concedes</i> that a model would, in principle, be able to sandbag on tasks that we don\u2019t know how to perform. It\u2019s just that doing so might be a strategic error.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefvpl0wsusqwq\"><sup><a href=\"#fnvpl0wsusqwq\">[15]</a></sup></span>&nbsp;Thus, to the extent we avoid sandbagging via this dynamic, what\u2019s preventing the sandbagging is not the power of our ML training per se. Rather, from the model's perspective, what matters is the broader context of uncertainty and coordination difficulty re: what sorts of deception are worth risking given the costs and benefits at stake.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref3vsmyb50xmv\"><sup><a href=\"#fn3vsmyb50xmv\">[16]</a></sup></span></p><ul><li>And note, too, that this sort of story actually supports a broader hypothesis: \u201cno sandbagging on tasks where it\u2019s sufficiently plausible, from the model\u2019s perspective, that humans + AI assistants already know how to do it\u201d \u2013 a set that could in principle include many tasks that we don\u2019t, in fact, know how to&nbsp;<i>check</i>, let alone perform (for example, generating actually-good superhuman hard-to-check AI alignment research). Still, checkability would play an important role in determining the number of tasks it\u2019s plausible that we know how to do.</li></ul><p>I won\u2019t try to evaluate these considerations in depth here. And the \u201cno sandbagging on checkable tasks\u201d hypothesis raises other questions, too (for example, if \u201c<a href=\"https://www.lesswrong.com/posts/uXH4r6MmKPedk8rMA/gradient-hacking\"><u>gradient hacking</u></a>\u201d is feasible, then models would plausibly be able to sandbag even on tasks that we know how to perform).<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreff576k2m206d\"><sup><a href=\"#fnf576k2m206d\">[17]</a></sup></span>&nbsp;Mostly, I just want to point at the hypothesis as an important subject of research. And I think it\u2019s plausible enough that it\u2019s also worth thinking through in detail what we could do to lower existential risk from AI, if it <i>is</i> true \u2013 including in worlds where the sort of deceptive power-seeking that might motivate sandbagging is common.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefn8uua6fcmv\"><sup><a href=\"#fnn8uua6fcmv\">[18]</a></sup></span></p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn81vino4b85k\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref81vino4b85k\">^</a></strong></sup></span><div class=\"footnote-content\"><p>See also the formulation of the concept of \u201ccapability elicitation\u201d in Shlegeris and Greenblatt&nbsp;<a href=\"https://www.lesswrong.com/posts/MbWWKbyD5gLhJgfwn/meta-level-adversarial-evaluation-of-oversight-techniques-1#Appendix__Capability_elicitation\"><u>here</u></a>: \u201cBy \u2018capability elicitation\u2019, I mean \u2018given a reward signal, training models to get as high an average reward during training as they\u2019d get if they were trying to do well rather than to sabotage training\u2019.\u201d This formulation is similar to the one I\u2019ve used in that, to the extent the model is capable of doing the task, then if it were \u201ctrying to do well,\u201d it seems likely it would succeed.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnnegcwowrov\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefnegcwowrov\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Here I\u2019m setting aside the ethical issues that this sort of training could raise in models that are or might be moral patients.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fns38k7zy6wp\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefs38k7zy6wp\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Let\u2019s assume that you have control adequate to ensure that it can\u2019t hack out of its environment or disempower you or anything like that in the process of performing the task.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnxjyqvdhafq\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefxjyqvdhafq\">^</a></strong></sup></span><div class=\"footnote-content\"><p>See Yudkowsky\u2019s 31,&nbsp;<a href=\"https://www.lesswrong.com/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities\"><u>here</u></a>, as an example of pessimism on this front: \u201cA strategically aware intelligence can choose its visible outputs to have the consequence of deceiving you, including about such matters as whether the intelligence has acquired strategic awareness; you can't rely on behavioral inspection to determine facts about an AI which that AI might want to deceive you about.&nbsp;(Including how smart it is, or whether it's acquired strategic awareness.)\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn2k8a2ui8omn\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref2k8a2ui8omn\">^</a></strong></sup></span><div class=\"footnote-content\"><p>My sense is that some folks might want to formulate the hypothesis specifically in terms of what you can expect out of reinforcement learning.</p><p>I'm also going to skip further precision on other aspects of the definition, like \"tasks the model is capable of performing\" and \"you can get it to perform blah task.\" All of this is just supposed to be a rough-and-ready gesture.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn5cn72w5tbt\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref5cn72w5tbt\">^</a></strong></sup></span><div class=\"footnote-content\"><p>For example, intuitively, in the example above, you\u2019re in a position to know that the blue banana has appeared on the screen. But in principle we can still ask questions like: what if the model intervenes on your retinas to create the <i>illusion</i> of a blue-banana screen? So \u201ccheckable\u201d in the relevant sense requires ruling out various sorts of epistemic distortions. But I think we\u2019ll often be in a position to do this.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn33xya5pfu08\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref33xya5pfu08\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Thanks to Lukas Finnveden for discussion.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnid5i594h4n\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefid5i594h4n\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Though: note that questions about sandbagging are more important to misalignment risk, and less to misuse risk. That is, if you\u2019re mostly worried about whether other humans can use/train the model to do something dangerous, and not about the model intentionally messing with your evaluations, then to the extent your ability to solicit the relevant dangerous behavior is comparable to that of \u201cother humans\u201d you\u2019re wondering about, your eval should be accurate.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnzd52f8a61gi\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefzd52f8a61gi\">^</a></strong></sup></span><div class=\"footnote-content\"><p>From&nbsp;<a href=\"https://www.dwarkeshpatel.com/p/carl-shulman-2#details\"><u>Shulman</u></a>: \u201cIf gradient descent is working fine and there's any way to slightly jiggle the weights to make it more likely to deliver a more acceptable answer, we ask the AI: can you think of any circumstances where if we put a copy of you into that situation, it would then violate some of the various constraints? It would tell a lie, it would insert a backdoor into a program it wrote when it was not supposed to. If the model knows yeah, I would look for signs of consistency of the information I was being presented with, certain checksums failing could indicate that it was actually a constructed example, a simulation. Right now we can detect AI generated images reasonably well and you might use those kinds of capabilities. We could do something called relaxed adversarial training. If we can find how those things are represented within the AI, we can induce a hallucination that it has seen that those checksums have been passed. We can then ask, well does that cause the forbidden behavior? If the AI understands how it's thinking and how it works, it can propose a bunch of experiments. It can say, I guess that if you perturb the network in this kind of way it might induce that hallucination using the best of its knowledge as to what might generate that. It can propose those experiments and can do the experiments and generate the data. Because humans are going to get to see the results of those experiments after the fact they can exert pressure to have the AI incrementally deliver better and better results.\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnz5mc12izoh8\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefz5mc12izoh8\">^</a></strong></sup></span><div class=\"footnote-content\"><p>See&nbsp;<a href=\"https://www.lesswrong.com/posts/zxmzBTwKkPMxQQcfR/let-s-use-ai-to-harden-human-defenses-against-ai\"><u>Davidson (2023)</u></a> for discussion of this one in particular.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fngwus2wrt85\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefgwus2wrt85\">^</a></strong></sup></span><div class=\"footnote-content\"><p>For example, it's hard to use your model to answer questions like \"are there any checkable and findable-by-you circumstances where you might try to grab power\" or \"are there any checkable and findable-by-you security vulnerabilities left in this system\" if you can't actively <i>rule out</i> sandbagging.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnr19d4i9o0xd\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefr19d4i9o0xd\">^</a></strong></sup></span><div class=\"footnote-content\"><p>There's some discussion of a type of sandbagging in <a href=\"https://cdn2.assets-servd.host/anthropic-website/production/files/model-written-evals.pdf\">Perez et al (2022)</a>: namely, models performing worse for users that appear less able to evaluate the model's answers. However, the type of sandbagging at stake in this post requires that the model performs worse-than-it-can on a task that we <i>can</i> evaluate, in a way that persists <i>despite</i> our training it in a way that harnesses this evaluation capacity to whatever extent possible.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fntfffj3w3jt\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreftfffj3w3jt\">^</a></strong></sup></span><div class=\"footnote-content\"><p>See e.g. Hubinger\u2019s discussion of the difficulties in relying purely on RL training,&nbsp;<a href=\"https://www.lesswrong.com/posts/dBmfb76zx6wjPsBC7/when-can-we-trust-model-evaluations#2__Behavioral_RL_Fine_Tuning_Evaluations\"><u>here</u></a>.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnv6mhjnmjldf\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefv6mhjnmjldf\">^</a></strong></sup></span><div class=\"footnote-content\"><p>It may be that \u201cintrospection\u201d tasks like \u201cfigure out and report the circumstances under which I would try to grab power\u201d are especially unlikely to be tasks that humans already know how to do. And anyway, a deceptive model planning for bad behavior later might choose to act as though humans don\u2019t know how to do this task, because if they already do, then all is lost. H/t Paul Christiano and Evan Hubinger for discussion. See also the \u201cslogan of the robot rebellion\u201d example from Shlergis and Greenblatt <a href=\"https://www.lesswrong.com/posts/MbWWKbyD5gLhJgfwn/meta-level-adversarial-evaluation-of-oversight-techniques-1#Appendix__Capability_elicitation\">here</a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnvpl0wsusqwq\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefvpl0wsusqwq\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Thanks to Beth Barnes for discussion here.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn3vsmyb50xmv\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref3vsmyb50xmv\">^</a></strong></sup></span><div class=\"footnote-content\"><p>If humans can consistently set up the sort of strategic uncertainty and coordination difficulty that makes the models choose not to engage in sandbagging here, then I think that the \u201cno sandbagging on checkable tasks\u201d hypothesis should still count as true. But we should be clear, in our own minds, about what\u2019s&nbsp;<i>making</i>&nbsp;<i>it&nbsp;</i>true \u2013 namely, uncertainty and coordination difficulties on the part of the misaligned AIs, rather than the power of having-a-training-signal just in itself. And insofar as we also want to be able to identify ahead of time the cases where sandbagging on checkable tasks might still occur, the complexity of anticipating the model's cost-benefit calculations here might be a barrier to confidence.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnf576k2m206d\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreff576k2m206d\">^</a></strong></sup></span><div class=\"footnote-content\"><p>See Hubinger&nbsp;<a href=\"https://www.lesswrong.com/posts/dBmfb76zx6wjPsBC7/when-can-we-trust-model-evaluations#3__Behavioral_I_I_D__Fine_Tuning_Evaluations\"><u>here</u></a> for more on the relevance of gradient hacking.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnn8uua6fcmv\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefn8uua6fcmv\">^</a></strong></sup></span><div class=\"footnote-content\"><p>In some sense, tons of work on alignment \u2013 and especially, \u201couter alignment\u201d \u2013 takes for granted that sandbagging isn\u2019t a problem. But I\u2019m specifically encouraging attention to what-can-be-done in worlds where the motivations that might give rise to sandbagging \u2013 for example, motivations related to \u201c<a href=\"https://www.lesswrong.com/posts/zthDPAjh9w6Ytbeks/deceptive-alignment\"><u>deceptive alignment</u></a>\u201d \u2013&nbsp;<i>are</i> a problem, but sandbagging on checkable tasks&nbsp;<i>isn\u2019t</i>.</p></div></li></ol>", "user": {"username": "Joe_Carlsmith"}}, {"_id": "CFtLLde48oWakvmfz", "title": "A Scheme for using WorldCoin to provide electricity & smart phone access in rural Malawi, Africa", "postedAt": "2023-07-31T19:22:37.731Z", "htmlBody": "<p>I have been working for the past 8 years trying to figure out how best to use individual donor funds to provide off-grid solar electricity access to low-income households in rural Malawi, Africa. What we have done is develop a very cost-efficient, small-scale assembly and distribution enterprise for getting solar equipment to thousands of households per year in low-income rural Malawi. Low-income rural Malawians cannot afford to pay the full price of a good, high-benefit solar system, so we optimally combine philanthropic subsidies with customer payments (of a discounted purchase price) to produce the maximum benefit per dollar of donated funds.&nbsp; Generally, per donated dollar, the solar systems are expected to produce between $10 and $100 of net benefit to the beneficiary households over the lifetime of the product.&nbsp;</p><p>On July 24, Sam Altman\u2019s Worldcoin project launched. Worldcoin is a project that plans to entitle all of humanity access to a digital wallet that can buy and sell the Worldcoin token. The owner of the wallet is verified through an iris scan which creates a unique verifiable identity for each human user. The identity and wallet are managed through a smart-phone app called World App operated by an organization called Tools for Humanity. To incentivize people to download, sign in to the World App and have their identity verified through an iris scan, the Worldcoin project is giving a \u201cgenesis grant\u201d of 25 WLD tokens for users that sign-up. The price of the WLD token on Binance.com is approximately $2.3 as of July 31, 2023. This amounts to a genesis grant value of approximately $57/person. In rural Malawi, Africa this is equivalent to about one month\u2019s cash income for a rural laborer.&nbsp;</p><p>NGOs or enterprises like what me and my colleagues have created could conceivably sell discounted solar systems and smart phones to people who sign-up to the Worldcoin project in exchange for some of their WLD genesis grant tokens, making such products affordable to all Malawians when previously they have been unaffordable to &nbsp;the vast majority of people in rural areas.&nbsp;</p><p>In Malawi, there are approximately 11 million adults, theoretically eligible for a total of more than $600M of Worldcoin genesis grant value. This is enough resources to solar electrify all of rural Malawi (currently more than 90% of rural Malawians do not have electricity access), and/or provide all rural Malawian adults with low-end smart phones.&nbsp;</p><p>If we can get about 15% of the total potential, or $100M worth of Worldcoin genesis grants invested in subsidies of solar systems that produce $10 to $100 of benefit for every subsidy dollar, then this could produce $1B to $10B in benefits to rural Malawians. This seems like a pretty big deal.&nbsp;</p><p>Of course there is a tremendous amount of detail and complications with implementing a scheme like this.&nbsp; But I have been working on solar distribution in rural Malawi for 8 years, and can see ways to create multiple paths forward for such a scheme.&nbsp;</p><p>But I see three obvious questions that arise from these recent developments and this new opportunity:&nbsp;</p><p>(1) Couldn\u2019t schemes like this be a HUGE opportunity for all of rural Africa? So shouldn't someone with much more power and resources than me be interested in this development potential?</p><p>(2) Should the EA global health and development community be jumping at this multi-billion-dollar development opportunity and figuring out how to get the genesis grant funds spent with maximum beneficial impact in dozens of low-income countries? &amp;&nbsp;</p><p>(3) Does anyone want to help me figure out how to get a scheme like this implemented to maximize the benefit to rural Malawians??? (i.e. the country in which I know how to organize things).</p><p>I would love to hear the EA community\u2019s comments and reactions to these questions. They will help me in two ways: #1 It will help me decide whether I want to take this on as one of my volunteer organizing efforts, and #2 The feedback will help me decide how to better organize such a project if I do decide to take it on.&nbsp;</p><p>Thanks a million for your constructive comments, reactions and help.&nbsp;</p>", "user": {"username": "Robert Van Buskirk"}}, {"_id": "h5DeaZ7twoT5vxT35", "title": "Infographics of the Report food security in Argentina in the event of an Abrupt Reduction of Sunlight Scenario (ASRS)", "postedAt": "2023-07-31T19:36:55.198Z", "htmlBody": "<p>We are pleased to share our <a href=\"https://riesgoscatastroficosglobales.com/articulos/infografias-informe-seguridad-alimentaria-en-argentina-en-caso-de-un-escenario-de-reduccin-abrupta-de-la-luz-solarerals\">infographic</a> of the <a href=\"https://static1.squarespace.com/static/60c0fe48b1480d2dddf3bff9/t/649f201802be2c0213fa6fa9/1688150046589/V2+Report_Food+Security+in+Argentina+in+the+event+of+an+Abrupt+Sunlight+Reduction+Scenario+%28ASRS%29.pdf\">report Food Security in Argentina in the event of an Abrupt Reduction of Sunlight Scenario (ASRS)</a>.</p><p>More information about the report: <a href=\"https://forum.effectivealtruism.org/posts/HujMqSaQwnNJfLhWw/report-food-security-in-argentina-in-the-event-of-an-abrupt\">https://forum.effectivealtruism.org/posts/HujMqSaQwnNJfLhWw/report-food-security-in-argentina-in-the-event-of-an-abrupt</a>&nbsp;</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/k6dfjuutax7jzelo8fz8\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/lalaqimqhqbifmlqcox3 160w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/t9kvhf0gnpg3dmigadsb 320w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/rson4ijs15mulmzksztl 480w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/xazaj2twaeb0ql9ohulo 640w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/ibcptiin2mhc0kadjffo 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/zo51u7jf90dt6rkuq356 960w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/nuqrfxaddv1ydnfbplt9 1120w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/tvyvyowkt30kml1qgzog 1280w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/ysxczp1tqefpdsdcs8sg 1440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/nywfhk8yfdknsg3vhigw 1587w\"></figure><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/z799wkavliyfooewxydb\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/efoea8jmau1j59ctuded 160w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/becar7sopgpr6erkwqk5 320w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/sw6nfewwcc2mdhkxbpvh 480w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/q0autiucw5ls2u8qguvr 640w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/a5yuvg9cwrcmmbdeqlgc 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/mu9wwtaxwhsikuzwmgpa 960w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/kpylspo3fo0gudkoslnc 1120w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/eb5afzxghpmdwyclmtcu 1280w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/xnhbmf1inalwqdvediip 1440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/jnw2hqz5rrfla3d5tsmm 1587w\"></figure><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/fno6tf5paxihl7wrkbg3\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/s1w90t0pbur6rhnwbqja 160w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/a5wcxa8wnn24rhofordz 320w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/ifndd2ns9ajvn4gfshks 480w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/ljbku9gf4hkg4muovbnk 640w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/fxb4rp5ob4drvz41yqls 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/i8adkyu1ek5yitnrvobt 960w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/hjis71vw6btforaizoah 1120w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/mlpqotuswsf8umn3aav7 1280w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/elnhkrvggk1vvfwculeq 1440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/tfjkgeoii9clsx1tjx7a 1587w\"></figure><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/nkxozoegxtw8q0lcbybg\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/c8iihvdkvd538ntwfepe 160w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/irahkv960jlqntpbgpyz 320w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/ubidgcgndguw0hcp29ql 480w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/p7epjlmbxtvsmt2kexxf 640w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/ipoc9hdok9tugcqbu566 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/zikfblwbwan8b97lbcne 960w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/jda4kttjs6jxtcxehyqe 1120w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/x00atark4sbkdjcsfm6a 1280w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/fektgwzo5obveetqyec9 1440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/osk8b3cheeateob3xsug 1587w\"></figure><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/sorao3yvb2byqyfse1hk\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/r88cepmrdbyorv7yvddi 160w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/krfnpyhyfcgkoo9e9qhq 320w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/euxewbtqu0sqh2dhixjf 480w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/fpzp8elrujmqxq5bsx72 640w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/vucf2yw9iacmhti5hqvr 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/gd7dj1awzy58rnqvdmgz 960w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/uhiijlhjnos2bborkz2t 1120w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/nrv3qkctvvfvoilxoltl 1280w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/o04kdtpfjown3dg07qn1 1440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/ynlr6yidoy7y455j1lmk 1587w\"></figure><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/yc36obe3khocvu2cem8z\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/stfjleswra8iz7drvpdn 160w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/trjlajtetska3uqovipb 320w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/x1tpr3xjdpebemneeoia 480w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/vn7knrhkbsyno4z2agxr 640w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/qoqvej1qytvgcvya7zic 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/gn5udfqrm5tcar2udvf5 960w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/clzzgopbyw6fxzz4rhch 1120w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/iv4a3eqfkibcey5dbddz 1280w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/vmxfk75n3eapmqkocj9j 1440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/h5DeaZ7twoT5vxT35/ujlems3gdb8lpc25snwj 1587w\"></figure>", "user": {"username": "Joatorresc"}}, {"_id": "qNbwGQzPR8sshwrRh", "title": "AI romantic partners will harm society if they go unregulated", "postedAt": "2023-07-31T15:55:14.405Z", "htmlBody": "<p>Recently, when people refer to \u201cimmediate societal harms and dangers\u201d of AI, in media or political rhetoric, they predominantly choose to mention \u201cbias\u201d, \u201cmisinformation\u201d, and \u201cpolitical (election) manipulation\u201d.</p><p>Despite politicians, journalists, and experts frequently compare the current opportunity of regulating AI for good with the <i>missed</i> opportunity to regulate social media in the early 2010s, somehow <strong>AI romantic partners</strong> are rarely mentioned as a technology and a business model that has the potential to <strong>grow very rapidly, harm the society significantly, and be very difficult to regulate once it has become huge</strong> (just as social media). This suggests that <strong>AI romance technology should be regulated swiftly.</strong></p><p>There is a wave of articles in the media (<a href=\"https://www.businessinsider.com/replika-ai-romance-behind-partners-backs-cheating-2023-7\">1</a>, <a href=\"https://www.theguardian.com/technology/2023/jul/22/ai-girlfriend-chatbot-apps-unhealthy-chatgpt\">2</a>, <a href=\"https://www.telegraph.co.uk/business/2023/07/16/ai-girlfriend-replika-caryn-apps-relationship-health/\">3</a>, <a href=\"https://thebottomline.as.ucsb.edu/2023/06/the-rise-of-ai-girlfriends-connecting-with-desires-and-discussing-controversy-future-implications\">4</a>, for just a small sample) about the phenomenon of AI romance which universally raise vague worries, but I haven\u2019t found a single article that rings the alarm bell that AI romance deserves, I believe.</p><p>The EA and LessWrong community response to the issue seems to be even milder: it\u2019s rarely brought up, and a post \u201c<a href=\"https://www.lesswrong.com/posts/m7EHa5rWTvmbjMTNZ/in-defense-of-chatbot-romance\">In Defence of Chatbot Romance</a>\u201d has been hugely upvoted.</p><p>This appears strange to me because I expect, with around 75% confidence, that rapid and unregulated growth and development of AI partners will become a huge blow to society, on a scale comparable to the blow from <a href=\"https://www.thesocialdilemma.com/\">unregulated social media</a>.</p><p>I'm not a professional psychologist and not familiar with academic literature in psychology, but the propositions on which I base my expectation seem at least highly likely and common-sensical to me. Thus, one of the purposes of this article is to attract expert rebuttals of my propositions. If there would be no such rebuttals, the second purpose of the article is to attract the attention of the community to the proliferation of AI romantic partners which should be regulated urgently (if my inferences are correct).</p><h2>What will AI romantic partners look like in a few years?</h2><p>First, <a href=\"https://www.lesswrong.com/posts/m7EHa5rWTvmbjMTNZ/in-defense-of-chatbot-romance?commentId=bsjiqkDvyiEa7fJJd\">as Raemon pointed out</a>, it\u2019s crucial not to repeat the mistake that is way too common in the discussions of general risks from AI, that is, to assume only the AI capabilities that are present already will exist and to fail to extrapolate the technology development.</p><p>So, here\u2019s what I expect AI romantic partner startups will be offering <strong>within the next 2-3 years</strong>, with very high probability, because none of these things requires any breakthroughs in foundational AI capabilities, and is only a matter of \u201cmundane\u201d engineering around the existing state-of-the-art LLMs, text-to-audio, and text-to-image technology:</p><ul><li>A user could create a new \u201cpartner\u201d, that comes with a <strong>unique, hyper-realistic \u201chuman avatar\u201d</strong>, generated according to the preferences of the user: body shape, skin colour, eye colour, lip shape, etc. Of course, these avatars will <a href=\"https://www.lesswrong.com/posts/3iYiXDvTa2BnrxNL3/why-are-women-hot#A_Fat_Bitch__What_Could_This_Mean_\">maximise sexual attractiveness</a>, within the constraints set by the user. You can see a sample of avatars that are already generated today in <a href=\"https://twitter.com/simps_ai\">this Twitter account</a>. Except, today these avatars still look just a tad \u201cplastic\u201d and \u201cAI-generated\u201d, which I expect to completely go away soon, i.e., they will look totally indistinguishable from real photos, except that the avatars themselves will be \u201ctoo perfect to be true\u201d (which also could be addressed, of course: an avatar could have some minor skin defect, or face asymmetry, or some other imperfection if the user chooses).</li><li>Apart from a unique appearance, the AI partner will also have a <strong>unique personality</strong> (a-la <a href=\"http://character.ai\">character.ai</a>) and <strong>unique voice</strong> (a-la Scarlett Johansson in the movie \u201cHer\u201d). Speech generation will be hyper-realistic, sound just like a real human voice recorded, and will correctly reflect the emotional charge of the text being said and the general emotional tone of the discussion happening between the user and the AI just before the given AI\u2019s voice reply is generated.</li><li>LLMs underlying the AI will be fine-tuned on real dialogues between romantic partners and will have <strong>human-level emotional intelligence and the skill of directing the dialogue</strong> (<a href=\"https://arxiv.org/abs/2302.02083\">human-level theory of mind</a> already goes without saying), such as noticing slight when it\u2019s acceptable to be \u201ccheerful\u201d and when it\u2019s better to remain \u201cserious\u201d when it\u2019s better to wrap up the dialogue because the user becomes slightly bored, etc. Of course, these LLMs won\u2019t be just OpenAI API with a custom system prompt, <a href=\"https://nypost.com/2023/05/16/i-went-on-a-date-with-chatgpts-carynai/\">which is prone to \u201cleaking\u201d those \u201cI\u2019m just an AI model\u201d disclaimers</a>, but a custom fine-tune, a-la <a href=\"https://www.notion.so/a47a268ede1b46359f99ecd0d9c4b91d?pvs=21\">character.ai</a>.</li><li>Even if the technology won\u2019t become sophisticated enough to automatically discover the dialogue style preferred by the user, this style could probably be configured by the user themselves, including the preferred \u201csmartness\u201d of their partner, the \u201csweetness\u201d of the dialogue (e.g., the usage of nouns such as \u201cdear\u201d or \u201cbaby\u201d), the preferred levels of sarcasm/seriousness, playfulness, agreeableness, and jealousy of the AI. <strong>The available level of smartness, erudition, and eloquence of the AI is already superhuman</strong>, as of GPT-4-level LLMs, although the user may prefer to deliberately \u201cdumb down\u201d their AI partner.</li><li>Even though, \u201cfor ethical reasons\u201d, AI partners (at least, those created by companies rather than by open-source hackers) will <i>not</i> actively conceal that they are AIs, such as if questioned directly \u201cAre you an AI or a real person?\u201d, they will answer \u201cI\u2019m an AI\u201d, they will probably be trained to avoid confronting the user with this fact if possible. For example, if the user asks the AI \u201cCan we meet in person?\u201d, the AI will answer \u201cSorry, but probably not yet :(\u201d, rather than \u201cNo, because I\u2019m an AI and can\u2019t meet in person.\u201d Similarly, unlike ChatGPT, Bard, and Claude, these AI partners won\u2019t be eager to deny that they have personality, feelings, emotions, preferences, likes and dislikes, desires, etc.</li><li><strong>AI partners will effectively acquire long-term memory</strong> with vector embeddings over the past dialogue and audio chat history, or with the help of extremely long context windows in LLMs, or with a combination of both, which will make AI relationships much less of a \u201c50 First Dates\u201d or \u201cpre-wakeup Barbieland\u201d experience, and more of a \u201creal relationship\u201d, where the AI partner, for example, remembers that the user has a hard time at work or in a relationship with their friends or parents and asks about it proactively even weeks after this has been revealed in the dialogue, giving the impression of \u201creal care\u201d.</li></ul><p>Please note that I don\u2019t just assume that \u201cAI = magic that is capable of anything\u201d. Below, I list possible features of AI romantic partners that would make them even more compelling, but I can\u2019t confidently expect them to arrive in the next few years because they hinge on AI and VR capability advances that haven\u2019t yet come. This, however, only highlights how compelling AI partners could <i>already</i> become, with <i>today\u2019s</i> AI capabilities and some proper product engineering.</p><p>So, here are AI partner features that I <i>don\u2019t</i> necessarily expect to arrive in the next 2-3 years:</p><ul><li>Generation of realistic, high-resolution videos with the avatar that are longer than a few seconds, i.e., not just \u201cloop photos\u201d.</li><li>Real-time video generation that is suitable for a live video chat with the AI partner.</li><li>The AI partner has a \u201cstrategic relationship intelligence\u201d in the relationship: for example, it is able to notice a growing issue in the relationship (such as the user growing bored of the AI, or growing irritated with some feature of the AI, or a shifting role of the AI in the life of the user) and knows how to address them, even if this would be just initiating a dialogue with the user about this issue, or adjusting the AI\u2019s personality (\u201dworking on oneself\u201d).</li><li>The personality of the AI partner could change or \u201cgrow\u201d spontaneously rather than upon the request or intervention from the user.</li><li>The AI can control or manipulate the user on a deep level. Only people who have expert practical knowledge of human psychology can do this. Also, this requires the ability to infer the psychological states of the user over long interaction histories, which LLMs probably cannot do out of the box (at least, not yet).</li><li>There is an app for a lightweight VR headset that projects the avatar of the AI partner on a sex doll.</li></ul><h2>AI romantic partners will reduce the \u201chuman relationship participation rate\u201d (and therefore the total fertility rate)</h2><p>I don\u2019t want to directly engage with all the arguments <i>against</i> the proposition that AI partners will make people work towards committed human relationships and having kids, e.g., in the <a href=\"https://www.lesswrong.com/posts/m7EHa5rWTvmbjMTNZ/in-defense-of-chatbot-romance#People_might_neglect_real_romance\">post by Kaj Sotala</a> and in the comments to that post, as well as some other places, because these arguments seem to me exactly of the <a href=\"https://en.wikipedia.org/wiki/Manufactured_controversy\">manufactured uncertainty</a> kind wielded by social media companies (Facebook, primarily) before.</p><p>Instead, I want to focus on the \u201cmainline scenario\u201d which will counterfactually deprive a noticeable share of young men outside of the \u201crelationship market pool\u201d, which, in turn, must reduce the total share of people ending up in committed relationships and having kids.</p><blockquote><p>A young man, between 16 and 25 years old, finds it difficult to get romantic partners or casual sex partners. This might happen either because the man is not yet physically, psychologically, intellectually, or financially mature, or because he has transient problems with their looks (such as acne, or wearing dental braces), or because the girls of the respective age are themselves \u201cdeluded\u201d by social media such as Instagram, have unrealistic expectations and reject the man. Or, the girls of the respective age haven\u2019t yet developed <a href=\"https://www.theguardian.com/lifeandstyle/2022/nov/20/the-rise-and-fall-of-dating-apps\">online dating fatigue</a> and use dating apps to find their romantic partners, where men outside of the top 20% by physical attractiveness are generally struggling to find dates. Alternatively, the young man finds a girl who is willing to have sex with him, but his first few experiences are unsuccessful and he becomes very unconfident about intimacy.<br><br>Whatever the reason, the man decides to try the AI girlfriend experience because his friends say this is much more fun than just watching porn. He quickly develops an intimate connection with his AI girlfriend and a longing to spend time with it. He is shy to admit this to his friends, and maybe even to himself, but nevertheless he stops looking for human partners completely, justifying this to himself with having to focus on college admission, or his studies at the college, or his first years on a job.<br><br>After a year in the AI relationship, he grows very uneasy feeling about it because he feels he is missing out on \u201creal life\u201d and is compelled to stop this relationship. However, he still feels somehow \u201cburned out\u201d of romance and only half more year after the breakup with his AI partner for the first time he feels sufficiently motivated to actively pursue dates with real women. However, he is frustrated by their low engagement, intermittent responses and flakiness, their dumb and shallow interests, and by how average and uninspiring they look, which is all in stark contrast with his former AI girlfriend. His attempts to make any meaningful romantic relationship go nowhere for years.<br><br>While he is trying to find a human partner, AI partner tech develops further and becomes even more compelling than it used to be when the man left his AI partner. So, he decides to reconcile with his AI partner and finds peace and happiness in it, albeit mixed with sadness due to the fact that he won\u2019t have kids. However, this is tolerable and is a fine compromise for him.</p></blockquote><p>The defenders of AI romance usually say that the scenario described above is not guaranteed to happen. This critique sounds to me exactly like the rhetorical lines in defence of social media, specifically that kids are not guaranteed to develop social media addiction and psychological problems due to that. Of course, the scenario described above is not guaranteed to unfold in the case of every single young man. But on the scale of the entire society, the defenders of AI romance should demonstrate that the above scenario is so unlikely that the damage to society from this tech is way outweighed by the benefits to the individuals<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefalf742nn0cr\"><sup><a href=\"#fnalf742nn0cr\">[1]</a></sup></span>.</p><p>The key argument in defence of AI romantic partnership is that the relationship that is developed between people and AIs will be of a different kind than romantic love between humans, and won\u2019t interfere with the latter much. But human psychology is complex and we should expect to see a lot of variation there. Some people, indeed, may hold sufficiently strong priors against \u201cbeing in love with robots\u201d and will create a dedicated place for their AI partner in their mind, akin to fancified porn, or to stimulating companionship<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref1xcxdjmfss1\"><sup><a href=\"#fn1xcxdjmfss1\">[2]</a></sup></span>. However, I expect that many other people will fall in love with their AI partners in the very conventional sense of \"falling in love\", and while they are in love with their AIs, they won\u2019t seek other partners, humans or AIs. I reflected this situation in the story above. There are two reasons why I think this will be the case for many people who will try AI romance:</p><ul><li>People <i>already</i> report falling in love with AI chatbots, even though the current products by Replika and other startups in this sphere are far less compelling than AI partners a few years from now, as I described in the section above.</li><li>We know that people fall into genuine romantic love very easily and very quickly from chat and (video) calls alone, \"flesh and blood\" meetings are not required. To most people, even having only a few photographs of the person and chatting with them is enough to be able to fall in love with them, phone calls or videos are not required. To some people, even just chatting alone (or, in the old times, exchanging written letters), without even having a single photograph of the person, is enough to fall in love with them and to dream of nothing except meeting with them.</li></ul><p>Also, note that the story above is not even the most \u201cradical\u201d: probably some people will not even try to break up with their AI partners and seek human relationships, and will remain in love with their AI partners for ten or more years.</p><h2>Are AI partners really good for their users?</h2><p>Even if AI romantic partners will affect society negatively through the reduction of the number of people who ever enter committed relationships and/or will have kids, we should also consider how AIs could make their human partners\u2019 lives better, and find a balance between these two utilities, societal and individual.</p><p>However, it\u2019s not even clear to me that in many cases, AI partners will really make the lives of their users better, or if people wouldn\u2019t regret their decisions to embark on these relationships retrospectively.</p><p>People&nbsp;<i>can</i>&nbsp;be in love and be deeply troubled by that. In previous times (and still in some parts of the world), this would often be interclass love. Or, there could be a clash on some critical life decisions, about the country of living, having or not having children, acceptable risk in the partner (e.g., partner does extreme sports or fighting), etc. True, this does lead to breakups, but they are at least extremely painful or even traumatic to people. And many people could never overcome this, keeping their love towards those who they were forced to leave for the rest of their lives, even after they find a new love. This experience may sound beautiful and dramatic but I suspect that most people would have preferred not to go through such an experience.</p><p>So, it's plausible that for a non-negligible share of users, the attempts to \"abandon\" their AI partner and find a human partner instead will be like such a \u201ctraumatic breakup\u201d experience.</p><p>Alternatively, people who will decide to \u201csettle\u201d with their AI partners <i>before</i> having kids may remain deeply sad or unfulfilled, even though after their first AI relationship, they may not realistically be able to achieve a happier state, as the young man in the story from the previous section. Those people may regret that they have given AI romance a try in the first place, without first making their best attempt at building a family.</p><p>I recognise that here I engage in the same kind of uncertainty manufacturing that I accused the defenders of AI romance of in the previous section. But since we are dealing with \u201cproducts\u201d which can clearly affect the psychology of their users in a profound way, I think it\u2019s unacceptable to let AI romance startups test this technology on millions of their users before the startups have demonstrated in the course of long-term psychological experiments that young people even find AI partners ultimately helpful and not detrimental for their future lives.</p><p>Otherwise, we will repeat the mistake with social media, when the negative effects of it on young people\u2019s psychology became apparent only about 10 years after the technology became widely adopted and a lot of harm had already been done. Similarly to social media, AI romance may become very hard to regulate once it is widely adopted: the technology couldn\u2019t be simply shut down if there are millions of people who are already in love with AIs on the given platform.</p><h3>AI romance for going through downturns in human relationships</h3><p><a href=\"https://nypost.com/2022/03/14/man-says-relationship-with-ai-girlfriend-saved-marriage/\">This article</a> describes an interesting case where a man had an \u201caffair\u201d with an AI girlfriend while his wife was depressed for a long time and even fell in love with the AI girlfriend, but that helped him to rekindle the desire to take care of his wife and \u201csaved his marriage\u201d.</p><p>While interesting, I don\u2019t think this case can be used as an excuse to continue the development and aggressive growth of the AI partner technology for the majority of their target audience, who are single (<a href=\"https://www.businessinsider.com/replika-ai-romance-behind-partners-backs-cheating-2023-7\">Replika said that 42% of their users are in a relationship or married</a>). There are multiple reasons for this.</p><p>First, this case of a man who saved his marriage is just an anecdote, and statistics may show that for the majority of people \u201cAI affairs\u201d only erode their human relationships rather than help to rekindle and strengthen them.</p><p>Second, the case mentioned above seems to be relatively unusual: the couple already has a son (which is a very huge factor that makes people want to preserve their relationships) and the wife of the man was \u201cin a cycle of severe depression and alcohol use\u201d for entire 8 years before \u201che was getting ready for divorce\u201d. Tolerating a partner who is in a cycle of severe depression and alcohol use for 8 years could be a sign that the man was unusually motivated, deep down, to keep their relationship, either for the love for his wife or his son. It seems that the case is hardly comparable to childless couples or unmarried couples.</p><p>Third, we shouldn\u2019t forget, once again, that soon AI partners may become much more compelling than today, and while they may be merely \u201cinspiring\u201d for some people in their human relationships (which are so far more compelling that AI relationships), soon this may change, and therefore the prevalence of the cases such as the one discussed in this section will go down.</p><p>Someone may reply to the last argument that along with making AI partners more compelling, the startups which create them might also make AI partners more considered for the existing human relationships of the users and deliberately nudge the users to improve their human relationships. I think this is very unlikely to happen (in the absence of proper regulation, at least) because this will go against the business incentives of these startups, which is to keep their users \u201cstay in AI relationship\u201d and pay a subscription fee for as long as possible. Also, \u201cdeliberately nudging people to improve their human relationships\u201d is basically the role of (family) psychotherapist, and there will be, no doubt, AI products that automate this role specifically, but having such AI psychotherapists extremely sexy avatars, flirting and sexting with their users wouldn't seem to be helpful to the \u201cbasic purpose\u201d of these AIs (which AI romance startups may pretend to be \u201chelping people to work their way towards successful human relationships\u201d) at all.</p><h2>Policy recommendations</h2><p>I think it would be prudent to immediately prohibit AI romance startups to onboard new users unless they are either:</p><ul><li><strong>Older than 30 years</strong> (pre-frontal cortex is not fully formed before 25 years; most men don\u2019t get to see what women they <i>could</i> potentially have relationships with before they are at least 28-30 years old); or,</li><li><strong>Clinically diagnosed psychopaths</strong> or have another clinical condition which could be dangerous for their human partners; or</li><li><strong>AI partner is recommended to a person by a psychotherapist for some other reason</strong>, such as the person has a severe defect in their physical appearance or a disability and the psychotherapist sees that the person doesn\u2019t have psychological resources or a willingness to deal with their very small chances of finding a human partner (at least before the person turns 30 years old, at which point the person could enter a relationship with an AI anyway), or because they have a depression or a very low self-esteem and the psychotherapist thinks the AI partner may help the person to combat with this issue, etc.</li></ul><p>It\u2019s also worthwhile to reiterate that many alleged benefits of AI romantic partners for their users and/or society, such as making people achieve happier and more effective psychological states, motivating them to achieve their goals, and helping them to develop empathy and emotional intelligence, could be embodied in AI teachers, mentors, psychotherapists, coaches, and friends/companions, without the romantic component, which will probably stand in the way of realising these benefits, although admittedly may be used as a clever strategy for mass adoption.</p><p>In theory, it might be possible to create such an AI that mixes romance, flirt, gamification, coaching, mentorship, education, and anti-addiction precautions in such a proportion that it genuinely helps young adults as well as society, but it seems to be out of reach for AI partners (and LLMs that underlie them) for the following few years at least and would require long psychological experiments to test. In a free and unregulated market for AI romance, any such \u201canti-addictive\u201d startup is bound to be outcompeted by startups which make AIs that maximise the chances that the user falls in love with their AI and stays on the hook for as long as possible.</p><h3>What about social media, online dating, porn, OnlyFans?</h3><p>Of course, all these technologies and platforms harm society as well (while benefitting at least some of their individual users, at least from some narrow perspectives). But I think bringing them up in the discussions of AI romance is irrelevant and is a classic case of whataboutism.</p><p>However, we should notice that <strong>AI partners are probably going to grab human attention more powerfully and firmly than any of social media, online dating, or porn has managed to do before</strong>. As a matter of simple heuristic, this inference alone should give us a pause and even if we think that this is unnecessary to regulate or restrict access to porn (for instance), this shouldn\u2019t automatically mean that the same policy is right for AI romantic partners.</p><hr><p><i>This post is cross-posted on </i><a href=\"https://www.lesswrong.com/posts/FK8SwbcCq4HqvXmLv/ai-romantic-partners-will-harm-society-if-they-go\"><i>LessWrong</i></a><i>.</i></p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnalf742nn0cr\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefalf742nn0cr\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Whereas it\u2019s not even clear that young individuals will really benefit from this technology, on average. More on this in the following section.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn1xcxdjmfss1\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref1xcxdjmfss1\">^</a></strong></sup></span><div class=\"footnote-content\"><p>I\u2019m sure that such \u201ccompanionship\u201d will be turned into a selling point for AI romantic partners. I think AI companions, mentors, coaches, and psychotherapists are worthwhile to develop, but none of such AIs should have a romantic or sexual aspect. More on this in the section \"Policy recommendations\" below.</p></div></li></ol>", "user": {"username": "Roman Leventov"}}, {"_id": "SZ6reaQ2HkABAcY2N", "title": "[JOB] Opportunity to found Charity Entrepreneurship NGO (outside of the incubation program): Tobacco taxation advocacy", "postedAt": "2023-07-31T15:38:16.542Z", "htmlBody": "<h1>Overview of job posting</h1><ol><li><a href=\"https://forum.effectivealtruism.org/posts/SZ6reaQ2HkABAcY2N/job-opportunity-to-found-charity-entrepreneurship-ngo#Highlights\">Highlights</a></li><li><a href=\"https://forum.effectivealtruism.org/posts/SZ6reaQ2HkABAcY2N/job-opportunity-to-found-charity-entrepreneurship-ngo#Why_found_an_NGO_charity\">Why found a NGO/charity</a></li><li><a href=\"https://forum.effectivealtruism.org/posts/SZ6reaQ2HkABAcY2N/job-opportunity-to-found-charity-entrepreneurship-ngo#Why_tobacco_taxation\">Why tobacco taxation</a></li><li><a href=\"https://forum.effectivealtruism.org/posts/SZ6reaQ2HkABAcY2N/job-opportunity-to-found-charity-entrepreneurship-ngo#The_role\">The role</a></li><li><a href=\"https://forum.effectivealtruism.org/posts/SZ6reaQ2HkABAcY2N/job-opportunity-to-found-charity-entrepreneurship-ngo#Who_your_future_co_founder_is\">Who your future co-founder is</a></li><li><a href=\"https://forum.effectivealtruism.org/posts/SZ6reaQ2HkABAcY2N/job-opportunity-to-found-charity-entrepreneurship-ngo#The_selection_process\">The selection process</a></li><li><a href=\"https://forum.effectivealtruism.org/posts/SZ6reaQ2HkABAcY2N/job-opportunity-to-found-charity-entrepreneurship-ngo#How_to_apply\">How to apply</a></li><li><a href=\"https://forum.effectivealtruism.org/posts/SZ6reaQ2HkABAcY2N/job-opportunity-to-found-charity-entrepreneurship-ngo#FAQs\">FAQs</a></li><li><a href=\"https://forum.effectivealtruism.org/posts/SZ6reaQ2HkABAcY2N/job-opportunity-to-found-charity-entrepreneurship-ngo#Recommended_readings\">Recommended readings</a></li></ol><p>&nbsp;</p><p><a href=\"https://docs.google.com/forms/d/e/1FAIpQLSdzF2T9L4cGqOkV55ol8CT2Z-HagEusM6QbVobQD592ZCOO4w/viewform?usp=sf_link\"><strong>Apply</strong></a> to be the co-founder of a Charity&nbsp;Entrepreneurship (CE) tobacco taxation advocacy NGO with a CE incubatee from the recent winter cohort.</p><p>Charity Entrepreneurship is often called the Y combinator of the charity/NGO space and its alumni are compared to the PayPal Mafia (but for the charity sector).</p><p><i>Note: this is <u>not</u> an application for the upcoming CE incubation program. You can apply for that&nbsp;</i><a href=\"https://www.charityentrepreneurship.com/incubation-program\"><i>here</i></a><i>.</i></p><p>&nbsp;</p><p><strong>Early application deadline: August 6<sup>th</sup> 23:59 UTC</strong></p><p><strong>Application deadline: August 13<sup>th</sup> 23:59 UTC</strong></p><p>After the deadline, applications will be taken on a rolling basis.</p><p>The process is going to be fast and most applicants that go through the whole process will do so in about 3.5 weeks. Times will be quicker for applicants that submit earlier at each stage. Turnaround times will typically be a matter of days.</p><p>&nbsp;</p><h1>Highlights</h1><ul><li><i><strong>The opportunity</strong></i><ul><li>This is a&nbsp;<a href=\"https://9475dbf4-555e-4808-9886-5f8ee815cc82.usrfiles.com/ugd/9475db_a1f6dde1f00e4e768b807327dd17a13e.pdf\">CE-researched intervention</a> with a&nbsp;<a href=\"https://www.youtube.com/watch?v=UhArKVmkS9I\">CE incubatee</a>\u2014J.T. Stanley\u2014that will be considered for seed funding (via the CE seed funder network) in mid-September.<ul><li>(The CE incubatee went through the winter 2023 cohort. His original match for co-founder from the cohort ended up pursuing another career opportunity with comparable impact that arose near the end of the program.)</li></ul></li></ul></li></ul><p>&nbsp;</p><ul><li><i><strong>The impact</strong></i><ul><li><strong>Tobacco is 13x Malaria in deaths&nbsp;</strong>(<a href=\"https://www.who.int/news-room/fact-sheets/detail/tobacco\">WHO</a>, 2023).</li><li>Whereas malaria, HIV, and neonatal deaths are all decreasing year over year, deaths from tobacco are increasing. <strong>Tobacco is currently on track to kill a billion people in the 21st century</strong> (<a href=\"https://www.who.int/publications/i/item/9789240032095\">WHO</a>, 2021).</li><li><a href=\"https://forum.effectivealtruism.org/posts/RRm8vnmwjWK24ung2/taxing-tobacco-the-intervention-that-got-away-happy-world-no#Problem_space\">Here is a link</a> to a section that talks about the financial and economic impacts.</li><li><strong>Taxation is both the most effective and most neglected form of tobacco control</strong>&nbsp;(<a href=\"https://www.who.int/activities/raising-taxes-on-tobacco#:~:text=Tobacco%20use%20kills%20eight%20million,measure%20for%20reducing%20tobacco%20use.\">WHO</a>;&nbsp;<a href=\"https://cancercontrol.cancer.gov/sites/default/files/2020-08/m21_complete.pdf\">NIH, 2016</a>;&nbsp;<a href=\"https://www.canva.com/link?target=https%3A%2F%2Fblogs.worldbank.org%2Fhealth%2Ftaxation-most-effective-still-least-used-tobacco-control-measure&amp;design=DAFhod1T8FI&amp;accessRole=viewer&amp;linkSource=document\">World Bank, 2017</a>).</li><li>Multiple EA organizations have ran analysis that found tobacco taxation advocacy to be \u201can extremely cost-effective intervention.\u201d<ul><li>CE\u2019s cost-effectiveness <a href=\"https://docs.google.com/spreadsheets/d/1i1wTJgeXiqvJF_OuYcZtMrCUlh_UHJu7a5BpDi56Npc/edit#gid=1384295676\">analysis</a> put the expected value between 39 and 51 USD per DALY averted.<a href=\"#_ftn1\">[1]</a></li><li><strong>Open Philanthropy</strong>\u2019s<strong>&nbsp;</strong><a href=\"https://docs.google.com/spreadsheets/d/12--1_VRJFIos4z6x_EGRDJcblLWjo0h0t7HBjcK-LFc/edit#gid=908733067\">back-of-the-envelope calculation</a><strong>&nbsp;</strong>found<strong>&nbsp;30 USD per DALY averted in expectation.</strong><a href=\"#_ftn2\">[2]</a></li><li>Giving What We Can\u2019s (GWWC) <a href=\"https://www.givingwhatwecan.org/reports/tobacco-control\">report</a> suggested that cost per life saved could go as low as 800 USD according to one scientific study.<a href=\"#_ftn3\">[3]</a></li></ul></li><li>In other words, a&nbsp;<i>successful</i>&nbsp;tobacco taxation charity would immediately have an impact with cost-effectiveness at the upper echelons (think Against Malaria Foundation for GiveWell and Lead Exposure Elimination Project for CE).</li></ul></li></ul><p>&nbsp;</p><ul><li><i><strong>Why you should apply</strong></i><ul><li>This is your chance to be a founder of an impactful organization.</li><li>Don\u2019t count yourself out. If in doubt apply. Roughly half of the successful applicants/founders that are accepted into the CE incubation program did not think they would qualify. Don\u2019t preempt yourself from becoming a founder; let the process play out.</li><li>If you\u2019ve applied to CE in the past, this is the opportunity for you.</li></ul></li></ul><p>&nbsp;</p><h1>Why found an NGO/charity</h1><p><i><strong>Pros</strong></i></p><ol><li>You are not just a cog in the machine; you have ownership of a venture/organization that could deliver massive impact. The health of hundreds of thousands of tobacco users depends on you and your co-founder\u2019s fateful actions.</li><li>One of the best expected values for&nbsp;impact\u2014This intervention has the potential to avert&nbsp;a ridiculously high amount of deaths and DALYs.</li><li>Upward career mobility and increased impact later in your career. Running an impactful organization will give you critical skills, experience, and career capital that will better position you for impact later in your career.</li></ol><p>&nbsp;</p><p><i><strong>Cons</strong></i></p><ol><li>A much more serious commitment than your typical job.</li><li>Founder salaries of CE charities are very modest compared to other parts of the EA ecosystem and the first-year salary is lean.</li><li>Founding an organization and trying to bring&nbsp;it to success is a rollercoaster of highs and lows\u2014this is for people with perseverance and grit.<ul><li>Tobacco kills 8 million people annually (<a href=\"https://www.who.int/news-room/fact-sheets/detail/tobacco\">WHO</a>).</li></ul></li></ol><p>&nbsp;</p><h1>Why tobacco taxation</h1><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/SZ6reaQ2HkABAcY2N/ozbsgganps3qwdydphhn\" alt=\"Figure\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/SZ6reaQ2HkABAcY2N/lohgrcz4siazyl1ifd1b 150w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/SZ6reaQ2HkABAcY2N/zucdmyydo4fwz7hqf1pl 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/SZ6reaQ2HkABAcY2N/az5eebfuymbw4splauoy 450w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/SZ6reaQ2HkABAcY2N/obvj6vkstlfmwm8gpwhw 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/SZ6reaQ2HkABAcY2N/fgimpamh13ay6bytpclu 750w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/SZ6reaQ2HkABAcY2N/o749mmq7ohoejfdp3qjz 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/SZ6reaQ2HkABAcY2N/r87peeopptxfqx17jfqj 1050w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/SZ6reaQ2HkABAcY2N/acqaizsirey3ybmodayx 1200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/SZ6reaQ2HkABAcY2N/zipne5katmbmidsenazm 1350w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/SZ6reaQ2HkABAcY2N/qpfn0zkinrxrjyb8jytw 1429w\"> (^From&nbsp;<a href=\"https://www.givingwhatwecan.org/reports/tobacco-control\">GWWC\u2019s 2015 report</a>)</p><p><i><strong>Problem</strong></i></p><ul><li><strong>Tobacco kills 8 million people annually </strong>(<a href=\"https://www.who.int/news-room/fact-sheets/detail/tobacco\">WHO</a>).</li><li>1.3 million are killed from secondhand smoke annually (<a href=\"https://www.canva.com/link?target=https%3A%2F%2Fwww.who.int%2Fnews-room%2Ffact-sheets%2Fdetail%2Ftobacco&amp;design=DAFhod1T8FI&amp;accessRole=viewer&amp;linkSource=document\">WHO</a>).</li><li>Disproportionately used by the poor in both HICs and LMICs&nbsp;(<a href=\"https://apps.who.int/iris/bitstream/handle/10665/44453/9789241500548_eng.pdf\">WHO, 2011</a>; <a href=\"https://www.cgdev.org/blog/who-smokes-developing-countries-implications-tobacco-tax\">CGD, 2019</a>).</li><li>Displaces household income (the median result of studies on this topic is roughly 4.5% of annual income)&nbsp;(<a href=\"https://tobaccocontrol.bmj.com/content/10/3/210\">de Beyer et al., 2001</a>).</li><li>The annual costs of tobacco from healthcare expenditures and losses in productivity are estimated at 1.8% of the world GDP&nbsp;(<a href=\"https://tobaccocontrol.bmj.com/content/27/1/58\">Goodchild et al., 2018</a>) (<a href=\"https://tobacconomics.org/files/research/523/UIC_Economic-Costs-of-Tobacco-Use-Policy-Brief_v1.3.pdf\">Tobacconomics, 2019</a>).</li><li>Globally the majority of addicts get hooked when they are a minors (<a href=\"https://www.theguardian.com/news/2016/aug/01/the-doctor-who-beat-big-tobacco\">The Guardian, 2016</a>).</li><li>Tobacco production utilizes several million child laborers (<a href=\"https://www.theguardian.com/news/2016/aug/01/the-doctor-who-beat-big-tobacco\">The Guardian, 2016</a>).</li><li>Deforestation from Tobacco is estimated as one tree for every 300 cigarettes produced totaling 600 million trees a year (<a href=\"https://truthinitiative.org/research-resources/harmful-effects-tobacco/how-tobacco-products-harm-environment-their-manufacture\">Truth Initiative, 2018</a>;&nbsp;<a href=\"https://www.who.int/campaigns/world-no-tobacco-day/2022\">WHO, 2022</a>)</li><li>Cigarettes are the most littered item in the world\u2014accounting for 1.7 billion pounds of toxic waste and over a third of all litter collected annually (<a href=\"https://truthinitiative.org/research-resources/harmful-effects-tobacco/5-ways-cigarette-litter-impacts-environment\">Truth Initiative, 2017</a>)</li><li>Tobacco\u2019s carbon footprint is equivalent to one-fifth of the carbon emissions from the commercial airline industry\u201484 million tonnes (<a href=\"https://www.who.int/news/item/31-05-2022-who-raises-alarm-on-tobacco-industry-environmental-impact\">WHO, 2022</a>).</li></ul><p>&nbsp;</p><p><i><strong>Intervention</strong></i></p><ul><li>Tobacco taxation is the <strong>most effective</strong> form of tobacco control&nbsp;(<a href=\"https://www.who.int/activities/raising-taxes-on-tobacco#:~:text=Tobacco%20use%20kills%20eight%20million,measure%20for%20reducing%20tobacco%20use.\">WHO</a>;&nbsp;<a href=\"https://cancercontrol.cancer.gov/sites/default/files/2020-08/m21_complete.pdf\">NIH, 2016</a>;&nbsp;<a href=\"https://www.canva.com/link?target=https%3A%2F%2Fblogs.worldbank.org%2Fhealth%2Ftaxation-most-effective-still-least-used-tobacco-control-measure&amp;design=DAFhod1T8FI&amp;accessRole=viewer&amp;linkSource=document\">World Bank, 2017</a>)<ul><li>Tobacco taxation typically has a price elasticity of -0.4 in HICs and -0.5 in LMICs, <strong>meaning that for every 10% increase in retail price there is 5% reduction in smoking</strong> (<a href=\"https://cancercontrol.cancer.gov/sites/default/files/2020-08/m21_complete.pdf\">NIH, 2016</a>).</li><li>Taxation reduces consumption especially amongst the most poor who are the&nbsp;most price sensitive (and also incur the most social costs from smoking)&nbsp;(<a href=\"https://tobaccocontrol.bmj.com/content/10/3/210\">de Beyer et al., 2001</a>; <a href=\"https://theunion.org/sites/default/files/2020-08/FS8%20-%20Tobacco%20and%20Poverty%202015.pdf\">The Union, 2015</a>; <a href=\"https://tobacconomics.org/uploads/misc/2018/03/UIC_Tobacco-and-Poverty_Policy-Brief.pdf\">Tobacconomics, 2018</a>)</li></ul></li><li>Tobacco taxation is the <strong>most neglected</strong> form of tobacco control (<a href=\"https://www.canva.com/link?target=https%3A%2F%2Fblogs.worldbank.org%2Fhealth%2Ftaxation-most-effective-still-least-used-tobacco-control-measure&amp;design=DAFhod1T8FI&amp;accessRole=viewer&amp;linkSource=document\">World Bank, 2017</a>)</li></ul><p>&nbsp;</p><p><i><strong>How tobacco taxation compares with other CE interventions</strong></i></p><ul><li>This is a policy intervention therefore its expected value is predicated on tailend outcomes. Passing policy is typically harder than a health-direct intervention, however if policy is passed and implemented then the impact would drastically exceed a health-direct intervention.</li><li>Even of policy interventions considered by CE, this is atypical. Tobacco is so disastrous for society that most policy wins would have massive impact. However, unlike some other CE policy interventions, tobacco taxation has an opposition lobby\u2014one of the most aggressive.</li></ul><p>&nbsp;</p><h1>The role</h1><p>You are applying to be a co-founder of an NGO founded through and supported by Charity Entrepreneurship.</p><p>&nbsp;</p><p><i><strong>Why co-founders are important</strong></i></p><p>Organization and co-founder success relies principally on A) judgment, B) productivity, and C) compatibility of the co-founders, and CE has found that these factors are multiplicative not additive\u2014i.e. you need high proficiency in all of them to have a top-tier impactful organization.&nbsp;</p><p>A CE charity is an experiment, it\u2019s a bet on the idea and the co-founders. It\u2019s not guaranteed that the idea will be viable in practice, and even if it is it might require the right decision-making and effort to unlock its potential impact. That latter part rides on the co-founders.</p><p>Hence a CE charity going up for funding is an experimental product that potential seed funders are evaluating, and a major component of that product is the co-founders.</p><p>&nbsp;</p><p><i><strong>Universal co-founder traits</strong></i></p><ul><li>Irrepressible<ul><li>Every start-up organization has significant low and stressful moments. Successful organizations exist not because they never experienced those moments but because the founders bounced back when they occurred.</li><li>There will be many pessimist moments where you question if the NGO can succeed with its intervention. You need to stay level-headed and push past the <i>noise</i> yet while not neglecting the <i>signal</i> of when it\u2019s time to double down, pivot, or wind down operations.</li></ul></li><li>Open-minded<ul><li>The successful tactic, strategy, etc. will often not be the first thing we think of. It\u2019s important to stay focused on finding what gets results rather than being invested in our own ideas.</li></ul></li><li>Highly productive and competent<ul><li>When starting a new organization with a seed budget, the biggest budget line item is the salaries of the co-founders. Thus, the productive output of the co-founders is critical to what the organization can accomplish with the seed budget\u2014which determines whether the organization will even secure the fundraising post-seed budget needed to scale the organization to impact.</li><li>If a person routinely can get 20% more stuff done in an hour than another person, that productive output compounds over many hours to the point that their two organizations reached substantially different outcomes at the end of a year.</li></ul></li><li>Creative<ul><li>There is no blueprint to success. Being a successful charity entrepreneur means finding innovative ways to the solution when conventional means fall short.</li></ul></li><li>Goal-oriented<ul><li>A co-founder\u2019s single biggest value (what the CE community is investing in) is the ability to find a way to get from point A to point B when most people haven\u2019t found a way, when there is no structure&nbsp;or blueprint, and when there are high degrees of ambiguity&nbsp;and difficulty. Co-founders are the ones that when tasked with getting to an end point find a way despite the challenges.</li></ul></li></ul><p>&nbsp;</p><p><i><strong>What you don\u2019t need</strong></i></p><p>There are many misconceptions about what it takes to be a successful founder. CE has found the following to not be necessary.</p><ul><li>Expertise in the subject<ul><li>As with past CE founders, you will become the expert in your field by diving headfirst. More important than a background in the subject is your ability to learn things quickly.</li></ul></li><li>Extensive experience<ul><li>As a founder you will need to have a hand in every part of running the org and every CE founder has taken on tasks that they didn\u2019t have experience in. The important trait is, again, being able to learn new things quickly (as a generalist), as well as, doing things to a high-quality level.</li></ul></li><li>Extraversion or being a great public speaker<ul><li>There have been great co-founders that didn\u2019t possess these skills. The more important thing is having at least one co-founder that can pitch your organization\u2014which your future co-founder can do.</li></ul></li></ul><p>&nbsp;</p><p><i><strong>Other important requirements</strong></i></p><p>Willing to travel abroad for&nbsp;<strong>at least</strong>&nbsp;3 months of the year. This would be waived for a candidate that brings exceptional value. Previous experience traveling (and being comfortable in) LMICs is preferred. Work overseas, especially in LMICs, is a plus but not necessary.</p><p>&nbsp;</p><p><strong>Here is some additional content (</strong><a href=\"https://www.youtube.com/watch?v=S7Cu59G1aSQ&amp;t=76s\"><strong>11 min video</strong></a><strong>) to consider about if you are the right fit for founding.</strong></p><p>&nbsp;</p><h1>Who your future co-founder is</h1><p>Your future co-founder\u2014J.T. Stanley\u2014was accepted into the incubation program on his second attempt (hint: it\u2019s okay if you applied to CE before and did not get in) and went through the <a href=\"https://www.youtube.com/watch?v=UhArKVmkS9I\">winter 2023 cohort</a>. During the cohort he settled on tobacco taxation.&nbsp;</p><p>In his recent past endeavors, he worked for a small local NGO in Goma, Congo in conflict threatened territory, started a small virtual reality business in Congo, and developed a few projects related to US democracy and governance.</p><p>Since the last cohort, he\u2019s been exploring experimental approaches to tobacco control (e.g. such as targeted reforms at the World Bank to alleviate bottlenecks) and launching the advocacy program of <a href=\"https://www.upstreampolicies.org/the-team\">Upstream Policies</a>.</p><p>Your future co-founder is a fierce competitor that was known in his cohort for being gregarious, affable, and persuasive, as well as, being a creative strategizer with strong pitching skills.</p><p>You will learn more about him as you advance through the selection pipeline. Finalists will also get to talk to other incubatees from that cohort about what it was like to work with your future co-founder.</p><p>&nbsp;</p><h1>The selection process</h1><p>The selection process is modeled after the CE selection process for the incubation program. It is a multi-stage process designed to be respectful of your time while finding people that match the predictive profiles of founders. Additionally, and unlike the CE selection process, this process will assess your compatibility with this specific co-founder.</p><ol><li>Application</li><li>Test task</li><li>Interview</li><li>Team work trial</li></ol><p>The process is going to be fast and most applicants that go through the whole process will do so in about 3.5 weeks. Times will be quicker for applicants that submit earlier at each stage. Turnaround times will typically be a matter of days.</p><p>At the last stage you will get to speak with peers from your co-founders\u2019 cohort about what it is like working with him and better inform your decision (because deciding to co-found together is a two-way street).</p><p><i>If you\u2019ve read to this point and decided not to apply I\u2019d love to hear why. </i><a href=\"https://docs.google.com/forms/d/e/1FAIpQLSd3ruOpbzSdK1NtjzsAwWymM0DIgOGjrvN1wWazstovBiTcWA/viewform?usp=sf_link\"><i>Here</i></a><i> is a one-question form where you can do that.</i></p><p>&nbsp;</p><h1>How to apply</h1><p><a href=\"https://docs.google.com/forms/d/e/1FAIpQLSdzF2T9L4cGqOkV55ol8CT2Z-HagEusM6QbVobQD592ZCOO4w/viewform?usp=sf_link\">Here is the link to the application form</a>.</p><p><strong>Early application deadline: August 6<sup>th</sup> 23:59 UTC</strong></p><p><strong>Application deadline: August 13<sup>th</sup> 23:59 UTC</strong></p><p>After the deadline, applications will be taken on a rolling basis.</p><p>&nbsp;</p><p>The application consists of many multiple-choice questions and a few short-answer questions. The additional requirement is to attach a resume. If you have launched or ran any ventures, organizations, or independent projects, the resume is a good place to highlight them.</p><p>Your identity will be blinded during the application and test task for impartial evaluation. To ensure this, please don\u2019t write your name in the short answers.</p><p>&nbsp;</p><h1>FAQs</h1><p><i><strong>Why has this not been founded before?</strong></i></p><ul><li>People were more attracted to health-direct interventions to be closer to the beneficiaries.</li><li>People were hesitant to go up against the tobacco industry.</li></ul><p>&nbsp;</p><p><i><strong>How much seed funding do you expect this intervention will receive?</strong></i></p><ul><li>Co-founder quality and fit will greatly affect what the seed funders think. Hence this intensive and iterative selection process (and the importance of you applying!)</li><li>For context, the three human (health-direct) charities in J.T.\u2019s cohort received $130,000 \u2013 $190,000. The animal policy charity received $110,000.</li><li>In the previous cohort (summer 2022), the one human policy charity received $170,000.</li><li>(all numbers are in USD)</li><li>Funding is not guaranteed. Some proposals have received zero funding in the past.</li><li>CE has a recent track record of getting 70-80% of proposals funded.</li></ul><p>&nbsp;</p><p><i><strong>I'm afraid do it without training from the CE incubation program (CE IP).</strong></i></p><ul><li>Everyone in my cohort will tell you not to worry about this. The training is not the principal value of CE IP, and the training can be supplemented. This will be elaborated on further in the selection pipeline.&nbsp;</li></ul><p>&nbsp;</p><p><i><strong>Is there a hierarchy? How much ownership do I get?</strong></i></p><ul><li>You will be one of two equal cofounders. There will likely be a bit of asymmetry at first because J.T. has been focused on this endeavor for a few more months than you. However, this will erode quickly and steps will be proactively taken to forge a shared vision for the organization.</li></ul><p>&nbsp;</p><h1>Recommended readings</h1><ol><li><a href=\"https://www.charityentrepreneurship.com/book\">CE handbook</a> \u2013 <i>top recommendation</i><ol><li>You can do a Kindle Unlimited free trial (and cancel it later) to get access to the book for free&nbsp;</li></ol></li><li><a href=\"https://9475dbf4-555e-4808-9886-5f8ee815cc82.usrfiles.com/ugd/9475db_a1f6dde1f00e4e768b807327dd17a13e.pdf\">CE\u2019s report</a> on tobacco taxation</li><li>J.T.\u2019s <a href=\"https://forum.effectivealtruism.org/posts/RRm8vnmwjWK24ung2/taxing-tobacco-the-intervention-that-got-away-happy-world-no\">EA Forum post</a> on tobacco taxation</li><li><a href=\"https://www.openphilanthropy.org/research/tobacco-control/\">Open Philanthropy\u2019s report</a> on tobacco control</li><li><a href=\"https://www.givingwhatwecan.org/reports/tobacco-control\">Giving What We Can\u2019s report</a> on tobacco&nbsp;</li></ol><hr><p><a href=\"#_ftnref1\">[1]</a> Based on a tax increase of 23.7% in Mongolia and Lebanon with 27.14% chance of success.</p><p><a href=\"#_ftnref2\">[2]</a> In Indonesia with a 10% probability of success, million-dollar campaign, 10% increase in retail price, and a counterfactual speed up of 3 years.</p><p><a href=\"#_ftnref3\">[3]</a> This appears to be under a scenario where the intervention is scaling.</p>", "user": {"username": "Yelnats T.J."}}, {"_id": "d7ocec7gNW3KNX6Nz", "title": "If AIs had subcortical brain simulation, would that solve the alignment problem?", "postedAt": "2023-07-31T15:48:51.167Z", "htmlBody": "<p>Warning: I am very unsure about all the things I say in this comment.</p>\n<p>Summary: I suspect that to begin solving the AI alignment problem we need to have AIs that have affective experiences similar to the ones humans have. That way they would have similar to humans values. That may be achieved with neural simulation.</p>\n<p>It seems like AGIs will be agents who try to maximise their reward function (from reinforcement learning) by doing things and learning from what they're doing. AI safety and alignment research is concerned with making sure that AIs have similar enough values to humans' values and that AIs don't do somethings catastrophically dangerous to humans. The questions would be \"how similar should these values or goals be?\" and \"what do humans value universally?\" and \"how would we compute that into AIs?\".</p>\n<p>But humans conflict with each other a lot (to the point of numerous wars). And they self-report somewhat different values (for example: conservatives and liberals value things quite differently from each other, judging from Jonathan Haidt's research). So it seems like humans are somewhat misaligned with each others' goals and values. So how would we align AIs with humans' goals and values when we seem to differ so much on that? Also, there is the problem of making our goals inteligible and measurable enough to act as reward functions for AIs.</p>\n<p>So it seems like the alignment problem might be pretty hard to solve. But then I thought that all reinforcement learning agents seem to have the terminal goal of optimising their own reward functions, whatever those may be. And then I asked \"what is the reward function of humans, if they have any?\".</p>\n<p>I think that humans' \"reward function\" is affect. Affective experiences reward and punish us and they can be of various types: sensory (pleasure from seeing something beautiful, disgust from smelling spoiled food or seeing something ugly), homeostasic (thirst, hunger, sleepiness, physical pains, food satiation), and emotional (the 7 basic affective systems described by Jaak Pankseep: SEEKING, RAGE, FEAR, LUST, CARE, GRIEF, PLAY). These experiences are \"produced\" by subcortical regions and circuits in mammalian brains, including humans' ones (like the ventral tegmental area or periaqueductal gray). They seem to be responsible for humans' universal basic \"values\".</p>\n<p>So, if AIs would also have these human values, specifically these kinds of affects, would that help with solving the AI alignment, corrigibility (changing AIs' goals) and interpretability (reading AIs' minds) problems? If we could compute neurons that are similar in function to humans' neurons, then put them together into networks that are similar to the brain circuits responsible for these affects, would that give the AIs these human values? Could that be achieved with brain simulation or something similar? I don't know.</p>\n<p>So, do you think that this kind of aproach is promising?</p>\n<p>Or do you think that this would lead to all sorts of problems, like sentient AIs getting mad at us and waging war with us, or AI companies ignoring this aproach because these AIs wouldn't be as capable, even if they are safer, or AIs acting in dangerous ways because that's what humans and mammals tend to do, or that we simply won't be able to develop this, or that black hat hackers will use them for hacking purposes?</p>\n", "user": {"username": "Rainbow Affect"}}, {"_id": "z8ZWwm4xeHBAiLZ6d", "title": "Thoughts on far-UVC after working in the field for 8 months", "postedAt": "2023-07-31T14:36:43.614Z", "htmlBody": "<p><i>Views expressed in this article are my own and do not necessarily reflect those of my employer&nbsp;</i><a href=\"https://securebio.org/\"><i><u>SecureBio</u></i></a><i>.</i></p><h2>Summary</h2><ul><li>Far-UVC has great promise, but&nbsp;<strong>a lot of work still needs to be done</strong><ul><li>There still are many important open research questions that need to be answered before the technology can become widely adopted</li><li>Right now, a key priority is to grow the research field and improve coordination</li></ul></li><li>The main reason far-UVC is so promising is that widespread installation&nbsp;<strong>could passively suppress future pandemics before we even learn that an outbreak has occurred</strong>&nbsp;</li><li>Higher doses mean more rapid inactivation of airborne pathogens but also more risk for harm to skin, eyes, and through indoor air chemistry. Therefore, the important question in safety is, \u201c<strong>How high can far-UVC doses go while maintaining a reasonable risk profile?</strong>\u201d</li><li>Existing evidence for skin safety within current exposure guidelines seems pretty robust, and I expect that skin safety won't be the bottleneck for far-UVC deployment at higher doses.</li><li>Current evidence around eye safety is much more sparse than for skin safety. Eye safety seems like it could be the bottleneck to what doses of far-UVC can be reasonably used.&nbsp;</li><li>Undoubtedly, far-UVC has a substantial impact on indoor air chemistry by producing ozone, which oxidizes volatile organic compounds in the air that can result in harmful products such as particulate matter.<ul><li>Little research has been done on methods to mitigate this issue.&nbsp;</li><li>This might turn out to be a bottleneck to what doses of far-UVC can be reasonably used, but I am really uncertain here.</li></ul></li><li>There is no doubt that far-UVC can dramatically reduce the amount of airborne pathogens within a room (inactivation of ~98% of aerosolized bacteria within 5 minutes).&nbsp;<strong>Crucially, we don't know how well this translates into an actual reduction in the total number of infections.</strong></li><li>Very few people have thought about how the adoption of far-UVC could be driven and what a widespread deployment of the technology could look like</li><li>So far, there is little to no regulation of far-UVC.&nbsp;<ul><li>In the US, (potential) regulation of far-UVC seems quite messy, as no authority has clear jurisdiction over it.</li></ul></li></ul><h2>Introduction</h2><p>Far-UVC (200-235 nm) has received quite a&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/pgSKdPwDbG5EppRFC/ubiquitous-far-ultraviolet-light-could-control-the-spread-of\"><u>bit</u></a>&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/WLok4YuJ4kfFpDRTi/first-clean-water-now-clean-air\"><u>of</u></a>&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/AJwuMw7ddcKQNFLcR/20-concrete-projects-for-reducing-existential-risk#Finding_market_opportunities_for_biodefence_relevant_technologies\"><u>attention</u></a> in EA-adjacent biosecurity circles as a technology to reduce indoor airborne disease spread and is often discussed in the context of&nbsp;<a href=\"https://forum.effectivealtruism.org/topics/indoor-air-quality\"><u>indoor air quality</u></a> (IAQ). Notably, Will MacAskill&nbsp;<a href=\"https://youtu.be/I9C41fx64dw?t=3942\"><u>mentioned</u></a>&nbsp;<a href=\"https://www.theguardian.com/world/2022/aug/21/william-macaskill-what-we-owe-the-future-philosopher-interview\"><u>it</u></a>&nbsp;<a href=\"https://www.npr.org/sections/goatsandsoda/2022/08/16/1114353811/how-can-we-help-humans-thrive-trillions-of-years-from-now-this-philosopher-has-a\"><u>often</u></a> throughout various media appearances in 2022.&nbsp;</p><p>I have been working on research around far-UVC for the past 8 months. More specifically, we wrote an extensive literature review on skin and eye safety (EDIT: now <a href=\"https://doi.org/10.1111/php.13866\">published online</a> [open access] <s>submitted &amp; soon\u2122 to be published as an academic paper</s>). We also coordinated with many researchers in the field to lay out a plan for the studies that still need to be done to get a more comprehensive understanding of the technology\u2019s safety &amp; efficacy.&nbsp;</p><p>Although far-UVC has been discussed on the forum, the existing information is relatively shallow, and most in-depth knowledge is either buried in technical research papers or not publicly available since a lot of intricacies are mostly discussed informally within the research community.</p><p>In this post, I will first offer high-level thoughts and then go over different categories of information around far-UVC (safety, efficacy, indoor air chemistry, adoption, and regulation) to provide my current perspectives &amp; takes. Please note that I am much more familiar with safety aspects than with the other categories. Also, this is not a general overview of far-UVC, what it is, and how it works. For a relatively recent and comprehensive introduction, I recommend \u201c<a href=\"https://www.tandfonline.com/doi/full/10.1080/10643389.2022.2084315\"><u>Far UV-C radiation: An emerging tool for pandemic control</u></a>\u201d.&nbsp;</p><h2>High-level thoughts</h2><ul><li><strong>Far-UVC seems like the only technology we currently know of that has the potential to passively mitigate a future catastrophic pandemic before we even know it is happening.</strong><ul><li>This is the main reason why it is so promising</li><li>For most of our other defenses against pandemics, e.g., masking/vaccines, we first need to notice a disease outbreak is occurring and then decide to deploy these countermeasures.&nbsp;</li><li>Widespread far-UVC could potentially halt an outbreak at an early stage without us ever learning that it happened.</li><li>While upper-room germicidal UV (GUV), ventilation/filtration and portable air purifiers similarly work in a passive manner, they&nbsp;<a href=\"https://www.nature.com/articles/s41598-022-08462-z\"><u>don't nearly reach</u></a> the rates of rapid pathogen inactivation that far-UVC can.<ul><li>There are also preliminary discussions about&nbsp;<a href=\"https://academic.oup.com/jid/article/226/11/2040/6731734\"><u>triethylene glycol</u></a> and&nbsp;<a href=\"https://www.mdpi.com/1999-4915/15/7/1443\"><u>microwave inactivation</u></a> as further passive interventions for controlling indoor airborne transmission but there is much less evidence for these.&nbsp;</li></ul></li></ul></li><li>In contrast to conventional GUV systems installed in the upper-room or air purifiers, far-UVC works through whole-room direct exposure. This means that&nbsp;<strong>far-UVC could provide immediate disinfection of aerosols within people\u2019s breath plumes. Plausibly, it could therefore help to slow down close-contact transmission, e.g. between people in a conversation.</strong>&nbsp;<ul><li>Whether this works in practice remains to be determined.&nbsp;</li></ul></li><li><strong>Far-UVC is still a young technology and research field.</strong><ul><li>A lot remains to be done before it can become widespread.</li><li>For example, the first-ever conference on far-UVC only happened&nbsp;<a href=\"https://web.cvent.com/event/231ad906-ecc1-4577-9bf9-32e11ae26f1a/summary\"><u>this June</u></a>.<ul><li>You can watch&nbsp;<a href=\"https://web.cvent.com/event/231ad906-ecc1-4577-9bf9-32e11ae26f1a/websitePage:0edb4b77-2385-4aae-9b7b-680115a7d7b0\"><u>recordings</u></a> of the talks!</li></ul></li><li>A far-UVC fixture currently costs ~$1000; the cheapest ones cost ~$500. There are approx. 20 (small) vendors of far-UVC fixtures.</li></ul></li><li>Multiple EA(-adjacent) organizations are doing work around far-UVC; these are the ones I am aware of (there might be more):<ul><li><a href=\"https://www.openphilanthropy.org/\"><u>Open Philanthropy</u></a><ul><li>Seem to be becoming increasingly interested in far-UVC. They recently put out a&nbsp;<a href=\"https://www.openphilanthropy.org/research/request-for-information-evaluation-of-germicidal-far-uvc-safety-efficacy-technology-and-adoption/\"><u>Request for Information: Evaluation of Germicidal Far-UVC: Safety, Efficacy, Technology, and Adoption</u></a>&nbsp;</li><li>Open Phil has funded far-UVC research in the past, e.g. at Columbia (Brenner group).</li></ul></li><li><a href=\"https://www.convergentresearch.org/\"><u>Convergent Research</u></a><ul><li>Have mostly worked on understanding the current landscape of far-UVC sources/emitters and how emitter tech development is moving forward</li><li>Convergent Research is dedicated to setting up&nbsp;<a href=\"https://www.convergentresearch.org/#learnMore\"><u>Focused Research Organizations</u></a> (FROs), so they are trying to scope out whether it could make sense to set up a FRO around far-UVC</li></ul></li><li><a href=\"https://www.1daysooner.org/\"><u>1DaySooner</u></a><ul><li>Published a report on indoor air quality, including a discussion of GUV:&nbsp;<a href=\"https://static1.squarespace.com/static/5f5f8496d1d7713486b6075a/t/645a6fa568c82728d5c51ed7/1683648422450/IAQ+Report_Final.pdf\"><i><u>Air Safety to Combat Global Catastrophic Biorisk</u></i></a></li></ul></li><li><a href=\"https://rethinkpriorities.org/\"><u>Rethink Priorities</u></a><ul><li>Ran&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/2rD6nLqw5Z3dyD5me/does-the-us-public-support-ultraviolet-germicidal\"><u>surveys</u></a> to asses the US public\u2019s perception of germicidal UV</li></ul></li></ul></li><li><strong>The ultimate goal for far-UVC is to have it become ubiquitous</strong> in indoor spaces where a lot of transmission tends to occur (e.g., hospitals, public transport).&nbsp;<ul><li>From a biosecurity perspective, we only really care about far-UVC if we can achieve widespread adoption of cheap, safe &amp; effective far-UVC. If we think that only marginal improvements to the current technology can be achieved, then it is not worth it to put substantial resources into far-UVC.&nbsp;</li></ul></li><li>A lot of information propagation in the far-UVC field happens informally via regular Zoom meetings or email lists. Many of the key researchers have known each other for a long time.&nbsp;<ul><li>This is probably&nbsp;<a href=\"https://marginalrevolution.com/marginalrevolution/2023/06/what-does-it-mean-to-understand-how-a-scientific-literature-is-put-together.html\"><u>normal</u></a>, especially for smaller fields.</li></ul></li><li>\u201cFar-UVC\u201d is often used almost synonymously with 222 nm since KrCl lamps with a peak emission wavelength at 222 nm have been the most efficient far-UVC sources available. Due to this, most far-UVC research has focused on 222 nm.&nbsp;&nbsp;<ul><li>We should be open-minded about deploying other wavelengths in the far-UVC range when other efficient sources become available.</li><li>There is an open question about what wavelengths would be ideal for air disinfection.</li><li>For example, there is a case that slightly longer far-UVC wavelengths (~230 nm) could be superior to 222 nm.<ul><li>This is because the solid-state emitter tech development for ~230 nm seems more promising. You would also get less ozone production and increased penetration through media like bigger saliva droplets.</li></ul></li><li>Multi-wavelength systems might be promising as well.</li></ul></li></ul><h2>Safety</h2><ul><li>Before far-UVC can become widely used, we need to understand how safe it is at what doses<ul><li>Higher doses means more rapid inactivation of airborne pathogens but also more risk for harm to skin, eyes and through indoor air chemistry<ul><li>Presumably, achieving rapid enough inactivation to achieve a reduction in close contact transmission would require significantly higher doses than what current guidelines permit</li></ul></li><li>Therefore, the important question in safety is, \u201c<strong>How high can far-UVC doses go while maintaining a reasonable risk profile?</strong>\u201d</li></ul></li><li>We have compiled a&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1MloCPdN72vSGUxUUeDeeqdW4b1wAT5RIRJW1AVl-AaI/edit?usp=sharing\"><u>Google Sheet</u></a> that lists the results of most of the important far-UVC safety studies. It gives a good overview but is not comprehensive, as you can see from the (potentially relevant) studies linked at the bottom that haven't been added yet. Note the readme in the top left and let me know if you spot any mistakes.</li><li>Existing evidence for skin safety within current exposure guidelines seems pretty robust.<ul><li>Even at much higher doses than current guidelines permit, there is preliminary evidence that skin safety isn't a significant issue (at least for healthy adults)</li><li>I expect that skin safety won't be the bottleneck for far-UVC deployment at higher doses</li></ul></li><li>Current evidence around eye safety is much more sparse than for skin safety<ul><li>Studying the eyes is much harder, for example, due to the dynamic nature of the eye (blinking + tear film)<ul><li>You also can't easily take biopsies of the eye like you can do with the skin</li><li>Designing useful eye safety trials is difficult and experienced ophthalmologists we have spoken to are skeptical of many study proposals that have been put forward.&nbsp;</li></ul></li><li>There is some solid evidence of eye safety from studies on rodents, most notably from Kaidzu et al. (2019; 2021; 2022).</li><li>Due to shielding by the eye socket and lids, the eye receives a much lower dose of far-UVC in typical overhead deployment scenarios than the skin.<ul><li>Nonetheless,&nbsp;<strong>eye safety seems like it could be the bottleneck to what doses of far-UVC can be reasonably used</strong>.&nbsp;</li><li>There seems to have been a near consensus in the field that eye safety hinges on how much protection the tear film offers. There is currently a lot of discussion and research ongoing about this question.&nbsp;</li><li>The tear film contains a bunch of proteins and lipids that strongly absorb far-UVC, so some researchers assumed that the tear film could provide very strong protection, as it\u2019s replenished with every blink.<ul><li>The idea that the tear film offers nearly total protection against far-UVC photons is so widespread that even the&nbsp;<a href=\"https://www.cdc.gov/coronavirus/2019-ncov/community/ventilation.html#faq-36966-question\"><u>CDC website</u></a> says (as of 2023-07-07): \u201c<i>This increase was in response to data showing 222 nm energy does not penetrate the tear layer of the eye\u201d</i></li><li>Recent (still unpublished) results cast doubt on this and the&nbsp;<strong>evidence suggests that the tear film provides almost no protection</strong>.&nbsp;</li><li>One way to think about this is to compare the tear film with the stratum corneum, the outermost layer of the skin. At 222 nm, &gt;90% of photons are absorbed in the approx. 16 \u00b5m thick stratum corneum, which is made up of dead cells that are almost entirely filled with proteins. These proteins are responsible for absorbing the far-UVC photons. The tear film, on the other hand, is only ~3-5 \u00b5m thick and mostly water, with some proteins and lipids in there. Accordingly, it shouldn't come as a surprise that the tear film attenuates nothing close to 90% of far-UVC photons.</li></ul></li></ul></li><li>Most research on far-UVC eye safety has focused on the cornea. The conjunctiva (and its goblet cells) have been studied much less.&nbsp;<ul><li>Also, the cornea and conjunctiva are very tightly innervated and full of little nerves<ul><li>Maybe higher doses of far-UVC could induce unpleasant sensations by interacting with these nerves</li></ul></li><li>Ultimately we care about whether higher doses of far-UVC could have some effect on vision (acuity, contrast sensitivity)</li></ul></li></ul></li></ul><h2>Efficacy</h2><ul><li>There is no doubt that far-UVC can dramatically reduce the amount of airborne pathogens within a room (inactivation of ~98% of aerosolized bacteria within 5 minutes (Eadie et al. 2022))<ul><li><strong>Crucially, we don't know how well this translates into an actual reduction in total number of infections.</strong><ul><li>Of course, on priors, you would expect a reduction in the number of airborne pathogens to result in reduced infection risk. Yet the real world is messy and a lot could depend on air circulation in the specific environment, transmissibility of the pathogen, susceptibility of people etc.&nbsp;</li></ul></li><li>What is needed is a well-powered, carefully controlled real-world trial of far-UVC that uses the number of infections as the primary outcome. Many researchers in the field agree with this need.<ul><li>Only one such trial is currently&nbsp;<a href=\"https://classic.clinicaltrials.gov/ct2/show/NCT05084898\"><u>ongoing</u></a>, but more needs to be done</li><li>Unfortunately, epidemiological studies are 1) very expensive and 2) very hard to do well</li><li>We have a study proposal for a trial on offshore oil platforms (Message me if you know anyone working for an oil company or have a few million dollars to spare)</li></ul></li></ul></li><li>We believe that demonstrating efficacy in a real-world environment would be crucial to make more people excited about the promise of far-UVC and drive adoption in the future.<ul><li>It will be important that the first epidemiological studies are carefully controlled so that any effect of far-UVC can be clearly observed&nbsp;</li><li>The first real-world trials showing ambiguous results because of lackluster study design would probably be bad for far-UVC adoption<ul><li>People worry about this because it seems likely that this is what happened with epidemiological studies of upper-room GUV in the 1940s and 1950s<ul><li>The first epidemiological trials of upper-room GUV showed great results but subsequent similar trials were more ambiguous<ul><li>The design of trials that showed more ambiguous results has been criticized. While upper-room GUV was installed in school classrooms, the kids shared other indoor environments (e.g. the schoolbus) that weren't equipped with upper-room GUV. Presumably, infections just shifted away from classrooms to these other shared environments.&nbsp;</li></ul></li><li>It seems likely that this made people somewhat disillusioned with the technology and is part of the reason why upper-room GUV hasn't been more popular</li></ul></li></ul></li></ul></li><li>The development of standardized test methods for evaluating germicidal efficacy will be necessary for comparing different products and determining reasonable performance expectations in complex, real-world environments.</li></ul><h2>Indoor air chemistry</h2><ul><li>Throughout 2023, the most hotly debated topic within the far-UVC field has been the impact of far-UVC on indoor air chemistry<ul><li>This doc links to most (all?) relevant studies that have been published on this issue:&nbsp;<a href=\"http://bit.ly/guv-chem\"><u>http://bit.ly/guv-chem</u></a>&nbsp;</li></ul></li><li>Undoubtedly,&nbsp;<strong>far-UVC has a substantial impact on indoor air chemistry</strong> by producing ozone, which oxidizes volatile organic compounds in the air that can result in harmful products such as particulate matter<ul><li>The debate surrounds the question of how detrimental this is and existing studies seem to disagree somewhat to what extent this is a substantial issue</li><li>Importantly, little research has been done on methods to mitigate this issue.&nbsp;<ul><li>For example, using activated carbon filters to remove ozone, making sure far-UVC is used with sufficient ventilation to remove ozone or altering far-UVC fixture designs.&nbsp;</li></ul></li></ul></li><li>A lot of research here is ongoing and the issue is far from settled</li><li>This&nbsp;<i>might</i> turn out to be the bottleneck to what doses of far-UVC can be reasonably used, but I am really uncertain here.<ul><li>This hinges on what future research uncovers about mitigation strategies for this issue</li></ul></li></ul><h2>Adoption (real-world deployment)</h2><ul><li>Very few people have thought about how adoption of far-UVC could be driven and what a widespread deployment of the technology could look like<ul><li>Presumably, the vendors of far-UVC fixtures have business plans about how to increase demand, but they aren't approaching this question from a pandemic-preparedness perspective</li><li>One interesting deployment mode would be far-UVC fixtures with two modes: \u201cbusiness as usual\u201d mode and \u201cemergency\u201d mode<ul><li>In non-pandemic times, you would have the lamps running at exposure levels that pose a negligible or acceptable risk for the vast majority of the population</li><li>Once a pandemic threat is detected and infections are ramping up, the risk-benefit calculus changes and you could flip the switch to emergency mode for the lamps to run at substantially higher exposure levels<ul><li>Ideally, these emergency mode doses would be sufficient to reduce the transmission of a pathogen with measles-level infectivity below an R<sub>0</sub> of 1<ul><li>While there are some intuitions about this, we don't really know what exposure doses would be needed to achieve this. It would be great to see more modeling work done around this question.</li></ul></li><li>If it turns out that these higher doses are still reasonably safe for the skin, but pose a greater risk to the eyes, you could mandate wearing safety goggles in places where the far-UVC fixtures are running\u2014just like masks were mandated during Covid.&nbsp;<ul><li>In a severe bioterrorist attack, this could be a reasonable tradeoff</li></ul></li></ul></li><li>This would be great because you wouldn't need to go through the laborious retrofitting of buildings with e.g. better ventilation/filtration. Flipping a switch is much more simple.&nbsp;</li><li>Of course, far-UVC manufacturers aren't currently incentivized to do this. Why would you install a more powerful source (presumably at a higher cost), if that power isn't usually needed?<ul><li>On the other hand, I have heard that the sources in current far-UVC fixtures are already run at lower power to comply with exposure guidelines.&nbsp;</li></ul></li></ul></li><li>You could also imagine that far-UVC fixture designs incorporate ways to adapt the irradiance based on what is happening in the room. E.g., via monitoring noise and low-resolution infrared cameras.<ul><li>E.g., a lower irradiance is deployed if few people are in the room and no one is talking, but as soon as people move more closely together and start a conversation, the irradiance could be increased.</li></ul></li></ul></li><li>Trying to get a decent cost-benefit analysis for the widespread adoption of far-UVC seems worthwhile&nbsp;<ul><li>Including risks from ozone, volatile organic compounds, particulate matter, etc.</li><li>Also, modeling how useful far-UVC would be under different pandemic scenarios</li><li>I am not aware of any decently comprehensive cost-benefit analysis</li></ul></li></ul><h2>Regulation</h2><ul><li>So far, there is little to no regulation of far-UVC.&nbsp;<ul><li>There are broadly accepted exposure \u201cguidelines\u201d, but&nbsp;<strong>these are not standards (at least in the US).&nbsp;</strong></li><li>Exposure guidelines in the US are set by the American Conference of Governmental Industrial Hygienists (<a href=\"https://portal.acgih.org/s/store#/store/browse/detail/a154W00000DqsbCQAR\"><u>ACGIH</u></a>).&nbsp;<ul><li>ACGIH exposure guidelines for far-UVC were updated in 2022 and are substantially higher than in the rest of the world, where those of the International Commission on Non-Ionizing Radiation Protection (<a href=\"https://www.icnirp.org/\"><u>ICNIRP</u></a>) apply.</li></ul></li></ul></li><li>Another important player on the regulation side of far-UVC is the American Society of Heating, Refrigerating and Air-Conditioning Engineers (ASHRAE)<ul><li>ASHRAE develops technical standards (\u201cbuilding codes\u201d) that are very widely adopted and indicate things like the minimal amount of air changes per hour a building should have<ul><li>These are frequently turned into legislation by policymakers</li></ul></li><li>They recently developed a&nbsp;<a href=\"https://www.ashrae.org/about/news/2023/ashrae-publishes-standard-241-control-of-infectious-aerosols\"><u>new</u></a> standard on indoor pathogen mitigation (Standard 241P, Control of Infectious Aerosols).&nbsp;<ul><li>The standard was recently released. It doesn't mention far-UVC explicitly but talks about GUV in a few places.&nbsp;</li><li>Interestingly, the standard defines \u201c<i>the amount of equivalent clean airflow necessary to substantially reduce the risk of disease transmission during infection risk management mode.</i>\u201d<ul><li>AFAIK it is the first standard to use equivalent clean airflow (similar to equivalent air changes per hour) as the key metric.&nbsp;<strong>This is interesting because it is agnostic to what technology is used to achieve the necessary levels of equivalent clean airflow!</strong></li><li>As mentioned above, far-UVC can achieve much higher rates of equivalent air changes per hour than other technologies.</li><li>Accordingly, the standard might incentivize more use of far-UVC</li></ul></li><li>(I have only skimmed this standard, and my interpretation might be misguided)</li></ul></li></ul></li><li>In the US, (potential) regulation of far-UVC seems quite messy, as no authority has clear jurisdiction over it.<ul><li>If it is advertised as a medical device, the Food and Drug Administration would need to get involved</li><li>Since on a very broad definition it counts as a pesticide, the Environmental Protection Agency also has a word</li><li>The Centers for Disease Control and Prevention makes recommendations about disease transmission mitigation strategies and has recently started to mention far-UVC on their&nbsp;<a href=\"https://www.cdc.gov/coronavirus/2019-ncov/community/ventilation.html#faq-36966-question\"><u>website</u></a></li><li>Since far-UVC might pose a risk to workers, the Occupational Safety and Health Administration could regulate it</li></ul></li><li>I have heard that some of the US regulators noted above are becoming more interested in far-UVC. Clearer regulations/standards might emerge in the coming years.&nbsp;<ul><li>The White House is also interested in germicidal UV<ul><li>A 2022&nbsp;<a href=\"https://www.whitehouse.gov/ostp/news-updates/2022/10/18/the-2022-national-biodefense-strategy-builds-upon-administration-st-priorities-for-pandemic-preparedness/\"><u>report</u></a> by the White House Steering Committee for Pandemic Innovation of the National Science and Technology Council notes, \u201cExpand the use of GUV in priority congregate settings through research, test and evaluation, real-world demonstration projects, clear standards and guidance, and LED technology innovation.\u201d</li><li>There is also an ongoing White House&nbsp;<a href=\"https://www.whitehouse.gov/cleanindoorair/\"><u>challenge</u></a> focused on clean air in buildings that mentions conventional GUV</li><li>Apparently, the development of the indoor pathogen mitigation standard by ASHRAE was also motivated by interactions between the White House and ASHRAE</li></ul></li></ul></li><li>Standards and regulations developed by trusted entities like ASHRAE and UL serve as critical enablers of far-UVC.</li><li>Far-UVC manufacturers desperately want to see standardization but don't want to face annoying regulations<ul><li>They want standardization to gain trust and pull demand</li></ul></li></ul><hr><p>Let me know if you have any questions! Also, feel free to DM me if you want to chat about far-UVC and working in the field.&nbsp;</p><p><i>Big thanks to my colleague Lenni Justen with whom I arrived at many of these perspectives, and thanks to Vivian Belenky and Jasper G\u00f6tting for valuable discussions and inputs.</i></p>", "user": {"username": "MaxG"}}, {"_id": "u5serAwnrrFSJonoF", "title": "4 things GiveDirectly got right and wrong sending cash to flood survivors", "postedAt": "2023-07-31T14:33:57.296Z", "htmlBody": "<p>For Hassana in Kogi, Nigeria, October\u2019s floods were not like years past. \u201cAll our farmlands washed away as many had not yet harvested what they planted. The flooding continued until our homes and other things were destroyed. At this point we were running helter-skelter,\u201d she said.&nbsp;</p><p>These floods, the worst in a decade, result from predictable seasonal rains. If we can anticipate floods, we can also anticipate the action needed to help. So why does aid often take months (even <a href=\"https://socialprotection.org/discover/blog/shock-responsive-social-protection-mozambique\">up to a year</a>) to reach people like Hassana? Traditional humanitarian <a href=\"https://executiveboard.wfp.org/document_download/WFP-0000138209\">processes</a> can be slow and cumbersome, government and aid agencies often lack the capacity and money to respond, and most aid is delivered in person, an added challenge when infrastructure is damaged.&nbsp;</p><p>Digital cash transfers can avoid these issues, and getting them to work in a disaster setting means more people will <a href=\"https://www.givedirectly.org/climate-funding/#:~:text=In%20some%20cases%2C%20we%20can%20send%20them%20money%20before%20disasters%20strike\">survive climate change</a>. In the past year, with support from <a href=\"https://www.google.org/\">Google.org</a>, GiveDirectly ran pilots to send cash remotely to flood survivors: in Nigeria, we sent funds to survivors weeks after flooding and in Mozambique, we sent funds days <i>before</i> predicted floods. Below, we outline what worked, what didn\u2019t, and how you can help for next time.</p><p>Over 1.5B people in low and middle income countries are threatened by extreme floods. <a href=\"https://www.givedirectly.org/climate-funding/#:~:text=Evidence%20shows%20giving%20them%20cash%20directly%20without%20conditions%20lets%20them%20both%20meet%20their%20immediate%20needs%20and%20rebuild%20their%20lives.\">Evidence shows</a> giving them unconditional cash during a crisis lets them meet their immediate needs and rebuild their lives. However, operating in countries with limited infrastructure during severe weather events is complicated, so we ran two pilots to test and learn (see <a href=\"https://www.givedirectly.org/flood-pilots/#design\">Appendix</a>):&nbsp;</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/u5serAwnrrFSJonoF/sjolcrlocdobzo1q5fgr\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/u5serAwnrrFSJonoF/lvqpdzfjmcouuntjhyxx 260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/u5serAwnrrFSJonoF/bcuwp8cs17xpd9bnpjh5 520w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/u5serAwnrrFSJonoF/dgmb0uvw6q2llvdgjel4 780w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/u5serAwnrrFSJonoF/hq7t4eeueetm2o9whvtc 1040w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/u5serAwnrrFSJonoF/dbhajmkjjgh547jhjq4f 1300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/u5serAwnrrFSJonoF/vnqqvqanrscszfjl6qrk 1560w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/u5serAwnrrFSJonoF/wolahs8f3srmtvpz0wlz 1820w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/u5serAwnrrFSJonoF/vgbdyxhkaxiuxqdiorip 2080w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/u5serAwnrrFSJonoF/qthd0tjnc223mv4tsckl 2340w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/u5serAwnrrFSJonoF/ec1z1xpuw1gzqi6lgg1h 2538w\"></figure><h2><strong>What went right and what went wrong</strong></h2><p>Innovating in the face of climate change requires a <a href=\"https://www.circlesofclimate.org/wp-content/uploads/2015/08/No-Regrets-Charter-2015.pdf\">\u2018no regrets\u2019 strategy</a>, accepting a degree of uncertainty in order to act early to prevent suffering. In that spirit, we\u2019re laying out what worked and did not:</p><p><strong>\u2705 Designing with community input meant our program worked better</strong></p><p>A cash program only works if recipients can easily access the money. In Nigeria, we customized our program design based on dozens of community member interviews:</p><ul><li>\ud83d\udc42<strong>Use the local dialect: </strong>There are 500+ dialects spoken in Nigeria, and our interviews determined a relatively uncommon one, Egbura Koto, was most widely used in the villages we were targeting. We hired field staff who spoke Egbura Koto, which made the program easier to access and more credible to community members, with one saying, \u201cI didn\u2019t believe the program at first when my husband told me but when I got a call from GiveDirectly and someone spoke in my language, I started believing.\u201d</li><li>\ud83d\udcf1<strong>Promote mobile money:</strong> Only 10% of Nigerians have a mobile money account (compared to 90% of Kenya), so we planned to text recipients instructions to create one and provide a hotline for assistance. But would they struggle to set up the new technology? Our interviews found most households had at least one technologically savvy member, and younger residents often helped their older or less literate neighbors read texts, so we proceeded with our design. In the end, 94% of surveyed recipients found the mobile money cash out process \u201ceasy.\u201d</li><li>\ud83d\udcb5 <strong>Send cash promptly:</strong> Cash is most useful where markets are functioning, so should we delay sending payments until floods recede if it means more shops will be reopened? In our interviews, residents explained the nearby Lokoja and Koton-Karfe markets functioned throughout flooding and could be reached in 10 minutes by boat. We decided not to design in a delay and found the nearby markets were, in fact, open during peak flooding.</li></ul><p><strong>\u274c We didn\u2019t send payments before severe floods</strong></p><p>In Mozambique, we attempted to pay people days ahead of severe floods based on data from <a href=\"https://sites.research.google/floodforecasting/\">Google Research\u2019s Flood Forecasting Initiative</a>, using a model validated on the only available data source: 50 years of government river level measurements. During Cyclone Freddy\u2019s second landfall, our forecasts predicted river levels would rise to dangerous levels in the region, so we sent anticipatory $225 transfers to 4,183 people across 11 villages, aiming to help families prepare.&nbsp;</p><p>Ultimately, severe floods never came in the villages we paid, though some un-enrolled villages in nearby areas were flooded as Cyclone Freddy was the most significant of the season. Though we couldn\u2019t respond in villages hit the hardest, we still paid people who are consistently vulnerable to climate disasters: 90% of people who received this payment had survived a significant flood in the prior year.</p><p>In the future, we need more flexibility on where to respond and to incorporate more than one trigger from forecasts to make sure we respond at the right time and where floods are most severe. In addition to overflowing rivers, floods are also caused by rain (flash floods), which are hard to predict on a village level, and certain villages are more likely to flood than their neighbors due to subtle geographic differences. In post-pilot conversations, these communities also told us they\u2019d need payments more than several days ahead of a flood event to fully utilize the cash and prepare.</p><p>As we scale up anticipatory action, we\u2019ll continue working with Google Research, local communities, and experts to:</p><ul><li><strong>Factor in more predictors</strong> to better weigh overall probability of a major flood event, and ensure we respond in advance&nbsp;</li><li><strong>Integrate local data</strong> to further optimize our triggers for different regions, such as by learning more from communities\u2019 past experiences with floods&nbsp;</li><li><strong>Target a larger area </strong>to ensure we have more flexibility to respond in whichever villages are most at risk for the type of impending flood&nbsp;</li><li><strong>Send payments even earlier</strong>, 4-5 days before a major flood event, so people have more time to prepare&nbsp;</li></ul><p><strong>\u274c Limited pre-enrollment meant we lacked flexibility to respond to the worst floods</strong></p><p>When Cyclone Freddy approached Mozambique, we could tell it would likely hit hardest far north of where we\u2019d pre-enrolled villages \u2013 but we couldn\u2019t pivot and pay the villages that were clearly about to experience the worst floods. Though we had more luck in Nigeria predicting where floods would hit, we accepted some uncertainty with our village selection. This lack of flexibility was a major limitation, but our budget limited us to only pre-enrolling a relatively small area.&nbsp;</p><p>A larger potential payment area means a more responsive program. There are two ways we can improve, each with its own trade-off:&nbsp;</p><ol><li><strong>Remotely enroll and pay based on storm path, excluding people without phones: </strong>We could use real-time mobile phone data or disaster registries to contact people in a storm\u2019s path, enrolling and paying them fully remotely. This would give us more geographic flexibility for a lower cost, but we\u2019d only reach people who already use mobile phones. Fewer than 40-60% of rural Mozambique has a SIM card, so this would likely mean excluding the poorest half of impacted families.&nbsp;</li><li><strong>Manually pre-enroll more villages, reaching fewer people</strong>: In our Mozambique pilot, we held in-person SIM card and mobile money registration drives to reduce how many people were excluded. However, scaling this up to pre-enroll a larger area would require hiring more staff, reducing the overall program efficiency and therefore reaching fewer people.</li></ol><p><strong>&nbsp;\u2705 Ultimately, people in poverty affected by floods got money</strong></p><p>One reason for our \u2018no regrets\u2019 principle is that any money put in the hands of people in extreme poverty is a good thing. Nearly all of the families in Mozambique paid ahead of March\u2019s forecasted river floods that never came had suffered from other flooding in the prior year and used the funds to improve their resilience. Across both countries, we delivered $3M to 13,782 families impacted by both flooding and poverty, which they spent on things like agricultural inputs to restore damaged cropland, evacuation to safer areas, food and essential goods, and home repairs/improvements (see <a href=\"https://www.givedirectly.org/flood-pilots/#recipients\">Appendix</a>)</p><h2><strong>Without your support, we cannot try again</strong></h2><p>Our Google.org-funded pilots prove it\u2019s possible to quickly send cash aid to flood survivors in extreme poverty. We already have actionable ways to improve our flexibility, accuracy, and speed next time. But in typical humanitarian grantmaking, funding is only released <i>after</i> a flood happens, which leaves little room to innovate. We need more donors committed to giving funds for climate survivors <i>before</i> the crisis hits. <a href=\"https://www.givedirectly.org/relief/\">Support innovation before the next disaster.</a></p><p>As the <a href=\"https://www.nytimes.com/2023/07/03/climate/cash-disaster-relief.html?unlocked_article_code=hJfSPWq0dpGVRrWkBVOeou82bOCmuUmeYC95FUZqn7hb6ByPXrUsEHZPBgBpAc_z4-qBXIq3dv0vHWREaSKucI9No9C580dH4y0rA7YxpDM3weAY9PjdwfF5AZ917-J30qGy58O63mw5JRk2Y2QJ09kteTprebo-IDlXL7NJoXZWY4kRMFUy3djVzvUzRfWQVkh4somHq7Osgce9_2AQcNG7zRiquiSPjopTiF4AHsogXW2rJh5VJqsPURKXtAxmJ6x7FauM14Cq2CKmmdRqRgXUPcx0dbAzTEbsKM7tESu46DS3fjtdceWOPx2jdyrrrf1DSFKo-dKAZC4GuoE&amp;smid=url-share\">New York Times observed</a>, bringing our work to scale could change how billions of dollars in loss and damage climate funding is spent. What works for 10,000 people could soon reach millions.</p>", "user": {"username": "givedirectly"}}, {"_id": "yKWGkcuke577ReBPW", "title": "You Can Also Help Animals By Earning (More) in Other Career Paths and Donating ", "postedAt": "2023-07-31T11:38:23.441Z", "htmlBody": "<h2>\u201cAnimal Advocacy Careers\u201d do not need to be only careers in animal advocacy organisations</h2><p><i>This is the first piece of </i><a href=\"https://animaladvocacycareers.org\"><i>AAC</i></a><i>'s new \u201cImpactful Animal Advocacy Career Paths\u201d series (more posts coming soon).</i></p><p>Animal advocacy organisations play a vital role in creating a compassionate world for animals, but they face significant challenges in securing adequate funding. Almost all organisations need financial support in order to sustain and expand their programs. Many of these organisations are funding constrained.&nbsp;</p><p><strong>Providing these resources creates an essential, indirect yet major impact for animals through empowering the organisations helping them.</strong></p><h1>Why Donations For Animals Are Crucial</h1><p>Almost every advocacy organisation would like to:</p><ul><li>hire more staff who would work on important tasks,&nbsp;</li><li>create more advertisements that would raise awareness about animal rights,&nbsp;</li><li>start more programs to grow and strengthen the movement.</li></ul><p>None of these things are free.&nbsp;</p><p>It is simply unrealistic and unfair to expect individuals to selflessly work for animals without any compensation. It is also hard to attract skilled, and competent individuals to work on animal advocacy without decent salaries.</p><p>There are 3 main problems limiting our progress in putting an end to animal suffering:</p><h2>Lack of funding in nonprofits</h2><p><strong>Animal advocacy organisations&nbsp;</strong><a href=\"https://www.animaladvocacycareers.org/post/animal-advocacy-bottlenecks\"><strong><u>listed</u></strong></a><strong> a lack of funding as the single most important thing that limited their organisations impact.</strong></p><p>For these reasons, organisations require extensive and stable funding.</p><p>Unless animal nonprofits are adequately resourced, they cannot create meaningful impact for animals. While some organisations also earn money by selling merchandise or event tickets, they simply cannot function like a for profit company.&nbsp;</p><p>Nonprofits primarily depend on donations to cover their expenses.&nbsp;</p><h2>Uneven distribution of funding</h2><p>The problem is not just the limited amount of money in the animal advocacy space, it is also about how the funds are shared and distributed.</p><p>Farmed and wild animal welfare organisations receive significantly fewer donations compared to organisations working on companion animals, animals used in labs, and captive animals. Yet, the number and suffering of farmed and wild animals are much higher than these other groups.</p><p>Farmed and wild animal advocacy is relatively more neglected than other animal advocacy fields, in terms of both public attention and funding.&nbsp;</p><p>While \u201c<a href=\"https://animalcharityevaluators.org/donation-advice/why-farmed-animals/#fn1-1-1222\"><u>for every one dog or cat euthanized in a shelter, 3,400 farmed land animals are confined and slaughtered</u></a>\u201d,&nbsp;<strong>farmed and wild animal organisations receive about %1 of total donations to animal charities&nbsp;</strong>(which also include shelters, organisations that focus on companion animals, etc.).&nbsp;</p><p><a href=\"https://animalcharityevaluators.org/donation-advice/why-farmed-animals/#fn1-1-1222\"><u><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/yKWGkcuke577ReBPW/nvmeufz193jjnnm7v5cp\"></u></a></p><p><a href=\"https://animalcharityevaluators.org/donation-advice/why-farmed-animals/#fn1-1-1222\"><i><u>Graphic by Animal Charity Evaluators</u></i></a></p><h2>Struggling Against Powerful Institutions</h2><p>Finally, the institutions that these organisations are struggling against are extremely powerful. The annual donations to farmed and wild animal advocacy organisations is approximately 200 million dollars.&nbsp;</p><p>Animal agriculture industry, on the other hand, is a billions of dollars worth industry where tens of thousands people work each day.</p><p><strong>The animal advocacy movement, farmed and wild animal advocacy in particular is miniscule in terms of financial power compared to the institutions it is positioned against.&nbsp;</strong></p><p>When animal welfare organisations stage campaigns against corporations like McDonalds or Kroeger in order to achieve institutional welfare reforms, they struggle against organisations that have hundreds, even thousands times more financial resources than they do.&nbsp;</p><h3>Is Alt Protein the Solution? Exploring Ambitions and Challenges</h3><p>The alternative protein sector has much more investment and market capitalisation than animal charities, due to its profit prospects. But it is also much smaller than the animal agriculture sector that it aims to substitute.&nbsp;</p><p>We need to develop new technologies to produce food that is as tasty and cheap as animal products, which is not an easy task. We also need to change consumer attitudes and behaviour towards animal products, which is also very difficult.</p><p>All these things require vast amounts of resources that need to be used in areas like research and development, management, and marketing.&nbsp;</p><h1>Earning to Give: How Does Earning to Donate to Animal Charities Work?&nbsp;</h1><p><strong>The idea is simple: earn money, save some, and donate to animal advocacy organisations.</strong>&nbsp;</p><p>We understand that not everyone can choose this option due to family responsibilities or limited opportunities for higher salaries. However, we believe it could be a practical and impactful choice for many advocates, contributing to reducing animal suffering.&nbsp;</p><h2>Step one: Discovering a Career with Adequate Income</h2><p><strong>Assess the salaries in different sectors, occupations, and companies.&nbsp;</strong></p><p>Certain sectors, occupations, and companies pay significantly higher, particularly for senior positions, and especially in certain countries that have higher GDP per capita.&nbsp;</p><p>For example: jobs in finance, traders, surgents, programmers, managers, and successful startup founders typically have higher incomes, especially in developed countries.&nbsp;</p><p>Of course, these are challenging.</p><p>It is not an easy task to graduate from a difficult program, get a job in a major company and move up in the corporate career ladder. But if you can overcome these challenges and reach a position of financial power, you can use this power (i. e. your high income) for the good of the animals.&nbsp;</p><p>Another important factor to consider is your personal fit. You'll do well in a job when you have the right skills and preferences that align with the occupation. Success comes when you're good at what you do.</p><p>For example, even if trading in a big bank is potentially impactful due to its high pay, it is not necessarily the best career path for you. This may be because you do not have the necessary skills or you simply do not like that work to start with. On the other hand, if you are really passionate about something, and excel at it, you can still earn a lot (even more than the options that \u201con average\u201d pay better), even if most people in that sector or occupation do not.&nbsp;</p><p>You might also have other goals than helping animals, which is totally legitimate. In those cases, it may be reasonable to choose from options that fit you better. For example, if you have a passion for academia, arts, or a certain trade, these may still be the best path for you.&nbsp;</p><p>Putting aside exceptions, you should be open minded and well informed in order to assess the potential income levels of different job opportunities, and your fitness for these roles.&nbsp;</p><p>Some occupations may appear more rewarding than they seem at first glance, and with time, most people can develop new skills and preferences that make them well-suited for these career paths too.</p><h2>Step two: Save Money</h2><p>The second stage of this approach is, of course, saving the money. You can set targets like %1 or %10 or %50 of your earnings, depending on what you make and your needs. This can be done by cutting unnecessary spending like luxury items, or opting for more affordable choices.</p><p>&nbsp;</p><p><strong>We are not advising that you should be extremely frugal, because that may not be sustainable.</strong>&nbsp;</p><p>Your biggest impact will likely come in the long term, likely as a result of your higher earnings as you progress in your career, and not as a result of how much you save by cutting back on your consumption.</p><p>&nbsp;</p><p><strong>Focusing too much on small savings for donations might take a toll on your mental well-being. Instead, concentrate on advancing in your career, which can lead to much bigger contributions.</strong></p><p>Fanatically thinking about the potential impact of an additional small donation that can be done by not buying a cup of coffee and using that money to donate, can disturb your mental health and distract you from more impactful actions like progressing in your career that may allow you to earn much more than the price of a cup of coffee.&nbsp;</p><p>&nbsp;</p><p><strong>It is also helpful to have a long term view of your financial situation.&nbsp;</strong></p><p>For example, buying a house (or getting a mortgage) may increase your expenses and leave less for donations for some time. But in the long run, this type of investment (if done well) may allow you to be more generous, since it increases your overall wealth and relieves you from paying rent.&nbsp;</p><p>Another example might be to use some of your savings for starting a business or simply for skilling up or taking&nbsp; some time off to prepare and focus on your job search and applications. These may increase your expenses and decrease your donations in the short term, but may very well increase your income and donations in the long run.&nbsp;</p><h2>Step three: Choose Which Organisations to Donate To</h2><p>When people decide to donate to animal charities, they often search for the best animal charity to donate to. There\u2019s no single best answer. You can choose from two options here.&nbsp;</p><h3>Option one: Donate to funds</h3><p>You can choose to donate to funds managed by people who claim to have experience and expertise in assessing organisations. These funds pool various donations and then make grants to individual organisations.</p><p>This is a reasonable approach if you don\u2019t have the time and knowledge to research into different organisations and explore the potential impact of your donations, and you generally agree with the grant making strategy of the fund (and its managers).&nbsp;&nbsp;</p><h3>Option two: Donate to animal charities directly</h3><p>&nbsp;This is the best approach for you if:</p><ol><li>You have the time and knowledge to research into the tactics of various organisations and understand the potential impact of your donations, and&nbsp;</li><li>You have a different viewpoint(s) than these funds (and its managers) about the value of different types of advocacy work (We intend to publish resources on how one might do this in the future).&nbsp;</li></ol><p>Regardless of which option you choose, deciding which organisation (or funds) you donate to is very important. This will determine the majority of the impact of your donation.</p><p>For example, you could donate to organisations who are helping individual animals, which is great. But you could also seek a potentially broader impact, such as donating to organisations who are advocating for policies that positively affect thousands of animals.In the end it\u2019s up to you, but it\u2019s important to identify the organisations whose tactics align best with your vision of creating impact.</p><h1>Empowering Progress: How Donors Drive Change in Animal Advocacy Organisation</h1><p><strong>There has been great progress in terms of financially empowering animal advocacy organisations over the past decades.&nbsp;</strong></p><p>In the past, most organisations primarily relied on volunteer work, which limited their potential and created fragilities. Today, while funding-constraints are still a big issue, there are many animal advocacy organisations worldwide that can employ numerous full-time staff with adequate pay. This lets organisations hire and keep skilled people for challenging projects and campaigns.</p><p>This progress happened thanks to large and small donors. Large donors like&nbsp;<a href=\"https://www.openphilanthropy.org/focus/farm-animal-welfare/\"><u>Open Philanthropy</u></a>, which is primarily supported by Dustin Muskovitz (co-founder of Facebook and Asana) and Cari Tuna, annually provide more than 8-digit grants to various organisations. Funds to which thousands of donors pool their donations, also annually provide grants which amount to millions of US dollars. Farmed Animal Funders is another community of large donors who aim to impact farmed animals.&nbsp;</p><p><a href=\"https://www.givingwhatwecan.org/\"><u>Giving What We Can</u></a> community, is a good example of how ordinary donors can collectively make an impact using their donations. This is a community of individuals who pledge to give at least 10% of their income to \u201corganisations that can most effectively use the donations to improve the lives of others\u201d. To this day, the Giving What We Can community has donated more than 100 million dollars in total to both humanitarian and animal charities.&nbsp;</p><p>There are also many anonymous donors who are essential for the success of the organisations they support</p><p>Supporters of farmed and wild animal welfare have managed to maintain their donations over time. The level of donations is either increasing or remaining stable each year.&nbsp;</p><p>Thanks to these efforts, there are now hundreds of advocates worldwide who are working to help animals as their job.&nbsp;</p><p><strong>This financial support is one of the main reasons why in the past two decades farmed animal advocates achieved tangible results like corporate animal welfare reforms, and the growth of the alternative protein sector.&nbsp;</strong></p><p>Without adequate funding, these wins probably wouldn\u2019t have happened.&nbsp;</p><h1>Upsides: The Power of Donating to Help Animals</h1><h2>High impact</h2><p><strong>As explained above, the need for more financial support is very high in the animal advocacy movement and every donation would help organisations to sustain and expand their work.&nbsp;</strong></p><p>You can calculate your impact by comparing the impact of an organisation (such as number of animals impacted, welfare gains, expected progress in the future) and the expenses of the programs that deliver these impacts (such as salaries, necessary equipment, office rents, advertisements, etc.).&nbsp;</p><p>You can then compare your donation amount to these costs, which at the end allow the organisations to deliver impact for animals.&nbsp;</p><h3>Practical scenario:</h3><p><strong>Let\u2019s imagine that you get a very high paying job: software engineering at Google.&nbsp;</strong></p><p>You can earn approximately 250.000 US dollars (or even more) annually if you achieve this. Since this is a lot of money, you can cover your expenses very easily with even half of this amount. Imagine that you decide to donate 50% of this amount each year. 125.000 US dollars annually may cover 2-3 full time staff of an animal advocacy NGO in developed countries (4-7 staff in developing countries).&nbsp;</p><p><strong>You would probably impact more animals by following this approach than directly working in a software development role in an animal charity.&nbsp;</strong></p><h3>Replaceability</h3><p><strong>Note that, the real difference of directly working in animal charities, instead of earning and donating, boils down to your \u201creplaceability\u201d</strong>.&nbsp;</p><p>If there are other people who have similar skills, experience and motivation as you, organisations can easily hire them as well, and your impact via your direct work in these organisations can be replaced. Under these circumstances, your counterfactually adjusted impact would not be that high if you choose direct work in animal charities.&nbsp;</p><p>On the other hand, we believe that a lot of people also underrate their capabilities for direct work as well - so they may very well not be that replaceable. And a lot of animal charities report that they are also talent-constraint as well as funding-constraint. More on that below.</p><h2>Flexibility</h2><p><strong>As a donor, you have the option to have a portfolio of organisations that you support. This way, you can support a wider range of advocacy activities.&nbsp;</strong></p><p>If you happen to change your mind about an organisation, you can choose to donate to another organisation as you see fit.&nbsp;</p><p>This flexibility does not exist in direct work career paths. You can\u2019t work in multiple organisations at the same time. Some part time work opportunities exist but it is unlikely that you can simultaneously work in more than three organisations. You can\u2019t also quit one job in one kind of advocacy approach one day and get another job in another organisation the other day.&nbsp;</p><h3>The importance of recurring donations</h3><p>But note that, while exercising some flexibility is fine, donating without any predictability and stability would limit the impact of your donations.&nbsp;</p><p>Organisations can use donations in the best way when they can make long term plans (like hiring a permanent additional staff). They can only do that if they can count on the continuous support of their donors. If not, they can only use money for short term projects since they can\u2019t be sure about the long term.&nbsp;</p><p>For that reason, making recurring donations and establishing some form of donor loyalty with the organisations is on balance much more impactful than donating one off sums each year without any pattern.&nbsp;</p><h2>Wide range of opportunities</h2><h3>Limitations to direct work at animal advocacy nonprofits</h3><p>Direct work in animal advocacy organisations is hard, and everyone may not be fit for these roles (although we believe that a lot of people also underestimate their fitness for these roles too).&nbsp;</p><ul><li>Some may lack the necessary skills and credentials.&nbsp;</li><li>Some may find it difficult to adapt to the culture and workload of certain organisations.&nbsp;</li><li>Some may find it stressful to indefinitely commit to activism.&nbsp;</li><li>Some may be uncomfortable with uncertainties or financial risks associated with direct animal advocacy.&nbsp;</li></ul><p>So while we think that more people should seriously consider doing direct animal advocacy work in animal charities, research institutions or alternative protein companies, we are still aware that these options do not fit well for a lot of people.&nbsp;</p><p>In addition to these limitations, there are relatively few opportunities in the existing impactful organisations. Some major organisations in the animal advocacy space employ about 100 people but typical farmed animal advocacy organisations employ around 10-20 people.&nbsp;</p><p>The alternative protein sector is relatively larger in terms of employment opportunities, but even these are generally smaller in comparison to other for-profit companies. Barring some exceptions, research, community building and other types of organisations also typically employ less than 20 people (our own organisation currently has a team of 5 people).&nbsp;</p><p>And as you can imagine, the demand for working in these organisations is high and most hiring rounds are generally very competitive.&nbsp;</p><h3>Advantages of pursuing other career paths to donate for the animals</h3><p><strong>However making an impact by structuring your career to make more and better donations, is not affected by these limitations.&nbsp;</strong></p><p>You can pretty much work in any sector or field, earn money, save some for giving and select effective organisations for your donations. For this reason, there is a wide range of opportunities for work. And in almost all sectors, if you work hard and succeed, you can earn much more as you progress in your career. These earnings can later be used for even more generous donations.&nbsp;</p><h2>Career capital</h2><p><strong>An important advantage of working in fields and institutions that are not doing direct animal advocacy work, is being able to develop skills and credentials.&nbsp;</strong></p><p>These can be later used in your career even if you decide to switch to direct work for animals in advocacy organisations.&nbsp;</p><p>For example, if you take a management career track in a for-profit sector, you would be likely to learn management skills and competencies which can also be used in advocacy organisations if you decide that you want to transition to work at these organisations. Similar dynamics also play in academia, marketing, operations, policy, etc.&nbsp;</p><p>You can safely develop these skills in your field of choice, <i>and</i> impact a lot of animals with your donations.&nbsp;</p><p>Additionally, training is relatively resource intensive, so many animal advocacy organisations are not able to afford to provide the same quality of training as other sectors, and using external resources to upskill and train also saves the animal movement money.&nbsp;</p><p>Also, having a list of credentials and decent savings can also allow you to be more risk tolerant in the future. At that point, you can more easily consider options for more radical career changes like founding a new animal charity, or writing a book, or moving to another country or a region to work in another animal advocacy organisation, or trying something completely new.&nbsp;</p><h2>Personal welfare</h2><p><strong>While other career paths in animal advocacy can be impactful and fulfilling, they can also be financially less rewarding, involve career risks and can be seen as less valuable by your peers and family members.</strong>&nbsp;</p><p>On the other hand, this approach is not affected by these downsides and risks. By taking this career path, you can pretty much continue as you would in your default option, and still create a lot of impact for animals.&nbsp;</p><p>If successful, you can achieve your other personal career goals, earn and save decent amounts of money, and satisfy the expectations of your peers and family members (if this is an important issue for you).&nbsp;</p><p>This career path is also flexible. You can manage the amount of your donations depending on your current and future financial earnings, needs and expectations. While it might be much harder to take a career break or transition from direct animal advocacy work, it is very easy to make adjustments in this career path.&nbsp;</p><p>For example, if you need a break, you can transition to a less demanding role with a more modest pay. If you need or want to spend more on yourself or your loved ones, you can lower your donations for some time. These would, of course, affect your impact but would probably not drastically affect your daily life and personal welfare. And you can always compensate for these downfalls by donating more in the future.&nbsp;</p><h1>Navigating Uncertainties and Risks: Donating for Animals with Awareness</h1><h2>Uncertainties about impact</h2><ul><li><strong>While this path seems straightforward, its impact rests primarily on your judgement about the effectiveness of the organisations you are donating to.</strong>&nbsp;</li></ul><p>If these organisations are less impactful than you believed them to be, due to lack of information or the uncertainties around their interventions, then the impact of your donations can be lower.&nbsp;</p><ul><li><strong>Just \u201caiming\u201d to earn more in order to donate more does not immediately guarantee that you will succeed in earning more.</strong>&nbsp;</li></ul><p>There will be professional challenges that inevitably involve uncertainties about your chances of succeeding in moving up in your career path. It may also be difficult to save money due to the expenses related to social expectations of your professional setting, like living in a prestigious neighbourhood, driving an expensive car, and wearing luxurious clothes, etc.&nbsp;</p><ul><li><strong>The impact of this career path is also dependent on your commitment to continue your donations too.</strong></li></ul><p>Not only it may be hard to simply earn money, it may also be tempting to discontinue donating large amounts of money to charity after some time and use that money for your own pleasures and needs.&nbsp;</p><ul><li><strong>In order to have a high impact in this career path, you should be cool with donating more than socially acceptable or conventional.&nbsp;</strong></li></ul><p>A lot of people find it odd to donate a significant portion of their income (like 10%) to charity.</p><p>Although there will always be a lot of people (especially the organisations that you support) who support and appreciate your generosity, there will also be some people, including people who you are close with, who will disapprove and criticise your choices. This may create discouragement over time and might lead to lower donations. (But note that these instances of disapproval and criticism to your career choices would probably be even higher if you choose to work directly in an animal advocacy organisation).&nbsp;</p><p><i>A lot of donors start with very high motivation and commitment but some lose their motivation and commitment over time and thus their impact is not as significant as they planned at the beginning.&nbsp;&nbsp;</i></p><ul><li><strong>Impact of the work you\u2019re doing to earn money:</strong>&nbsp;</li></ul><p>If the activities involved in earning money for donations are harmful (e.g., working for a tobacco company or a fraudulent crypto currency exchange), it may raise ethical concerns about supporting animal advocacy through such means. This act may help animals, but it would be at the expense of people who are harmed in this process. Making good moral judgments about the impact of the job you are paid for is crucial in this approach.</p><p>This is especially important for the \u201coptimising\u201d strategy where you pursue the highest paying career opportunities.&nbsp;<strong>Narrowly and shortsightedly optimising for the highest paying job or position may end up being in a place where one makes shady businesses, or exploiting workers and customers.&nbsp;</strong></p><p>While it is more likely than not that most high paying jobs are legitimate and legal, there may be cases where these are illegitimate and even illegal. We clearly advise not to take these paths, even if it might increase your donation amounts.&nbsp;</p><h2>Uncertainties about opportunity costs</h2><p><strong>Even if your donations are effective and legitimate, it may be the case that you are taking a suboptimal career path because other career options may be more impactful</strong>.&nbsp;</p><p>For example, even if you are donating 5-digit or even 6-digit amounts annually, the value that you might create for animals may still be higher if your talents and skills are more suitable and needed in animal advocacy organisations. This may also be true for high-earning careers too.&nbsp;</p><p>If you work as a manager in a financial institution, it is more likely than not that your skills, experience, and competencies may well create a lot of impact in an organisation.&nbsp;</p><p><i>Andres Jimenez Zorrilla, for instance, was working in a high paying position in finance and real estate sectors, before he co-founded the&nbsp;</i><a href=\"https://www.shrimpwelfareproject.org/team\"><i><u>Shrimp Welfare Project</u></i></a><i> with his co-founder Aaron Boddy. Even if he was to donate a portion of his earnings to various effective organisations, it would have been unlikely that the impact of his donations is greater than the impact of the foundation of a high impact organisation.&nbsp;</i></p><p><strong>So when considering the impact of your donations, don\u2019t do this&nbsp; in isolation.this judgement is better made in comparison with other options, including direct work in advocacy organisations.&nbsp;</strong></p><p>A helpful question to ask is: would organisations prefer me to donate a certain amount of money each year, or would they rather have me work for them? If you believe your skills are better than others and you can make modest donations, direct work may be a better approach.</p><h3>Organisations are also constrained for talent</h3><p>A lot of animal advocacy organisations also report that talent constraints are more serious than funding constraints, especially for roles that are harder to hire. A lot of advocates also underrate their potential at direct work in animal advocacy organisations. So don\u2019t just write off direct work by just looking at your donation opportunities.</p><h2>Personal downsides</h2><p>While it may be more convenient for most people to stay in their \u201cnormal\u201d career path, or to generally aim for high-paying positions, this may also be unsatisfying or even highly stressful for some.&nbsp;</p><p>Doing direct advocacy work in organisations may be significantly more fulfilling than doing work that you don\u2019t enjoy doing, even if this may allow you to donate lots of money. This may be even worse if you optimise to get the highest-paying work.&nbsp;</p><p>These sectors and positions typically come with huge responsibilities and workloads which are usually very demanding.&nbsp;</p><p>For these reasons, we suggest that you seriously evaluate your personal fitness before making career decisions. While our general information and advice on career paths and strategies may apply for some cases, it may work out very differently for individuals who have diverse views on animal ethics, social change and have different personal goals, traits, and talents.</p><p>&nbsp;</p><p><strong>On average though, we believe that this career path is less uncertain and risky compared to other career paths.&nbsp;</strong></p><p>People who are less comfortable with uncertainty and risks may find this career path more suitable for them.&nbsp;</p><p>&nbsp;</p><p><strong>On the other hand, the upward impact potential of this approach may be relatively lower than other career paths for most people.&nbsp;</strong></p><p>Advocates in crucial positions in advocacy organisations can have a tremendous impact and make a huge difference if they can perform well. For this reason, you should also be open-minded about taking more risks and assessing possibilities in direct advocacy work.&nbsp;</p><p>Finally, remember that these considerations would mainly depend on your personal fitness and career options. So we highly recommend that before making any drastic decision,&nbsp;you&nbsp;seriously consider your own conditions and values, rather than acting based on our content alone.</p><p>&nbsp;</p><p><strong>If you\u2019ve read this and think you can benefit from more information and guidance about your career options and donation opportunities, we are offering a small number of 1:1 career advising calls.&nbsp;</strong></p><p>You can fill in this&nbsp;<a href=\"https://docs.google.com/forms/d/e/1FAIpQLScGT8BY5aKIEwoot1pzkaNGIfpZvcrvEjNR5NAtOC93E_Jh0w/viewform\"><u>form</u></a> to apply for career advising. Please note we have limited capacity and might not be able to offer you a call.</p><p>We are also considering starting an initiative for increasing the number of people who pledge to donate a certain percentage of their income to impactful animal charities. If you are interested in this, we would love to hear from you so we can understand how much potential room for growth exists in this area and what would be our potential impact.If you\u2019re interested in joining, please email lauren@animaladvocacycareers.org.</p>", "user": {"username": "Animal Advocacy Careers"}}, {"_id": "JthPLyb5tjcY6jmdd", "title": "Apply Now: EAGxPhilippines in October", "postedAt": "2023-07-31T08:59:29.757Z", "htmlBody": "<h1>TL;DR:&nbsp;<a href=\"https://www.effectivealtruism.org/ea-global/events/eagxphilippines-2023\">Applications</a> are now open for EAGxPhilippines happening on October 20-22, 2023 in Manila \ud83c\uddf5\ud83c\udded \ud83e\udde1</h1><p>&nbsp;</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JthPLyb5tjcY6jmdd/fpgxbbjckfmfm8bkl9ic\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JthPLyb5tjcY6jmdd/lfharx2wbj5zehm6edo1 115w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JthPLyb5tjcY6jmdd/ggwr4k1zlj5tdvnaqvjy 195w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JthPLyb5tjcY6jmdd/azfg6ag9x6sloa5zzwuj 275w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JthPLyb5tjcY6jmdd/rzqbf38hpysonxvitsas 355w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JthPLyb5tjcY6jmdd/hboyjswo8i5jwvs0itek 435w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JthPLyb5tjcY6jmdd/yfwpxybttoopzjtae90a 515w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JthPLyb5tjcY6jmdd/wcpo3xp5e4hlbpnof0bx 595w\"></figure><p><strong>Apply now for the Philippines\u2019 first ever EA Conference!</strong></p><p>Join us from October 20 to 22 for a weekend of talks, workshops, networking, and more in the bustling city of Manila.</p><h2><strong>\ud83d\udcdd Applications</strong></h2><p><strong>The deadline for applications is September 30, 2023.&nbsp;</strong>Slots are limited and applications will be considered on a rolling basis, so please apply early!</p><h2><strong>\ud83d\udccd When and Where</strong></h2><p>From Friday, October 20 until Sunday, October 22 at the conference venue Rizal Park Hotel, located at South Road Drive, Kalaw Avenue Extension, Manila, Philippines.</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JthPLyb5tjcY6jmdd/zwvh1mn6ogah5lzr2stl\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JthPLyb5tjcY6jmdd/himia8xuecphcvg3zp8c 130w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JthPLyb5tjcY6jmdd/ghtmuikzjjq0x95o1iar 260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JthPLyb5tjcY6jmdd/hd7ot430xtz7s0ludpe8 390w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JthPLyb5tjcY6jmdd/vkksfezvf0f1xjcsp0em 520w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JthPLyb5tjcY6jmdd/zqomvyib0hy2ciixj2ht 650w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JthPLyb5tjcY6jmdd/c1ud57w2vlx8snw87wa4 780w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JthPLyb5tjcY6jmdd/ofzkwp6sx6tgemilfnsb 910w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JthPLyb5tjcY6jmdd/v9s61fkvetiv82j7fvex 1040w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JthPLyb5tjcY6jmdd/kjgv2hn7vxsto7oljukh 1170w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JthPLyb5tjcY6jmdd/xl8yme49tueux7o2qhe2 1229w\"></figure><h2><strong>\ud83d\udc64 Who</strong></h2><p>EAGxPhilippines is intended for both individuals new to the effective altruism (EA) community and those already professionally engaged with EA, mostly focusing on attendees based in Southeast and East Asia.</p><p>We believe the conference will be of value to those currently exploring new ways they can have an impact, such as students, young professionals, people that are excited to start new impactful projects and mid-career professionals looking to shift into EA-aligned work. We also invite established organizations looking to share their work and grow their pool of potential collaborators or hirees.</p><p>If you are uncertain about your eligibility, please don't hesitate to apply!</p><h2><strong>\ud83d\uddd3 Schedule</strong></h2><p>More detailed information on the agenda, speakers, and content will be available closer to the conference via Swapcard and updates to this post.</p><h2><strong>\ud83d\udeeb Travel expenses</strong></h2><p>Funding is available to support travel to the conference for those that would not be able to attend otherwise and priority will be granted to individuals who reside within Southeast and East Asia.</p><h2><strong>\ud83d\udcee Contact Us</strong></h2><p>Email us at philippines@eaglobalx.org if you have any questions that are not answered in the FAQ.</p><p>&nbsp;</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JthPLyb5tjcY6jmdd/rbrrfl996oqeayjv27ws\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JthPLyb5tjcY6jmdd/uzd8p9ynrcks9vdyvjwk 170w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JthPLyb5tjcY6jmdd/vtbxmylivkpjppfyebwz 340w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JthPLyb5tjcY6jmdd/sn8ritazf8i9vfuo7e7t 510w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JthPLyb5tjcY6jmdd/dot8kaexyvjhq982zgre 680w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JthPLyb5tjcY6jmdd/s18a9godbcgpjpaidg8u 850w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JthPLyb5tjcY6jmdd/em8npdbeutjea51m5efw 1020w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JthPLyb5tjcY6jmdd/i80umwzyvq5k1impmjan 1190w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JthPLyb5tjcY6jmdd/ydpgu28trkbrc1f4irgh 1360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JthPLyb5tjcY6jmdd/bq51l3mwukt0evpp9ybs 1530w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JthPLyb5tjcY6jmdd/sanmvhe39b5bpcu00dvf 1679w\"></figure><h3><br>&nbsp;</h3><h3><strong>EAGxPhilippines Organizers</strong></h3><p><strong>Andrea Medina Cue</strong>, <i>Tech Production Lead</i></p><p><strong>Dion Tan</strong>, <i>Strategy and Programs Lead</i></p><p><strong>Elmerei Cuevas</strong>, <i>Project Manager</i></p><p><strong>Kira Chan</strong>,<i> Physical Production Lead</i></p><p><strong>Xyeanne Million</strong>, <i>Admissions and Volunteers Lead</i></p><p><strong>Zian Bonoan</strong>, <i>Communications and Marketing Lead</i></p>", "user": {"username": "zianbee"}}, {"_id": "hJ73qd6sRNMcjCsoX", "title": "EU\u2019s AI ambitions at risk as US pushes to water down international treaty (linkpost)", "postedAt": "2023-07-31T00:34:28.529Z", "htmlBody": "", "user": {"username": "michaelchen"}}, {"_id": "b6mZuozqLkbBCH7k9", "title": "Abortion Experience: collecting data", "postedAt": "2023-08-01T11:49:23.267Z", "htmlBody": "<p>This post is about abortion support. I am collecting data pertaining to experiences related to abortion from our community members. By gathering your stories, perspectives, and advice, I hope to develop a comprehensive resource that can help those facing similar situations.&nbsp;<br><br>If you have:</p><ol><li>Undergone an abortion, elective or otherwise.</li><li>Supported a partner through an abortion.</li><li>Helped someone close (friend/relative) through an abortion.</li><li>Managed a colleague undergoing an abortion.</li></ol><p>Please consider filling out&nbsp;<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSexcd--Tt8FCKoFO0Qy2K6KIQ1TGs5cUNkORExtYEF4mg-xwA/viewform?usp=sf_link\"><u>this form</u></a>. The form includes open-ended prompts designed to capture your unique experiences and may require some time to complete. The level of engagement is entirely up to you. Please be assured that the form is anonymous, and all responses will be treated confidentially. Every shared experience is valuable and will be respected with utmost care. Also, I welcome volunteers who can help sift through the responses or contribute to a follow-up post (pro bono, alas).<br>&nbsp;</p><p>Why discuss this on the EA forum?&nbsp;</p><ol><li>Participants in the EA forum are more likely to be intensely focused on their careers, driven by a desire for impact, which may lead some to choose not to have children. The experience of dealing with an unwanted pregnancy and abortion could be uniquely challenging and isolating.</li><li>By discussing personal challenges like abortion openly, we make actionable strides toward fostering a more supportive, compassionate community.</li></ol><p><br>What is a positive outcome?&nbsp;<br>A follow-up post, if written right, gathering data and insights on this topic should serve two objectives:<br>- a well-researched, supportive resource about abortion experiences providing guidance that someone who finds themselves in a similar position might turn to<br>- we, as a community, feel adequately equipped to engage in informed discussions.<br>&nbsp;</p><p>Why am I investing my time in doing this?<br>In addition to helping others, I seek satisfaction in channeling my ordeal (I went through this last year) into something constructive - I might even call it closure.&nbsp;</p><p>My experience.&nbsp;<br><i>(sharing in case it helps people open up about sharing theirs)</i><br>When I went through the process myself, I realized that I lacked guidance on what to expect, the help I could ask for, and the changes in my life that would follow. Fortunately, I had abundant financial and social support, and access to abortion-related healthcare was straightforward where I lived. I consider myself incredibly fortunate for knowing my priorities clearly enough to decide on an abortion when faced with an unwanted pregnancy; I did not want kids then, so I was getting an abortion. Clear. However, the experience led me down a path of unexpected grief. The disparity between my expectations (it was a well-informed, rational decision) and the reality (my body going through proper, hormone-driven trauma and grieving) triggered the most challenging mental health period I have ever endured.</p><p>A recent&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/uxfwaQaPq2martJAv/suggestions-for-how-to-talk-about-pregnancy-losses\">post on pregnancy loss</a> provides some insights but doesn't entirely cover my experience. After all, I wasn't grieving a loss but grappling with 'Why me?' and 'When can I get back to normal?\u2019 People in my support network \u2013 partner, friends, and coworkers \u2013 were keen to help. But, my inability to articulate what I needed led to a frustrating situation for everyone involved. While this was manageable within my personal relationships, my work status did not survive the sudden loss of agency/reliability.</p><p>On March 8, 2023, my roommate wished me a \"Happy International Women's Day,\" which prompted me to contemplate my happiness as a woman. As I searched for an affirmative answer, I slipped into a minor menty-B, desperate to find clarity. I never had a problem with identifying with the gender assigned to me at birth, but it has been incredibly clear throughout my career so far that it places me at a disadvantage. After a couple of hours of crying, thinking through, writing a Google doc while crying, and speaking with my trusted support group, I decided to do something about it. This is what I have come up with so far.&nbsp;<br><br>In conclusion, sharing our experiences can strengthen us, foster understanding, and contribute to creating a more supportive community. Let's begin this conversation, hoping it will be beneficial to us all.</p><p><br>&nbsp;</p>", "user": {"username": "shewilleval"}}, {"_id": "Bjr6FXvnKqb37uMPP", "title": "Shutting down AI Safety Support", "postedAt": "2023-07-30T06:00:09.066Z", "htmlBody": "<p>This is a quick post to officially announce that AI Safety Support is on an indefinite pause. We have been on pause for a while now, but I wanted to make it official. I might have more to say on this later but expect that if I wait till I write a longer explanation, it will not happen.</p><p>I\u2019m calling it a pause because maybe AI Safety Support does reopen in some capacity in the future, possibly with a different person running it.</p><p>A lack of funding is a part of the decision but is not the only factor. That is to say that I\u2019m not looking for offers of funding.</p><p>AI Safety Support Ltd, the Australian-based charity, supports several other projects and will continue to do so. None of these projects should be affected by this.</p><p>If you have any questions, you can ask them in the comments here, but I may not respond to them.</p><p>It has been a wild ride these last few years. I have so much love and appreciation for everyone I have worked with.</p><p>Thank you all so much.</p>", "user": {"username": "JJ Hepburn"}}, {"_id": "owM2obTsNiZHK2nu9", "title": "About \u2018subjective\u2019 wellbeing and cost-effectiveness analysis in mental health", "postedAt": "2023-07-30T13:39:18.792Z", "htmlBody": "<p>Hello everyone,</p>\n<p>I was first \u2018sucked in\u2019 to this forum when I was directed to a post I might find interesting \u2013 it was about a research organisation with EA endorsement that was straying into my area of work, mental health. I\u2019m a UK doctor specialising in psychiatry, with some research experience. To be honest, I was baffled and a little frustrated by how far this organisation strayed from what I would expect from mental health research \u2013 hence the (perhaps overly) technical diatribe I launched into on a website I hadn\u2019t visited before, about an organisation I hadn\u2019t heard of prior.</p>\n<p>However, that\u2019s not usually my style, and once I took a step back from my knee-jerk reaction, I wanted to understand how people with the same goals could arrive at completely different conclusions. It\u2019s led me to do a lot of reading, and I wanted to see if I could try on a makeshift \u2018EA\u2019 hat, with most of my philosophy knowledge gained from The Good Place, no economics experience, and see where it went.</p>\n<p>What I wanted to understand:</p>\n<ol>\n<li>Where has the interest in \u2018wellbeing\u2019 arisen from, and what does it mean?</li>\n<li>What are \u2018subjective wellbeing\u2019 (SWB) measures, and are they useful?</li>\n<li>Are we at a point of putting monetary value on SWB (e.g. like QALYs) for the sake of cost-effectiveness analysis (CEA)?</li>\n<li>When people are in this space talking about mental health, are we talking the same language?</li>\n<li>Why are RCTs the \u2018best\u2019 evidence for subjective wellbeing?</li>\n<li>What would I come up with from my perspective of working within mental health for a way of comparing different interventions based on their intended effects on wellbeing?\na.\tSpillover effects\nb.\tCatastrophic multipliers</li>\n<li>How does my guess stack up against existing research into wellbeing?</li>\n<li>How could my framework be helpful in practice?</li>\n<li>What would I be suggesting as research areas for maximal gains in wellbeing from my biased perspective?</li>\n</ol>\n<p>I\u2019m aware this might be well-trodden ground in EA, which would make me embarrassingly late to the party, and consequently a complete bore. To lay my cards firmly on the table, I did approach these questions from the perspective that mental health is desperately underfunded, I spend a lot of time with patients who are severely affected by mental illness and therefore I\u2019m biased towards seeing \u2018wellbeing\u2019 as an opportunity to rebalance this scale and acknowledge the impact mental illnesses have on people. I also feel the term \u2018mental health\u2019 is used in a way which is often confusing and occasionally unhelpful or stigmatising.</p>\n<p>This is not meant as an attempt to further an argument against any person or organisation; it will also not be high in tech-speak as this was the first lesson I learnt very quickly on my journey \u2013 while jargon is a useful shorthand for talking with people in the same field, as an outsider it is <em>exhausting</em>. This post does not reflect the attitudes or opinions of anyone but me \u2013 this is my personal quest for common ground and understanding, not a representation of \u2018UK psychiatry\u2019 \u2013 I\u2019m speaking in an entirely personal capacity and, accordingly, I\u2019m assuming I\u2019ve gotten a lot of it completely wrong.</p>\n<p>To make this less self-indulgent, I\u2019ve arranged this post to follow that question-and-answer format. For the sake of transparency, this was how this work came to be: I started with a long piece of writing about my concerns with assumptions made about mental health interventions in low- or middle-income country (LMIC) settings. I then did a quick Google on the WELLBY and wrote a lot about the idea of asking people to rate their \u2018satisfaction with life\u2019 on a scale from 0-10 which was essentially just entirely critical. I subsequently wrote out my concept of wellbeing as a framework, and my recommendations for high-gain areas for wellbeing-directed funding. Then I realised this was arrogant and so spent a couple of days doing a non-scientific review of the current subjective wellbeing literature. After several further drafts, this behemoth was born.</p>\n<p>For readability/skipability: I\u2019ve cut out some of my tangents, left others in for comment (#4, #5), and this piece will go through my arguments for an evaluative framework as a way of collating/synthesising (subjective) wellbeing research until we have more robust data (#6, #8). It will also cover my quick literature review (#7). [To be clear, this is not a scientific method which should be given any weight \u2013 I was bored over a weekend and so this was the best I could do, it\u2019s not my day job!]</p>\n<p>I am completely open to other opinions and comments. It\u2019s almost certain that I\u2019ve missed some key information from my speed-run through EA and wellbeing research so it will not offend me to hear this is the case.</p>\n<h2>Where has the interest in \u2018wellbeing\u2019 arisen from, and what does it mean?</h2>\n<p>Wellbeing, as a construct, seems to refer to a state of thriving vs surviving (in a nutshell). From some of the psychology/philosophy papers I skimmed through, it seems there is relative agreement that it\u2019s complex and people might judge their wellbeing in different ways:</p>\n<ul>\n<li>Evaluative wellbeing \u2013 how satisfied we are in life, how do we rate the quality of our lives</li>\n<li>Hedonistic wellbeing \u2013 do we have more \u2018positive\u2019 feelings in life rather than \u2018negative\u2019 ones</li>\n<li>Eudemonic wellbeing \u2013 do we have a sense of purpose in life, can we derive meaning from life</li>\n</ul>\n<p>While it might be relatively easy to gauge some (hedonistic) aspects of wellbeing e.g. how do people feel on a day-to-day basis in terms of their emotional/mental state, other questions are clearly more difficult to answer without some thought and maybe experiencing an existential crisis or two.</p>\n<p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/owM2obTsNiZHK2nu9/ctezr5zk5peijyd4w4wh\" alt=\"PubMed search results for papers including \u2018subjective wellbeing\u2019 in title or abstract/summary by date\"></p>\n<p><em>PubMed search results for papers including \u2018subjective wellbeing\u2019 in title or abstract/summary by date</em></p>\n<p>From my quick literature review, the interest in wellbeing as a research area is a relatively recent phenomenon. There has been rapid growth in papers being published about subjective wellbeing from around 2020 onwards. I\u2019d guess this is due to (1) the COVID-19 pandemic and lockdown restrictions making this a hugely important topic for public health officials and politicians, and (2) the recent interest in using wellbeing as an outcome when evaluating the effect of a broad range of policy decisions, which has subsequently driven interest in quantifying \u2018wellbeing\u2019 for use in cost-impact analyses.</p>\n<p>Organisations like <a href=\"https://whatworkswellbeing.org/\">this one</a> aim to bring wellbeing into the forefront of discussions for how governments, communities and organisations can improve people\u2019s lives. Spending a little time on their website somewhat illustrates that this is not exactly straightforward: there are lots of factors which contribute to overall wellbeing, and a huge number of ways this information can be collected.</p>\n<h2>What are \u2018subjective wellbeing\u2019 (SWB) measures, and are they useful?</h2>\n<p>Subjective wellbeing measures are one way to capture the wellbeing impact from an intervention \u2013 you ask the people affected by the change to rate their wellbeing (using various tools) and you can compare these scores to those provided before the intervention to evaluate the overall gain or loss. This, however, opens debate into which questions are important to ask to get an idea about wellbeing \u2013 this complex concept with lots of theories and components. It also favours putting this information into a numerical form so you can compare scores before and after an intervention, which is much easier than trying to quantify impact from answers to questions like, \u201cDo you feel your life has more meaning?\u201d.</p>\n<p>To capture information about national wellbeing in the UK, as part of growing interest in this area, a number of questions were added to national surveys (the \u2018ONS4\u2019). The four questions added:</p>\n<ul>\n<li><em>Overall, how satisfied are you with your life nowadays?</em> 0=not at all satisfied, 10=completely satisfied (this question of Life Satisfaction sometimes crops up in research as \u2018LS\u2019)</li>\n<li><em>Overall, to what extent do you feel the things you do in your life are worthwhile?</em> 0=not at all worthwhile, 10=completely worthwhile</li>\n<li><em>Overall, how happy did you feel yesterday?</em> 0=not at all happy, 10=completely happy</li>\n<li><em>On a scale where 0 is \u2018not at all anxious\u2019 and 10 is \u2018completely anxious\u2019, overall, how anxious did you feel yesterday?</em></li>\n</ul>\n<p>The last two questions can then be combined to give an idea of \u2018affect (mood) balance\u2019 \u2013 which I gather is important from some of the psychology research I read which argued that questions about affect shouldn\u2019t reduce it down to unipolar constructs (e.g. happy vs sad) as this is not reflective of how people judge their overall wellbeing.</p>\n<p>While a lot of interest has been devoted to using Life Satisfaction in UK policy as a singular measure of wellbeing for decision-making, I\u2019m yet to be fully convinced of its value (more on this later). However, my personal thoughts aside, I\u2019m not alone in thinking this isn\u2019t the best way of measuring wellbeing. My quick literature review, which returned 286 relevant papers, included 41 different scales to gather information on subjective wellbeing (SWB), with several other papers including bespoke questionnaires designed for particular studies, or interviews with people to gather non-numerical (qualitative) data. Many studies combined different tools to capture different aspects of subjective wellbeing i.e. some tools are designed to just gather information on hedonistic wellbeing, or evaluative wellbeing, etc.</p>\n<p>To me, as well, there is an issue with using purely subjective data for wellbeing. Perhaps this is my psychiatry bias coming into play, but while we elicit subjective information from patients, either by directly asking them e.g. how they are feeling, or indirectly through assessment of their thoughts and views on themselves; this is balanced against our \u2018objective\u2019 (i.e. external) evaluation as clinicians. Mental illnesses wreak havoc on our ability to think and perceive reality; either through distorting our perception of the world around us and ourselves; making us perceive our internal experiences as happening outside in the real world (e.g. hallucinations or delusions); or making our thoughts race, become disjointed, or slowed down.</p>\n<p>While it is important to not dismiss patients\u2019 subjective views, it\u2019s not always appropriate to take them out of context. As an example, a patient experiencing mania might feel subjectively on top of the world and destined for greatness (10/10 Life Satisfaction) \u2013 they are, however, incredibly sick, their family is likely distraught, and they are at serious risk of harm if they don\u2019t receive treatment - even if this would correlate to a lowered Life Satisfaction rating. Similarly, for people who might struggle to understand questions asking for a complex/abstract evaluation, it seems unfair to use standardised questioning to get an idea of their wellbeing; it\u2019s arguably even more important to be flexible to ensure the information you\u2019re gathering is useful and reflective of their experiences.</p>\n<p>All of this to say, I have a feeling that while SWB data are helpful in some contexts, it\u2019s important to use the information thoughtfully. Perhaps the huge number of SWB measures is reflective of this being a field in its infancy, still finding its feet, and there might be a future standardised and validated scale we can use to compare different interventions based on their wellbeing improvements. However, it\u2019s equally possible to me that the number of tools reflects the different aspects of wellbeing which are most important to different researchers, different communities, or different groups of people. The future of subjective wellbeing research might be development of further tools for specific settings or people, or increased use of interviews to generate qualitative data if researchers want more in-depth understanding of the people they want to help.</p>\n<p>At the very least, I think it\u2019s reasonable to say that at the moment, it would be unwise to compare different SWB measures when this doesn\u2019t appear to be validated as offering useful information. With wellbeing having a wide scope, and SWB measures still a growing area of research, it might be comparing apples and oranges to compare different SWB outcomes for different interventions.</p>\n<h2>Are we at a point of putting monetary value on SWB (e.g. like QALYs) for the sake of cost-effectiveness analysis (CEA)?</h2>\n<p>For the purposes of policy decision-making, there is interest in converting wellbeing impacts to an equivalent monetary value so it\u2019s possible to make a judgement on whether or not the intervention was worth the money, and allow for different interventions to be compared e.g. which intervention can provide the best return (in wellbeing) for the cost. This is an approach which is already used for other metrics e.g. the value of a Quality Adjusted Life Year (QALY).</p>\n<p>The UK Treasury has been looking into whether SWB can be used in a similar way with the WELLBY. <a href=\"https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/1005389/Wellbeing_guidance_for_appraisal_-_background_paper_reviewing_methods_and_approaches.pdf\">This</a> discussion paper suggests an approach which values one WELLBY at around \u00a313,000; the equivalent of a one-point change in Life Satisfaction per year, using the 0-10 scale. It also goes into some of the complexities in using Life Satisfaction in this manner, especially converting this 0-10 scale of \u2018satisfaction in life\u2019 to the 0-1 scale used in the QALY between death and living a year with no health problems. While you could argue the QALY is only capturing a few areas of wellbeing, and it\u2019s useful to have a broader perspective when wanting to measure how a change has helped people, it seems a bit tricky as a concept when considering settings where people are dying in significant numbers from preventable/treatable illnesses. It\u2019s worth keeping in mind that the countries considering using the WELLBY (UK and New Zealand) would not fit that category, and <a href=\"https://whatworkswellbeing.org/blog/converting-the-wellby/\">this</a> was an interesting read about the intricacies of using life satisfaction in CEAs in LMICs in terms of how you calculate the cost of a WELLBY for countries with different average LS, life expectancy and income (GDP).</p>\n<p>I haven\u2019t seen many arguments about estimating WELLBYs to direct funding or to compare different interventions. In general, it seems that the argument for WELLBYs is to collect SWB data before and after implementing a change, and use this to inform arguments about cost-effectiveness in terms of wellbeing; which in itself then requires careful work to \u2018covert\u2019 the WELLBY to a monetary value based on the country you are working within. This is good for interventions which aren\u2019t just health-based where the QALY is not really capturing what you\u2019re trying to do. It seems collecting robust SWB data (especially as this is a new field) and using wellbeing as one way to communicate the impact of an intervention is the recommended approach, rather than trying to use a \u2018cost per WELLBY\u2019 metric to compare different interventions. I haven\u2019t seen much data to argue this is appropriate, and haven\u2019t found many papers reporting Life Satisfaction in a range of settings from similar-style interventions to be able to support doing this (yet).</p>\n<p>While for policy decision-making this perhaps isn\u2019t a big deal, it clearly is a problem for people within EA who are interested in wellbeing as a way of measuring the \u2018most good\u2019 that can be done across a range of challenges and settings.</p>\n<h2>When people are in this space talking about mental health, are we talking the same language?</h2>\n<p>This is just a quick note to avoid confusion \u2013 there are lots of discussions about \u2018mental health\u2019 which have nothing to do with \u2018mental illness\u2019 and it\u2019s important to avoid conflating the two to avoid misunderstandings. I suppose, to me, it\u2019s a bit like this: generally speaking, smoking is bad for your health, it would be considered health-promotion to encourage people to stop smoking and dissuade young people from picking up the habit, however I couldn\u2019t argue that not smoking or stopping smoking <em>prevents</em> lung cancer, emphysema and heart disease. Smoking greatly elevates your risk of all three, but you can live a perfectly healthy life and be unlucky. Similarly, while there are lots of things I can argue are good or bad for one\u2019s (mental) health, that is a completely separate conversation from what is an effective treatment for a mental illness.</p>\n<p>Generally, these mental health-promotion interventions are based around considering health as holistic (mental, physical and cognitive i.e. healthy mind/healthy body/healthy brain) so exercise, eating well, etc are generally good. Others are around avoiding stress e.g. workplaces offering flexible hours, mindfulness sessions, etc. You can make arguments about how mindfulness and exercise might promote (mental) health and wellbeing, but you\u2019d have to show these are effective treatments for e.g. depression to make any argument they help people with a mental illness. Similarly, giving people without a diagnosed mental illness evidence-based treatments for mental illness to help their wellbeing would be odd. It\u2019s a bit like telling non-smokers with lung cancer to stop smoking to get better.</p>\n<p>I can see why mental illnesses have been used in the discussions I\u2019ve seen on SWB, not only due to confusing terminology which uses \u2018mental health\u2019 and \u2018mental wellbeing\u2019 somewhat interchangeably, but also based on how \u2018hedonistic wellbeing\u2019 (positive vs negative emotions) is measured and how this might be over-simplified i.e. suggesting treating depression promotes happiness, or treating anxiety disorders reduces anxiety. I\u2019m strongly against this approach because, simply put, these are complex illnesses which are more than simple emotions. A few examples: PTSD is an anxiety disorder, but rarely manifests in constant worry (hypervigilance, intrusive thoughts, numbness, etc \u2013 yes); someone with agoraphobia able to remain at home will not be living in terror day-to-day but may be extremely disabled due to their illness; for a diagnosis of depression being \u2018low in mood\u2019 is not even a requirement, etc. I do think mental illnesses have a massive impact on wellbeing, but not solely due to their effect on affect/mood balance.</p>\n<h2>Why are RCTs the \u2018best\u2019 evidence for subjective wellbeing?</h2>\n<p>I think, for evaluative purposes, the concept of randomised-controlled trials (RCTs) being the \u2018best\u2019 evidence to answer a research question is flawed when considering the need for subjective wellbeing approaches. While, in the hierarchy of evidence, RCTs are better than other types of studies, it\u2019s important to clarify what \u2018best evidence\u2019 means, rather than taking that at face value.</p>\n<p>Let\u2019s say I\u2019m doing an RCT on how well psychoanalysis (intensive psychotherapy offered five times a week) improves depression in working-age adults. My interest is in proving psychoanalysis works in treating depression. I recruit 100 people with depression and offer 50 of them psychoanalysis, the other 50 I offer \u2018sham\u2019 psychoanalysis (a placebo). Because I need them to stay on the trial to complete the study, I might offer them incentives, be really nice to them, or I\u2019ll work within a company that\u2019s happy for me to monopolise their time. Because I want to make sure it\u2019s the psychoanalysis that\u2019s having an effect on depression, I might exclude people that might complicate the picture (e.g. I might not want people already having therapy, or people misusing substances, etc); for the safety of participants who have kindly volunteered, I might not include people really sick with depression as they need immediate care.</p>\n<p>I\u2019ll randomly assign people into treatment or control groups as this usually makes the groups roughly similar and allows me to compare them fairly e.g. I wouldn\u2019t want the groups to be all men vs all women, etc. I\u2019ll also want to make sure (ideally) nothing else happens over the trial period to change how depressed they are because I need to ensure any benefit is due to my intervention and not some other reason (e.g. I can\u2019t have the company give a raise to a bunch of people in my treatment or control group).</p>\n<p>I\u2019ll collect lots of measures of depression at the end, and let\u2019s say it\u2019s worked, I make people 10x better. I can do a CEA on this to argue everyone in the UK should have this amazingly effective treatment. I\u2019d have to allow for the fact we know people do better in a trial than in the real world (because I\u2019ve tried to stop them dropping out and chosen my participants carefully). I\u2019ll begrudgingly accept it\u2019s likely to be half as effective, people only get 5x better. But, even then, it\u2019s worth doing and I roll it out across the UK.</p>\n<p>It\u2019s a complete failure.</p>\n<p>It\u2019s not really that the treatment isn\u2019t as effective, although I find that too. The problem is I\u2019ve spent a bunch of money on training and providing accessible psychoanalysis but no one is attending. Because, obviously, most people cannot attend therapy that frequently with work commitments, or won\u2019t pay a babysitter to allow them to come. Maybe they prefer the free once-weekly therapy available in the UK, even if it is a bit less effective than psychoanalysis. The therapists I\u2019ve quickly trained to do this work are burning out, and suddenly people are getting worse because their therapist has dropped them. The people that are attending are not very depressed (likely because their illness and their lives are allowing them to come five times a week for therapy) and so my treatment effects become less impressive because there is only so much you can make someone with mild depression less depressed vs the gains in my RCT when people had moderate/severe depression.</p>\n<p>In this example, the RCT is <em>still</em> good evidence for psychoanalysis being an effective treatment for depression (i.e. it shows the intervention works). The CEA similarly might have been well reasoned. People are just messy and, outside of a ridiculous example like this, it's hard to predict how the treatment works in the \u2018real world\u2019 (i.e. the application). While in a RCT we need to reduce the amount of \u2018noise\u2019 to be sure any effect is due to our intervention, if a treatment is highly impractical or unacceptable, it\u2019s not just the effect will be less good, it might not be effective <em>at all</em>.</p>\n<p>This is particularly relevant in settings where it\u2019s harder to predict all the unintended consequences (positive or negative) of an intervention. If wellbeing is an argument for subjectivity (vs objectivity obtained from RCTs), you need as much noise as possible: it weights qualitative evidence and observational studies much more highly. You have to accept there is a huge amount that is unknown in thinking about adapting a trial to the real world of another country, and simply reducing the likely treatment effect by an arbitrary number is an unhelpful approach without this work.</p>\n<p>In other words \u2013 collecting real-world feedback on the intervention from the people most affected by it is helpful to understand their perspective on the \u2018most good\u2019 which can be done in their community. How much subjective wellbeing should be understood alongside other metrics is veering into dangerous philosophical territory for me e.g. if an intervention improves mortality in a country, but it negatively affects everyone\u2019s wellbeing, is it still doing good, or how much should that down-grade estimates of goodness? Alternatively, is it right at all for anyone else to say what \u2018doing good\u2019 is in another community? Perhaps \u2018wellbeing\u2019 allows for a more complex construct of \u2018good\u2019 which reflects the philosophy of those affected rather than risk imposing an external set of values.</p>\n<p>There is the additional issue that RCTs are expensive to run and therefore present a barrier for researchers in LMIC settings to produce this 'best evidence', which seems like an issue when aiming to reduce assumptions in CEAs. To me, personally, there seems to be an under-recognition of the problems in relying on externally-funded RCTs to produce this evidence. Firstly, it almost inevitably involves applying assumptions to drastically different cultures \u2013 in terms of mental health, this is particularly problematic given how culturally-bound mental illnesses are in terms of experience, understanding and expressions of distress; as well as approaches to treatment. In some cultures, physical/spiritual symptoms are much more common than our more psychological formulations of difficulties; and psychotherapy is not always acceptable or even desirable as a treatment. Secondly, it appears to ignore the power dynamics at play when a wealthy \u2018outsider\u2019 pitches up in a remote community to conduct research.</p>\n<p>As another detour from reality, let\u2019s imagine I don\u2019t live in London. I live in a tiny village and I\u2019m hit by a devastating flood. I\u2019m sleeping on a camp-bed in the local community centre \u2013 I\u2019ve lost everything and I\u2019m in a very dire situation. Suddenly, Elon Musk arrives in a helicopter and hands me a designer raincoat (worth \u00a3200). His assistant asks me a few weeks later if that was helpful and if I\u2019m glad I have the raincoat. I would probably answer yes, because by then I\u2019ve found some use for it, and I don\u2019t want to upset the team handing out expensive raincoats. I might even say it\u2019s the best thing ever because I\u2019m hoping he\u2019ll come back and offer me something else. However, if he had asked me initially if I wanted \u00a3200 <em>or</em> the raincoat, of course I would take the money \u2013 and I would find it slightly irritating if he then pulled a face and told me the weather forecast for next week to suggest I would be better off taking the raincoat.</p>\n<p>To return to reality once more, I can see the argument for RCTs for mental health interventions in LMICs \u2013 it's worth seeing if treatments are similarly effective in these settings when the bulk of evidence is otherwise derived from non-LMICs. It might allow for some gauge of cultural acceptability if provided in a non-coercive manner and would also allow researchers to collect SWB data as one of the outcome measures to argue for cost-effectiveness. However, this is not the only way of gathering this information, and to define the \u2018best\u2019 evidence, this is not a simple matter of hierarchy.</p>\n<h2>What would I come up with from my perspective of working within mental health for a way of comparing different interventions based on their intended effects on wellbeing?</h2>\n<p><strong>How satisfied are you with your life, on a scale from 0-10?</strong></p>\n<p>As I\u2019m talking to some EA folks, my \u2018prediction\u2019 is there\u2019s a mix of people who had a gut response to that question (including a complete reluctance to answer at all), those who puzzled over that initial response, those consumed with guilt for any instinctive rating deemed \u2018too low\u2019 given an acute awareness of others\u2019 suffering, and those who suppressed any immediate response and set in motion a internal moral philosophy machine to answer the broader question of what is satisfaction, how do we self-evaluate? <em>[Now I've spent some time on this forum - I give you 80% odds every EA reading fits at least one category, with the known variable giving a confidence estimate highly increases the chance of someone wanting to object to prove me wrong and now struggling with the trap I\u2019ve laid  which has created a scenario, regardless of outcome, where I\u2019m 100% right\u2026 and down-valued my goodwill from EA with this joke by 0.85]</em></p>\n<p>I suppose I\u2019m trying to recreate real-world conditions for how people respond to that question with some mild impatience or irritation in the person asking i.e. as part of a survey, or lumped in other outcome measures in an RCT, or even being asked by a stranger. Perhaps a reliance on comparable, numerical metrics produces a certain absurdity. I\u2019m trying to imagine having a conversation with someone I care about to ascertain their wellbeing, and following that up with \u201cyeah, sure, but on a scale from 0-10?\u201d. Or possibly, from my experience in medicine, the face a patient makes if they are rolling around, screaming in agony, and someone asks for a pain rating out of 10. We accept a range of responses to mean '10', but a pain scale is at least useful in other contexts.</p>\n<p>My gut response to the same question about life satisfaction (\u201cI don\u2019t know, about 7/8?\u201d) seems to put me in good company amongst survey respondents in the UK where average Life Satisfaction is <a href=\"https://www.ons.gov.uk/peoplepopulationandcommunity/wellbeing/bulletins/measuringnationalwellbeing/april2021tomarch2022\">7.54</a>, but does that mean we have comparable wellbeing? Is it just the British approach to any similar question (\"How am I? Good, thanks.\"). I struggled to imagine what the difference between a 7 or 8 would be, and if I answered the same question next year with no changes in my wellbeing, it might therefore be +/- 1 based on a coin-flip. While I can remember a 10, I\u2019m struggling to know how I\u2019d keep at a 10 on repeated measures to determine wellbeing or whether that is even desirable to me i.e. if I took a pill that made me feel like that way constantly, what effect would that have on my life? Similarly, my growing devaluation of this question could easily provoke a \u2018f**k you\u2019 response if I was asked uncaffeinated. Apparently \u00a32 spent in buying me a coffee before asking next year nets a good 5 points \u2013 I\u2019m cheap at \u00a30.40 a WELLBY. Obviously, responses are more valuable when taken across a sample or population\u2026 but <em>are they</em>? It seems taking averages loses meaning too.</p>\n<p>It doesn\u2019t really matter, as a full roll-out of Life Satisfaction scores for the purposes of WELLBYs is under consideration, so I\u2019ll wait to see the value in the data collected to be proved wrong. However, my feeling is it\u2019s unlikely to produce helpful information alone, and if I was going to guess what makes up \u2018overall wellbeing\u2019, I might use the qualitative nature of my interactions with patients (and qualitative research in general) to identify key concepts. For the sake of comparison to QALYs etc, I would probably agree it\u2019s sensible to keep 0 at death, and use 1 as a year lived at \u2018baseline/average wellbeing\u2019. I suppose the same way that being in peak physical fitness is a \u2018bonus\u2019 for a QALY, living an enlightened high-wellbeing life is a bonus for my scale.</p>\n<h3>The key concepts</h3>\n<p><strong>Health</strong> - Illness will reduce wellbeing from your normal baseline, both in terms of the acute illness and the years spent with this illness that prevents return to baseline</p>\n<ul>\n<li>Where the duration of untreated illness can affect prognosis, the immediate impact should be weighted much more severely than considered over the long-term e.g. duration of untreated psychosis is a negative prognostic factor in predicting recovery in schizophrenia - it is much more effective to reduce the duration of untreated psychosis (immediate) than treatment in the longer term to promote long-term wellbeing</li>\n<li>Some illnesses produce highly unpleasant symptoms that are likely to affect someone\u2019s day-to-day enjoyment of life e.g. pain, fear, fatigue, etc. I don\u2019t think it\u2019s appropriate to relate this uniformly to severity e.g. through symptom measures. I would favour \u2018daily symptom burden\u2019, which will be affected by access to effective treatment \u2013 if treatments are broadly ineffective, or not available to people, it allows different weighting here.</li>\n<li>To explain my reasoning, anxiety disorders (mild/moderate/severe) appear exponential in <a href=\"https://cdn.who.int/media/docs/default-source/gho-documents/global-health-estimates/ghe2019_daly-methods.pdf?sfvrsn=31b25009_7\">Disability Adjusted Life Years (DALY) weighting</a> \u2013 a measure of impairment. Someone with agoraphobia may be housebound (significant loss of function) due to extreme fear of the outside world, but provided they are able to avoid leaving home they will not be living in fear. In other anxiety disorders e.g. generalised anxiety disorder, it is not possible to escape the anxiety (and you can't use fast-acting anxiety-relief treatments to mitigate this), even if it doesn't meet the same level of terror someone with agoraphobia might face if forced to leave the house.</li>\n<li>Someone constantly experiencing 3/10 pain daily despite pain relief might rate their overall wellbeing worse than someone experiencing 8/10 pain once a week who can relieve this with their morphine prescription, despite being lower on the pain scale</li>\n<li>In short \u2013 Daily symptom burden = how bad are the symptoms, how prevalent are they, and can you get any relief from them?</li>\n<li>In looking at \u2018ill health\u2019 in general, it might be worth considering if certain illnesses have a compounding effect (i.e. if you get X illness, is this worse because you already had Y), or multi-morbidity in mitigation to ensure problems aren\u2019t double-counted i.e. if two conditions result in loss of a person\u2019s left arm, these shouldn\u2019t be added together as you don\u2019t have two left arms).</li>\n<li>Overall, for wellbeing, it\u2019s understanding \u2018poor health\u2019 as (1) having a mental/physical illness (with the expected effects on life expectancy as my scale uses 0 as death), (2) unpleasant daily symptom burden.</li>\n</ul>\n<p><strong>Autonomy</strong> - The ability to maintain control and independence of one\u2019s body/self and make choices in life which reflect one\u2019s beliefs and values.</p>\n<ul>\n<li>The disability weight used in the DALY gives some idea of the \u2018unpleasantness\u2019 or undesirability of an illness/impairment which seems useful as a measure of the impact of a new diagnosis and it reflects broadly how people feel they will cope i.e. it should be a good measure of the short-term impact of an illness and how relatively feared/undesirable/distressing it is.</li>\n<li>However, the effect on wellbeing in the longer term has to allow for adaptation and deterioration, as well as recovery to baseline. Some conditions have a poor prognosis with further impairments and therefore a constant, subjective feeling of loss (e.g. progressive MS). Other people adapt to impairments with time and I feel it is wrong to imagine they cannot obtain high levels of wellbeing. Rather than saying someone with a disability will be X% worse off over the course of their lives as a static measure, it instead puts the onus on doing what we can to promote their access to the same opportunities. It would therefore weight the impact of a disability worse in resource-poor settings where people are not provided means to adapt.</li>\n<li>Ideally this would be informed through qualitative feedback from people with the illnesses in question in different settings to understand short-term vs long-term \u2018impact\u2019.</li>\n<li>Other examples I would imagine that drastically decrease autonomy might involve exposure to inescapable forms of violence and abuse (e.g. domestic violence, persecution), inability to exercise bodily autonomy (e.g. access to contraception)</li>\n<li>I suppose \u2018lack of autonomy\u2019 would include other aspects of being able to freely make decisions - this is seen in different ways e.g. people feeling trapped on benefits or trapped in jobs due to economic insecurity, being barred from education, or unable to afford/access healthcare. It is also a consideration for people requiring hospitalisation (particularly over the long term), institutionalisation, or incarceration.</li>\n</ul>\n<p><strong>Security</strong> - Confidence in having basic needs met (food, water, shelter, care).</p>\n<ul>\n<li>I would extend this to the benefit of having close confiding relationships if desired (an emotional/social sense of security).</li>\n<li>I would also imagine that childhood experiences of insecurity have ongoing effects in how people judge security throughout their lives, and leads to varying responses to real or perceived threats to that security \u2013 as an example, it\u2019s thought that adverse childhood experiences are common in the aetiology of all mental illnesses, but it\u2019s thought that neglect of a child\u2019s physical/emotional needs (e.g. if parents are not able to respond appropriately due to mental illness, substance misuse, or exposure to violence) can lead to problems throughout adolescence and adulthood in personality difficulties and disorders.</li>\n</ul>\n<p><strong>Time-direction</strong> - Having the ability to spend time in ways people value or find meaningful.</p>\n<ul>\n<li>People are not just 'living to work' or so over-burdened with responsibility they cannot utilise time for themselves how they wish e.g. social activities, interests; and they have the freedom to make trade-offs to reflect their priorities.</li>\n<li>Similarly, people being able to feel connected to a cause or community greater than themselves is important for people to find a deeper meaning in life and have a sense of purpose and fulfilment.</li>\n</ul>\n<p><strong>Equality/justice</strong> - Belief we are in control of our destinies and society rewards efforts and skills fairly.</p>\n<ul>\n<li>I think, as social creatures, we judge ourselves and our position in life compared to others and are therefore sensitive to \u2018unfairness\u2019. I think this plays out repeatedly in multiple ways across society, and generally inequality will act to decrease wellbeing e.g. I imagine in communities with high economic inequality or prevalent discrimination/unequal opportunity, this will decrease life satisfaction.</li>\n<li>While I think the impact is greater in the disadvantaged group, it can also reduce wellbeing in the advantaged group, because by profiting from an unjust society, there can be concern one\u2019s circumstances can be lost if not based on factors within your control or your achievements are not reflections of your abilities e.g. if I slept with my boss for a promotion, those around me will feel this was unfair (I didn\u2019t get this opportunity/salary bump through hard work or aptitude at my job) and will likely lead to a strong decrease in job satisfaction amongst my colleagues (why bother trying when promotions are handed out like this?). On the other hand, while I\u2019ve benefited from the promotion, I would question if I could have gotten it on my own merits, worry about my competency and be very sensitive to mistakes or criticism. I might worry I could lose my job if I get a new boss and it\u2019s discovered I'm actually incompetent.</li>\n</ul>\n<p>How this feeds into a 0-1 scale? I\u2019d suggest a matrix approach is helpful \u2013 even if SWB data aren't available to argue for wellbeing as a whole (either because it doesn't exist yet, or uses tools other than the supposed 'common currency' of Life Satisfaction, or uses qualitative information), this will allow what is known from existing research to be incorporated in these judgements while avoiding trying to combine SWB measures together, and produce an overall value of 'wellbeing impact'. Taking the above, I feel this could accurately reflect the benefits to society from broader interventions other than health alongside health-focussed interventions.</p>\n<p>For interest's sake, I tried thinking of mental illnesses along these lines. From most to least impact on wellbeing, I'd probably put it in this order (non-exhaustive list):</p>\n<p>Schizophrenia/Schizoaffective disorder (with further higher rating in first episode psychosis) &gt; Bipolar disorder type 1/Severe depression with psychosis &gt; Severe personality disorder/Severe depression &gt; OCD/PTSD/Eating disorders &gt; Moderate to severe generalised anxiety disorder/Moderate depression/Bipolar type 2/Agoraphobia/Social Phobia &gt; Mild depression/Mild to moderate generalised anxiety</p>\n<p>The DALY disability weighting (limited list/different language):</p>\n<p>Acute schizophrenia &gt; Severe depressive disorder &gt; Residual schizophrenia &gt; Severe anxiety disorder &gt; Bipolar disorder (manic episode) i.e. type 1 &gt; Moderate depression &gt; Anorexia/Bulimia &gt; Mild depression &gt; Moderate anxiety &gt; Residual bipolar disorder &gt; Mild anxiety</p>\n<p>So, it doesn\u2019t seem to be just arriving at the same answer in a more complicated way. However, there are a couple more things I would add if understanding the effects of (mental) illness on wellbeing.</p>\n<h3>Spillover effects</h3>\n<p>I\u2019ve seen the term \u2018emotional contagion\u2019 used now and then when talking about household spillover i.e. how are other members of the household impacted by an illness, or benefit from this person receiving an intervention. I think it\u2019s more helpful to take a systems-approach to understand the \u2018spillover\u2019 effects on wellbeing, which could similarly be modelled on the same framework. It reflects, then, the role that someone fulfils in their household and therefore the impact on the household if they become ill i.e. are they the main breadwinner, do they have caring responsibilities, do they have dependent children, is there a social \u2018safety net\u2019 if they are unable to work or fulfil their usual duties in the home. Is someone else having to pick up extra hours to pay rent, or reduce their hours to stay home and provide care, can they no longer enjoy life or engage in activities because their role in the home has changed?</p>\n<p>Again, based on my brief comment above, we have to weight heavily impacts on children, particularly in their early years, where adversity will have enduring effects on their wellbeing throughout their lives.</p>\n<h3>A catastrophic effect multiplier \u2013 despair</h3>\n<p>While slightly cautious of mentioning this topic in a broader discussion of mental health <em>[this bit will be talking about suicide and physician-assisted suicide, as well as electing not to pursue life-prolonging treatments]</em>, I think it is important in discussions of subjective wellbeing. While it\u2019s difficult to imagine what types of people have maximal wellbeing, with 0 being \u2018death\u2019 on my proposed wellbeing scale, it seems there are many people who do judge their lives as equivocal or worse than death when contemplating or attempting/completing suicide. I don\u2019t think that should then produce negative ratings below zero on my proposed 0-1 scale, but if an illness or societal adversity predictably increases rates of suicide, the overall effect on wellbeing considered in these situations should have a catastrophic multiplier applied to reflect this causes a number of people to make negative evaluations (i.e. to bring the wellbeing measure closer to 0).</p>\n<p>I think this is more helpful than including suicide in estimates of premature mortality of various illnesses, where otherwise \u2018mental illness\u2019 is rarely questioned as an attributing factor compared to others, or \u2018untreated/undiagnosed\u2019 mental illness is speculated upon when no diagnosis exists (either colloquially or through these data being sought in the first place). I think it is harmful to perpetuate either this understanding of suicide, or mental illness. Aside from all the research demonstrating suicide is not predictable in anyone, or preventable by improving access to mental health services/treatments (aside from lithium, interestingly, this does appear to prevent suicide, seemingly on an <a href=\"https://pubmed.ncbi.nlm.nih.gov/32056756/\">ecological scale</a>). It also seems to fail on face validity alone in countries that permit euthanasia, where psychiatric illnesses impacting judgement are screened for in referrals. If wishing to end your life was uniformly symptomatic of a mental health problem, and assuming this is not eugenics in action, there would be no demand or uptake of these services.</p>\n<p>Instead, I think suicide is best understood through the concept of current subjective wellbeing + prediction of future subjective wellbeing x belief we can change our future (i.e. current SWB + hope vs despair). My interpretation of wellbeing already incorporates viewing not only one\u2019s current state but a view of one\u2019s future (i.e. health, autonomy, equality), but it\u2019s important to recognise that these concepts should be defined separately here for the purposes of applying 'despair' as a multiplier. If someone\u2019s current wellbeing is critically low, they view their future as continued/worsening suffering and have the belief this cannot be changed, this appears to correlate to how people make decisions to end their lives. Conversely, it might allow some understanding for how people persevere even in incredible adversity \u2013 they maintain hope things can improve and that this can be brought about by their actions, or perhaps are more resilient to factors compromising wellbeing or naturally optimistic in predicting/valuing the positive impact of future events.</p>\n<p>Despair therefore can be an effect multiplier in known conditions which increase risk of suicide, as well as conditions that could plausibly result in critically low wellbeing, negative evaluations of the future, or lack of control over the future, when this information is not clear. E.g. in thinking about health, these evaluations could arise from illnesses that produce a large negative impact on wellbeing and/or have a deteriorating prognosis which leads to a particularly grim view of the future; for which there is no treatment, palliation or support to induce any hope things can improve.</p>\n<p>I prefer this as a catastrophising modifier on the effect of illnesses/societal adversity rather than incorporating it into the framework as another concept because I don\u2019t believe it arises independently, and I think it is harmful to categorise people seeking physician-assisted suicide or not agreeing to life-prolonging treatments as \u2018lacking wellbeing\u2019. To do so would go against my view on death and dying. Thinking about someone approaching the natural end of their life: there is nothing that can be done to change this, and predictions of the future become increasingly certain. It would be deeply wrong to characterise this as \u2018despair\u2019 or suggest people with life-limiting illnesses therefore cannot rate their lives with high satisfaction or experience high wellbeing. I\u2019d argue that when the otherwise prospective approach to self-evaluations of wellbeing is no longer appropriate, this reverses to a retrospective view, where we evaluate our satisfaction based more on our current subjective wellbeing and take on an increasingly retrospective view on what we have done, our impact on the world, and take comfort in what we are leaving behind.</p>\n<h2>How does my guess stack up against existing research into wellbeing?</h2>\n<p>I searched PubMed for original studies looking at predictors of subjective wellbeing. I searched for \u201cSubjective\u201d + \u201cWellbeing\u201d which yielded 699 results. I did an abstract-only review (i.e. looked only at the summaries of papers written by the authors) for studies which looked at a variable/factor and how this related to SWB. I couldn\u2019t include papers which used SWB to explain a relationship between two other variables, or those which produced conflicting results on different SWB measures for the purposes of what I was doing. This left me with 286 relevant abstracts in total.</p>\n<p>I picked out information on the country the research originated from, the SWB scores used, the factor the study looked at and if there were any important moderating/mediating factors the researchers found e.g. while variable X was associated with low wellbeing, we found lots of this effect could be accounted for by variable Y. I didn\u2019t pull out information about the size of the study or the effect size as this was an abstract-only review, and I can\u2019t make comments about how robust any of these studies were. [Again, this is why \u2018abstract-only reviews\u2019 are not a useful research tool, but it seemed like the least biased way of collecting information, and I only had a weekend.]</p>\n<h3>General findings</h3>\n<p>Firstly, I mentioned earlier on that this is a recent area of research interest. It\u2019s important to also mention that, therefore, it\u2019s influenced by early-adopters of this work i.e. the countries that developed an interest in SWB measures and so produced a lot of research from the get-go are over-represented in the available research. As wellbeing is highly subjective and context-dependent, this should be kept in mind when understanding the direction of research and how we draw conclusions from what's currently available. Where the country information was available in the title or abstract, here is the number of studies by country:</p>\n<p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/owM2obTsNiZHK2nu9/o1swnnspi81xcd2q0rly\" alt=\"Number of studies by country\"></p>\n<p>For anyone who prefers a visual representation of the research share for single-nation studies:</p>\n<p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/owM2obTsNiZHK2nu9/tidsbxrj11csxneiilrj\" alt=\"Number of studies by country\"></p>\n<p>As well as this being one of the prettiest pie charts I\u2019ve ever made, it demonstrates a few countries hold a lot of wellbeing research territory at present.</p>\n<p>In case anyone skipped me talking about this in an earlier section, in these 286 studies, I found 41 different SWB scales being used, and a number of studies using bespoke questionnaires or interviews collecting non-numerical (qualitative) data to describe subjective wellbeing. Lots of studies used more than one SWB measure.</p>\n<p>It\u2019s worth mentioning that many of these studies were focussed on very specific groups e.g. rural-to-urban older adult migrants, or specific ages e.g. adolescents, or specific circumstances e.g. mothers of children &lt;18y with autism spectrum disorder. How useful any of this information is taken out of that context is debatable, but I found it interesting to see what the researchers <em>thought</em> might be related to wellbeing, to judge my finger-in-the-air style guesswork that otherwise is based on a \u2018trust me, bro\u2019 of my clinical experience.</p>\n<p>What also became clear to me from wading through these abstracts, is that it\u2019s difficult to really tease out a \u2018causal\u2019 relationship i.e. to say XYZ results in better or worse wellbeing. To give an example, there were a fair few studies which found that physical activity was related to greater SWB. Does this mean exercise improves wellbeing? It might also mean that people who have good wellbeing are more likely to engage in exercise. If it was just about activity, should we expect manual labourers, service industry workers, cleaners, etc to therefore have higher wellbeing as they have active jobs? Or, is it that people who regularly exercise have a higher income/socio-economic status, or just aren\u2019t sick and therefore able to exercise \u2013 and perhaps it\u2019s just that wealthy people with no health problems are likely to have high wellbeing, whilst also engaging in regular exercise.</p>\n<p>In simple terms, lots of variables can coincidentally relate to higher SWB, some might interact with other variables (i.e. have a greater impact on wellbeing as a system vs the sum of their parts), and some are likely unhelpful taken out of context with other issues we know impact wellbeing.</p>\n<h3>The non-scientific literature review</h3>\n<p>I took my proposed framework and saw what studies were out there to validate it. Some concepts I think could be debated into where they fit in the matrix \u2013 it\u2019s my best approximation but, as an example, \u2018low SES\u2019 spans multiple domains in terms of autonomy, security, time-allocation and equality.</p>\n<p>Here is a summary of the 286 studies, with the number of studies which identify the same factor as worsening wellbeing (No.), the number of studies showing conflicting results/no effect (No. con) and any mitigating/moderating factors.</p>\n<p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/owM2obTsNiZHK2nu9/wdw2ifldcaojgzmu7jlv\" alt=\"Image alt-text\">\n<img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/owM2obTsNiZHK2nu9/pjdhzxao2oyxsziyp122\" alt=\"Image alt-text\">\n<img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/owM2obTsNiZHK2nu9/pb9u2puop8jir3qfnxoj\" alt=\"Image alt-text\">\n<img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/owM2obTsNiZHK2nu9/uetm8j9nnksnbl9m8tow\" alt=\"Image alt-text\"></p>\n<p>A number of studies identified relevant factors for considering spillover effects:</p>\n<p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/owM2obTsNiZHK2nu9/ngepsgwpfwifjcsbleyo\" alt=\"Image alt-text\"></p>\n<p>Of course, there was a large number of factors which didn\u2019t fit my matrix that appeared in research:</p>\n<p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/owM2obTsNiZHK2nu9/w6ljaai9bcgst9disjkl\" alt=\"Image alt-text\">\n<img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/owM2obTsNiZHK2nu9/of7alzlkhfaktlzsmevq\" alt=\"Image alt-text\"></p>\n<p>So, for the sake of transparency, I did alter my matrix following this research in one domain \u2013 while I had included leisure time in my initial framework, I hadn\u2019t considered having time for purposeful or meaningful activity. For readability, I altered my \u2018guess\u2019 in this regard but this was a post-review addition. It was a blind spot, and I think it was based on my own biases i.e. as a doctor, I perhaps take it for granted I find my work meaningful. I know 80000 hours may disagree, but it doesn\u2019t change the way I perceive my work, how I derive value from my job, and generally think working in medicine, in psychiatry in particular, and in the NHS, reflects my personal values. It\u2019s easy to take for granted, but being able to spend my work hours in this way is perhaps a privilege others cannot enjoy.</p>\n<p>Perhaps less overt biases are coming into play, but finding the factors which didn\u2019t neatly fit my matrix (after correcting that oversight) did not lead me to doubt myself. I\u2019m not arguing any of that work is invalid or irrelevant, but for the purposes of the matrix, I didn\u2019t feel bad for excluding them. Happy to be challenged, but here\u2019s (quickly) why:</p>\n<ul>\n<li>It seems plausible to me that due to innate/genetic factors people have traits or overall \u2018good wellbeing\u2019 genes which means they are naturally prone to rate their wellbeing higher. This, as well as other immutable characteristics (e.g. age) aren\u2019t changeable if considering wellbeing interventions.</li>\n<li>Other internal factors e.g. coping skills, emotional intelligence, I felt could be related to spillover effects from childhood experiences or childhood/adult adversity, or similarly be innate. My personal bias is that problem-focussed interventions to \u2018improve self-esteem\u2019 and the like are less helpful than general measures to allow children opportunities and environments to thrive within.</li>\n<li>In terms of situational/external factors, I felt many of these (natural disasters, \u2018stress\u2019) are unavoidable in normal life, and others (having children, getting married) probably shouldn\u2019t be mandated. While it\u2019s important to consider when people may require additional support, I think \u2018wellbeing\u2019 should be incorporated in larger discussions about disaster/future preparedness i.e. it could be considered along the matrix, but shouldn\u2019t form part of it</li>\n<li>In terms of the behavioural factors, I alluded to this above in considering if these are \u2018causative\u2019 factors or not.</li>\n<li>The only exception is probably thinking about living standards, local environment, access to greenspace, pollution, etc which are very much not \u2018people problems\u2019 but \u2018societal problems\u2019 and likely related to SES, income, etc. It\u2019s likely a limitation of my people-centred wellbeing matrix if this doesn\u2019t weight appropriately in other measures (Leisure, Equality, Security i.e. adequate shelter, safe neighbourhood and ability to spend time in nature).</li>\n</ul>\n<p>Overall, I felt my matrix held up reasonably well as a way of categorising existing SWB research, and my assumptions weren't too wild to be unsupported in literature.</p>\n<h2>How could my framework be helpful in practice?</h2>\n<p>To further expose my agenda: I do think mental illnesses have a huge impact on wellbeing, and historical measures of quality of life have somewhat underestimated their impact. I generally think using a wellbeing approach helps to accurately judge the impact of these conditions; while schizophrenia and bipolar affective disorder are related to significantly reduced life expectancy (not due to suicide), mental illnesses rarely cause physical impairments or direct mortality.</p>\n<p>To take the matrix and use it in practice (0 = death, 1 = year at wellbeing baseline) for depression, based on my clinical experience:</p>\n<p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/owM2obTsNiZHK2nu9/f4l37i720pqyg1eajalt\" alt=\"Image alt-text\"></p>\n<p>It\u2019s slightly reassuring my \u2018guesses\u2019 weren\u2019t too outrageous compared to the existing DALY weightings (I guess you have to trust I wasn\u2019t cheating), but also not so similar it made all of this a completely pointless exercise.</p>\n<p>To be brief, rather than just looking at \u2018years lost\u2019 or how unpleasant one judges an illness or impairment to be, a matrix allows an illness like depression to be considered more holistically:</p>\n<ul>\n<li><em>Health</em> \u2013 Depression is an illness, and results in lots of \u2018unpleasant\u2019 symptoms \u2013 low mood, fatigue, disturbed sleep, distorted perceptions of the world, and intrusive, negative thoughts. It can also affect appetite, and seems to compound the negative effects of other illnesses (e.g. post-MI (heart attack) depression)</li>\n<li><em>Autonomy</em> \u2013 At the more severe end, people can find it difficult to function and make choices for themselves; they can end up in hospital</li>\n<li><em>Security</em> \u2013 Depression is a common reason for people to miss work, have difficulty getting back into work (i.e. risks financial security), and at the more severe end people can have difficulty caring for themselves (i.e. maintaining adequate food and fluid intake, accessing healthcare). It can also strain close relationships.</li>\n<li><em>Time</em> \u2013 Depression causes fatigue and also leads to people being unable to enjoy activities they used to, it\u2019s common to withdraw from these pursuits and also from social interaction i.e. while the amount of time they have doesn\u2019t change, they will be unable to spend this in leisure pursuits or meaningful activity with more severe depression</li>\n<li><em>Equality</em> \u2013 With this being relatively common and discussed, it\u2019s unlikely milder forms of depression will result in inequality. Again, for the severe end, this could be stigmatising e.g. if people cannot maintain self-care, lose status at home/work or end up in hospital</li>\n<li><em>Despair</em> \u2013 At the more severe end, depression can lead to suicidal thoughts and acts, so this should qualify for a catastrophic multiplier (currently arbitrary as not standardised across other conditions)</li>\n</ul>\n<p>For \u2018spillover\u2019 effects, using a systems-approach: having a loved one suffering with depression is worrying, and this is more worrying the more unwell a loved one is. Similarly, the increasing loss of functioning because of more severe depression leaves others in the household taking on their responsibilities to keep the system functioning.</p>\n<p>A system-approach allows for consideration of times where someone suffering with depression has particularly bad effects on other members of the household. If someone is the main income-provider, one could imagine the threat to financial security is particularly acute for all household members. Similarly, for anyone with caring responsibilities, struggling to function will be particularly bad for those they care for. This tends to be the reasoning behind active screening for postnatal depression as this affects the care, bonding and emotional/social development of the infant when untreated. It is then highly cost-effective to treat postnatal depression, not just for the mother\u2019s wellbeing, but all the benefits this has for the infant. Outside of this specific example, parental mental health clearly has an impact on children (poverty of close relationship, threats to security) and it\u2019s therefore particularly important to address mental health needs of parents with young children for their wellbeing throughout life.</p>\n<h3>Measuring interventions</h3>\n<p>It follows that effectively treating depression improves the wellbeing of the person suffering from depression and, to some degree, their household. If you then wanted to roll out a scheme e.g. a local programme for people to access free cognitive-behavioural therapy (CBT) for depression, and wanted to judge how cost-effective this would be for wellbeing, I guess it would be along these lines:</p>\n<ul>\n<li>Firstly, you would need to know the cost of this scheme i.e. setting up the scheme, training people to deliver CBT, spaces/technology for people to have CBT. You then need to predict how many people could be seen in one year</li>\n<li>Then you would need to know the prevalence of depression in the community (roughly) i.e. how many people this could potentially benefit in the longer-term, as well as the \u2018average severity\u2019 of depression in sufferers. For spillover effects, it might be helpful to know the prevalence in working-age adults, parents, etc.</li>\n<li>With that information you know how many people could get the free CBT in a year, and multiply this by the \u2018wellbeing impact effect\u2019 of the average severity of depression e.g. the service can see 1000 people in a year, the average severity is \u2018moderate\u2019 (0.6 wellbeing-adjusted impact years), so therefore there are potentially 400 WAIYs you could get out of this intervention</li>\n<li>Let\u2019s say 50% of people do recover completely with CBT (guess stolen from <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5942544/\">here</a>) \u2013 that gives you 200 WAIYs</li>\n<li>Of the remaining 500 people, another 160 show a reliable improvement (i.e. they are still depressed but they are now mildly depressed vs severely). 160 people being mildly depressed (0.88) vs moderately depressed (0.6) gives you an additional 44.8 WAIYs \u2013 a total benefit for the intervention of <strong>244.8 WAIYS</strong> per year for the cost of providing CBT.</li>\n<li>You can similarly model spillover effects to work out the likely benefits to wider household members/community e.g. in reducing unemployment.</li>\n</ul>\n<p>Obviously, it\u2019s based on a lot of guesswork, so you\u2019d want to collect more detailed information to understand the service when it\u2019s up and running i.e. then you could see how many people are accessing the service with different severities of depression, their recovery/improvement rates and then judge the true impact on WAIYs vs the estimate.\nYou could then assign a cash value for what one WAIY is worth to see if this is greater than the costs, or have a minimum cost-per-WAIY hurdle that interventions have to meet in order to be considered \u2018worthy\u2019 of public funding. You could compare this to other treatments for depression to see if this is the best use of money.</p>\n<p>One quick diversion to release the bee in my bonnet - I would discourage the assumption that psychotherapy does not result in harm and so there is no need to consider this in CEAs. Firstly, we do know that a fraction of people deteriorate during treatment (whether or not this is due to the therapy itself). It also seems like a logical fallacy to assume harm cannot occur \u2013 if talking to someone can improve one\u2019s mental health, it makes sense that talking to someone can worsen one\u2019s mental health. Again there are clear examples of this \u2013 it used to be commonplace to offer debriefing sessions following a traumatic event; it has since been demonstrated this is, at best, unhelpful, and at worst <a href=\"https://www.cochrane.org/CD000560/DEPRESSN_psychological-debriefing-for-preventing-post-traumatic-stress-disorder-ptsd\">increases the risk of PTSD</a>. It is clinically accepted that therapy can \u2018destabilise\u2019 people i.e. talking about painful memories can make people feel worse before they feel better, and so if people are in crisis, therapy is contraindicated without a robust safety net (which may not be available in resource-poor settings). Similarly, assuming it is universally helpful is an error \u2013 some people do not want therapy, some will not be able to reliably attend due to work/family commitments, and the rates of non-improvement, deterioration and drop-out before the minimum number of 'effective' sessions needs to be included.</p>\n<p>Usually there are guardrails around therapy\u2019s harms, because if therapy is having a non- or adverse effect, people will drop out. However, this makes evaluating risks difficult because those who drop out of therapy do not complete outcome measures. This is also the risk of using the wrong form (or modality) of therapy, especially if providing this as the only treatment option in resource-poor settings e.g. if you provide a therapy only suited for mild depression, you can imagine that people actually suffering more from another illness, or more severe depression, will get worse or not improve while still trying to engage as there's nothing else.</p>\n<p>If adopting a task-shifted approach (i.e. you ask non-clinicians to deliver therapy), you have to factor in adequate support for the person expected to take on these therapeutic relationships, and in some populations you can imagine they will encounter a much higher burden of patients who have had traumatic experiences than what is captured in RCTs in other settings \u2013 it may directly harm those delivering the therapy to put them in that position, and similarly a lack of support/supervision can lead to even trained therapists straying into counter-therapeutic territory to harm those accessing it. If a therapy group collapses because it can\u2019t be managed safely by a non-clinician, this will likely make everyone in the group worse. And then what?</p>\n<p>But, back on topic, for a fairer CEA, you would need to factor in the service being underfilled (e.g. if the country was completely opposed to CBT on principle, or your scheme was completely impractical in its implementation). You would also need to collect data on how many people dropped out (assuming no effect in the remaining people otherwise unaccounted for) and who got worse.</p>\n<ul>\n<li>Again, stealing data from the above paper, 6% of people got worse; let\u2019s say they become severely depressed (0.2) vs moderate (0.6). -24 WAIYs, for a net total of <strong>220.8 WAIYs</strong></li>\n<li>To be fair, you should also compare this against the alternative i.e. what is the likely outcome of these 1000 people not having free CBT in terms of rates of spontaneous recovery (adjusted for time spent sick vs time to recovery/improvement with CBT) and deterioration which might produce an even stronger argument for the CEA of the intervention if you show, without the service, we expect X number of people to get worse.</li>\n</ul>\n<p>However, this essentially works best when I can gauge the acceptability, uptake and benefit of my intervention with reasonable reliability. If I was thinking about providing CBT to an LMIC setting, I would have to proceed with more caution given the issues I raised with RCTs in judging whether CBT is similarly helpful as an intervention in an LMIC and my lack of lived experience within an LMIC.</p>\n<p>The greater issue, though, is me stating that for this amount of money, this intervention for depression is the best way to improve your (population of LMIC\u2019s) wellbeing. It's based on my assumptions about wellbeing from my perspective, and in the name of subjectivity, I could be completely wrong. I could try and support locally run research to collect more data to be sure of my assumptions, or impose an external RCT and accept it could be misleading. However, this doesn\u2019t really address the fact that I\u2019ve decided treating depression is the best use of funding in the first place, which means I\u2019ve not only made assumptions about depression\u2019s effect on wellbeing, but also every other problem that community might be facing i.e. I\u2019ve done a comparison WAIYs estimate for different issues, compounding my assumptions. I\u2019ve already admitted that the existing research into wellbeing is in its early days and heavily weighted by wealthy countries with different cultures and so it might not be that helpful in considering something like CBT in an LMIC.</p>\n<p>Unless I decide wellbeing isn\u2019t that important to consider and it\u2019s worth waiting (likely) decades for this research to come to fruition, it is always going to involve a certain amount of guesswork. However, it also seems to me that the focus on \u2018subjective\u2019 wellbeing can allow for more direct measures via trade-offs. I could, as an example, go to a community I think might benefit from my free-CBT scheme, screen people for depression and find some eligible participants. I could explain CBT and all of its benefits, and that I think they are depressed and this could help them (50% chance of recovery! 66% chance of improvement!). I could then offer the CBT, or the equivalent cash-value sum of providing the therapy \u2013 if no one chooses the CBT, it suggests it\u2019s not worth the money to the people I\u2019m trying to help. I could even return in a couple of months, find these people, screen them again and offer the money vs money plus CBT if I want an even better idea of how to judge my intervention\u2019s \u2018subjective\u2019 benefits.</p>\n<p>This is at least an up-front approach which avoids coercing people into CBT, and provides quite an honest CEA i.e. am I better off just taking the money I would have spent on therapy and giving it directly to this community if I want to do what they would find most helpful? Or should I be considering a way of providing access to those that want CBT but factoring the costs for people to attend if I want to make this work? E.g. if they can\u2019t spare the time away from work/family commitments without financial compensation, but would benefit from CBT, should I be offering compensation/childcare.</p>\n<p>Either way, there has to be some way of involving local communities and allowing them to provide feedback if there is going to be any argument for CEAs in directly improving \u2018subjective\u2019 wellbeing.</p>\n<h2>What would I be suggesting as research areas for maximal gains in wellbeing from my biased perspective?</h2>\n<p>I thought from my biased/blinkered UK psychiatry perspective on what I would be thinking were potential areas for funding which would have the greatest impact on wellbeing from my assumptions. While my framework has been informed by subjective wellbeing approaches, the overall matrix is an \u2018objective\u2019 overview of \u2018subjective\u2019 wellbeing. These are things I think generally would have great effects, potentially globally, with the caveat that I wouldn\u2019t suggest these are priorities in LMICs specifically \u2013 this must involve local involvement and a great deal more research. [Generally addressing the global mental health gap is unlikely to be low-impact (provided it\u2019s done thoughtfully with involvement of the communities affected).]</p>\n<p>If I had to pick my top three:</p>\n<h3>Psychosis/Schizophrenia research</h3>\n<p>While there are arguments for mental illnesses having a strong societal context, schizophrenia is relatively consistently prevalent around the globe (1%). This is a very disabling illness, particularly for people who have \u2018negative symptoms\u2019 which is common in chronic forms of schizophrenia, and acute episodes (psychotic episodes) are highly distressing for people to experience. The current treatments are various shades of problematic (either due to Parkinson\u2019s-type side effects, or due to metabolic side effects e.g. resulting in obesity, diabetes, heart disease). It tends to first present when people are young (i.e. late teens/early twenties) and therefore can affect people in work or higher education, or those with dependent children (thinking of spillover and autonomy).</p>\n<p>It has a variable life course \u2013 some have one episode of psychosis and get better, some have a relapsing/remitting illness, and others have a progressively disabling course. Some people will have treatment-resistant schizophrenia i.e. it does not respond to multiple trials of antipsychotics, and therefore are eligible for clozapine (another antipsychotic which works better than others, but has a risk of serious complications and so requires intensive monitoring of blood tests and heart health). A good proportion (60%) respond, but others do not. Schizophrenia remains highly stigmatised as an illness, reduces life expectancy, and can lead to protracted hospital admissions.</p>\n<p>Generally, it feels we are barely scratching the surface of understanding this illness properly and are sorely in need for better treatments. Regardless, it\u2019s important to ensure timely treatment if someone does become unwell (as the duration of untreated psychosis is a significant factor for how well and how quickly someone recovers) and to support them in returning to their usual activities. There\u2019s ongoing research about earlier use of clozapine for this reason (i.e. not waiting for two treatments to fail), or genetic testing for antipsychotic response, and other ways to make antipsychotic/clozapine treatment less invasive e.g. finger-prick blood monitoring. CBT for psychosis is relatively new and has some very good wellbeing-oriented results, as does family-based therapy.</p>\n<p>This is a high-impact area where research and advances in treatment could be high-yield.</p>\n<h3>Interventions aimed at women of childbearing age to empower control over pregnancy, and generally any intervention to benefit young children</h3>\n<p>I don\u2019t want to risk over-simplifying a very fraught topic, but this <a href=\"https://www.pause.org.uk/\">UK-based charity</a> has a lot of information to help understand the issues women face in trying to \u2018break the cycle\u2019 if they have children removed from their care (often due to being in a violent relationship, or mental health/substance misuse problems). I would endorse any supportive measures for safely escaping domestic violence, etc; or proactively engaging vulnerable women or those at risk of exploitation in discussions about long-acting reversible contraception if desired. While children\u2019s mental health services are important, I personally find it hard to reconcile children who are born into very difficult situations receiving support for their mental health (which is not really addressing the reasons they may be suffering) or interventions from social care, but this drops away after they turn 18 and they go on to have children themselves. I feel this leads to an odd disconnect between support for children in \u2018bad homes\u2019 but seeming indifference or derision towards parents/mothers who are unable to provide a supportive environment.</p>\n<p>Based on what I\u2019ve said about spillover effects, it seems these problems should be addressed in tandem \u2013 women should have a supportive environment where they are more able to exercise control over pregnancy and choice of partner, and difficulties the parents face need to garner the same amount of support (regardless of the effects on the child) to ensure children are in an environment to promote their wellbeing in the long-term.</p>\n<h3>Psychedelics in palliative care</h3>\n<p>Alright, I don\u2019t really see this as a key priority, but it\u2019s something I surprised myself with. To keep it short, I\u2019ve been highly sceptical about psychedelic-assisted psychotherapy \u2013 I am keeping an open mind, but so far the research I\u2019ve come across has been unconvincing (you can\u2019t \u2018blind\u2019 any trials, recruitment is often targeted to people curious/believing in psychedelics), and I still remember the hype about \u2018micro-dosing\u2019 which has since been debunked. For what it\u2019s worth, I\u2019m pro-legalisation for the sake of these drugs not being as harmful as alcohol, I just dislike the \u2018medicalisation\u2019 route. It ends up leading to a politicisation of medicine (e.g. medical cannabis being recommended for a range of problems with absolutely no basis in evidence) which completely taints any discussion about harms/benefits.</p>\n<p>I also generally think the impact of psychedelic-psychotherapy is fairly minor and likely costly, the proposed application of psychedelics requires controlled administration (i.e. in a clinical environment) alongside relatively intensive psychotherapy which makes it likely to favour relatively wealthy people, not in crisis, with jobs which will allow them to work around these sessions. Obviously in certain groups/situations it could be very useful (i.e. survivor\u2019s guilt in PTSD), but the research isn\u2019t quite there yet, in my entirely personal opinion.</p>\n<p>However, in my trawl through all the wellbeing research and evaluating my framework, I did come across a couple of tangentially-related studies about the effects of psychedelics in promoting positive attitudes to death and reducing existential fear (i.e. despair). With even a one-off dose of LSD having <a href=\"https://pubmed.ncbi.nlm.nih.gov/28918441/\">relatively enduring effects</a>. It makes sense to me to consider the use of psychedelics for people with life-limiting illnesses (e.g. in palliative care), or perhaps in the elderly more conservatively. Palliative care is set-up to be more holistic and spiritual, and opening conversations about death is very much their strength (I\u2019d argue much more appropriately than thinking of this in psychotherapy).</p>\n<p>Reducing fears, anxieties and existential dread could have significant gains in palliative care, and may reduce the use of opiates and other drugs which negatively affect wellbeing outside of limiting pain i.e. they are sedating, cause constipation, and interfere with enjoyment of life. Pain is highly related to anxiety (one of the first surgical \u2018anaesthetics\u2019 used was Valium), and it\u2019s not uncommon for people to feel physical pain as a result of psychological distress (tension headache is the classic example), so it wouldn\u2019t seem too far-fetched to imagine psychedelics could have a hugely beneficial effect on wellbeing in this context.</p>\n<h2>Final thoughts</h2>\n<p>Thank you to anyone who has spent time reading my earnest, but likely misinformed, approach to wellbeing as it relates to mental health. I\u2019d be interested to know how far I\u2019ve strayed off track, or if there is any weight to my general argument: having an evaluative framework based on subjective concepts of wellbeing (allowing synthesis of existing research and providing the skeleton for these cross-comparisons) is useful. I think the end result \u2013 producing something which could be considered a \u2018tweak\u2019 of the DALY to better reflect subjective concepts of wellbeing is a little easier to adopt and understand than creating something completely new.</p>\n<p>[References linked in-line as this is long enough! Sorry my Word tables have formatted quite badly.]</p>\n", "user": {"username": "LondonGal"}}, {"_id": "ptY8aRiyCj3NbuTeY", "title": "The value of cost-effectiveness analysis (David Thorstad)", "postedAt": "2023-07-29T22:54:51.473Z", "htmlBody": "<p>A few years ago, some EAs dismissed interventions like political action on the grounds that they had no detailed cost-effectiveness analysis.</p>\n<p>Section 5 of this post wonders why some of these same people are now willing to promote longtermist interventions that have no such analyses (or whose analyses are, let's say, light on the details):</p>\n<blockquote>\n<p>Did effective altruists discover some powerful new arguments against cost-effectiveness analysis that they were previously unaware of? Did they simply re-evaluate the strength of arguments against cost-effectiveness analysis that they had previously rejected. Perhaps. It would be good to hear more about what these arguments are, and where and when they became influential. Otherwise, critics may have some grounds to suspect the explanation for effective altruists' changing attitudes towards cost-effectiveness analysis is sociological rather than philosophical.</p>\n</blockquote>\n<p>I'm one of the flip-floppers myself, and my own best answer is that I re-evaluated the strength of the arguments. But I completely agree with Thorstad that the whole situation smells like motivated reasoning.</p>\n<p>I remember Holden Karnofsky once explaining it differently: he started out with a narrow focus because that's what was tractable at the time, and broadened his focus when he learned more. He never insisted on cost-effectiveness analysis from a philosophical standpoint, only a practical standpoint. (Apologies if I'm mischaracterizing his views.)</p>\n<p>Interested to hear others' thoughts.</p>\n", "user": {"username": "smountjoy"}}, {"_id": "ehAwQrCBhaefdBbbo", "title": "Most Effective Methods for My Problem Areas", "postedAt": "2023-07-29T16:42:12.143Z", "htmlBody": "<p>I completed the 80,000 Hours career guide. My primary problem area interests are emotional intelligence, promoting effective altruism, promoting positive values, and mental health.&nbsp;</p><p>Based on the career guide exercises, I think that advancing social-and-emotional learning (i.e., improving education) is one of the best methods for these problem areas. There are many SEL organizations that I would like to get involved with possibly as a professor.&nbsp;</p><p><i>Note: If you do not know what social-and-emotional learning is, look it up.</i></p><p>I think that communicating ideas around solving these problems through the media is an effective method as well (i.e., being an influencer). However, emotional intelligence - which includes my other problem areas - is not nearly as neglected in the media as it is in education. There is a lot of videos and books about motivation, hard work, happiness, anxiety, managing emotions, etc.</p><p>Currently, I am stuck on whether I should focus on education or the media or both. What do you think is/are the most effective method(s) for these problem areas (focused around emotional intelligence)?</p>", "user": {"username": "Cole123"}}, {"_id": "QahDdRzpPuat8ujx2", "title": "Why isn't there a charity evaluator for longtermist projects?", "postedAt": "2023-07-29T16:30:12.762Z", "htmlBody": "<p>i.e., Why isn't there an org analogous to GiveWell and Animal Charity Evaluators that evaluates and recommends charities according to how much impact they can have on the long-term future, e.g. by reducing existential risk? As opposed to only making grants directly and saying \"just trust us\" like the EA Funds.</p>", "user": {"username": "evelynciara"}}, {"_id": "vsmwFn5gMkKeRmCfA", "title": "The Parable of the Dagger - The Animation", "postedAt": "2023-07-29T14:03:12.081Z", "htmlBody": "", "user": {"username": "Writer"}}, {"_id": "ZQ77uGtKX8mR4vtxo", "title": "The Ultimate Argument Against Deontology And For Utilitarianism", "postedAt": "2023-07-29T09:36:07.676Z", "htmlBody": "<p><a href=\"https://benthams.substack.com/p/the-ultimate-argument-against-deontology\">Crossposted </a>to my blog. &nbsp;The formatting is a bit better there. &nbsp;</p><p>Very often, our intuitions about principles will conflict with our intuitions about cases. Most people, for example, have the following three intuitions:</p><p>The world would be improved if one person died and five others were saved.</p><p>If some action makes the world better, it isn\u2019t wrong.</p><p>You shouldn\u2019t kill one person to save five.</p><p>These are, however, inconsistent. In addition, as <a href=\"https://benthams.substack.com/p/michael-huemer-should-be-a-utilitarian\"><u>I\u2019ve </u></a>documented extensively, deontology\u2014and more broadly any theory that believes in rights\u2014requires giving up belief in dozens of plausible principles. Let me just list several:</p><ol><li>Perfectly moral beings <a href=\"https://rychappell.substack.com/p/a-new-paradox-of-deontology\"><u>shouldn\u2019t hope you do the wrong thing</u></a>.</li><li><a href=\"https://benthams.substack.com/p/is-moderate-deontology-problematically\"><u>The fact that some act would give perfectly moral beings extra options doesn\u2019t make it worse, all else equal</u></a>.</li><li><a href=\"https://www.utilitarianism.net/arguments-for-utilitarianism#agency-as-a-force-for-good\"><u>Doing the right thing won\u2019t make things worse.</u></a></li><li><a href=\"https://philpapers.org/archive/HUEAPF.pdf\"><u>If X is wrong and Y is wrong conditional on X, then X and Y are wrong.</u></a></li><li><a href=\"https://www.utilitarianism.net/arguments-for-utilitarianism#arguments-for-utilitarianism\"><u>If some action would be done if you experienced everything experienced by anyone, or if you were behind the veil of ignorance, and was also approved of by the golden rule, that action is right.</u></a></li><li><a href=\"https://benthams.substack.com/p/another-paradox-of-deontology\"><u>If you do the wrong thing and you can undo it before it\u2019s affected anyone, you should.</u></a></li><li><a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2680537\"><u>If some action is wrong, and you can prevent it from happening at no cost, you should do so</u></a>.</li><li><a href=\"https://benthams.substack.com/p/is-it-good-when-more-people-are-endangered\"><u>It\u2019s bad when more people are endangered by trolleys.</u></a></li><li><a href=\"https://benthams.substack.com/p/deontological-norms-are-unimportant\"><u>Our reasons to take action are given by the things that really matter.</u></a></li><li><a href=\"https://benthams.substack.com/p/organ-harvesting-isnt-different-from\"><u>If you should do A instead of C, then it will never be true that some third option will make it so that you should do C instead. In other words, options that you don\u2019t take don\u2019t affect the desirability of the ones you do take.</u></a></li><li><a href=\"https://benthams.substack.com/p/suitcases-deontology-and-wishing\"><u>If some action makes everyone much better off in expectation</u></a>, you <a href=\"https://benthams.substack.com/p/two-more-pieces-of-serious-scholarship\"><u>should take it</u></a>.</li><li><a href=\"https://benthams.substack.com/p/huemers-paradox-of-deontologys-more\"><u>It\u2019s wrong to take lengthy sequences of immoral acts</u></a>.</li><li><a href=\"https://benthams.substack.com/p/moderate-deontology-requires-thinking\"><u>If some action causes others to do the wrong things, that makes it worse as opposed to better.</u></a></li><li><a href=\"https://benthams.substack.com/p/debate-with-truth-teller-part-1-my\"><u>If some action is wrong, then if a person did it while sleepwalking, that would be bad.</u></a></li><li><a href=\"https://www.utilitarianism.net/arguments-for-utilitarianism/#agency-as-a-force-for-good\"><u>Perfectly moral beings being put in charge of more things isn\u2019t bad.</u></a></li></ol><p>There are, of course, various other principles that one should give up on rather than these. But the ones I\u2019ve listed are the ones that are most plausible. And this only is the tip of the iceberg when it comes to arguments against deontology; there are many more. In addition, the same types of general arguments are available against other things that critics of utilitarianism believe in\u2014for example, those who believe in desert have to believe that what you deserve depends on <a href=\"https://benthams.substack.com/p/against-desert-part-2-moral-luck\"><u>how lucky you are</u></a> and that <a href=\"https://benthams.substack.com/p/against-desert-part-4-better-to-be\"><u>it\u2019s sometimes better to be worse</u></a>. But let\u2019s use rights as a nice test case to see just how overwhelming the case is for utilitarianism.</p><p>The argument above is the cumulative case against deontic constraints. But let\u2019s compare it to the cumulative case for deontic constraints, and then see which has more force. The argument for deontic constraints is that they\u2019re the only way to make sense of the following intuitions:</p><ol><li>It\u2019s wrong to kill a person and harvest her organs to save five people.</li><li>You shouldn\u2019t push people off bridges to stop trains from running over five people.</li><li>You shouldn\u2019t frame an innocent person to stop a mob from killing dozens of people.</li><li>It would be very wrong to kill someone to get money, even if that money could be then used to save lots of lives.</li><li>It\u2019s wrong to steal from people, even if you get more pleasure from the stolen goods than they lost.</li><li>It\u2019s wrong to torture people even if you get more pleasure from torturing them than they get pain from being tortured.</li><li>It\u2019s wrong to bring people into existence, give them a good life, and then kill them.</li></ol><p>So the question is which type of intuition we should trust more\u2014the intuitions about cases or the intuitions about principles. If we should trust the intuitions about cases, then deontology probably beats utilitarianism. In contrast, utilitarianism utterly dominates deontology when it comes to intuitions about principles. But it seems like we have every reason in the world to trust the intuitions about principles over the intuitions about cases (for more on these points, see Huemer\u2019s <a href=\"https://fakenous.substack.com/p/revisionary-intuitionism\"><u>great article</u></a> and the associated paper, Revisionary Intuitionism).</p><ol><li>Suppose that some intuition about principles was true. Well then, we\u2019d expect the principle to be counterintuitive sometimes, because principles apply to lots of cases. If our moral intuitions are right 90% of the time, then if a principle applies to ten cases, we\u2019d expect it to be counterintuitive once. Given that most of these principles apply to infinity cases, it\u2019s utterly unsurprising that they\u2019ll occasionally produce counterintuitive results. In contrast, if some case-specific judgment were right, it would be a bizarre, vast coincidence if it conflicted with a plausible principle. So we expect true principles to conflict with cases but we don\u2019t expect true cases to conflict with principles. As a consequence, when cases conflict with principles, we should guess that the principle is true and the judgment about the case is false.</li><li>We know that our intuitions constantly conflict. That\u2019s why ethicists disagree and there are moral conflicts. In addition, lots of people historically have been very wrong about morality, judging, for example, that slavery is permissible. So we know that at the very least, many of our judgments about cases must be wrong. In contrast, we don\u2019t have the same evidence for persistent error about principles. I can\u2019t think of a single intuition about broad moral principles that has been unambiguously overturned. So trusting the deontological intuitions over the utilitarian ones is trusting the intuitions that we know to be wrong over the ones that we don\u2019t know to be wrong. You might object by pointing out that utilitarians disagree with lots of broad principles, such as, for example, the principle that people have rights. But we don\u2019t intuit the principle itself\u2014and if we do, it\u2019s clearly debunkable, for reasons I\u2019ll explain in a bit. Instead, we infer it from cases. But this means the reason to believe in rights comes from intuitions about cases, which we know to often be wrong.</li><li>We know that people\u2019s moral beliefs are hugely dependent on their culture. The moral intuitions of people in Saudi Arabia differ dramatically from the intuitions of people in China, which differ dramatically from the intuitions of people in the U.S.. So we have good reason to expect that what we think are genuine moral intuitions are often just reflections of culturally transmitted values. But none of the principles I gave has any plausible cultural explanation\u2014there is no government document that declares \u201cthe fact that some act would give perfectly moral beings extra options doesn\u2019t make it worse, all else equal.\u201d No one is taught that from a young age. In contrast, norms about rights are hammered into us all from a young age\u2014the rules taught to us from the time we are <i>literally babies</i> are deontological. We are told by our teachers, parents, and government documents that people have rights\u2014and if you doubt that, it\u2019s seen as a sign of corrupt character (I remember one debater who attempted to paint me as a terrible person declared that I \u201cliterally don\u2019t think anyone has human rights.\u201d) We are told not to take the toys of others, not to only take away their toys if doing so is optimific. So it\u2019s not hard to explain how we would come to have these intuitions even if they were bullshit. In contrast, there is no remotely plausible account of how we came to have the intuitions that, if accepted, lead us inescapably to utilitarianism.</li><li>We know that our moral beliefs are often hugely influenced by emotions. Emotions can plausibly explain a lot of our non-utilitarian beliefs\u2014contemplating genuine homicide brings out a lot of emotion. In contrast, the intuition that \u201cif it\u2019s wrong to do A and wrong to do B after doing A, it\u2019s wrong to do A and B,\u201d is not at all emotional. It seems true, but no one is passionate about it. So very plausibly, unreliable, emotional reactions can explain our non-utilitarian intuitions. Our desert-based intuitions come from our anger towards people who do evil; our rights-based intuitions come from the horror of things like murder. We have <a href=\"https://benthams.substack.com/p/utilitarianism-wins-outright-part-c19\"><u>lots of evidence for this</u></a>\u2014we know, for example, that when people\u2019s brains are damaged so that they are less emotional, they become almost 6 times more likely to support pushing the fat man off the bridge to stop six.</li><li>We know that humans have a <a href=\"https://r.jordan.im/download/philosophy/huemer2008-2.pdf\"><u>tendency to overgeneralize </u></a>principles that are usually true. Huemer gives a nice example of the counterfactual theory of causation\u2014intuitively a lot of people believe a simple counterfactual model of causation, that has clear counterexamples\u2014I\u2019ll provide the full quote in a footnote<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefe9tkfs3lgb8\"><sup><a href=\"#fne9tkfs3lgb8\">[1]</a></sup></span>. But this tendency can explain every single non-utilitarian intuition. It\u2019s obviously almost always wrong to kill people. And so we infer the rule \u201cit\u2019s wrong to kill,\u201d even in weird gerrymandered scenarios where it\u2019s not wrong to kill. Every single counterexample to utilitarianism seems to involve a case in which an almost universally applicable heuristic doesn\u2019t apply. But why would we trust our intuitions in cases like that? If we think about murder a million times, and conclude it\u2019s wrong all of those times, then we infer the rule \u201cyou shouldn\u2019t murder,\u201d even if there are weird scenarios where you should. That\u2019s why when you <a href=\"https://rychappell.substack.com/p/ethically-alien-thought-experiments?utm_source=%2Fprofile%2F32790987-richard-y-chappell&amp;utm_medium=reader2\"><u>modify a lot of the deontological scenarios</u></a> so that they are less like real-world cases, our intuitions about them go away. You might object that utilitarian principles can also be explained in this way. But the utilitarian principles aren\u2019t just attempts to generalize our intuitions about cases\u2014we have an independent intuition that they\u2019re true, before considering any cases. The reason we think that perfectly moral beings shouldn\u2019t hope you do the wrong thing is not that there are lots of cases where perfectly moral beings hope you do particular things and we also know that those things are rights. Instead, it\u2019s that we have an independent intuition that you should want people to do the right thing\u2014but that means that we don\u2019t acquire the intuition from overgeneralizing, or from generalizing at all. The intuitions supporting utilitarianism don\u2019t rely on judgments about cases, but instead rely on the inherent plausibility of the principle itself.</li><li>We know that our linguistic intuitions affect our moral intuitions. We think things are wrong because they sound wrong. But the moral intuitions supporting utilitarianism sound much less convincing than the moral intuitions supporting deontology. No one recoils in horror at the idea that the fact that some action gives some perfectly moral person extra options is wrong. In contrast, people do recoil in horror at the idea that it\u2019s okay to kill and eat people if you get enough pleasure from it. Anscombe famously declared of the person who accepts that you should frame an innocent person to prevent a mob from killing several people, \u201cI do not want to argue with him; he shows a corrupt mind.\u201d So it\u2019s unsurprising that so many people are non-utilitarians\u2014the non-utilitarian intuitions sound convincing, while the utilitarian intuitions sound sort of boring and bureaucratic. No one cares much about whether \u201cif it\u2019s wrong to do A and then do B then it\u2019s wrong to do A and B.\u201d <a href=\"https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0094842\"><u>When people are given moral dilemmas in a second language</u></a>, they\u2019re more likely to give utilitarian answers\u2014this is perfectly explained by our non-utilitarian intuitions being dependent on non-truth-tracking linguistic intuitions.</li><li>Some of our beliefs have evolutionary explanations. Caring more about those closer to us, not wanting to do things that would make us directly morally responsible, and caring more about friends and family is easily evolutionarily debunked. But those intuitions are core deontological intuitions.</li><li>False principles tend to have lots of counterexamples, many of them being very clear. For example, the principle that you shouldn\u2019t do things that would be bad for everyone to do implies that you shouldn\u2019t be the first to cut a cake, move to a secluded forest, and that it\u2019s wrong to kiss your spouse (it would be terrible if everyone kissed your spouse). Often, you can derive straightforward contradictions from them. So when there is a principle without a clear counterexample\u2014as is true of these principles\u2014you should give it even more deference.</li><li>Our moral beliefs are subject to various biases. But it seems our deontological intuitions are uniquely subject to debunking. For example, humans are subject to status quo bias\u2014an irrational tendency to maintain the status quo. But deontological norms instruct us to maintain the status quo, even when diverging from it would be better. So we\u2019d expect to be biased to believe in deontic norms even if they weren\u2019t real.</li><li>Deontological norms seem like the norms we\u2019d expect one to adopt to rationalize a theory that tries to minimize being blamable. Our intuition that you shouldn\u2019t kill people to save five can be explained by you being blamable if you kill one but not blamable if you just fail to act\u2014after all, everyone is constantly failing to act all the time. But if our moral beliefs stem from rationalizing a course of action for which no one could criticize us, then they can be debunked.</li></ol><p>So it seems like we have overwhelming evidence against the trustworthiness of our deontological intuitions. It\u2019s not hard for a utilitarian to explain why so many intuitions favor deontology on the hypothesis that utilitarianism is true. In contrast, there is no plausible explanation of why we would come to have so many intuitions that favor utilitarianism if it were false. The deontologist seems to have to suppose that we make errors over and over again, with no explicable explanation, and the intuitions that are in error are the ones that are most trustworthy. This is miraculously improbable, and gives us very good reason to give up deontology.</p><p>Edit: After I wrote this, I realized it greatly resembled <a href=\"https://open.substack.com/users/32790987-richard-y-chappell?utm_source=mentions\">Richard Y Chappell</a>\u2018s <a href=\"https://rychappell.substack.com/p/three-arguments-for-consequentialism\"><u>master argument</u></a>. They\u2019re similar, but I think my argument is more sweeping and describes how the entire debate between utilitarians should be resolved. I also disagree with his master argument, but that\u2019s a story for another day.</p><p>&nbsp;</p><p><br>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fne9tkfs3lgb8\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefe9tkfs3lgb8\">^</a></strong></sup></span><div class=\"footnote-content\"><p>\u201cFor example, the following generalization seems initially plausible:</p><p>(C) For any events X and Y, if X was the cause of Y, then if X had not occurred, Y would not have occurred.</p><p>But now consider the following case: The Preemption Case: Two mob assassins, Lefty and Righty, have been hired to assassinate FBI informant Stoolie. As it happens, both of them get Stoolie in their sights at about the same time, and both fire their rifles. Either shot would be sufficient to kill Stoolie. Lefty\u2019s bullet, however, reaches Stoolie first; Consequently, Lefty\u2019s shot is the one that actually causes Stoolie\u2019s death. However, if Lefty had not fired, Stoolie would still have died, because Righty\u2019s bullet would have killed him.</p><p>This shows that there can be a case in which X is the cause of Y, but if X had not occurred, Y would still have occurred.\u201d</p><p>&nbsp;</p><p><br>&nbsp;</p></div></li></ol>", "user": {"username": "Omnizoid"}}, {"_id": "yBavn9rtThLFTfLoz", "title": "Fundamentals of Fatal Risks", "postedAt": "2023-07-29T07:12:37.776Z", "htmlBody": "<p>We must begin our serious discussion of fatal risks from the basic premise that we may need to change our strategies.</p><h1>The Misstep Named Balance</h1><p>Some people cannot escape the concept of balance when thinking about risks.</p><p>Balance refers to a rational strategy when there's a loss on one side and a benefit on the other.</p><p>It aims to balance both sides by giving a slight advantage to the benefits. If that balance can be maintained over time, even if losses occur occasionally, it indicates that overall gain is being achieved.</p><p>This model cannot handle fatal risks. Balance should only be considered a rational strategy if even a partial failure allows for an overall benefit. Walking a dangerous path with a cliff on the right side, in the name of maintaining balance, is not a rational strategy. It's reckless and by no means rational.</p><p>The term balance becomes a misstep when it comes to fatal risks. The wise do not approach fatal risks.</p><h1>The Misstep Named Risk Management</h1><p>Some people cannot escape the concept of risk management when thinking about risks.</p><p>Risk management refers to a rational strategy that involves managing the likelihood and impact of risks to minimize them while maximizing benefits.</p><p>If you manage to minimize risks and maximize benefits, you can eventually gain significant benefits. This way of thinking assumes that even if the minimized risk materializes, it's acceptable as long as the expected value favors benefits.</p><p>This model also cannot handle fatal risks. When risks materialize, no matter how much profit is made, it will always end up as a loss. Even if the risk probability is low, it's challenging to quantify the impact of fatal risks. Therefore, we cannot calculate the expected value. Thus, dealing with fatal risks through risk management is not a rational strategy. It's arrogant and by no means rational.</p><p>The term risk management becomes a misstep when it comes to fatal risks. The wise do not approach fatal risks.</p><h1>The Misstep Named Risk Minimization</h1><p>Some people cannot escape the concept of risk minimization when thinking about risks.</p><p>The idea is that it's good if risks can be minimized. However, this way of thinking lacks the concept of reducing risks to zero.</p><p>Fatal risks demand that risk zero is the baseline. If you cannot reduce fatal risks to zero, it should not be because you desire benefits. That would lead to the misstep named risk management. The only cases in which fatal risks cannot be reduced to zero are when other fatal risks increase. Only when suppressing other fatal risks does taking on fatal risks become rational.</p><p>By excluding benefits not involving fatal risks and considering other fatal risks, minimizing overall fatal risks becomes a rational strategy.</p><p>The term risk minimization becomes a misstep when faced with a single fatal risk. The wise only consider risk minimization when facing multiple fatal risks.</p><h1>The Gap Between Impossible and Difficult</h1><p>Sometimes people say that achieving risk zero is difficult. Indeed, it is difficult. But if we look at that fatal risk alone, it's not impossible. If we don't take the risk, the risk of the adventure is zero.</p><p>On the other hand, some people suggest that we should strive to keep fatal risks from materializing by controlling them. However, it's almost never guaranteed that we can control everything completely. Overlooking risk modes, human errors, and the emergence of unexpected new risks make it nearly impossible to handle everything flawlessly in most cases.</p><p>We need to focus on the gap between the words difficult and impossible. They are entirely different. Difficulties can be overcome. But what is impossible cannot be made possible. This difference is vast. Exceedingly so.</p><p>Therefore, while the difficulty of avoiding risk and the impossibility of full risk control may seem similar in wording, it's crucial to understand that there's a decisive break between them in reality.</p><p>The Dichotomy between Logical Impossibility and Empirical Impossibility</p><p>There are two types of 'impossible': logically impossible and empirically impossible.</p><p>In the case of logical impossibility, it is absolutely never possible.</p><p>However, empirical impossibility might be logically possible. The probability is not zero. In other words, it can be rephrased as 'difficult'.</p><p>The dichotomy between these two types of impossibility is larger than the impression of the word itself. Therefore, when faced with the word 'impossible', it's essential to clearly distinguish between these two.</p><h1>The Dual Difficulty in Dealing with Existential Risks</h1><p>When it's difficult to both cease the adventure to make the existential risk zero and also take measures while adventuring to make the existential risk zero, the best strategy becomes to exert effort on both fronts.</p><p>In particular, the effort to stop the adventure is important. Stopping the adventure is essentially a one-time difficulty. On the other hand, taking measures while continuing the adventure is an endlessly continuing effort, where the risk is always required to be kept at zero. Clearly, the former is a more rational risk measure.</p><p>Judgment by Values, Decision by Resolve, or a Strategy of Ignoring</p><p>On the other hand, we are frequently exposed to fatal risks with very low probabilities in our daily lives. We don't always act based solely on risk rationality.</p><p>When we cross the street, get in a car, train, airplane, or boat, enjoy sports or outdoor activities, or enjoy alcohol and delicious food. When we go to unknown places or intentionally ignore the doctor's advice. We expose ourselves to fatal risks with minute probabilities.</p><p>This is different from risk balance or risk management. It's likely one of the following three:</p><h1>Judgment by Values</h1><p>Even if our lifespan might be shortened a bit, enjoying alcohol and delicious food is part of life. Sports, outdoor activities, and visiting unknown places enrich our lives. What's the point of living long by giving up enjoyment? We take risks with such a value perspective on life and enjoyment.</p><p>Decision by Resolve<br>Getting on an airplane can be a little nerve-wracking and scary. However, if something happens, so be it. Although it might be small, we take risks based on such resolve.</p><p>A Strategy of Ignoring<br>Living while considering all risks is difficult. Humans are not made to live while paying attention to all worries. Risks with minute probabilities associated with things everyone does as a matter of course, or things repeated many times in the past, have become invisible. We expose ourselves to fatal risks with such a strategy.</p><h1>Ethics in Fatal Risks</h1><p>The above is the basic literacy we should understand beforehand when thinking about fatal risks.</p><p>With this literacy as a prerequisite, we can finally have a sincere discussion about risks. Especially in the case of fatal risks, if we don't base our discussions on this literacy, we will not be able to communicate effectively.</p><p>Bringing up balance, risk management, and risk minimization in discussions as if they were rational strategies, while having this literacy, is neither wise nor conscientious. Also, discussing difficulties and impossibilities as if they were on the same level is neither rational nor responsible.</p><p>If an adventure is absolutely necessary, we need to ask those affected by the fatal risks for judgments based on their values and decisions based on their resolve. Of course, based on the concept of informed consent, it's a prerequisite to carefully and clearly explain what we know and what we don't know about the risks.</p><p>Neglecting this, venturing on our own judgment, or pretending to be responsibly handling risks with expressions like balance, risk management, and risk minimization, is undoubtedly an act against ethics.</p><p>The former violates respect for human rights, while the latter violates the duty of care of a good administrator.<br>&nbsp;</p>", "user": {"username": "YoshiAino"}}, {"_id": "cf8Dth9vpxX9ptgma", "title": "Against much financial risk tolerance", "postedAt": "2023-07-30T22:27:54.202Z", "htmlBody": "<h1>Introduction</h1><p>It\u2019s an oft-cited rule of thumb that people saving for their own future consumption hold 40% of their financial wealth in bonds, which offer low expected returns but at low risk, and 60% in stocks, which offer higher expected returns at higher risk. It is sometimes argued, especially in EA circles, that philanthropists should adopt much more aggressive portfolios: investing everything in stocks and similarly risky assets, and perhaps even going further, taking on leverage to achieve higher expected returns at higher risk. I have argued this in the past.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefl52wv3zjsb\"><sup><a href=\"#fnl52wv3zjsb\">[1]</a></sup></span></p><p>Since the collapse of FTX, many have emphasized that there are limits to this position. Some, like&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/THgezaPxhvoizkRFy/clarifications-on-diminishing-returns-and-risk-aversion-in\"><u>Wiblin (2022)</u></a>, have reminded us that even spending toward large-scale philanthropic goals runs into diminishing returns at large enough scales. Other discussion (I think&nbsp;<a href=\"https://news.ycombinator.com/item?id=33550702\"><u>this</u></a> is a representative sample) has argued that philanthropists should use utility functions that are roughly logarithmic instead of near-linear.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref4vichsqddwf\"><sup><a href=\"#fn4vichsqddwf\">[2]</a></sup></span>&nbsp;But both these strands of pushback against adopting extreme financial risk tolerance as a philanthropist still end with the conclusion that philanthropists should invest much more riskily than most other people.</p><p>This is not how philanthropic endowments are usually invested. On&nbsp;<a href=\"https://scholar.harvard.edu/files/campbell/files/investingandspending_forumfutures2012_0.pdf\"><u>Campbell\u2019s (2011)</u></a> account, the Harvard endowment consisted of about 70% stocks and 30% bonds until the late \u201990s, and the endowment managers then expanded into more exotic asset classes only once they concluded that they could do so&nbsp;<i>without&nbsp;</i>taking on more risk. The story with the Yale portfolio is similar.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref7qqd7t1nluy\"><sup><a href=\"#fn7qqd7t1nluy\">[3]</a></sup></span>&nbsp;<a href=\"https://drive.google.com/drive/folders/1t7K9GPkYvJd4EQk8UeZ4RYDejfgxmATn\"><u>Investment reports</u></a> from large American foundations display some variety in investment strategies, but as far as I can tell, they skew only slightly more risk tolerant than university endowments, tending not to depart far from a portfolio of 70% (public and private) equity, 10% cash and bonds, and 20% alternative investments which usually behave roughly like a combination of the two.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref11db65p50yni\"><sup><a href=\"#fn11db65p50yni\">[4]</a></sup></span>&nbsp;If anyone reading this knows of (or produces) a more detailed analysis of the risk tolerance currently adopted by philanthropic investors, please share it! But in any event, my strong impression is that extreme financial risk tolerance is at odds with mainstream philanthropic practice.</p><p>This post is yet another EA-Forum-article attempt to summarize the considerations for and against adopting an unusual degree of financial risk aversion in philanthropy. It doesn\u2019t produce a quantitative recommendation, but it does conclude that there are issues with many of the arguments for unusual financial risk tolerance most often heard in the EA community, including those from&nbsp;<a href=\"https://80000hours.org/2012/01/salary-or-startup-how-do-gooders-can-gain-more-from-risky-careers/\"><u>Shulman (2012)</u></a>,&nbsp;<a href=\"https://rationalaltruist.com/2013/02/28/risk-aversion-and-investment-for-altruists/\"><u>Christiano (2013)</u></a>,&nbsp;<a href=\"https://reducing-suffering.org/should-altruists-leverage-investments\"><u>Tomasik (2015)</u></a>, Irlam (<a href=\"https://www.gordoni.com/effective-altruism/asset-allocation.html\"><u>2017</u></a>,&nbsp;<a href=\"https://www.gordoni.com/effective-altruism/investing.html\"><u>2020</u></a>),&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/g4oGNGwAoDwyMAJSB/how-much-leverage-should-altruists-use\"><u>Dickens (2020)</u></a>, and an old Google doc I\u2019m told summarizes Open Phil\u2019s investment advice to Good Ventures.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefgfkvkzw6r3w\"><sup><a href=\"#fngfkvkzw6r3w\">[5]</a></sup></span>&nbsp;This is not to say that there are no good reasons for some philanthropists to adopt unusually risky (or, for that matter, cautious) financial portfolios. I\u2019ll flag what strike me as some important considerations along the way. An EA philanthropist\u2019s objectives are indeed different in some relevant ways from those of many other endowment managers, and certainly from those of individuals saving for their own futures. But on the whole, the impression I\u2019ve come away with is that the mainstream philanthropic community may be onto something. On balance, directionally, this post is what its title suggests: a case against much financial risk tolerance.</p><p>The arguments for financial risk tolerance explored here are organized into three sections.</p><ol><li>The <a href=\"https://forum.effectivealtruism.org/posts/cf8Dth9vpxX9ptgma/against-much-financial-risk-tolerance#Arguments_from_a_seeming_lack_of_diminishing_marginal_utility\">first</a> discusses arguments stemming directly from the intuition that the marginal utility to philanthropic spending doesn\u2019t diminish very quickly. (I think the intuition has some merit, but is not as well founded as often supposed.)</li><li>The <a href=\"https://forum.effectivealtruism.org/posts/cf8Dth9vpxX9ptgma/against-much-financial-risk-tolerance#Arguments_from_Merton_s_model\">second</a> discusses the argument that, even if the marginal utility to philanthropic spending does diminish pretty quickly, a formal financial model tells us that philanthropists should still be more financially risk tolerant than most people are. (I think the model is usually misapplied here, and that if anything, a proper application of it suggests the opposite.)</li><li>The <a href=\"https://forum.effectivealtruism.org/posts/cf8Dth9vpxX9ptgma/against-much-financial-risk-tolerance#Arguments_for_equities\">third</a> discusses arguments that philanthropists might consider equities\u2014which happen to be risky\u2014unusually valuable, even if the philanthropists aren\u2019t particularly risk tolerant&nbsp;<i>per se</i>. (I think this is true but only to a small extent.)</li></ol><p>Even if you disagree with the conclusion, I hope you find some of the post\u2019s reexaminations of the classic arguments for financial risk tolerance helpful. I hope the post also sheds some light on where further research would be valuable.</p><h2>Defining financial risk aversion</h2><p>To be financially risk averse is to prefer a portfolio with much lower expected returns than you could have chosen, for the sake of significantly reducing the chance that you lose a lot of money. To be financially risk tolerant is to prefer a portfolio with higher expected returns despite a higher chance of losing a lot of money, or, in the extreme case of risk-neutrality, to always choose a portfolio that maximizes expected returns. A portfolio is risky if it has a high chance of losing a lot of its value. So I\u2019ll be arguing that, when constructing their portfolios, philanthropists, including small ones, should typically be willing to sacrifice expected returns for lower riskiness to roughly the same extent as most other investors. I won\u2019t get more formal here, since I think the first section should mostly be accessible without it, but the second section will introduce some formalism.</p><p>It may be worth distinguishing financial from moral risk aversion. Throughout the post, I\u2019ll assume moral risk-neutrality: that a philanthropist should try to maximize the expected amount of good she does. So everything written here is compatible with the classical utilitarian position that one should take a gamble offering, say, a 51% chance of doubling the world and a 49% chance of destroying it. If you endorse some degree of moral risk aversion as well, you may think philanthropists should adopt even less risky financial portfolios than would be justified by the points made here.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref5vngg03h9na\"><sup><a href=\"#fn5vngg03h9na\">[6]</a></sup></span></p><h1>Arguments from a seeming lack of diminishing marginal utility</h1><h2>The basic argument</h2><p>A common starting intuition is that philanthropists should be highly financially risk tolerant because the marginal value of spending on philanthropic projects generally seems not to diminish quickly. The idea is, most investors face steeply diminishing marginal utility in spending. Doubling your consumption only helps you a little bit, whereas losing it all really hurts. So it makes sense for them to invest cautiously. By contrast, philanthropists, if they just want to maximize the expected value of the good they accomplish, face very little diminishing marginal utility in spending. Twice as much money can buy twice as many bed nets, say, and save roughly twice as many lives. This might seem to mean that philanthropists should be highly risk tolerant when investing\u2014indeed, almost risk-neutral. Let\u2019s call this the \u201cbasic\u201d argument. See&nbsp;<a href=\"https://80000hours.org/2012/01/salary-or-startup-how-do-gooders-can-gain-more-from-risky-careers/\"><u>Shulman (2012)</u></a> for an early illustration, and the first half of&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/THgezaPxhvoizkRFy/clarifications-on-diminishing-returns-and-risk-aversion-in\"><u>Wiblin (2022)</u></a> for a recent one.</p><p>But it\u2019s not clear why having philanthropic objectives&nbsp;<i>per se</i> would result in a lack of steeply diminishing returns. The intuitive appeal of the basic argument relies mainly, I think, on the fact that an individual philanthropist often provides only a small fraction of the total funding destined for a given cause. She is often a \u201csmall fish in a big pond\u201d. Consider by contrast a philanthropist only interested in a cause for which she provides about all the funding: the public park in her own hometown, say, or some very obscure corner of the EA landscape.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefo2bs9yq5rxh\"><sup><a href=\"#fno2bs9yq5rxh\">[7]</a></sup></span>&nbsp;The philanthropist would typically not find that doubling her spending in the area would come close to doubling her impact. It would therefore not be right for her to invest almost risk-neutrally.</p><p>So this section has two further subsections. The first discusses whether being a small fish in a big pond really should motivate a philanthropist to adopt an unusually risky financial portfolio, and argues that it generally shouldn\u2019t. The second discusses whether our philanthropic objectives&nbsp;<i>per se</i> should be expected to exhibit a lack of steeply diminishing returns, and again argues that they generally shouldn\u2019t (though more tentatively).</p><h2>The \u201csmall fish in a big pond\u201d argument</h2><h3>Without idiosyncratic risk</h3><p>When an individual philanthropist provides only a small fraction of an area\u2019s total funding, the marginal impact of her own spending does tend to be roughly constant. Let\u2019s call such a philanthropist \u201cproportionally small\u201d. Intuitively, being proportionally small might seem to motivate financial risk tolerance. The intuition may be represented visually like this:</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cf8Dth9vpxX9ptgma/qhshfxt4ss0rfawj8uzp\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cf8Dth9vpxX9ptgma/sspk7smbmrjrcj0hsvf8 260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cf8Dth9vpxX9ptgma/dvl0yyhwgxpwebtggjlu 520w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cf8Dth9vpxX9ptgma/cmiiufab4uvlvjhybbx2 780w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cf8Dth9vpxX9ptgma/lxja8j0qnuahfthtnxkz 1040w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cf8Dth9vpxX9ptgma/sxehtfoumdm8y04v4nlb 1300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cf8Dth9vpxX9ptgma/sxdhaaxngoxmfcymyokd 1560w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cf8Dth9vpxX9ptgma/rqqyqw6fu8f7oeuvaouk 1820w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cf8Dth9vpxX9ptgma/tesjibgs926gldxl9yop 2080w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cf8Dth9vpxX9ptgma/kfbiuzvwbwsbpvyhohs9 2340w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cf8Dth9vpxX9ptgma/cefncmos0diwwiv5pgv5 2540w\"><figcaption>Figure 1</figcaption></figure><p>But there\u2019s something fishy with this argument. Consider a billionaire, investing for his own future consumption, whose $1B portfolio would optimally contain 60% stocks and 40% bonds. And suppose that, instead of putting the $1B all in one investment account, he divides it among 1,000 managers each responsible for $1M of it. If 999 of the managers all put 60% of their $1M in stocks and 40% in bonds, then of course, manager #1,000 should do the same. She shouldn\u2019t think that, as a small fish in a big pond, she should be risk tolerant and put it all in stocks.</p><p>What goes wrong with the argument sketched above is that it fails to account for the possibility that when one philanthropic investor\u2019s portfolio performs well (/badly), the other funders of her favorite causes may also tend to perform well (/badly). This is what happens, for instance, if funders all face the same set of investment opportunities\u2014if they all just have access to the same stock and bond markets, say. In this case, a funder\u2019s distribution of utility gains and losses from a given high-risk, high-return investment actually looks like this:</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cf8Dth9vpxX9ptgma/k0aaktct4tlggc1puj6g\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cf8Dth9vpxX9ptgma/qraddwbagcndae0fkmrs 260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cf8Dth9vpxX9ptgma/smr7uem6ko15avi9e0ux 520w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cf8Dth9vpxX9ptgma/s8cx4e7zvamdfghmejyp 780w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cf8Dth9vpxX9ptgma/dwxdedwjkhqtfyrrgk92 1040w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cf8Dth9vpxX9ptgma/hfjiyjrevslxtgqkktwz 1300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cf8Dth9vpxX9ptgma/schu6lx9yziddvv7eetd 1560w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cf8Dth9vpxX9ptgma/j5lhajpvliawgtickl6e 1820w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cf8Dth9vpxX9ptgma/uld6wwidrouwpknodlxc 2080w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cf8Dth9vpxX9ptgma/phgybc8zdkles6bs1oc5 2340w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cf8Dth9vpxX9ptgma/s4oraovqfca1s3e82emb 2558w\"><figcaption>Figure 2</figcaption></figure><p>We now see the wrinkle in a statement like \u201ctwice as much money can buy twice as many bed nets, and save roughly twice as many lives\u201d. When markets are doing unusually well, other funders have unusually much to spend on services for the poor, and the poor probably have more to spend on themselves as well. So it probably gets more costly to increase their wellbeing.</p><p>Unfortunately, I\u2019m not aware of a good estimate of the extent to which stock market performance is associated with the cost of lowering mortality risk in particular.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefv942izmt4p\"><sup><a href=\"#fnv942izmt4p\">[8]</a></sup></span>&nbsp;I grant that the association is probably weaker than with the cost of \u201cbuying wellbeing for the average investor\u201d (weighted by wealth), since the world\u2019s poorest probably get their income from sources less correlated than average with global economic performance, and that this might justify a riskier portfolio for an endowment intended for global poverty relief than the portfolios most individuals (weighted by wealth) adopt for themselves.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefe4sevprasfw\"><sup><a href=\"#fne4sevprasfw\">[9]</a></sup></span>&nbsp;But note that, whatever association there may be, it can\u2019t be straightforwardly estimated from GiveWell\u2019s periodically updated estimates of the current \u201ccost of saving a life\u201d. Those estimates are based on studies of how well a given intervention has performed in recent years, not live data. They don\u2019t (at least fully) shed light on the possibility that, say, when stock prices are up, then the global economy is doing well, and this means that</p><ul><li>other philanthropists and governments<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreffhgol240dr\"><sup><a href=\"#fnfhgol240dr\">[10]</a></sup></span>&nbsp;have more to spend on malaria treatment and prevention;<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreftrd9twbg50n\"><sup><a href=\"#fntrd9twbg50n\">[11]</a></sup></span></li><li>wages in Nairobi are high, this raises the prices of agricultural products from rural Kenya, this in turn leaves rural Kenyans better nourished and less likely to die if they get malaria;</li></ul><p>and so on, all of which lowers the marginal value of malaria spending by a bit. A relationship along these lines strikes me as highly plausible even in the short run (though see the caveats in <a href=\"https://forum.effectivealtruism.org/posts/cf8Dth9vpxX9ptgma/against-much-financial-risk-tolerance#fnfhgol240dr\">footnote 9</a>). And more importantly, over the longer run, it is certainly plausible that if the global economic growth rate is especially high (low), this will lead both to higher (lower) stock prices and to higher (lower) costs of most cheaply saving a life.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefhcknsluens\"><sup><a href=\"#fnhcknsluens\">[12]</a></sup></span>&nbsp;But even over several years, noise (both in the&nbsp;<i>estimates&nbsp;</i>of how most cheaply to save a life and in the form of&nbsp;<i>random fluctuations in the actual cost</i> of most cheaply saving life) could mask the association between these trends, since the GiveWell estimates are not frequently updated.</p><p>In any event, the point is that it\u2019s not being proportionally small&nbsp;<i>per se</i> that should motivate risk tolerance. The \u201csmall fish in a big pond\u201d intuition relies on the assumptions that one is only providing a small fraction of the total funding destined for a given cause&nbsp;<i>and</i> that the other funders\u2019 investment returns will be uncorrelated with one\u2019s own. While the first assumption may often hold, the latter rarely does, at least not fully. There\u2019s no general rule that small fishes in big ponds should typically be especially risk tolerant, since the school as a whole typically faces correlated risk.</p><h3>Non-optimal risk tolerance by other funding sources</h3><p>As we\u2019ve seen, when other funding streams are correlated with her own, a proportionally small funder shouldn\u2019t adopt an unusual investment strategy just because she\u2019s small. If she trusts that the other funding sources\u2014the other \u201c999 managers\u201d\u2014aren\u2019t investing too risk aversely or risk tolerantly, she should copy what they do.</p><p>If most of the funding in some domain comes from people investing too cautiously, then yes, a proportionally small funder should try to correct this by investing very riskily, as e.g.&nbsp;<a href=\"https://rationalaltruist.com/2013/02/28/risk-aversion-and-investment-for-altruists/\"><u>Christiano (2013)</u></a> emphasizes. I don\u2019t doubt that in some domains, it can be established that most of the funding does come from people investing too cautiously. But of course it could also go the other way. The <a href=\"https://forum.effectivealtruism.org/posts/cf8Dth9vpxX9ptgma/against-much-financial-risk-tolerance#With_idiosyncratic_risk\">next sub-subsection</a> introduces a reason to believe that a lot of philanthropic funding should be expected to come from people investing especially riskily. More generally, if I\u2019m right that the collective EA financial portfolio should be invested even a little bit less riskily than EA discourse to date would suggest is ideal, then a proportionally small reader of this post should invest as cautiously as possible.</p><p>Ultimately, a proportionally small philanthropist with the typical suite of investment opportunities just has to make up her own mind about what the collective portfolio toward her favored causes should look like, observe what it does look like, and invest so that the collective portfolio resembles her ideal as closely as possible.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefzraicywh3nb\"><sup><a href=\"#fnzraicywh3nb\">[13]</a></sup></span>&nbsp;We\u2019ll think about how risky the collective portfolio should be in the <a href=\"https://forum.effectivealtruism.org/posts/cf8Dth9vpxX9ptgma/against-much-financial-risk-tolerance#Arguments_about_the_utility_function_for__the_pond_as_a_whole_\">next subsection</a>.</p><h3>With idiosyncratic risk</h3><p>Before doing that, though, sometimes a proportionally small philanthropist&nbsp;<i>does&nbsp;</i>have a private investment opportunity whose performance is relatively uncorrelated\u2014or even anticorrelated\u2014with the wealth of her cause\u2019s other funders. In these cases, at least in principle, we finally have a sound motivation for financial risk tolerance. Suppose you alone get the chance to bet on a coin flip, where you will pay $<i>x</i> if the coin lands on one side and win slightly more than $<i>x</i> if the coin lands on the other (up to some large&nbsp;<i>x</i>). You should typically choose an&nbsp;<i>x</i> that is a small fraction of your wealth if you\u2019re an individual or a proportionally large philanthropist, but all your wealth if you\u2019re a proportionally small philanthropist. The logic illustrated by Figure 1 goes through.</p><p>I believe that in practice, the most significant private investment opportunities available to proportionally small philanthropists are startups. A startup, like a coin flip, comes with some idiosyncratic risk. A proportionally small philanthropist should therefore sometimes be willing to take the opportunity to found or join a startup that most people wouldn\u2019t. Indeed, this is the case to which&nbsp;<a href=\"https://80000hours.org/2012/01/salary-or-startup-how-do-gooders-can-gain-more-from-risky-careers/\"><u>Shulman (2012)</u></a> applies what at least sounds, without this context, like the \u201cbasic argument\u201d.</p><p>But startup returns are also largely correlated with the returns of publicly traded companies. Indeed, to my understanding, the startups\u2014especially tech startups\u2014fluctuate&nbsp;<i>more</i>. That is, when the stock market does a bit better than usual, the startups typically boom, and when the stock market does a bit worse than usual, the startups are typically the first to go bust.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref18zn7quratt\"><sup><a href=\"#fn18zn7quratt\">[14]</a></sup></span>&nbsp;Proportionally small philanthropists should not much mind the first kind of risk (\u201cidiosyncratic\u201d), but as noted previously, they should indeed mind the second (\u201csystematic\u201d). Let\u2019s now consider how the two effects shake out.</p><p>Consider a startup founder who is not a proportionally small philanthropist\u2014e.g. one who just wants to maximize the expected utility he gets from his own future consumption. His ideal financial portfolio presumably contains only a small investment in his own startup, so that he can diversify away the idiosyncratic risk that his startup carries. But a founder typically can\u2019t sell off almost all of the startup, and thereby insure himself against its risks, due to adverse selection and moral hazard. That is, potential buyers naturally worry that a founder selling off most of his startup (a) knows it\u2019s less valuable than it looks, and/or (b) will put less effort into the company when he has less skin in the game. This means that the marginal startup should be expected to offer its founder a premium high enough to compensate him for the fact that, to start it, he will have to fill his own portfolio with a lot of idiosyncratic risk.</p><p>Since proportionally small philanthropists shouldn\u2019t care much about idiosyncratic risk, they should be unusually willing to start startups, and willing to put unusually large shares of their wealth into whatever startups they have. But in doing so, they will load the&nbsp;<i>collective&nbsp;</i>portfolio with the concentrated dose of systematic risk that startups also typically carry. If this is more than the level of systematic risk that the collective philanthropic portfolio should exhibit, then to offset this, the value-aligned philanthropists without startups should invest especially&nbsp;<i>cautiously</i>. For illustration:</p><ul><li>Suppose the optimal collective financial portfolio across philanthropists in some cause area would have been 60% stocks, 40% bonds if stocks and bonds had been the only asset options.</li><li>Now suppose some of the philanthropists have opportunities to invest in startups. Suppose that, using bonds as a baseline, startup systematic risk is twice as severe as the systematic risk from a standard index fund. What should the collective portfolio be?</li><li>First, consider the unrealistic case in which\u2014despite systematic risk fully twice as severe for startups as for publicly traded stocks\u2014the expected returns are only twice as high. That is, suppose that whenever stock prices on average rise or fall by 1%, the value of a random portfolio of startups rises or falls by&nbsp;<i>x</i>% where&nbsp;<i>x </i>&gt; 0.6. For illustration, say&nbsp;<i>x </i>= 2. Then a portfolio of 30% startups and 70% bonds would behave like a portfolio of 60% stocks and 40% bonds. Either of these portfolios, or any average of the two, would be optimal.</li><li>But if startups are (say) twice as systematically risky as stocks (relative to bonds), expected returns (above bonds) should be expected to be&nbsp;<strong>more&nbsp;</strong>than twice as high. If the expected returns were only twice as high, startup founders would only be being compensated for the&nbsp;<i>systematic&nbsp;</i>risk; but as noted, most founders also need to be compensated for&nbsp;<i>idiosyncratic&nbsp;</i>risk.</li><li>To the extent that startup returns are boosted by this compensation for idiosyncratic risk, the optimal collective financial portfolio across these philanthropists is then some deviation from 30% startups / 70% bonds in the direction of startups. Everyone without a startup should have 100% of their portfolio in bonds.</li></ul><p>In sum, 2022 was more than bad luck (even besides the fraud). It\u2019s not entirely a coincidence that the year FTX imploded was also the year in which crypto as a whole crashed, Meta and Asana lost most of their value, and stock markets as a whole lost a lot of their value. An EA-aligned endowment held in safe bonds would not have lost value, and so would have done a lot more good now that the marginal utility to \u201cEA spending\u201d is (presumably permanently) higher than it otherwise would have been.</p><p>Finally, note that a given philanthropic community may wind up exposed not to \u201ca portfolio of startups\u201d, whose idiosyncratic risks wash out, but to a small number of startups whose idiosyncratic risks contribute significantly to the variance of the whole portfolio. That has certainly been the situation of the EA community in recent years. In these cases, as many have pointed out already, the proportionally small philanthropists without startups should invest not just to offset the aligned startups\u2019 systematic risk but also to offset their idiosyncratic risks. That is, they should invest in firms and industries whose performance is anticorrelated with the industries of the aligned startups. But I\u2019d like to keep this post focused mainly on philanthropic finance in the abstract, so I won\u2019t think about how to apply this insight to the EA case in more detail.</p><h2>Arguments about the utility function for \u201cthe pond as a whole\u201d</h2><p>So far, the discussion largely mirrors that of&nbsp;<a href=\"https://reducing-suffering.org/should-altruists-leverage-investments/\"><u>Tomasik (2015)</u></a>,&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/g4oGNGwAoDwyMAJSB/how-much-leverage-should-altruists-use\"><u>Dickens (2020)</u></a>, and, more briefly,&nbsp;<a href=\"https://rationalaltruist.com/2013/02/28/risk-aversion-and-investment-for-altruists/\"><u>Christiano (2013)</u></a>. All these pieces acknowledge the intuitive appeal of what I\u2019ve called the \u201csmall fish in a big pond\u201d argument, explain that its logic only goes through when a proportionally small philanthropist faces an investment opportunity with idiosyncratic risk, and note that such opportunities are rare, with the possible exceptions of startups. They don\u2019t make the point that, if the advice about investing more in startups is taken, then proportionally small philanthropists&nbsp;<i>without</i> startups should invest especially cautiously, to offset the risk others\u2019 startups bring to the collective portfolio. But otherwise, we all basically agree that members of a philanthropic community should generally adopt portfolios about as risky as it would make sense to make the collective portfolio. This subsection considers arguments about how risky that is.</p><p>Naturally, it depends on the function from&nbsp;<i>total spending in some domain of philanthropic concern</i> to&nbsp;<i>impact</i>. Let\u2019s call this the \u201cphilanthropic utility function\u201d, but remember that the input to the function is total spending in the relevant domain (including spending by governments, and spending by the poor on themselves), not just spending by philanthropists. If the philanthropic utility function exhibits as much curvature as a typical individual\u2019s utility function, then philanthropists should invest about as cautiously as typical individuals do (at least if individuals typically invest about as riskily as is best for them, an assumption I\u2019ll sort of defend when <a href=\"https://forum.effectivealtruism.org/posts/cf8Dth9vpxX9ptgma/against-much-financial-risk-tolerance#The_equity_premium_puzzle_argument\">discussing the equity premium puzzle argument</a>). As summarized below, I disagree with most of the arguments I\u2019m aware of for thinking that philanthropic utility functions exhibit unusually little curvature\u2014though one does strike me as strong, and some raise considerations that seem important but directionally ambiguous.</p><p>When I refer to a utility function\u2019s curvature, I\u2019m referring to what\u2019s known as its&nbsp;<a href=\"https://en.wikipedia.org/wiki/Risk_aversion#Relative_risk_aversion\"><u>coefficient of relative risk aversion</u></a>, or RRA. This is a number that equals 0 everywhere for linear utility functions, 1 everywhere for logarithmic utility functions, and a higher number everywhere for yet more steeply curved utility functions. A utility function doesn\u2019t have to exhibit the same curvature everywhere, and estimates of the curvature of people\u2019s utility functions in different contexts vary, but they\u2019re typically found to be well above 1.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefiscyb5rkg\"><sup><a href=\"#fniscyb5rkg\">[15]</a></sup></span>&nbsp;So this is what I\u2019m defending above as a baseline for the philanthropic case.</p><h3>Typical risk aversion as a (weak) baseline</h3><p>Suppose a philanthropist\u2019s (or philanthropic community\u2019s) goal is simply to provide for a destitute but otherwise typical household with nothing to spend on themselves. Presumably, the philanthropist should typically be as risk averse as a typical household.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefdbi4nkj04gs\"><sup><a href=\"#fndbi4nkj04gs\">[16]</a></sup></span>&nbsp;Likewise, suppose the goal is to provide for many<i>&nbsp;</i>such households, all of which are identical. The philanthropist should then adopt a portfolio like the combination of the portfolios these households would hold themselves, which would, again, exhibit the typical level of riskiness. This thought suggests that the level of risk aversion we observe among households may be a reasonable baseline for the level of risk aversion that should guide the construction of a philanthropic financial portfolio.</p><p>Also, as noted briefly in the introduction, most philanthropists do appear to invest <i>very</i> <i>roughly</i> as risk aversely as most households.</p><p>These arguments are both very weak, but I think they offer a prior from which to update in light of the three arguments at the end of this subsection. I will indeed argue for updating from it, on the basis of, e.g., the facts that not all the households who might be beneficiaries of philanthropy are identical and that not all philanthropy is about increasing households\u2019 consumption. But if we\u2019re looking for a prior for philanthropic utility functions, I at least think&nbsp;<i>typical individual utility functions</i> offer a better prior than&nbsp;<i>logarithmic utility functions</i>, which is the only other proposal I\u2019ve seen.</p><h3>Against logarithmic utility as a baseline</h3><p>Instead of taking the curvature of a typical individual utility function as a baseline, logarithmic utility\u2014a curvature of 1\u2014is sometimes proposed as a baseline. I\u2019m aware of three primary arguments for doing this (beyond analytic convenience), but I don\u2019t believe these are informative.</p><p>First: if you invest&nbsp;<i>as if&nbsp;</i>you have a logarithmic utility function, even if you really don\u2019t, then under certain assumptions, your portfolio probably performs better in the long run than if you invest in any other way. This point was first made by&nbsp;<a href=\"https://www.princeton.edu/~wbialek/rome/refs/kelly_56.pdf\"><u>Kelly (1956)</u></a>, so it might be called the \u201cKelly argument\u201d. Despite endorsements by many blog posts in the EA sphere,<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefuq0abqccv2h\"><sup><a href=\"#fnuq0abqccv2h\">[17]</a></sup></span>&nbsp;it\u2019s simply a red herring. Under the assumptions in question, though you&nbsp;<i>probably</i> wind up with more money by acting as if you have logarithmic utility than by acting on the utility function you actually have, the rare scenarios in which you wind up with less money can leave you with much less utility. On balance, the move to pretending you have logarithmic utility lowers your expected utility, which is what matters. The economist Paul Samuelson got so tired of making this point that in 1979 he published a&nbsp;<a href=\"https://www.sciencedirect.com/science/article/abs/pii/0378426679900232\"><u>paper</u></a> spelling it out entirely in monosyllabic words.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefqq5wam3xz2o\"><sup><a href=\"#fnqq5wam3xz2o\">[18]</a></sup></span></p><p>Second:&nbsp;<a href=\"http://www.fhi.ox.ac.uk/cost-effectiveness-of-research-overview/\"><u>Cotton-Barratt (2014)</u></a> wrote a series of articles arguing that, given a set of problems whose difficulties we don\u2019t know, like open research questions, we should expect that the function from&nbsp;<i>resources put into solving them</i> to&nbsp;<i>fraction of them that are solved</i> will be logarithmic. As explained in the&nbsp;<a href=\"http://www.fhi.ox.ac.uk/how-to-treat-problems-of-unknown-difficulty/\"><u>first article</u></a>, this conclusion follows from an assumption that one\u2019s uncertainty about how many resources it will take to solve a given problem follows a roughly uniform distribution over a logarithmic scale. This simply amounts to assuming the conclusion. One could just as well posit a roughly uniform distribution over a differently transformed scale, and then conclude that the function from inputs to outputs is not logarithmic but something else. The later articles develop the view and illustrate its implications, but don\u2019t return to providing a more compelling theoretical basis for it.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefwstbg5uo6x\"><sup><a href=\"#fnwstbg5uo6x\">[19]</a></sup></span>&nbsp;Finally, even if there is a roughly logarithmic research production function, this does not justify a logarithmic&nbsp;<i>utility&nbsp;</i>function (as&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/g4oGNGwAoDwyMAJSB/how-much-leverage-should-altruists-use\"><u>Dickens (2020)</u></a> seems to imply) unless our utility is linear in what we are calling \u201cresearch outputs\u201d, which I see no particular reason to believe.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefx0dfpt848ca\"><sup><a href=\"#fnx0dfpt848ca\">[20]</a></sup></span></p><p>Third:&nbsp;<a href=\"https://rationalaltruist.com/2013/02/28/risk-aversion-and-investment-for-altruists/\"><u>Christiano (2013)</u></a> argues that in the long run, your \u201cinfluence\u201d (in some sense) will depend on what fraction of the world you control. He then infers that \u201can investor concerned with maximizing their influence ought to maximize the expected fraction of world wealth they control\u201d, and he argues that this should motivate investing as if you have logarithmic utility. It is an interesting observation that if you just want to maximize the expected fraction of world wealth you control in the long run, then you should invest roughly as if you have logarithmic utility. But even if (a) maximizing influence is all that matters and (b) influence depends only on the fraction of world wealth you control, it doesn\u2019t follow that influence is&nbsp;<i>linear</i> in the fraction of world wealth you control, which is what we need in order to conclude that the thing to maximize is&nbsp;<i>expected fraction&nbsp;</i>of world wealth. Indeed, this would seem to be an especially pessimistic vision, in which control of the future is a zero-sum contest, leaving no ways for people to trade some of their resources away so that others use their resources slightly differently. If they can, we should expect to see diminishing returns to proportional wealth: the most mutually beneficial \u201cbargains over the future\u201d will be made first, then the less appealing bargains, and so on. Double the proportional wealth can then come with arbitrarily less than double the utility. See <a href=\"https://forum.effectivealtruism.org/posts/cf8Dth9vpxX9ptgma/against-much-financial-risk-tolerance#Appendix_A__Decreasing_returns_to_proportional_wealth\">Appendix A</a>.</p><h3>Arguments from the particulars of current top priorities</h3><p>Instead of more reasoning in the abstract, it would be great to try to estimate the curvature of the philanthropic utility function with respect to top EA-specific domains in particular. Unfortunately, I\u2019m not aware of any good estimates. What few estimates I am aware of, though, don\u2019t give us strong reasons to posit very low curvatures.</p><p>First, I think the impression that the philanthropic utility function with respect to top EA-specific domains exhibits relatively little curvature can to some extent be traced back to posts in which this is simply claimed without argument. It\u2019s stated offhand in&nbsp;<a href=\"https://rationalaltruist.com/2013/02/28/risk-aversion-and-investment-for-altruists/\"><u>Christiano (2013)</u></a> and throughout&nbsp;<a href=\"https://reducing-suffering.org/should-altruists-leverage-investments/\"><u>Tomasik (2015)</u></a>, for instance, that a \u201creasonable\u201d degree of curvature to assume in these domains is less than 1. For whatever it\u2019s worth, I don\u2019t share the intuition.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefvf3g968cop\"><sup><a href=\"#fnvf3g968cop\">[21]</a></sup></span></p><p><a href=\"https://www.openphilanthropy.org/research/technical-updates-to-our-global-health-and-wellbeing-cause-prioritization-framework/\"><u>Berger and Favaloro (2021)</u></a> offer what seems like an estimate of the curvature, in the domain of GiveWell-style global health funding. Their curvature estimate is 0.375.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefxydmrgeqczk\"><sup><a href=\"#fnxydmrgeqczk\">[22]</a></sup></span>&nbsp;As the authors explain, this estimate was reached \u201cby fitting isoelastic curves to projections GiveWell has performed to model their opportunity set, though they are quite uncertain about those projections and wouldn\u2019t want to independently defend them.\u201d Even if we do trust these projections, though, what they appear to capture is how fast the value of further GiveWell-style spending would fall if such spending were ramped up,&nbsp;<i>all else equal</i>. That is, 0.375 appears to be an estimate of \u201ccurvature\u201d in the sense of Figure 1. What should govern how riskily we\u2019re willing to invest, however, is \u201ccurvature\u201d in the sense of Figure 2: that is, again,&nbsp;<i>curvature of the philanthropic utility function</i>. This is the kind of curvature that captures how much higher the marginal value of spending is when markets are down, global economic performance is poor, and other relevant spending\u2014including e.g. spending by the poor on their own nutrition\u2014dries up. An accurate estimate of curvature in the first sense would probably be a considerable underestimate of curvature in the sense that matters.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref3r1msfska2v\"><sup><a href=\"#fn3r1msfska2v\">[23]</a></sup></span></p><p><a href=\"https://forum.effectivealtruism.org/posts/g4oGNGwAoDwyMAJSB/how-much-leverage-should-altruists-use\"><u>Dickens (2020)</u></a> offers a very rough estimate of curvature in this second sense, as applied to GiveWell-style global health funding, albeit without GiveWell\u2019s internal projections. He estimates that the curvature is at least 1 and perhaps even over 3.</p><p>Besides Berger and Favaloro\u2019s work in the global health domain, others on the Open Phil team have recently been trying to estimate the curvature in other domains. I think it\u2019s great that this work is being done, and I look forward to incorporating it at some point, but much of it is still quite preliminary, and its authors don\u2019t want the conclusions made public. It\u2019s possible, of course, that these analyses will end up largely confirming the old conclusion in favor of risk tolerance, even if the old reasoning for that conclusion was largely faulty. But I worry that, especially in domains where a given project\u2019s path to impact is hard to measure, the analyses will themselves be influenced by intuitions which were developed by&nbsp;<i>a priori&nbsp;</i>arguments like those discussed throughout this post. In conversation, for example, one person contributing to an estimate of the curvature in a certain Open Phil funding domain noted that they had been giving some weight to one of the (I believe mistaken) arguments for using logarithmic utility as a baseline.</p><p>Finally, in that spirit, it may be worth briefly considering a simple model of existential risk reduction. Suppose that every unit increase in x-risk-focused spending buys the same proportional reduction in x-risk. This is what happens, for instance, if each unit increase in spending lets us build another safeguard of some kind, if a catastrophe only occurs if the safeguards all fail, and if the safeguards\u2019 failure probabilities are equal and independent. What then is the curvature of the function from spending to impact, as measured by probability of survival? The unsurprising answer is that it could be arbitrarily high or low, depending on the parameters. See <a href=\"https://forum.effectivealtruism.org/posts/cf8Dth9vpxX9ptgma/against-much-financial-risk-tolerance#Appendix_B__Decreasing_returns_to_x_risk_reduction_spending\">Appendix B</a>.</p><h3>The truncated lower tail argument</h3><p>You might think: \u201cIf the total funding for some philanthropic cause area goes to zero, the results (probably) won\u2019t truly be catastrophic. The world will lack some helpful top-up that the funding in that area would have provided, but otherwise it will carry on fine. By contrast, if an individual loses all her resources, she starves and dies. So philanthropists should worry less about losing all their resources than individuals typically do.\u201d I haven\u2019t seen this argument made explicitly in writing, but I\u2019ve heard it expressed, and I would guess that a thought along these lines underlies the Christiano and Tomasik intuitions that the curvature of the philanthropic utility functions they\u2019re concerned with is less than 1. A function&nbsp;<i>u</i>(<i>x</i>) whose curvature is&nbsp;<i>everywhere&nbsp;</i>1 or more falls arbitrarily low as&nbsp;<i>x</i> falls to 0; if its curvature is everywhere in the (0, 1) range, it looks like, say, the square root function, bottoming out at some baseline utility level (say, 0) when&nbsp;<i>x </i>= 0.</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cf8Dth9vpxX9ptgma/nmak0utlpcidqitaw4lz\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cf8Dth9vpxX9ptgma/n1kaiy6gpi7pegmmqvj4 240w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cf8Dth9vpxX9ptgma/cslvczcfi6wrf5vzbpa2 480w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cf8Dth9vpxX9ptgma/dulcipqthokqbzlcl3av 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cf8Dth9vpxX9ptgma/ldopdow1rotirjuwz77q 960w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cf8Dth9vpxX9ptgma/xc322taatnsul2qdux62 1200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cf8Dth9vpxX9ptgma/klvmx5xoryd52rukhwjs 1440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cf8Dth9vpxX9ptgma/krenn2xm7bb3ggpujsuh 1680w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cf8Dth9vpxX9ptgma/ftofgovmxc4d43peog4o 1920w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cf8Dth9vpxX9ptgma/tqds0dmat92muo5vzwsq 2160w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cf8Dth9vpxX9ptgma/zfcz7uwgtak6ibrkuzn6 2400w\"><figcaption>Figure 3</figcaption></figure><p>I don\u2019t think this line of reasoning is right on either count.</p><p>First, though individuals suffer some disutility if they lose all their money, they don\u2019t suffer infinite disutility any more than philanthropists do. Not even if they starve, presumably; but certainly not if their welfare just falls to the more realistic baseline, at least in the developed world, of a life on (however meager) social assistance. When we see people acting as if their utility functions have curvatures greater than 1, we usually just infer that their utility functions have curvatures greater than 1 above some low threshold. The fact that such a threshold exists for philanthropists too isn\u2019t a reason to think that the curvature of a philanthropic utility function tends to be&nbsp;<i>everywhere&nbsp;</i>less than 1 either.</p><p>Second, to repeat a point from <a href=\"https://forum.effectivealtruism.org/posts/cf8Dth9vpxX9ptgma/against-much-financial-risk-tolerance#The__small_fish_in_a_big_pond__argument\">the \u201csmall fish in a big pond\u201d subsection</a>, the wholesale loss of a philanthropic portfolio doesn\u2019t just \u201cleave the world as it is today, but without some helpful top-up funding\u201d. A scenario in which, say, the global stock market in 30 years is worthless is likely a scenario in which the world as a whole is worse off than it is today, funding for important projects from other sources has disappeared, and your resources are needed more. It\u2019s a world in which more people are starving.</p><p>Ultimately, perhaps philanthropists should be less concerned than typical individuals with ensuring that they don\u2019t lose everything in pessimistic economic scenarios, and perhaps they should be more concerned. It just depends on what the philanthropists are interested in funding.</p><h3>The cause variety argument</h3><p>I\u2019ve argued so far that we don\u2019t have much reason to expect that the philanthropic utility function for any given cause exhibits less curvature than a typical individual\u2019s utility function. Even if this is true on some narrow definition of \u201ccause\u201d, though, a cause-neutral philanthropist will want to fund the most important area up to the point that the value of further funding there has fallen to the value of funding the next-best area, then switch to funding both, and so on. As a result, the value of further funding, for such a philanthropist, falls less quickly as funding scales up than the value of further funding for a philanthropist who restricts her attention to a single narrow area. That is, a cause-neutral philanthropist\u2019s philanthropic utility function has less curvature. If we think that the Yale portfolio is ideal for a goal like&nbsp;<i>supporting Yale</i>, we should think that a riskier portfolio is ideal for a goal like&nbsp;<i>doing the most good</i>.</p><p>The magnitude of the impact of \u201ccause variety\u201d on the curvature of a philanthropic utility function may not be obvious. On the one hand, as noted in <a href=\"https://forum.effectivealtruism.org/posts/cf8Dth9vpxX9ptgma/against-much-financial-risk-tolerance#Typical_risk_aversion_as_a__weak__baseline\">the sub-subsection on using typical risk aversion as a baseline</a>, when a philanthropist is providing only for a range of identical, destitute households, the fact that there are many \u201ccauses\u201d (i.e. households) has no impact at all. On the other hand, if the causes a philanthropist might be interested in funding are not structurally identical, the range of causes may not have to be very wide for cause variety to be an important effect. And even if a philanthropist is only interested in, say, relieving poverty in some small region with a bell-shaped income distribution, she effectively faces a continuum of causes: relieving the poverty of those at the very bottom of the distribution, relieving the poverty of those just above them, and so on. Under some assumptions I think are vaguely reasonable, cause variety of this sort can easily be enough to cut the curvature of the philanthropic utility function by more than half, all else equal. The implications of cause variety are explored more formally in <a href=\"https://forum.effectivealtruism.org/posts/cf8Dth9vpxX9ptgma/against-much-financial-risk-tolerance#Appendix_C__Less_curvature_due_to_cause_variety\">Appendix C</a>.</p><h3>Arguments from uncertainty</h3><p>So far, we\u2019ve been reasoning as if the function from spending to impact takes a certain shape, and that we just need to work out a central guess about what that shape is and act according to that guess. But even our best guess is bound to be bad. Philanthropists face a lot of uncertainty about how valuable funding opportunities are relative to each other: more uncertainty, arguably, than the uncertainty individuals face about how much less a second car (say) will contribute to their welfare than a first. I\u2019m aware of two arguments that this extra uncertainty systematically justifies more financial risk tolerance. This is possible, but it seems to me that, in both cases, the impact of the extra uncertainty could go either way.</p><p>First, one might argue that financial risk tolerance follows from uncertainty about the curvature of the philanthropic utility function&nbsp;<i>per se</i>. The argument goes: \u201cAssuming that we will be richer in the future than today, the possibility that our utility function exhibits a lot of curvature is a low-stakes scenario. In that case we might mess up a little bit by putting everything in stocks, but even if we\u2019d invested optimally, there isn\u2019t much good we could have done anyway. But if it turns out our utility function was close to linear and we messed up by holding too many bonds, we left a lot of expected value on the table.\u201d</p><p>This is true, but it rests critically on the assumption that we&nbsp;<i>will&nbsp;</i>be \u201cricher\u201d, in that the most important domains for philanthropic funding will be better funded than they are today. If not, the high-curvature scenarios are the high-stakes ones. This isn\u2019t to say it\u2019s all a wash, just that the implications of \u201ccurvature uncertainty\u201d for optimal financial behavior depend on the details of the form that the uncertainty takes, in ways that seem hard to determine&nbsp;<i>a priori</i>. A more formal exploration of the possible asymmetry at play here can be found in <a href=\"https://forum.effectivealtruism.org/posts/cf8Dth9vpxX9ptgma/against-much-financial-risk-tolerance#Uncertainty_about___\">Appendix D: Uncertainty about \ud835\udf02</a>.</p><p>Second, one might argue that philanthropists have a hard time distinguishing between the value of different projects, and that this makes the \u201c<i>ex ante</i> philanthropic utility function\u201d, the function from spending to&nbsp;<i>expected</i> impact, less curved than it would be under more complete information. But again, this all depends on the form that the uncertainty takes. If possible projects actually differ significantly in impact per dollar but under uncertainty they all offer the same, slightly positive expected value, then the utility function under full information can be arbitrarily curved but uncertainty will make the&nbsp;<i>ex ante</i> utility function linear. On the other hand, if possible projects actually all generate impacts of either +1 or \u20131 per dollar, but they vary a lot in terms of how easy it is to determine whether the sign of the value is positive or negative, then the utility function under full information is linear (just fund as many of the \u201c+1\u201ds as you can afford to) but the&nbsp;<i>ex ante</i> utility function can be arbitrarily curved.</p><h1>Arguments from Merton\u2019s model</h1><p>Here\u2019s a summary of the reasoning of the previous section.</p><ul><li>How riskily a philanthropist should invest depends centrally on the curvature of his \u201cphilanthropic utility function\u201d. This is the function from&nbsp;<i>total spending on the things he\u2019s interested in funding</i> to&nbsp;<i>impact</i>.</li><li>There seem to be no good (public) empirical estimates of this curvature, at least in the EA case. And many proposed arguments for guessing&nbsp;<i>a priori&nbsp;</i>that philanthropic utility functions exhibit less curvature than individuals\u2019 utility functions are actually either directionally ambiguous or simply vacuous.</li><li>One argument for lower-than-average curvature seems solid: the \u201ccause variety\u201d argument. This suggests that cause-neutral philanthropists should collectively invest more riskily than most other people.</li><li>On the other hand, small philanthropists should be expected to be unusually willing to start startups. This should make the other philanthropists in the same domain want to invest more cautiously than they would otherwise.</li></ul><p>Which of these effects is larger is unclear, at least to my mind. It\u2019s also not clear what to make of the directionally ambiguous arguments. So far, I don\u2019t feel like I can rule out that philanthropists without startups who want to maximize their expected impact basically have no stronger reasons for risk tolerance than typical investors.</p><p>But even given a philanthropic utility function whose curvature is the same as that of a typical individual utility function, it doesn\u2019t follow that the philanthropic investment portfolio should be the same as the portfolio that individuals actually&nbsp;<i>choose</i>. This equality could fail in two ways.</p><p>First, we might doubt that people invest appropriately given their own utility functions. One might agree that philanthropic utility functions probably look similar to (scaled up) typical individual utility functions, and still argue that philanthropists as a whole should invest unusually riskily, on the grounds that most individuals currently invest more cautiously than is best for them.</p><p>It\u2019s often argued, on the basis of a formal portfolio construction model, that a conventional portfolio along the lines of 60% stocks and 40% bonds couldn\u2019t possibly be optimal for most people. When we try to estimate the curvature of a typical individual utility function in practically any way (besides the giant data point of how riskily they\u2019re willing to invest, of course), we find that the curvature may be above 1, but it\u2019s not high enough to warrant such a cautious portfolio. Even if a community of philanthropists believes that their philanthropic utility function exhibits about as much curvature as a typical individual utility function, therefore, they shouldn\u2019t simply adopt the portfolio that they see most people adopting for themselves. Instead, they should plug the curvature they think a typical individual utility function&nbsp;<i>actually&nbsp;</i>exhibits into the formal model, and then adopt the portfolio the model recommends.</p><p>The simple model typically used to reach this conclusion, and the one used most frequently by far in EA discussions about all this, is&nbsp;<a href=\"http://lifecycleinvesting.net/Resources/merton%20lifetime%20portfolio%20selection%201969.pdf\"><u>Merton\u2019s (1969)</u></a> model. This is the formula used to justify investing riskily in the quantitative discussions of philanthropic investment advice by Tomasik, Irlam, and Dickens.</p><p>But individuals have good reasons not to behave as Merton\u2019s formulas recommend. That is, the model oversimplifies their portfolio construction problem in important ways. Economists have identified some of the missing complications over the past few decades, and developed more complex models which show how a conventional portfolio might be justified after all. I\u2019ll explain this below. I\u2019ll also argue that, in general, the complications which seem to justify individuals\u2019 cautious investment behavior apply to philanthropists as well.</p><p>Second, we might think that, even if people do invest appropriately given their own utility functions, and even if philanthropic utility functions do look similar to (scaled up) individual utility functions, philanthropists should still invest differently, because the amount of wealth being spent pursuing one\u2019s goals in the future depends not only on how well financial investments have performed but also on how much wealth has turned up from elsewhere to pursue those goals. This is true for both philanthropists and typical individuals. A philanthropist should account for the fact that new funders may arrive in the future to support the causes she cares about, for instance, and an individual should account for the fact that he will probably get most of his future wealth from wages, not from the returns on his financial investments. But if this distribution of possible amounts of relevant outside income is different for a philanthropist than for a typical individual, this might motivate the philanthropist to invest differently. In particular, Merton\u2019s model is sometimes used to argue that the difference between these distributions should motivate philanthropists to invest unusually riskily.</p><p>I agree that there is a difference between these distributions, and that it might motivate a difference in investment behavior. But I\u2019ll argue that, if anything, it should generally motivate philanthropists\u2014especially in EA\u2014to invest unusually cautiously.</p><h2>Describing the formula</h2><p>Suppose an investor wants to maximize the expectation of the integral, over time, of his discounted flow utility at each time, where flow utility at a time&nbsp;<i>t</i> is a CRRA function,&nbsp;<i>u</i>(\u00b7), of consumption at&nbsp;<i>t</i>,&nbsp;<i>c<sub>t</sub></i>. Formally, suppose he wants to maximize</p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"E\\Big[\\int_0^\\infty e^{-\\delta t} u(c_t)dt\\Big],\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;(1)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;\">E</span></span><span class=\"mjx-mstyle\"><span class=\"mjx-mrow\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size2-R\" style=\"padding-top: 0.961em; padding-bottom: 0.961em;\">[</span></span></span></span></span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\" style=\"margin-right: -0.388em;\"><span class=\"mjx-mo\" style=\"vertical-align: 0.001em; padding-right: 0.388em;\"><span class=\"mjx-char MJXc-TeX-size2-R\" style=\"padding-top: 1.109em; padding-bottom: 1.109em;\">\u222b</span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.921em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 2.15em; padding-left: 0.784em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">\u221e</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">e</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.007em;\">\u03b4</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mstyle\"><span class=\"mjx-mrow\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size2-R\" style=\"padding-top: 0.961em; padding-bottom: 0.961em;\">]</span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span><style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}\n.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}\n.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}\n.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}\n.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}\n.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}\n.mjx-numerator {display: block; text-align: center}\n.mjx-denominator {display: block; text-align: center}\n.MJXc-stacked {height: 0; position: relative}\n.MJXc-stacked > * {position: absolute}\n.MJXc-bevelled > * {display: inline-block}\n.mjx-stack {display: inline-block}\n.mjx-op {display: block}\n.mjx-under {display: table-cell}\n.mjx-over {display: block}\n.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-stack > .mjx-sup {display: block}\n.mjx-stack > .mjx-sub {display: block}\n.mjx-prestack > .mjx-presup {display: block}\n.mjx-prestack > .mjx-presub {display: block}\n.mjx-delim-h > .mjx-char {display: inline-block}\n.mjx-surd {vertical-align: top}\n.mjx-surd + .mjx-box {display: inline-flex}\n.mjx-mphantom * {visibility: hidden}\n.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}\n.mjx-annotation-xml {line-height: normal}\n.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}\n.mjx-mtr {display: table-row}\n.mjx-mlabeledtr {display: table-row}\n.mjx-mtd {display: table-cell; text-align: center}\n.mjx-label {display: table-row}\n.mjx-box {display: inline-block}\n.mjx-block {display: block}\n.mjx-span {display: inline}\n.mjx-char {display: block; white-space: pre}\n.mjx-itable {display: inline-table; width: auto}\n.mjx-row {display: table-row}\n.mjx-cell {display: table-cell}\n.mjx-table {display: table; width: 100%}\n.mjx-line {display: block; height: 0}\n.mjx-strut {width: 0; padding-top: 1em}\n.mjx-vsize {width: 0}\n.MJXc-space1 {margin-left: .167em}\n.MJXc-space2 {margin-left: .222em}\n.MJXc-space3 {margin-left: .278em}\n.mjx-test.mjx-test-display {display: table!important}\n.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}\n.mjx-test.mjx-test-default {display: block!important; clear: both}\n.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}\n.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}\n.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}\n.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}\n.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}\n.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}\n.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}\n.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}\n.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}\n.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}\n.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}\n.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}\n.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}\n.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}\n.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}\n.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}\n.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}\n.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}\n.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}\n.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}\n.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}\n.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}\n.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}\n.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}\n.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}\n.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}\n.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}\n.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}\n.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}\n@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}\n@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}\n@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}\n@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}\n@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}\n@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}\n@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}\n@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}\n@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}\n@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}\n@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}\n@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}\n@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}\n@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}\n@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}\n@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}\n@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}\n@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}\n@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}\n@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}\n@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}\n@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}\n@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}\n@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}\n@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}\n@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}\n</style></span></span></span><p>where</p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"\\begin{align} u(c_t) &amp;= \\frac{c_t^{1-\\eta}}{1-\\eta}, \\;\\;\\; \\eta\\neq 1 \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;(2)\\\\ &amp;= \\log(c_t), \\;\\;\\, \\eta = 1 \\end{align}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mtable\" style=\"vertical-align: -1.856em; padding: 0px 0.167em;\"><span class=\"mjx-table\"><span class=\"mjx-mtr\" style=\"height: 2.987em;\"><span class=\"mjx-mtd\" style=\"padding: 0px 0px 0px 0px; text-align: right; width: 2.074em;\"><span class=\"mjx-mrow\" style=\"margin-top: 0.865em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-strut\"></span></span></span><span class=\"mjx-mtd\" style=\"padding: 0px 0px 0px 0px; text-align: left; width: 12.225em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mfrac MJXc-space3\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 2.425em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"width: 2.425em; top: -1.865em;\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.287em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span><span class=\"mjx-denominator\" style=\"width: 2.425em; bottom: -0.972em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 2.425em;\" class=\"mjx-line\"></span></span><span style=\"height: 2.837em; vertical-align: -0.972em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">\u2260</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-strut\"></span></span></span></span><span class=\"mjx-mtr\" style=\"height: 1.225em;\"><span class=\"mjx-mtd\" style=\"padding: 0.15em 0px 0px 0px; text-align: right;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.2em;\"><span class=\"mjx-strut\"></span></span></span><span class=\"mjx-mtd\" style=\"padding: 0.15em 0px 0px 0px; text-align: left;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.2em;\"><span class=\"mjx-mi\"></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.519em;\">log</span></span><span class=\"mjx-mo\"><span class=\"mjx-char\"></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-strut\"></span></span></span></span></span></span></span></span></span></span></span><p>for some RRA \ud835\udf02 and some discount rate \ud835\udeff.&nbsp;<i>T</i> could be finite, perhaps representing the length of the investor\u2019s life, or infinite, if the investor cares about his descendants or is a philanthropist who cares about distant future impacts.&nbsp;<i>T</i> won\u2019t matter much, as we\u2019ll see.</p><p>The investor begins at time 0 with wealth&nbsp;<i>W</i><sub>0</sub> &gt; 0. There are two assets in which he can invest.</p><ul><li>The first grows more valuable over time at a constant rate&nbsp;<i>r</i>. I.e. if you buy $1 of it at time&nbsp;<i>t</i>, its price at a time&nbsp;<i>s</i> &gt;&nbsp;<i>t</i> is $<i>e<sup>r</sup></i><sup>(</sup><i><sup>s</sup></i><sup>\u2013</sup><i><sup>t</sup></i><sup>)</sup>. It\u2019s essentially a safe bond offering interest rate&nbsp;<i>r</i>.</li><li>The second is risky. Its price jumps around continuously in such a way that, if you buy $1 of it at time&nbsp;<i>t</i>, the price at&nbsp;<i>s</i> &gt;&nbsp;<i>t</i> is lognormally distributed, the associated normal distribution having mean \ud835\udf07(<i>s</i>\u2013<i>t</i>) for some \ud835\udf07 &gt;&nbsp;<i>r</i> and variance \ud835\udf0e<sup>2</sup>(<i>s</i>\u2013<i>t</i>) for some \ud835\udf0e &gt; 0. The risky asset is like an index fund of stocks, offering higher expected returns than the bond but an ever-widening distribution of possible returns as we consider times&nbsp;<i>s</i> ever further in the future from the purchase date&nbsp;<i>t</i>. \ud835\udf07\u2013<i>r</i> is the equity premium.</li></ul><p>The investor\u2019s wealth at&nbsp;<i>t</i> is denoted&nbsp;<i>W<sub>t</sub></i>.&nbsp;<i>W<sub>t</sub></i> depends on four things: his initial wealth&nbsp;<i>W</i><sub>0</sub>, how quickly he\u2019s been consuming, how much of his savings have been invested in the risky asset, and how well the risky asset has performed.</p><p>At each time&nbsp;<i>t</i>, our investor has two questions to answer. First is how fast he should consume at&nbsp;<i>t</i>: i.e. what \ud835\udf08<i><sub>t</sub></i> should be, where \ud835\udf08<i><sub>t</sub></i> denotes his consumption rate at&nbsp;<i>t</i> as a proportion of&nbsp;<i>W<sub>t</sub></i>. Second is, of the wealth not yet consumed, what fraction \ud835\udf0b<i><sub>t</sub></i> he should hold in stocks.</p><p>As it turns out, under the assumptions above,<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefpt1yd241ut\"><sup><a href=\"#fnpt1yd241ut\">[24]</a></sup></span>&nbsp;\ud835\udf0b should be constant over time, equaling</p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"\\pi^* = \\frac{\\mu-r}{\\eta \\sigma^2}.\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;(3)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.003em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.076em; padding-right: 0.071em;\"><span class=\"mjx-mo\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.298em;\">\u2217</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mfrac MJXc-space3\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 2.476em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"width: 2.476em; top: -1.389em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03bc</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span></span></span><span class=\"mjx-denominator\" style=\"width: 2.476em; bottom: -1.059em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.001em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.001em;\">\u03c3</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.409em; padding-left: 0.073em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 2.476em;\" class=\"mjx-line\"></span></span><span style=\"height: 2.448em; vertical-align: -1.059em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">3</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span><p>If&nbsp;<i>T&nbsp;</i>= \u221e, then \ud835\udf08 should also be constant over time, equaling</p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"\\nu^* = \\frac{r\\eta - r + \\delta}{\\eta} + (\\eta-1)\\frac{(\\mu-r)^2}{2\\sigma^2\\eta^2}. \\;\\;\\; (4)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.036em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.036em;\">\u03bd</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.137em; padding-right: 0.071em;\"><span class=\"mjx-mo\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.298em;\">\u2217</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mfrac MJXc-space3\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 4.501em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"width: 4.501em; top: -1.523em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.007em;\">\u03b4</span></span></span></span><span class=\"mjx-denominator\" style=\"width: 4.501em; bottom: -0.927em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 4.501em;\" class=\"mjx-line\"></span></span><span style=\"height: 2.45em; vertical-align: -0.927em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mn MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 3.643em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"width: 3.643em; top: -1.667em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03bc</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span><span class=\"mjx-denominator\" style=\"width: 3.643em; bottom: -1.059em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.001em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.001em;\">\u03c3</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.409em; padding-left: 0.073em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.409em; padding-left: 0.082em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 3.643em;\" class=\"mjx-line\"></span></span><span style=\"height: 2.725em; vertical-align: -1.059em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">4</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span><p>This is explained in <a href=\"https://forum.effectivealtruism.org/posts/cf8Dth9vpxX9ptgma/against-much-financial-risk-tolerance#Understanding_the_model\">Appendix D: Understanding the model</a>. If&nbsp;<i>T</i> is finite, the formula for&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\nu_t^*\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.036em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.036em;\">\u03bd</span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.287em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0.137em; padding-right: 0.071em;\"><span class=\"mjx-mo\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.298em;\">\u2217</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span></span></span></span></span>&nbsp;is more complicated, and should rise as&nbsp;<i>t</i> approaches&nbsp;<i>T</i>. But this post is about \ud835\udf0b, which in this model is independent of&nbsp;<i>T</i>, so for simplicity we\u2019ll just work with the&nbsp;<i>T&nbsp;</i>= \u221e case.</p><h2>The equity premium puzzle argument</h2><p>Of course, the assumptions of Merton\u2019s model are not exactly accurate. There are different kinds of bonds, for instance, and none of them literally offer a risk-free interest rate. Still, though, the model is arguably accurate enough that we can try to \u201ccalibrate\u201d its variables: i.e., find values of the variables that relatively closely match the preferences and circumstances that typical investors face. In that spirit, here are some ballpark calibrations of all the variables except \ud835\udf02.</p><ul><li>\ud835\udeff = 0.01,</li><li><i>r</i> = 0.01,</li><li>\ud835\udf07 = 0.06,</li><li>\ud835\udf0e = 0.14.</li></ul><p>Likewise, we can calibrate \ud835\udf0b and \ud835\udf08 to our observations of people\u2019s investment portfolios and saving rates. A standard calibration of \ud835\udf0b is 0.6, as noted in the introduction, and a standard calibration of \ud835\udf08 is 0.016.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefp4b9jnyu8jf\"><sup><a href=\"#fnp4b9jnyu8jf\">[25]</a></sup></span></p><p>This presents a puzzle. Rearranging (3), people seem to be holding bonds at a rate that only makes sense if the curvature of their utility functions equals</p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"\\eta = \\frac{\\mu-r}{\\pi\\sigma^2} \\approx 4.25. \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\; (5)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mfrac MJXc-space3\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 2.476em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"width: 2.476em; top: -1.389em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03bc</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span></span></span><span class=\"mjx-denominator\" style=\"width: 2.476em; bottom: -0.854em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.001em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.001em;\">\u03c3</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.409em; padding-left: 0.073em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 2.476em;\" class=\"mjx-line\"></span></span><span style=\"height: 2.243em; vertical-align: -0.854em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u2248</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">4.25.</span></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">5</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span><p>But rearranging (4) (and using the quadratic formula), people seem to be saving at a rate that only makes sense if<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefhk1ehlruphn\"><sup><a href=\"#fnhk1ehlruphn\">[26]</a></sup></span></p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"\\eta = \\frac{r-\\delta-(\\mu-r)^2/(2\\sigma^2)+\\sqrt{(r-\\delta-(\\mu-r)^2/(2\\sigma^2))^2+4(r-\\nu)(\\mu-r)^2/(2\\sigma^2)}}{2(r-\\nu)}\\approx 1.12.\\;\\;\\;\\;(6)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mfrac MJXc-space3\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 33.685em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"width: 33.685em; top: -1.85em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.007em;\">\u03b4</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03bc</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.001em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.001em;\">\u03c3</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0.073em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-msqrt MJXc-space2\"><span class=\"mjx-box\" style=\"padding-top: 0.045em;\"><span class=\"mjx-surd\"><span class=\"mjx-char MJXc-TeX-size1-R\" style=\"padding-top: 0.593em; padding-bottom: 0.593em;\">\u221a</span></span><span class=\"mjx-box\" style=\"padding-top: 0.061em; border-top: 1px solid;\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.007em;\">\u03b4</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03bc</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.409em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.001em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.001em;\">\u03c3</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.409em; padding-left: 0.073em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.409em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mn MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">4</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.036em;\">\u03bd</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03bc</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.409em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.001em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.001em;\">\u03c3</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.409em; padding-left: 0.073em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span></span><span class=\"mjx-denominator\" style=\"width: 33.685em; bottom: -1.09em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.036em;\">\u03bd</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 33.685em;\" class=\"mjx-line\"></span></span><span style=\"height: 2.94em; vertical-align: -1.09em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u2248</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1.12.</span></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">6</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span><p>One way of putting this is that, given the only-moderately-above-1 \ud835\udf02 we estimate from people\u2019s saving rates (and other estimates of how people trade off consumption between periods, which we won\u2019t get into here), the equity premium \ud835\udf07\u2013<i>r</i> is too high to explain the low \ud835\udf0b people choose.</p><p>But this is only a puzzle if the assumptions of the Merton model are valid. If they\u2019re not, then a low choice of \ud835\udf0b and a high choice of \ud835\udf08 might be compatible. Many tweaks to the model have been proposed which reconcile this pair of choices. Here are four, for illustration.</p><h3>Tail risk</h3><p>The Merton model assumes that stock prices follow a geometric random walk. But historically, they haven\u2019t: sudden collapses in stock prices are much more common than sudden jumps of a similar proportional size. As many (e.g.&nbsp;<a href=\"https://www.jstor.org/stable/30034086\"><u>Weitzman, 2006</u></a>) have shown, this might make it rational for people to buy a lot of bonds, even if their \ud835\udf02\u2019s aren\u2019t all that high and they still want to do a lot of saving.</p><p>Of course, this applies to philanthropists just as much as to anyone else.</p><h3>Habit formation</h3><p>The Merton model assumes that an individual\u2019s utility at a given time&nbsp;<i>t</i> depends only on her own consumption&nbsp;<u>at&nbsp;</u><i><u>t</u></i>. But people might value consumption more at times when they have recently been consuming more. As many (e.g.&nbsp;<a href=\"https://pages.stern.nyu.edu/~dbackus/BCZ/Abel%20Joneses%20AER%2090.pdf\"><u>Abel (1990)</u></a>) have shown, this too might make it rational for people to buy a lot of bonds. Even if a drop in consumption won\u2019t be so bad once you\u2019ve acclimated to it, the pain of moving to the lower level, and perhaps back up again, makes it valuable to hold some of one\u2019s wealth in assets whose value is more reliable.</p><p>This effect is usually called \u201chabit formation\u201d, since the most obvious way it can arise is if people literally develop expensive habits. But it can also arise whenever there are concrete transition costs associated with moving between levels of consumption. Suppose you fall on hard times and have to move to a smaller apartment. The walls of your apartment don\u2019t just slide in; you have to pack your boxes and rent a van.</p><p>Similar transition costs presumably apply in the nonprofit setting. An organization whose funding is cut has to pay the cost of moving to a smaller office, and some of its employees, instead of hopping immediately to some other valuable line of work, face the costs that come with changing jobs. A philanthropist presumably values the time and other resources of the nonprofits that receive her funding, and so prefers being able to pay out a steady funding stream, to avoid imposing such costs.</p><h3>Keeping up with the Joneses</h3><p>The Merton model assumes that an individual\u2019s utility at a given time&nbsp;<i>t</i> depends only on&nbsp;<u>her own</u> consumption at&nbsp;<i>t</i>. But people might value consumption more at a time when others are also consuming more. That is, they might especially prefer to avoid scenarios in which they\u2019re poor but others are rich. This effect is usually called \u201ckeeping up with the Joneses\u201d, since one way it can arise is if people care intrinsically to some extent about their place in the income distribution. But this preference can also arise instrumentally. Some people might especially want to buy things in fixed supply, like beachfront property, which are less affordable the richer others are.</p><p>Again, as e.g.&nbsp;<a href=\"https://crei.cat/wp-content/uploads/2016/07/gali_jmcb1994.pdf\"><u>Gal\u00ed (1993)</u></a> shows, this can make it rational to invest less riskily, since risky investing leaves one poorer than one\u2019s former peers if the risky investments do badly. Note that it also leaves one richer than one\u2019s former peers if the risky investments do well, though, so for this effect to motivate more cautious investment on balance, one has to have diminishing marginal utility in one\u2019s relative place. The boost that comes with moving from the bottom of the pack to the middle has to be greater than the boost that comes with moving from the middle to the top.&nbsp;</p><p>Philanthropists might care about their place in the distribution too\u2014perhaps even more than most others. They might care somewhat about their \u201cinfluence\u201d, for example, in the way proposed by&nbsp;<a href=\"https://rationalaltruist.com/2013/02/28/risk-aversion-and-investment-for-altruists/\"><u>Christiano (2013)</u></a> and discussed at the end of <a href=\"https://forum.effectivealtruism.org/posts/cf8Dth9vpxX9ptgma/against-much-financial-risk-tolerance#Against_logarithmic_utility_as_a_baseline\">the \u201cAgainst logarithmic utility\u2026\u201d sub-subsection</a>. Recall, though, that on the model Christiano proposes, the philanthropist cares&nbsp;<i>only</i> about her relative place\u2014more precisely, about the fraction of all wealth she owns\u2014and her utility is linear in this fraction. As he notes, such a philanthropist should invest roughly as if she has logarithmic utility in her&nbsp;<i>own&nbsp;</i>wealth, which would mean investing more risk tolerantly than most people do. By contrast, in a standard \u201ckeeping up with the Joneses\u201d model, being relatively richer comes with diminishing marginal utility, as noted in the previous paragraph, and this effect exists alongside the standard sort of<i>&nbsp;</i>diminishing marginal utility in one\u2019s own resources.</p><h3>New products</h3><p>The Merton model assumes that an individual\u2019s utility at a given time&nbsp;<i>t</i> always depends&nbsp;<u>in the same way</u> on her own consumption at&nbsp;<i>t</i>. But even if one\u2019s utility level is, at any given time, only a function of one\u2019s own consumption, the shape of the function can change over time for various reasons. One such reason that I\u2019ve explored a bit (<a href=\"https://philiptrammell.com/static/New_Products_and_Long_term_Welfare.pdf\"><u>PDF</u></a>,&nbsp;<a href=\"https://www.youtube.com/watch?v=Q73nUsA57mM\"><u>video</u></a>) could be the introduction of new products. Consider an early society in which the only consumption goods available are local agricultural products. In such a society, once you have acquired enough food, clothing, and shelter to meet your basic needs\u2014a basket of goods that would cost very little at today\u2019s prices\u2014the marginal utility of further consumption might be low. Later in time, once more products have been developed, marginal utility in consumption&nbsp;<i>at the same level of consumption</i> might be higher.</p><p>Once again, this can make a low \ud835\udf0b* compatible with a high \ud835\udf08*. \ud835\udf02 may really be very high at any given time, motivating people to hold a lot of the wealth they invest for consumption at any given future time in bonds. But unlike in the Merton model, even if we posit such a high \ud835\udf02, people might still be willing to save as much as they currently do. They will probably be richer in the future, and this significantly lowers their marginal utility in consumption&nbsp;<i>relative to what it would have been if their consumption had stagnated at its current level</i>, because \ud835\udf02 is high. But their marginal utility consumption may not fall much&nbsp;<i>relative to what it is today</i>, since new products will raise the marginal utility in consumption at any given level of consumption. On this account, young savers in, say, 1960 were saving in part to make sure they would be able to afford air conditioners, computers, and so on, once such products became available. But they saved largely in bonds, because they understood that what really matters is usually the ability to afford the new goods at least in small quantities, not the ability to afford many copies of them.</p><p>Once again, philanthropists might be in a similar situation. The philanthropic utility function at any given time might exhibit a high \ud835\udf02. But a philanthropist might still find it worthwhile to save a lot for the future, even on the assumption that funding levels will be higher than they are today, because in the meantime, a wider range of funding opportunities will be available, as cause areas mature and new projects begin, all of which will benefit greatly from a little bit of funding.</p><p>I don\u2019t think this \u201cnew products\u201d (/projects) effect is the most important driver of the equity premium puzzle. But in <a href=\"https://forum.effectivealtruism.org/posts/cf8Dth9vpxX9ptgma/against-much-financial-risk-tolerance#Adding_new_products_to_the_model\">Appendix D: Adding new products to the model</a>, I use it to quantitatively illustrate how these effects can in principle resolve the puzzle, because it yields the simplest equations.&nbsp;</p><p>----------</p><p>For brevity, we\u2019ve only covered four possible resolutions to the equity premium puzzle. Many more have been proposed. Of the four we\u2019ve covered, only the first applies equally to philanthropists and to other investors. The other three apply similarly, I think, but could apply somewhat more or less strongly than average to philanthropists. More could be said on this, but on balance, my understanding is that the phenomenon of the equity premium puzzle doesn\u2019t give us much reason to think that philanthropists should invest more (or less) riskily than average.&nbsp;&nbsp;</p><h2>The lifecycle argument</h2><p>As noted at the beginning of this section, there\u2019s another way in which Merton\u2019s model is sometimes used to argue that a philanthropist should invest more risk tolerantly than most people do invest, even if philanthropic and individual utility functions look the same. The reason\u2014stated a bit more formally now that we\u2019ve introduced the model\u2014is that the model only tells you the fraction \ud835\udf0b of your wealth to invest in stocks if all your wealth is already \u201cin the bank\u201d. If you have a source of outside income (such as a career), then this source is like another asset, offering its own distribution of possible future returns (such as wages). The portfolio you should adopt for your wealth \u201cin the bank\u201d should be such that, in conjunction with the \u201casset\u201d generating the outside income, the&nbsp;<i>combined&nbsp;</i>portfolio exhibits the desired tradeoff between safety and expected returns.</p><p>Applied to individuals, the reasoning typically looks something like this. Wages don\u2019t jump around wildly, like stock returns. They grow steadily and reliably over the course of a career, more like bond payments. A person early in his career usually doesn\u2019t yet have much wealth in the bank, but does have a long career ahead of him, so his \u201cwealth\u201d in the broader sense consists mostly of the relatively low-risk asset that is the rest of his career. As his career progresses, this situation reverses. But equation (3) tells us that the fraction \ud835\udf0b of his \u201cwealth\u201d in risky investments should stay constant. So, over the course of his life, he should shift from holding all his financial wealth in stocks\u2014or even \u201cmore than all of it\u201d, via leverage\u2014to holding a mix of stocks and bonds. This is often called&nbsp;<i>lifecycle investing</i>, a term coined by Nalebuff and Ayres, who wrote a popular 2010&nbsp;<a href=\"https://www.amazon.co.uk/Lifecycle-Investing-Audacious-Performance-Retirement-ebook/dp/B06XD7FZGG\"><u>book</u></a> promoting this way of thinking.</p><p>The \u201clifecycle argument\u201d for unusual financial risk tolerance by philanthropists then goes as follows. Most of the resources, in the broader sense, of a typical philanthropic community\u2014most of those that will ever be put toward its philanthropic utility function\u2014don\u2019t consist of financial assets that the community already possesses. Rather, they consist of \u201coutside income\u201d: contributions that are yet to arrive, including many from people who are not yet members of the community. So a philanthropic community is usually like a person early in his career. The small fraction of its total wealth that its current members&nbsp;<i>do&nbsp;</i>control more tangibly, they should invest in stocks, perhaps with leverage. See, again,&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/g4oGNGwAoDwyMAJSB/how-much-leverage-should-altruists-use#Time_diversification\"><u>Dickens (2020) (The \u201cTime diversification\u201d section)</u></a> for an example of this argument being made.&nbsp;</p><p>But this analogy relies on the assumption that the possibility of outside contributions is like a giant bond. In fact, if we\u2019re going to model the possible future funding provided by the rest of the world as an&nbsp;<i>asset</i>, it\u2019s a very risky one: philanthropic fads and hot policy agenda items come and go, leaving the distribution of future funding for a given cause often very uncertain. I.e. the \u201coutside-income asset\u201d, as we might call it, comes with a lot of idiosyncratic risk. And because it constitutes such a large fraction of the community\u2019s total \u201cwealth\u201d, this is idiosyncratic risk of the sort that the community&nbsp;<i>does</i> care about, and should want to diffuse with bonds or anticorrelated investments\u2014not the idiosyncratic risk that comes with an individual proportionally small philanthropist\u2019s startup and is diluted by the uncorrelated bets of other members.</p><p>The outside-income asset also presumably tends to come with a fair bit of systematic risk. When the economy is doing poorly and stock prices are down, people have less to give to any given cause. It\u2019s true that, since the world at large isn\u2019t entirely invested in stocks, new contributions to a given cause probably don\u2019t fluctuate as much as if the \u201casset\u201d were literally stocks. But recall that an unusually large fraction of new EA funding comes from the founders of tech startups, which exhibit high \u201cbeta\u201d, as noted in <a href=\"https://forum.effectivealtruism.org/posts/cf8Dth9vpxX9ptgma/against-much-financial-risk-tolerance#With_idiosyncratic_risk\">the sub-subsection on proportionally small philanthropists with idiosyncratic risk</a>. So I would guess that the outside-income asset exhibits even more systematic risk for the EA community than for most philanthropic communities.</p><p>I don\u2019t think there\u2019s any need to think about this philanthropic investment question from scratch with a tweaked analogy to an individual and his future wages. The math of the \u201clifecycle\u201d-style adjustment to Merton\u2019s original model that a philanthropist should adopt, in light of the real but risky possibilities of future outside contributions, was worked out by&nbsp;<a href=\"https://www.nber.org/system/files/chapters/c6102/c6102.pdf\"><u>Merton himself in 1993</u></a>. But the relevant upshot is: suppose the outside-income asset behaves more like the \u201crisky asset\u201d than like the \u201csafe asset\u201d, in Merton\u2019s model. Then for any given target \u201c\ud835\udf0b\u201d, the more of your wealth is tied up in the outside-income asset, the&nbsp;<i>more</i> of the rest of your wealth you should hold in bonds.</p><p>In other words, what we need most isn\u2019t more high-risk, high-return investments; we already have&nbsp;<i>possible future contributions from the rest of the world</i> for that. What we need is a guarantee that we\u2019ll be able to cover the most important future philanthropic opportunities in case markets crash and the rest of the world doesn\u2019t show up.</p><h1>Arguments for equities</h1><p>This section will briefly cover three arguments for why philanthropists might consider equities more (or less) valuable than other people, even if they\u2019re not particularly risk tolerant (or averse)&nbsp;<i>per se</i> and none of the arguments above for behaving unusually risk tolerantly (/aversely) go through.</p><p>These won\u2019t be arguments that philanthropists should mind financial risk more or less&nbsp;<i>per se</i>. At best they\u2019ll be arguments that a philanthropist should choose a portfolio which has more or less than the usual share of stocks, and which therefore happens to be unusually safe or risky.</p><h2>Mispricing</h2><p>A philanthropist, like anyone else, may have reason to believe that financial markets are not very efficient, and that stocks as a whole, or certain stocks, are currently mispriced. If so, she should skew her portfolio toward or away from (perhaps particular) stocks, relative to whatever would have been optimal otherwise.</p><p>Such beliefs may follow from her philanthropy. For instance, maybe a search for ways to do the most good has motivated philanthropists in the EA community to reach an unusually deep understanding of the potential of AI, including an unusually accurate assessment of the chance that advances in AI will soon significantly increase the returns to capital.</p><p>For my part, I used to think it was almost always a mistake for someone to think they could beat the market like this (and I\u2019m still a bit skeptical), but now I don\u2019t think it\u2019s so unreasonable to think&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/nsLTKCd3Bvdwzj9x8/ingroup-deference\"><u>we can, at least to a moderate extent</u></a>. In any event, this seems like a question on which people basically just have to use their judgment.</p><h2>Mission hedging</h2><p>It\u2019s typically assumed that an individual\u2019s utility function doesn\u2019t depend on how well the stock market (or any particular company) is doing, except via how it affects his own bank account.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefkqttsysqmye\"><sup><a href=\"#fnkqttsysqmye\">[27]</a></sup></span>&nbsp;But a philanthropic utility function might look different in different macroeconomic scenarios, for reasons that have nothing to do with the funding available for any given cause. That is, for philanthropists focusing on certain issues, resources might be more (or less) valuable when the market is booming,&nbsp;<i>before&nbsp;</i>accounting for the fact there are then more (or fewer) resources available to spend.</p><p>For example, AI risk mitigation might be an issue toward which resources are more valuable in a boom. Maybe boom scenarios are disproportionately scenarios in which AI capabilities are advancing especially quickly, and maybe these in turn are scenarios in which resources directed toward AI risk mitigation are especially valuable.</p><p>It might also be an issue toward which resources are&nbsp;<i>less&nbsp;</i>valuable when the market is booming. Maybe scenarios in which AI capabilities are accelerating economic growth, instead of starting to cause mayhem, are scenarios in which AI is especially under control, and maybe these in turn are scenarios in which resources directed toward AI risk mitigation are less valuable.</p><p>Philanthropists focusing on issues of the first kind should be unusually willing to buy stocks, and so should probably have unusually risky portfolios. Philanthropists focusing on issues of the first kind should be unusually unwilling to buy stocks, and so should probably have unusually safe portfolios. This is discussed more formally by&nbsp;<a href=\"https://pubs.aeaweb.org/doi/pdfplus/10.1257/aeri.20180347\"><u>Roth Tran (2019)</u></a>, and some in the EA community have thought more about the implications of mission hedging in the EA case.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreffqzr2vwbye\"><sup><a href=\"#fnfqzr2vwbye\">[28]</a></sup></span>&nbsp;I haven\u2019t thought about it much, and don\u2019t personally have strong opinions about whether the most important-seeming corners of philanthropy on the whole are more like the first kind or the second kind.</p><h2>Activist investing</h2><p>Throughout this document, we\u2019ve been assuming that the only difference between stocks and bonds is that they offer different distributions of financial returns. But another small difference is that stocks but not bonds usually give their owners the right to vote on how a company is run. The philanthropic impact an investor can have by exercising this right was emphasized on this forum by&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/fqf4vgCWebTszvHm9/shareholder-activism\"><u>Behmer (2022)</u></a>. If an investor values that right, he should want to hold more of his wealth in stocks.</p><p>By the same token, though, if he just wants to invest passively, like almost all investors, then he should expect that stock prices are slightly higher than they would otherwise be, having been bid up a bit by the few investors who do value their voting rights. I would have thought that this effect would be negligible, but see the first table&nbsp;<a href=\"https://www.stout.com/en/insights/article/price-differentials-between-voting-and-nonvoting-stock\"><u>here</u></a>: for companies that issue both stock with voting rights and stock without, apparently the stock without voting rights is a few percent cheaper, which isn\u2019t nothing. In any event, an investor not planning to make use of his voting rights should prefer the cheaper, non-voting stock when it\u2019s available, and when it\u2019s not, should want to hold slightly more of his wealth in other assets like bonds.</p><p>A philanthropist might know enough about the details of some firm or industry that they can make a difference by \u201cactivist investing\u201d: say, by buying large stakes in particular firms and voting (or even organizing votes) against its most destructive practices. If a foundation or philanthropic community is large enough, it may be worth someone putting in the effort to research and advise on how to implement some investor activism. But my guess is that this will only ever be a minor consideration, at best marginally tweaking the optimal portfolio at all, and only very, very slightly making it riskier on the whole (instead of just shifting it toward some risky investments and away from others).</p><h1>Conclusion</h1><p>There are many conceivable reasons why philanthropists might want to invest unusually safely or riskily. Here is a summary of the reasons considered in this document, organized by the direction of the implications they have,&nbsp;<u>in my view</u>.</p><p><i>Justifying a riskier portfolio</i></p><ul><li><strong>The \u201csmall fish in a big pond + idiosyncratic risk\u201d argument, part 1:</strong><br>Proportionally small philanthropists should be more inclined to take investment opportunities with a lot of idiosyncratic risk, like startups.</li><li><strong>The \u201ccause variety\u201d argument:</strong><br>Cause-neutral philanthropists can expand or contract the range of cause areas they fund in light of how much money they have. This lets marginal utility in spending diminish less quickly as the money scales up.</li><li><strong>The \u201cmispriced equities\u201d argument:</strong><br>Certain philanthropists might develop domain expertise in certain areas which informs them that certain assets are mispriced. [This could push in either direction in principle, but the motivating case to my mind is a belief that the EA community better appreciates the fact that a huge AI boom could be coming soon.]</li><li><strong>The \u201cactivist investing\u201d argument, if it\u2019s worth it:</strong><br>Stock owners can vote on how a firm is run. Some philanthropists might know enough about the details of some firm or industry that it\u2019s worthwhile for them to buy a lot of stock in that area and participate actively like this\u2014voting against a firm\u2019s bad practices, say\u2014despite the fact that this will probably make their portfolios riskier.</li></ul><p><i>Justifying a more cautious portfolio</i></p><ul><li><strong>The \u201csmall fish in a big pond + idiosyncratic risk\u201d argument, part 2:</strong><br>Proportionally small philanthropists&nbsp;<i>without&nbsp;</i>startups should invest especially cautiously, to dilute the risk that others\u2019 startups bring to the collective portfolio.</li><li><strong>The \u201clifecycle\u201d argument:</strong><br>The distribution of future funding levels for the causes supported by a given community tends to be high-variance even independently of the financial investments we make today; risky investments only exacerbate this. [I think this is especially true of the EA community.]</li><li><strong>The \u201cactivist investing\u201d argument, if it\u2019s not worth it:</strong><br>Activist investing may be more trouble than it\u2019s worth, and the fact that stocks come with voting rights slightly raises stock prices relative to bond prices.</li></ul><p><i>Directionally ambiguous</i></p><ul><li><strong>Arguments from the particulars of current top priorities:</strong><br>The philanthropic utility function for any given \u201ccause\u201d could exhibit more or less curvature than a typical individual utility function.</li><li><strong>The \u201ctruncated lower tail\u201d argument:</strong><br>The philanthropic utility function\u2019s \u201cworst-case scenario\u201d\u2014the utility level reached if no resources end up put toward things considered valuable at all\u2014 might bottom out in a different place from a typical individual utility function\u2019s worst-case scenario.</li><li><strong>Arguments from uncertainty:</strong><br>Philanthropists may be more uncertain about the relative impacts of their grants than individuals are about how much they enjoy their purchases. This extra uncertainty could flatten out an \u201c<i>ex ante</i> philanthropic utility function\u201d, or curve it further.</li><li><strong>The \u201cequity premium puzzle\u201d argument:</strong><br>The reasons not captured by the Merton model for why people might want to buy a lot of bonds despite a large equity premium could, on balance, apply to philanthropists more or less than they apply to most others.</li><li><strong>The \u201cmission hedging\u201d argument:</strong><br>Scenarios in which risky investments are performing well could tend to be scenarios in which philanthropic resources in some domain are more or less valuable than usual (before accounting for the fact that how well risky investments are performing affects how plentiful philanthropic resources in the domain are).</li></ul><p><i>No (or almost no) implications</i></p><ul><li><strong>The \u201csmall fish in a big pond\u201d argument without idiosyncratic risk:</strong><br>Small philanthropists supporting a common cause, who have access to the same investment opportunities, should (collectively) invest as risk aversely as if they each were the cause\u2019s only funders.</li><li><strong>The \u201clogarithmic utility as a baseline\u201d argument:</strong><br>None of the&nbsp;<i>a priori</i> arguments I\u2019m aware of for assuming a logarithmic philanthropic utility function are valid.</li></ul><p>We\u2019re left with the question of how all these arguments combine. I haven\u2019t come close to trying to work this out formally, since so many of the relevant numbers would be made up. Ongoing Open Phil work may make more progress on this front. But for whatever it\u2019s worth, my own central guess at the moment, with wide uncertainty, is that philanthropists\u2014at least in the EA space, which I\u2019ve thought most about\u2014should invest about as risk tolerantly as other relatively cause-neutral philanthropists do on average (i.e. foundations rather than universities), which is only slightly more risk tolerantly than individuals invest for themselves.</p><p>There are other arguments one might consider, of course. I haven\u2019t explored the implications of tax policy, for instance. But I\u2019m not aware of other arguments that seem important enough to have much chance of overturning the broad conclusion.</p><p>To close, it may be worth noting a connection between this post and&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/nsLTKCd3Bvdwzj9x8/ingroup-deference\"><u>another I wrote recently</u></a>. There, I reflected on the fact that a lot of my research, attempting to adhere to a sort of epistemic modesty, has followed the following template: (a) assume that people are typically being more or less rational, in that they\u2019re doing what best achieves their goals; and then (b) argue that the EA community should copy typical behavior, except for a short list of tweaks we can motivate by replacing typical goals with the goal of doing the most good. I then explained that I don\u2019t think this template is as reasonable as I used to. I now think there are some questions without much direct connection to doing good on which \u201cEA thought\u201d is nonetheless surprisingly reliable, and that on these questions, it can be reasonable for EA community practice to depart from conventional wisdom.</p><p>I also noted that one such question, to my mind, is whether advances in AI will dramatically increase the economic growth rate. I think there\u2019s a good chance they will: a belief that is widespread in the EA community but seems to be rare elsewhere, including in the academic economics community. And I think that, all else equal, this should motivate riskier investment than we observe most people adopting, as noted in <a href=\"https://forum.effectivealtruism.org/posts/cf8Dth9vpxX9ptgma/against-much-financial-risk-tolerance#Mispricing\">the \u201cmispricing\u201d subsection</a>.</p><p>But otherwise, here, I have followed the \u201ctemplate\u201d. I\u2019m taking typical observed levels of financial risk aversion as my default, instead of old intuitions from the EA sphere and dismissive claims that most people invest irrationally. This is because, at least from what I\u2019ve read and heard, \u201cEA thought\u201d on philanthropy and financial risk seems surprisingly&nbsp;<i>un</i>reliable, and unreliable in surprisingly important ways. Indeed, as I won\u2019t be the first to point out, it seems that confused thinking on philanthropy and financial risk partly explains Sam Bankman-Fried\u2019s willingness to take such absurd gambles with FTX. In sum, I\u2019m not saying we should never depart from conventional wisdom, in finance or anything else. I\u2019m just saying we should be more careful.</p><p><i>Thanks to Michael Dickens, Peter Favaloro, John Firth, Luis Mota, Luca Righetti, Ben Todd, Matt Wage, and others for reviewing the post and giving many valuable comments on it. Thanks also to Ben Hilton, Ben Hoskin, Michelle Hutchinson, Alex Lawsen, members of the LSE economics and EA societies, and others for other valuable conversations about this topic that influenced how the post was written.</i></p><p>&nbsp;</p><h1>Appendix A: Decreasing returns to proportional wealth</h1><p>Suppose that, at some future time&nbsp;<i>t</i>, the subsequent course of civilization will be determined by a grand bargain between two actors: the EA community (\u201cEA\u201d), which wants to fill the universe with \u201chedonium\u201d (computer simulations of bliss), and an eccentric billionaire (\u201cEB\u201d), who wants to fill the universe with monuments to himself. Both utility functions are linear, and neither actor considers the other\u2019s goal to be of any value.</p><p>Suppose that by default, if at&nbsp;<i>t</i> party&nbsp;<i>i</i> has fraction&nbsp;<i>x<sub>i</sub>&nbsp;</i>of the world\u2019s resources, they very tangibly have \u201cfraction&nbsp;<i>x<sub>i</sub></i> of the influence\u201d: they get to build fraction&nbsp;<i>x<sub>i</sub></i> of the self-replicating robot rockets, and ultimately fill fraction&nbsp;<i>x<sub>i</sub></i> of the universe with the thing you value. With no possibility of gains from trade\u2014no room for compromise\u2014party&nbsp;<i>i</i>\u2019s utility,&nbsp;<i>u<sub>i</sub></i>, is linear in&nbsp;<i>x<sub>i</sub></i>.</p><p>But with room for gains from trade, the situation looks different. For simplicity, let\u2019s normalize&nbsp;<i>u<sub>i</sub></i> to 0 at&nbsp;<i>x<sub>i</sub></i> = 0 and&nbsp;<i>u<sub>i</sub></i> to 1 at&nbsp;<i>x<sub>i</sub></i> = 1. Also note that&nbsp;<i>x<sub>EB</sub></i> = 1\u2013<i>x<sub>EA</sub></i>, so we have&nbsp;<i>u<sub>EA</sub></i>(<i>x<sub>EA</sub></i>) =&nbsp;<i>x<sub>EA</sub></i> and&nbsp;<i>u<sub>EB</sub></i>(<i>x<sub>EA</sub></i>) = 1\u2013<i>x<sub>EA</sub></i>. The situation then looks like this:</p><figure class=\"image image_resized\" style=\"width:66.11%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cf8Dth9vpxX9ptgma/bkp8jo4j26qyner89yfp\"><figcaption>Figure 4</figcaption></figure><p>The dotted line represents the utility levels achieved by each actor without gains from trade, given some&nbsp;<i>x</i> from 0 to 1. The \u201cutility profile\u201d (pair of utility levels) achieved without trade is called the \u201cdefault point\u201d. The light blue region represents the set of possible \u201cPareto improvements\u201d (utility profiles that both parties would prefer to the default point). Instead of filling 80% of the universe with hedonium and 20% of it with monuments to EB, the parties could agree to, say, fill the whole universe with computer simulations in which EB is experiencing bliss: only slightly less efficient at producing bliss than simulations that don\u2019t have to include the details of EB\u2019s biography, and only slightly less efficient at leaving a grand legacy to EB than other kinds of monuments.</p><p>The general point I want to make is that gains from trade would tend to produce diminishing marginal utility to proportional wealth. This point doesn\u2019t depend on the shape of the possibilities frontier or on the way in which the actors bargain over what Pareto improvement they settle on. When&nbsp;<i>x<sub>i</sub></i> = 1, you do exactly what you want, so&nbsp;<i>u<sub>i</sub></i> =&nbsp;<i>x<sub>i</sub></i> = 1, but when&nbsp;<i>x<sub>i</sub></i> &lt; 1,&nbsp;<i>u<sub>i</sub></i> &gt;&nbsp;<i>x<sub>i</sub>&nbsp;</i>if there are any gains from trade. So \u201con average\u201d, the utility gains from moving from some&nbsp;<i>x<sub>i</sub></i> &lt; 1 toward&nbsp;<i>x<sub>i</sub></i> = 1 are sublinear in the proportional wealth gains.</p><p>Nonetheless, I thought it might be interesting to look quantitatively at the coefficient of relative risk aversion&nbsp;<u>in&nbsp;</u><i><u>x</u><sub><u>i</u></sub></i> given some more specific, vaguely reasonable-seeming assumptions. (Recall that an RRA of 0 here would motivate investing like you have logarithmic utility, not linear utility.) So, first, let\u2019s assume that the possibilities frontier is a quarter-circle, as in Figure 4 above. And second, let\u2019s assume that the outcome of the bargaining process is the&nbsp;<a href=\"https://en.wikipedia.org/wiki/Cooperative_bargaining#Nash_bargaining_solution\"><u>Nash bargaining solution</u></a>: the Pareto improvement that maximizes the product of possible utility-gains from the default point. As explained in the link above, parties implement the Nash bargaining solution as long as their bargaining process satisfies a relatively short and intuitively appealing list of axioms.</p><p>Under the quarter-circle assumption, the possibilities frontier follows the equation</p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"u_{EA}^2+u_{EB}^2=1.\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.35em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;\">E</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.327em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;\">E</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1.</span></span></span></span></span></span></span><p>So if the parties reach the possibilities frontier, which they must in the Nash bargaining solution, the&nbsp;<i>u<sub>EB</sub></i> implied by a given&nbsp;<i>u<sub>EA</sub></i> is&nbsp;</p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"u_{EB}=(1-u_{EA}^2)^{1/2}.\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;\">E</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.35em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;\">E</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span></span></span></span></span></span><p>The&nbsp;<i>u<sub>EA</sub></i> achieved in the utility profile that maximizes the product of possible utility-gains from the default point is thus the&nbsp;<i>u<sub>EA</sub></i> that maximizes</p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"(u_{EA}-x_{EA})((1-u_{EA}^2)^{1/2}-(1-x_{EA})).\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;\">E</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;\">E</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.35em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;\">E</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;\">E</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span></span></span></span></span></span><p>Taking the first-order condition with respect to&nbsp;<i>u<sub>EA</sub></i>, we have</p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"\\begin{align}(1-u_{EA}^2)^{1/2}-1+x_{EA}-(u_{EA}-x_{EA})(1-u_{EA}^2)^{1/2}u_{EA}&amp;=0\\\\ \\implies 1+u_{EA}x_{EA}-2u_{EA}^2 &amp;=(1-x_{EA})(1-u_{EA}^2)^{1/2}. \\end{align}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mtable\" style=\"vertical-align: -1.229em; padding: 0px 0.167em;\"><span class=\"mjx-table\"><span class=\"mjx-mtr\" style=\"height: 1.479em;\"><span class=\"mjx-mtd\" style=\"padding: 0px 0px 0px 0px; text-align: right; width: 23.428em;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.039em;\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.35em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;\">E</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mn MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;\">E</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;\">E</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;\">E</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.35em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;\">E</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;\">E</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span><span class=\"mjx-strut\"></span></span></span><span class=\"mjx-mtd\" style=\"padding: 0px 0px 0px 0px; text-align: left; width: 11.064em;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.039em;\"><span class=\"mjx-mi\"></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span><span class=\"mjx-strut\"></span></span></span></span><span class=\"mjx-mtr\" style=\"height: 1.479em;\"><span class=\"mjx-mtd\" style=\"padding: 0.15em 0px 0px 0px; text-align: right;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.039em;\"><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u27f9</span></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;\">E</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;\">E</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mn MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.35em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;\">E</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span><span class=\"mjx-strut\"></span></span></span><span class=\"mjx-mtd\" style=\"padding: 0.15em 0px 0px 0px; text-align: left;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.039em;\"><span class=\"mjx-mi\"></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;\">E</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.35em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;\">E</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span><span class=\"mjx-strut\"></span></span></span></span></span></span></span></span></span></span></span><p>(The concavity of the possibilities frontier ensures that there will be a unique solution, so we don\u2019t need to worry about other optimality conditions.) From here, solving for&nbsp;<i>u<sub>EA</sub></i> as a function of&nbsp;<i>x<sub>EA</sub></i> gets complicated, but Mathematica tells us that&nbsp;<i>u<sub>EA</sub></i>(<i>x<sub>EA</sub></i>) looks like this:</p><figure class=\"image image_resized\" style=\"width:65.2%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cf8Dth9vpxX9ptgma/qpwk9yxw06huz2iwas4k\"><figcaption>Figure 5</figcaption></figure><p>and that the RRA of&nbsp;<i>u<sub>EA</sub></i>(\u00b7), as a function of&nbsp;<i>x<sub>EA</sub></i>, looks like this:</p><figure class=\"image image_resized\" style=\"width:65.7%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cf8Dth9vpxX9ptgma/ut6jgrjaqxp9ffubaxjc\"><figcaption>Figure 6</figcaption></figure><p>As we can see, the RRA in&nbsp;<i>proportional</i> wealth ranges from around 0.5 when&nbsp;<i>x<sub>EA</sub>&nbsp;</i>\u2248 0 to very high values when&nbsp;<i>x<sub>EA</sub>&nbsp;</i>\u2248 1. It\u2019s not monotonic, interestingly, but it\u2019s always significantly positive.</p><p>A Mathematica workbook with the calculations is available&nbsp;<a href=\"https://philiptrammell.com/static/bargaining_over_the_future.nb\"><u>here</u></a>.</p><h1>Appendix B: Decreasing returns to x-risk reduction spending</h1><p>Suppose that the probability that an existential catastrophe occurs in the absence of any spending on x-risk reduction efforts is&nbsp;<i>b</i> \u2208 (0,1), and the proportion by which this risk is multiplied per unit of spending is&nbsp;<i>p</i> \u2208 (0,1). If all you care about is whether we suffer an existential catastrophe, then your expected utility as a function of x-risk reduction spending&nbsp;<i>x</i> equals the survival probability:</p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"u(x)=1-bp^x.\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">b</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span></span></span></span></span></span><p>Your RRA in wealth, \u2013<i>xu</i>\u2032\u2032(<i>x</i>)/<i>u</i>\u2032(<i>x</i>), is then</p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"-x/\\log(p).\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.519em;\">log</span></span><span class=\"mjx-mo\"><span class=\"mjx-char\"></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span></span></span></span></span></span><p>(Recall that&nbsp;<i>p&nbsp;</i>&lt; 1, so log(<i>p</i>) &lt; 0.) As we can see, this expression is not a constant. Fixing&nbsp;<i>p</i>, it rises linearly from 0\u2014financial risk-neutrality\u2014when&nbsp;<i>x&nbsp;</i>= 0, to \u221e\u2014extreme financial risk aversion\u2014when&nbsp;<i>x&nbsp;</i>= \u221e. On this model, therefore, how riskily to invest depends on how rich you already are, as well as on how effectively spending reduces x-risk, as determined by&nbsp;<i>p</i>.</p><h1>Appendix C: Less curvature due to cause variety</h1><p>Consider the following model. There is a continuum of potential causes (potential individual beneficiaries of philanthropy, even): one for each&nbsp;<i>p</i> \u2265 0.&nbsp; The philanthropic utility function within each cause, from some philanthropist\u2019s perspective, is identical and has a constant coefficient of relative risk aversion \ud835\udf02 &gt; 0. Within each cause, there is a pre-existing funding level&nbsp;<i>f</i>(<i>p</i>) \u2265 0. The causes are ordered so that&nbsp;<i>f</i>(\u00b7) is non-decreasing,<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefixc0euyk6o9\"><sup><a href=\"#fnixc0euyk6o9\">[29]</a></sup></span>&nbsp;and we will assume that&nbsp;<i>f</i>(\u00b7) is integrable. The philanthropist considers all the causes equally valuable, and prefers funding some to others only because some are more neglected: they have lower&nbsp;<i>f</i>(<i>p</i>). So, given a spending rate of&nbsp;<i>B</i> at a given time, the philanthropist chooses an integrable allocation of spending across the causes,&nbsp;<i>b</i>(<i>\u00b7</i>), so as to maximize</p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"\\int_0^\\infty [u(f(p)+b(p))-u(f(p))]dp,\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.388em;\"><span class=\"mjx-mo\" style=\"vertical-align: 0.001em; padding-right: 0.388em;\"><span class=\"mjx-char MJXc-TeX-size2-R\" style=\"padding-top: 1.109em; padding-bottom: 1.109em;\">\u222b</span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.921em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 2.15em; padding-left: 0.784em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">\u221e</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">[</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;\">f</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">b</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;\">f</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">]</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span></span></span></span></span></span><p>where&nbsp;<i>u</i>(\u00b7) is CRRA, subject to the budget constraint</p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"\\int_0^\\infty b(p)dp \\leq B.\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.388em;\"><span class=\"mjx-mo\" style=\"vertical-align: 0.001em; padding-right: 0.388em;\"><span class=\"mjx-char MJXc-TeX-size2-R\" style=\"padding-top: 1.109em; padding-bottom: 1.109em;\">\u222b</span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.921em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 2.15em; padding-left: 0.784em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">\u221e</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">b</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.446em;\">\u2264</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span></span></span></span></span></span><p>We\u2019re assuming that the philanthropist doesn\u2019t crowd outside funding out (or in): that&nbsp;<i>f</i>(<i>p</i>) is independent of&nbsp;<i>b</i>(<i>p</i>). (So we could also interpret the model as being one in which the causes simply have \u201clower tails\u201d that are \u201ctruncated\u201d at different points given by&nbsp;<i>f</i>(\u00b7), as discussed briefly in <a href=\"https://forum.effectivealtruism.org/posts/cf8Dth9vpxX9ptgma/against-much-financial-risk-tolerance#The_truncated_lower_tail_argument\">the \u201ctruncated lower tail argument\u201d sub-subsection</a>.) It follows immediately from the diminishing returns to spending within each cause that the philanthropist chooses&nbsp;<i>b</i>(<i>\u00b7</i>) such that&nbsp;<i>f</i>(<i>p</i>) +&nbsp;<i>b</i>(<i>p</i>) equals some constant \u201c<i>x</i>\u201d for all&nbsp;<i>p</i> &lt;&nbsp;<i>P</i>, for some&nbsp;<i>P</i> &gt; 0, with&nbsp;<i>b</i>(<i>p</i>) = 0 and&nbsp;<i>f</i>(<i>p</i>) \u2265&nbsp;<i>x</i> for all&nbsp;<i>p</i> &gt;&nbsp;<i>P</i>:</p><figure class=\"image image_resized\" style=\"width:45.92%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cf8Dth9vpxX9ptgma/ofqzbjfk6xsgw4kiounl\"><figcaption>Figure 7</figcaption></figure><p>Denote the philanthropist\u2019s overall utility as a function of&nbsp;<i>B</i>, after accounting for the fact that she can vary the range of causes she supports in light of how high&nbsp;<i>B</i> is, by&nbsp;<i>v</i>(<i>B</i>). Now we\u2019ll find the class of&nbsp;<i>f</i>(\u00b7)\u2019s for which&nbsp;<i>v</i>(<i>\u00b7</i>) is itself CRRA.</p><p><i>v</i>(<i>\u00b7</i>) is CRRA iff every multiplication of&nbsp;<i>B</i> by some&nbsp;<i>m</i> &gt; 0 multiplies the marginal utility of further wealth by&nbsp;<i>m</i><sup>\u2013\ud835\udefe</sup> for some constant \ud835\udefe. Here \ud835\udefe must be &gt; 0, since there is no way for increases in&nbsp;<i>B</i> to leave marginal utility higher or unchanged, and must be &lt; \ud835\udf02, since \ud835\udefe \u2265 \ud835\udf02 would imply that the&nbsp;<i>f</i>(<i>p</i>) curve was vertical or backward-sloping. Then, because the marginal utility of further wealth equals&nbsp;<i>u</i>\u2032(<i>x</i>), which equals&nbsp;<i>x</i><sup>\u2013\ud835\udf02</sup>,&nbsp;<i>v</i>(<i>\u00b7</i>) is CRRA with RRA \ud835\udefe iff every multiplication of&nbsp;<i>B</i> by some&nbsp;<i>m</i> &gt; 0 multiplies the \u201cwater line\u201d&nbsp;<i>x</i> by&nbsp;<i>m</i><sup>\ud835\udefe/\ud835\udf02</sup>. That is, flipping the axes of Figure 7, we must have&nbsp;<i>p</i>(<i>f</i>) such that multiplying&nbsp;<i>x</i> by&nbsp;<i>m</i> multiplies the area under the&nbsp;<i>p</i>(<i>f</i>) curve (representing&nbsp;<i>B</i>) by&nbsp;<i>m</i><sup>\ud835\udf02/\ud835\udefe</sup>:</p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"\\int_0^x p(f)df = Cx^{\\eta/\\gamma} \\;\\;\\; \\text{for some} \\;\\;\\; C>0.\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.388em;\"><span class=\"mjx-mo\" style=\"vertical-align: 0.001em; padding-right: 0.388em;\"><span class=\"mjx-char MJXc-TeX-size2-R\" style=\"padding-top: 1.109em; padding-bottom: 1.109em;\">\u222b</span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.921em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 2.15em; padding-left: 0.784em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;\">f</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;\">f</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;\">C</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.025em;\">\u03b3</span></span></span></span></span></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mtext\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">for some</span></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;\">C</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&gt;</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.</span></span></span></span></span></span></span><p>The solution to this differential equation is that&nbsp;<i>p</i>(<i>f</i><sup>&nbsp;</sup>) = (<i>C&nbsp;</i>\ud835\udf02/\ud835\udefe)<i>&nbsp;f</i><sup> (\ud835\udf02\u2013\ud835\udefe)/\ud835\udefe</sup>. Rearranging, we have</p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"f(p)=(\\frac{\\gamma}{C\\eta})^{\\frac{\\gamma}{\\eta-\\gamma}}p^{\\frac{\\gamma}{\\eta-\\gamma}}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;\">f</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 1.463em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"width: 1.463em; top: -1.247em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.025em;\">\u03b3</span></span></span><span class=\"mjx-denominator\" style=\"width: 1.463em; bottom: -1.011em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;\">C</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 1.463em;\" class=\"mjx-line\"></span></span><span style=\"height: 2.258em; vertical-align: -1.011em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.84em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 1.687em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 83.3%; width: 2.024em; top: -1.279em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.025em;\">\u03b3</span></span></span><span class=\"mjx-denominator\" style=\"font-size: 83.3%; width: 2.024em; bottom: -0.821em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.025em;\">\u03b3</span></span></span></span><span style=\"border-bottom: 1px solid; top: -0.296em; width: 1.687em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.75em; vertical-align: -0.684em;\" class=\"mjx-vsize\"></span></span></span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.84em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 1.687em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 83.3%; width: 2.024em; top: -1.279em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.025em;\">\u03b3</span></span></span><span class=\"mjx-denominator\" style=\"font-size: 83.3%; width: 2.024em; bottom: -0.821em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.025em;\">\u03b3</span></span></span></span><span style=\"border-bottom: 1px solid; top: -0.296em; width: 1.687em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.75em; vertical-align: -0.684em;\" class=\"mjx-vsize\"></span></span></span></span></span></span></span></span></span></span></span><p>Since&nbsp;<i>C</i> and \ud835\udefe/(\ud835\udf02\u2013\ud835\udefe) can take any positive values,&nbsp;<i>v</i>(<i>\u00b7</i>) is CRRA iff&nbsp;<i>f</i>(\u00b7) is a power function. In particular, if we know that the power on&nbsp;<i>p</i> takes some value \ud835\udefc, then we know&nbsp;<i>v</i>(<i>\u00b7</i>)\u2019s RRA:</p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"\\alpha=\\frac{\\gamma}{\\eta - \\gamma} \\implies \\gamma = \\eta \\, \\frac{\\alpha}{1+\\alpha}.\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b1</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mfrac MJXc-space3\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 2.468em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"width: 2.468em; top: -1.247em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.025em;\">\u03b3</span></span></span><span class=\"mjx-denominator\" style=\"width: 2.468em; bottom: -0.927em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.025em;\">\u03b3</span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 2.468em;\" class=\"mjx-line\"></span></span><span style=\"height: 2.174em; vertical-align: -0.927em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u27f9</span></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.025em;\">\u03b3</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 2.562em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"width: 2.562em; top: -1.144em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b1</span></span></span><span class=\"mjx-denominator\" style=\"width: 2.562em; bottom: -0.838em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b1</span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 2.562em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.982em; vertical-align: -0.838em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span></span></span></span></span></span><p>In the case where&nbsp;<i>f</i>(<i>p</i>) is linear, for instance, we have \ud835\udefc = 1 and thus \ud835\udefe = \ud835\udf02/2. If the \u201cprojects\u201d are individuals and the income distribution is bell-shaped (e.g. lognormal), its cumulative distribution function (CDF) is&nbsp;<a href=\"https://en.wikipedia.org/wiki/Sigmoid_function\"><u>sigmoidal</u></a>. The CDF is conceptually&nbsp;<i>p</i>(<i>f</i>), which will be strictly convex for low values of&nbsp;<i>f</i>. So&nbsp;<i>f</i>(<i>p</i>) will be strictly concave for low values of&nbsp;<i>p</i>.&nbsp;<i>f</i>(<i>\u00b7</i>) probably won\u2019t be a power function, but the concavity suggests a conclusion like that of the \ud835\udefc &lt; 1 case: i.e. a philanthropic utility function exhibiting less than half the curvature of an individual utility function.</p><h1>Appendix D: Merton\u2019s model</h1><h2>Understanding the model</h2><p>Suppose an investor\u2019s utility is as described in (1)\u2013(2).</p><p>He begins at time 0 with wealth&nbsp;<i>W</i><sub>0</sub> &gt; 0. There are two assets in which he can invest his wealth. We\u2019ll describe their prospects a bit more precisely here than in the body text.</p><ul><li>The first grows more valuable over time at a constant rate&nbsp;<i>r</i>. I.e. if you buy $1 of it at time&nbsp;<i>t</i>, its price an infinitesimal step \u201c<i>dt</i>\u201d later is 1+<i>r dt</i>, and since this compounds, its price at a time&nbsp;<i>s</i> &gt;&nbsp;<i>t</i> is $<i>e<sup>r</sup></i><sup>(</sup><i><sup>s</sup></i><sup>\u2013</sup><i><sup>t</sup></i><sup>)</sup>. It\u2019s essentially a safe bond offering interest rate&nbsp;<i>r</i>.</li><li>The second is risky. Its interest rate jumps around continuously over time, but in effect, if you buy $1 of it at time&nbsp;<i>t</i>, the distribution of possible price-increases&nbsp;<i>dt</i> later is a normal distribution with expected value \ud835\udf07&nbsp;<i>dt</i>, for some \ud835\udf07 &gt;&nbsp;<i>r</i>, and variance \ud835\udf0e<sup>2</sup><i>dt</i>, for some \ud835\udf0e &gt; 0. In other words, its price&nbsp;<i>dt</i> later is 1+\ud835\udf00<i><sub>t</sub> dt</i>, where \ud835\udf00<i><sub>t</sub></i> ~&nbsp;<i>N</i>(\ud835\udf07,\ud835\udf0e<sup>2</sup>/<i>dt</i>) (so that \ud835\udf00<i><sub>t</sub> dt</i> ~&nbsp;<i>N</i>(\ud835\udf07&nbsp;<i>dt</i>,\ud835\udf0e<sup>2</sup><i>dt</i>)). As these price movements compound independently over time, the price follows a geometric random walk. The risky asset is essentially a stock, offering higher expected returns than the bond but an ever-widening distribution of possible returns as we consider times&nbsp;<i>s</i> ever further in the future from the purchase date&nbsp;<i>t</i>. \ud835\udf07\u2013<i>r</i> is the equity premium.</li></ul><p>The investor\u2019s wealth at&nbsp;<i>t</i> is denoted&nbsp;<i>W<sub>t</sub></i>.&nbsp;<i>W<sub>t</sub></i> depends on four things: his initial wealth&nbsp;<i>W</i><sub>0</sub>, how quickly he\u2019s been consuming, how much of his savings have been invested in the risky asset, and how well the risky asset has performed.</p><p>At each time&nbsp;<i>t</i>, our investor has two questions to answer. First is how fast he should consume at&nbsp;<i>t</i>: i.e. what \ud835\udf08<i><sub>t</sub></i> should be, where \ud835\udf08<i><sub>t</sub></i> denotes his consumption rate at&nbsp;<i>t</i> as a proportion of&nbsp;<i>W<sub>t</sub></i>. Second is, of the wealth not yet consumed, what fraction \ud835\udf0b<i><sub>t</sub></i> he should hold in stocks. We\u2019ll hand-wavily calculate the optimal \ud835\udf0b<i><sub>t</sub></i> first, and then use what we learn to calculate the optimal \ud835\udf08<i><sub>t</sub></i>.</p><h3>Calculating the optimal&nbsp;\ud835\udf0b</h3><p>Because of the way&nbsp;<i>u</i>(\u00b7) is defined, optimal \ud835\udf0b<i><sub>t</sub></i> and \ud835\udf08<i><sub>t</sub></i> are independent of&nbsp;<i>W<sub>t</sub></i>. To see this, fix some policy for choosing \ud835\udf0b<i><sub>s</sub></i> and \ud835\udf08<i><sub>s</sub></i> for&nbsp;<i>s</i> \u2265&nbsp;<i>t</i>. Given starting wealth&nbsp;<i>W<sub>t</sub></i> =&nbsp;<i>W</i>, this policy achieves some expected utility&nbsp;<i>EU</i>. Now consider what happens if in fact&nbsp;<i>W<sub>t</sub></i> =&nbsp;<i>mW</i>, for some&nbsp;<i>m</i> &gt; 0, but we always choose the \ud835\udf0b<i><sub>s</sub></i> and \ud835\udf08<i><sub>s</sub></i> that the policy in question would have dictated at&nbsp;<i>s</i> if we had started with&nbsp;<i>W<sub>t</sub></i> =&nbsp;<i>W</i>. Wealth at each future time will be&nbsp;<i>m</i> times what it would have been. So the absolute consumption rate at each future time&nbsp;<i>s</i>\u2014i.e. \ud835\udf08<i><sub>s</sub>W<sub>s</sub></i>\u2014will also be&nbsp;<i>m</i> times what it would have been. So by (2), the flow utility at each time&nbsp;<i>s</i> will be&nbsp;<i>m</i><sup>1\u2013\ud835\udf02</sup> times what it would have been. Finally, by (1), the total discounted utility across time is also&nbsp;<i>m</i><sup>1\u2013\ud835\udf02</sup> times what it would have been. Since the policy that maximizes&nbsp;<i>EU</i> must also be the policy that maximizes&nbsp;<i>m</i><sup>1\u2013\ud835\udf02</sup><i>EU</i>, the optimal policy is independent of&nbsp;<i>W<sub>t</sub></i>. Finally, observe that&nbsp;<i>W</i> is the only state variable; for a given&nbsp;<i>W<sub>t</sub></i>, the expected utility achieved after&nbsp;<i>t</i> by a given policy is always the same.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefrd9sny30xde\"><sup><a href=\"#fnrd9sny30xde\">[30]</a></sup></span>&nbsp;So the optimal choices of \ud835\udf0b and \ud835\udf08 are constant.&nbsp;</p><p>Given some choices of \ud835\udf0b and \ud835\udf08,&nbsp;<i>W<sub>t</sub></i><sub>+</sub><i><sub>dt</sub></i> equals</p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"W_t(1-\\nu \\,dt) \\;\\; +\\;\\;W_t(1-\\nu\\,dt)(1-\\pi)\\,r\\,dt\\;\\;\\;+\\;\\;\\;W_t(1-\\nu\\,dt)\\,\\pi\\,\\varepsilon_t\\,dt.\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.104em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;\">W</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.036em;\">\u03bd</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\" style=\"margin-right: -0.104em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;\">W</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.036em;\">\u03bd</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\" style=\"margin-right: -0.104em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;\">W</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.036em;\">\u03bd</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b5</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span></span></span></span></span></span><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\"><span class=\"mjx-mrow\" aria-hidden=\"true\"></span></span></span></span></span>The first term equals the wealth left for investing, after consuming at proportional rate \ud835\udf08 for&nbsp;<i>dt</i> units of time. The second term equals the interest accrued from the fraction 1\u2013\ud835\udf0b of invested wealth that is held in bonds. The third term equals the interest accrued from the fraction \ud835\udf0b held in stocks. Collecting terms, we have</p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"W_{t+dt}=W_t(1-\\nu\\,dt)\\,(1+((1-\\pi)r+\\pi\\,\\varepsilon_t)dt).\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.104em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;\">W</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\" style=\"margin-right: -0.104em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;\">W</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.036em;\">\u03bd</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b5</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span></span></span></span></span></span><p>Since \ud835\udf00<i><sub>t</sub></i> ~&nbsp;<i>N</i>(\ud835\udf07, \ud835\udf0e<sup>2</sup>/<i>dt</i>),</p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"\\begin{align}c_{t+dt} &amp;\\sim \\nu W_t(1-\\nu\\,dt)\\,(1+(1-\\pi)r\\,dt+\\pi\\,N(\\mu,\\sigma^2/dt)dt)\\\\&amp;=\\nu W_t(1-\\nu\\,dt)\\,N(1+(1-\\pi)r\\,dt+\\pi\\,\\mu\\,dt,\\pi^2\\sigma^2dt). \\end{align}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mtable\" style=\"vertical-align: -1.077em; padding: 0px 0.167em;\"><span class=\"mjx-table\"><span class=\"mjx-mtr\" style=\"height: 1.327em;\"><span class=\"mjx-mtd\" style=\"padding: 0px 0px 0px 0px; text-align: right; width: 1.899em;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.098em;\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span><span class=\"mjx-strut\"></span></span></span><span class=\"mjx-mtd\" style=\"padding: 0px 0px 0px 0px; text-align: left; width: 22.556em;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.098em;\"><span class=\"mjx-mi\"></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">\u223c</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.036em;\">\u03bd</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.104em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;\">W</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.036em;\">\u03bd</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;\">N</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03bc</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\" style=\"margin-right: -0.001em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.001em;\">\u03c3</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.073em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-strut\"></span></span></span></span><span class=\"mjx-mtr\" style=\"height: 1.327em;\"><span class=\"mjx-mtd\" style=\"padding: 0.15em 0px 0px 0px; text-align: right;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.098em;\"><span class=\"mjx-strut\"></span></span></span><span class=\"mjx-mtd\" style=\"padding: 0.15em 0px 0px 0px; text-align: left;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.098em;\"><span class=\"mjx-mi\"></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.036em;\">\u03bd</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.104em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;\">W</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.036em;\">\u03bd</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;\">N</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03bc</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\" style=\"margin-right: -0.003em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.076em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.001em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.001em;\">\u03c3</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.073em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span><span class=\"mjx-strut\"></span></span></span></span></span></span></span></span></span></span></span><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\"><span class=\"mjx-mrow\" aria-hidden=\"true\"></span></span></span></span></span>This is a normal distribution with mean</p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"\\bar{c}_{t+dt} \\triangleq \\nu W_t(1-\\nu\\,dt)\\,(1+(1-\\pi)r\\,dt+\\pi\\,\\mu\\,dt).\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.096em; padding-bottom: 0.06em; padding-left: 0.022em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u00af</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span></span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-ams-R\" style=\"padding-top: 0.593em; padding-bottom: 0.298em;\">\u225c</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.036em;\">\u03bd</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.104em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;\">W</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.036em;\">\u03bd</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03bc</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span></span></span></span></span></span><p>It may seem paradoxical to conclude that consumption is normally distributed, since consumption cannot be negative. Without getting too into the weeds, what makes it work is that the variance \ud835\udf0b<i><sup>2</sup></i>\ud835\udf0e<sup>2</sup><i>dt</i> is infinitesimal; in effect, this normal distribution is so narrow that fraction zero of its left tail extends below 0. The extreme narrowness of the distribution also lets us say that marginal utility in consumption falls approximately linearly in consumption across the range of the distribution, so that the marginal utility in consumption at&nbsp;<i>t</i>+<i>dt</i> is distributed like</p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"\\begin{align}&amp;u'(\\bar{c}_{t+dt})+u''(\\bar{c}_{t+dt})\\bar{c}_{t+dt}N(0,\\pi^2\\sigma^2dt)\\\\ =\\;&amp;\\bar{c}_{t+dt}^{-\\eta}-\\eta\\bar{c}_{t+dt}^{-\\eta}N(0,\\pi^2\\sigma^2dt) \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\; \\text{by (2).}\\end{align} \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;(7)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mtable\" style=\"vertical-align: -1.17em; padding: 0px 0.167em;\"><span class=\"mjx-table\"><span class=\"mjx-mtr\" style=\"height: 1.327em;\"><span class=\"mjx-mtd\" style=\"padding: 0px 0px 0px 0px; text-align: right; width: 1.056em;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.098em;\"><span class=\"mjx-strut\"></span></span></span><span class=\"mjx-mtd\" style=\"padding: 0px 0px 0px 0px; text-align: left; width: 20.499em;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.098em;\"><span class=\"mjx-msup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mo\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u2032</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.096em; padding-bottom: 0.06em; padding-left: 0.022em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u00af</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span></span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-msup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mo\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u2032\u2032</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.096em; padding-bottom: 0.06em; padding-left: 0.022em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u00af</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span></span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.096em; padding-bottom: 0.06em; padding-left: 0.022em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u00af</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span></span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;\">N</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\" style=\"margin-right: -0.003em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.076em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.001em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.001em;\">\u03c3</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.073em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-strut\"></span></span></span></span><span class=\"mjx-mtr\" style=\"height: 1.514em;\"><span class=\"mjx-mtd\" style=\"padding: 0.15em 0px 0px 0px; text-align: right;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.046em;\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-strut\"></span></span></span><span class=\"mjx-mtd\" style=\"padding: 0.15em 0px 0px 0px; text-align: left;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.046em;\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.096em; padding-bottom: 0.06em; padding-left: 0.022em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u00af</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span></span></span></span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.335em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.096em; padding-bottom: 0.06em; padding-left: 0.022em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u00af</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span></span></span></span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.335em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;\">N</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\" style=\"margin-right: -0.003em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.076em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.001em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.001em;\">\u03c3</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.073em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mtext\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">by (2).</span></span><span class=\"mjx-strut\"></span></span></span></span></span></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">7</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\"><span class=\"mjx-mrow\" aria-hidden=\"true\"></span></span></span></span></span>To be optimal, \ud835\udf0b has to be such that the expected utility-gain to investing slightly more in bonds until&nbsp;<i>t</i>+<i>dt</i>, and then consuming the resulting extra wealth, equals that to investing slightly more in stocks until&nbsp;<i>t</i>+<i>dt</i> and then consuming the resulting extra wealth. If these two quantities are not equal, expected utility can be increased by marginally shifting investments from stocks to bonds, or vice-versa, and undoing any wealth-difference that results by adjusting consumption at&nbsp;<i>t</i>+<i>dt</i>. This observation will let us find the optimal choice of \ud835\udf0b.</p><p>The expected marginal utility achieved at&nbsp;<i>t</i>+<i>dt</i> from investing a little more in bonds from&nbsp;<i>t</i> to&nbsp;<i>t</i>+<i>dt</i>, and then consuming them, equals</p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"(1+r\\,dt)\\bar{c}_{t+dt}^{-\\eta}\\;\\;\\;\\;\\;\\;\\;\\;\\;(8)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.096em; padding-bottom: 0.06em; padding-left: 0.022em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u00af</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span></span></span></span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.335em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">8</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\"><span class=\"mjx-mrow\" aria-hidden=\"true\"></span></span></span></span></span>per extra increment invested in bonds and then consumed. This is because this investment yields 1+<i>r<sub>&nbsp;</sub>dt</i> units of extra consumption at&nbsp;<i>t</i>+<i>dt</i> per increment bought at&nbsp;<i>t</i>, and the expected marginal utility to consumption at&nbsp;<i>t</i>+<i>dt</i> equals&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\bar{c}_{t+dt}^{\u2013\ud835\udf02}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.096em; padding-bottom: 0.06em; padding-left: 0.022em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u00af</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span></span></span></span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.335em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: 0.004em; padding-bottom: 0.298em;\">\u2013</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03b7</span></span></span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span></span></span></span></span></span></span>.</p><p>Likewise, the expected marginal utility achieved at&nbsp;<i>t</i>+<i>dt</i> from investing a little more in stocks from&nbsp;<i>t</i> to&nbsp;<i>t</i>+<i>dt</i>, and then consuming them, equals</p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"\\begin{align}&amp;E[(1+\\varepsilon_tdt)(\\bar{c}_{t+dt}^{-\\eta}-\\eta\\bar{c}_{t+dt}^{-\\eta}\\pi(\\varepsilon_t-\\mu)dt)]\\\\ =\\,&amp;E[(1+\\mu\\,dt+(\\varepsilon_t-\\mu)dt)(\\bar{c}_{t+dt}^{-\\eta}-\\eta \\bar{c}_{t+dt}^{-\\eta}\\pi(\\varepsilon_t-\\mu)dt)]\\;\\;\\;\\;\\;\\;\\;\\;\\;(9)\\end{align}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mtable\" style=\"vertical-align: -1.264em; padding: 0px 0.167em;\"><span class=\"mjx-table\"><span class=\"mjx-mtr\" style=\"height: 1.514em;\"><span class=\"mjx-mtd\" style=\"padding: 0px 0px 0px 0px; text-align: right; width: 0.945em;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.046em;\"><span class=\"mjx-strut\"></span></span></span><span class=\"mjx-mtd\" style=\"padding: 0px 0px 0px 0px; text-align: left; width: 26.015em;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.046em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;\">E</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">[</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b5</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.096em; padding-bottom: 0.06em; padding-left: 0.022em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u00af</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span></span></span></span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.335em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.096em; padding-bottom: 0.06em; padding-left: 0.022em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u00af</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span></span></span></span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.335em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b5</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03bc</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">]</span></span><span class=\"mjx-strut\"></span></span></span></span><span class=\"mjx-mtr\" style=\"height: 1.514em;\"><span class=\"mjx-mtd\" style=\"padding: 0.15em 0px 0px 0px; text-align: right;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.046em;\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-strut\"></span></span></span><span class=\"mjx-mtd\" style=\"padding: 0.15em 0px 0px 0px; text-align: left;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.046em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;\">E</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">[</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03bc</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b5</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03bc</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.096em; padding-bottom: 0.06em; padding-left: 0.022em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u00af</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span></span></span></span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.335em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.096em; padding-bottom: 0.06em; padding-left: 0.022em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u00af</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span></span></span></span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.335em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b5</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03bc</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">]</span></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">9</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-strut\"></span></span></span></span></span></span></span></span></span></span></span><p>per extra increment invested in stocks and then consumed. This is because this investment yields 1+\ud835\udf00<i><sub>t&nbsp;</sub>dt</i> units of extra consumption at&nbsp;<i>t</i>+<i>dt</i> per increment bought at&nbsp;<i>t</i>, and the (actual, not expected) marginal utility to consumption at&nbsp;<i>t</i>+<i>dt</i> equals&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\bar{c}_{t+dt}^{\u2013\ud835\udf02}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.096em; padding-bottom: 0.06em; padding-left: 0.022em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u00af</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span></span></span></span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.335em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: 0.004em; padding-bottom: 0.298em;\">\u2013</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03b7</span></span></span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span></span></span></span></span></span></span>&nbsp;\u2013 \ud835\udf02<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\bar{c}_{t+dt}^{\u2013\ud835\udf02}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.096em; padding-bottom: 0.06em; padding-left: 0.022em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u00af</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span></span></span></span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.335em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: 0.004em; padding-bottom: 0.298em;\">\u2013</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03b7</span></span></span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span></span></span></span></span></span></span>&nbsp;\ud835\udf0b(\ud835\udf00<i><sub>t</sub></i>\u2013\ud835\udf07)<i>dt</i>. (Recall (7), and observe that \ud835\udf0b(\ud835\udf00<i><sub>t</sub></i>\u2013\ud835\udf07)<i>dt</i> ~&nbsp;<i>N</i>(0, \ud835\udf0b<i><sup>2</sup></i>\ud835\udf0e<sup>2</sup><i>dt</i>).) (We can\u2019t just multiply returns by expected marginal utility, as in the case of bonds, because \ud835\udf00<i><sub>t</sub></i>, unlike&nbsp;<i>r</i>, varies with&nbsp;<i>u</i>\u2032. When \ud835\udf00<i><sub>t</sub></i> is higher, one\u2019s wealth at&nbsp;<i>t</i>+<i>dt</i> is higher, so one\u2019s consumption at&nbsp;<i>t</i>+<i>dt</i> is higher, so one\u2019s marginal utility in consumption at&nbsp;<i>t</i>+<i>dt</i> is lower.) Simplifying (9), and recalling that</p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"\\begin{align} E[(\\varepsilon_t-\\mu)dt]&amp;=0 \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\text{and}\\\\ E[((\\varepsilon_t-\\mu)dt)^2]=Var[(\\varepsilon_t-\\mu)dt]&amp;=\\sigma^2dt, \\end{align}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mtable\" style=\"vertical-align: -1.026em; padding: 0px 0.167em;\"><span class=\"mjx-table\"><span class=\"mjx-mtr\" style=\"height: 1.225em;\"><span class=\"mjx-mtd\" style=\"padding: 0px 0px 0px 0px; text-align: right; width: 14.614em;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.2em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;\">E</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">[</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b5</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03bc</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">]</span></span><span class=\"mjx-strut\"></span></span></span><span class=\"mjx-mtd\" style=\"padding: 0px 0px 0px 0px; text-align: left; width: 6.779em;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.2em;\"><span class=\"mjx-mi\"></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mtext\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">and</span></span><span class=\"mjx-strut\"></span></span></span></span><span class=\"mjx-mtr\" style=\"height: 1.327em;\"><span class=\"mjx-mtd\" style=\"padding: 0.15em 0px 0px 0px; text-align: right;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.098em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;\">E</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">[</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b5</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03bc</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">]</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;\">V</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">[</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b5</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03bc</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">]</span></span><span class=\"mjx-strut\"></span></span></span><span class=\"mjx-mtd\" style=\"padding: 0.15em 0px 0px 0px; text-align: left;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.098em;\"><span class=\"mjx-mi\"></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\" style=\"margin-right: -0.001em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.001em;\">\u03c3</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.073em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-strut\"></span></span></span></span></span></span></span></span></span></span></span><p>the term equals</p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"(1+\\mu\\,dt)\\bar{c}_{t+dt}^{-\\eta}-\\eta\\bar{c}_{t+dt}^{-\\eta}\\pi\\,\\sigma^2dt.\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03bc</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.096em; padding-bottom: 0.06em; padding-left: 0.022em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u00af</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span></span></span></span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.335em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.096em; padding-bottom: 0.06em; padding-left: 0.022em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u00af</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span></span></span></span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.335em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.001em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.001em;\">\u03c3</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.073em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span></span></span></span></span></span><p>Setting this equal to the marginal utility to investing in bonds (8), and dividing both sides by&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\bar{c}_{t+dt}^{\u2013\ud835\udf02}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.096em; padding-bottom: 0.06em; padding-left: 0.022em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u00af</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span></span></span></span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.335em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: 0.004em; padding-bottom: 0.298em;\">\u2013</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03b7</span></span></span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span></span></span></span></span></span></span>, we have</p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"\\begin{align} 1+r\\,dt &amp;= 1+\\mu\\,dt-\\eta\\,\\pi^*\\sigma^2dt\\\\ \\implies r&amp;=\\mu-\\eta\\,\\pi^*\\sigma^2\\\\ \\implies \\pi^*&amp;=\\frac{\\mu-r}{\\eta\\sigma^2}.\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;(10) \\end{align}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mtable\" style=\"vertical-align: -2.416em; padding: 0px 0.167em;\"><span class=\"mjx-table\"><span class=\"mjx-mtr\" style=\"height: 1.293em;\"><span class=\"mjx-mtd\" style=\"padding: 0px 0px 0px 0px; text-align: right; width: 3.484em;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.098em;\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-strut\"></span></span></span><span class=\"mjx-mtd\" style=\"padding: 0px 0px 0px 0px; text-align: left; width: 9.51em;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.098em;\"><span class=\"mjx-mi\"></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03bc</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.003em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.076em; padding-right: 0.071em;\"><span class=\"mjx-mo\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.298em;\">\u2217</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.001em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.001em;\">\u03c3</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.073em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-strut\"></span></span></span></span><span class=\"mjx-mtr\" style=\"height: 1.443em;\"><span class=\"mjx-mtd\" style=\"padding: 0.15em 0px 0px 0px; text-align: right;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.098em;\"><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u27f9</span></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-strut\"></span></span></span><span class=\"mjx-mtd\" style=\"padding: 0.15em 0px 0px 0px; text-align: left;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.098em;\"><span class=\"mjx-mi\"></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03bc</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.003em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.076em; padding-right: 0.071em;\"><span class=\"mjx-mo\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.298em;\">\u2217</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.001em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.001em;\">\u03c3</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.073em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-strut\"></span></span></span></span><span class=\"mjx-mtr\" style=\"height: 2.598em;\"><span class=\"mjx-mtd\" style=\"padding: 0.15em 0px 0px 0px; text-align: right;\"><span class=\"mjx-mrow\" style=\"margin-top: 0.389em;\"><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u27f9</span></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\" style=\"margin-right: -0.003em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.076em; padding-right: 0.071em;\"><span class=\"mjx-mo\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.298em;\">\u2217</span></span></span></span><span class=\"mjx-strut\"></span></span></span><span class=\"mjx-mtd\" style=\"padding: 0.15em 0px 0px 0px; text-align: left;\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mfrac MJXc-space3\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 2.476em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"width: 2.476em; top: -1.389em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03bc</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span></span></span><span class=\"mjx-denominator\" style=\"width: 2.476em; bottom: -1.059em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.001em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.001em;\">\u03c3</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.409em; padding-left: 0.073em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 2.476em;\" class=\"mjx-line\"></span></span><span style=\"height: 2.448em; vertical-align: -1.059em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">10</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-strut\"></span></span></span></span></span></span></span></span></span></span></span><p>So the fraction of the portfolio to keep in stocks is constant and equal to (10).</p><h3>Calculating the optimal&nbsp;\ud835\udf08</h3><p>It was noted above that, as the price movements of the stock compound independently over time, its price follows a geometric random walk. It turns out, though we won\u2019t show this, that given a constant \ud835\udf0b and \ud835\udf08, wealth also follows a geometric random walk. Given that it takes value&nbsp;<i>W<sub>t</sub></i> at&nbsp;<i>t</i>, its value at&nbsp;<i>s</i> &gt;&nbsp;<i>t</i> is distributed lognormally as</p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"W_s\\sim W_t \\exp(N(((1-\\pi)r+\\pi\\mu-\\nu-\\pi^2\\sigma^2/2)(s-t),\\pi^2\\sigma^2(s-t)).\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.104em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;\">W</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">s</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">\u223c</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\" style=\"margin-right: -0.104em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;\">W</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.519em;\">exp</span></span><span class=\"mjx-mo\"><span class=\"mjx-char\"></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;\">N</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03bc</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.036em;\">\u03bd</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\" style=\"margin-right: -0.003em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.076em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.001em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.001em;\">\u03c3</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.073em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">s</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\" style=\"margin-right: -0.003em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.076em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.001em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.001em;\">\u03c3</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.073em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">s</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span></span></span></span></span></span><p>Consumption at&nbsp;<i>s</i> is thus also distributed lognormally, as \ud835\udf08 times the above.</p><p>To be optimal, \ud835\udf08 has to be such that the marginal utility to consumption at&nbsp;<i>t</i> equals the expected utility-gain to investing slightly more in bonds until&nbsp;<i>s</i> and then consuming the resulting extra wealth. If these two quantities are not equal, expected utility can be increased by marginally increasing or decreasing the quantity of bonds invested to&nbsp;<i>s</i>. This observation will let us find the optimal choice of \ud835\udf08.</p><p>The marginal utility to consumption at&nbsp;<i>t</i> equals</p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"(\\nu W_t)^{-\\eta}. \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\; (11)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.036em;\">\u03bd</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.104em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;\">W</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">11</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span><p>The marginal expected discounted utility-gain to investing in bonds until&nbsp;<i>s</i> and then consuming the resulting extra wealth is distributed lognormally, as</p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"\\begin{align} &amp;e^{(r-\\delta)(s-t)}(\\nu W_t \\exp(N(((1-\\pi)r+\\pi\\mu-\\nu-\\pi^2\\sigma^2/2)(s-t),\\pi^2\\sigma^2(s-t))))^{-\\eta}\\\\ = \\;&amp; e^{(r-\\delta)(s-t)}(\\nu W_t)^{-\\eta}\\exp(N(-\\eta((1-\\pi)r+\\pi\\mu-\\nu-\\pi^2\\sigma^2/2)(s-t),\\eta^2\\pi^2\\sigma^2(s-t))). \\;\\;\\;\\;\\;\\;\\;(12) \\end{align}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mtable\" style=\"vertical-align: -1.136em; padding: 0px 0.167em;\"><span class=\"mjx-table\"><span class=\"mjx-mtr\" style=\"height: 1.386em;\"><span class=\"mjx-mtd\" style=\"padding: 0px 0px 0px 0px; text-align: right; width: 1.056em;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.039em;\"><span class=\"mjx-strut\"></span></span></span><span class=\"mjx-mtd\" style=\"padding: 0px 0px 0px 0px; text-align: left; width: 38.77em;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.039em;\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">e</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.007em;\">\u03b4</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">s</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.036em;\">\u03bd</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.104em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;\">W</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.519em;\">exp</span></span><span class=\"mjx-mo\"><span class=\"mjx-char\"></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;\">N</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03bc</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.036em;\">\u03bd</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\" style=\"margin-right: -0.003em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.076em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.001em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.001em;\">\u03c3</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.073em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">s</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\" style=\"margin-right: -0.003em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.076em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.001em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.001em;\">\u03c3</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.073em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">s</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span></span></span><span class=\"mjx-strut\"></span></span></span></span><span class=\"mjx-mtr\" style=\"height: 1.386em;\"><span class=\"mjx-mtd\" style=\"padding: 0.15em 0px 0px 0px; text-align: right;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.039em;\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-strut\"></span></span></span><span class=\"mjx-mtd\" style=\"padding: 0.15em 0px 0px 0px; text-align: left;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.039em;\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">e</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.007em;\">\u03b4</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">s</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.036em;\">\u03bd</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.104em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;\">W</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span></span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.519em;\">exp</span></span><span class=\"mjx-mo\"><span class=\"mjx-char\"></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;\">N</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03bc</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.036em;\">\u03bd</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\" style=\"margin-right: -0.003em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.076em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.001em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.001em;\">\u03c3</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.073em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">s</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.082em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.003em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.076em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.001em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.001em;\">\u03c3</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.073em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">s</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">12</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-strut\"></span></span></span></span></span></span></span></span></span></span></span><p>The expected value of a lognormal distribution whose associated normal distribution has mean&nbsp;<i>M</i> and variance&nbsp;<i>V</i> is&nbsp;<i>e<sup>M</sup></i><sup>+</sup><i><sup>V</sup></i><sup>/2</sup> (see&nbsp;<a href=\"https://en.wikipedia.org/wiki/Log-normal_distribution\"><u>Wikipedia</u></a>). So the expected value of distribution (12) is</p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"e^{(r-\\delta)(s-t)}(\\nu W_t)^{-\\eta} \\exp(-\\eta((1-\\pi)r+\\pi\\mu-\\nu-\\pi^2\\sigma^2/s)(s-t)+\\eta^2\\pi^2\\sigma^2(s-t)/2). \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\, (13)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">e</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.007em;\">\u03b4</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">s</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.036em;\">\u03bd</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.104em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;\">W</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span></span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.519em;\">exp</span></span><span class=\"mjx-mo\"><span class=\"mjx-char\"></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03bc</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.036em;\">\u03bd</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\" style=\"margin-right: -0.003em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.076em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.001em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.001em;\">\u03c3</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.073em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">s</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">s</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.082em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.003em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.076em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.001em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.001em;\">\u03c3</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.073em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">s</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">13</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span><p>\ud835\udf08* is the value of \ud835\udf08 that sets (11) equal to (13). Setting these terms equal, and dividing both sides by (\ud835\udf08*<i>W<sub>t</sub></i>)<sup>\u2013\ud835\udf02</sup>, we have</p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"\\begin{align} 1&amp;=e^{(r-\\delta)(s-t)}\\exp(-\\eta((1-\\pi)r+\\pi\\mu-\\nu^*-\\pi^2\\sigma^2/2)(s-t)+\\eta^2\\pi^2\\sigma^2(s-t)/2)\\\\ \\implies \\delta-r&amp;=-\\eta((1-\\pi)r+\\pi\\mu-\\nu^*-\\pi^2\\sigma^2/2)+\\eta^2\\pi^2\\sigma^2/2\\\\ \\implies \\frac{r-\\delta}{\\eta} &amp;= (1-\\pi)r+\\pi\\mu-\\nu^*-\\pi^2\\sigma^2/2-\\eta\\pi^2\\sigma^2/2\\\\ \\implies \\nu^* &amp;= (1-\\pi)r+\\pi\\mu-(1+\\eta)\\frac{\\pi^2\\sigma^2}{2} - \\frac{r-\\delta}{\\eta}. \\end{align}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mtable\" style=\"vertical-align: -3.806em; padding: 0px 0.167em;\"><span class=\"mjx-table\"><span class=\"mjx-mtr\" style=\"height: 1.386em;\"><span class=\"mjx-mtd\" style=\"padding: 0px 0px 0px 0px; text-align: right; width: 5.036em;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.039em;\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-strut\"></span></span></span><span class=\"mjx-mtd\" style=\"padding: 0px 0px 0px 0px; text-align: left; width: 33.014em;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.039em;\"><span class=\"mjx-mi\"></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">e</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.007em;\">\u03b4</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">s</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.519em;\">exp</span></span><span class=\"mjx-mo\"><span class=\"mjx-char\"></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03bc</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\" style=\"margin-right: -0.036em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.036em;\">\u03bd</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.137em; padding-right: 0.071em;\"><span class=\"mjx-mo\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.298em;\">\u2217</span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\" style=\"margin-right: -0.003em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.076em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.001em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.001em;\">\u03c3</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.073em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">s</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.082em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.003em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.076em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.001em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.001em;\">\u03c3</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.073em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">s</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-strut\"></span></span></span></span><span class=\"mjx-mtr\" style=\"height: 1.477em;\"><span class=\"mjx-mtd\" style=\"padding: 0.15em 0px 0px 0px; text-align: right;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.098em;\"><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u27f9</span></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.007em;\">\u03b4</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-strut\"></span></span></span><span class=\"mjx-mtd\" style=\"padding: 0.15em 0px 0px 0px; text-align: left;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.098em;\"><span class=\"mjx-mi\"></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03bc</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\" style=\"margin-right: -0.036em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.036em;\">\u03bd</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.137em; padding-right: 0.071em;\"><span class=\"mjx-mo\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.298em;\">\u2217</span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\" style=\"margin-right: -0.003em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.076em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.001em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.001em;\">\u03c3</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.073em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.082em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.003em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.076em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.001em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.001em;\">\u03c3</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.073em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span><span class=\"mjx-strut\"></span></span></span></span><span class=\"mjx-mtr\" style=\"height: 2.645em;\"><span class=\"mjx-mtd\" style=\"padding: 0.15em 0px 0px 0px; text-align: right;\"><span class=\"mjx-mrow\"><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u27f9</span></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mfrac MJXc-space3\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 2.324em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"width: 2.324em; top: -1.419em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.007em;\">\u03b4</span></span></span></span><span class=\"mjx-denominator\" style=\"width: 2.324em; bottom: -0.927em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 2.324em;\" class=\"mjx-line\"></span></span><span style=\"height: 2.345em; vertical-align: -0.927em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-strut\"></span></span></span><span class=\"mjx-mtd\" style=\"padding: 0.15em 0px 0px 0px; text-align: left;\"><span class=\"mjx-mrow\" style=\"margin-top: 0.419em;\"><span class=\"mjx-mi\"></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03bc</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\" style=\"margin-right: -0.036em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.036em;\">\u03bd</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.137em; padding-right: 0.071em;\"><span class=\"mjx-mo\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.298em;\">\u2217</span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\" style=\"margin-right: -0.003em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.076em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.001em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.001em;\">\u03c3</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.073em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.003em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.076em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.001em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.001em;\">\u03c3</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.073em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span><span class=\"mjx-strut\"></span></span></span></span><span class=\"mjx-mtr\" style=\"height: 2.605em;\"><span class=\"mjx-mtd\" style=\"padding: 0.15em 0px 0px 0px; text-align: right;\"><span class=\"mjx-mrow\" style=\"margin-top: 0.528em;\"><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u27f9</span></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\" style=\"margin-right: -0.036em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.036em;\">\u03bd</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.137em; padding-right: 0.071em;\"><span class=\"mjx-mo\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.298em;\">\u2217</span></span></span></span><span class=\"mjx-strut\"></span></span></span><span class=\"mjx-mtd\" style=\"padding: 0.15em 0px 0px 0px; text-align: left;\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03bc</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 2.224em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"width: 2.224em; top: -1.528em;\"><span class=\"mjx-mrow\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.003em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0.076em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.001em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.001em;\">\u03c3</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0.073em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span><span class=\"mjx-denominator\" style=\"width: 2.224em; bottom: -0.756em;\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 2.224em;\" class=\"mjx-line\"></span></span><span style=\"height: 2.284em; vertical-align: -0.756em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mfrac MJXc-space2\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 2.324em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"width: 2.324em; top: -1.419em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.007em;\">\u03b4</span></span></span></span><span class=\"mjx-denominator\" style=\"width: 2.324em; bottom: -0.927em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 2.324em;\" class=\"mjx-line\"></span></span><span style=\"height: 2.345em; vertical-align: -0.927em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span><span class=\"mjx-strut\"></span></span></span></span></span></span></span></span></span></span></span><p>Substituting (10) for \ud835\udf0b, we get an expression for optimal \ud835\udf08 in terms of the primitive variables, given the optimal choice \ud835\udf0b* for \ud835\udf0b:</p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"\\nu^* = \\frac{r\\eta-r+\\delta}{\\eta} + (\\eta-1)\\frac{(\\mu-r)^2}{2\\sigma^2\\eta^2}. \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;(14)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.036em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.036em;\">\u03bd</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.137em; padding-right: 0.071em;\"><span class=\"mjx-mo\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.298em;\">\u2217</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mfrac MJXc-space3\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 4.501em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"width: 4.501em; top: -1.523em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.007em;\">\u03b4</span></span></span></span><span class=\"mjx-denominator\" style=\"width: 4.501em; bottom: -0.927em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 4.501em;\" class=\"mjx-line\"></span></span><span style=\"height: 2.45em; vertical-align: -0.927em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mn MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 3.643em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"width: 3.643em; top: -1.667em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03bc</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span><span class=\"mjx-denominator\" style=\"width: 3.643em; bottom: -1.059em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.001em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.001em;\">\u03c3</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.409em; padding-left: 0.073em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.409em; padding-left: 0.082em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 3.643em;\" class=\"mjx-line\"></span></span><span style=\"height: 2.725em; vertical-align: -1.059em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">14</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span><p>Note that a solution to the problem only exists if (14) &gt; 0. Otherwise, for any positive consumption rate, a lower (but still positive) rate is preferred.</p><h2>Adding new products to the model</h2><p>Maintain all the assumptions of Merton\u2019s model, except suppose that, instead of (2), your flow utility at&nbsp;<i>t</i> equals</p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"\\begin{align} N_t\\frac{(c_t/N_t)^{1-\\eta}}{1-\\eta},&amp; \\;\\;\\;\\; \\eta \\neq 1;\\\\ N_t\\log(c_t/N_t),&amp; \\;\\;\\;\\; \\eta = 1\\\\ \\\\ = N_t^\\eta \\frac{c_t^{1-\\eta}}{1-\\eta},&amp; \\;\\;\\;\\; \\eta \\neq 1; \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;(15)\\\\ N_t\\log(c_t)-N_t\\log(N_t),&amp; \\;\\;\\;\\; \\eta = 1. \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\,(16) \\end{align}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mtable\" style=\"vertical-align: -4.663em; padding: 0px 0.167em;\"><span class=\"mjx-table\"><span class=\"mjx-mtr\" style=\"height: 2.789em;\"><span class=\"mjx-mtd\" style=\"padding: 0px 0px 0px 0px; text-align: right; width: 9.95em;\"><span class=\"mjx-mrow\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.085em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;\">N</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 4.59em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"width: 4.59em; top: -1.667em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.085em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;\">N</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span></span></span></span></span><span class=\"mjx-denominator\" style=\"width: 4.59em; bottom: -0.972em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 4.59em;\" class=\"mjx-line\"></span></span><span style=\"height: 2.639em; vertical-align: -0.972em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-strut\"></span></span></span><span class=\"mjx-mtd\" style=\"padding: 0px 0px 0px 0px; text-align: left; width: 8.726em;\"><span class=\"mjx-mrow\" style=\"margin-top: 0.667em;\"><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">\u2260</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.519em;\">;</span></span><span class=\"mjx-strut\"></span></span></span></span><span class=\"mjx-mtr\" style=\"height: 1.375em;\"><span class=\"mjx-mtd\" style=\"padding: 0.15em 0px 0px 0px; text-align: right;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.2em;\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.085em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;\">N</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.519em;\">log</span></span><span class=\"mjx-mo\"><span class=\"mjx-char\"></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.085em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;\">N</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-strut\"></span></span></span><span class=\"mjx-mtd\" style=\"padding: 0.15em 0px 0px 0px; text-align: left;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.2em;\"><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-strut\"></span></span></span></span><span class=\"mjx-mtr\" style=\"height: 1.3em;\"><span class=\"mjx-mtd\" style=\"padding: 0.15em 0px 0px 0px; text-align: right;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.2em;\"><span class=\"mjx-strut\"></span></span></span><span class=\"mjx-mtd\" style=\"padding: 0.15em 0px 0px 0px; text-align: left;\"><span style=\"margin-top: -0.2em;\"></span></span></span><span class=\"mjx-mtr\" style=\"height: 3.137em;\"><span class=\"mjx-mtd\" style=\"padding: 0.15em 0px 0px 0px; text-align: right;\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\" style=\"margin-right: -0.085em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;\">N</span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.287em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0.227em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 2.425em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"width: 2.425em; top: -1.865em;\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.287em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span><span class=\"mjx-denominator\" style=\"width: 2.425em; bottom: -0.972em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 2.425em;\" class=\"mjx-line\"></span></span><span style=\"height: 2.837em; vertical-align: -0.972em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-strut\"></span></span></span><span class=\"mjx-mtd\" style=\"padding: 0.15em 0px 0px 0px; text-align: left;\"><span class=\"mjx-mrow\" style=\"margin-top: 0.865em;\"><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">\u2260</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.519em;\">;</span></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">15</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-strut\"></span></span></span></span><span class=\"mjx-mtr\" style=\"height: 1.225em;\"><span class=\"mjx-mtd\" style=\"padding: 0.15em 0px 0px 0px; text-align: right;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.2em;\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.085em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;\">N</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.519em;\">log</span></span><span class=\"mjx-mo\"><span class=\"mjx-char\"></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\" style=\"margin-right: -0.085em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;\">N</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.519em;\">log</span></span><span class=\"mjx-mo\"><span class=\"mjx-char\"></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.085em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;\">N</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-strut\"></span></span></span><span class=\"mjx-mtd\" style=\"padding: 0.15em 0px 0px 0px; text-align: left;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.2em;\"><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1.</span></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">16</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-strut\"></span></span></span></span></span></span></span></span></span></span></span><p><i>N<sub>t</sub></i> might be interpreted as the number of available products / shovel-ready projects at&nbsp;<i>t</i>. You split your spending at&nbsp;<i>t</i> equally across products/projects, since there\u2019s diminishing returns to spending on each, so spending on each is&nbsp;<i>c<sub>t</sub></i>/<i>N<sub>t</sub></i>; your utility function is CRRA in each one; and your overall utility is the sum of the utilities you derive from each of them.</p><p>Suppose also that the product/project range grows exponentially over time, such that&nbsp;<i>N<sub>t</sub></i> =&nbsp;<i>e<sup>nt</sup></i> for some&nbsp;<i>n</i>. (Note that this model is the same as before if&nbsp;<i>n</i> = 0.) Then the goal is to maximize</p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"E\\int_0^\\infty e^{(-\\delta+n\\eta)t}u(c_t)dt, \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;(17)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;\">E</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\" style=\"margin-right: -0.388em;\"><span class=\"mjx-mo\" style=\"vertical-align: 0.001em; padding-right: 0.388em;\"><span class=\"mjx-char MJXc-TeX-size2-R\" style=\"padding-top: 1.109em; padding-bottom: 1.109em;\">\u222b</span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.921em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 2.15em; padding-left: 0.784em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">\u221e</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">e</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.007em;\">\u03b4</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">17</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span><p>where&nbsp;<i>u</i>(\u00b7) is defined by (2) as before. In the \ud835\udf02 \u2260 1 case, this follows immediately from (15) and the fact that, if&nbsp;<i>N<sub>t</sub></i> =&nbsp;<i>e<sup>nt</sup></i>,&nbsp;<i>N<sub>t</sub></i><sup>\ud835\udf02</sup> =&nbsp;<i>e<sup>n</sup></i><sup>\ud835\udf02</sup><i><sup>t</sup></i>. In the \ud835\udf02 = 1 case, there is an extra \u201c\u2013&nbsp;<i>N<sub>t</sub></i> log(<i>N<sub>t</sub></i>)\u201d at the end of the expression (16) for flow utility, but because this is not affected at all by the investor\u2019s behavior, and its presence does not affect the marginal utility of consumption in any period, it can be removed without affecting the optimal policy.</p><p>Maximizing (17) is the same objective as before, except with the discount rate \ud835\udeff replaced with a \u201cdiscount rate\u201d of \ud835\udeff\u2013<i>n</i>\ud835\udf02. So the optimal choices of \ud835\udf0b and \ud835\udf08 are</p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"\\begin{align} \\pi^* &amp;= \\frac{\\mu-r}{\\eta\\sigma^2},\\\\ \\nu^* &amp;= \\frac{r\\eta-r+\\delta-n\\eta}{\\eta} + (\\eta-1)\\frac{(\\mu-r)^2}{2\\sigma^2\\eta^2}. \\end{align}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mtable\" style=\"vertical-align: -2.487em; padding: 0px 0.167em;\"><span class=\"mjx-table\"><span class=\"mjx-mtr\" style=\"height: 2.598em;\"><span class=\"mjx-mtd\" style=\"padding: 0px 0px 0px 0px; text-align: right; width: 1.013em;\"><span class=\"mjx-mrow\" style=\"margin-top: 0.389em;\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.003em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.076em; padding-right: 0.071em;\"><span class=\"mjx-mo\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.298em;\">\u2217</span></span></span></span><span class=\"mjx-strut\"></span></span></span><span class=\"mjx-mtd\" style=\"padding: 0px 0px 0px 0px; text-align: left; width: 16.787em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mfrac MJXc-space3\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 2.476em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"width: 2.476em; top: -1.389em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03bc</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span></span></span><span class=\"mjx-denominator\" style=\"width: 2.476em; bottom: -1.059em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.001em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.001em;\">\u03c3</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.409em; padding-left: 0.073em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 2.476em;\" class=\"mjx-line\"></span></span><span style=\"height: 2.448em; vertical-align: -1.059em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-strut\"></span></span></span></span><span class=\"mjx-mtr\" style=\"height: 2.875em;\"><span class=\"mjx-mtd\" style=\"padding: 0.15em 0px 0px 0px; text-align: right;\"><span class=\"mjx-mrow\" style=\"margin-top: 0.667em;\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.036em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.036em;\">\u03bd</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.137em; padding-right: 0.071em;\"><span class=\"mjx-mo\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.298em;\">\u2217</span></span></span></span><span class=\"mjx-strut\"></span></span></span><span class=\"mjx-mtd\" style=\"padding: 0.15em 0px 0px 0px; text-align: left;\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mfrac MJXc-space3\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 6.826em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"width: 6.826em; top: -1.523em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.007em;\">\u03b4</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span><span class=\"mjx-denominator\" style=\"width: 6.826em; bottom: -0.927em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 6.826em;\" class=\"mjx-line\"></span></span><span style=\"height: 2.45em; vertical-align: -0.927em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mn MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 3.643em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"width: 3.643em; top: -1.667em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03bc</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span><span class=\"mjx-denominator\" style=\"width: 3.643em; bottom: -1.059em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.001em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.001em;\">\u03c3</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.409em; padding-left: 0.073em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.409em; padding-left: 0.082em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 3.643em;\" class=\"mjx-line\"></span></span><span style=\"height: 2.725em; vertical-align: -1.059em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span><span class=\"mjx-strut\"></span></span></span></span></span></span></span></span></span></span></span><p>Given the calibrations of \ud835\udeff,&nbsp;<i>r</i>, \ud835\udf07, and \ud835\udf0e we have used, it again follows from \ud835\udf0b* = 0.6 that \ud835\udf02 \u2248 4.25. Given \ud835\udf02 \u2248 4.25, it then follows from \ud835\udf08* = 0.16 that&nbsp;<i>n</i> \u2248 0.005. That is, the puzzle can be fully resolved if we posit that the product range (or, for the philanthropist, project range) grows at 0.5% per year, even if we make no other changes.</p><h2>Uncertainty about \ud835\udf02</h2><p>(This part of the appendix is linked to from <a href=\"https://forum.effectivealtruism.org/posts/cf8Dth9vpxX9ptgma/against-much-financial-risk-tolerance#Arguments_from_uncertainty\">the \u201cArguments from uncertainty\u201d sub-subsection</a>, which comes before Merton\u2019s model is introduced, but it assumes that the reader is familiar with Merton\u2019s model. If you aren\u2019t, or would like to clarify the notation used here, see the appendix section above on <a href=\"https://forum.effectivealtruism.org/posts/cf8Dth9vpxX9ptgma/against-much-financial-risk-tolerance#Understanding_the_model\">\u201cUnderstanding the model\u201d</a>, through <a href=\"https://forum.effectivealtruism.org/posts/cf8Dth9vpxX9ptgma/against-much-financial-risk-tolerance#Calculating_the_optimal___\">\u201cCalculating the optimal \ud835\udf0b\u201d</a>.)</p><p>Maintain all the assumptions of Merton\u2019s model, except suppose that \ud835\udf02 is unknown, with a distribution of values independent of the distribution of stock returns. For any particular realization of \ud835\udf02, the expected marginal utility achieved by investing in bonds is still</p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"(1+r\\,dt)\\bar{c}_{t+dt}^{-\\eta}.\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.096em; padding-bottom: 0.06em; padding-left: 0.022em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u00af</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span></span></span></span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.335em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span></span></span></span></span></span><p>And because we have assumed that our uncertainty about \ud835\udf02 is independent of our uncertainty about stock returns, the expected marginal utility to investing in bonds all things considered is</p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"E_\\eta[1+r\\,dt)\\bar{c}_{t+dt}^{-\\eta}].\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.026em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;\">E</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">[</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.096em; padding-bottom: 0.06em; padding-left: 0.022em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u00af</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span></span></span></span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.335em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">]</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span></span></span></span></span></span><p>Likewise, the expected marginal utility to investing in stocks is</p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"E_\\eta[(1+\\mu\\,dt)\\bar{c}_{t+dt}^{-\\eta}-\\eta\\bar{c}_{t+dt}^{-\\eta}\\pi\\,\\sigma^2dt].\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.026em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;\">E</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">[</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03bc</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.096em; padding-bottom: 0.06em; padding-left: 0.022em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u00af</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span></span></span></span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.335em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.096em; padding-bottom: 0.06em; padding-left: 0.022em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u00af</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span></span></span></span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.335em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.001em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.001em;\">\u03c3</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.073em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">]</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span></span></span></span></span></span><p>Setting these equal, we have that \ud835\udf0b* must satisfy</p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"\\begin{align} E_\\eta[(1+r\\,dt)\\bar{c}_{t+dt}^{-\\eta}-(1_\\mu\\,dt)\\bar{c}_{t+dt}^{-\\eta}+\\eta\\bar{c}_{t+dt}^{-\\eta}\\pi^*\\sigma^2dt] &amp;= 0\\\\ \\implies E_\\eta[(1+r\\,dt)-(1+\\mu\\,dt)+\\eta\\,\\pi^*\\sigma^2dt] &amp;= 0\\\\ \\implies \\pi^* &amp;= E_\\eta\\Big[\\frac{\\mu-r}{\\eta\\sigma^2}\\Big]=\\frac{\\mu-r}{\\sigma^2}E[1/\\eta]. \\end{align}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mtable\" style=\"vertical-align: -2.567em; padding: 0px 0.167em;\"><span class=\"mjx-table\"><span class=\"mjx-mtr\" style=\"height: 1.514em;\"><span class=\"mjx-mtd\" style=\"padding: 0px 0px 0px 0px; text-align: right; width: 20.297em;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.046em;\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.026em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;\">E</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">[</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.096em; padding-bottom: 0.06em; padding-left: 0.022em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u00af</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span></span></span></span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.335em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03bc</span></span></span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.096em; padding-bottom: 0.06em; padding-left: 0.022em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u00af</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span></span></span></span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.335em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.096em; padding-bottom: 0.06em; padding-left: 0.022em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u00af</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span></span></span></span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.335em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.003em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.076em; padding-right: 0.071em;\"><span class=\"mjx-mo\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.298em;\">\u2217</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.001em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.001em;\">\u03c3</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.073em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">]</span></span><span class=\"mjx-strut\"></span></span></span><span class=\"mjx-mtd\" style=\"padding: 0px 0px 0px 0px; text-align: left; width: 13.274em;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.046em;\"><span class=\"mjx-mi\"></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span><span class=\"mjx-strut\"></span></span></span></span><span class=\"mjx-mtr\" style=\"height: 1.522em;\"><span class=\"mjx-mtd\" style=\"padding: 0.15em 0px 0px 0px; text-align: right;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.098em;\"><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u27f9</span></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\" style=\"margin-right: -0.026em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;\">E</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">[</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03bc</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.003em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.076em; padding-right: 0.071em;\"><span class=\"mjx-mo\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.298em;\">\u2217</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.001em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.001em;\">\u03c3</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.073em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">]</span></span><span class=\"mjx-strut\"></span></span></span><span class=\"mjx-mtd\" style=\"padding: 0.15em 0px 0px 0px; text-align: left;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.098em;\"><span class=\"mjx-mi\"></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span><span class=\"mjx-strut\"></span></span></span></span><span class=\"mjx-mtr\" style=\"height: 2.598em;\"><span class=\"mjx-mtd\" style=\"padding: 0.15em 0px 0px 0px; text-align: right;\"><span class=\"mjx-mrow\" style=\"margin-top: 0.389em;\"><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u27f9</span></span><span class=\"mjx-mspace\" style=\"width: 0.278em; height: 0px;\"></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\" style=\"margin-right: -0.003em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;\">\u03c0</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.584em; padding-left: 0.076em; padding-right: 0.071em;\"><span class=\"mjx-mo\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.298em;\">\u2217</span></span></span></span><span class=\"mjx-strut\"></span></span></span><span class=\"mjx-mtd\" style=\"padding: 0.15em 0px 0px 0px; text-align: left;\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\" style=\"margin-right: -0.026em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;\">E</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span><span class=\"mjx-mstyle\"><span class=\"mjx-mrow\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size2-R\" style=\"padding-top: 0.961em; padding-bottom: 0.961em;\">[</span></span></span></span></span></span><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 2.476em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"width: 2.476em; top: -1.389em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03bc</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span></span></span><span class=\"mjx-denominator\" style=\"width: 2.476em; bottom: -1.059em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.001em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.001em;\">\u03c3</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.409em; padding-left: 0.073em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 2.476em;\" class=\"mjx-line\"></span></span><span style=\"height: 2.448em; vertical-align: -1.059em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mstyle\"><span class=\"mjx-mrow\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size2-R\" style=\"padding-top: 0.961em; padding-bottom: 0.961em;\">]</span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mfrac MJXc-space3\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 2.476em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"width: 2.476em; top: -1.389em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03bc</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span></span></span><span class=\"mjx-denominator\" style=\"width: 2.476em; bottom: -0.854em;\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.001em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.001em;\">\u03c3</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.409em; padding-left: 0.073em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 2.476em;\" class=\"mjx-line\"></span></span><span style=\"height: 2.243em; vertical-align: -0.854em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;\">E</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">[</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">]</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span><span class=\"mjx-strut\"></span></span></span></span></span></span></span></span></span></span></span><p>This reveals an asymmetry. Since 1/\ud835\udf02 is strictly convex in \ud835\udf02 &gt; 0, symmetric distributions about \ud835\udf02 itself should motivate portfolios closer those motivated by low values of \ud835\udf02 than high values. For illustration, suppose (\ud835\udf07\u2013<i>r</i>)/\ud835\udf0e<sup>2</sup> = 1 and compare \ud835\udf0b* in the case that \ud835\udf02 is known to equal 2 (\ud835\udf0b* = 1/2) to \ud835\udf0b* in the case that \ud835\udf02 could equal 1 or 3 with equal probability (\ud835\udf0b* = 0.5(1)+0.5(1/3) = 2/3 &gt; 1/2).</p><p>But why should our uncertainty about the curvature of the philanthropic utility function be expected to take the form of a symmetric distribution about \ud835\udf02? One could just as well posit a symmetric distribution about any other parametrization of curvature: any strictly monotonic (increasing or decreasing) transformation of \ud835\udf02, for example. In particular, symmetric uncertainty about 1/\ud835\udf02\u2014the \u201celasticity of intertemporal substitution\u201d, a quantity with no less natural an interpretation than the RRA \ud835\udf02\u2014has no impact on the optimal portfolio. For illustration, suppose again that (\ud835\udf07\u2013<i>r</i>)/\ud835\udf0e<sup>2</sup> = 1 and compare \ud835\udf0b* in the case that 1/\ud835\udf02 is known to equal 2 (\ud835\udf0b* = 2) to \ud835\udf0b* in the case that 1/\ud835\udf02 could equal 1 or 3 with equal probability (\ud835\udf0b* = 0.5(1)+0.5(3) = 2).</p><p>(Symmetric uncertainty about \ud835\udf02 also seems badly motivated because of another asymmetry: we can be reasonably confident that \ud835\udf02 isn\u2019t zero or negative, but not that it isn\u2019t very high. But the same can be said for 1/\ud835\udf02, of course.)</p><p>Finally, I should acknowledge that arguments for \u201cacting as if \ud835\udf02 is low when we\u2019re not sure\u201d have a lot in common with arguments for \u201cacting as if \ud835\udeff is low when we\u2019re not sure\u201d that I\u2019ve endorsed in the past. I hope I\u2019m not being inconsistent here. There are a few important differences between the cases, but without getting too far into the weeds, let me just note one of them: namely that it\u2019s arguably reasonable to put non-negligible weight on the possibility that we should use a \ud835\udeff, but not a \ud835\udf02, around zero.<br>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnl52wv3zjsb\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefl52wv3zjsb\">^</a></strong></sup></span><div class=\"footnote-content\"><p>An earlier version of&nbsp;<a href=\"https://docs.google.com/document/d/1NcfTgZsqT9k30ngeQbappYyn-UO4vltjkm64n4or5r4/edit#heading=h.bmotm8q6xhn5\"><u>Patient Philanthropy in an Impatient World, \u00a74.3 \u2013 Patient finance</u></a> defended using roughly logarithmic utility for patient philanthropists in particular, for reasons rejected in <a href=\"https://forum.effectivealtruism.org/posts/cf8Dth9vpxX9ptgma/against-much-financial-risk-tolerance#Against_logarithmic_utility_as_a_baseline\">the \u201cAgainst logarithmic utility\u2026\u201d sub-subsection</a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn4vichsqddwf\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref4vichsqddwf\">^</a></strong></sup></span><div class=\"footnote-content\"><p>They refer to \u201cusing something like the Kelly criterion\u201d. Using the Kelly criterion amounts to optimizing for a logarithmic utility function, as discussed in <a href=\"https://forum.effectivealtruism.org/posts/cf8Dth9vpxX9ptgma/against-much-financial-risk-tolerance#Against_logarithmic_utility_as_a_baseline\">the \u201cAgainst logarithmic utility\u2026\u201d sub-subsection</a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn7qqd7t1nluy\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref7qqd7t1nluy\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Like Harvard, Yale in the early 2000\u2019s adopted a portfolio that pursues excess returns by taking advantage of investment opportunities beyond the publicly traded stocks and bonds to which the rest of us have easy access. But according to a 2005&nbsp;<a href=\"https://www.amazon.co.uk/dp/B003YCOR9Q/\"><u>book</u></a> by the former Yale portfolio manager, a&nbsp;<a href=\"https://www.optimizedportfolio.com/david-swensen-portfolio/\"><u>portfolio</u></a> of publicly traded assets consisting of 50% publicly traded stocks, 30% bonds, and 20% real estate funds behaves roughly like the Yale portfolio.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn11db65p50yni\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref11db65p50yni\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Exactly how risky this portfolio is depends on how risky private equity is. Whether it\u2019s more or less risky (in a relevant sense) than publicly traded equity seems to be a matter of debate; see footnote <a href=\"https://forum.effectivealtruism.org/editPost?postId=cf8Dth9vpxX9ptgma&amp;key=f1f2a95cae5b698978d8ad235867ed#fn18zn7quratt\">14</a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fngfkvkzw6r3w\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefgfkvkzw6r3w\">^</a></strong></sup></span><div class=\"footnote-content\"><p>I don\u2019t mean to criticize the authors at all, especially because these documents are several years old and don\u2019t necessarily reflect their authors\u2019 current thinking. Also, in some cases, such as&nbsp;<a href=\"https://80000hours.org/2012/01/salary-or-startup-how-do-gooders-can-gain-more-from-risky-careers/\"><u>Shulman (2012)</u></a>, the documents make claims which are technically correct, but which I think are easy to misinterpret and have been misinterpreted by some readers.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn5vngg03h9na\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref5vngg03h9na\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Though in principle there are also cases in which moral risk aversion would motivate more financial risk tolerance.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fno2bs9yq5rxh\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefo2bs9yq5rxh\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Or, of course, a large segment of the EA landscape if the cause receives little non-EA support and the philanthropist in question is Open Philanthropy. E.g. according to&nbsp;<a href=\"https://80000hours.org/podcast/episodes/lewis-bollard-end-factory-farming/\"><u>Lewis Bollard, as of 2017</u></a> Open Phil probably constituted a large majority of all farm animal welfare philanthropy.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnv942izmt4p\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefv942izmt4p\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://www.openphilanthropy.org/research/technical-updates-to-our-global-health-and-wellbeing-cause-prioritization-framework/\"><u>Berger and Favaloro (2021)</u></a> say: \u201cWe\u2019ve done more sophisticated modeling work on how we expect the cost-effectiveness of direct global health aid and asset returns to interact over time\u2026 We\u2019re still hoping to share that analysis and code\u201d. It hasn\u2019t been made public yet, but the context suggests that the analysis treats the quantity of philanthropic global health spending as the primary determinant of the cost-effectiveness of direct global health aid. If that\u2019s true, I would worry that it neglects the less visible ways in which poverty is more acute, and global health aid therefore more valuable, when asset returns are low. Those interested in doing further work on this should also consider reaching out to&nbsp;<a href=\"mailto:john.firth@economics.ox.ac.uk\"><u>John Firth</u></a>, who tells me he\u2019s aware of some relevant data and has some ideas about how he would go about the project.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fne4sevprasfw\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefe4sevprasfw\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Also, who the poorest&nbsp;<i>are</i> can vary from period to period, producing less variation in how poor the poorest are than in how poor any particular individual is\u2014and thus weaker correlations between \u201cthe consumption of the poorest\u201d and a given other variable, like stock market performance. The implications of a philanthropist\u2019s&nbsp;<i>ability to vary his range of beneficiaries in light of how rich he is</i> for his&nbsp;<i>financial risk tolerance</i> are explored further in <a href=\"https://forum.effectivealtruism.org/posts/cf8Dth9vpxX9ptgma/against-much-financial-risk-tolerance#The_cause_variety_argument\">the \u201ccause variety\u201d sub-subsection</a> and <a href=\"https://forum.effectivealtruism.org/posts/cf8Dth9vpxX9ptgma/against-much-financial-risk-tolerance#Appendix_C__Less_curvature_due_to_cause_variety\">Appendix C</a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnfhgol240dr\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreffhgol240dr\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Philanthropic funding is indeed responsive to stock market movements. I\u2019m not familiar with the literature on this, but see&nbsp;<a href=\"https://bpb-us-w2.wpmucdn.com/voices.uchicago.edu/dist/f/1276/files/2018/09/8Charitable-Donations-are-more-Responsive-to-Stock-Market-Booms-than-Busts-1tlfzsi.pdf\"><u>List and Peysakhovich (2010)</u></a> for an example and perhaps a \u201cway in\u201d to the rest of the literature. It\u2019s true that in the short term, government spending (or philanthropic) might be only mildly cyclical, or even countercyclical, rising in busts and falling in booms. (See&nbsp;<a href=\"https://www.givewell.org/rollover-funds#How_rollover_funding_impacts_the_cost-effectiveness_of_donations\"><u>GiveWell\u2019s discussion of \u201crollover spending\u201d</u></a>, for example. This smoothing can be justified by the frictions discussed in the later <a href=\"https://forum.effectivealtruism.org/posts/cf8Dth9vpxX9ptgma/against-much-financial-risk-tolerance#Habit_formation\">section on \u201chabit formation\u201d</a>.) But in the long term, stock performance should be expected to move with economic performance, which in turn determines how much governments and philanthropists can spend.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fntrd9twbg50n\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreftrd9twbg50n\">^</a></strong></sup></span><div class=\"footnote-content\"><p>If this spending takes the form of funding for a current GiveWell charity, like Malaria Consortium, then a jump in spending in some year would affect Open Philanthropy\u2019s judgment of the charity\u2019s room for more funding; they would correctly infer that Malaria Consortium\u2019s employees and infrastructure were already being used at closer to full capacity. But if the new outside spending takes the form of, say, better swamp drainage or better-staffed hospitals, it would lower the marginal value of contributions to Malaria Consortium in less visible ways.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnhcknsluens\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefhcknsluens\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Michael Dickens tells me that analyses by <a href=\"https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1745-6622.2003.tb00524.x\">Dimson et al. (2005)</a> and <a href=\"https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1745-6622.2012.00385.x\">Ritter (2012)</a> find no correlations, or even negative correlations, between stock market movements and GDP movements. I won\u2019t be able to dive into this question myself for a long time, unfortunately, and I think it would be good to get this post out without further delay, so although the size of the correlation here is a central question for this post, for now I\u2019ll have to put it aside. I will say, though, that<br>- if global index funds return a geometric average of 10%/year for the next 30 years, I think GWP (the sum of countries\u2019 GDPs) will be higher than it is today;<br>- if global index funds return a geometric average of -10%/year for the next 30 years, I think GWP will be lower than it is today; and<br>- if any of the authors cited above want to bet on either count, they can reach out at <a href=\"mailto:philip.trammell@economics.ox.ac.uk\">pawtrammell@gmail.com</a>...!</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnzraicywh3nb\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefzraicywh3nb\">^</a></strong></sup></span><div class=\"footnote-content\"><p>But his would only be a \u201cpartial equilibrium\u201d recommendation; i.e. it would require the assumption that other investors don\u2019t have different targets for the collective portfolio and rebalance it in light of a given small funder\u2019s portfolio-changes. I\u2019m not aware of a thorough analysis of the game played by different parties funding the same cause but with different risk attitudes.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn18zn7quratt\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref18zn7quratt\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Formally, the claim here is that [tech] startups exhibit&nbsp;<a href=\"https://www.investopedia.com/terms/b/beta.asp#:~:text=Beta%20(%CE%B2)%20is%20a%20measure,volatile%20than%20the%20S%26P%20500.\"><u>betas</u></a> greater than 1. This is what I\u2019ve always heard, and it\u2019s consonant with the very-often-cited point (e.g. in the very explanation of \u201cbeta\u201d linked above) that publicly traded (a) small cap companies and (b) tech companies in general both exhibit betas &gt; 1. On the other hand, I should note for completeness that it\u2019s sometimes argued that private equity has&nbsp;<a href=\"https://www.nasdaq.com/articles/modeling-private-equity-market-beta\"><u>beta &lt; 1</u></a>. I\u2019m not sure what explains this. Michael Dickens, reviewing a draft of this post, notes that <a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4121735\">D\u00f8skeland and Str\u00f6mberg (2018)</a> find venture capital beta &gt; 1, and suggests that PE firms might just be misreporting. In any case, if an optimally-behaving philanthropic community will have unusually many startup founders, it will presumably tend to get most of the value of these during the period when the startups are publicly traded, as e.g. Meta and Asana currently are.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fniscyb5rkg\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefiscyb5rkg\">^</a></strong></sup></span><div class=\"footnote-content\"><p>A recent literature review by&nbsp;<a href=\"http://meta-analysis.cz/risk/risk.pdf\"><u>Elminejad et al. (2022)</u></a> reports that published estimates are indeed well above 1. The authors argue that this question has been subject to publication bias, however, and that after correcting for it, one class of estimates does center around 1 while another\u2014the one more relevant to our case\u2014remains well above 1.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fndbi4nkj04gs\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefdbi4nkj04gs\">^</a></strong></sup></span><div class=\"footnote-content\"><p>This only follows if poor households don\u2019t tend to be more risk tolerant or risk averse than average, in the relevant sense. If people\u2019s utility functions exhibit \u201cconstant relative risk aversion\u201d, or CRRA, then the coefficient of relative risk aversion (RRA)\u2014the measure of risk aversion relevant here\u2014is independent of their consumption. Since the RRAs on which people act has not appeared to change much over time, as even as people have on average gotten much richer, it is common for economists to assume CRRA utility functions.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnuq0abqccv2h\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefuq0abqccv2h\">^</a></strong></sup></span><div class=\"footnote-content\"><p>See e.g.&nbsp;<a href=\"https://rationalaltruist.com/2013/02/28/risk-aversion-and-investment-for-altruists/\"><u>Christiano (2013)</u></a>. A quick scroll through LessWrong and EA Forum posts tagged \u201crisk aversion\u201d turns up the recent examples of&nbsp;<a href=\"https://www.lesswrong.com/posts/zmpYKwqfMkWtywkKZ/kelly-isn-t-just-about-logarithmic-utility\"><u>SimonM (2021)</u></a>,&nbsp;<a href=\"https://www.lesswrong.com/posts/NPzGfDi3zMJfM2SYe/why-bet-kelly\"><u>Mennen (2022)</u></a>, to some extent&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/WJbnygdFQwEpBez4i/extreme-risk-neutrality-isn-t-always-wrong-1#fnrefz1eaaioeuuh\"><u>Demaree (2022)</u></a>, and more. That old Google doc I mentioned in the introduction defends the \u201cKelly argument\u201d as well.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnqq5wam3xz2o\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefqq5wam3xz2o\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Except for \u201closses\u201d, which seems to have been a mistake in the second paragraph, and \u201csyllable\u201d, which is the punchline at the end.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnwstbg5uo6x\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefwstbg5uo6x\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Cotton-Barratt does also cite some empirical evidence from&nbsp;<a href=\"https://www.amazon.co.uk/Scientific-Progress-Philosophical-Economics-Research/dp/0631179801\"><u>Rescher (1978)</u></a> for the view that the research production function is in some sense logarithmic. A lot more data has been collected on this question since 1978, so to the extent that we think this is a valuable approach, it might be worth updating. But I don\u2019t think it\u2019s important to sort through that question here, since as noted just below, the research production function isn\u2019t what matters anyway.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnx0dfpt848ca\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefx0dfpt848ca\">^</a></strong></sup></span><div class=\"footnote-content\"><p>If what we mean by a \u201cresearch output\u201d is an \u201cidea\u201d in the sense of&nbsp;<a href=\"https://www.aeaweb.org/articles?id=10.1257/aer.20180338\"><u>Bloom et al. (2020)</u></a>\u2014i.e. a proportional \u201cproductivity increase\u201d\u2014then our utility is linear in research outputs iff our utility is logarithmic in whatever we\u2019re producing. So inferring logarithmic utility on this basis would again amount to assuming the conclusion.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnvf3g968cop\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefvf3g968cop\">^</a></strong></sup></span><div class=\"footnote-content\"><p>I don\u2019t think this is unique to me. Anecdotally, many others heavily involved in the EA community seem to share the intuition that the marginal utility to \u201cEA spending\u201d diminishes rapidly, at least within any given period. See the beginning of&nbsp;<a href=\"https://twitter.com/ben_j_todd/status/1470432322558246914\"><u>Ryan Carey\u2019s tweet-response here</u></a>, for instance.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnxydmrgeqczk\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefxydmrgeqczk\">^</a></strong></sup></span><div class=\"footnote-content\"><p>This estimate is currently being used to determine how quickly to spend, but not how to invest.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn3r1msfska2v\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref3r1msfska2v\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Berger and Favaloro may understand this, but at least some readers, such as&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/WJbnygdFQwEpBez4i/extreme-risk-neutrality-isn-t-always-wrong-1#fnrefz1eaaioeuuh\"><u>Demaree (2022)</u></a>, have taken what I see as the wrong impression.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnpt1yd241ut\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefpt1yd241ut\">^</a></strong></sup></span><div class=\"footnote-content\"><p>To ensure that the investor\u2019s problem has a solution, we also have to assume that the parameter values are such that (4) &gt; 0. Otherwise there is no solution: for any positive consumption rate, a lower (but still positive) rate is preferred.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnp4b9jnyu8jf\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefp4b9jnyu8jf\">^</a></strong></sup></span><div class=\"footnote-content\"><p>The conclusion that people tend to consume only 1.6% of their wealth every year may sound absurd. But this is what we must conclude if we (a) follow the assumption in this model that the only source of future income is interest on investments, and (b) assume a roughly standard economic growth rate of 2% per year. Given a portfolio of 60% stocks, earning an average of 6% interest per year, and 40% risk-free bonds, earning 1% per year, growth in wealth would average around 3.6% per year if there were&nbsp;<i>no</i> consumption; so growth of 2% per year must imply a consumption rate of around 1.6% per year. The fact that growth continues despite the fact that people consume more than 1.6% of their saved stocks and bonds every year is due to the fact that, in practice, most income comes not from interest on investments but from wages. The implications of this are discussed in <a href=\"https://forum.effectivealtruism.org/posts/cf8Dth9vpxX9ptgma/against-much-financial-risk-tolerance#The_lifecycle_argument\">the \u201clifecycle argument\u201d subsection</a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnhk1ehlruphn\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefhk1ehlruphn\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Or \u22489.5, if we use the \u201c\u2013\u221a\u2026\u201d arm of the quadratic formula instead of the \u201c+\u221a\u2026\u201d arm. Intuitively, the reason that this equation has two solutions is that a higher \ud835\udf02 exerts two opposing forces on the saving rate. First, if you expect to be richer in the future, a higher value of \ud835\udf02 means that this future wealth will more greatly lower future marginal utility in consumption. This motivates less saving. Second, if some of your investment returns are risky, a high value of \ud835\udf02 makes you more scared about whatever low possibility remains of a consumption decline. This motivates more saving (in bonds). So, sometimes, a given high saving rate\u2014i.e. low \ud835\udf08\u2014might be motivated by high&nbsp;<i>or</i> low \ud835\udf02. A graph of this hump-shaped relationship can be found&nbsp;<a href=\"https://www.wolframalpha.com/input?i=plot+%28r*h%E2%80%93r%2Bd%29%2Fh+%2B+%28h%E2%80%931%29*%28m%E2%80%93r%29%5E2%2F%282*s%5E2*h%5E2%29+at+r%3D0.01%2C+d%3D0.01%2C+m%3D0.06%2C+s%3D0.14%2C+h+from+0+to+15\"><u>here</u></a>. But since&nbsp;<a href=\"https://www.academicwebpages.com/preview/mehra/pdf/The%20Equity%20Premium%20A%20Puzzle.pdf\"><u>Mehra and Prescott\u2019s (1985)</u></a> original observation of the equity premium puzzle, the very-high-\ud835\udf02 calibrations have typically been ruled out as, in their words, not \u201cconsistent with findings in micro, macro and international economics\u201d.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnkqttsysqmye\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefkqttsysqmye\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Or perhaps how it leaves his bank account comparing with others\u2019, as noted in <a href=\"https://forum.effectivealtruism.org/posts/cf8Dth9vpxX9ptgma/against-much-financial-risk-tolerance#Keeping_up_with_the_Joneses\">the Keeping up with the Joneses sub-subsection</a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnfqzr2vwbye\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreffqzr2vwbye\">^</a></strong></sup></span><div class=\"footnote-content\"><p>E.g.&nbsp;<a href=\"https://mdickens.me/2022/04/04/model_of_mission-correlated_investing/\"><u>Dickens (2022a)</u></a>, <a href=\"https://mdickens.me/2022/08/23/should_philanthropists_mission_hedge_ai_progress/\">Dickens (2022b)</a>, and <a href=\"https://forum.effectivealtruism.org/posts/5hjcGjsmkD4RPmyRF/mission-correlated-investing-examples-of-mission-hedging-and\">Harris (2022)</a>, which I\u2019m linking for completeness though unfortunately have only glanced at.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnixc0euyk6o9\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefixc0euyk6o9\">^</a></strong></sup></span><div class=\"footnote-content\"><p>If there is literally a continuum of causes, this reordering may not be possible. Consider the case in which the set of \u201cnon-reordered\u201d projects&nbsp;<i>p</i> for which&nbsp;<i>f</i>(<i>p</i>) \u2208 (0, 1) and the set for which&nbsp;<i>f</i>(<i>p</i>) \u2208 (1, 2) are both of infinite measure, for instance. (Thanks to Luis Mota for flagging this.) So a further assumption of this model is that the projects can be ordered so that&nbsp;<i>f</i>(<i>p</i>) is non-decreasing.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnrd9sny30xde\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefrd9sny30xde\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Given a finite horizon&nbsp;<i>T</i>, the calendar time&nbsp;<i>t</i> would itself have been another state variable.</p></div></li></ol>", "user": {"username": "trammell"}}, {"_id": "WJGsb3yyNprAsDNBd", "title": "EA orgs need to tabletop more. ", "postedAt": "2023-07-30T20:45:54.423Z", "htmlBody": "<h2>TLDR;&nbsp;</h2><p><a href=\"https://www.longgameproject.org\">The Long Game Project </a>want to assist more EA organisations in performing tabletop exercises.</p><p>EA work often involves making decisions about important topics but under high uncertainty and complexity. This presents challenges in decision-making that can be improved through practice.</p><p>We believe more EA decision-makers should enhance their decision-making abilities through regular practice. This will help in building teams that are prepared for the future and can proactively address upcoming challenges.</p><p>Tabletop exercises can effectively explore questions of uncertainty, risk, hypotheses, or problems from a fresh perspective. If your organisation has a particular issue to explore, consider using tabletop exercises as a tool.</p><p>If you don't have a specific scenario in mind, don't worry. We can handle the design process! We can create exercises for any topic or question of uncertainty.</p><p>To start asking yourself the right questions, <a href=\"https://ohgqv9umwna.typeform.com/to/KR1JgDBU\">start here</a>.</p><p>&nbsp;</p><h3><strong>What are Tabletop Exercises (TTXs)?</strong></h3><p>TTXs are structured activities that simulate real-life scenarios, enabling organisations to practice responding to crises and complex decision-making situations. They serve as a low-risk environment to explore institutional resilience, team coordination, and decision-making effectiveness. Participants can make mistakes, learn from them, and iterate their strategies without real-world consequences.</p><p>&nbsp;</p><h3><strong>Why Should EA Organisations Care?</strong></h3><p>EA organisations often deal with complex issues, making decision-making processes uncertain. Errors can have significant consequences in terms of resource allocation and the potential impact on lives, and missed opportunities for positive action.</p><p>&nbsp;</p><h3><strong>Why EA organisations should engage more in tabletop exercises:</strong></h3><ul><li><strong>Improve Decision-Making</strong>: Tabletop exercises allow teams to confront simulated crises, helping them refine their decision-making skills, enhance strategic thinking, and better understand the ripple effects of their actions.</li><li><strong>Boost Team Collaboration</strong>: These exercises promote collaborative problem-solving, fostering more substantial team unity, improving communication, and clarifying roles and responsibilities.</li><li><strong>Build Resilience</strong>: Regularly tackling various challenges through these exercises can make your organisation more adaptable and resilient, preparing it to handle real-life crises when they arise effectively.</li><li><strong>Encourage Long-Term Planning</strong>: Tabletop exercises (TTXs) stimulate forward-thinking by simulating potential scenarios. This can inform strategic planning and risk management and tighten feedback loops for organisational plans.</li><li><strong>Explore New Perspectives</strong>: TTXs provide a platform to approach a question or problem set from different angles. They offer an immersive environment for exploring agency and decision-making.<br>&nbsp;</li></ul><h3><strong>Why don\u2019t EA orgs do more of this?</strong></h3><p>Despite the clear benefits of tabletop exercises, many organisations have yet to adopt them. This reluctance often arises from several common obstacles:</p><ul><li><strong>Perceived Complexity</strong>: Some organisations might view the setup and execution of tabletop exercises as overly complex or time-consuming. While designing realistic scenarios and facilitating productive discussions require careful planning and expertise, these challenges can be surmounted with the proper guidance and support around the scope.</li><li><strong>Limited Resources</strong>: Organisations may lack the necessary resources - time, funds, or personnel - to invest in tabletop exercises. However, viewing these exercises as an investment in risk mitigation and crisis readiness is crucial, which can yield significant long-term savings. Tabletop exercises can be scaled to any budget. Time and personnel are usually limited by aligning calendar blocks and prioritising an exercise as necessary.&nbsp;</li><li><strong>Organisational Culture</strong>: To embrace tabletop exercises, an organisation's culture must prioritize proactive risk management. Shifting this mindset requires leadership endorsement and clear communication about the exercises' value.</li><li><strong>Fear of Exposure</strong>: Some organisations might worry that tabletop exercises will reveal weaknesses or vulnerabilities. However, it's far more advantageous to identify and address these issues in a controlled, simulated environment than during an actual crisis.</li><li><strong>Lack of Awareness</strong>: Certain organisations might not fully understand the benefits of tabletop exercises or may underestimate their value. Increasing awareness about these exercises and their potential uses is a vital initial step.</li></ul><p>&nbsp;</p><p>We exist to make tabletop exercises an accessible and valuable tool for all organisations within the EA community. We aim to help you navigate these challenges, ensuring the implementation of tabletop exercises is as straightforward and beneficial as possible.</p><p><br>&nbsp;</p><h3><strong>How Can We Help?</strong></h3><p>We aim to shoulder the design, facilitation, and feedback responsibilities, allowing you to focus on participating and enhancing your effectiveness. We can also provide tools to run your own game. Check out the repository of <a href=\"https://www.longgameproject.org/resources\">run-it-yourself scenario guides</a> or make one yourself with the <a href=\"https://www.longgameproject.org/generator\">generator tool</a>.</p><p>We specialise in designing and facilitating Tabletop Exercises (TTXs) customised to your organisation's needs. The topics for these scenarios can be flexible. All you need to do is communicate your concerns, problems, or questions, and we will define the aim of the exercise. A good starting point is our <a href=\"https://ohgqv9umwna.typeform.com/to/KR1JgDBU\">scoping guide.</a></p><p>TTXs don't require an all-day commitment. A session of 2-3 hours is a good starting point. We encourage organisations to engage in lean but regular exercises to tighten feedback loops and avoid a one-and-done mindset.</p><p>&nbsp;</p><h3><strong>The Long Game Project can:</strong></h3><ul><li><strong>Design Scenarios</strong>: We develop custom scenarios considering your organisation's specific concerns, objectives, and operational context.</li><li><strong>Facilitate TTX</strong>: Our experienced facilitators guide your team through the exercise, ensuring everyone stays focused and capitalises on crucial learning opportunities.</li><li><strong>Assist Post-Exercise Analysis</strong>: We provide a thorough debriefing and report, highlighting areas of strength and identifying opportunities for improvement.</li></ul><p><br>&nbsp;</p><p>Whether you're new to tabletop exercises or looking to deepen your organisation's crisis management capabilities, we're here to help. By integrating tabletop exercises into your organisational culture, you can equip your team with the skills and experience necessary to navigate a complex world.</p><p>&nbsp;</p><p><a href=\"https://ohgqv9umwna.typeform.com/to/KR1JgDBU\">Please contact us</a> to learn more about how tabletop exercises can benefit your organisation. We're eager to help you strengthen your decision-making processes, enhance resilience, and increase your positive impact on the world.&nbsp;</p><p><br>&nbsp;</p>", "user": {"username": "Dan Epstein"}}, {"_id": "nT8Ybhjvz5qG3eLuw", "title": "Implementational Considerations for Digital Consciousness", "postedAt": "2023-07-30T22:15:53.501Z", "htmlBody": "<p>This post is a summary of my conclusions after a philosophical <a href=\"https://philpapers.org/rec/SHIICF\">project</a> investigating some aspects of computing architecture that might be relevant to assessing digital consciousness. [Edit: The main ideas are <a href=\"https://link.springer.com/article/10.1007/s11229-023-04473-z\">published in shorter form</a>.] I tried to approach the issues in a way that is useful to people with mainstream views and intuitions. Overall, I think that present-day implementational considerations should significantly reduce the probability most people assign to the possibility of conscious digital systems using current architectural and programming paradigms.</p><p><i>The project was funded by the Long Term Future Fund.</i></p><p>&nbsp;</p><p><strong>Key claims and synopses of the rationale for each:</strong></p><p>&nbsp;</p><p><strong>1. Details of the implementation of computer systems may be important to how confident we are about their capacity for consciousness.</strong></p><ul><li>Experts are unlikely to come to agree that a specific theory of consciousness is correct and epistemic humility demands that we keep an open mind.</li><li>Some plausible theories will make consciousness dependent on aspects of implementation.</li><li>The plausible implementational challenges to digital consciousness should influence our overall assessment of the likelihood of digital consciousness.</li></ul><p>&nbsp;</p><p><strong>2. If computer systems are capable of consciousness, it is most likely that some theory of the nature of consciousness in the ballpark of functionalism is true.</strong></p><ul><li>Brains and computers are composed of fundamentally different materials and operate at low levels in fundamentally different ways.</li><li>Brains and computers share abstract functional organizations, but not their material composition.</li><li>If we don\u2019t think that functional organizations play a critical role in assessing consciousness, we have little reason to think computers could be conscious.</li></ul><p>&nbsp;</p><p><strong>3. A complete functionalist theory of consciousness needs two distinct components: 1) a theory of what organizations are required for consciousness and 2) a theory of what it takes to implement an organization.</strong></p><ul><li>An organization is an abstract pattern \u2013 it can be treated as a set of relational claims between the states of a system\u2019s various parts.</li><li>Whether a system implements an organization depends on what parts it has, what properties belong to those parts, and how those properties depend on each other over time.</li><li>There are multiple ways of interpreting the parts and states of any given physical system. Even if we know what relational claims define an organization, we need to know how it is permissible to carve up a system to assess whether the system implements that organization.</li></ul><p>&nbsp;</p><p><strong>4. There are hypothetical systems that can be interpreted as implementing the organization of a human brain that are intuitively very unlikely to be conscious.</strong></p><ul><li>See examples in <a href=\"https://philpapers.org/archive/SHIICF.pdf#page=15\">section 4</a>.</li></ul><p>&nbsp;</p><p><strong>5. To be plausible, functionalism should be supplemented with additional constraints related to the integrity of the entities that can populate functional organizations.</strong></p><ul><li>Philosophers have discussed the need for such constraints and some possible candidates, but there has been little exploration of the details of those constraints or what they mean for hypothetical artificial systems.</li><li>There are many different possible constraints that would help invalidate the application of functional organizations to problematic systems in different ways.</li><li>The thread tying together different proposals is that functional implementation is constrained by the cohesiveness or integrity of a system\u2019s component parts that play the roles in the implementations of functional organizations.</li><li>Integrity constraints are independently plausible.</li></ul><p>&nbsp;</p><p><strong>6.) Several plausible constraints would prevent digital systems from being conscious even if they implemented the same functional organization as a human brain, supposing that they did so with current techniques.</strong></p><ul><li>See examples in <a href=\"https://philpapers.org/archive/SHIICF.pdf#page=26\">section 6</a>.</li><li>Since these are particularly central to the project, I summarize one below:</li></ul><blockquote><p>Continuity: do the parts that play the right roles in a functional organization exist over time and are they mostly composed of the same materials or are those parts different things at different times? Major components of a brain appear relatively stable. In contrast, computer memory is allocated as needed, such that the memory cells that underly different parts of a program change frequently. The memory cells storing the values of nodes in a network will likely change from invocation to invocation. This might make a difference to consciousness.</p></blockquote><p>For more on why continuity might seem important, consider this thought experiment:</p><blockquote><p>The brain transducer is a machine that takes as an input a human brain that has been frozen into a single state within a preservative medium and produces as an output a fully new human brain frozen in another brain state. This machine would disassemble the input brain and construct the output brain out of new atomic materials that reflected what state the input brain would have momentarily occupied were it not frozen. We might route the output brains back around to form the machine's inputs so that it produced a constant succession of new frozen brains reflecting the states that a human brain would naturally occupy as its internal dynamics evolved over time.</p></blockquote><p>I think we should take seriously the possibility that a series of brains produced by a transducer would not have a single unified conscious experience \u2014 or any experiences at all \u2014 even if functionalism is true. For similar reasons, we should be open to the possibility that computer systems utilizing dynamically assigned memory would not be capable of having unified conscious experiences even if functionalism is true.</p><p>&nbsp;</p><p><strong>7.) Implementation considerations offer new opportunities for approaching the welfare of digital systems.</strong></p><ul><li>Implementation worries introduce new sources of ambiguity which may lower our confidence about the consciousness and well-being of hypothetical systems.</li><li>We may be able to alter the implementation of digital systems to make them more or less plausibly conscious without changing the algorithms they use.</li><li>Implementational choices may be used to increase the probability of consciousness existing where we want it to be and reduce the probability of consciousness existing where we don\u2019t.</li></ul>", "user": {"username": "Derek Shiller"}}]