[{"_id": "Fm5GiRq3QpPP3d6pq", "postedAt": "2022-12-12T22:33:01.938Z", "postId": "WBWXLZTF5FPzmK8nh", "htmlBody": "<p>This is really, really cool. Thanks!</p>", "parentCommentId": null, "user": {"username": "BenStewart"}}, {"_id": "cZXEtBkAbfHmtDa2f", "postedAt": "2022-12-12T23:35:55.483Z", "postId": "WBWXLZTF5FPzmK8nh", "htmlBody": "<p>Thanks for this report! I 100% agree with Ben Stewart this is really really cool. However, <i>minor gripe:</i> I do wish this had been edited for clarity of language. Even by EA Forum standards this the prose here is about as twisty as a pissed off octopus' tentacles.&nbsp;</p>", "parentCommentId": null, "user": {"username": "LKor"}}, {"_id": "C4HxZaeozthzRsgcf", "postedAt": "2022-12-13T04:40:12.232Z", "postId": "WBWXLZTF5FPzmK8nh", "htmlBody": "<blockquote><p>Indeed, we have evidence that withdrawal behavior is frequently unconscious. Noxious stimulation can cause humans in vegetative states to yell, withdraw or display \u2018pained\u2019 facial expressions (Laureys 2007).</p></blockquote><p>While I think the point is correct that pain reflexes can occur unconsciously, I would be wary of using humans in a vegetative state as a clean example of unconsciousness. A significant minority of patients in a diagnosed vegetative state without behavioural responses are nevertheless able to follow auditory commands. The classic paradigm uses instructions to 'imagine playing tennis' or 'imagine walking around your home' and detect the resulting distinctive fMRI or EEG signatures - where some patients can use their choice of imagined activity to communicate and answer binary questions!</p>", "parentCommentId": null, "user": {"username": "BenStewart"}}, {"_id": "zKqJPNL4ThCge8fHq", "postedAt": "2022-12-13T11:38:52.305Z", "postId": "WBWXLZTF5FPzmK8nh", "htmlBody": "<p>Thanks for this observation, Ben. I agree that this isn't the cleanest example. Maybe the best examples are in animals--e.g., <a href=\"https://psychclassics.yorku.ca/James/Principles/prin2.htm\">headless frogs</a> whose legs still try to remove acid from their skin. But I'm sure Joe has his own thoughts about this.</p>", "parentCommentId": "C4HxZaeozthzRsgcf", "user": {"username": "bob-fischer"}}, {"_id": "NAoLLZCLtz324uaEA", "postedAt": "2022-12-13T13:56:39.963Z", "postId": "WBWXLZTF5FPzmK8nh", "htmlBody": "<p>Hi Ben - Thanks for this. I agree that the PVS case is tricky, and probably not the best example. I assume that you are claiming that PVS patients are still phenomenally conscious, and that you are pointing to <a href=\"https://www.science.org/doi/10.1126/science.1130197\">this</a> study. (Note though that the authors never use \"phenomenally conscious\".) However, as expected, the Owen et al study is controversial. I find &nbsp;<a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3361721/\">this</a> paper helpful when it comes to understanding some of the underlying methodological issues. One issue is whether these patients actually have intentional agency--perhaps suggested by their task responses--as this is often used as the diagnostic criterion for inferring that these subjects are (minimally?) conscious. It's unclear whether they have such agency (see <a href=\"https://www.journals.uchicago.edu/doi/full/10.1093/bjps/axv012\">here</a>), although this would not itself eliminate consciousness. So, fair point!&nbsp;</p>", "parentCommentId": "C4HxZaeozthzRsgcf", "user": {"username": "Joe Gottlieb"}}, {"_id": "rcp7qD7pTsuJcyRjT", "postedAt": "2022-12-13T14:39:23.772Z", "postId": "WBWXLZTF5FPzmK8nh", "htmlBody": "<p>Oh, also: &nbsp;</p><ul><li>I was confused by references to amputation until I understood that amputated tentacles can act autonomously for some amount of time. A brief, direct description of this would be useful.</li><li>Your 0.025 and 0.035 are extremely specific; it would be interesting to get a brief description of how you ended up with those numbers without having to delve into the full report.</li></ul>", "parentCommentId": "cZXEtBkAbfHmtDa2f", "user": {"username": "LKor"}}, {"_id": "JTDzStejWyPttmsCB", "postedAt": "2022-12-13T17:37:33.094Z", "postId": "WBWXLZTF5FPzmK8nh", "htmlBody": "<p>Usually, people end up with such specific numbers by starting with several round numbers and multiplying. We didn't do that in this case, though we could. Instead, I asked Joe to use a heuristic that I sometimes find helpful. Imagine being presented with the same information ten times. How many times do you think you'd come to a different conclusion if you were reasoning about it in good faith? In other words, try to run many simulations of your own sincere deliberations to assess how much variation there might be in the results. If none, then imagine going to 100 simulations. If still none, imagine going to 1000. Etc. And when Joe did that, those are the numbers that struck him as plausible.</p>", "parentCommentId": "rcp7qD7pTsuJcyRjT", "user": {"username": "bob-fischer"}}, {"_id": "T2WwH8bJRGx5tcdWW", "postedAt": "2022-12-13T18:08:24.366Z", "postId": "WBWXLZTF5FPzmK8nh", "htmlBody": "<p>Thanks for writing this up! It was helpful to give a concrete example to bolster the argument you made in the <a href=\"https://forum.effectivealtruism.org/s/y5n47MfgrKvTLE3pw/p/vbhoFsyQmrntru6Kw\">last post</a>.</p><p>I'm curious if anybody has considered <strong>temporality</strong> as an element of this question? Some (maybe) relevant questions:</p><ul><li>Does my current brain constitute the \"same\" conscious system as I did when I was 2 years old?</li><li>&nbsp;What about somebody who undergoes a traumatic brain injury and becomes a \"new person\" with regard to personality/memory/learned behaviors?</li><li>If congruity/consistency between one's self(ves) at different life-stages is related to memory, might non-human animals actually have far more conscious (sub)systems over their lifetimes than humans?</li><li>What does this imply about death? If some factory-farmed animals have lives that are worse than worth living, do we have even more evidence that they would be better off dying sooner (before they develop more conscious systems/subsystems)?</li><li>If these ideas have any amount of credence, how might we possibly quantify this?</li></ul><p>I have little background in philosophy of mind, and there's a good chance your team has already considered/debunked these ideas, but I wanted to throw them out there as food for thought anyway.</p>", "parentCommentId": null, "user": {"username": "Jasper Meyer"}}, {"_id": "Fxx8yFiS7M4jnxGTa", "postedAt": "2022-12-13T19:14:43.050Z", "postId": "WBWXLZTF5FPzmK8nh", "htmlBody": "<p>Oh, that's interesting. Did you folks come up with that methodology?&nbsp;</p>", "parentCommentId": "JTDzStejWyPttmsCB", "user": {"username": "LKor"}}, {"_id": "pEnNqpk9Fc785sagJ", "postedAt": "2022-12-13T19:53:58.390Z", "postId": "WBWXLZTF5FPzmK8nh", "htmlBody": "<p>We did. I don\u2019t know how helpful it is for others, but I find it useful.</p>\n", "parentCommentId": "Fxx8yFiS7M4jnxGTa", "user": null}, {"_id": "bLf2XYcLyNvH7HSwa", "postedAt": "2022-12-13T20:26:35.738Z", "postId": "WBWXLZTF5FPzmK8nh", "htmlBody": "<p>I agree - it's very unclear what the level of intention, awareness, or phenomenal consciousness is in these cases. The 2006 study is definitely the foundational one, but there's a decent amount of subsequent literature (though without much further clarity). I thought of this point because I'm currently reading Anil Seth's 2021 book on the neuroscience of consciousness, \"Being You\", which covers the topic quite well. (I'd highly recommend it to other interested readers!)<br>But this was a very minor nitpick on a fascinating report - well done!</p>", "parentCommentId": "NAoLLZCLtz324uaEA", "user": {"username": "BenStewart"}}, {"_id": "hjdCAgpEj2kcjcXyS", "postedAt": "2022-12-13T21:11:57.184Z", "postId": "WBWXLZTF5FPzmK8nh", "htmlBody": "<p>Hi Jasper - Thanks for these interesting questions. So speaking for myself, I did not take up the temporality issue--at least not in the way you seem to be suggestion without these cases. I can say something about your brain injury question though. The term 'person' is used in different ways. Sometimes it is used to just mean whatever we are fundamentally. So, if a traumatic brain injury resulted in a numerically distinct person in this sense, then it would be the same thing as death and then \u2018birth\u2019 of a new person. In that case, if there was a welfare subject pre-trauma, then there will be a new welfare subject post-trauma, so long as whatever capacities necessary and sufficient for being a welfare subject are preserved.&nbsp;</p><p>On another usage, being a \u201cnew person\u201d is just metaphorical, as in what I might say to my daughter if she came home from college super interested in Goth stuff. (My daughter is not quite 5 yet, but who knows\u2026)</p><p>Finally, some use \u2018person\u2019 in a Lockean (after John Locke) forensic sense, where forensic persons are the kinds of things which can be held morally responsible for their actions, for which prudential concern is rational, etc. There are all sorts of tricky issues here, but one possibility is that *you* can survive even if you do not survive <i>as the same forensic person</i>. Perhaps something like that can happen in certain cases of brain trauma. For example, maybe whatever survives post-trauma is not morally responsible for any pre-trauma actions\u2014precisely because there are none of the same memories, personality, beliefs, and behavioral dispositions. I\u2019d have to think more on how this connection to questions about being/counting welfare subjects, though.</p><p>I think which of these different sense of \u2018person\u2019 is apt for saying someone is a \u2018new person\u2019 post trauma depends a whole lot on the actual details of the trauma in question.&nbsp;</p>", "parentCommentId": "T2WwH8bJRGx5tcdWW", "user": {"username": "Joe Gottlieb"}}, {"_id": "ZaGqjPuzEaSbe3dZQ", "postedAt": "2022-12-13T21:29:18.026Z", "postId": "WBWXLZTF5FPzmK8nh", "htmlBody": "<p>Thanks for the detailed reply to the trauma case. Your delineation between various definitions of personhood are helpful for interrogating my other questions as well.&nbsp;</p><p>If it is the case that a \"new\" welfare subject can be \"created\" by a traumatic brain injury, then it might well be the case that new welfare subjects are created as one's life progresses. This implies that, as we age, welfare subjects effectively die and new ones are reborn. However, we don't worry about this because 1. we can't prevent it and 2. it's not clear when this happens / if it ever happens fully (perhaps there is always a hint of one's old self in one's new self, so a \"new\" welfare subject is never truly created).</p><p>Given the same argument applies to non-human animals, we could reasonably assume that we can't prevent this loss and recreation of welfare subjects. Moreover, we would probably come to the same conclusions about the badness of the death of the animals, even if throughout their lives they exist as multiple welfare subjects that we should care about. Where it becomes morally questionable is in considering non-human animals whose lives are worse than not worth living. Then, there should be increased moral concern for factory farmed animals given we accept that: 1. their lives are worse than not worth living; 2. they instantiate different welfare subjects throughout there life and 3. there is something worse about 2 different subjects each suffering for 1 year than 1 subject suffering for 2 years. (Again I don't think I accept premise 2 or 3 of this conclusion, I just wanted to take the hypothetical to its fullest conclusion.)</p>", "parentCommentId": "hjdCAgpEj2kcjcXyS", "user": {"username": "Jasper Meyer"}}, {"_id": "3L6t4uLFZLbF3vYLc", "postedAt": "2022-12-14T00:58:38.156Z", "postId": "WBWXLZTF5FPzmK8nh", "htmlBody": "<p>Hi again. Regarding this comment:&nbsp;</p><p>\u201cIf it is the case that a \"new\" welfare subject can be \"created\" by a traumatic brain injury, then it might well be the case that new welfare subjects are created as one's life progresses. This implies that, as we age, welfare subjects effectively die and new ones are reborn.\u201d</p><p>I am not sure this follows. Even if we granted that traumatic brain injury could result in a new welfare subject\u2014which would depend on (i) what welfare subjects are, and (ii) what happens in in brain injury\u2014whether the same thing would happen during the aging process would depend on whether whatever relevant thing happens in the brain injury happens in aging. (For my part, I do not see why this would be the case. Maybe you are thinking of natural neurological changes that happens as we get older?) &nbsp;&nbsp;</p><p>And let me add this. The most neutral way of understanding welfare subjects, to my mind, is just what we say in the report: an individual S be a <i>welfare subject</i> if and only if things can be non-instrumentally good or bad for S. Assuming that our theory of welfare subjects is subordinate to our theory of well-being or welfare, then a welfare subject will just be the kind of thing that can accrue welfare goods and bads\u2014whatever those are.&nbsp;</p><p>Suppose now that <i>x</i> has a traumatic brain injury at <i>t1</i>. &nbsp;We can then ask:</p><ol><li>Is there<i> still</i> a welfare subject at <i>t</i>2?</li><li>Is <i>y&nbsp;</i>at <i>t2&nbsp;</i>(post trauma)<i>&nbsp;</i>the same welfare subject as <i>x&nbsp;</i>at <i>t</i>1?</li></ol><p>The answer to (1) depends on whether whatever is there at <i>t</i>2 can accrue welfare goods and bads. And that depends on what those goods and bads are. If, for example, we adopted a desire-satisfaction view, and the brain injury knocked out the ability to have desires, then tjere<i>&nbsp;</i>would no longer be a welfare subject at <i>t</i>2.</p><p>The answer to (2) depends not just on whether there is still a welfare subject at <i>t</i>2 [so a \u2018yes\u2019 answer to (1)], but also the kind of thing <i>x </i><u>fundamentally</u> is\u2014maybe a forensic person, maybe something else--which will determine its persistence conditions, and thus whether it can survive brain injury. (Compare: I am a resident of Texas, but this does have anything to do with what I am fundamentally, as I can survive if I move somewhere else. If I am a forensic person but only in the way I am a Texan, then I can survive not being a forensic person. And if being a welfare subject has nothing to do with being a forensic person, then I can survive as a welfare subject without surviving as a forensic person.) I would assume that if <i>x</i> at <i>t</i>1 = <i>y</i> at <i>t</i>2, then we have the very same welfare subject too, so long as being a welfare subject comes automatically with whatever it takes for us to persist over time. &nbsp;</p>", "parentCommentId": "ZaGqjPuzEaSbe3dZQ", "user": {"username": "Joe Gottlieb"}}, {"_id": "qsnvk7KdicWKhA9vh", "postedAt": "2022-12-14T17:02:41.499Z", "postId": "WBWXLZTF5FPzmK8nh", "htmlBody": "<p>Thanks for fleshing this out - that all makes sense to me.</p>\n", "parentCommentId": "3L6t4uLFZLbF3vYLc", "user": {"username": "Jasper Meyer"}}, {"_id": "XsDbCBG5iBk5izdJj", "postedAt": "2022-12-14T21:11:22.317Z", "postId": "WBWXLZTF5FPzmK8nh", "htmlBody": "<p>Bob - thanks for this fascinating post. (And for all your other cool work on animal ethics -- I'd encourage EA folks to check out your other papers on your website <a href=\"https://www.bobfischer.net/publications\">here</a>.)</p><p>Your post focused mostly on a sort of philosophy-of-neuroscience approach to these issues. I didn't see much discussion of the evolutionary/functional/adaptive reasons why an animal might evolve an integrated, unitary consciousness versus separate consciousnesses.</p><p>From my evolutionary psychology perspective, I interpret sentience (consciousness, subjective awareness) as an adaptation that arises &nbsp;mostly to coordinate learning and behavior at the level of the whole organism (the complete phenotype)-- e.g. where it goes, what it does, what it pays attention to, how it updates &amp; learns in response to positive and negative fitness affordances, etc.&nbsp;</p><p>From that functional perspective, it seems like your 'Default to One Subject Assumption' is pretty reasonable. &nbsp;</p><p>As Richard Dawkins has argued, although an animal's phenotype contains many different organs, tissue types, and subsystems, there are some final common pathway for survival and reproduction that typically require whole-body coordinated responses to environmental threats and opportunities. It seems reasonable that a 'central executive' should prioritize responses, make decisions, and plan behaviors -- rather than splitting up the body-coordination task into separate consciousnesses, which could easily give rise to conflicts, incompatible movements, and incoherent behavioral tactics.</p><p>I guess an interesting edge case might be whether eusocial insect colonies (ants, termites, &nbsp;bees, etc) might have a functionally unified sentience to coordinate whole-colony perception, decision-making, and behavioral responses (even if this colony-level sentience relies on spatially distributed computation among thousands of 'individual' organisms -- just as our sentience relies on spatially distributed computation among billions of neurons).</p><p>Anyway, I'm curious whether you think an evolutionary-functional analysis of animal consciousness could reinforce the case that the 'One Subject Assumption' is usually valid. &nbsp;(Or at least that it's a bit implausible that an octopus would evolve a sort of 1+8 structure to its sentience.)</p>", "parentCommentId": null, "user": {"username": "geoffreymiller"}}, {"_id": "vKr7Eatf9xddpEued", "postedAt": "2022-12-14T23:53:15.756Z", "postId": "WBWXLZTF5FPzmK8nh", "htmlBody": "<p>Hi Geoffrey -</p><p>I will let Bob speak for himself in case he has any thoughts on this, but speaking for what went into the report, it's true that we did not take much of an evolutionary psychology perspective, certainly not directly. I actually think it's a live possibility that consciousness is a spandrel--see <a href=\"https://www.cambridge.org/core/journals/journal-of-the-american-philosophical-association/article/abs/is-consciousness-a-spandrel/30243610CC398D3527500FFE5B8AADB9\">here</a> and <a href=\"https://www.sciencedirect.com/science/article/abs/pii/S0028393207003867\">here</a>--although nothing in the report hinged on this. (Note that consciousness having little to no utility is consistent with consciousness being causally efficacious in the production of behavior etc. So no epiphenomenalism here.)</p><p>With that said, one consideration that did come up related to your question is the idea that an organism has at most one <i>independent </i>cognitive system. (These are different from cognitive subsystems, of which an organism can have many.) The prevailing idea, as noted in <a href=\"https://www.tandfonline.com/doi/abs/10.1080/09515089.2019.1585797\">this</a> paper by Carls-Diamante--is that having more than one would be counter-productive in various ways due to, e.g., failures of complete information transfer across the systems. So <i>perhaps </i>this could be connected to your point: having more than one independent system per organism is maladaptive. But of course, Carls-Diamante goes on to suggest that the octopus may be an exception to what is otherwise a rule. As we argue though, even granting this, we are still away far from the core issue, which is whether the octopus houses more than one welfare subject.&nbsp;</p>", "parentCommentId": "XsDbCBG5iBk5izdJj", "user": {"username": "Joe Gottlieb"}}, {"_id": "TJ4NStN8zv6AdTbH8", "postedAt": "2022-12-15T00:03:51.466Z", "postId": "WBWXLZTF5FPzmK8nh", "htmlBody": "<p>Thanks so much for your comments, Geoffrey! Just to clarify, Joe really deserves all the credit for this great report; I only provided feedback on drafts. That aside, I'm very sympathetic to the functional perspective you outline, which I've borrowed in other (unpublished) work from Peter Godfrey-Smith. Seems exactly right to me.</p>", "parentCommentId": "vKr7Eatf9xddpEued", "user": {"username": "bob-fischer"}}, {"_id": "dumPB2n5XHRhAuSMK", "postedAt": "2022-12-15T03:44:15.455Z", "postId": "WBWXLZTF5FPzmK8nh", "htmlBody": "<p>Bob (and Joe) - thanks for the thoughtful replies. Will mull this over a bit more before writing a proper response.</p><p>Fun fact: I used to hang out with Peter Godfrey-Smith in grad school, and his philosophy of evolutionary biology/psychology influenced some of my thinking as well (and maybe vice-versa).</p>", "parentCommentId": "TJ4NStN8zv6AdTbH8", "user": {"username": "geoffreymiller"}}]