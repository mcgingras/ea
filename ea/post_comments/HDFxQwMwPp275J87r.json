[{"_id": "EANqY2HTus7ibf4tH", "postedAt": "2023-09-26T19:16:59.084Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<ul><li>Does the conclusion flip if you don't value 30 shrimps/shrimp moments the same as a human? &nbsp;</li><li>It might be more meaningful to present your results as a function, e.g., if you value shrimps and chicken at xyz, then the overall value is negative/positive&nbsp;</li><li>Particularly in uncertain domains, it might have been worth it to consider uncertainty explicitly, and RP does give confidence intervals.</li></ul>", "parentCommentId": null, "user": {"username": "NunoSempere"}}, {"_id": "L7pqLJTQKrnDcPrJa", "postedAt": "2023-09-26T20:17:18.166Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<p>In terms of digital sentience, I do think it is <i>somewhat</i> reassuring that we harm animals out of indifference, not malice. &nbsp;There's no particular general reason I can see to think that when we pursue our interests with indifference rather than hostility to the well-being of other sentients, that the side-effects of this for the other sentients will systematically and non-coincidentally harm rather than help them. Like, it could be that what suits our interests just happens to be to bunch of digital minds that have no feelings, or that mostly enjoy the tasks we give them, just as much as it could turn out that the best way to exploit them involves net suffering for the minds. Factory farming is basically a single case, so I don't think it should move us much towards \"actually exploiting other sentients for our own gain will have systematically negative, rather than basically random effects on their welfare\". After all, it's not even completely clear the <i>pre</i> factory farming was net negative for the animals involved.&nbsp;</p>", "parentCommentId": null, "user": {"username": "Dr. David Mathers"}}, {"_id": "AyitjjrrpARobLxvp", "postedAt": "2023-09-26T20:33:09.572Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<p>Hi Kyle,&nbsp;<br><br>This is a very interesting post! One quick and very small technical detail: Rethink Priorities' welfare ranges aren't capped at 1 for non-human animals. (It just happens that, when we adjusted for probability of sentience, they all happened to have 50th percentile estimates that fall below 1). They're instead a reflection of the difference between the best and worst states that the non-human animal can experience relative to the difference between the best and worst states that a human can experience (which is normalized to 1). In theory, this relative difference could be greater than 1 if the range in intensity of experiences that a non-human animal can experience is wider than that of humans.&nbsp;<br><br>In fact, one of our welfare range models (the undiluted experiences mode) that feeds into the aggregate estimates tends to produce sentience-adjusted welfare range estimates greater than 1 under the theory that less cognitively complex organisms may not be able to dampen negative experiences by contextualizing them. As such, a few animals have 95th percentile estimates for their welfare ranges that are above 1 (octopuses, pigs, and shrimp). Here are some more details about the models and distributions: <a href=\"https://docs.google.com/document/d/1xUvMKRkEOJQcc6V7VJqcLLGAJ2SsdZno0jTIUb61D8k/edit?usp=sharing\">https://docs.google.com/document/d/1xUvMKRkEOJQcc6V7VJqcLLGAJ2SsdZno0jTIUb61D8k/edit?usp=sharing</a> As well as the spreadsheet of results from all models: <a href=\"https://docs.google.com/spreadsheets/d/1SpbrcfmBoC50PTxlizF5HzBIq4p-17m3JduYXZCH2Og/edit?usp=sharing\">https://docs.google.com/spreadsheets/d/1SpbrcfmBoC50PTxlizF5HzBIq4p-17m3JduYXZCH2Og/edit?usp=sharing</a>&nbsp;<br><br>Again, this is a really thought-provoking and sobering post, thanks for writing it :)</p>", "parentCommentId": null, "user": {"username": "Laura "}}, {"_id": "YSge2LnHiz7TN9kKJ", "postedAt": "2023-09-26T21:24:24.918Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<p>Thanks for putting this together! I'm skeptical of putting too much weight on the conclusions (just given how much uncertainty there is), but I think this is valuable addition to the conversation on this subject.&nbsp;</p><p>It's worth noting that MacAskill touched on this topic in chapter 9 of WWOTF, using neuron counts as a proxy for moral weight. He comes to a very different conclusion, which makes sense given that neuron count-based moral weights for basically all animals are much lower than the RP moral weights:&nbsp;</p><blockquote><p>To capture the importance of differences in capacity for wellbeing, we could, as a very rough heuristic, weight animals\u2019 interests by the number of neurons they have. The motivating thought behind weighting by neurons is that, since we know that conscious experience of pain is the result of activity in certain neurons in the brain, then it should not matter more that the neurons are divided up among four hundred chickens rather than present in one human. If we do this, then a beetle with 50,000 neurons would have very little capacity for wellbeing; honeybees, with 960,000 neurons, would count a little more; chickens, with 200 million neurons, count a lot more; and humans, with over 80 billion neurons, count the most. This gives a very different picture than looking solely at numbers of animals: by neuron count, humans outweigh all farmed animals (including farmed fish) by a factor of thirty to one. This was very surprising to me; before looking into this, I hadn\u2019t appreciated just how great the difference in brain size is between human beings and nonhuman animals.</p><p>If, however, we allow neuron count as a rough proxy, we get the conclusion that the total weighted interests of farm land animals are fairly small compared to that of humans, though their wellbeing is decisively negative.</p><p>This does not yet resolve whether the welfare of humans and farmed animals combined is negative. Even though, in totality, farmed animals may have fewer neurons, the vast majority of farmed animals (chicken and fish) live lives full of intense suffering, which could well outweigh total human wellbeing. If the intensity of the suffering of chickens and fish is at least forty times the intensity of average human happiness, then the combined wellbeing of humans and farmed animals is negative.</p></blockquote><p>Are you willing to share your underlying source code? I might be interested in adding uncertainty to the analysis. &nbsp;</p>", "parentCommentId": null, "user": {"username": "MHR"}}, {"_id": "GHmiZzocxtqsCCaJC", "postedAt": "2023-09-26T21:35:47.918Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<p><strong>Executive summary</strong>: The total moral value of the world may be negative and declining, as growing animal agriculture could be causing more suffering than improvements in human welfare offset.</p><p><strong>Key points</strong>:</p><ol><li>The total moral value of the world includes both humans and non-human animals, with the rise of industrial animal agriculture significantly impacting the latter.</li><li>The author's analysis, focused on the period from 1961-2021, suggests net global welfare may be both negative and declining, due to the increased suffering of farmed animals outweighing human wellbeing.</li><li>The author notes several assumptions and limitations, including the exclusion of wild animals and insects, and the use of point estimates rather than confidence intervals.</li><li>The author used data from the Food and Agriculture Organization of the United Nations and human population data, along with estimates of welfare ranges across different species, to calculate the total welfare of a given species in a given year.</li><li>The analysis suggests that the suffering of farmed animals is so intense and their populations have grown so large that they may outweigh all of humanity\u2019s progress.</li><li>The author concludes that humanity may have inadvertently set systems in motion that put the total welfare of the world on a steep downward trajectory, and calls for more rigorous research on animal welfare and the development of interventions aimed at improving total welfare.</li></ol><p>&nbsp;</p><p><i>This comment was auto-generated by the EA Forum Team. Feel free to point out issues with this summary by replying to the comment, and</i><a href=\"https://forum.effectivealtruism.org/contact\"><i>&nbsp;<u>contact us</u></i></a><i> if you have feedback.</i></p>", "parentCommentId": null, "user": {"username": "SummaryBot"}}, {"_id": "wgm7Zew2JsTJmYPCb", "postedAt": "2023-09-26T22:59:53.575Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<p>Thank you for flagging this, Laura! I've edited the definition to correct the misstatement.</p>", "parentCommentId": "AyitjjrrpARobLxvp", "user": {"username": "kyle_fish"}}, {"_id": "SoTvPtyBcKGHydEp2", "postedAt": "2023-09-26T23:18:29.994Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<p>Thanks for the kind words! I'm also skeptical of putting too much weight on the conclusions given the huge uncertainties, which I hope comes across in the post.&nbsp;</p><p>Re: underlying code\u2014I'm working on a sharable version. Just sent you a DM!</p>", "parentCommentId": "YSge2LnHiz7TN9kKJ", "user": {"username": "kyle_fish"}}, {"_id": "F2eJP9L6c5pdHh9PP", "postedAt": "2023-09-26T23:30:07.802Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<ul><li>The sign of the conclusion would be the same (though significantly weaker) even if you ignore shrimp entirely, provided all other assumptions are held constant. That said, the final numbers are indeed quite sensitive to the moral weights, particularly those of chickens, shrimp, and fish as the most abundant nonhumans.</li><li>I agree re: the value of both a function-based version that would allow folks to put in their own weights/assumptions, and a version that explicitly considers uncertainty. I don't have plans to build these out myself, but might reconsider if there's sufficient interest, and in any case would be happy to support someone else in doing so.&nbsp;</li></ul>", "parentCommentId": "EANqY2HTus7ibf4tH", "user": {"username": "kyle_fish"}}, {"_id": "AJCG7C74ihyK668zG", "postedAt": "2023-09-27T02:54:49.264Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<blockquote><p>This work draws heavily on the Moral Weight Project from Rethink Priorities and relies on the same assumptions: utilitarianism, hedonism, valence symmetry, unitarianism, use of proxies for hedonic potential, and more. Although I think the Rethink Priorities welfare range estimates are currently the best tool available for interspecies welfare comparisons, I do not necessarily endorse these assumptions in full, nor do I think the Rethink Priorities welfare ranges are the \u201ccorrect\u201d weights\u2014only the best available.</p></blockquote><p>These are some pretty big assumptions. In particular, when they discussed the sensitivity to the hedonism assumption, ReThink argued that this simplifying assumption wasn't a big deal, because relaxing it would only make a 3x difference or so, and this was <a href=\"https://forum.effectivealtruism.org/posts/WfeWN2X4k8w8nTeaS/theories-of-welfare-and-welfare-range-estimates#Conclusion\">not relevant for cause prioritization</a>:</p><blockquote><p>We suggest that, compared to hedonism, an objective list theory might 3x our estimate of the differences between humans\u2019 and nonhumans\u2019 welfare ranges. But just to be cautious, let\u2019s suppose it\u2019s 10x. While not insignificant, that multiplier makes it far from clear that the choice of a theory of welfare is going to be practically relevant. To see this, recall that Open Philanthropy <a href=\"https://www.openphilanthropy.org/research/worldview-diversification/\">once estimated</a> that \"[if] you value chicken life-years equally to human life-years, this implies that corporate campaigns do about 10,000x as much good per dollar as top [global health] charities.\"</p></blockquote><p>But your human vs all-nonhuman lines are sufficiently close that a 3x, let alone a 10x, difference would reverse the bottom line conclusion. I think it does make a considerable difference that the argument they use for 'why we don't need to worry about this assumption' doesn't apply here, given that pure hedonism is basically the least-favourable theory of welfare to use here.</p><p>(As it happens I also think that their attempt to bound the importance of non-hedonic factors at 3x or 10x doesn't work, <a href=\"https://forum.effectivealtruism.org/posts/WfeWN2X4k8w8nTeaS/theories-of-welfare-and-welfare-range-estimates?commentId=ZFwEQLz3zjC7tZNgG\">because their thought experiments about Tim only consider relatively weak non-hedonic goods</a>).</p>", "parentCommentId": null, "user": {"username": "Larks"}}, {"_id": "j3nLCKLuhJWBLxaJq", "postedAt": "2023-09-27T05:43:22.658Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<p>Thanks this is great.</p>\n<p>I think it's worth the perhaps basic reflection that rethink priorities' animal welfare ranges are so close to humans, and the number of farmed animals so high that any global welfare estimates are going to look terrible using their data. This isn't a value judgement at all, just a perhaps-obvious observation.</p>\n<p>From my perspective, for accuracy the next thing to include should be uncertainty ranges in the graph. For example a graph like this would need that before it could be considered for any serious peer reviewed literature.</p>\n<p>Unfortunately even just using rethink's errors, ranges will be so large it will even make displaying them in a graph difficult.</p>\n<p>Another huge source of uncertainty like you mention is wild animal welfare, an even harder area where most EAs I think would estimate their welfare as net negative, whereas some (like me) would estimate it perhaps positive.</p>\n<p>As a side note I would love a non EA, non animal rights focused group to do some kind of counter - calculation on welfare ranges so I could see what different assumptions they might make, but that's probably unrealistic as why would a dispassionate group bother with that kind of difficult work? Maybe we ould just use neuron weights as a counter equivalent?</p>\n<p>Again this is a really interesting graph nice one.</p>\n", "parentCommentId": null, "user": {"username": "NickLaing"}}, {"_id": "YKmtfvDomnpQnWQrC", "postedAt": "2023-09-27T05:49:20.319Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<p>I agree, especially living here in Uganda, (anecdata incoming) where many people keep their chicken and goats inside at night, then release them for the day to wander around and the animals behave at least like they are pretty OK. Also in my home country of new Zealand, I find it hard to imagine that farmed sheep and beef cows don't have her positive lives, roaming free on big farms.</p>\n", "parentCommentId": "L7pqLJTQKrnDcPrJa", "user": {"username": "NickLaing"}}, {"_id": "cK2F7fKsSnsQfX8ua", "postedAt": "2023-09-27T08:58:37.331Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<p>While I agree that net global welfare may be negative and declining, in light of the reasoning and evidence presented here, I think you could and should have claimed something like this: \"net global welfare may be negative and declining, but it may also be positive and increasing, and really we have no idea which it is - any assessment of this type of is enormously speculative and uncertain\".</p><p>As I read the post, the two expressions that popped into my head were \"if it's worth doing, it's worth doing with made-up numbers\" and \"if you saw how the sausage is made ...\".</p><p>The problem here is that <i>all</i> of the numbers for 'animal welfare capacity' and 'welfare percentages' are essentially - and unfortunately - made up. You cite Rethink Priorities for the former, and Charity Entrepreneurship for the latter, and express some scepticism, but then more or less take them at face value. You don't explain how those people came up with numbers and whether they should be trusted. I don't think I am disparaging the good folk at either organisation - and I am certainly not trying to! - because you asked them about this, I think they would freely say \"look, we don't really know how to do this. We have intuitions about this, of course, but we're not sure if there's any good evidenced-based way to come up with these numbers\";* indeed, that is, in effect, <a href=\"https://forum.effectivealtruism.org/posts/rLiCjrAv9D8chCoG5/dimensions-of-pain-workshop-summary-and-updated-conclusions\">the conclusion Rethink Priorities stated in the write-up of their recent workshop</a> (see <a href=\"https://forum.effectivealtruism.org/posts/rLiCjrAv9D8chCoG5/?commentId=GLcmxWDjcHnZAahQj\">my comment</a> on that too). Hence, such numbers should not be taken with a mere pinch of salt, but with a bucketload.&nbsp;</p><p>You don't account for uncertainty here (you used point estimates), and I appreciate that is extra hassle, but I think the uncertainty here <i>is </i>the story. If you were to use upper and lower subjective bounds for e.g. \"how unhappy are chickens compared to how happy humans are?\", they would be <i>very </i>large. They must be very large because, as noted, we don't even know what factual, objective evidence we would use to narrow them down, so we have nothing to constrain the bounds of what's plausible. But given how large they would be, we'd end up with the conclusion that we really don't know whether global welfare is negative or positive.</p><p>&nbsp;</p><p>* People are often tempted to say that we could look at objective measures, like neuron counts, for interspecies comparison. But this merely kicks the can down the road. How do we know what the relationship is between neuron counts and levels of pleasure and pain? We don't. We have intuitions, yes, but what evidence could we point to to settle the question? I do not know.&nbsp;</p>", "parentCommentId": null, "user": {"username": "MichaelPlant"}}, {"_id": "C9TAyccrXzpurXmbi", "postedAt": "2023-09-27T09:17:49.436Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<p>This is a minor comment but you say</p><blockquote><p>There\u2019s&nbsp;<a href=\"https://www.cold-takes.com/has-life-gotten-better-the-post-industrial-era/\"><u>compelling</u></a>&nbsp;<a href=\"https://www.amazon.com/Enlightenment-Now-Science-Humanism-Progress/dp/0525427570?sa-no-redirect=1\"><u>evidence</u></a> that life has gotten better for humans recently</p></blockquote><p>I don't think that is compelling evidence. Neither Pinker nor Karnosfky look at averages of self-reported happiness or life satisfaction, which would be the most relevant and comparable evidence, given your assumptions. According to the so-called <a href=\"https://en.wikipedia.org/wiki/Easterlin_paradox\">Easterlin Paradox</a> average subjective wellbeing has not been going up over the past few decades and won't with further economic growth. There have been years of debates over this (I confess <a href=\"https://forum.effectivealtruism.org/posts/gCDsAj3K5gcZvGgbg/will-faster-economic-growth-make-us-happier-the-relevance-of\">I got sucked in, once</a>) but, either way, there is not a consensus among happiness researchers that there is compelling evidence life has gotten better (at least as far as happiness is concerned).&nbsp;</p>", "parentCommentId": "cK2F7fKsSnsQfX8ua", "user": {"username": "MichaelPlant"}}, {"_id": "cKjWmtdjioAWcWPzk", "postedAt": "2023-09-27T10:01:14.905Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<p>Perhaps a dark thought, and coming from someone not being well versed in these types of high-level analyses: Could this work possibly lend some support to antinatalist/misanthropic points of view? &nbsp;I should state for the record that I feel tremendous hesitation to these types of views.&nbsp;</p>", "parentCommentId": null, "user": {"username": "Ulrik Horn"}}, {"_id": "PcRRddPkaocivqiPj", "postedAt": "2023-09-27T10:49:05.362Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<p>I appreciate the care and detail here, but would guess that wild animals dwarf everything considered here and present a much more difficult + important question.</p><p>How bad are forests per unit of land vs corn/soy/wheat fields or cattle ranches that have been replacing them seems like a key question.&nbsp;</p>", "parentCommentId": null, "user": {"username": "Mjreard"}}, {"_id": "nwnJeGqTccoLNA6cJ", "postedAt": "2023-09-27T14:57:34.785Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<p>I strongly agree with your main point on uncertainty, and I'll defer to you on the (lack of) consensus among happiness researchers on the question of whether or not life is getting better for humans given their paradigm.</p><p>However, I think one can easily ground out the statement \"There\u2019s&nbsp;<a href=\"https://www.cold-takes.com/has-life-gotten-better-the-post-industrial-era/\"><u>compelling</u></a>&nbsp;<a href=\"https://www.amazon.com/Enlightenment-Now-Science-Humanism-Progress/dp/0525427570?sa-no-redirect=1\"><u>evidence</u></a> that life has gotten better for humans recently\" in <a href=\"https://forum.effectivealtruism.org/posts/zy6jGPeFKHaoxKEfT/the-capability-approach-to-human-welfare\">ways that do not involve subjective wellbeing</a> and if one does so then the statement is quite defensible.</p>", "parentCommentId": "C9TAyccrXzpurXmbi", "user": {"username": "ryancbriggs"}}, {"_id": "gSxXcSLx7ctf7mvtm", "postedAt": "2023-09-27T15:00:01.636Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<p>I think this is one of those posts where the question is ultimately more valuable than the answer. And to be clear that isn't a criticism and I upvoted the post. I appreciate posts that push people to think about important questions, even if our best guess answers are not currently very compelling.</p>", "parentCommentId": null, "user": {"username": "ryancbriggs"}}, {"_id": "wZ7faqGnNmEgeuj9J", "postedAt": "2023-09-27T15:29:38.808Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<p>Yup, I'd be inclined to agree it's easier to ground the idea life is getting better for humans on objective measures. The is author's comparison is made in terms of happiness though:</p><blockquote><p>This work draws heavily on the Moral Weight Project from Rethink Priorities and relies on the same assumptions: utilitarianism, hedonism, valence symmetry, unitarianism, use of proxies for hedonic potential, and more</p></blockquote><p>I'm actually not sure how I'd think about the animal side of things on the capabilities approach. Presumably, factory farming looks pretty bad on that, so there are increasingly many animals with low/negative capability lives, so unclear how this works out on a global level.</p>", "parentCommentId": "nwnJeGqTccoLNA6cJ", "user": {"username": "MichaelPlant"}}, {"_id": "3zC3WnKwAEwecBRbL", "postedAt": "2023-09-27T15:42:18.581Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<p>Fair. I struggle with how to incorporate animals into the capabilities approach, and while I appreciate Martha Nussbaum turning her attention here I was also wary of list-based approaches so it doesn't help me too much.</p>", "parentCommentId": "wZ7faqGnNmEgeuj9J", "user": {"username": "ryancbriggs"}}, {"_id": "eoMpWqqL7HHdFFhsh", "postedAt": "2023-09-27T20:22:09.043Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<p>This sort of work is very sensitive to your choices for moral weights, and while I do appreciate you showing your input weights clearly in a table I think it's worth emphasizing up front how unusual they are.  For example, I'd predict an overwhelming majority of humans would rather see an extra year of good life for one human than four chickens, twelve carp, or thirty three shrimp. And, eyeballing your calculations, if you used more conventional moral weights your bottom-line conclusion would be that net global welfare was positive and increasing.</p>\n", "parentCommentId": null, "user": {"username": "Jeff_Kaufman"}}, {"_id": "X6S7Cgo2mKKCpcRjN", "postedAt": "2023-09-28T02:17:11.358Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<p>Agreed! While I do think there's value in looking just at humans and farmed animals given the current state of available data and welfare analysis, a major hope of mine for this work is that it might inspire more comprehensive and more rigorous models that include wild animals.</p>", "parentCommentId": "PcRRddPkaocivqiPj", "user": {"username": "kyle_fish"}}, {"_id": "bkH8CXbjavCHeNg39", "postedAt": "2023-09-28T03:19:02.780Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<p>I'm skeptical of anchoring on people's initial intuitions about cross-species tradeoffs as a default for moral weights, as there are strong reasons to expect that those intuitions are inappropriately biased. The weights I use are far from perfect and are not robust enough to allow confident conclusions to be drawn, but I do think they're the best ones available for this kind of analysis by a decent margin.</p>", "parentCommentId": "eoMpWqqL7HHdFFhsh", "user": {"username": "kyle_fish"}}, {"_id": "rnYt5nJj5bnNNpjFS", "postedAt": "2023-09-28T03:33:16.269Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<p>There are a ton of judgement calls in coming up with moral weights. I'm worried about a dynamic where the people most interested in getting deep into these questions are people who already intuitively care pretty strongly about animals, and so the best weights available end up pretty biased</p>\n", "parentCommentId": "bkH8CXbjavCHeNg39", "user": {"username": "Jeff_Kaufman"}}, {"_id": "hnNrfD7Zywz2wkMz7", "postedAt": "2023-09-28T04:02:53.008Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<p>When doing rough analysis, there are virtues to having simple models simply laid out, so I commend this - but step 2 is looking at which analytic and other choices the simple model is most sensitive to, and laying that out, and &nbsp;I think this post suffers from not doing that.</p><p>In this case, there are plausible moral and analytic assumptions that lead to almost any conclusion you'd like. A few examples:&nbsp;</p><ul><li>Include declining total numbers of net-negative lives among wild animals.&nbsp;</li><li>Reject total utilitarianism for average utilitarianism across species.&nbsp;</li><li>Change your time scale to longer than 10m years, and humanity is plausibly the only way any species on earth survives.&nbsp;</li><li>Project species welfare on a per-species basis instead of an aggregate, and it may be improving, and this may be Simpson's paradox.&nbsp;</li><li>Change the baseline zero-level for species welfare, and the answer could reverse.</li></ul><p>And other than the first, none of these is even considered in you future directions - even though the assumptions being made are, it seems, far too strong given the types of uncertainties involved. So I applaud flagging that this is uncertain, but don't think it's actually useful to make any directional claim, not would further modeling do that much to change this.</p><p>Finally, I'm struggling to see how and where this is decision relevant for people or organizations - but that's an entirely different set of complaints about how to do analyses.</p>", "parentCommentId": null, "user": {"username": "Davidmanheim"}}, {"_id": "FsYjDSuik2AJwpfne", "postedAt": "2023-09-28T04:04:20.114Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<p>Agreed narrowly, but as I <a href=\"https://forum.effectivealtruism.org/posts/HDFxQwMwPp275J87r/net-global-welfare-may-be-negative-and-declining-1?commentId=hnNrfD7Zywz2wkMz7\">commented</a>, I think the sensitivities involved are to many, many more factors.</p>", "parentCommentId": "eoMpWqqL7HHdFFhsh", "user": {"username": "Davidmanheim"}}, {"_id": "wNbwbXexi5Ci9WJCR", "postedAt": "2023-09-28T04:12:58.560Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<p>\"Best available\" doesn't imply that you should use them to create a first order answer instead of, for example, inputting the extremes of a range of plausible values to see what changes. And even then, the analytic choices you make are both cruxes, and deeply debated.</p>", "parentCommentId": "bkH8CXbjavCHeNg39", "user": {"username": "Davidmanheim"}}, {"_id": "Zk4zveAi88MzAbyqe", "postedAt": "2023-09-28T08:10:20.103Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<p>I'd be very skeptical as well of the views of the majority of humans, since we tend to be extremely biased to favor our own species, for evolutionary, cultural and biological reasons. We also benefit directly from a society that treats humans correctly, and benefit directly from animal exploitation. Some studies indicate that we put a lower moral weight to cows when there's beef at lunch.</p><p>Plus, few people though about the topic seriously, and we are just pretty bad at imagining the happiness of other beings. We put the moral weight of a dog much higher than that of a pig (despite pigs being smarter than dogs), because we are closer to them.</p><p>There's also a strong social stigma against those that dare to suggest otherwise.</p><p>&nbsp;</p><p>Imagine that we were able to ask carps how much they'd weigh their own lives compared to that of humans. It would be pretty unlikely that they'd say \"well, I disagree with your 12 to 1 human/carp ratio, I rather think that it's worth sacrificing a hundred of us for one human life, definitely\".</p>", "parentCommentId": "eoMpWqqL7HHdFFhsh", "user": {"username": "Corentin Fressoz"}}, {"_id": "ddXgoqwZEoZzCRy2v", "postedAt": "2023-09-28T08:19:15.399Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<p>Neuron count doesn't seem to be that good to indicate the sentience of other beings.</p><p>See the post <a href=\"https://forum.effectivealtruism.org/posts/Mfq7KxQRvkeLnJvoB/why-neuron-counts-shouldn-t-be-used-as-proxies-for-moral \">Why Neuron Counts Shouldn't Be Used as Proxies for Moral Weight</a></p>", "parentCommentId": "YSge2LnHiz7TN9kKJ", "user": {"username": "Corentin Fressoz"}}, {"_id": "n5pYCBof4zmDvkS6N", "postedAt": "2023-09-28T08:25:51.625Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<p>This is a good question. I'd instinctively be wary of misanthropic views, and I don't like asking myself these kind of questions, but I'm not sure my instinct is enough to make a good decision here.</p><p>Another way to pose the question could be : Should we strive to preserve the lives of those that (although inadvertantly, and probably not out of bad intentions) cause terrible harms ?</p>", "parentCommentId": "cKjWmtdjioAWcWPzk", "user": {"username": "Corentin Fressoz"}}, {"_id": "vpWfacrbBmQRhrEcj", "postedAt": "2023-09-28T08:36:22.274Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<p>Good point on the intentions, I think that matters. Moreover, and perhaps naively I also think in terms of option value. If we were to hypothetically lose human-level intelligence, it might never be recovered. But if we give ourselves a few more decades (hopefully!) perhaps we can do better and become an assuredly, massively net positive welfare portion of the universe.</p>", "parentCommentId": "n5pYCBof4zmDvkS6N", "user": {"username": "Ulrik Horn"}}, {"_id": "rtg7wLjoLs5cdHvs5", "postedAt": "2023-09-28T08:41:29.603Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<p>Thanks for the post !&nbsp;</p><p>This is a question I have asked myself for a long time, and that I don't like asking myself, but that I find incredibly important. <strong>I'm less motivated to work on x-risks if in practice it means \"</strong><i><strong>supporting to continuation of factory farming for a long, long time</strong></i><strong>\"</strong>.</p><p>I also think that including this possibility into other cause areas might be very important. This advice especially seems very crucial : modeling the animal welfare impacts of human health and global development interventions.</p><p>I'll note that while there are indeed massive uncertainties, <strong>I really have trouble seeing how the combined happiness of humanity might outweight the terrible suffering of farmed animals</strong>, since they are far more numerous and have far worse living conditions(although wild animal suffering might change everything). Especially since there are &gt; 4x as many farmed chickens as humans, and &gt; 10x more farmed fish and shrimp, with terrible living conditions.</p><p>Instinctively, of course, I think of humans as having more worth, and I like the idea of saving lives. But in practice, I don't find good arguments to justify that humans have a much higher moral weight than other animals.</p>", "parentCommentId": null, "user": {"username": "Corentin Fressoz"}}, {"_id": "dj8FCha6AfHfgu4yq", "postedAt": "2023-09-28T08:57:26.650Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<p>Well, hopefully, but given the current trends, I'd be very wary of that - it could very well be that factory farming continues forever and expands to other planets.</p><p>See these articles : <a href=\"https://www.forbes.com/sites/briankateman/2022/09/06/optimistic-longtermism-is-terrible-for-animals/?sh=328a115d2059\">Optimistic longtermist is terrible for animals</a>, <a href=\"https://www.forbes.com/sites/briankateman/2022/12/07/if-we-dont-end-factory-farming-soon-it-might-be-here-forever/?sh=63fa11527e3e\">Why factory farming might be there forever</a>, and this one explains <a href=\"https://forum.effectivealtruism.org/posts/bfdc3MpsYEfDdvgtP/why-the-expected-numbers-of-farmed-animals-in-the-far-future\">why cellular meat might not replace everything</a>.</p>", "parentCommentId": "vpWfacrbBmQRhrEcj", "user": {"username": "Corentin Fressoz"}}, {"_id": "cFdigpxKDbqfvbJtz", "postedAt": "2023-09-28T09:42:50.837Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<p><strong>There are two factors mixed up here:</strong> <a href=\"https://forum.effectivealtruism.org/users/kyle_fish?mention=user\">@kyle_fish</a> writes about an (objective) <i><strong>amount </strong></i><strong>of animal welfare</strong>. The concept <a href=\"https://forum.effectivealtruism.org/users/jeff_kaufman?mention=user\">@Jeff Kaufman</a> refers to instead includes the <i><strong>weight</strong></i><strong> </strong><i><strong>we humans put </strong></i><strong>on that animals' welfare. For a meaningful conversation about the topic, we should not mix these two up.*</strong><br><br>Let's briefly assume a || world with humans2: just like us, but they simply never cared about animals at all (weight = 0). Concluding: \"We thus have no welfare problem\" is the logical conclusion for humans2 indeed, but it would not suffice to inform a genetically mutated human2x who happened to have developed care about animal welfare - or who simply happened to be curious about absolute welfare in his universe.</p><p>In the same vein: There's no strict need to account for usual human's <i>care</i> when analyzing whether, \"Net global welfare may be negative\" (title!). On the contrary, it would lead to an unnecessary bias, that just comes on top of the analysis' necessarily huge uncertainty (that the author does not fail to emphasize, although as others comment, it could deserve even stronger emphasis).</p>", "parentCommentId": "eoMpWqqL7HHdFFhsh", "user": {"username": "FlorianH"}}, {"_id": "JxdShxwFp8y8ajQbp", "postedAt": "2023-09-28T10:54:45.940Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<blockquote><p>There are a ton of judgement calls in coming up with moral weights.I'm worried about a dynamic where the people most interested in getting deep into these questions are people who already intuitively care pretty strongly about animals, and so the best weights available end up pretty biased</p></blockquote><p>I agree there's such a problem. But I think it is important to also point out that there is the same problem for people who tend to think they \"do not make judgement calls about moral weights\", but have nonetheless effectively came up with their own judgement calls when they live their daily lives which \"by the way\" affect animals (eat animals, live in buildings that require constructions that kill millions of animals, gardening, which harms and give rise to many animals, etc).</p><p>Also, I think it is equally, maybe more, important to recognize those people who make such judgement calls without explicitly thinking about moral weights, let alone go into tedious research projects, are people who intuitively care pretty little about animals, and so their \"effective intuition about moral weights\" (intuitive because they didn't want to use research to back it up) backing up their actions end up pretty biased.</p><p>I think I intuitively worry about the bias of those who do not particularly feel strongly about animals' suffering (even those caused by them), than the bias of those who care pretty strongly about animals. And of course, disclaimer: I think I lie within the latter group.</p>", "parentCommentId": "rnYt5nJj5bnNNpjFS", "user": {"username": "tseyipfai@gmail.com"}}, {"_id": "kRXAjPJ9NC7AhrNuj", "postedAt": "2023-09-28T13:52:34.433Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<p>Sure! I'd love to see a group of people who don't start out caring about animals much more than average try to tackle this research problem. And then maybe an adversarial collaboration?</p>\n<p>I just wrote up more on this here: <a href=\"https://forum.effectivealtruism.org/posts/H6hxTrgFpb3mzMPfz/weighing-animal-worth\">Weighing Animal Worth</a>.</p>\n", "parentCommentId": "JxdShxwFp8y8ajQbp", "user": {"username": "Jeff_Kaufman"}}, {"_id": "fe24F7BXGgxhCPnJN", "postedAt": "2023-09-28T16:58:02.413Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<p>Ah, interesting! I like both the terminology and and idea of \"adversarial collaboration\". For instance, I think incorporating debates into this research might actually move us closer to the truth.</p><p>But I am also wary that if we use a classical way of deciding who wins debate, the losing side would aljmost always be the group who assigned higher (even just slightly higher than average) \"moral weights\" to animals (not relative to humans, but relative to the debate opponent). So I think maybe if we use debate as a way to push closer to the truth, we probably use the classical ways of deciding debates.</p>", "parentCommentId": "kRXAjPJ9NC7AhrNuj", "user": {"username": "tseyipfai@gmail.com"}}, {"_id": "akGHa3sK785HZYHQq", "postedAt": "2023-09-28T17:09:13.291Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<blockquote>\n<p>if we use a classical way of deciding who wins debate</p>\n</blockquote>\n<p>Can you say more about what you mean by that?</p>\n", "parentCommentId": "fe24F7BXGgxhCPnJN", "user": {"username": "Jeff_Kaufman"}}, {"_id": "YH2DPcLKyzptjJKh3", "postedAt": "2023-09-28T17:19:51.251Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<blockquote><p>Finally, I'm struggling to see how and where this is decision relevant for people or organizations - but that's an entirely different set of complaints about how to do analyses.</p></blockquote><p>One way in which it's decision relevant for people considering how much to prioritize extinction risk mitigation. Arguments for extinction risk mitigation being overwhelmingly important often rely on the assumption that the expected value of the future is positive (and astronomically large). A seemingly sensible way to get evidence on whether the future is likely to be good is to look at whether the present is good and whether the trend is positive. I think this is why multiple people have tried to look into those questions (see Holden Karnovsky's blog, which is linked already in the main post, and Chapter 9 of What We Owe the Future).&nbsp;</p><p>In fact, in WWOTF, Macaskill does almost the same exercise as the one in this post, except he uses neuron counts as measures of moral weight instead of rethink priorities' weights. My memory is that he comes to the conclusion that the welfare of animals hardly makes an impact on total welfare. I think this post makes a very nice contribution in showing that Macaskill's conclusion isn't robust to using alternative (and plausible) moral weights.<br>&nbsp;</p><p>Note: there could be plenty of other arguments for X-risk being overwhelmingly important that don't rely on the claim that the expected value of the future is positive.</p>", "parentCommentId": "hnNrfD7Zywz2wkMz7", "user": {"username": "sbehmer"}}, {"_id": "4xXSET3CybhTBoDd9", "postedAt": "2023-09-28T17:48:23.538Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<p>I think the question \"would you rather see additional one human life-year or 3 chicken life-years\" conflates the hedonic comparison with special obligations to help human beings. One might prefer human experiences vs non-human experiences even when they are hedonically equivalent because of special obligations. If we're exclusively interested in welfare I think a better thought experiment would be how would you feel about having these experiences yourself.&nbsp;</p><p>If God offered you an opportunity to have an extra year of average human life, and on top of that, 1 year of average layer hen life, 1 year of average broiler chicken life, 10 years of average farmed fish life, and 100 years of farmed shrimp life, would you accept that offer? Of course that experiment is too artificial, but people go through extreme illnesses that cause them have mental capacities similar to a chicken. I sometimes think about how afraid I would be about being reincarnated after my death, going through some mental changes to get my mental capacities equivalent to that of a chicken, and going through all the average chicken experiences. I personally wouldn't take that risk in exchange of one additional year of human life.</p>", "parentCommentId": "eoMpWqqL7HHdFFhsh", "user": {"username": "emre kaplan"}}, {"_id": "gweartm7y9GCjCBhs", "postedAt": "2023-09-28T17:56:57.376Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<p>I don't think that thought experiment works for me: what would it even mean for a human to experience a year of chicken life?</p>\n", "parentCommentId": "4xXSET3CybhTBoDd9", "user": {"username": "Jeff_Kaufman"}}, {"_id": "X8ikawHFdeHkpfnBE", "postedAt": "2023-09-28T18:19:35.138Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<p>Yeah I agree that it is not the most natural and straightforward thought-experiment. Unfortunately hedonic comparisons make most sense to me when I can ask \"would I prefer experience A or B\" and asking this question is much more difficult when you try to compare experiences for the animals.</p>\n<p>But at least it should be physically imaginable to get me lobotomised to have mental capacities equivalent to that of a chicken. I'm much less likely to care about what happens to future me if my mental capacities were altered to be similar to that of an ant. But if my brain was altered to be similar to a chicken brain, I'm much more afraid of getting boiled alive, being crammed in a cage etc.</p>\n", "parentCommentId": "gweartm7y9GCjCBhs", "user": {"username": "emre kaplan"}}, {"_id": "SmoaJEGxXAjkr9hQL", "postedAt": "2023-09-28T18:42:25.498Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<p>I'm concerned about that dynamic too and think it's important to keep in mind, especially in the general case of researchers' intuitions tending to bias their work, even when attempting objectivity. However, I'm also concerned about the dismissal of results like RP's welfare ranges on the basis of speculation about the researchers' priors and/or the counterintuitive conclusions, rather than on the merits of the analyses themselves.</p>", "parentCommentId": "rnYt5nJj5bnNNpjFS", "user": {"username": "kyle_fish"}}, {"_id": "7jCHstHGuEDG7gQMd", "postedAt": "2023-09-29T02:13:15.446Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<p>I think the judgement calls used in coming up with moral weights have less to do with caring about animals and more to do with how much you think attributes like intelligence and self-awareness have to do with sentience. They're applied to animals, but I think they're really more neuroscience/philosophy intuitions. The people who have the strongest/most out-of-the-ordinary intuitions are MIRI folk, not animal lovers.</p>", "parentCommentId": "rnYt5nJj5bnNNpjFS", "user": {"username": "RedStateBlueState"}}, {"_id": "nGzRn3rHf2phgp3eg", "postedAt": "2023-09-29T17:17:34.555Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<p>On your future directions / tentative reflections (with apologies that I haven't looked into your model, which is probably cool and valuable!):</p>\n<p>To the extent that we think this is relevant for things like lock-in and x-risk prioritisation we need to also think that current trends are predictive of future trends. But it's not at all clear that they are once you take into account the possibility of explosive growth a la <a href=\"https://www.cold-takes.com/all-possible-views-about-humanitys-future-are-wild/\">https://www.cold-takes.com/all-possible-views-about-humanitys-future-are-wild/</a>. Moreover, worlds where there is explosive growth have way more moral patients, so if their probability is non-negligible they tend to dominate moral considerations.</p>\n<p>Once we focus on explosive growth scenarios as the most important, I find much more persuasive considerations like these: <a href=\"https://www.effectivealtruism.org/articles/the-expected-value-of-extinction-risk-reduction-is-positive\">https://www.effectivealtruism.org/articles/the-expected-value-of-extinction-risk-reduction-is-positive</a></p>\n<p>I've written up decently extended reflections on why we shouldn't give much weight to the fact that the history and presency of our world is an utter moral hellscape that I'm happy to share privately if these questions are important for you.</p>\n<p>(All that said, I do think lock-in is undervalued in longtermism and I'm excited to see more work on that, and I do think the path to x-risk prioritisation is much more complicated than many EAs think and that these kinds of considerations you point out are exactly why.)</p>\n", "parentCommentId": null, "user": {"username": "tylermjohn"}}, {"_id": "JAxR8j4NyDK3rMH3v", "postedAt": "2023-10-04T04:41:11.144Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<p>What if you weight them by <a href=\"https://en.wikipedia.org/wiki/List_of_animals_by_number_of_neurons#List_of_animal_species_by_forebrain_(cerebrum_or_pallium)_neuron_number\">number of neurons</a>? (Though we don't actually know whether capacity to generate qualia scales with neuron count; it could be that it's easy to do, and we suffer no more than chickens or even ants, for example.)&nbsp;</p>", "parentCommentId": "bkH8CXbjavCHeNg39", "user": {"username": "kuira"}}, {"_id": "9Rafobd5uMspwQFPc", "postedAt": "2023-10-06T22:18:51.958Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<p>I was scared when seeing the title. Then I read a little bit more:</p>\n<blockquote>\n<p>That is, the entire good of humanity may be outweighed by the cumulative suffering of farmed animals, with total animal suffering growing faster than human wellbeing is increasing, especially in recent decades</p>\n</blockquote>\n<p>I already thought that was the case. It's really sad, but at least it's not another massive source of suffering to add to my list. Thank you for substantiating this with a calculation!</p>\n", "parentCommentId": null, "user": {"username": "rhaps0dy"}}, {"_id": "JopiHboJtLPRsoJcW", "postedAt": "2023-10-30T14:06:52.919Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<p>I\u2019m skeptical of Charity Entrepreneurship\u2019s estimates. Really, cattle have negative utility?</p>\n<p>Cattle avoid being factory farmed. So I\u2019d bet the average cow would much rather be born than not.</p>\n<p>Really, are shrimp so picky about their environment that they feel negative, how they are farmed? I\u2019d think any place where they are alive and fed may yield positive utility to a shrimp.</p>\n<p>So I am distrustful of their ratings. Kudos to your analysis, though, I think that\u2019s the right approach, assuming good data being fed into it</p>\n", "parentCommentId": null, "user": {"username": "Maxim"}}, {"_id": "qmio55k7BhQpC3zEB", "postedAt": "2023-10-30T15:50:35.383Z", "postId": "HDFxQwMwPp275J87r", "htmlBody": "<p>CE's cattle estimates are for factory farmed cattle (the \"FF\" means factory farmed), not for non-factory farmed cattle. So, I agree that they probably shouldn\u2019t be used here as representative for cattle in general. That being said, I don\u2019t think it matters much, because their population is small relative to other farmed animals included.</p>\n<p>(FWIW, the shrimp welfare estimates are by the author and don't come directly from CE, from my understanding.)</p>\n<p>I'm not sure about shrimp welfare, but food is not the only challenge they can face. Poor enough water quality can kill them, and I'd guess water quality can be suboptimal and stressful without killing them. Without proper management, high stocking densities can throw off water quality, e.g. low dissolved oxygen, ammonia buildup, suboptimal pH. The weather can also affect water quality, including temperature, as shrimp farming is mostly done outdoors, and fast changes to conditions even within safe ranges can be stressful. That being said, I don\u2019t know how good or bad water quality actually is on shrimp farms. I think there's financial incentive to manage it well, because of increased mortality and poorer growth rates with poorer water quality. On high density farms, they'd probably all die without some management, like aeration for dissolved oxygen, although the oxygen levels could still be suboptimal for welfare. When I did look into it a few years ago, it seemed pretty good on samples of high density farms I saw (mostly for Vietnam and Thailand), but I'm not sure how representative the samples were, as I've heard it's worse. It can be managed less well on lower density (extensive, semi-intensive) farms.</p>\n<p>Maybe they also feel stressed being crowded at very high stocking densities (independently of effects on water quality and food availability), but I don't know if that's something that bothers them. The female breeding stock often have eyes removed (eyestalk ablation). There can be white spot disease breakouts. Their deaths could often be pretty painful, too, being potentially crushed by ice or other shrimp.</p>\n", "parentCommentId": "JopiHboJtLPRsoJcW", "user": {"username": "MichaelStJules"}}]