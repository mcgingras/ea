[{"_id": "ZH6fZ3XhppoNc9ANs", "postedAt": "2017-04-20T17:33:38.937Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>This is excellent. How might you evaluate fund managers? Do new fund managers have to have an existing relationship with anyone on the team?</p>\n", "parentCommentId": null, "user": {"username": "nonzerosum"}}, {"_id": "gs3TyLubqX2keHtZF", "postedAt": "2017-04-20T19:39:22.552Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>Do you have any thoughts as to what the next funds added might be? Does the manager come first, or will you announce things you'd like to have funds in, where you don't yet have a manager?</p>\n", "parentCommentId": null, "user": {"username": "nonzerosum"}}, {"_id": "JNWq3MwrWJ4nXEEZN", "postedAt": "2017-04-20T19:39:36.530Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>What is the internal process for adding a new fund or manager? What happens after the form is submitted - is it a casual discussion amongst the team, or something else?</p>\n", "parentCommentId": null, "user": {"username": "nonzerosum"}}, {"_id": "TFF4SBCybmrCaaTSe", "postedAt": "2017-04-20T19:40:21.350Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>What does an ideal fund manager look like?</p>\n<p>(Many questions because I'm really excited and think this is fantastic, and am really glad you're doing it)</p>\n", "parentCommentId": null, "user": {"username": "nonzerosum"}}, {"_id": "smtM5kdXxWTatbKMY", "postedAt": "2017-04-20T20:24:17.602Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>I'm pleased to see the update on GWWC recommendations; it was perturbing to have such different messages being communicated in different channels.</p>\n<p>However I'm really disappointed to hear the Giving What We Can trust will disappear - not least because it means I no longer have a means to leave a legacy to effective charities in my will (which I'll now need to change). Previously the GWWC trust meant I had a means of leaving money, hedging against changes in the landscape of what's effective, run by an org whose philosophy I agree with and whose decisions I had a good track record of trusting. EA funds requires I either specify organisations (which I can do myself in a will, but might not be the best picks at a relevant time), or trust a single individual in whom I don't have the same confidence. Also if a legacy is likely to be a substantial amount of money I am more risk averse about where it goes. </p>\n", "parentCommentId": null, "user": {"username": "Bernadette_Young"}}, {"_id": "CqMAuWPwPkRBpvMKA", "postedAt": "2017-04-20T22:47:50.965Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>First, thanks very much for this valuable transparency!</p>\n<p>I notice the movement building fund hasn't donated any money yet. I'm curious what the process for making grants from this fund will be?</p>\n<p>Specifically, what steps is CEA and Nick (a trustee of CEA) going to take to recuse themselves from discussions in the movement building fund? Will CEA apply for money through the fund? Would there be any possibility of inappropriate pro-CEA bias if someone else applied for the fund wanting to do something similar to what CEA is doing or wants to do?</p>\n", "parentCommentId": null, "user": {"username": "Peter_Hurford"}}, {"_id": "o8To79uBFx5RkeWKZ", "postedAt": "2017-04-20T23:51:05.755Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<blockquote>\n<p>While this way of gauging feedback is far from perfect, our impression is that community feedback has been largely positive. Where we\u2019ve received criticism it has mostly been around how we can improve the website and our communication about EA Funds as opposed to criticism about the core concept.</p>\n</blockquote>\n<p>As much as I admire the care that has been put into EA Funds (e.g. the 'Why might you choose not to donate to this fund?' heading for each fund), this sentence came across as 'too easy' for me. To be honest, it made me wonder if the analysis was self-critical enough (I admit to having scanned it) as I'd be surprised if the trusted people you spoke with couldn't think of any significant risks.\nI also think 'largely positive' reception does not seem like a good indicator. If a person like Eliezer would stand out as the sole person in disagreement, that should give pause for thought.</p>\n<p>Even though the article is an update, I'm somewhat concerned by that it goes little into possible long-term risks. One that seems especially important is the consequences of centralising fund allocation (mostly to managers connected to OP) to having a diversity of views and decentralised correction mechanisms within our community. Please let me know where you think I might have made mistakes/missed important aspects.</p>\n<p>I especially want to refer to Rob Wiblin's earlier comment: <a href=\"http://effective-altruism.com/ea/17v/ea_funds_beta_launch/aco\">http://effective-altruism.com/ea/17v/ea_funds_beta_launch/aco</a></p>\n<blockquote>\n<p>I love EA Funds, but my main concern is that as a community we are getting closer and closer to a single point of failure. If OPP reaches the wrong conclusion about something, there's now fewer independent donors forming their own views to correct them. This was already true because of how much people used the views of OPP and its staff to guide their own decisions.</p>\n</blockquote>\n<blockquote>\n<p>We need some diversity (or outright randomness) in funding decisions for robustness.</p>\n</blockquote>\n", "parentCommentId": null, "user": {"username": "remmelt"}}, {"_id": "SCC9M5ES8g4nxKgQk", "postedAt": "2017-04-21T01:15:56.900Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>Excellent point.</p>\n<p>My suggestion for increasing robustness:</p>\n<p>Diverse fund managers, and willingness to have funds for less-known causes.\nA high diversity of background/personal social networks amongst fund managers, and a willingness to have EA funds for causes not currently championed by OPP or other well known orgs in the EA-sphere could be a good way to increase robustness.</p>\n<p>Do you agree? And what are your thoughts in general on increasing robustness?</p>\n", "parentCommentId": "o8To79uBFx5RkeWKZ", "user": {"username": "nonzerosum"}}, {"_id": "Ad9cSB4MzQwHbfQuQ", "postedAt": "2017-04-21T02:05:13.703Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<blockquote>\n<p>One that seems especially important is the consequences of centralising fund allocation (mostly to managers connected to OP)</p>\n</blockquote>\n<p>This is my largest concern as well. As someone who looks for funding for projects, I've noticed a lot of donors centralizing around these funds. This is good for them, because it saves them the time of having to evaluate, and good for me, because it gives me a single place to request funding. But if I can't convince them to fund me for some reason and I think they're making a mistake, there are no other donors to appeal to anymore. It's all or nothing.</p>\n", "parentCommentId": "o8To79uBFx5RkeWKZ", "user": {"username": "Peter_Hurford"}}, {"_id": "RWLqzW5cfXWSdCPkG", "postedAt": "2017-04-21T02:16:58.294Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>I'm worried that this impairs our ability to credibly signal that we are not a scam. Originally we could say that we didn't want any money ourselves - we were just asking for donations to third parties. Then we started asking for money directly, but the main focus was still on recommending donations to third parties. But now the main advice is to give us money, which we will then spend wisely (trust us!). It seems that outsiders could (justifiably) find this much less persuasive.</p>\n", "parentCommentId": null, "user": {"username": "Larks"}}, {"_id": "z4Zu2H2zKg2meHote", "postedAt": "2017-04-21T05:58:59.025Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>Thanks, this was really interesting.</p>\n", "parentCommentId": null, "user": {"username": "lukeprog"}}, {"_id": "g8HKtewpHdscvPzQx", "postedAt": "2017-04-21T09:35:49.377Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>Thanks for the post!</p>\n<p>Lewis Bollard gave away 180k but Nick Beckstead says he only had access to 14k. Was this due to a spike in donations to the far future cause after they made their recommendations?</p>\n", "parentCommentId": null, "user": {"username": "Ben Pace"}}, {"_id": "24xZ6R4pwL7H2jo4X", "postedAt": "2017-04-21T10:05:23.192Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>What percentage of funds was raised from people who are part of the EA community / identify as EAs, and what percentage of funds from people outside the community (e.g. Hacker News)?</p>\n<p>(The launch post said that you'll be &quot;seeing how the concept is received outside of the EA community&quot; so it would be nice to learn about that, too.)</p>\n", "parentCommentId": null, "user": {"username": "Jonas Vollmer"}}, {"_id": "isPTG6F2Y6tmLxr4e", "postedAt": "2017-04-21T10:50:10.914Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>Hi Bernadette,</p>\n<p>We\u2019re sorry that our communication on this has not been clear enough. We were waiting on some technical details so that we could infor Trust users of the exact changes and what they needed to do in advance but now I\u2019ll communicate what we can today while Larissa Hesketh-Rowe is also going to email Giving What We Can members to make sure everyone is included.</p>\n<p>In terms of the Trust we are moving all of the functionality the Trust had over to EA Funds which we believe will ultimately be a much better platform both for users and for us in terms of managing the administration.</p>\n<p>You can leave a legacy in a similar way via EA Funds; as you mentioned you can allocate it to the Funds or to specific charities. However, you can also allocate it to GiveWell\u2019s recommended charities as they stand at the time of granting your bequest. In practice this should be similar to how bequests were made to the Trust - keeping the Giving What We Can Trust running would still mean using GiveWell\u2019s recommendation as Giving What We Can no longer conduct our own research. In our update to members at the end of July we explained that the restructure with CEA meant that while we would continue to run the core aspects of Giving What We Can like the pledge we felt that our research was not offering sufficient value over and above GiveWell\u2019s and that we would therefore move to making our list of recommended charities follow GiveWell\u2019s recommendations. We are still establishing what the Trust\u2019s options are for handling and transferring bequests, to see whether it is necessary to ask donors to change their wills, or whether we can transfer them, along with their instructions and allocations, to CEA. We\u2019ll look to communicate this as soon as we have more information.</p>\n<p>It seems we\u2019ve not communicated these changes clearly enough to members and so we\u2019ll be seeking to address this over the next couple of weeks. Do please post any other questions you have or clarifications you\u2019d like as we can use that to help inform what else we email to members.</p>\n<p>Best wishes,\nAlison</p>\n", "parentCommentId": "smtM5kdXxWTatbKMY", "user": {"username": "aliwoodman"}}, {"_id": "Ns5tP4X5rzqjGhCfE", "postedAt": "2017-04-21T11:23:52.222Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p><em>I appreciate that the post has been improved a couple times since the criticisms below were written.</em></p>\n<p>A few of you were diligent enough to beat me to saying much of this, but:</p>\n<blockquote>\n<p>Where we\u2019ve received criticism it has mostly been around how we can improve the website and our communication about EA Funds as opposed to criticism about the core concept.</p>\n</blockquote>\n<p><a href=\"http://effective-altruism.com/ea/174/introducing_the_ea_funds/a45\">This</a> <a href=\"http://effective-altruism.com/ea/174/introducing_the_ea_funds/a33\">seems</a> <a href=\"http://effective-altruism.com/ea/174/introducing_the_ea_funds/a4h\">false</a>, <a href=\"http://effective-altruism.com/ea/174/introducing_the_ea_funds/a3p\">based</a> <a href=\"http://effective-altruism.com/ea/174/introducing_the_ea_funds/a2m\">on</a> <a href=\"http://effective-altruism.com/ea/174/introducing_the_ea_funds/a28\">these</a> <a href=\"http://effective-altruism.com/ea/17v/ea_funds_beta_launch/acj\">replies</a>. The author of this post replied to the majority of those comments, which means he's aware that many people have in fact raised concerns about things other than communication and EA Funds' website. To his credit, someone added a paragraph acknowledging that these concerns had been raised elsewhere, in the pages for the <a href=\"https://app.effectivealtruism.org/funds/ea-community\">EA community fund</a> and the <a href=\"https://app.effectivealtruism.org/funds/animal-welfare\">animal welfare fund</a>. Unfortunately, though, these concerns were never mentioned in this post. There are a number of people who would like to hear about any progress that's been made since the discussion which happened on <a href=\"http://effective-altruism.com/ea/174/introducing_the_ea_funds/\">this thread</a> regarding the problems of 1) how to address conflicts of interest given how many of the fund managers are tied into e.g. OPP, and 2) how centralizing funding allocation (rather than making people who aren't OPP staff into Fund Managers) narrows the amount of new information about what effective opportunities exist that the EA Funds' Fund Managers encounter.</p>\n<p>I've spoken with a couple EAs in person who have mentioned that making the claim that &quot;EA Funds are likely to be at least as good as OPP\u2019s last dollar&quot; is harmful. In this post, it's certainly worded in a way that implies very strong belief, which, given how popular consequentialism is around here, would be likely to make certain sorts of people feel bad for not donating to EA Funds instead of whatever else they might donate to counterfactually. This is the same sort of effect people get from looking at <a href=\"https://i0.wp.com/inspire99.com/wp-content/uploads/2015/05/childrensvillage-iPhone.jpg\">this sort of advertising</a>, but more subtle, since it's less obvious on a gut level that this slogan half-implies that the reader is morally bad for not donating. Using this slogan could be net negative even without considering that it might make EAs feel bad about themselves, if, say, individual EAs had information about giving opportunities that were more effective than EA Funds, but donated to EA Funds anyways out of a sense of pressure caused by the &quot;at least as good as OPP&quot; slogan.</p>\n<p>More immediately, I have negative feelings about how this post used the Net Promoter Score to evaluate the reception of EA Funds. First, it mentions that EA Funds &quot;received an NPS of +56 (which is generally considered excellent according to the NPS Wikipedia page).&quot; But the first sentence of the <a href=\"https://en.wikipedia.org/wiki/Net_Promoter\">Wikipedia page for NPS</a>, which I'm sure the author read at least the first line of given that he linked to it, states that NPS is &quot;a management tool that can be used to gauge the loyalty of <em>a firm's</em> customer relationships&quot; (emphasis mine). However, EA Funds isn't a firm. My view is that implicitly assuming that, as a nonprofit (or something socially equivalent), your score on a metric intended to judge how satisfied a for-profit company's customers are can be compared side by side with the scores received by for-profit firms (and then neglecting to mention that you've made this assumption) belies a lack of intent to honestly inform EAs.</p>\n<p>This post has other problems, too; it uses the NPS scoring system to analyze donors and other's responses to the question:</p>\n<blockquote>\n<p>How likely is it that your donation to EA Funds will do more good in expectation than where you would have donated otherwise?</p>\n</blockquote>\n<p>The NPS scoring system was never intended to be used to evaluate responses to this question, so perhaps that makes it insignificant that an NPS score of 0 for this question just misses the mark of being &quot;felt to be good&quot; in industry. Worse, the post mentions that this result</p>\n<blockquote>\n<p>could merely represent healthy skepticism of a new project or it could indicate that donors are enthusiastic about features other than the impact of donations to EA Funds.</p>\n</blockquote>\n<p>It seems to me that including only positive (or strongly positive-sounding) interpretations of this result is incorrect and misleadingly optimistic. I'd agree that it's a good idea to not &quot;take NPS too seriously&quot;, though in this case, I wouldn't say that the benefit that came from using NPS in the first place outweighed the cost that was incurred by the resultant incorrect suggestion that we should feel there was a respectable amount of quantitative support for the conclusions drawn in this post.</p>\n<p>I'm disappointed that I was able to point out so many things I wish the author had done better in this document. If there had only been a couple errors, it would have been plausibly deniable that anything fishy was going on here. But with as many errors as I've pointed out, which <em>all point in the direction of making EA Funds look better than it is</em>, things don't look good. Things don't look good regarding how well this project has been received, but that's not the larger problem here. The larger problem is that things don't look good because this post decreases how much I am willing to trust communications made on the behalf of EA funds in particular, and communications made by CEA staff more generally.</p>\n<p>Writing this made me cry, a little. It's late, and I should have gone to bed hours ago, but instead, here I am being filled with sad determination and horror that it feels like I can't trust anyone I haven't personally vetted to communicate honestly with me. In Effective Altruism, honesty used to mean something, consequentialism used to come with integrity, and we used to be able to work together to do the most good we could.</p>\n<p>Some days, I like to quietly smile to myself and wonder if we might be able to take that back.</p>\n", "parentCommentId": null, "user": {"username": "Fluttershy"}}, {"_id": "9PoNjpvomCpRqxSwN", "postedAt": "2017-04-21T15:58:19.324Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<blockquote>\n<p>This seems false, based on these replies. The author of this post replied to the majority of those comments, which means he's aware that many people have in fact raised concerns about things other than communication and EA Funds' website.</p>\n</blockquote>\n<p>Thanks for taking the time to provide such detailed feedback.</p>\n<p>I agree. This was a mistake on my part. I was implicitly thinking about some of the recent feedback I'd read on Facebook and was not thinking about responses to the initial launch post. </p>\n<p>I agree that it's not fair to say that the criticism have been predominately about website copy. I've changed the relevant section in the post to include links to some of the concerns we received in the launch post.</p>\n<p>I'd like to be as exhaustive as possible, so please provide links to any areas I missed so that I can include them (note that I didn't include all of the comments you linked to if I thought our launch post already addressed the issue).</p>\n", "parentCommentId": "Ns5tP4X5rzqjGhCfE", "user": {"username": "Kerry_Vaughan"}}, {"_id": "2v7zJoSRrAvaC3gGD", "postedAt": "2017-04-21T16:09:20.818Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<blockquote>\n<p>I've spoken with a couple EAs in person who have mentioned that making the claim that &quot;EA Funds are likely to be at least as good as OPP\u2019s last dollar&quot; is harmful... would be likely to make certain sorts of people feel bad for not donating to EA Funds instead of whatever else they might donate to counterfactually</p>\n</blockquote>\n<p>I'm not sure I follow the concern here.</p>\n<p>Are you arguing that a) the &quot;OPP's last dollar&quot; content is not attempting to provide an argument or that b) it's wrong to give an argument if the argument causes guilt as a side effect or are you arguing for something else?</p>\n<p>I'd be willing to defend that it's acceptable to make arguments for a position even if those arguments have the unintended consquence of causing guilt.</p>\n", "parentCommentId": "Ns5tP4X5rzqjGhCfE", "user": {"username": "Kerry_Vaughan"}}, {"_id": "HEMhTpE2sHdShxq5d", "postedAt": "2017-04-21T16:33:17.588Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<blockquote>\n<p>But the first sentence of the Wikipedia page for NPS, which I'm sure the author read at least the first line of given that he linked to it, states that NPS is &quot;a management tool that can be used to gauge the loyalty of a firm's customer relationships&quot; (emphasis mine). However, EA Funds isn't a firm. My view is that implicitly assuming that, as a nonprofit (or something socially equivalent), your score on a metric intended to judge how satisfied a for-profit company's customers are can be compared side by side with the scores received by for-profit firms (and then neglecting to mention that you've made this assumption) belies a lack of intent to honestly inform EAs.</p>\n</blockquote>\n<p>I think your concern is that since NPS was developed with for-profit companies in mind, we shouldn't assume that a +50 NPS is good for a nonprofit.</p>\n<p>If so, that's fair and I agree. </p>\n<p>When people benchmark NPS scores, they usually do it by comparing NPS scores in similar industries. Unfortunately, I don't know of any data for NPS scores of nonprofits like ours (e.g. consumer-facing and providing a donation service). I think the information about what NPS score is generally considered good is helpful to understanding why we updated in favor of EA Funds persisting past the three month trial.</p>\n<p>Is it your view that I a) shouldn't have included NPS data at all or b) shoulnd't have included information about what scores are good or c) that I should have caveated the paragraph more carefully?</p>\n", "parentCommentId": "Ns5tP4X5rzqjGhCfE", "user": {"username": "Kerry_Vaughan"}}, {"_id": "RW9g2o9jf7c4mtdEN", "postedAt": "2017-04-21T16:47:01.681Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<blockquote>\n<p>I'm disappointed that I was able to point out so many things I wish the author had done better in this document. If there had only been a couple errors, it would have been plausibly deniable that anything fishy was going on here. But with as many errors as I've pointed out, which all point in the direction of making EA Funds look better than it is, things don't look good.</p>\n</blockquote>\n<p>From my point of view, the context for the first section was to explain why we updated in favor of EA Funds persisting past the three-month trial before the trial was over. This was important to communicate because several people expressed confusion about our endorsement of EA Funds while the project was still technically in beta. This is why the first section highlights mostly positive information about EA Funds whereas later sections highlight challenges, mistakes etc.</p>\n<p>I think the update that your comment is suggesting is that I should have made the first section longer and should have provided a more detailed discussion of the considerations for and against concluding that EA Funds has been well-received so far. Is that what you think or do you think I should make a different update?</p>\n", "parentCommentId": "Ns5tP4X5rzqjGhCfE", "user": {"username": "Kerry_Vaughan"}}, {"_id": "EoyJQKXTrYdrxueGP", "postedAt": "2017-04-21T16:53:04.599Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<blockquote>\n<p>As much as I admire the care that has been put into EA Funds (e.g. the 'Why might you choose not to donate to this fund?' heading for each fund), this sentence came across as 'too easy' for me. To be honest, it made me wonder if the analysis was self-critical enough (I admit to having scanned it) as I'd be surprised if the trusted people you spoke with couldn't think of any significant risks. I also think 'largely positive' reception does not seem like a good indicator.</p>\n</blockquote>\n<p>I agree. This was a mistake on my part. I was implicitly thinking about some of the recent feedback I'd read on Facebook and was not thinking about responses to the initial launch post.</p>\n<p>I agree that it's not fair to say that the criticism have been predominately about website copy. I've changed the relevant section in the post to include links to some of the concerns we received in the launch post.</p>\n<p>I'd like to develop some content for the EA Funds website that goes into potential harms of EA Funds that are separate from the question of whether EA Funds is the best option right now for individual donors. Do you have a sense of what concerns seem most compelling or that you'd particularly like to see covered?</p>\n", "parentCommentId": "o8To79uBFx5RkeWKZ", "user": {"username": "Kerry_Vaughan"}}, {"_id": "dDqccbkt2YkxBAxcR", "postedAt": "2017-04-21T17:11:07.967Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<blockquote>\n<p>But if I can't convince them to fund me for some reason and I think they're making a mistake, there are no other donors to appeal to anymore. It's all or nothing.</p>\n</blockquote>\n<p>The upside of centralization is that it helps prevent the unilateralist curse for funding bad projects. As the number of funders increases, it becomes increasingly easy for the bad projects to find <em>someone</em> who will fund them.</p>\n<p>That said, I share the concern that EA Funds will become a single point of failure for projects such that if EA Funds doesn't fund you, the project is dead. We probably want some centralization but we also want worldview diversification. I'm not yet sure how to accomplish this. We could create multiple versions of the current funds with different fund managers, but that is likely to be very confusing to most donors. I'm open to ideas on how to help with this concern.</p>\n", "parentCommentId": "Ad9cSB4MzQwHbfQuQ", "user": {"username": "Kerry_Vaughan"}}, {"_id": "X8Kqeuazfb2TsxBiZ", "postedAt": "2017-04-21T17:12:43.819Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>Nick's recommendation came much sooner after launch than Lewis's, so Nick had much less money available at the time.</p>\n", "parentCommentId": "g8HKtewpHdscvPzQx", "user": {"username": "Kerry_Vaughan"}}, {"_id": "oaY7B9QiCoEtHP3Bu", "postedAt": "2017-04-21T17:19:14.174Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>I agree that people new to EA could find EA Funds much less persuasive than the previous donation recommendations we used. I expect that we'll find out whether or not this is true as we work on expanding EA Funds outside of EA. If non-EAs don't want to use EA Funds, then we'll probably want to lead with other examples of how people select effective donation options.</p>\n", "parentCommentId": "RWLqzW5cfXWSdCPkG", "user": {"username": "Kerry_Vaughan"}}, {"_id": "xa39oBqPWiRZn7P6K", "postedAt": "2017-04-21T17:53:45.349Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<blockquote>\n<p>Specifically, what steps is CEA and Nick (a trustee of CEA) going to take to recuse themselves from discussions in the movement building fund?</p>\n</blockquote>\n<p>The current process is that fund managers send grant recommendations to me and Tara and we execute them. Fund managers don't discuss their grant recommendations with us ahead of time and we don't have any influence over what they recommend.</p>\n<p>From a legal standpoint, money donated to EA Funds has been donated to CEA. This means that we need board approval for each grant the fund managers recommend. The only cases I see at the moment where we might fail to approve a grant would be cases where a) the grant violates the stated goals of the fund or b) where the grant would not be consistent with CEA's broad charitable mission. I expect both of these cases to be unlikely to occur.</p>\n<blockquote>\n<p>Will CEA apply for money through the fund?</p>\n</blockquote>\n<p>At the moment there isn't really an application process. Any formal system for requesting grants would be set up by Nick without CEA's input or assistance. </p>\n<p>That said, CEA is a potential recipient of money donated to the EA Community fund. If we believe that we can make effective use of money in the EA Community fund we will make our case to Nick for receiving funding. Nick's position as a trustee of CEA means that he has robust access to information about CEA's activities, bnudget, and funding sources.</p>\n<blockquote>\n<p>Would there be any possibility of inappropriate pro-CEA bias if someone else applied for the fund wanting to do something similar to what CEA is doing or wants to do?</p>\n</blockquote>\n<p>This is certainly possible. Because Nick talks to the other CEA trustees regularly, it is likely that he would know where other organizations overlap with CEA's work and it is likely that he would know what CEA staff think about other oganizations. This might cause him to judge other organizations more unfavorably than he might if he was not a CEA trustee.</p>\n<p>I think the appropriate outside view is that Nick will be unintentionally biased in CEA's favor in cases where CEA conflicts with other EA community building organizations. My inside view from interacting with Nick is that he is a careful and thoughtful decision-maker who is good at remaining objective. </p>\n<p>If you're worried about pro-CEA bias and if you don't have sufficient information about Nick to trust him, then you probably shouldn't donate to the EA Community Fund.</p>\n", "parentCommentId": "CqMAuWPwPkRBpvMKA", "user": {"username": "Kerry_Vaughan"}}, {"_id": "HRNbZbR5cPGTNJ6fv", "postedAt": "2017-04-21T18:03:33.457Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>In our post-donation survey, we ask whether people consider themselves a part of the EA Community. Out of 32 responses, 10 said no which indicates that around 1/3 of donors are new to EA.</p>\n<p>However, donations from this group were generally quite small and some of them indicated that they had donated to places like AMF or GiveDirectly in the past. My overall guess is that the vast majority of money donated so far has been from people who were already familiar with EA.</p>\n", "parentCommentId": "24xZ6R4pwL7H2jo4X", "user": {"username": "Kerry_Vaughan"}}, {"_id": "axYfyK4XiEGfnL3Xm", "postedAt": "2017-04-21T18:06:26.865Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>We're still working on the process for adding new fund managers. New fund managers will not need to have a relationship with anyone on the team.</p>\n", "parentCommentId": "ZH6fZ3XhppoNc9ANs", "user": {"username": "Kerry_Vaughan"}}, {"_id": "tvscSQtXk7xvXTEhs", "postedAt": "2017-04-21T18:09:08.073Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>We haven't decided this yet, but I can share my current guesses. I expect that we'll be looking for fund managers who have worldviews that are different from the existing fund managers, who are careful thinkers, who are respected in the EA community and our likely pool of donors, and who are willing to devote a sufficient amount of time to manage the fund.</p>\n", "parentCommentId": "TFF4SBCybmrCaaTSe", "user": {"username": "Kerry_Vaughan"}}, {"_id": "4ohMmZJTYmfSAd6bG", "postedAt": "2017-04-21T18:09:58.807Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>Unfortunately, we don't have any details around this at the moment. We should have more to share once we devote more time to this question over the summer.</p>\n", "parentCommentId": "gs3TyLubqX2keHtZF", "user": {"username": "Kerry_Vaughan"}}, {"_id": "vJqz3r7mgaRtt4JsG", "postedAt": "2017-04-21T20:45:14.407Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>Quick (thus likely wrong) thought on solving unilateralist's curse: put multiple position in charge of each fund, each representing a different worldview, and give everyone 3 grant vetoes each year (so they can prevent grants that are awful in their worldview). You can also give them control of a percentage of funds in proportion to CEA's / the donor's confidence in that worldview.</p>\n", "parentCommentId": "dDqccbkt2YkxBAxcR", "user": {"username": "Ben Pace"}}, {"_id": "hAgc7Gg4d8zMMyaSX", "postedAt": "2017-04-22T02:08:29.741Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>Or maybe allocate grants according to a ranked preference vote of the three fund managers, plus have them all individually and publicly write up their reasoning and disagreements? I'd like that a lot.</p>\n", "parentCommentId": "vJqz3r7mgaRtt4JsG", "user": {"username": "Peter_Hurford"}}, {"_id": "ZbnJuE9vPELstKwTR", "postedAt": "2017-04-22T04:49:06.897Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<blockquote>\n<p>given how popular consequentialism is around here, would be likely to make certain sorts of people feel bad for not donating to EA Funds </p>\n</blockquote>\n<p>This is wholly speculative. I've seen no evidence that consequentialists &quot;feel bad&quot; in any emotionally meaningful sense for having made donations to the wrong cause.</p>\n<blockquote>\n<p>This is the same sort of effect people get from looking at this sort of advertising, but more subtle</p>\n</blockquote>\n<p>Looking at that advertising slightly dulled my emotional state. Then I went on about my day. And you are worried about something that would even be <em>more</em> subtle? Why can't we control our feelings and not fall to pieces at the thought that we might have been responsible for injustice? The world sucks and when one person screws up, someone else is suffering and dying at the other end. Being cognizant of this is far more important than protecting feelings.</p>\n<blockquote>\n<p>if, say, individual EAs had information about giving opportunities that were more effective than EA Funds, but donated to EA Funds anyways out of a sense of pressure caused by the &quot;at least as good as OPP&quot; slogan.</p>\n</blockquote>\n<p>I think you ought to place a bit more faith in the ability of effective altruists to make rational decisions.</p>\n", "parentCommentId": "Ns5tP4X5rzqjGhCfE", "user": {"username": "Zeke_Sherman"}}, {"_id": "voR37JZwQQmYDL7kt", "postedAt": "2017-04-22T07:02:41.319Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>Our friend presiding over Machine Doggo Fund I'm sure would be interested to here about heterodox or contrarian advice to hedge against the centralization of EA philanthropy. I know a few effective altruists whose advice on giving he'd respect. That'd it consolidate his image as some cross between an edgy renegade and a folk hero, a sort of Batman of earning to give, can only help the case we could make.</p>\n", "parentCommentId": "Ad9cSB4MzQwHbfQuQ", "user": {"username": "Evan_Gaensbauer"}}, {"_id": "XGTw4YJYJxa2HdMC8", "postedAt": "2017-04-22T07:50:55.743Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<blockquote>\n<p>The upside of centralization is that it helps prevent the unilateralist curse for funding bad projects.</p>\n</blockquote>\n<p>This is an interesting point.</p>\n<p>It seems to me like mere veto power is sufficient to defeat the unilateralist's curse.  The curse doesn't apply in situations where 99% of the thinkers believe an intervention is <strong>useless</strong> and 1% believe it's useful, only in situations where the 99% think the intervention is <strong>harmful</strong> and would want to veto it.  So technically speaking we don't need to centralize power of action, just power of veto.</p>\n<p>That said, my impression is that the EA community has such a strong allergic reaction to authority that anything that looks like an official decisionmaking group with an official veto would be resisted.  So it seems like the result is that we go past centralization of veto in to centralization of action, because (ironically) it seems less authority-ish.</p>\n", "parentCommentId": "dDqccbkt2YkxBAxcR", "user": {"username": "John_Maxwell_IV"}}, {"_id": "7HiLwfmQvPqJSc2FQ", "postedAt": "2017-04-22T07:55:12.278Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>On second thought, perhaps it's just an issue of framing.</p>\n<p>Would you be interested in an &quot;EA donors league&quot; that tried to overcome the unilateralist's curse by giving people in the league some kind of power to collectively veto the donations made by other people in the league?  You'd get the power to veto the donations of other people in exchange for giving others the power to veto your donations (details to be worked out)</p>\n<p>[pollid:7]</p>\n<p>(I guess the biggest detail to work out is how to prevent people from simply quitting the league when they want to make a non-kosher donation.  Perhaps a cash deposit of some sort would work.)</p>\n", "parentCommentId": "XGTw4YJYJxa2HdMC8", "user": {"username": "John_Maxwell_IV"}}, {"_id": "vYmLFXsNGaM53RXex", "postedAt": "2017-04-22T10:38:47.261Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<blockquote>\n<p>The donation amounts we\u2019ve received so far are greater than we expected, especially given that donations typically decrease early in the year after ramping up towards the end of the year. </p>\n</blockquote>\n<p>How much did you expect?</p>\n", "parentCommentId": null, "user": {"username": "ChristianKleineidam"}}, {"_id": "bpPEvanKiRNBzGDPj", "postedAt": "2017-04-22T12:51:34.190Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<blockquote>\n<p>Things don't look good regarding how well this project has been received</p>\n</blockquote>\n<p>I know you say that this isn't the main point you're making, but I think it's the hidden assumption behind some of your other points and it was a surprise to read this. Will's post introducing the EA funds is the 4th most upvoted post of all time on this forum. Most of the top rated comments on his post, including at least one which you link to as raising concerns, say that they are positive about the idea. Kerry then presented some survey data in this post. All those measures of support are kind of fuzzy and prone to weird biases, but putting it all together I find it much more likely than not that the community is as-a-whole positive about the funds. An alternative and more concrete angle would be money received into the funds, which was just shy of CEA's target of $1m.</p>\n<p>Given all that, what would 'well-received' look like in your view? </p>\n<p>If you think the community is generally making a mistake in being supportive of the EA funds, that's fine and obviously you can/should make arguments to that effect. But if you are making the empirical claim that the community is <em>not</em> supportive, I want to know why you think that.</p>\n", "parentCommentId": "Ns5tP4X5rzqjGhCfE", "user": {"username": "AGB"}}, {"_id": "96DiXj6y2nACBAzd7", "postedAt": "2017-04-22T13:31:09.629Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>The unilateralist's curse does not apply to donations, since funding a project can be done at a range of levels and is not a single, replaceable decision.</p>\n", "parentCommentId": "7HiLwfmQvPqJSc2FQ", "user": {"username": "kbog"}}, {"_id": "9RZSnKpnGhbqsmiHL", "postedAt": "2017-04-22T13:37:07.326Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>Yeah, in this community it's easy for your data to be filtered. People commonly comment with criticism, rarely with just &quot;Yeah, this is right!&quot;, and so your experience can be filled with negative responses even when the response is largely positive.</p>\n", "parentCommentId": "bpPEvanKiRNBzGDPj", "user": {"username": "Ben Pace"}}, {"_id": "6mD6Fg5F5HjmgXWNz", "postedAt": "2017-04-22T15:53:10.408Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>I appreciate the information being posted here, in this blog post, along with all the surrounding context. However, I don't see the information on these grants on the actual EA Funds website. Do you plan to maintain a grants database on the EA Funds website, and/or list all the grants made from each fund on the fund page (or linked to from it)? That way anybody can check in at any time to see how how much money has been raised, and how much has been allocated and where.</p>\n<p>The Open Philanthropy Project grants database might be a good model, though your needs may differ somewhat.</p>\n", "parentCommentId": null, "user": {"username": "vipulnaik"}}, {"_id": "H6fxzbtbSRaTfXKXL", "postedAt": "2017-04-22T16:48:22.607Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>We have an issue with our CMS which is making the grant information not show up on the website. I will include these grants and all future grants as soon as that is fixed.</p>\n", "parentCommentId": "6mD6Fg5F5HjmgXWNz", "user": {"username": "Kerry_Vaughan"}}, {"_id": "ENvC7u4HBXumnAfaM", "postedAt": "2017-04-22T20:20:20.967Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>In one view, the concept post had 43 upvotes, the launch post had 28, and this post currently has 14. I don't think this is problematic in itself, since this could just be an indication of hype dying down over time, rather than of support being retracted.</p>\n<p>Part of what I'm tracking when I say that the EA community isn't supportive of EA Funds is that I've spoken to several people in person who have said as much--I think I covered all of the reasons they brought up in my post, but one recurring theme throughout those conversations was that writing up criticism of EA was tiring and unrewarding, and that they often didn't have the energy to do so (though one offered to proofread anything I wrote in that vein). So, a large part of my reason for feeling that there isn't a great deal of community support for EA funds has to do with the ways in which I'd expect the data on how much support there actually is to be filtered. For example:</p>\n<ul>\n<li>the method in which Kerry presented his survey data made it look like there was more support than there was</li>\n<li>the fact that Kerry presented the data in this way suggests it's relatively more likely that Kerry will do so again in the future if given the chance</li>\n<li>social desirability bias should also make it look like there's more support than there is</li>\n<li>the fact that it's socially encouraged to praise projects on the EA Forum and that criticism is judged more harshly than praise should make it look like there's more support than there is. Contrast this norm with the one at LW, and notice how it affected how long it took us to get rid of Gleb.</li>\n<li>we have a social norm of wording criticism in a very mild manner, which might make it seem like critics are less serious than they are.</li>\n</ul>\n<p>It also doesn't help that most of the core objections people have brought up have been acknowledged but not addressed. But really, given all of those filters on data relating to how well-supported the EA Funds are, and the fact that the survey data doesn't show anything useful either way, I'm not comfortable with accepting the claim that EA Funds has been particularly well-received.</p>\n", "parentCommentId": "bpPEvanKiRNBzGDPj", "user": {"username": "Fluttershy"}}, {"_id": "zHcpjYwnnSEJXFZ2Y", "postedAt": "2017-04-22T21:13:00.618Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<blockquote>\n<p>Writing this made me cry, a little. It's late, and I should have gone to bed hours ago, but instead, here I am being filled with sad determination and horror that it feels like I can't trust anyone I haven't personally vetted to communicate honestly with me. </p>\n</blockquote>\n<p>There are a range of reasons that this is not really an appropriate way to communicate. It's socially inappropriate, it could be interpreted as emotional blackmail, and it could encourage trolling.</p>\n<p>It's a shame you've been upset. Still, one can call others' writing upsetting, immoral, mean-spirited, etc etc etc - there is a lot of leeway to make other reasonable conversational moves.</p>\n", "parentCommentId": "Ns5tP4X5rzqjGhCfE", "user": {"username": "RyanCarey"}}, {"_id": "njAzoBoMrh853FyWR", "postedAt": "2017-04-22T21:53:26.070Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>A more detailed discussion of the considerations for and against concluding that EA Funds had been well received would have been helpful if the added detail was spent examining people's concerns re: conflicts of interest, and centralization of power, i.e. concerns which were commonly expressed but not resolved.</p>\n<p> I'm concerned with the framing that you updated <em>towards</em> it being correct for EA Funds to persist past the three month trial period. If there was support to start out with and you mostly didn't gather more support later on relative to what one would expect, then your prior on whether EA Funds is well received should be stronger but you shouldn't update in favor of it being well received based on more recent data. This may sound like a nitpick, but it is actually a crucially important consideration if you've framed things as if you'll continue on with the project only if you update in the direction of having more public support than before.</p>\n<p>I also dislike that you emphasize that some people &quot;expressed confusion at your endorsement of EA Funds&quot;. Some people may have felt that way, but your choice of wording both downplays the seriousness of some people's disagreements with EA Funds, while also implying that critics are in need of figuring something out that others have already settled (which itself socially implies they're less competent than others who aren't confused). This is a part of what some of us mean when we talk about a tax on criticism in EA.</p>\n", "parentCommentId": "RW9g2o9jf7c4mtdEN", "user": {"username": "Fluttershy"}}, {"_id": "L8BZrCiQmZs8QNuD2", "postedAt": "2017-04-22T22:51:44.428Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>So I probably disagree with some of your bullet points, but unless I'm missing something I don't think they can be the crux of our disagreement here, so for the sake of argument let's suppose I fully agree that there are a variety of strong social norms in place here that make praise more salient, visible and common than criticism.</p>\n<p>...I still don't see how to get from here to (for example) 'The community is probably net-neutral to net-negative on the EA funds, but Will's post introducing them is the 4th most upvoted post of all time'. The relative (rather than absolute) nature of that claim is important; even if I think posts and projects on the EA forum generally get more praise, more upvotes, and less criticism than they 'should', why has that boosted the EA funds in particular over the dozens of other projects that have been announced on here over the past however-many years? To pick the most obviously-comparable example that quickly comes to mind, Kerry's post introducing EA Ventures has just 16 upvotes*.</p>\n<p>It just seems like the simplest explanation of your observed data is 'the community at large likes the funds, and my personal geographical locus of friends is weird'.</p>\n<p>And without meaning to pick on you in particular (because I think this mistake is super-common), in general I want to push strongly towards people recognising that EA consists of a large number of almost-disjoint filter bubbles that often barely talk to each other and in some extreme cases have next-to-nothing in common. Unless you're very different to me, we are both selecting the people we speak to in person such that they will tend to think much like us, and like each other; we live inside one of the many bubbles. So the fact that everyone I've spoken to in person about the EA funds thinks they're a good idea is <em>particularly</em> weak evidence that the community thinks they are good, and so is your opposing observation. I think we should both discount it ~entirely once we have anything else to go on. Relative upvotes are extremely far from perfect as a metric, but I think they are much better than in-person anecdata for this reason alone. </p>\n<p>FWIW I'm very open to suggestions on how we could settle this question more definitively. I expect CEA pushing ahead with the funds if the community as a whole really is net-negative on them would indeed be a mistake. I don't have any great ideas at the moment though.</p>\n<p>*<a href=\"http://effective-altruism.com/ea/fo/announcing_effective_altruism_ventures/\">http://effective-altruism.com/ea/fo/announcing_effective_altruism_ventures/</a></p>\n", "parentCommentId": "ENvC7u4HBXumnAfaM", "user": {"username": "AGB"}}, {"_id": "m7wh5x2H768vbrjvu", "postedAt": "2017-04-22T23:20:50.546Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<blockquote>\n<p>I'm concerned with the framing that you updated towards it being correct for EA Funds to persist past the three month trial period. If there was support to start out with and you mostly didn't gather more support later on relative to what one would expect...</p>\n</blockquote>\n<p>In the OP Kerry wrote:</p>\n<blockquote>\n<p>The donation amounts we\u2019ve received so far are greater than we expected, especially given that donations typically decrease early in the year after ramping up towards the end of the year. </p>\n</blockquote>\n<p>CEA's original expectation of donations could just have been wrong, of course. But I don't see a failure of logic here.</p>\n<p>Re. your last paragraph, Kerry can confirm or deny but I think he's referring to the fact that a bunch of people were surprised to see (e.g.? Not sure if there were other cases.) GWWC start recommending the EA funds and closing down the GWWC trust recently when CEA hadn't actually officially given the funds a 'green light' yet. So not referring to the same set of criticisms you are talking about. I think 'confusion at GWWC's endorsement of EA funds' is a reasonable description of how I felt when I received this e-mail, at the very least*; I like the funds but prominently recommending something that is in beta and might be discontinued at any minute seemed odd.</p>\n<p>*I got the e-mail from GWWC announcing this on 11th April. I got CEA's March 2017 update saying they'd decided to continue with the funds later on the same day, but I think that goes to a much narrower list and in the interim I was confused and was going to ask someone about it. Checking now it looks like CEA actually announced this on their blog on 10th April (see below link), but again presumably lots of GWWC members don't read that.</p>\n<p><a href=\"https://www.centreforeffectivealtruism.org/blog/cea-update-march-2017/\">https://www.centreforeffectivealtruism.org/blog/cea-update-march-2017/</a></p>\n", "parentCommentId": "njAzoBoMrh853FyWR", "user": {"username": "AGB"}}, {"_id": "pcsjNAiWyLqP7TaPq", "postedAt": "2017-04-23T00:21:13.163Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>Thanks again for writing about the situation of the EA Funds, and thanks also to the managers of the individual funds for sharing their allocations and the thoughts behind it. In light of the new information, I want to raise some concerns regarding the Global Health and Development fund.</p>\n<p>My main concern about this fund is that it's not really a &quot;Global Health and Development&quot; fund -- it's much more GiveWell-centric than global health- and development-centric. The decision to allocate all fund money to GiveWell's top charity reinforces some of my concerns, but it's actually something that is clear from the fund description.</p>\n<p>From the <a href=\"https://app.effectivealtruism.org/funds/global-development\">description</a>, it seems to be serving largely as a backup to GiveWell Incubation Grants (in cases where e.g. Good Ventures chooses not to fund the full amount) and as additional funding for GiveWell top charities.</p>\n<blockquote>\n<p>This fund will support charities that the fund manager believes may be better in expectation than those recommended by GiveWell, a charity evaluator focused on outstandingly effective giving opportunities. For example, by pooling the funds of many individual donors, the fund could support new, but very promising global health charities in getting off the ground (e.g. Charity Science Health or No Lean Season). These organizations may not be able to meet GiveWell\u2019s rigorous evaluation criteria at the moment, but may be able to meet the criteria in the future. If no such options are available, the fund will likely donate to GiveWell for granting. This means we think there is a strong likelihood that the fund will be at least as good as donating in accordance with GiveWell\u2019s recommendations, but could be better in expectation.</p>\n</blockquote>\n<p>Both the cited examples are recipients of GiveWell Incubation Grants, and in the pipeline for evaluation by GiveWell for top charity status. Even setting aside actual grantees, the value of the fund, according to the fund manager, is in terms of its value <em>to GiveWell</em> (emphasis mine):</p>\n<blockquote>\n<p>Nonetheless, donating to this fund is valuable because it helps demonstrate <em>to GiveWell</em> that there is donor demand for higher-risk, higher-reward global health and development giving opportunities.</p>\n</blockquote>\n<p>The GiveWell-centric nature of the fund is fine except that the fund's name suggests that it is a fund for global health and development, without affiliation to any institution.</p>\n<p>Even beyond the GiveWell-as-an-organization-centered nature of the fund, there is a sense in which the fund reinforces the association of global health and development with quantifiable-and-low-risk, linear, easy buys. That association makes sense in the context of GiveWell (whose job it is to recommend linear-ish buys) but seems out of place to me here. Again quoting from the page about the fund:</p>\n<blockquote>\n<p>Interventions in global health and development are generally tractable and have strong evidence to support them. </p>\n</blockquote>\n<p>There are two distinct senses in which the statement could be interpreted:</p>\n<ul>\n<li>There is large enough room for more funding for interventions in global health that have a strong evidence base, so that donors who want to stick to things with a strong evidence base won't run out of stuff to buy (i.e., lots of low-hanging fruit)</li>\n<li>There's not much scope in global health for high-risk but high-expected value investments, because any good buy in global health would have a strong evidence base</li>\n</ul>\n<p>I'd agree with the first interpretation, but the second interpretation seems quite false (looking at the Gates Foundation's portfolio shows a fair amount of risky, nonlinear efforts including new vaccine development, storage and surveillance technology breakthroughs, breakthroughs in toilet technology, etc.). The framing of the sentence, however, most naturally suggests the second interpretation, and moreover, may lead the reader to a careless conflation of the two. It seems to me like there's a lot of conflation in the EA community (and penumbra) between &quot;global health and development&quot; and &quot;GiveWell current and potential top charities&quot;, and the setup of this EA Fund largely reflects that. So in that sense, my criticism isn't just of the fund but of what seems to me an implicit conflation.</p>\n<p>Similar issues exist with two of the other funds: the animal welfare fund and the far future fund, but I think they are less concerning there. With &quot;animal welfare&quot; and &quot;far future&quot;, the way the terms are used in EA Funds and in the EA community are different from the picture they'll conjure in the minds of people in general. But as far as I know, there isn't so much of an established existing cohesive infrastructure of organizations, funding sources, etc. that is at odds with the EA community.* Whereas with global health and development, you have things like WHO, Gates Foundation, Global Fund, and even an associated academic discipline etc. so the appropriation of the term for a fund that's somewhat of a GiveWell satellite seems jarring to me.</p>\n<p>Some longer-term approaches that I think might help; obviously they wouldn't be changes you can make quickly:</p>\n<p>(a) Rename funds so that the names capture more specifically the sort of things the funds are doing. e.g. if a fund is only being used for last-mile delivery of interventions as opposed to e.g. vaccine development, that can be specified within the fund name.</p>\n<p>(b) Possibly have multiple funds within the same domain (e.g., global health &amp; development) that capture different kinds of use cases (intervention delivery versus biomedical research) and have fund managers with relevant experience in the domains. e.g. it's possible that somebody with experience at the Gates Foundation, Global Fund, WHO, IHME, etc. could do fund allocation in some domains of global health and development better for some use cases.</p>\n<p>Anyway, these are my thoughts. I'm not a contributor (or potential contributor, in the near term) to the funds, so take with appropriate amount of salt.</p>\n<p>*It could be that if I had deeper knowledge of mainstream animal welfare and animal rights, or of mainstream far future stuff (like climate change) then I would find these jarring as well.</p>\n", "parentCommentId": null, "user": {"username": "vipulnaik"}}, {"_id": "6qSDYgYLNcioh2ux2", "postedAt": "2017-04-23T07:30:23.423Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<blockquote>\n<p>As the number of funders increases, it becomes increasingly easy for the bad projects to find someone who will fund them.</p>\n</blockquote>\n<p>I'm not sure that's true. There are a lot of venture funds in the Valley but that doesn't mean it's easy to get any venture fund to give you money.</p>\n", "parentCommentId": "dDqccbkt2YkxBAxcR", "user": {"username": "ChristianKleineidam"}}, {"_id": "8diArRWQNsLaLavWF", "postedAt": "2017-04-23T08:54:29.174Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>The basic dynamic applies. Think it's pretty reasonable to use the name to point loosely in such cases, even if the original paper didn't discuss this extension.</p>\n", "parentCommentId": "96DiXj6y2nACBAzd7", "user": {"username": "Owen_Cotton-Barratt"}}, {"_id": "ahk7Nx2HT3cCCdcNs", "postedAt": "2017-04-23T09:10:49.020Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>Ryan, I substantially disagree and actually think all of your suggested alternatives are worse. The original is reporting on a response to the writing, not staking out a claim to an objective assessment of it. </p>\n<p>I think that reporting honest responses is one of the best tools we have for dealing with emotional inferential gaps -- particularly if it's made explicit that this is a function of the reader and writing, and not the writing alone.</p>\n", "parentCommentId": "zHcpjYwnnSEJXFZ2Y", "user": {"username": "Owen_Cotton-Barratt"}}, {"_id": "rKwBP7CKRD3uA9shx", "postedAt": "2017-04-23T13:41:53.462Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>Every choice to fund has false positives (funding something that should not have been funded) and false negatives (not funding something that should have been funded). Veto power only guards against the first one.</p>\n", "parentCommentId": "7HiLwfmQvPqJSc2FQ", "user": {"username": "Peter_Hurford"}}, {"_id": "WJKSCQ5mTutwuZAMy", "postedAt": "2017-04-23T14:12:18.539Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<blockquote>\n<p>FWIW I'm very open to suggestions on how we could settle this question more definitively.</p>\n</blockquote>\n<p>Perhaps a simple (random) survey? Or, if that's not possible, a poll of some sort?</p>\n", "parentCommentId": "L8BZrCiQmZs8QNuD2", "user": {"username": "Peter_Hurford"}}, {"_id": "ec5jfqB4qRg6wqn6S", "postedAt": "2017-04-23T18:44:56.402Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<blockquote>\n<p>It just seems like the simplest explanation of your observed data is 'the community at large likes the funds, and my personal geographical locus of friends is weird'.</p>\n<p>And without meaning to pick on you in particular (because I think this mistake is super-common), in general I want to push strongly towards people recognising that EA consists of a large number of almost-disjoint filter bubbles that often barely talk to each other and in some extreme cases have next-to-nothing in common. Unless you're very different to me, we are both selecting the people we speak to in person such that they will tend to think much like us, and like each other; we live inside one of the many bubbles. So the fact that everyone I've spoken to in person about the EA funds thinks they're a good idea is particularly weak evidence that the community thinks they are good, and so is your opposing observation.</p>\n</blockquote>\n<p>I'd say this is correct. The EA Forum itself has such a selection effect, though it's weaker than the ones either of our friend groups have. One idea would be to do a survey, as Peter suggests, though this makes me feel slightly uneasy given that a survey may weight the opinions of people who have considered the problem less or feel less strongly about it equally with the opinions of others. A relevant factor here is that it sometimes takes people a fair bit of reading or reflection to develop a sense for why integrity is particularly valuable from a consequentialist's perspective, and then link this up to why EA Funds continuing has the consequence of showing people that projects others use relatively lower-integrity methods to report on and market can succeed despite (or even because?) of this.</p>\n<p>I'd also agree that, at the time of Will's post, it would have been incorrect to say:</p>\n<blockquote>\n<p>The community is probably net-neutral to net-negative on the EA funds, but Will's post introducing them is the 4th most upvoted post of all time</p>\n</blockquote>\n<p>But what we likely care about is whether or not the community is positive on EA Funds at the moment, which may or may not be different from whether it was positive on EA Funds in the past.</p>\n<p>My view is further that the community's response to this sort of thing is partly a function of how debates on honesty and integrity have been resolved in the past; if lack of integrity in EA has been an issue in the past, the sort of people who care about integrity are less likely to stick around in EA, such that the remaining population of EAs will have fewer people who care about integrity, which itself affects how the average EA feels about future incidents relating to integrity (such as this one), and so on. So, on some level I'm positing that the public response to EA Funds would be more negative if we hadn't filtered certain people out of EA by having an integrity problem in the first place.</p>\n", "parentCommentId": "L8BZrCiQmZs8QNuD2", "user": {"username": "Fluttershy"}}, {"_id": "DhkPi5vconogobdYe", "postedAt": "2017-04-23T18:48:05.393Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>Hey Vipul, thanks for taking the time to write this. I think I largely agree with the points you've made here. </p>\n<p>As we've stated in the past, the medium-term goal for EA Funds to have 50% or less of the fund managers be Open Phil/GiveWell staff. We haven't yet decided whether we would plan to add fund managers in new cause areas, add fund managers with different approaches in existing cause areas, or some combination of the two. Given that Global Health and Development has received the most funding, there is likely room for adding funds that take a different approach to funding the space. Personally, I'd be excited to see something like a high risk, high reward global health and development fund.</p>\n<p>I probably disagree with changing the name of the fund right now as I think the current name does a good job of making it immediately clear what the fund is about. Because the UI of EA Funds shows you all the available funds and lets you split between them, we chose names that make it clear what the fund is about as compared to what the other funds are about. </p>\n<p>If we added a fund that was also in Global Heath and Development, then it might make sense to change the current name of the Global Health and Development fund to make it clear how the two funds are distinct from one another.</p>\n<p>By the way, if you know of solid thinkers in Global Heath and Development funding who are unaffiliated with GiveWell please feel free to email their names to me at <a href=\"mailto:kerry@effectivealtruism.org\">kerry@effectivealtruism.org</a>.</p>\n", "parentCommentId": "pcsjNAiWyLqP7TaPq", "user": {"username": "Kerry_Vaughan"}}, {"_id": "x8fHzLiKkcnzbjfs6", "postedAt": "2017-04-23T19:01:03.111Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<blockquote>\n<p>Kerry can confirm or deny but I think he's referring to the fact that a bunch of people were surprised to see (e.g.? Not sure if there were other cases.) GWWC start recommending the EA funds and closing down the GWWC trust recently when CEA hadn't actually officially given the funds a 'green light' yet.</p>\n</blockquote>\n<p>Correct. We had updated in favor of EA Funds internally but hadn't communicated that fact in public. When we started linking to EA Funds on the GWWC website, people were justifiably confused.</p>\n<blockquote>\n<p>I'm concerned with the framing that you updated towards it being correct for EA Funds to persist past the three month trial period. If there was support to start out with and you mostly didn't gather more support later on relative to what one would expect, then your prior on whether EA Funds is well received should be stronger but you shouldn't update in favor of it being well received based on more recent data.</p>\n</blockquote>\n<p>The money moved is the strongest new data point. </p>\n<p>It seemed quite plausible to me that we could have the community be largely supportive of the <em>idea</em> of EA Funds without actually using the product. This is more or less what happened with EA Ventures -- lots of people thought it was a good idea, but not many promising projects showed up and not many funders actually donated to the projects we happened to find.</p>\n<p>Do you feel that the post as currently written still overhypes the communities perception of the project? If so, what changes would you suggest to bring it more in line with the observable evidence?</p>\n", "parentCommentId": "m7wh5x2H768vbrjvu", "user": {"username": "Kerry_Vaughan"}}, {"_id": "M9GLQLtPYvMNKpcDK", "postedAt": "2017-04-23T19:04:02.953Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<blockquote>\n<p>Or maybe allocate grants according to a ranked preference vote of the three fund managers, plus have them all individually and publicly write up their reasoning and disagreements?</p>\n</blockquote>\n<p>Serious question: What do you think of N fund managers in your scenario?</p>\n", "parentCommentId": "hAgc7Gg4d8zMMyaSX", "user": {"username": "DonyChristie"}}, {"_id": "7fNnn3vqttqZoNNSX", "postedAt": "2017-04-23T19:16:06.149Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>I don't understand the question.</p>\n", "parentCommentId": "M9GLQLtPYvMNKpcDK", "user": {"username": "Peter_Hurford"}}, {"_id": "BiThNhheAtB6Mvmv5", "postedAt": "2017-04-23T19:24:54.707Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<blockquote>\n<p>It also doesn't help that most of the core objections people have brought up have been acknowledged but not addressed.</p>\n</blockquote>\n<p>My sense (and correct me if I'm wrong) is that the biggest concerns seem to be related to the fact that there is only one fund for each cause area and the fact that Open Phil/GiveWell people are running each of the funds.</p>\n<p>I share this concern and I agree that it is true that EA Funds has not been changed to reflect this. This is mostly because EA Funds simply hasn't been around for very long and we're currently working on improving the core product before we expand it.</p>\n<p>What I've tried to do instead is precommit to 50% or less of the funds being managed by Open Phil/GiveWell and give a general timeline for when we expect to start making good on that committment. I know that doesn't solve the problem, but hopefully you agree that it's a step in the right direction.</p>\n<p>That said, I'm sure there are other concerns that we haven't sufficiently addressed so far. If you know of some off the top of your head, feel free to post them as a reply to this comment. I'd be happy to either expand on my thoughts or address the issue immediately.</p>\n", "parentCommentId": "ENvC7u4HBXumnAfaM", "user": {"username": "Kerry_Vaughan"}}, {"_id": "uTD69utiv9rfbxWsR", "postedAt": "2017-04-23T19:32:52.171Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<blockquote>\n<p>I'm not sure that's true. There are a lot of venture funds in the Valley but that doesn't mean it's easy to get any venture fund to give you money.</p>\n</blockquote>\n<p>I don't have the precise statistics handy, but my understanding is that VC returns are very good for a small number of firms and break-even or negative for most VC firms. If that's the case, it suggests that as more VCs enter the market, more bad companies are getting funded.</p>\n", "parentCommentId": "6qSDYgYLNcioh2ux2", "user": {"username": "Kerry_Vaughan"}}, {"_id": "a7hxgNpdqi5ZknA9S", "postedAt": "2017-04-24T01:32:39.653Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>There's no shortage of bad ventures in the Valley:\n<a href=\"https://thenextweb.com/gadgets/2017/04/21/this-400-juicer-that-does-nothing-but-squeeze-juice-packs-is-peak-silicon-valley/#.tnw_Aw4G0WDt\">https://thenextweb.com/gadgets/2017/04/21/this-400-juicer-that-does-nothing-but-squeeze-juice-packs-is-peak-silicon-valley/#.tnw_Aw4G0WDt</a></p>\n<p><a href=\"http://valleywag.gawker.com/is-the-grilled-cheese-startup-silicon-valleys-most-elab-1612937740\">http://valleywag.gawker.com/is-the-grilled-cheese-startup-silicon-valleys-most-elab-1612937740</a></p>\n<p>Of course, there are plenty of other bad ventures that don't get funding...</p>\n", "parentCommentId": "6qSDYgYLNcioh2ux2", "user": {"username": "Daniel_Eth"}}, {"_id": "eq9Fe2zmJaKsDd3bA", "postedAt": "2017-04-24T03:09:17.240Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>Not sure if this is the right place to say this, but on effectivealtruism.org where it links to &quot;Donate Effectively,&quot; I think it would make more sense to link to GiveWell and ACE ahead of the EA Funds, because GiveWell and ACE are more established and time-tested ways of making good donations in global poverty and animal welfare.</p>\n<p>(The downside is this adds complexity because now you're linking to two types of things instead of one type of thing, but I would feel much better about CEA endorsing GiveWell/ACE as the default way to give rather than its own funds, which are controlled by a single person and don't have the same requirement (or ability!) to be transparent.)</p>\n", "parentCommentId": null, "user": {"username": "MichaelDickens"}}, {"_id": "J6ZciYSpG2Ms8kjDa", "postedAt": "2017-04-24T03:11:23.452Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<blockquote>\n<p>There's no shortage of bad ventures in the Valley</p>\n</blockquote>\n<p>Every time in the past week or so that I've seen someone talk about a bad venture, they've given the same example. That suggests that there is indeed a shortage of bad ventures--or at least, ventures bad enough to get widespread attention for how bad they are. (Most ventures are &quot;bad&quot; in a trivial sense because most of them fail, but many failed ideas looked like good ideas ex ante.)</p>\n", "parentCommentId": "a7hxgNpdqi5ZknA9S", "user": {"username": "MichaelDickens"}}, {"_id": "rt4mSbDX9bpzNJnDm", "postedAt": "2017-04-24T03:28:44.535Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>This is a huge digression, but:</p>\n<p>I'm not sure it's obvious that current VCs fund all the potentially top companies. If you look into the history of many of the biggest wins, many of them nearly failed multiple times and could have easily shut down if a key funder didn't exist (e.g. Airbnb and YC).</p>\n<p>I think a better approximation is an efficient market, in which the risk-adjusted returns of VC at the margin are equal to the market. This means that the probability of funding a winner for a marginal VC is whatever it would take for their returns to equal the market.</p>\n<p>Then also becoming a VC, to a first order, has no effect on the cost of capital (which is fixed to the market), so no effect on the number of startups formed. So you're right that additional VCs aren't helpful, but it's for a different reason.</p>\n<p>To a second order, there probably are benefits, depending on how skilled you are. The market for startups doesn't seem very efficient and requires specialised knowledge to access. If you develop the VC skill-set, you can reduce transaction costs and make the market for startups more efficient, which enables more to be created. </p>\n<p>Moreover, the more money that gets invested rather than consumed, the lower the cost of capital in the economy, which lets more companies get created.</p>\n<p>The second order benefits probably diminish as more skilled VCs enter, so that's another sense in which extra VCs are less useful than those we already have.</p>\n", "parentCommentId": "uTD69utiv9rfbxWsR", "user": {"username": "Benjamin_Todd"}}, {"_id": "HNjPcs9aDwvdEtKNT", "postedAt": "2017-04-24T04:32:46.359Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>Or that there's one recent venture that's so laughably bad that everyone is talking about it right now...</p>\n", "parentCommentId": "J6ZciYSpG2Ms8kjDa", "user": {"username": "Daniel_Eth"}}, {"_id": "MaRsbriZz6Zz8JQbd", "postedAt": "2017-04-24T07:46:39.648Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>I don't think the argument that there are a lot of VC firms that don't get good returns suggest that centralization into one VC firm would be good.\nThere are different successful VC firms that have different preferences in how to invest. </p>\n<p>Having one central hub of decision making is essentially the model used in the Soviet Union. I don't think that's a good model.</p>\n<p>Decentral decision making usually beats central planning with one single decision making authority in domain with a lot of spread out information.  </p>\n", "parentCommentId": "uTD69utiv9rfbxWsR", "user": {"username": "ChristianKleineidam"}}, {"_id": "ctCf6GStncTYBy7Q9", "postedAt": "2017-04-24T08:13:49.213Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>It's not clear that Juicero is actually a bad venture in the sense that doesn't return the money for it's investors. </p>\n<p>Even if that would be the case, VC's make most of the money with a handful companies. A VC can have a good fund if 90% of their investments don't return their money.</p>\n<p>I would guess that the same is true for high risk philanthropic investments. It's okay if some high risk investments don't provide value as long as you are betting on some investments that deliever.</p>\n", "parentCommentId": "a7hxgNpdqi5ZknA9S", "user": {"username": "ChristianKleineidam"}}, {"_id": "8Ygurmofq4h92onvW", "postedAt": "2017-04-24T09:30:24.072Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>I've discussed this with Owen a bit further. How emotions relate to norms of discourse is a tricky topic but I personally think many people would agree on the following pointers going forward (not addressed to Fluttershy in particular):</p>\n<p>Dos:</p>\n<ul>\n<li>flag your emotions when they are relevant to the discussion. e.g. &quot;I became sick of redrafting this post so please excuse if it comes across as grumpy&quot;, or &quot;These research problems seem hard and I'm unmotivated to try to work more on them&quot;.</li>\n<li>discuss emotional issues relevant to many EAs</li>\n</ul>\n<p>Don'ts:</p>\n<ul>\n<li>use emotion as a rhetorical boost for your arguments (appeal to emotion)</li>\n<li>mix arguments together with calls for social support</li>\n<li>mix arguments with personal emotional information that would make an EA (or regular) audience uncomfortable.</li>\n</ul>\n<p>Of course, if you want to engage emotionally with a specific people, you can use private messages.</p>\n", "parentCommentId": "ahk7Nx2HT3cCCdcNs", "user": {"username": "RyanCarey"}}, {"_id": "avFBPLvDC6d9kpnB7", "postedAt": "2017-04-24T12:59:57.420Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>The basic dynamic doesn't apply. This isn't about the name, it's about the concept. You can't make an extension from the literature without mathematically showing that the concept is still relevant!</p>\n<p>If there's potential utility to be had in multiple people taking the same action, then people are just as likely to err in the form of donating too little money as they are to donate too much. The only reason the unilateralist's curse is a problem is that there is no benefit to be had from lots of agents taking the same action, which prevents the expected value of a marginal naive EV-maximizing agent's action from being positive.</p>\n", "parentCommentId": "8diArRWQNsLaLavWF", "user": {"username": "kbog"}}, {"_id": "aiBKti25sfQat2Hdt", "postedAt": "2017-04-24T16:51:27.216Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>The kind of set-up where it would apply:</p>\n<ul>\n<li>An easy-to-evaluate opportunity which produces 1 util/$, which everyone correctly evaluates</li>\n<li>100 hard-to-evaluate opportunities each of which actually produces 0.1 util / $, but where everyone has an independent estimate of cost-effectiveness which is a log-normal centered on the truth</li>\n</ul>\n<p>Then for any individual the're likely to think one of the 100 is best and donate there. If they all pooled their info they would instead all donate to the first opportunity.</p>\n<p>Obviously the numbers and functional form here are implausible -- I chose them for legibility of the example. It's a legitimate question how strongly the dynamic applies in practice. But it seems fairly clear to me that it can apply. You suggested there's a symmetry with donating too little -- I think this is broken because people are selecting the top option, so they are individually running into the <a href=\"https://faculty.fuqua.duke.edu/~jes9/bio/The_Optimizers_Curse.pdf\">optimizer's curse</a>.</p>\n", "parentCommentId": "avFBPLvDC6d9kpnB7", "user": {"username": "Owen_Cotton-Barratt"}}, {"_id": "GmdArpYFhpMrZPfP2", "postedAt": "2017-04-24T21:38:50.667Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>Allocating grants according to a ranked preference vote of an arbitrary amount of people (and having them write up their arguments); what is the optimal number here? Where is the inflection point where adding more people decreases the quality of the grants?</p>\n<p>On tertiary reading I somewhat misconstrued &quot;three fund managers&quot; as &quot;three fund managers per fund&quot; rather than &quot;the three fund managers we have right now (Nick, Elie, Lewis)&quot;, but the possibility is still interesting with any variation.</p>\n", "parentCommentId": "7fNnn3vqttqZoNNSX", "user": {"username": "DonyChristie"}}, {"_id": "mnEnwLaZMgq4zvgTM", "postedAt": "2017-04-25T02:11:02.402Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>That's a good question. I did intend &quot;three fund managers&quot; to mean &quot;the three fund managers we have right now&quot;, but I could also see the optimal number of people being 2-3.</p>\n", "parentCommentId": "GmdArpYFhpMrZPfP2", "user": {"username": "Peter_Hurford"}}, {"_id": "9kQvuHBKzjBtzYEN7", "postedAt": "2017-04-25T05:16:14.015Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>Have you even read Bostrom's paper? This isn't the unilateralist's curse. You are not extending a principle of the paper, you are rejecting its premise from the start. I don't understand how this is not obvious. </p>\n<p>You are merely restating the optimizer's curse, and the easy solution there is for people to read Givewell's blog post about it. If someone has, then the only way their decisions can be statistically biased is if they have the wrong prior distributions, which is something that nobody can be sure about anyway, and therefore is wholly inappropriate as the grounds for any sort of overruling of donations. But even if it were appropriate, having a veto would simply be the wrong thing to do, since (as noted above) the unilateralist's curse is no longer present, and you're going to have to find a better strategy that corrects for improper priors in accordance with the actual situation.</p>\n<blockquote>\n<p>But it seems fairly clear to me that it can apply. </p>\n</blockquote>\n<p>It also seems fairly clear to me that the opposite can apply  - e.g., if giving opportunities are normally distributed and people falsely believe them to be lognormal, then they will give too much to the easy-to-evaluate opportunity.</p>\n", "parentCommentId": "aiBKti25sfQat2Hdt", "user": {"username": "kbog"}}, {"_id": "oWK6w64dNB6zLRp6S", "postedAt": "2017-04-25T09:03:38.902Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>I find your comments painfully uncharitable, which really reduces my inclination to engage. If you can't find an interpretation of my comment which isn't just about the optimizer's curse I don't feel like helping you right now.</p>\n<p>Agree that vetoes aren't the right solution, though (indeed they are themselves subject to a unilateralist's curse, perhaps of a worse type).</p>\n", "parentCommentId": "9kQvuHBKzjBtzYEN7", "user": {"username": "Owen_Cotton-Barratt"}}, {"_id": "T3M7AYAQxM3MRfHGT", "postedAt": "2017-04-25T17:19:29.247Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<blockquote>\n<p>This is more or less what happened with EA Ventures -- lots of people thought it was a good idea, but not many promising projects showed up and not many funders actually donated to the projects we happened to find.</p>\n</blockquote>\n<p>It seems like the character of the EA movement needs to be improved somehow, (probably, as always, there are marginal improvements to the implementation too) but especially the character of the movement because arguably if EA could spawn many projects, its impact would be increased many-fold.</p>\n", "parentCommentId": "x8fHzLiKkcnzbjfs6", "user": {"username": "RyanCarey"}}, {"_id": "bDPGXeNMDqivDkSR5", "postedAt": "2017-04-26T23:48:48.686Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>I'm shocked that no one has commented on Elie Hassenfeld distributing 100% of money to GiveWell's top charity.  Even if he didn't run GiveWell, this just seems like an extra step between giving to GiveWell.  But given that one of the main arguments for the funds was to let smaller projects get funded quickly and with less overhead, giving 100% to one enormous charity with many large donors is clearly failing at a goal.  </p>\n<p>I would guess that $300k simply isn't worth Elie's time to distribute in small grants, given the enormous funds available via GoodVentures and even GiveWell direct and directed donations.  It seems to me the obvious thing is to is have the fund managed by someone who has the time to do so, rather than make another way to give money to GiveWell.</p>\n", "parentCommentId": null, "user": {"username": "Elizabeth"}}, {"_id": "5LKvtGyydqrB8m4v9", "postedAt": "2017-04-27T00:22:58.177Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>I hadn't considered the unilateralist's curse and I'll keep this in mind.</p>\n<p>To what extent do you think it's sustainable to </p>\n<p>a) advocate for a centralised system run by trusted professionals VS. </p>\n<p>b) building up the capacity of individual funders to recognise activities that are generally seen as problematic/negative EV by cause prioritisation researchers?</p>\n<p>Put simply, I wonder if going for a) centralisation would make the 'system' fragile because EA donors would be less inclined to build up their awareness of big risks. For those individual donors who'd approach cause-selection with rigour and epistemic humility, I can see b) being antifragile. But for those approaching it amateuristically/sloppily, it makes sense to me that they're much better off handing over their money and employing their skills elsewhere.</p>\n<p>I admit I don't have a firm grasp of unilateralist's curse scenarios.</p>\n", "parentCommentId": "dDqccbkt2YkxBAxcR", "user": {"username": "remmelt"}}, {"_id": "zGpuEkRkvHNvZWRrq", "postedAt": "2017-04-27T00:52:21.503Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>I haven't looked much into this but basically I'm wondering if simple, uniform promotion of EA Funds would undermine the capacity of community members in say the upper quartile of rationality/commitment to built robust idea sharing and collaboration networks. </p>\n<p>In other words, whether it would decrease their <a href=\"https://en.wikipedia.org/wiki/Collective_intelligence\">collective intelligence</a> pertaining to solving cause-selection problems. I'm really interested in getting practical insights on improving the collective intelligence of a community (please send me links: remmeltellenis[at]gmail.dot.com)</p>\n<p>My earlier comment seems related to this: </p>\n<blockquote>\n<p>Put simply, I wonder if going for a) centralisation would make the 'system' fragile because EA donors would be less inclined to build up their awareness of big risks. For those individual donors who'd approach cause-selection with rigour and epistemic humility, I can see b) being antifragile. But for those approaching it amateuristically/sloppily, it makes sense to me that they're much better off handing over their money and employing their skills elsewhere.</p>\n</blockquote>\n<p>(Btw, I admire your openness to improving analysis here.)</p>\n", "parentCommentId": "EoyJQKXTrYdrxueGP", "user": {"username": "remmelt"}}, {"_id": "REojwRDFm97fsLbPY", "postedAt": "2017-04-27T00:54:08.816Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<blockquote>\n<p>Will's post introducing the EA funds is the 4th most upvoted post of all time on this forum.</p>\n</blockquote>\n<p>Generally I upvote a post because I am <em>glad that the post has been posted in this venue</em>, not because I am <em>happy about the facts being reported</em>. Your comment has reminded me to upvote Will's post, because I'm glad he posted it (and likewise Tara's) - thanks!</p>\n", "parentCommentId": "bpPEvanKiRNBzGDPj", "user": {"username": "BenHoffman"}}, {"_id": "SkpeqQSLRsMCRLLvJ", "postedAt": "2017-04-27T01:09:16.661Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<blockquote>\n<p>I also dislike that you emphasize that some people &quot;expressed confusion at your endorsement of EA Funds&quot;. Some people may have felt that way, but your choice of wording both downplays the seriousness of some people's disagreements with EA Funds, while also implying that critics are in need of figuring something out that others have already settled (which itself socially implies they're less competent than others who aren't confused). </p>\n</blockquote>\n<p>I definitely perceived the sort of strong exclusive endorsement and pushing EA Funds got as a direct contradiction of what I'd been told earlier, privately and publicly - that this was an MVP experiment to gauge interest and feasibility, to be reevaluated after three months. If I'm confused, I'm <strong><em>confused about how this wasn't just a lie</em></strong>. My initial response was &quot;HOW IS THIS OK???&quot; (verbatim quote). I'm willing to be persuaded, of course. But, barring an actual resolution of the issue, simply describing this as confusion is a pretty substantial understatement.</p>\n<p>ETA: I'm happy with the update to the OP and don't think I have any unresolved complaint on this particular wording issue.</p>\n", "parentCommentId": "njAzoBoMrh853FyWR", "user": {"username": "BenHoffman"}}, {"_id": "JmGBz6AJhS26jzoRm", "postedAt": "2017-04-27T01:13:59.881Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>Or to simply say &quot;for global poverty, we can't do better than GiveWell so we recommend you just give them the money&quot;.</p>\n", "parentCommentId": "bDPGXeNMDqivDkSR5", "user": {"username": "BenHoffman"}}, {"_id": "L5dE3XrMpJkcKvcug", "postedAt": "2017-04-27T01:21:08.867Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>On the other hand, it does seem worthwhile to funnel money through different intermediaries sometimes if only to independently confirm that the obvious things are obvious, and we probably don't want to advocate contrarianism for contrarianism's sake. If Elie had given the money elsewhere, that would have been strong evidence that the other thing was valuable and underfunded relative to GW top charities (and also worrying evidence about GiveWell's ability to implement its founders' values). Since he didn't, that's at least weak evidence that AMF is the best global poverty funding opportunity we know about.</p>\n<p>Overall I think it's good that Elie didn't feel the need to justify his participation by doing a bunch of makework. This is still evidence that channeling this through Elie probably gives a false impression of additional optimizing power, but I think that should have been our strong prior anyhow.</p>\n", "parentCommentId": "bDPGXeNMDqivDkSR5", "user": {"username": "BenHoffman"}}, {"_id": "CEAw9qRTMYv6hd7y6", "postedAt": "2017-04-27T01:24:10.144Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<blockquote>\n<p>I would guess that $300k simply isn't worth Elie's time to distribute in small grants, given the enormous funds available via GoodVentures and even GiveWell direct and directed donations.</p>\n</blockquote>\n<p>This is consistent with the optionality story in the <a href=\"http://effective-altruism.com/ea/17v/ea_funds_beta_launch/\">beta launch post</a>:</p>\n<blockquote>\n<p>If the EA Funds raises little money, they can spend little additional time allocating the EA Funds\u2019 money but still utilize their deep subject-matter expertise in making the allocation. This reduces the chance that the EA Funds causes fund managers to use their time ineffectively and it means that the lower bound of the quality of the donations is likely to be high enough to justify donations even without knowing the eventual size of the fund.</p>\n</blockquote>\n<p>However, I do think this suggests that - to the extent to which GiveWell is already a known and trusted institution - for global poverty in particular it's more important to get the fund manager with the <em>most unique</em> relevant expertise than a fund manager with the <em>most</em> expertise.</p>\n", "parentCommentId": "bDPGXeNMDqivDkSR5", "user": {"username": "BenHoffman"}}, {"_id": "8B585f2y2yySKAteN", "postedAt": "2017-04-27T01:37:08.140Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<blockquote>\n<p>If Elie had given the money elsewhere, that would have been strong evidence that the other thing was valuable and underfunded relative to GW top charities.</p>\n</blockquote>\n<p>Only if GiveWell and the EA Fund are both supposed to be perfect expressions of Elie's values.  GiveWell has a fairly specific mission which includes not just high expected value but high certainty (compared to the rest of the field, which is a low bar).  EA Funds was explicitly supposed to be more experimental.  Like you say below, if organizers don't think you can beat GiveWell, encourage donating to GiveWell.</p>\n", "parentCommentId": "L5dE3XrMpJkcKvcug", "user": {"username": "Elizabeth"}}, {"_id": "gsraZTyiD8Wu3r6k2", "postedAt": "2017-04-27T02:02:22.416Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>Agreed - it definitely seems reasonable to me, and very consistent with GiveWell's overall approach, that Elie sincerely believes that donating to AMF is the best use of funds.</p>\n", "parentCommentId": "JmGBz6AJhS26jzoRm", "user": {"username": "Peter_Hurford"}}, {"_id": "Nhivaef4iJBzmAkbe", "postedAt": "2017-04-27T02:03:01.982Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>It's worth noting that it's all pretty fungible anyway. GiveWell could have just as easily claimed the money was going toward an incubation grant and then put more incubation grant money toward AMF.</p>\n", "parentCommentId": "bDPGXeNMDqivDkSR5", "user": {"username": "Peter_Hurford"}}, {"_id": "mjraZvyDGxgkG5ejJ", "postedAt": "2017-04-27T02:48:52.454Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>This seems like an excellent reason to have someone uninvolved with an existing large organization administer the fund.</p>\n", "parentCommentId": "Nhivaef4iJBzmAkbe", "user": {"username": "Elizabeth"}}, {"_id": "nmEeSi2Asyym6JMWX", "postedAt": "2017-04-27T07:46:31.180Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>I forgot to do a disclosure here (to reveal potential bias):</p>\n<p>I'm working on the <a href=\"https://www.facebook.com/groups/easafetynet/\">EA Community Safety Net project</a> with other committed people, which just started on 31 March. We're now shifting direction from focusing on peer insurance against income loss to building a broader peer-funding platform in a Slack Team that also includes project funding and loans. </p>\n<p>It will likely fail to become a thriving platform that hosts multiple financial instruments given the complexities involved and the past project failures I've seen on .impact. Having said that, we're aiming high and I'm guessing there's a 20% chance that it will succeed. </p>\n<p>I'd especially be interested in hearing people's thoughts on structuring the application form (i.e. criteria for project framework) to be able to reduce Unilateralist's Curse scenarios as much as possible (and other stupid things we could cause as entrepreneurial creators who are moving away from the status quo). </p>\n<p>Is there actually a list of 'bad strategies naive EAs could think off' where there's a consensus amongst researchers that one party's decision to pursue one of them will create systemic damage on an expected value basis? A short checklist (that I can go through before making an important decision) based on surveys would be really useful to me. </p>\n<p>Come to think of this: I'll start by with a quick Facebook poll in the general EA group. That sounds useful for compiling an initial list.</p>\n<p>Any other opinions on preventing risks here are really welcome. I'm painfully aware of my ignorance here.  </p>\n", "parentCommentId": "EoyJQKXTrYdrxueGP", "user": {"username": "remmelt"}}, {"_id": "z8Lvt3EE9SNtJcTfb", "postedAt": "2017-04-28T01:10:04.289Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>Alternatively, you could have global poverty and animal welfare funds that are unmanaged and just direct money to GiveWell/ACE top charities (or maybe have some light management to determine how to split funds among the top charities).</p>\n", "parentCommentId": "eq9Fe2zmJaKsDd3bA", "user": {"username": "MichaelDickens"}}, {"_id": "TbxWoDbDFbp5xXsbR", "postedAt": "2017-04-30T10:48:40.324Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>That seems like a good use of the upvote function, and I'm glad you try to do things that way. But my nit-picking brain generates a couple of immediate thoughts:</p>\n<ol>\n<li><p>I don't think it's a coincidence that a development you were concerned about was also one where you forgot* to apply your general rule. In practice I think upvotes track 'I agree with this' extremely strongly, even though lots of people (myself included) agree that ideally they shouldn't.</p>\n</li>\n<li><p>In the hypothetical where there's lots of community concern about the funds but people are happy they have a venue to discuss it, I expect the top-rated comments to be those expressing those concerns. This possibility is what I was trying to address in my next sentence:</p>\n</li>\n</ol>\n<blockquote>\n<p>Most of the top rated comments on his post, including at least one which you link to as raising concerns, say that they are positive about the idea.</p>\n</blockquote>\n<p>*Not sure if 'forgot' is quite the right word here, just mirroring your description of my comment as 'reminding' you.</p>\n", "parentCommentId": "REojwRDFm97fsLbPY", "user": {"username": "AGB"}}, {"_id": "bHLgjMQWjK4QCvtjN", "postedAt": "2017-04-30T12:22:24.700Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>(Sorry for the slower response, your last paragraph gave me pause and I wanted to think about it. I still don't feel like I have a satisfactory handle on it, but also feel I should reply at this point.)</p>\n<blockquote>\n<p>this makes me feel slightly uneasy given that a survey may weight the opinions of people who have considered the problem less or feel less strongly about it equally with the opinions of others.</p>\n</blockquote>\n<p>This makes total sense to me, and I do currently perceive something of an inverse correlation between how hard people have thought about the funds and how positively they feel about them. I agree this is a cause for concern. The way I would describe that situation from your perspective is not 'the funds have not been well-received', but rather 'the funds have been well-received <em>but</em> only because too many (most?) people are analysing the idea in a superficial way'. Maybe that is what you were aiming for originally and I just didn't read it that way.</p>\n<blockquote>\n<p>But what we likely care about is whether or not the community is positive on EA Funds at the moment, which may or may not be different from whether it was positive on EA Funds in the past.</p>\n</blockquote>\n<p>True. That post was only a couple of months before this one though; not a lot of time for new data/arguments to emerge or opinions to change. The only major new data point I can think of since then is the funds raising ~$1m, which I think is mostly orthogonal to what we are discussing. I'm curious whether you personally a perceive a <em>change</em> (drop) in popularity in your circles?</p>\n<blockquote>\n<p>My view is further that the community's response to this sort of thing is partly a function of how debates on honesty and integrity have been resolved in the past; if lack of integrity in EA has been an issue in the past, the sort of people who care about integrity are less likely to stick around in EA, such that the remaining population of EAs will have fewer people who care about integrity, which itself affects how the average EA feels about future incidents relating to integrity (such as this one), and so on. So, on some level I'm positing that the public response to EA Funds would be more negative if we hadn't filtered certain people out of EA by having an integrity problem in the first place.</p>\n</blockquote>\n<p>This story sounds plausibly true. It's a difficult one to falsify though (I could flip all the language and get something that also sounds plausibly true), so turning it over in my head for the past few days I'm still not sure how much weight to put on it.</p>\n", "parentCommentId": "ec5jfqB4qRg6wqn6S", "user": {"username": "AGB"}}, {"_id": "TpeB4xyHvPQzewWw7", "postedAt": "2017-05-04T13:42:32.268Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<blockquote>\n<p>I find your comments painfully uncharitable, which really reduces my inclination to engage. </p>\n</blockquote>\n<p>Really? I haven't misinterpreted you in any way. I think the issue is that you don't like my comments because I'm not being very nice. But you should be able to deal with comments which aren't very nice.</p>\n<blockquote>\n<p>If you can't find an interpretation of my comment which isn't just about the optimizer's curse I don't feel like helping you right now.</p>\n</blockquote>\n<p>Yes, it's specifically <em>the effect of the optimizer's curse in situations where the better options have more uncertainty regarding their EV estimates</em>, but that's the only time that the optimizer's curse is decision relevant <em>anyway</em>, since all other instantiations of the optimizer's curse modify expected utilities without doing anything to change the ordinal ranking. And the fact that this happens to be a case with 100 uncertain options rather than 1, or a large group of donors rather than just one, doesn't modify the basic issue that people's choices will be suboptimal, so the fact that you specified a very particular scenario doesn't make it about anything other than the basic optimizer's curse.</p>\n", "parentCommentId": "oWK6w64dNB6zLRp6S", "user": {"username": "kbog"}}, {"_id": "RtrubgAd3p6aRDw8x", "postedAt": "2017-07-04T19:45:07.008Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>One note on this: blockchain-based DAOs (decentralized autonomous organizations) are a good way to decentralize a giving body (like EAFunds). Rhodri Davies has been doing good work in this space (on AI-led DAOs for effective altruism). See <a href=\"https://givingthought.libsyn.com/algorithms-and-effective-altruism\">https://givingthought.libsyn.com/algorithms-and-effective-altruism</a> or my recent overview of EA + Blockchain: <a href=\"https://medium.com/@RhysLindmark/creating-a-humanist-blockchain-future-2-effective-altruism-blockchain-833a260724ee\">https://medium.com/@RhysLindmark/creating-a-humanist-blockchain-future-2-effective-altruism-blockchain-833a260724ee</a></p>\n", "parentCommentId": "o8To79uBFx5RkeWKZ", "user": {"username": "rhys_lindmark"}}, {"_id": "mZjqAkgQwZwuyYq9j", "postedAt": "2018-07-08T18:11:17.523Z", "postId": "MsaS8JKrR8nnxyPkK", "htmlBody": "<p>Kerry's argument was that centralization helps prevent false positives.  I was trying to show that there are other ways to prevent false positives.</p>\n<p>With regard to false negatives, I would guess that centralization exacerbates that problem-- a decentralized group of funders are more likely to make decisions using a diverse set of paradigms.</p>\n", "parentCommentId": "rKwBP7CKRD3uA9shx", "user": {"username": "John_Maxwell_IV"}}]