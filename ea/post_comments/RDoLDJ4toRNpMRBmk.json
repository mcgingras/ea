[{"_id": "s5i2GmtXCBjLZECu8", "postedAt": "2022-10-12T00:08:19.535Z", "postId": "RDoLDJ4toRNpMRBmk", "htmlBody": "<p>I don\u2019t endorse judging AI safety organisations by less wrong consensus alone - I think you should at least read the posts!</p>\n", "parentCommentId": null, "user": {"username": "David Johnston"}}, {"_id": "H7jDDhSk6GRWa3LsK", "postedAt": "2022-10-12T04:25:16.483Z", "postId": "RDoLDJ4toRNpMRBmk", "htmlBody": "<p>Seems worth asking in interviews \"I'm concerned about advancing capabilities and shortening timelines, what actions is your organization taking to prevent that\", with the caveat that you will be BSed.</p><p>Bonus: You can turn down roles explicitly because they're doing capabilities work, which if it becomes a pattern may incentivize them to change their plan.</p>", "parentCommentId": null, "user": {"username": "Rubi"}}, {"_id": "igFzcCwFa8wDRPmKZ", "postedAt": "2022-10-12T05:16:42.294Z", "postId": "RDoLDJ4toRNpMRBmk", "htmlBody": "<p>Seems like there is a big gap between \"Study AI Safety for 2 years before you apply\" and reading posts, rather than just the most up-voted comments.</p>\n", "parentCommentId": null, "user": {"username": "WilliamKiely"}}, {"_id": "fZTRHxTWCBaHMj9zo", "postedAt": "2022-10-12T05:21:38.665Z", "postId": "RDoLDJ4toRNpMRBmk", "htmlBody": "<p>Other feedback: I don't understand why you call some of your suggestions \"crazy\"/\"crazier\". Also when you wrote \"less joklingly\" I had missed the joke. Perhaps your suggestions could be rewritten to be more clear without these words.</p>\n", "parentCommentId": "igFzcCwFa8wDRPmKZ", "user": {"username": "WilliamKiely"}}, {"_id": "xtRGBMJAizX9vKzsC", "postedAt": "2022-10-12T05:23:02.261Z", "postId": "RDoLDJ4toRNpMRBmk", "htmlBody": "<p>I think this is fairly bad advice - LessWrong commenters are wrong about a <i>lot </i>of things. I think this is an acceptable way to get a vibe for the what the LessWrong bubble thinks though. But idk, for most of these questions the hard part is figuring out <i>which </i>bubble to believe. Most orgs will have some groups think they're useless, some think they're great, and probably some who think they're net negative. Finding one bubble who believes one of these three doesn't tell you much!</p>", "parentCommentId": null, "user": {"username": "Neel Nanda"}}, {"_id": "NELK4CtxgcpKY83jB", "postedAt": "2022-10-12T06:33:32.672Z", "postId": "RDoLDJ4toRNpMRBmk", "htmlBody": "<p>Thinking about where to work seems reasonable, listening to others' thoughts on where to work seems reasonable, this post advises both.</p>\n<p>This post also pretty strongly suggests that lesswrong comments are the best choice of others' thoughts, and I would like to see that claim made explicit and then argued for rather than slipped in. As a couple of other comments have noted, lesswrong is far from a perfect signal of the alignment space.</p>\n", "parentCommentId": null, "user": {"username": "alexrjl"}}, {"_id": "mJe7WvjhGSXgutYvX", "postedAt": "2022-10-12T07:39:54.272Z", "postId": "RDoLDJ4toRNpMRBmk", "htmlBody": "<p>Thanks for the pushback!</p><p>Do you have an alternative suggestion?</p>", "parentCommentId": "xtRGBMJAizX9vKzsC", "user": {"username": "hibukki"}}, {"_id": "CaupZujFsFbuMzTqy", "postedAt": "2022-10-12T07:41:45.671Z", "postId": "RDoLDJ4toRNpMRBmk", "htmlBody": "<p>Thanks for the push back!</p><p><a href=\"https://forum.effectivealtruism.org/posts/RDoLDJ4toRNpMRBmk/which-ai-safety-org-to-join#Bonus__Read_the_comments\">Added</a> this to the post</p>", "parentCommentId": "s5i2GmtXCBjLZECu8", "user": {"username": "hibukki"}}, {"_id": "acWvmJpTfXp3nTduk", "postedAt": "2022-10-12T07:42:45.002Z", "postId": "RDoLDJ4toRNpMRBmk", "htmlBody": "<p>Thanks (also) for the pushback part!</p><p>Do you have an alternative to lesswrong comments that you'd suggest?</p>", "parentCommentId": "NELK4CtxgcpKY83jB", "user": {"username": "hibukki"}}, {"_id": "v9dhDyCc5TujBwGHq", "postedAt": "2022-10-12T07:46:56.513Z", "postId": "RDoLDJ4toRNpMRBmk", "htmlBody": "<p>The joke is supposed to be that \"reading the post\" isn't actually that crazy. I see this wasn't understood (oops!). I'm going to start by trying to get the content right (since lots of people pushed back on it) and then try fixing this too</p>", "parentCommentId": "fZTRHxTWCBaHMj9zo", "user": {"username": "hibukki"}}, {"_id": "wgfhFuZGiFHCFsWiD", "postedAt": "2022-10-12T07:48:09.509Z", "postId": "RDoLDJ4toRNpMRBmk", "htmlBody": "<p>I didn't understand, could you say this in other words please?</p><p>Or did you mean it like this:</p><blockquote><p>Seems like there is a big gap between [\"Study AI Safety for 2 years before you apply\" and reading posts], rather than [just the most up-voted comments].</p></blockquote><p>?</p>", "parentCommentId": "igFzcCwFa8wDRPmKZ", "user": {"username": "hibukki"}}, {"_id": "BczLXTtAHEwpLRcPK", "postedAt": "2022-10-12T07:49:05.471Z", "postId": "RDoLDJ4toRNpMRBmk", "htmlBody": "<p>I agree, see foot note 2</p>", "parentCommentId": "H7jDDhSk6GRWa3LsK", "user": {"username": "hibukki"}}, {"_id": "tJfjiSEwo9RrFgey7", "postedAt": "2022-10-12T07:53:00.487Z", "postId": "RDoLDJ4toRNpMRBmk", "htmlBody": "<p>By the way, I personally <a href=\"https://forum.effectivealtruism.org/posts/6tJsFxy66oJCzkkMb/concrete-advice-for-forming-inside-views-on-ai-safety?commentId=ZhrdAmumhpqFJKTEJ#comments\">resonate</a> with your advice on forming an inside view and am taking that path, but it doesn't fit everyone. Some people don't want all that homework, they want to get in a company and write code, and, to be clear, it is common for them to apply to all orgs that [they see their names in EA spaces] or something like that (very wide, many orgs). This is the target audience I'm trying to help.</p>", "parentCommentId": "mJe7WvjhGSXgutYvX", "user": {"username": "hibukki"}}, {"_id": "WDE8wXotLHpQmsYYy", "postedAt": "2022-10-12T17:07:05.178Z", "postId": "RDoLDJ4toRNpMRBmk", "htmlBody": "<p>I meant it like that, yes. Seems like there is a big gap between [\"Study AI Safety for 2 years before you apply\" and reading posts].</p>", "parentCommentId": "wgfhFuZGiFHCFsWiD", "user": {"username": "WilliamKiely"}}, {"_id": "wFQLYFLN42BL2mt5h", "postedAt": "2022-10-13T09:47:18.680Z", "postId": "RDoLDJ4toRNpMRBmk", "htmlBody": "<p>I personally interpret Neel's comment as saying this is ~not better (perhaps worse) than going in blindly. So I just wanted to highlight that a better alternative is not needed for the sake of arguing this (even if it's a good idea to have one for the sake of future AI researchers).</p>\n", "parentCommentId": "mJe7WvjhGSXgutYvX", "user": {"username": "Guy Raveh"}}, {"_id": "imy94qq5xE4RhCetn", "postedAt": "2022-10-13T11:32:49.013Z", "postId": "RDoLDJ4toRNpMRBmk", "htmlBody": "<p>So what would you suggest? Reading a few posts about that org?</p>", "parentCommentId": "WDE8wXotLHpQmsYYy", "user": {"username": "hibukki"}}, {"_id": "iKru4bcbSk47BTrQz", "postedAt": "2022-10-13T11:34:30.297Z", "postId": "RDoLDJ4toRNpMRBmk", "htmlBody": "<p>Do you think that going to do capabilities work at DeepMind or OpenAI is just as impactful as going to whatever the lesswrong community recommends (as presented by their comments and upvotes) ?</p>", "parentCommentId": "wFQLYFLN42BL2mt5h", "user": {"username": "hibukki"}}, {"_id": "vgZguaeLcrckSRzR9", "postedAt": "2022-10-13T11:42:24.135Z", "postId": "RDoLDJ4toRNpMRBmk", "htmlBody": "<p>Possibly. As we've discussed privately, I think some AI safety groups which are usually lauded are actually net negative \ud83d\ude43</p>\n<p>But I was trying to interpret Neel and not give my own opinion.</p>\n", "parentCommentId": "iKru4bcbSk47BTrQz", "user": {"username": "Guy Raveh"}}, {"_id": "KcHiEHvh3gkdGxeQq", "postedAt": "2022-10-13T14:49:41.067Z", "postId": "RDoLDJ4toRNpMRBmk", "htmlBody": "<p>My meta-opinion is that it would be better to see what others think about working on capabilities in top labs, compared to going there without even considering the downsides. What do you think? (A)</p><p>And also that before working at \"AI safety groups which are usually lauded [but] are actually net negative\", it would be better to read comments of people like you. What do you think? (B)</p>", "parentCommentId": "vgZguaeLcrckSRzR9", "user": {"username": "hibukki"}}, {"_id": "f8Nyug6WGdydTdQFE", "postedAt": "2022-10-13T15:29:52.011Z", "postId": "RDoLDJ4toRNpMRBmk", "htmlBody": "<p>I somewhat disagree with both statements.</p>\n<p>(A) Sure, it'd be good to have opinions from relevant people, but on the other hand it's non-trivial to figure out who \"relevant people\" are, and \"the general opinion on LW\" is probably not the right category. I'd look more at what (1) people actually working in the field, and (2) the broad ML community, think about an org. So maybe the Alignment Forum.</p>\n<p>(B) I can only answer on my specific views. My opinion on [MIRI] probably wouldn't really help individuals seeking to work there, since they probably know everything I know and have their own opinions. My opinions are more suitable for discussions on the general AI safety community culture.</p>\n", "parentCommentId": "KcHiEHvh3gkdGxeQq", "user": {"username": "Guy Raveh"}}, {"_id": "x8hsZqtNuKMJpEBEq", "postedAt": "2022-10-18T15:19:39.200Z", "postId": "RDoLDJ4toRNpMRBmk", "htmlBody": "<p>I would just probably tell people to work in another field than explicitly encouraging goodharting their way to trying to having positive impact in an area with extreme variance.</p>\n", "parentCommentId": "tJfjiSEwo9RrFgey7", "user": {"username": "JJ Balisan"}}]