[{"_id": "oZNX5vBeKDq7J2egF", "postedAt": "2023-05-29T15:54:16.823Z", "postId": "2TdXocyDF9PxWewwY", "htmlBody": "<p>I'd be interested in more examples and better linking with existing written opinions on these topics. So I invite whoever is reading this to suggest some more ideas, or better - contact me to get editing permissions on the post (and co-authorship if you wish).</p>", "parentCommentId": null, "user": {"username": "edoarad"}}, {"_id": "42kLPYrjqk6AWb6uA", "postedAt": "2023-05-29T17:00:52.610Z", "postId": "2TdXocyDF9PxWewwY", "htmlBody": "<p>Really grateful for the focus on construction instead of destruction. It might not be as dramatic or exciting, but it's still kind of messed up that damaging large parts of EA count as <a href=\"https://betonit.substack.com/p/strong-cheap-signals\">costly signals to signal credibility</a>, even though <i>people other than the poster</i> are the ones who carry the entire burden of the costs.</p><p>I think another dimension of interest for cause-first vs member-first is how much faith you have in the people who make up the causes. If you think everyone is <a href=\"https://www.lesswrong.com/posts/Zp6wG5eQFLGWwcG6j/focus-on-the-places-where-you-feel-shocked-everyone-s\">dropping the ball</a> then you focus on the cause, whereas you focus on the people if you trust their expertise and skill enough to defer to them.</p>", "parentCommentId": null, "user": {"username": "trevorw96"}}, {"_id": "hQ8j9GqrEaSaG5PhW", "postedAt": "2023-05-29T17:36:04.936Z", "postId": "2TdXocyDF9PxWewwY", "htmlBody": "<p>Thanks Edo, I really like this distinction. In particular, your table helped me understand a bunch of seemingly-unrelated disagreements I tend to have with \"mainstream EA\" - I tend to lean member-first (for reasons that maybe I'll write about one day).&nbsp;</p>", "parentCommentId": null, "user": {"username": "Amber"}}, {"_id": "FHXN9dBJC8w4MusjH", "postedAt": "2023-05-29T18:16:22.802Z", "postId": "2TdXocyDF9PxWewwY", "htmlBody": "<blockquote><p>there are important downsides to the \"cause-first\" approach, such as a possible lock-in of main causes</p></blockquote><p>I think this is a legitimate concern, and I'm glad you point to it. An alternative framing is lock-<i>out</i> of potentially very impactful causes. Dynamics of lock-out, as I see it, include:</p><ul><li>EA selecting for people interested in the already-established causes.</li><li>Social status gradients within EA pushing people toward the highest-regarded causes, like AI safety.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefs4avdq5v60p\"><sup><a href=\"#fns4avdq5v60p\">[1]</a></sup></span></li><li>EAs working in an already-established cause having personal and career-related incentives to ensure that EA keeps their cause as a top priority.</li></ul><p>A recent <a href=\"https://forum.effectivealtruism.org/posts/LrxLa9jfaNcEzqex3/calebp-s-shortform?commentId=JwMiAgJxWrKjX52Qt\">shortform</a> by Caleb Parikh, discussing the specific case of digital sentience work, feels related. In Caleb's words:</p><blockquote><p>I think aspects of EA that make me more sad is that there seems to be a few extremely important issues on an impartial welfarist view that don\u2019t seem to get much attention at all, despite having been identified at some point by some EAs.</p></blockquote><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fns4avdq5v60p\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefs4avdq5v60p\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Personal anecdote: Part of the reason, if I'm to be honest with myself, for my move from nuclear weapons risk research to AI strategy/governance is that it became increasingly difficult, socially, to be an EA working on nuclear risk. (In my sphere, at least.) <i>Many</i> of my conversations with other EAs, even in non-work situations and even with me trying avoid this conversation area, turned into me having to defend my not focusing on AI risk, on pain of being seen as \"not getting it\".</p></div></li></ol>", "parentCommentId": null, "user": {"username": "Will Aldred"}}, {"_id": "CTYtgDTTXMnspQK5a", "postedAt": "2023-05-29T18:45:19.411Z", "postId": "2TdXocyDF9PxWewwY", "htmlBody": "<p>Thanks for writing this post, I've been thinking about this framing recently. Although more because I felt like I was member-first when I started community building and now I am much more cause-first when I'm thinking about how to have the most impact.</p><p>I don't agree with some of the categorisations in the table and think there are quite a few that don't fall on the cause/member axis. For example you could have member first outreach that is highly deferential (GiveWell suggestions) and cause-first outreach that brings together very different people that disagree with EA.</p><p>Also when you say the downsides of cause-first are that it led to lock in or lack of diversification I feel like those are more likely due to earlier on member-first focus in EA.</p>", "parentCommentId": null, "user": {"username": "DavidNash"}}, {"_id": "ypzoxDufo5xtHePYX", "postedAt": "2023-05-29T21:49:41.251Z", "postId": "2TdXocyDF9PxWewwY", "htmlBody": "<p>Thanks for the post, it was an interesting read!</p>\n<p>Responding to one specific point: you compare</p>\n<blockquote>\n<p>Community members delegate to high-quality research, think less for themselves but more people end up working in higher-impact causes</p>\n</blockquote>\n<p>to</p>\n<blockquote>\n<p>Community members think for themselves, which improves their ability to do more good, but they make more mistakes</p>\n</blockquote>\n<p>I think there is actually just one correct solution here, namely thinking through everything yourself and trusting community consensus only insofar as you think it can be trusted (which is just thinking through things yourself on the meta-level).</p>\n<p>This is the straightforwardly correct thing to do for your personal epistemics, and IMO it's also the move that maximizes overall impact. It would be kind of strange if the right move was for people to not form beliefs as best they can, or to act on other people's beliefs rather than their own?</p>\n<p>(A sub-point here is that we haven't figured out all the right approaches yet so we need people to add to the epistemic commons.)</p>\n", "parentCommentId": null, "user": {"username": "Lauro Langosco"}}, {"_id": "hNDfSeFH3HGonGMTm", "postedAt": "2023-05-29T21:58:26.838Z", "postId": "2TdXocyDF9PxWewwY", "htmlBody": "<blockquote>\n<p>However, there are important downsides to the \"cause-first\" approach, such as a possible lock-in of main causes</p>\n</blockquote>\n<p>I'm surprised by this point - surely a core element of the 'cause-first' approach is cause prioritization &amp; cause neutrality? How would that lead to a lock-in?</p>\n", "parentCommentId": null, "user": {"username": "Lauro Langosco"}}, {"_id": "qFWCeAgfgXwEr6XL6", "postedAt": "2023-05-29T21:59:49.904Z", "postId": "2TdXocyDF9PxWewwY", "htmlBody": "<p>Written quickly, prioritizing sharing information over polish. Feel free to ask clarifying qs!</p>\n<p>Have been considering this framing for some time, and have quite a lot of thoughts. Will try to comment more soon.</p>\n<p>Very rough thoughts are that I don't /quite/ agree with all the examples in your table and this changes how I define the difference between the two approaches. So e.g. I don't quite think the difference you are describing is people vs cause it's more principles vs cause.</p>\n<p>Then there is a different distinction that I don't think your post really covers (or maybe it does but not directly?) Which is the difference between seeing your (a community builders) obligation towards improving the existing community vs finding more  talented / top people</p>\n<p>Arjun and I wrote something on this: <a href=\"https://forum.effectivealtruism.org/posts/PbtXD76m7axMd6QST/the-funnel-or-the-individual-two-approaches-to-understanding\">https://forum.effectivealtruism.org/posts/PbtXD76m7axMd6QST/the-funnel-or-the-individual-two-approaches-to-understanding</a></p>\n<p>Funnel model = treat people in accordance with how much they contribute (kind of cause first)</p>\n<p>Individual model = treat people wrt how they are interacting with the principles and what stage they are in their own journey (kind of people)</p>\n", "parentCommentId": "oZNX5vBeKDq7J2egF", "user": {"username": "vaidehi_agarwalla"}}, {"_id": "BpNCiaJHos7xvmSjr", "postedAt": "2023-05-29T22:55:27.825Z", "postId": "2TdXocyDF9PxWewwY", "htmlBody": "<p>I like your attempt to draw a distinction between two different ways to view community building, however some parts of the table appear strange.</p><p>When people say that they want EA to <a href=\"https://slatestarcodex.com/2017/08/16/fear-and-loathing-at-effective-altruism-global-2017/\">stay weird</a>, they mean that they want people exploring all kinds of crazy cause areas instead of just sticking the main ones (in tension with your definition of cause-first).</p><p>Also: one the central arguments for leaning more towards EA being small and weird is that you end up with a community more driven by principle because a) slower growth makes it easier for new members to absorb knowledge from more experienced ones vs. from people who don't really understand the philosophy very well themselves yet b) lower expectations for growth make it easier to focus on people with whom the philosophy really resonates vs. marginally influencing people who aren't that keen on it.</p><p>Another point, there's two different ways to build a member first community:</p><ul><li>The first is to try to build a welcoming community that best meets the needs of everyone who has an interest in the community.</li><li>The second it to build a community that focuses on the needs of the core members and relies on them to drive impact.</li></ul><p>These two different definitions will lead to two different types of community.</p><p>To build the first you'd want to engage in broach outreach with diverse messaging. With the second, it would be more about finding the kinds of people who most resonate with your principles. With the first you try to meet people where they are, with the second you're more interested in people who will deeply adopt your principles. With the first, you want engagement with as many people as possible, with the second you want enagement to be as deep as possible.</p>", "parentCommentId": null, "user": {"username": "casebash"}}, {"_id": "Fwq554wxyuGqwgce9", "postedAt": "2023-05-30T07:08:53.192Z", "postId": "2TdXocyDF9PxWewwY", "htmlBody": "<p>Thank you for writing this post. Even without agreeing with the exact distinction as it's made on the table, I think this is a good framing for an important problem. Specifically, I think the movement underestimates the importance of having a mismatch between how it presents itself and its exact focus.<br><br>The way I think about it is:<br>(1) An individual encounters the movement and understands that the value they're going to gain from it is X \u2192 (2) they decide to get involved because they want X \u2192 (3) it takes quite a while (months to years, depends on their involvement) to understand that the movement actually does Y OR sees they don't get the value X they expected \u2192 (4) There's a considerable they're not <i>as </i>interested in Y and doesn't get <i>as</i> involved as they originally thought they would.<br><br>It means that the movement: (1) Missed many people who would've been interested in Y, (2) invested its resources sub-optimally on people who seek X instead of people who seek Y.<br><br>I've experienced this on a weekly basis in EA Israel before we focused our <a href=\"https://forum.effectivealtruism.org/posts/SYaHgTaHG2TopKdpD/eag-london-22-ea-israel-s-approach-to-community-building\">strategy and branding on something that sounds like a members-focused approach</a>. Even after doing that, I have dozens of stories of members being disappointed that the movement doesn't offer them concrete tools for their own social action (as much as it offers tools on how to choose a cause area), or disappointed that the conferences are mostly about AI safety and biosecurity.&nbsp;<br>Even with a strong member-first approach, the movement could still invest considerable resources into organizing AI safety conferences and biosecurity conferences - which would also attract professionals from outside the movement. And the movement could still be constructed in a way that gets people from the EA movement to these other conferences and communities.&nbsp;<br><br>I'm a bit time limited at the moment, but would be happy to discuss this with people working on this topic. I wrote before about this mismatch as a <a href=\"https://forum.effectivealtruism.org/posts/82ig8odF9ooccfJfa/how-ea-is-perceived-is-crucial-to-its-future-trajectory\">branding problem</a>, tried to address this through <a href=\"https://forum.effectivealtruism.org/posts/mnGkj5aerHbfTdf7o/the-explanatory-obstacle-of-ea\">better ways to explain what EA is</a>, and got the chance to present EA Israel's member-first approach at conferences (<a href=\"https://forum.effectivealtruism.org/posts/SYaHgTaHG2TopKdpD/eag-london-22-ea-israel-s-approach-to-community-building\">linked above</a>) since CEA was interested in some different community-building results that came out of EA Israel. If you're working on this topic and think I might be helpful, feel free to get in touch!<br><br>One last thought - I think that <a href=\"https://forum.effectivealtruism.org/users/will-aldred?mention=user\">@Will Aldred</a>'s framing <a href=\"https://forum.effectivealtruism.org/posts/2TdXocyDF9PxWewwY/should-the-ea-community-be-cause-first-or-member-first?commentId=FHXN9dBJC8w4MusjH\">in the comments</a> is correct in describing a connection between how this approach could shape the structure of the movement. Moreover, l think this goes even beyond incentive structures - for instance, the mismatch described above between X and Y could be a good explanation for why community building efforts leans toward \"multi-session programs where people are expected to attend most sessions\". This is because the current branding requires us to gradually move people from wanting X to understanding that Y is actually more important. This is kind of the opposite of product-market fit.<br><br>I'm not saying that either of the approaches is incorrect, but I think this mismatch is harmful. I hope this is resolved either way.&nbsp;</p>", "parentCommentId": null, "user": {"username": "GidonKadosh"}}, {"_id": "qX3hqGynsjQpeA9ia", "postedAt": "2023-05-30T09:05:13.999Z", "postId": "2TdXocyDF9PxWewwY", "htmlBody": "<p>That might be true in theory, but not in practice. People become biased towards the causes they like or understand better.</p>\n", "parentCommentId": "hNDfSeFH3HGonGMTm", "user": {"username": "Guy Raveh"}}, {"_id": "iwBLrHEDi32LPyxg8", "postedAt": "2023-05-30T10:31:00.777Z", "postId": "2TdXocyDF9PxWewwY", "htmlBody": "<p>Sure, but that's not a difference between the two approaches.</p>\n", "parentCommentId": "qX3hqGynsjQpeA9ia", "user": {"username": "Lauro Langosco"}}, {"_id": "Bc5eLiCdzGRA7ZQYo", "postedAt": "2023-05-30T10:37:20.248Z", "postId": "2TdXocyDF9PxWewwY", "htmlBody": "<p>But it'll be intensified if the community mainly exists of people that like the same causes because the filter for membership is cause-centered rather than member-centered.&nbsp;</p>", "parentCommentId": "iwBLrHEDi32LPyxg8", "user": {"username": "mhendric"}}, {"_id": "6y3wg4ryrgzQHYxBd", "postedAt": "2023-05-30T10:48:03.788Z", "postId": "2TdXocyDF9PxWewwY", "htmlBody": "<p>I feel like this post introduces a helpful contrast.&nbsp;</p><p>I am personally partial to the member-first approach. A cause-first approach seems to place a lot of trust into the epistemics of leaders and decision-makers that identify the <i>correct</i> cause. I take this to be an unhealthy strategy generally - I believe a vibrant community of smart, empirically-minded individuals can be trusted to make their own calls, and I think this may often challenge the opinion of leadership or the community at large in a healthy way. Even if many individual calls end up leading to suboptimal individual behaviour, I'd expect the epistemic benefits of a diversity of opinions and thought to outweigh this downside in the long run, even for the centrally boosted causes, which benefit from having their opinions challenged and questioned from people that do not share their views, and having the likelihood of groupthink significantly reduced.&nbsp;</p><p>On a more abstract level, I think EA is pretty unique as a community because of its open epistemics, where a variety of views can be pitched and will receive a fair hearing, often leading to positive interventions and initiatives. I worry that a cause-first approach will endanger this and turn EA into \"just another\" cause-specific organization, even if the selection of the cause is well-motivated at the initial point of choice.</p>", "parentCommentId": null, "user": {"username": "mhendric"}}, {"_id": "aBhCtfxRTrNwNPNmk", "postedAt": "2023-05-30T14:05:19.510Z", "postId": "2TdXocyDF9PxWewwY", "htmlBody": "<blockquote><ul><li>Social status gradients within EA pushing people toward the highest-regarded causes, like AI safety.<a href=\"https://forum.effectivealtruism.org/posts/2TdXocyDF9PxWewwY/should-the-ea-community-be-cause-first-or-member-first#fns4avdq5v60p\"><sup>[1]</sup></a></li></ul></blockquote><p><br>I think this is relatively underdiscussed / important. I previously wrote about the <a href=\"https://forum.effectivealtruism.org/posts/2v49tMYph3dKpvdRp/the-availability-bias-in-job-hunting\">availability bias in EA jobhunting</a> and have anecdotally seen many examples of this both in terms of social pressures and norms, but also just difficulty of forging your own path vs sticking to the \"defaults\". It's simply easier to try and go for EA opportunities where you have existing networks, and there are additionally several monetary, status, &amp; social rewards for pursuing these careers.&nbsp;</p><p>I think it's sometimes hard for people to decouple these when making career decisions (e.g. did you take the job because it's your best option, or because it's a stable job which people think is high status)&nbsp;</p><p><strong>Caveats before I begin:&nbsp;</strong></p><ol><li>I think it's <strong>really good </strong>for people who need to (e.g. from low SES backgrounds) to take financial security into consideration when making important career decisions. But I think this community also has a lot of privileged people who could afford to be a little more risk-taking.&nbsp;</li><li>I don't think it's bad that these programs and resources exist - I'm excited that they exist. But we need to acknowledge how they affect the EA ecosystem. I expect the top pushback will be the standard one, which is that if you have very short timelines, other considerations simply don't matter if you do a E(V) calculation.&nbsp;</li><li>I think that people should take more ownership of exploring other paths and trying difficult things than they currently do, but I also think it's important to consider the ecoystem impacts and how it can create lock-in effects on certain causes.&nbsp;</li><li>These projects exist for a reason - the longtermist space is less funding constrained than the non-longtermist one, it's a newer field, and so many of the opportunities available are field building ones. &nbsp;</li></ol><p>Here are some concrete examples of how the presence of upskilling opportunities &amp; incentives in&nbsp;<br>more specifically x-risk and AIS space) in the last 12-24 months , with comparisons of some other options and how they stack up:</p><p>(written quickly of the top of my head, I expect some specific examples may be wrong in details or exact scope. If you can think of counter-examples please let me know!)</p><ul><li><strong>Career advising resources: &nbsp;</strong><ul><li>80K has been the key career resource for over 10 years, and they primarily investing resources in expanding their LT career profiles, resources &amp; advice (without a robust alternative for several years.&nbsp;</li><li>80K made a call to get others interested in various aspects of career advising they are not covering and have posted about it in <a href=\"https://forum.effectivealtruism.org/posts/dC8w35Y9G7gyWhNHK/what-will-80-000-hours-provide-and-not-provide-within-the\">2020</a>, <a href=\"https://forum.effectivealtruism.org/posts/R7rLHPhdwPajQtyGv/80-000-hours-one-on-one-team-plans-plus-projects-we-d-like\">2021</a>, and <a href=\"https://forum.effectivealtruism.org/posts/Ay42LLjQDjkTpnaMJ/80k-would-be-happy-to-see-more-projects-in-the-careers-space\">2022</a> but (as far as I can tell) with limited traction.<ul><li>There are some other career options - Animal Advocacy Careers and Probably Good - they are at early stages and still ramping up (even in 2023).&nbsp;</li></ul></li></ul></li><li><strong>Career funding / upskilling opportunities:&nbsp;</strong><ul><li>There are the century fellowship &amp; early career funding for AI / bio &amp; Horizon for longtermist policy careers (there is nothing similar for any other cause AFAIK). These are 1-2 year long open-ended funding opportunities. (There is the Charity Entrepreneurship incubator, which mostly funds neartermist and meta orgs and accepts about 20 applicatns per round (historically one per year, from 2023 will be 2 rounds per year))</li><li>When Future Fund was running (and LTFF has also done this), there were several opportunities for people interested in AI safety (possibly other LT causes too, my guess was the bulk was AIS) to visit the bay for the summer, or do career transition grants and so on (there was no equivalent for other causes)&nbsp;</li><li>Since 2021, we now have multiple programs to skill up in AI and other X-risks (AGISF &amp; biosecurity program from BlueDot, SERI MATS, various other ERIx summer internships). (somewhat similar programs with fewer resources are the alt proteins fellowship from BlueDot, a China-based &amp; South East Asia-based farmed animal fellowship in 2022, and AAC's programming)</li><li>There are paid general LT intro programs like the Global Challenge Project retreats, Atlas Fellowship, Nontrivial (There is Intro to VP program, community retreats organized by some local groups &amp; LEAF which have less funding / monetary compensation)</li><li>There are now several dedicated AIS centers at various universities (SERI @ Stanford, HAIST @ Harvard, CBAI @ Harvard / MIT) and a few X-risk focused (ERA @ Cambridge (?), CHERI in Switzerland). As far as I know, there are no such centers for other causes (and even non-AI x-risk causes). These centers are new, but can provide better quality advice, resources and guidance for pursuing these career paths over others.&nbsp;</li></ul></li><li><strong>Networking: </strong>This seems rougly equal.&nbsp;<ul><li>The SERI conference has run since 2021 (there is EA Global, and several EAGx's per year, but no dedicated opportunities for other causes.)</li></ul></li><li><strong>Funding for new community projects</strong><ul><li>Bulk (90%) of EA movement building from OP is funded by the longtermist team, and most univesity EA groups funding is from the longtermist team. I'd love to know more about how those groups and projects are evaluated and how much funding ends up going to more principles-first community building, as opposed to cause-specific work.</li><li>Most of OP's neartermist granting has gone towards effective giving (because it has the highest ROI)</li><li>There are even incentives for infrastructure providers (e.g. Good Impressions, cFactual, EV, Rethink etc.) to primarily support the longtermist ecosystem as that's where the funding is (There are a few meta orgs supporting the animal space, such as AAC, Good Growth, and 2 CE incubated orgs - Animal Ask &amp; Mission Motor)</li></ul></li><li><strong>Career exploration grants:&nbsp;</strong><ul><li>At various points when Future Fund was running, lots of small grants for folks to spend time in the Bay (link), do career exploration, etc. The LTFF has also given x-risk grants that are somewhat similar (as far as I know, the EAIF or others have not given more generic career exploration grants, or grants for other causes)</li></ul></li></ul>", "parentCommentId": "FHXN9dBJC8w4MusjH", "user": {"username": "vaidehi_agarwalla"}}, {"_id": "cSDtg2jSDBbcpFFer", "postedAt": "2023-05-30T15:18:51.546Z", "postId": "2TdXocyDF9PxWewwY", "htmlBody": "<blockquote><p>So e.g. I don't quite think the difference you are describing is people vs cause it's more principles vs cause</p></blockquote><p>Yea, I think I mostly agree with you. I think the main decision I had in mind is pretty much what you make in <a href=\"https://forum.effectivealtruism.org/posts/PbtXD76m7axMd6QST/the-funnel-or-the-individual-two-approaches-to-understanding\">The funnel or the individual: Two approaches to understanding EA engagement </a>which does make very similar points!</p>", "parentCommentId": "qFWCeAgfgXwEr6XL6", "user": {"username": "edoarad"}}, {"_id": "QdL5i3mEQHpTumcDn", "postedAt": "2023-05-30T15:40:08.897Z", "postId": "2TdXocyDF9PxWewwY", "htmlBody": "<p>I'm glad that I tricked you into sharing more of your thoughts :)&nbsp;</p><p>I think you give good reasons for the harms of an incoherent community-building strategy.&nbsp;</p>", "parentCommentId": "Fwq554wxyuGqwgce9", "user": {"username": "edoarad"}}, {"_id": "FEHKX9DKR7ZiyxeYJ", "postedAt": "2023-05-30T15:47:37.945Z", "postId": "2TdXocyDF9PxWewwY", "htmlBody": "<blockquote><p>now I am much more cause-first when I'm thinking about how to have the most impact.</p></blockquote><p>Do you mean, \"the most impact as a community builder\"?</p>", "parentCommentId": "CTYtgDTTXMnspQK5a", "user": {"username": "edoarad"}}, {"_id": "LsiWgKtn4ovvGZdyj", "postedAt": "2023-05-30T16:02:00.622Z", "postId": "2TdXocyDF9PxWewwY", "htmlBody": "<p>(I generally don't feel that happy with my proposed definitions and the categorization in the table, and I hope other people could make better distinctions and framing for thinking about EA community strategy. )</p><p>I don't quite share your intuition on the couple of examples you suggest, and I wonder whether that's because our definitions differ or because the categorization really is off/misleading/inaccurate.</p><p>For me, your first example shows that the relation to deference doesn't necessarily result from a choice of the overall strategy, but I still expect it to usually be correlated (unless strong and direct effort is taken to change focus on deference).</p><p>And for the second example, I think I view a kind of \"member first\" strategy as (gradually) pushing for more cause-neutrality, whereas the cause-first is okay with stopping once a person is focused on a high-impact cause.&nbsp;</p>", "parentCommentId": "CTYtgDTTXMnspQK5a", "user": {"username": "edoarad"}}, {"_id": "uXZXCcJqq5ZH7G5g6", "postedAt": "2023-05-30T16:02:01.856Z", "postId": "2TdXocyDF9PxWewwY", "htmlBody": "<p>I guess the overlap is quite high for myself between 'impact' and 'impact as a community builder'.</p>", "parentCommentId": "FEHKX9DKR7ZiyxeYJ", "user": {"username": "DavidNash"}}, {"_id": "QShErQes5y2ZBqCqu", "postedAt": "2023-05-30T16:11:15.507Z", "postId": "2TdXocyDF9PxWewwY", "htmlBody": "<blockquote><p>When people say that they want EA to <a href=\"https://slatestarcodex.com/2017/08/16/fear-and-loathing-at-effective-altruism-global-2017/\">stay weird</a>, they mean that they want people exploring all kinds of crazy cause areas instead of just sticking the main ones (in tension with your definition of cause-first).</p></blockquote><p>I think this is an important point, and I may be doing a <a href=\"https://en.wikipedia.org/wiki/Motte-and-bailey_fallacy\">motte and bailey</a> here which I don't fully understand. Under what I imagine as a \"cause-first\" movement strategy, you'd definitely want more people engaging in the cause-prioritization effort. However, I think I characterize it as more top-down than it needs to be.&nbsp;</p><blockquote><p>Also: one the central arguments for leaning more towards EA being small and weird is that you end up with a community more driven by principle because a) slower growth makes it easier for new members to absorb knowledge from more experienced ones vs. from people who don't really understand the philosophy very well themselves yet b) lower expectations for growth make it easier to focus on people with whom the philosophy really resonates vs. marginally influencing people who aren't that keen on it.</p></blockquote><p>This feels true to me.</p>", "parentCommentId": "BpNCiaJHos7xvmSjr", "user": {"username": "edoarad"}}, {"_id": "vMijBAeBWSZ2WjFAm", "postedAt": "2023-05-30T16:12:40.419Z", "postId": "2TdXocyDF9PxWewwY", "htmlBody": "<p>Thanks, that makes sense. Can you say a bit about what has changed, and in what way you now focus more on impact?</p>", "parentCommentId": "uXZXCcJqq5ZH7G5g6", "user": {"username": "edoarad"}}, {"_id": "7DNmqPByPhbzmDvt4", "postedAt": "2023-05-30T16:25:26.290Z", "postId": "2TdXocyDF9PxWewwY", "htmlBody": "<p>I guess a lot of the strange causes people explored weren\u2019t chosen in a top down manner. Rather someone just decided to start a project and seek funding for it.</p>\n<p>This is probably changing now that Rethink is incubating new orgs and Charity Entrepreneurship is thinking further afield, but regardless I expect most people who want EA to be weird want people doing this kind of exploration.</p>\n", "parentCommentId": "QShErQes5y2ZBqCqu", "user": {"username": "casebash"}}, {"_id": "XjM2d3EfwbzfxGmeB", "postedAt": "2023-05-30T16:26:29.643Z", "postId": "2TdXocyDF9PxWewwY", "htmlBody": "<blockquote><p>only insofar as you think it can be trusted</p></blockquote><p>Note that if you place a high degree of trust, then the correct approach to maximize direct impact would generally be to delegate a lot more (and, say, focus on the particularities of your specific actions). I think that it makes a lot of sense to mostly trust the cause-prioritization enterprise as a whole, but maybe this comes at the expense of people doing less independent thinking, which should address your <a href=\"https://forum.effectivealtruism.org/posts/2TdXocyDF9PxWewwY/should-the-ea-community-be-cause-first-or-member-first?commentId=hNDfSeFH3HGonGMTm\">other comment</a>.&nbsp;</p>", "parentCommentId": "ypzoxDufo5xtHePYX", "user": {"username": "edoarad"}}, {"_id": "NbBpqLFAfqmiMmaMY", "postedAt": "2023-05-31T09:58:29.114Z", "postId": "2TdXocyDF9PxWewwY", "htmlBody": "<p>When I started community building I would see the 20 people who turned up most regularly or had regular conversations with and I would focus on how I could help them improve their impact, often in relatively small ways.</p><p>Over time I realised that some of the people that were potentially having the biggest impact weren't turning up to events regularly, maybe we just had one conversation in four years, but they were able to shift into more impactful careers. Partially because there were many more people who I had 1 chat with than there were people I had 5 chats with, but also the people who are more experienced/busy with work have less time to keep on turning up to EA social events, and they often already had social communities they were a part of.</p><p>It also would be surprising/suspicious if the actions that make members the happiest also happened to be the best solution for allocating talent to problems.</p>", "parentCommentId": "vMijBAeBWSZ2WjFAm", "user": {"username": "DavidNash"}}, {"_id": "F6mTXMbqdzxF8fPPt", "postedAt": "2023-06-01T19:02:18.231Z", "postId": "2TdXocyDF9PxWewwY", "htmlBody": "<p>Nice post, Edo!</p><p>One seemingly important factor to decide whether to lean cause-first or member-first is whether impact varies more across causes or interventions. 80,000 Hours thinks the variation across causes is larger, so it leans cause-first. <a href=\"https://forum.effectivealtruism.org/posts/seFH9jcH3saXHJqin/data-on-how-much-solutions-differ-in-effectiveness\">This</a> recent analysis from Ben Todd suggests variations across causes are not as large as previously thought.</p>", "parentCommentId": null, "user": {"username": "vascoamaralgrilo"}}, {"_id": "vF5MFpwGXbJDm9APa", "postedAt": "2023-06-02T17:26:25.682Z", "postId": "2TdXocyDF9PxWewwY", "htmlBody": "<p>Thanks for writing this. After reading this, I want EA to be even more \"cause first\". One of the things that I worry about for EA is that it becomes a fairly diffuse \"member-first\" movement, not much unlike a religious group that comes together and supports each other and believes in some common doctrines but at the end of the day, doesn't accomplish much.&nbsp;</p><p>I look at EA now and am nothing short of stunned at how much it is accomplishing. Not in dollars spent. But in stuff done. The EA community was at the forefront of pushing AI safety to the mainstream. It has started several new charities. It's responsible for a lot of wins for animals. It's responsible for saving hundreds of thousands of lives. It's about the only place out there that measures charities, and does so with a lot of rigor. It's produced countless reports that actually change what gets worked on. It creates new charities every year. It changes what it works on pretty well.</p><p>I think caring about its members is an instrumental goal to caring about causes. The members do, after all, work on the causes. EA does recognize this though and with notable exceptions, I think it does a very good job of it.</p>", "parentCommentId": null, "user": {"username": "MarcusAbramovitch"}}, {"_id": "crMnSSgtuRKKWyCRu", "postedAt": "2023-06-02T21:24:50.422Z", "postId": "2TdXocyDF9PxWewwY", "htmlBody": "<p><strong>Note</strong>: I'm writing this comment in my capacity as an individual, not as a representative of CEA, although I do work there. I wouldn\u2019t be surprised if others at CEA disagree with the characterization I\u2019m making in this comment.&nbsp;<br><br>I want to provide one counterexample to the conception that most of mainstream EA is leaning \u201ccause-first\u201d in the status quo. CEA is a large organization (by EA standards) and we definitely invest substantial resources in \u201cmember-first\u201d style ways.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref3oy6mekqbin\"><sup><a href=\"#fn3oy6mekqbin\">[1]</a></sup></span>&nbsp;</p><p>To be specific, here is a sampling of major programs we run:&nbsp;</p><ul><li>Groups<ul><li>University Groups (mostly focused on the <a href=\"https://forum.effectivealtruism.org/posts/d83HJFMnEvP6x6LaD/ugap-starter-program-retrospective\">University Group Accelerator Program</a> currently, which is a scaled program targeting a broad range of mostly <i>non</i>-top unis)</li><li>City &amp; National Groups (most of the funds go towards our top 15 city-national groups, but we also fund a long tail of other groups all around the world.)</li><li>Virtual Programs (designed to be accessible, available globally, focused on EA fundamentals principles, although it also covers causes.)</li></ul></li><li>Events<ul><li>EAGs and EAGx are designed to help members coordinate, and EAGx in particularly is held around the world and fairly \"big tent\"</li></ul></li><li>Community Health / Online<ul><li>Services offered by these programs (e.g. this forum) are basically infrastructure for community members</li></ul></li></ul><p>Some important caveats: there\u2019s other things we do, we think seriously about trying to capture the heavy-tail and directing people towards specific cause areas (including encouraging groups we support to do the same), and we definitely shifted some content (like the handbook) to be more cause-area oriented. CEA is also only one piece of the ecosystem.&nbsp;<br><br>Overall though, I do think much of CEA's work currently represents investment that intuitively seems more \"member-first\", (whether or not this is the correct strategy), and we're a reasonably large part of the CB ecosystem.&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn3oy6mekqbin\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref3oy6mekqbin\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Also, although I think the member/cause distinction is useful, it's also sufficiently vague and \"vibes-y\" enough that many programs and organizations, like CEA, could probably be construed as focusing on either one.&nbsp;</p></div></li></ol>", "parentCommentId": null, "user": {"username": "Conor McGurk"}}, {"_id": "ab6uceGZ6eEpzZwCP", "postedAt": "2023-06-03T04:28:55.161Z", "postId": "2TdXocyDF9PxWewwY", "htmlBody": "<p>A \"cause first\" movement has similar risks in vesting too much authority into a small elite, not much unlike a cult that comes together and supports each other and believes in some common goal and makes <i>major</i> strides to get closer to said goal, but ultimately burns out as cults often do due to treating their members too instrumentally as objects for the good of the cause. Fast and furious without the staying power of a religion.<br><br>That said, I'm also partial to the cause first approach, but man, stuff we have learnt like <a href=\"https://forum.effectivealtruism.org/posts/2y9eSkMAkdPQeXWMf/podcast-with-oli-habryka-on-lesswrong-lightcone?commentId=ogfPjdCbJrKBXErbn\">Oli Habryka's podcast here</a> made me strongly update more towards a member-first mindset which I think would have more firmly pushed against such revelations as being antithetical to caring for one's members. Less <a href=\"https://forum.effectivealtruism.org/posts/Jx6ncakmergiC74kG/deference-culture-in-ea\">deference</a> and more thinking for yourself like Oli did seems like a better long-term strategy for any community's long-term flourishing. EA's recent wins don't seem to counteract this intuition of mine strongly enough when you think decades or even generations into the future.</p><p>That said, if AI timelines really are really short, maybe we just need a fast and furious approach for now.</p>", "parentCommentId": "vF5MFpwGXbJDm9APa", "user": {"username": "Cornelis Dirk Haupt"}}, {"_id": "szR4CoHhTNBGK7CEF", "postedAt": "2023-06-04T07:50:42.424Z", "postId": "2TdXocyDF9PxWewwY", "htmlBody": "<p>To emphasize Cornelis's point:<br><br>I've noticed that most of the tension that a \"cause-first\" model has is that it's \"cause\" in the singular, and not \"causes\" (ie - people who join EA because of GHWB and Animal Welfare but then discover that at EAG everyone is only talking about AI). Marcus claims that EA's success is based on cause-first, and brings examples:<br><br>\"The EA community was at the forefront of pushing AI safety to the mainstream. It has started several new charities. It's responsible for a lot of wins for animals. It's responsible for saving hundreds of thousands of lives. It's about the only place out there that measures charities, and does so with a lot of rigor. \"</p><p>But I think that in practice, when someone today is calling for \"cause-first EA\", they're calling for \"longtermist / AI safety focused EA\". The diversity of the examples above seem to support a \"members-first EA\" (at least as outlined in this post).</p>", "parentCommentId": "ab6uceGZ6eEpzZwCP", "user": {"username": "ezrah"}}, {"_id": "rWJhEaHMiWtXctNM3", "postedAt": "2023-06-04T09:00:54.506Z", "postId": "2TdXocyDF9PxWewwY", "htmlBody": "<p>Thanks for your perspective Conor! Looking into these activities in more detail, I have some notes:</p><ol><li>UGAP - I don't know much about this program, unfortunately. The reports I've seen seem to maybe encourage more member-first but I'm not sure. Regarding their KPIs for university groups, it seems like they used HEAs but write that they don't like it and want to use other metrics. I'd be interested in what comes up with that.<ol><li>I am also not that familiar with OpenPhil's university program, which I imagine to be mostly hands-off. I guess that they are thinking of community building in a more cause-oriented way, but I don't know.</li></ol></li><li>City &amp; National Groups - I'd be interested in understanding the considerations involving which groups to fund and which activities seem most important.</li><li><a href=\"https://www.effectivealtruism.org/virtual-programs\">Virtual programs</a> -&nbsp;<ol><li>Open programs<ol><li>The Precipice reading group (cause-first)</li><li>Introductory EA program (follows the Handbook, which is arguably cause-first)</li><li>In-Depth EA Program (mostly methodological, member-first)</li><li>How to (actually) change the world (member-first, even though it's hosted by <a href=\"https://www.non-trivial.org/\">Non-Trivial</a> which seems strongly cause-first)</li></ol></li><li>Past programs<ol><li>cause-specific (alt. proteins, animal advocacy, ML safety and AGI safety)</li><li>career-specific: US policy (very practical, seems member-first, even though likely motivated by x-risk concerns), Law (cause-first, maybe due to good pedagogical reasons).</li></ol></li></ol></li><li>Events - definitely a mix of the two. Helping members coordinate is done both for intra-cause reasons and to broadly support EAs in their EA endeavors.&nbsp;</li><li>Forum - also definitely a platform for both cause-first and member-first discussions, but I think its goals are leaning more member-first.&nbsp;</li></ol>", "parentCommentId": "crMnSSgtuRKKWyCRu", "user": {"username": "edoarad"}}, {"_id": "gTybjpiEBX7A3mPkk", "postedAt": "2023-06-05T04:37:49.969Z", "postId": "2TdXocyDF9PxWewwY", "htmlBody": "<p>I'd like to note that it is totally possible for someone to sincerely be talking about \"cause-first EA\" and simultaneously believe longtermism and AI safety should be the cause EA should prioritize.</p>\n<p>As a community organizer I've lost track of how many times people I've introduced to EA initially get excited, but then disappointed that all we seem to talk about are effective charities and animals instead of... mental health or political action or climate change or world war 3 or &lt;insert favourite cause here&gt;.</p>\n<p>And when this happens I try to take a member-first approach and ensure they understand what led to these priorities so that the new member can be armed to either change their own mind or argue with us or apply EA principles in their own work regardless of where it makes sense to do so.</p>\n<p>A member-first approach wouldn't ensure we have diversity of causes. We could in theory have a very members-first movement that only prioritizes AI Alignment. This is totally possible. The difference is that a members-first AI alignment focused movement would focus on ensuring its members properly understand cause agnostic EA principles - something they can derive value from regardless of their ability to contribute to AI Alignment - and based on that understand why AI Alignment just happens to be the thing the community mostly talks about at this point in time.</p>\n<p>Our current cause-first approach is less concerned with teaching EA principles that are cause agnostic and more concerned with just getting skilled people of any kind, whether they care about EA principles or not, to work on AI Alignment or other important things. Teaching EA principles being mostly instrumental to said end goal.</p>\n<p>I believe this is more the cause of the tension you describe in the \"cause-first\" model. It has less to do with only one cause being focused on. It has more to do with the fact that humans are tribalistic.</p>\n<p>If you're not going to put effort into making sure someone new is part of the tribe (in this case giving them the cause-agnostic EA principle groundwork they can take home and feel good about) then they're not going to feel like they're part of your cause-first movement if they don't feel like they can contribute to said cause.</p>\n<p>I think if we were more members-first we would see far more people who have nothing to offer to AI Safety research still nonetheless feel like \"EA is my tribe.\" Ergo, less tension.</p>\n", "parentCommentId": "szR4CoHhTNBGK7CEF", "user": {"username": "Cornelis Dirk Haupt"}}, {"_id": "XnxjT4etoMWoYFCjN", "postedAt": "2023-06-05T09:29:27.283Z", "postId": "2TdXocyDF9PxWewwY", "htmlBody": "<p>I'd love to see the results of a good experiment in in the member-first approach.</p>\n<p>I'm leaning more towards the cause-first approach, but possibly for the wrong reasons. It's easier to measure, it's impact is easier to communicate and understand, the funnel feels shorter and more straight-forward, the activities and tools to achieve impact are there for me to use, I don't need to invent anything from skratch. This all might be a streetlight fallacy.</p>\n<p>The strongest for the member-first approach for me would be:</p>\n<ul>\n<li>After your members take the job in a high-impact position, they will continue to make decisions. Decisions at their work, decisions about where to work next, etc. If they are not well equipped with tools and knowledge about how to make good decisions independently which optimize for impact, their choices might be far from optimal.</li>\n<li>By delegating cause prioritization to a few small groups of researchers, we might succumb to effects of echo chambers, fail to identify important mistakes in our reasoning and even more effective causes.</li>\n<li>The impact from a member-first approach might be &gt;10-100x larger than that of a cause-first approach. It's the difference between motivating a few people to work on AI safety vs changing the societal norms themselves to be more impact-focused when doing career planning.</li>\n</ul>\n", "parentCommentId": null, "user": {"username": "rannilo"}}, {"_id": "qBWdxaNuet5QweTkq", "postedAt": "2023-07-16T09:30:06.180Z", "postId": "2TdXocyDF9PxWewwY", "htmlBody": "<p>I really liked the axis that you presented and the comparision between a version of the community that is more cause oriented vs member oriented.</p><p>The only caveat that I have is that I don't think we can define a neutral point in between them that allows you to classify communities as one type or the other.&nbsp;</p><p>Luckily, I think that is unnecesary because even though the objective of EA is to have the best impact in the world and not the greatest number of members, I think we all think the best decision is to have a good balance between cause and member oriented. So the question that we should ask is should EA be MORE big tent, weird, or do we have a good balance right now?</p><p>And to achieve that balance we can be more big tent in some aspects, moments and orgs and weirder in others.</p>", "parentCommentId": null, "user": {"username": "Patricio"}}]