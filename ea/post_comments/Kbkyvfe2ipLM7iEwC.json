[{"_id": "C9TL4RTjGzjpk6FRy", "postedAt": "2023-10-29T10:13:32.489Z", "postId": "Kbkyvfe2ipLM7iEwC", "htmlBody": "<blockquote>\n<p>Besides contingency, it seems that there is a strong neglectedness case in favor of prioritizing the promotion of better values and political frameworks over the advancement of consciousness research.</p>\n</blockquote>\n<p>Consciousness research seems to be very neglected to me, relative to its importance in understanding the world we live in. Nonhuman consciousness is especially neglected. Should it prioritized over other things? That seems to me to turn on tractability. Consciousness research doesn\u2019t seem particularly tractable (though there are low hanging fruit), but neither does research to expand value systems and political frameworks to care about all sentient creatures.</p>\n", "parentCommentId": null, "user": {"username": "Derek Shiller"}}, {"_id": "HRm7TP29fgdwGjtLz", "postedAt": "2023-10-30T10:51:16.301Z", "postId": "Kbkyvfe2ipLM7iEwC", "htmlBody": "<p>Do you have instincts or perhaps even analysis about what interventions to expand \"good\" values look like? I am interested as my interest in values was how I came into EA thinking to begin with and have since thought more and more that it is too large a task to tackle. I know of the Sentience Institute but my feeling is that they are more about research and less about actually going out and spreading positive values.</p>", "parentCommentId": null, "user": {"username": "Ulrik Horn"}}, {"_id": "r4wrp3HfuspTGzQ8B", "postedAt": "2023-10-30T11:47:26.380Z", "postId": "Kbkyvfe2ipLM7iEwC", "htmlBody": "<p>Hi Ulrik,</p><blockquote><p>Do you have instincts or perhaps even analysis about what interventions to expand \"good\" values look like? I am interested as my interest in values was how I came into EA thinking to begin with and have since thought more and more that it is too large a task to tackle.</p></blockquote><p>Thanks for the question, and sharing you story! I do not think I have great insights here, but I can at least share some relevant resources (you may well be aware of them already, but they could still be useful to other readers):</p><ul><li>80,000 Hours' profiles on <a href=\"https://80000hours.org/problem-profiles/s-risks/\">s-risks</a> and <a href=\"https://80000hours.org/problem-profiles/promoting-positive-values/\">promoting positive values.</a></li><li>CLR's <a href=\"https://longtermrisk.org/beginners-guide-to-reducing-s-risks/\">beginner\u2019s guide to reducing s-risks</a>. Maybe people at <a href=\"https://forum.effectivealtruism.org/users/center-on-long-term-risk?mention=user\">@Center on Long-Term Risk</a> would be keep to expand the above 80,000 Hours' profiles, which as of now are quite short?</li><li>Websites of organisations working in the area:<ul><li><a href=\"https://longtermrisk.org/\">Center on Long-Term Risk</a>.</li><li><a href=\"https://centerforreducingsuffering.org/\">Centre for Reducing Suffering</a>.</li><li><a href=\"https://www.sentienceinstitute.org/\">Sentience Institute</a>.</li></ul></li></ul><blockquote><p>I know of the Sentience Institute but my feeling is that they are more about research and less about actually going out and spreading positive values.</p></blockquote><p>I have the impression the field is still quite nascent, and share your sense that the above organisations are mostly doing research. CLR's guide has a <a href=\"https://longtermrisk.org/beginners-guide-to-reducing-s-risks/#4_Approaches_to_s-risk_reduction\">section</a> on approaches to s-risk reduction, but it seems to point towards further investigation, as opposed to specific interventions. <a href=\"https://www.cooperativeai.com/\">Cooperative AI</a> was what I found in the guide which seemed more like an intervention with direct applications, but it is targeted at improving cooperation among advanced AI models, and you may be looking for something more broad.</p><p>Maybe concern for the suffering of factory-farmed animals is a decent way to promote positive values, but I have not thought much about this. I mostly <a href=\"https://forum.effectivealtruism.org/posts/vBcT7i7AkNJ6u9BcQ/prioritising-animal-welfare-over-global-health-and#Corporate_campaigns_for_chicken_welfare_increase_nearterm_wellbeing_way_more_cost_effectively_than_GiveWell_s_top_charities\">think</a> the best animal welfare interventions are a super cost-effective way of decreasing nearterm suffering.</p><p>It would be useful to ensure that frontier AI models have good values. So I have wondered about whether people at frontier AI labs (namely OpenAI, Anthropic, and Deepmind) and organisations like <a href=\"https://evals.alignment.org/\">Arc Evals</a> should be running a few tests to see assess:</p><ul><li>The underlying morality of LLMs, like figuring out whether they support the total or average view, expected value maximisation with or without risk aversion, which theory of wellbeing, and how they answer thought experiments like the repugnant conclusion or the trolley problem.</li><li>Their stance on real world problems. For example, what are the views of LLMs on factory farming, wild animal suffering, extreme poverty, high global catastrophic risks, current wars, and digital sentience?</li></ul><p>I have not checked whether people are looking into this, but it seems worth it as a more empirical type of intervention to influence future values. Then maybe the models could be (partly) aligned based on their views on questions like the above.</p>", "parentCommentId": "HRm7TP29fgdwGjtLz", "user": {"username": "vascoamaralgrilo"}}, {"_id": "isKm4iWEsgftnqWYT", "postedAt": "2023-10-30T12:18:53.933Z", "postId": "Kbkyvfe2ipLM7iEwC", "htmlBody": "<p>I really like your suggestion on just plain AI value alignment perhaps being the most effective. In a sense, even though these are perilous times we do perhaps have the opportunity to massively impact the values of millions of machine intelligences so that even though humans stick with pretty much the same values (something I perceive being really hard to change), we will \"improve\" the average values globally. Thanks for your thoughtful response - it certainly have made me see this issue from a new perspective!</p>", "parentCommentId": "r4wrp3HfuspTGzQ8B", "user": {"username": "Ulrik Horn"}}, {"_id": "Zz3Xst3vRrc2uZ2fQ", "postedAt": "2023-10-30T13:41:42.317Z", "postId": "Kbkyvfe2ipLM7iEwC", "htmlBody": "<p>Thanks for the kind words, and also for clarifying my own views!</p>", "parentCommentId": "isKm4iWEsgftnqWYT", "user": {"username": "vascoamaralgrilo"}}]