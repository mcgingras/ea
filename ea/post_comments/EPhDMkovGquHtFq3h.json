[{"_id": "EajPzQukXRhkRiB6u", "postedAt": "2022-09-12T12:05:22.907Z", "postId": "EPhDMkovGquHtFq3h", "htmlBody": "<p>A slightly edited section of my comment on the earlier draft:</p>\n<blockquote>\n<p>I lean skeptical about \"relative pair-wise comparisons\" after participating:\nI think people were surprised by their aggregate estimates (e.g., I was very surprised!);\nI think later convergence was due to common sense and mostly came from people moving points between interventions and not from pair-wise anything;</p>\n<p>I think this might be because I am unconfident about eliciting distributions with Squiggle. As I don't have good intuition about how a few log-normals with 80% probability between xx and yy would compare to each other after aggregations (probably this is common, see 2a).\nAfter I did my point estimates + my CI via Squiggle for everything alltogether, I think they didn't match each other that well. Maybe that's because lognormal is right-skewed and fairly heavy-tailed?</p>\n</blockquote>\n", "parentCommentId": null, "user": {"username": "Misha_Yagudin"}}, {"_id": "nyBmbfimvZ4djFHwq", "postedAt": "2022-09-12T12:16:04.641Z", "postId": "EPhDMkovGquHtFq3h", "htmlBody": "<p>(Comments re-worded from those on a draft)</p><p>Overall I like the direction this post pushes in.</p><blockquote><p>I shared a&nbsp;<a href=\"https://docs.google.com/document/d/1sTCwFUA7_G46YzUp4p4U_OvpYd9tdmq7D8IRdL63BeA/edit#heading=h.tf7bismm62hi\"><u>briefing</u></a> with the participants summarizing the nine Open Philanthropy grants above, with the idea that it might speed the process along.&nbsp;</p><p>In hindsight, this was suboptimal, and might have led to some anchoring bias. Some participants complained that the summaries had some subjective component. These participants said they used the source links but did not pay that much attention to these opinions.</p><p><strong>On the other hand, other participants said they found the subjective estimates useful. And because the briefing was written in good faith, I am personally not particularly worried about it. Even if there are anchoring issues, we may not necessarily care about it if we think that the output is accurate, in the same way that we may not care about forecasters anchoring on the base rate. </strong>[emphasis mine]</p><p>If I were redoing this experiment, I would probably limit myself even more to expressing only factual claims and finding sources. A better scheme may have been share a&nbsp;writeup with a minimal subjective component, then&nbsp; strongly encouraging participants to make their own judgments before looking at a separate writeup with more subjective summaries, which they can optionally use to adjust their estimates</p></blockquote><p>I disagree with the opinions expressed in the bolded paragraph. I wouldn't want forecasters to anchor on a specific base rate I gave them! I'd want them to find their own. Of course you think that the forecasters are anchoring on something accurate since the opinions they're anchoring on are your own! This isn't reassuring to me at all.</p><blockquote><p>Thoughts on scaling up this type of estimation up [section header]</p></blockquote><p>I'm more excited about in-depth evaluation of agendas/organizations as a whole than trying to scale up shallow estimations to all grants.</p><blockquote><p>Giving some&nbsp;<i>very</i> quick numbers to this, say:</p><ul><li>a 12% chance of AGI being built before 2030,&nbsp;</li><li>a 30% of it being built in Britain by then if so,</li><li>a 90% of it being built by DeepMind if so,&nbsp;</li><li>an initial 50% chance of it going well if so</li><li>GovAI efforts shift the probability of it going well from 50% to 55%.&nbsp;</li></ul><p>Punching those numbers into a calculator, a rough estimate is that GovAI reduces existential risk by around 0.081%, or 8.1&nbsp;<a href=\"https://en.wikipedia.org/wiki/Basis_point\"><u>basis points</u></a>.&nbsp;</p></blockquote><p>This BOTEC feels too optimistic about GovAI's impact to me, and I trust it even less than most BOTECs because it's not directly modeling the channel though which I (and I believe GovAI) think GovAI will have the most impact, which is field-building.</p>", "parentCommentId": null, "user": {"username": "elifland"}}, {"_id": "NLb7kDMaFiEkQiMxr", "postedAt": "2022-09-12T13:06:32.650Z", "postId": "EPhDMkovGquHtFq3h", "htmlBody": "<p>Thanks Misha</p>", "parentCommentId": "EajPzQukXRhkRiB6u", "user": {"username": "NunoSempere"}}, {"_id": "mCamwQHDmS34wqwME", "postedAt": "2022-09-12T13:08:26.493Z", "postId": "EPhDMkovGquHtFq3h", "htmlBody": "<p>Thanks Eli. I think I most disagree with you on the BOTEC point. Copying a paragraph from the text:</p><blockquote><p>The key number here is the 5% improvement (from 50% to 55%). I\u2019m getting this estimate mostly because I think that Allan Dafoe being the \u201cHead of Long-term Strategy and Governance\u201d at DeepMind seems like a promising signal. It nicely corresponds to the \u201chaving people in places to implement safety strategies\u201d part of GovAI\u2019s pathway to impact. But that estimation strategy is very crude, and I could imagine a better estimate ranging from &lt;0.5% to more than 5%.</p></blockquote><p>So I think that the handwavy estimate is still meaningful.&nbsp;</p>", "parentCommentId": "nyBmbfimvZ4djFHwq", "user": {"username": "NunoSempere"}}, {"_id": "ZRwdTXyxfBQCYgBtk", "postedAt": "2022-09-12T19:38:50.492Z", "postId": "EPhDMkovGquHtFq3h", "htmlBody": "<p><strong>Some thoughts on the greater project:</strong> &nbsp;</p><p>- The greater prospect of \u201clet\u2019s have collaborative estimates of the impacts of key longtermist projects\u201d is something I strongly want to see, but I think it\u2019s also *really* difficult to do well.</p><p>- This experiment went through a few early strategies. I think the results are clearly mediocre (in that estimates were all over the place, and were wildly inconsistent), but could be a good place to build much better work.&nbsp;</p><p>- I see this very much as an MVP, so I\u2019d expect it to have severe limitations. I generally prefer processes of \u201cbuild a bunch of MPVs and test them out, and see what fails\u201d, then one of \u201cspend a whole lot of time getting it right the first time.\u201d</p><p>- The fact that estimates were inconsistent suggests that elicitation is very difficult to do well, but also that there\u2019s a great deal of improvement to be done. So, future work is probably less tractable than expected, but more important.</p><p>- I\u2019m still very bullish on relative evalutions, but think that they will require a lot of clever innovations to do well.&nbsp;</p><p>- I think that longer-term, it would be promising to have people submit relative evaluations as long Squiggle (or similar) files. I\u2019m unsure how these can best be displayed or organized for specific discussions.</p><p><strong>Some thoughts on the estimations:&nbsp;</strong>&nbsp;</p><p>- I think this is the first most/any of us have really had to estimate the relative value of these kinds of longtermist projects. There\u2019s been very little literature on this before. I think the numbers are correspondingly questionable (including my own).</p><p>- Utility elicitation for comparing one item to another that could be negative, in particular, was really poor. I tried some naive Squiggle calculations that clearly weren\u2019t very accurate. I\u2019m not sure what tool would be best here, maybe there\u2019s some custom drawing-with-mouse tool that could work, or people could figure out better quantitative function representations.</p><p>- It\u2019s very hard to evaluate these sorts of projects without much more data. Ideally, there would be a lot of data gathering. For example, if a program funds 10 people to do work, we\u2019d ideally have a good table of all of their outputs, and comments from people in the area about how good these comments were. A lot of evaluation work can reduce to \u201ceffective systems to gather objective and subjective information from diverse sets of sources.\u201d</p><p>- I believe people estimated \u201chow valuable do you think this is\u201d instead of, \u201chow valuable do you think a council would think this is?\u201d The latter should be much more uncertain, and possibly much more important to readers (if done well).</p><p>- From what I remember, I think my main disagreement with other evaluators is that some had much narrower ranges than I thought were reasonable. I guess that some of this is part of a learning process.</p>", "parentCommentId": null, "user": {"username": "oagr"}}, {"_id": "KKBJrFcbZsziHPyF3", "postedAt": "2022-09-12T20:50:13.334Z", "postId": "EPhDMkovGquHtFq3h", "htmlBody": "<p>In the table with post-discussion distributions, how is the lower bound of the aggregate distribution for the Open Phil AI Fellowship -73, when the lowest lower bound for an individual researcher is -2.4? Also in that row, Researcher 3's distribution is given as \"250 to 320\", which doesn't include their median (35) and is too large for a scale that's normalized to 100.</p>", "parentCommentId": null, "user": {"username": "Dan_Keys"}}, {"_id": "mG4pJSKz7tzynGzMT", "postedAt": "2022-09-12T21:14:20.996Z", "postId": "EPhDMkovGquHtFq3h", "htmlBody": "<p>I think it would've been better to just elicit point estimates of the grants' expected value, rather than distributions. Using distributions adds complexity, for not much benefit, and it's somewhat unclear what the distributions even represent.</p><p>Added complexity: for researchers giving their elicitations, for the data analysis, for readers trying to interpret the results. This can make the process slower, lead to errors, and lead to different people interpreting things differently. e.g., For including both positive &amp; negative numbers in the distributions.</p><p>Not much benefit: at least, when I read this report I mostly looked at the point estimates, except for the section showing that researchers' confidence intervals for the two elicitation methods didn't overlap.</p><p>Unclear what the distribution represents: The distribution is basically a probability distribution over a probability (p(x-risk)), and it's not obvious which uncertainties should be represented in the distribution and which are part of p(x-risk). e.g., If someone thinks that there's an 80% chance that a research direction is misguided &amp; useless and a 20% chance that it's meaningful &amp; relevant, should they just multiply their distribution by 0.2 (relative to research that is definitely in a meaningful &amp; relevant direction), or should this give a more spread-out distribution with most of the probability mass near zero, or something in between?</p>", "parentCommentId": null, "user": {"username": "Dan_Keys"}}, {"_id": "A7RWtb6N6JdznxCTT", "postedAt": "2022-09-12T21:31:15.775Z", "postId": "EPhDMkovGquHtFq3h", "htmlBody": "<p>Hey, thanks</p><blockquote><p>Also in that row, Researcher 3's distribution is given as \"250 to 320\", which doesn't include their median (35) and is too large for a scale that's normalized to 100.</p></blockquote><p>Should have been -250, updated.</p><p>This also explains the -73.</p>", "parentCommentId": "KKBJrFcbZsziHPyF3", "user": {"username": "NunoSempere"}}, {"_id": "BhFWxNcvqkorhxgDC", "postedAt": "2022-09-12T21:40:58.380Z", "postId": "EPhDMkovGquHtFq3h", "htmlBody": "<p>My intuitions point the other way with regards to point estimates vs distributions. Distributions seem like the correct format here, and they could allow for value of information calculations, sensitivity, to highlight disagreements which people wouldn't notice with point estimates, to better combine. The bottom line could also change when using estimates, e.g., as in <a href=\"https://arxiv.org/abs/1806.02404\">here</a>.&nbsp;</p><p>That said, they do have a learning curve and I agree with you that they add additional complexity/upfront cost.</p>", "parentCommentId": "mG4pJSKz7tzynGzMT", "user": {"username": "NunoSempere"}}, {"_id": "yH7Fz9hBoSsKezmxR", "postedAt": "2022-09-12T21:44:16.085Z", "postId": "EPhDMkovGquHtFq3h", "htmlBody": "<blockquote><p>Unclear what the distribution represents: The distribution is basically a probability distribution over a probability (p(x-risk)), and it's not obvious which uncertainties should be represented in the distribution and which are part of p(x-risk). e.g., If someone thinks that there's an 80% chance that a research direction is misguided &amp; useless and a 20% chance that it's meaningful &amp; relevant, should they just multiply their distribution by 0.2 (relative to research that is definitely in a meaningful &amp; relevant direction), or should this give a more spread-out distribution with most of the probability mass near zero, or something in between?</p></blockquote><p>Yeah, you can use a mixture distribution if you are thinking about the distribution of impact, like <a href=\"https://www.squiggle-language.com/playground/#code=eNo1ir0KwkAQBl%2Fl4yqFQ2MgIPYW1inVYsFNXLi71cte%2FMN3NwjpZob5uOGqj7bESPnldpYL%2B3%2FaX8Q0z0WSmFBo70X6PnBrWVLvdi4%2BF8ekOVJYVB6bpUcDUzTV2eNYrWqParU9L09pvUZSY9iVDAdIGjkbXybnaalBaeYtxgEvLRn8pHgLjE4npoGhHUYZCgV5k4km9%2F0BMbhAAA%3D%3D\">so</a>, or you can take the mean of that mixture if you want to estimate the expected value, like <a href=\"https://www.squiggle-language.com/playground/#code=eNo1is2KwkAQBl%2FlY04JDBoFQbzvYc85qocG29gw071OeuIfvrthwVtVUa8wXuzW15ypPMLOS%2BX4n35O4la%2BRVRcKPXXKsOQuPciOoRdyEza5HuzVyuZUtNFrNqIDdyw6Y4R%2B26xjugW22PbHnS5hJoz%2FEKOX4hOXJxPs%2FP8rEH65S2mEQ%2BrBXyn%2FJcYZ5uZRoadMclYKcmTXEzD%2BwPCwEHy\">so</a>. Depends of what you are after.</p>", "parentCommentId": "mG4pJSKz7tzynGzMT", "user": {"username": "NunoSempere"}}, {"_id": "Pzxn2Nh8yojPvcKDd", "postedAt": "2022-09-12T21:50:20.624Z", "postId": "EPhDMkovGquHtFq3h", "htmlBody": "<p>More generally, I think there is a difference between what would have been best for this analysis, and you might be right that point estimates would have been better, and what EA/longtermism should be aiming to have, which I think are more uncertain estimates in the shape of distributions.</p>", "parentCommentId": "BhFWxNcvqkorhxgDC", "user": {"username": "NunoSempere"}}, {"_id": "eSAiGwzbNJs7ybJjq", "postedAt": "2022-09-12T21:51:49.619Z", "postId": "EPhDMkovGquHtFq3h", "htmlBody": "<p>Agreed that there are some contexts where there's more value in getting distributions, like with the Fermi paradox.</p><p>Or, before the grants are given out, you could ask people to give an ex ante distribution for \"what will be your ex post point estimate of the value of this grant?\" That feeds directly into VOI calculations, and it is clearly defined what the distribution represents. But note that it requires focusing on point estimates ex post.</p>", "parentCommentId": "BhFWxNcvqkorhxgDC", "user": {"username": "Dan_Keys"}}, {"_id": "CkbFAfyniJaWQoEXJ", "postedAt": "2022-09-13T12:09:15.465Z", "postId": "EPhDMkovGquHtFq3h", "htmlBody": "<p>&gt; Or, before the grants are given out, you could ask people to give an ex ante distribution for \"what will be your ex post point estimate of the value of this grant?\" That feeds directly into VOI calculations, and it is clearly defined what the distribution represents. But note that it requires focusing on point estimates ex post.</p><p>Aha, but you can also do this when the final answer is also a distribution. In particular, you can look at the KL-divergence between the initial distribution and the answer, and this is also a proper scoring rule.</p>", "parentCommentId": "eSAiGwzbNJs7ybJjq", "user": {"username": "NunoSempere"}}, {"_id": "oyy3LBbLHjJGqkHYb", "postedAt": "2023-05-08T05:39:50.746Z", "postId": "EPhDMkovGquHtFq3h", "htmlBody": "<figure class=\"image\"><img src=\"http://res.cloudinary.com/cea/image/upload/v1667995027/mirroredImages/EPhDMkovGquHtFq3h/uagwwuiu2w5e08nexzz9.png\"></figure><blockquote><p>This produces an estimate of 0.52% of the future, or 52 basis points, which is around 6x higher than our initial estimate of 8.1 basis points.</p></blockquote><p>Isn't that chart mean = 0.052% = 5.2 basis points \u2248 the earlier pointwise estimate, not 0.52%, or am I misreading?</p>", "parentCommentId": null, "user": {"username": "Mo Nastri"}}, {"_id": "fqJCcqme7Ps2nvzpk", "postedAt": "2023-05-09T03:34:24.543Z", "postId": "EPhDMkovGquHtFq3h", "htmlBody": "<p>That seems correct, though now I am doubting myself.</p>", "parentCommentId": "oyy3LBbLHjJGqkHYb", "user": {"username": "NunoSempere"}}, {"_id": "mH6i7njQRox2CX6Yq", "postedAt": "2023-05-09T03:49:30.763Z", "postId": "EPhDMkovGquHtFq3h", "htmlBody": "<p>Sorry but the squiggle link doesn't work in footnote 4. I'd like to replicate it in a different colour just to look at graph properly.</p>", "parentCommentId": null, "user": {"username": "zichenghuang"}}]