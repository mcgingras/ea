[{"_id": "QKPsQX5ioSxS5borM", "postedAt": "2024-01-03T14:56:44.000Z", "postId": "8vrgD7f7RxjamZpS4", "htmlBody": "<p><strong>Executive summary</strong>: The essay series examines issues around relating to different agents and sharing power, especially as advanced AI systems emerge.</p><p><strong>Key points</strong>:</p><ol><li>Discusses being \"gentle\" toward non-human others like animals, aliens, and AIs, but notes the risk of \"getting eaten\" in the attempt.</li><li>Touches on technical and empirical issues relevant to AI risk, but focuses more on underlying philosophical assumptions.</li><li>Interrogates the influential philosophical views of Eliezer Yudkowsky regarding AI risk, but notes caring about AI safety does not require affiliation with his views.</li><li>Questions arise from trying to ensure the future goes well generally, not just from ensuring AIs don't kill everyone.</li><li>Aims to examine an abstract existential narrative that conversations about advanced AI often express, rather than Yudkowsky's views specifically.</li></ol><p>&nbsp;</p><p><i>This comment was auto-generated by the EA Forum Team. Feel free to point out issues with this summary by replying to the comment, and</i><a href=\"https://forum.effectivealtruism.org/contact\"><i>&nbsp;<u>contact us</u></i></a><i> if you have feedback.</i></p>", "parentCommentId": null, "user": {"username": "SummaryBot"}}]