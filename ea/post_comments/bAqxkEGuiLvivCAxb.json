[{"_id": "xoXQtjjPPn87Efzfp", "postedAt": "2015-05-22T00:22:59.097Z", "postId": "bAqxkEGuiLvivCAxb", "htmlBody": "<p>So like you, I\u2019ve been inspired by lots of people in the EA movement and I\u2019m optimistic that the EA movement can continue growing and do lots of good.</p>\n<p>However, the history of disasters teaches us that major disasters are often preceded by minor disasters of a similar sort.  If people took minor disasters more seriously and put stronger safeguards in place, there would be fewer major disasters.  \u201cOnly the paranoid survive\u201d, as Andy Grove says.</p>\n<p>I\u2019ve been really impressed by the reflectiveness and thoughtfulness of everyone I\u2019ve met through the EA movement.  But if the EA movement continues executing on its aggressive expansion plans, we\u2019ll eventually start seeing a larger population of EAs that are less reflective by disposition than our current set.  Someday they might even make up the majority of EAs.</p>\n<p>Because of this, I think it\u2019s worthwhile taking some time to figure out how to preserve our current culture (which I think is great for the most part) and guard against the failure modes that may come with growth.  As Rob Bensinger writes, \u201cThe value of growing the EA movement is instrumental, and conditional.\u201d  If we\u2019re ever going to codify our cultural norms, that feels like something we should do sooner rather than later.  As the movement grows, it\u2019s harder to get group buy-in on new proposed norms.</p>\n<p>The biggest failure modes I foresee right now fall under the broad category of \u201cpoliticization\u201d.  \u201cPoliticization\u201d doesn\u2019t refer to the discussion of traditionally political topics per se; rather, it refers to the dysfunctional conversational modes traditionally associated with political topics.  In principle any topic can be politicized (e.g. the color of the sky in <a href=\"http://lesswrong.com/lw/gt/a_fable_of_science_and_politics/\">this</a> short story).</p>\n<p>Unfortunately, politicization is hard to talk about because discussing it tends to trigger object-level discussion of politicized topics.  I\u2019ve been thinking about it a fair amount lately, but I haven\u2019t posted on it because I was afraid to trigger the wrong sort of discussion.  However, now that you\u2019ve brought the topic up, I may as well share some thoughts and hopefully contribute to a relatively nonpoliticized tone for this comment thread :)</p>\n<p>So my first question is what the best way to ratchet politicization down is once it has been ratcheted up.  It\u2019s possible that, like cockroaches or government corruption, it\u2019s a problem that\u2019s difficult to get rid of once you acquire it.  It\u2019s also possible that expert mediators are relatively good at defusing politicization, and all the EA community needs is a team of respected neutral mediators (\u201cflame war firefighters\u201d) to deal with problems as they arise.</p>\n<p>If there aren\u2019t reliable ways to ratchet politicization down, then we\u2019ll want to focus on prevention.</p>\n<p>You write: \u201cEffective altruism could become a movement of multiple communities, in which people of different political stripes or cluster-groups stick to their own.\u201d  I agree this would not <em>necessarily</em> be terrible, but it does seem <em>potentially</em> terrible.  I can imagine a community of republican EAs and a community of democrat EAs, each deciding that the best way to be an effective altruist is to donate and promote \u201ceffectively altruistic\u201d government policies (aka whichever policies they would have promoted anyway), and the two communities exactly cancel each other out with their work.</p>\n<p>Right now we are not even close to the failure mode I describe above.  The EA community currently has a strong norm against discussing government policy.  I think this is a good norm and we shouldn\u2019t let it degrade.  There\u2019s no question that improving policies can be high-impact, but if we allow discussion of policy on official EA channels, there\u2019s nothing preventing that discussion from degrading in to a typical internet flamewar as the movement grows.  If the EA movement ever wants to work on improving policy, we should do it very carefully.</p>\n<p>Another way politicization could happen is if certain causes within the EA movement amp up their rhetoric and aggressively go around trying to convince EAs that their cause is the best.</p>\n<p>This could trigger a corresponding response from other causes within the EA movement, and the official EA discussion channels could be flooded with cause prioritization discussion in the resulting arms race.  I think we should be ready to ban cause prioritization discussion on mainstream EA channels and restrict it to dedicated cause prioritization channels if this starts happening.  (E.g. a regular cause prioritization thread on this forum.)</p>\n<p>Even worse, a heated cause prioritization discussion favors simple, legible accusations of the form \u201cyou\u2019re a terrible person if you don\u2019t support my cause\u201d over the careful, reflective analysis that I currently see in the EA community.  I see EA\u2019s culture of careful, reflective analysis as the primary thing differentiating us from regular non-EA altruism.  If our standards of discussion degrade, we may lose what makes us different.</p>\n<p>I don\u2019t think there are easy solutions but being aware of potential problems seems valuable.</p>\n", "parentCommentId": null, "user": {"username": "John_Maxwell_IV"}}, {"_id": "GJhxB8MLwMv4ccSXm", "postedAt": "2015-05-22T02:07:43.227Z", "postId": "bAqxkEGuiLvivCAxb", "htmlBody": "<blockquote>\n<p>The EA community currently has a strong norm against discussing government policy.</p>\n</blockquote>\n<p>Does it? The <em>rationality</em> community has this norm because Politics Are The Mind-Killer, but I don't think it exists that much in EA. For instance, didn't the Global Priorities Project (or something) give policy advice to the UK government? And surely people have discussed GiveWell's criminal justice reform work.</p>\n", "parentCommentId": "xoXQtjjPPn87Efzfp", "user": {"username": "Ben_Kuhn"}}, {"_id": "3EGDpaMLXGz4hSjSw", "postedAt": "2015-05-22T02:21:09.046Z", "postId": "bAqxkEGuiLvivCAxb", "htmlBody": "<p>It seems pretty possible to ratchet down politicized discussion if you're careful about how you do it. Here are some general suggestions for fighting politicization:</p>\n<ul>\n<li><p>Talk about things in person if possible. When talking online, I've noticed that I often feel offended/attacked by remarks where, if someone had changed like two words of the remark with something else, I would have been fine with it (e.g. &quot;I think you're wrong to believe &quot; vs. &quot;it's disturbing that you believe &quot;). For some reason this doesn't seem to happen nearly as often in person, probably because it's higher bandwidth.</p>\n</li>\n<li><p>Talk about things one-on-one or in small groups if possible. On polarized topics, I sometimes have the experience of saying something centrist, then being attacked by people who don't like side A because I forgot to put in an anti-side-A caveat, and then being attacked by people who don't like side B because I forgot to put in an anti-side-B caveat and the anti-side-A caveat made me look to much like a side-B-person to them.</p>\n<p>  This can happen even if sides A and B are both essentially strawman positions that <em>nobody</em> in the discussion believes: the problem isn't that anyone is a tribalist for A or B, just that people are <em>worried about running into</em> A- or B-tribalists and argue with you to make sure you're not one. In a small enough group, it's much easier to remember which caveats you have to insert and which ones you can let people infer.</p>\n</li>\n<li><p>Be careful to separate people's arguments from people's character. As I recently wrote in the Facebook group (in response to someone saying &quot;it's sad to see people talking about  here&quot; and &quot;your attitude about Y is troubling&quot;):</p>\n<blockquote>\n<p>One can also correct people's misconceptions <em>without</em> shaming them--e.g., by being careful to imply that they're incorrect simply by being misinformed rather than out of some kind of malice or character flaw (which indeed they often are, though not always). For example, instead of saying &quot;it's sad that you believe &quot;--which immediately puts someone on the defensive, because now if they admit that you're right then they also have to admit that your judgment of their character was correct--you can say &quot;I don't think  is true.&quot; Instead of saying &quot; is troubling&quot;--which people sometimes interpret as not only meaning that you think they're wrong but that you think they're a bad person for believing it!--you can say &quot; suffers from &quot; or &quot; is actually harmful to express for .&quot;</p>\n<p>I'm not arguing that you should <em>believe</em> the second statement over the first, only that purely as an empirical matter it seems to create a more effective and thoughtful discussion. And I'm also not necessarily arguing that one should never shame, just that if one is specifically worried about not-shaming people, it's possible to dissent without shaming.</p>\n</blockquote>\n</li>\n</ul>\n", "parentCommentId": "xoXQtjjPPn87Efzfp", "user": {"username": "Ben_Kuhn"}}, {"_id": "54w8fukLZiLZJvEnf", "postedAt": "2015-05-22T03:44:46.226Z", "postId": "bAqxkEGuiLvivCAxb", "htmlBody": "<p>These seem like good suggestions.  I have my own list of suggestions <a href=\"http://lesswrong.com/lw/axn/6_tips_for_productive_arguments/\">here</a> if anyone is interested.  I think it would be valuable to institutionalize <em>some</em> set of suggestions by e.g. adding them to the set of links <a href=\"http://effective-altruism.com/ea/6x/introduction_to_effective_altruism/\">here</a>.  (I also like Paul Graham's <a href=\"http://www.paulgraham.com/disagree.html\">disagreement hierarchy</a> and your <a href=\"http://www.benkuhn.net/debate\">useful ideas in debate</a>.  And Scott Adams' idea of shorthand terms for debate tactics like &quot;<a href=\"http://blog.dilbert.com/post/109482303301/outragists-are-the-new-awful\">outragism</a>&quot; that we want to discourage.)</p>\n", "parentCommentId": "3EGDpaMLXGz4hSjSw", "user": {"username": "John_Maxwell_IV"}}, {"_id": "YakiNZhkgC2d27r3D", "postedAt": "2015-05-22T04:04:04.482Z", "postId": "bAqxkEGuiLvivCAxb", "htmlBody": "<p>Yeah, maybe it's not a &quot;strong&quot; norm, but I do perceive <em>some</em> norm and I think it's valuable.  I think I'm much more OK with EA organizations like Givewell doing policy research and delivering targeted policy recommendations vs casual policy discussion in the EA Facebook group.  Maybe because an individual organization is more likely to follow all the recommendations you describe <a href=\"http://effective-altruism.com/ea/j3/dont_be_discouraged_in_reaching_out_an_open_letter/3p8\">here</a>: employees discuss issues face-to-face in small groups, and are typically on sufficiently good terms to stay away from character assassinations.</p>\n<p>BTW, I'm tempted to nominate you as &quot;mediator of online EA discussions&quot; to fight <a href=\"http://en.wikipedia.org/wiki/Diffusion_of_responsibility\">diffusion of responsibility</a> in flamewar firefighting, but I guess your revealed preferences suggest that it's not a role that you particularly enjoy?  It's not a role that I particularly enjoy either.  I feel like part of the problem is that trying to carefully evaluate all sides of an issue and not be a jerk to everyone is a lot less fun than trying to win points for your side, so that's why the &quot;honest middle&quot; tends to leave a lot of politicized conversations and let extremists to duke it out.  (You probably have the moral authority to nominate someone else if you wanted to though.  Note that a &quot;mediator&quot; and a &quot;moderator&quot; are not quite the same thing... a &quot;moderator&quot; censors discussion that gets off track, whereas a &quot;mediator&quot; participates in discussions and tries to help each side understand the other.  It feels like a bad idea for both roles to be played by the same person.  I think ideally the EA community would have a sizable population of mediator types in order to keep us cohesive.  We want disagreements to be about facts, not personalities.)</p>\n", "parentCommentId": "GJhxB8MLwMv4ccSXm", "user": {"username": "John_Maxwell_IV"}}, {"_id": "DrWLBscMRtZeWE3ph", "postedAt": "2015-05-22T07:42:58.844Z", "postId": "bAqxkEGuiLvivCAxb", "htmlBody": "<p>I'm flattered by your nomination!</p>\n<p>I don't particularly enjoy flamewar firefighting, but it's not like I can't do it; it's just frustrating, distracting and not very immediately rewarding, and I don't feel very qualified even when I'm at the top of my game (let alone in the middle of a flamewar)! But you're not the first person to suggest this to me, so maybe I should update.</p>\n", "parentCommentId": "YakiNZhkgC2d27r3D", "user": {"username": "Ben_Kuhn"}}, {"_id": "CB5rJZLdFioTcmG86", "postedAt": "2015-05-22T18:11:42.825Z", "postId": "bAqxkEGuiLvivCAxb", "htmlBody": "<p>Where is the Ben post that this is referring to?</p>\n", "parentCommentId": null, "user": {"username": "Raemon"}}, {"_id": "SsrqTZ3cAZAz2j9Br", "postedAt": "2015-05-22T22:37:52.597Z", "postId": "bAqxkEGuiLvivCAxb", "htmlBody": "<blockquote>\n<p>The EA community currently has a strong norm against discussing government policy.</p>\n</blockquote>\n<blockquote>\n<p> does seem potentially terrible. I can imagine a community of republican EAs and a community of democrat EAs, each deciding that the best way to be an effective altruist is to donate and promote \u201ceffectively altruistic\u201d government policies (aka whichever policies they would have promoted anyway), and the two communities exactly cancel each other out with their work.</p>\n</blockquote>\n<p>I think we do not have anywhere near as strong a norm against this as is required. LW has it, though the line is constantly tested. In effective altruism, by contrast, we have Will MacAskill suggesting that supporting the Labour party might be the most effective thing to do (if you restricted yourself to domestic causes).</p>\n", "parentCommentId": "xoXQtjjPPn87Efzfp", "user": {"username": "Larks"}}, {"_id": "ZqhwtxLLxnm2uhcYD", "postedAt": "2015-05-22T23:34:06.104Z", "postId": "bAqxkEGuiLvivCAxb", "htmlBody": "<p>Preventative remark: I asked Evan not to link the post in the OP because I was worried it would distract the comments here into debates about the object-level merits of the discussion I was reacting to. I don't think that's a productive direction to go in on an Internet forum (not in general, just unproductive here, specifically because the Internet is a terrible medium for conveying nuance/defusing tension), so I'd suggest that people stay away from that topic here.</p>\n<p>(Not that this conversation seemed to be going in that direction; just making this remark out of an abundance of caution.)</p>\n", "parentCommentId": "CB5rJZLdFioTcmG86", "user": {"username": "Ben_Kuhn"}}, {"_id": "rRRqLszZohsK592DX", "postedAt": "2015-05-24T16:25:09.239Z", "postId": "bAqxkEGuiLvivCAxb", "htmlBody": "<p>Gotcha. If thats the case it'd have relaxed my mind if that point was addressed briefly rather than left to be assumed.</p>\n", "parentCommentId": "ZqhwtxLLxnm2uhcYD", "user": {"username": "Raemon"}}, {"_id": "6WpBNvypCadMAhbfa", "postedAt": "2015-05-26T08:36:27.545Z", "postId": "bAqxkEGuiLvivCAxb", "htmlBody": "<p>Can you remind me why we should rule out political issues from discussions about what is likely to be most effective please?</p>\n", "parentCommentId": "SsrqTZ3cAZAz2j9Br", "user": {"username": "tomstocker"}}, {"_id": "bbyPumC8Nt2RarSmG", "postedAt": "2015-05-27T00:01:16.770Z", "postId": "bAqxkEGuiLvivCAxb", "htmlBody": "<p>I've observed the last point happening among many people I know, including myself - people absorb and act on EA values while not necessarily remaining in the community. It seems like creating people who act by EA values is more important than creating an EA community per se. I'm not sure how much community building helps bring this about, though. It would be interesting to see more research and thinking on the connection between community building and generating new EAs (a similar debate is going on among animal activists at the moment).</p>\n", "parentCommentId": null, "user": {"username": "zdgroff"}}, {"_id": "fQfPhjT7aHvgTxMb6", "postedAt": "2015-05-27T00:05:38.203Z", "postId": "bAqxkEGuiLvivCAxb", "htmlBody": "<p>To push back a bit against the fear of multiple movements, it seems like you could have multiple movements that all overlap with EA. for instance, animal rights and global poverty both overlap with EA, as does immigration work and criminal justice, increasingly. This parallels social justice movements where, say, gay rights and women's rights both overlap with social justice, and I don't see too much harm coming from this (indeed, many social justice movements have tight alliances). Separation might allow specialization, which could easily be net positive.</p>\n", "parentCommentId": "xoXQtjjPPn87Efzfp", "user": {"username": "zdgroff"}}, {"_id": "vwBfCSfiGJ349bLDW", "postedAt": "2015-05-27T00:23:41.532Z", "postId": "bAqxkEGuiLvivCAxb", "htmlBody": "<p>Sure. As LW has long held, politics is the mindkiller. Even the most rational people apply significantly lower epistemic standards to political issues, and generally end up endorsing pretty much the positions you'd expect them to on the basis of arational reasons. A good recent example if you're on facebook would be the thread where Tyler asked for recommendations for speakers who could talk on Systemic Change, which quickly devolved into everyone simply naming their pet favourite politicians/activists.</p>\n<p><em>Edit: Actually, there are even better examples of where politics lead to EAs wasting a huge amount of effort in pointless arguments, but they're so political I'm afraid if I mention them here people will start arguing about them again!</em></p>\n<p>A secondary reason is that it is far more diversive than anything else we do. For most EA causes, it is reasonably uncontroversial that they are at least not actively bad - there are few pro-african-poverty, pro-increasing-meat-consumption, or pro-extinction activists. But this cannot be said of many political issues, which are extremely diversive. Michelle has previously written about this if I recall correctly.</p>\n", "parentCommentId": "6WpBNvypCadMAhbfa", "user": {"username": "Larks"}}, {"_id": "WQXb6Gk75v3TdSRDC", "postedAt": "2015-05-27T00:27:58.517Z", "postId": "bAqxkEGuiLvivCAxb", "htmlBody": "<blockquote>\n<p>A secondary reason is that it is far more diversive than anything else we do ... Michelle has previously written about this if I recall correctly.</p>\n</blockquote>\n<p><a href=\"http://effective-altruism.com/ea/d4/blind_spots_compartmentalizing/22r\">Found it: Michelle responding to one particularly diversive example</a>. Rob's reply outlines the standard response to this argument, namely that politically causes might happen to be much more effective than apolitical ones, so we will just have to accept the associated costs. </p>\n", "parentCommentId": "vwBfCSfiGJ349bLDW", "user": {"username": "Larks"}}, {"_id": "X5Gk7EwoetksQbsgP", "postedAt": "2015-05-27T12:59:04.287Z", "postId": "bAqxkEGuiLvivCAxb", "htmlBody": "<p>Tibetan monks I think used to have a tradition of a physical circle of rope that you could step into to debate openly - the idea being that you leave offense and bad feelings about what's said in the ring in the ring after the debate so you can have a free and open discussion. This kind of norm might be helpful but difficult over the internet. The costs of controversy for political action, however, seem to me to be something you should just factor in to your decision.</p>\n", "parentCommentId": "WQXb6Gk75v3TdSRDC", "user": {"username": "tomstocker"}}, {"_id": "YmQymm4KxsexAE3Cg", "postedAt": "2015-05-27T13:24:15.308Z", "postId": "bAqxkEGuiLvivCAxb", "htmlBody": "<p>Sure.  So if that's the case, this discussion could be reframed as trying to estimate just how high those &quot;controversy costs&quot; are likely to be.  My feeling is that the controversy costs are right-tailed, that is, there is a large probability of low/moderate costs but a small probability of large costs.   Something that happens to controversies as they grow is that as they become more and more visible, it becomes harder and harder to avoid commenting on them, which reinforces their growth.</p>\n<p>Personally, I think instead of working on policy in the near term, EA should think about how to think about policy... that is, why is it that policy discussions seem to predictably go wrong in a way that (say) effective malaria charity discussions don't, and how to fix that.  If we find plausible solutions, that's valuable in order to</p>\n<ol>\n<li><p>clarify our own political thinking as a movement and make sure that whichever policies we push for are the right ones</p>\n</li>\n<li><p>possibly improve the state of political discourse in general if our ideas are sufficiently compelling</p>\n</li>\n<li><p>replace zero-sum political competition between ideologically opposed people with a sensible nonpoliticized policy discussion where peoples views become more accurate</p>\n</li>\n</ol>\n<p>In the EA Facebook thread Larks mentions, I said this and got 9 likes:</p>\n<blockquote>\n<p>Aligning ourselves with almost any prominent political pundit at this stage risks alienating people who disagree with that pundit. EA is mostly liberal now; if we have a liberal speaker, that will make it even harder to interest conservatives. (Ideological diversity is the most valuable kind of diversity, so this matters.) Choosing a conservative or neutral pundit is a safer choice from this perspective. Tyler Cowen seems relatively sensible, non-polarizing, and thoughtful: <a href=\"http://www.ted.com/.../tyler_cowen_be_suspicious_of_stories\">video link</a></p>\n</blockquote>\n<blockquote>\n<p>I\u2019m optimistic that EA will be able to tackle political issues in the long run. But we have to do it right. In the same way none of us can be expected to choose charities as well as Givewell does in our spare time, none of us should assume that whatever political beliefs we\u2019ve acquired in our spare time correlate all that well with the truth on political topics. (Note that politics is far more epistemically hazardous than evaluating developing world charities. See filter bubbles, tribalism, politically motivated distortions, confirmation bias, etc.) I think the way to do it would be to put an ideologically diverse group of EAs together in the same office reading papers and discussing political issues full-time.</p>\n</blockquote>\n<blockquote>\n<p>This is similar to a \u201cthink tank\u201d, which already exists. I think nonpartisan groups like the RAND Corporation and maybe thoughtful news sources like Vox.com and the Center for Public Integrity are probably the closest thing to EA organizations in the US politics space. They\u2019ve been accumulating prestige &amp; influence for a while. So it\u2019s not clear to me whether the best approach would be to create a rival org or try to influence those orgs to take a more EA approach (through funding them, joining up, etc.) Getting partisan think tanks to work together better (e.g. conduct studies together?) is a more interesting and exotic idea. Howie Lempel might have something to say since he used to work at a think tank.</p>\n</blockquote>\n<p>Maybe this would be worth expanding in to a post on this forum with a more formal &amp; fleshed-out proposal?</p>\n", "parentCommentId": "X5Gk7EwoetksQbsgP", "user": {"username": "John_Maxwell_IV"}}, {"_id": "tcsMcKxNK5rS6BBC4", "postedAt": "2015-05-27T13:46:05.204Z", "postId": "bAqxkEGuiLvivCAxb", "htmlBody": "<p>Yes, I think these ideas are pretty good - especially working more closely with politically enaged people and deeply engaging people from different ideational political traditions. I'm a little worried that some of these exercises might create the internal controversy and confusion without changing anything? It might be interesting to provide a platform for EAs engaging in political opportunities as they see them as individuals and catch up with the rest of the group about what they're learning? There's a lot you can do before having to transform the nature of political debates...</p>\n", "parentCommentId": "YmQymm4KxsexAE3Cg", "user": {"username": "tomstocker"}}]