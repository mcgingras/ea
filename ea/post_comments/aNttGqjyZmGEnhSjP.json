[{"_id": "c6cKjmq8MnktPnzuM", "postedAt": "2023-02-16T17:12:19.964Z", "postId": "aNttGqjyZmGEnhSjP", "htmlBody": "<p>I think Ozy Brennan's <a href=\"https://thingofthings.substack.com/p/my-disagreements-with-doing-ea-better\">response</a> to this section was very good. To quote the relevant section (though I would encourage readers to read the whole piece, which also includes some footnotes) :&nbsp;</p><blockquote><p>It is true that effective altruism is very homogeneous, and this is a problem. I am 100% behind inclusivity efforts. And I praise the authors for their observation that inclusivity goes beyond the standard race/class/gender to matters of culture and intellectual diversity.</p><p>However, I think that this subject should be addressed with care. When you\u2019re talking about homogeneity, it\u2019s important to acknowledge effective altruist members of various groups underrepresented in effective altruism. Very few things are more unwelcoming than \u201cby the way, people like you don\u2019t exist here.\u201d</p><p>Further, the description itself is offensive in many ways. Describing the average member of a movement with as many Jews as effective altruism as \u201cculturally Protestant\u201d is quite anti-Semitic. The authors fail to mention queerness and transness, probably because it would be a bit inconvenient for their point to mention that an enormous number of EAs are bisexual and trans women are represented in EA at something like forty times the population rate. The average effective altruist is \u201cneurodivergent\u201d which\u2026 is a bad thing, apparently? We need to go represent the neurotypical point of view, which is inescapable everywhere else in politics, corporations, and the media? The vague term \u201cneurodivergence\u201d actually understates the scale of effective altruism\u2019s inclusion problem. Effective altruism is inclusive of a relatively narrow range of neurodivergences: it\u2019s strikingly unwelcoming of, say, non-Aspie autistics.</p><p>Finally, some of this homogeneity is about things that are\u2026 true? I realize it\u2019s rude to say so, but consuming animal products in the vast majority of situations <i>in fact</i> supports an industry which tortures animal and God <i>in fact</i> doesn't exist.I am glad that the effective altruism movement has reached general consensus on these things! Effective Altruist Political Ideology is hardly correct in every detail, but I don't think it's a bad sign if a movement broadly agrees on a lot of political issues. Some political policies are harmful! Other policies make things better!</p><p>Further, perhaps I am interpreting the authors uncharitably, but I suspect that when they say \u201cthere should be more diversity of political opinions\u201d they mean \u201cthere should be more leftists.\u201d I am just <i>ever-so-slightly suspicious</i> that if my <a href=\"https://youtu.be/2NoSZYnyPsw?t=9\"><u>one-sided archnemesis</u></a> <a href=\"https://richardhanania.substack.com/\"><u>Richard Hanania</u></a> showed up with a post about how the top cause area is fighting wokeness, the authors would not be happy with this and in fact would probably start talking about racism. Which is fine! I too agree that fighting wokeness is not the top cause area! But in this case your criticism is not \u201ceffective altruism should be more inclusive of different political views,\u201d it\u2019s \u201ceffective altruism\u2019s political views are wrong and they should have different, correct ones,\u201d and it is dishonest to smuggle it in as an inclusivity thing.</p></blockquote>", "parentCommentId": null, "user": {"username": "MHR"}}, {"_id": "mpF8YhQ6GBWibyfaQ", "postedAt": "2023-02-16T20:01:43.927Z", "postId": "aNttGqjyZmGEnhSjP", "htmlBody": "<p>I remain of the opinion that posts made in good faith should not be voted below one karma without a pretty good reason. The original Doing EA Better was just too massive to facilitate discussion of specifics, and splitting it up to facilitate more specific discussion seems reasonable. I do not see a good reason for this to have negative karma.</p>\n", "parentCommentId": null, "user": {"username": "Jason"}}, {"_id": "Fb7mvLp4XCRsqC8Hy", "postedAt": "2023-02-16T20:04:24.922Z", "postId": "aNttGqjyZmGEnhSjP", "htmlBody": "<p>A charitable interpretation would be that it's a symptom of there being no separate way to 'upvote and disagreevote' something that a Forum user thinks is important but still disagree with. -5 from 17 (at time of writing) does seem unbalanced though, especially given the original DEAB post was highly upvoted, and one of the most common suggestions was for the authors to break it up into smaller chunks</p>", "parentCommentId": "mpF8YhQ6GBWibyfaQ", "user": {"username": "JWS"}}, {"_id": "vnd8hprDiTb8NDtjq", "postedAt": "2023-02-16T20:35:30.546Z", "postId": "aNttGqjyZmGEnhSjP", "htmlBody": "<p>I think the unfortunate absence of disagreevote on posts is a good bit of what we are seeing. Given the single vote type, I'm <em>more</em> okay with downvote-to-disagreevote on posts that have a decent amount of karma. But negging a substantial post sends an implied message that the content was inappropriate or unwelcome, which comes across as somewhat unfriendly at best.</p>\n<p>(For comments, negging serves a more useful purpose in rank ordering comments, and getting a light neg on a five-line comment just doesn't have the same sting as on a substantial post.)</p>\n", "parentCommentId": "Fb7mvLp4XCRsqC8Hy", "user": {"username": "Jason"}}, {"_id": "jCu6vHEpLzC9WZydt", "postedAt": "2023-02-16T20:49:39.031Z", "postId": "aNttGqjyZmGEnhSjP", "htmlBody": "<p>You state:\n\"Effective Altruist Political Ideology is hardly correct in every detail, but I don't think it's a bad sign if a movement broadly agrees on a lot of political issues. Some political policies are harmful! Other policies make things better!\"</p>\n<p>I identified EA as right-leaning because of lack of EA concern about climate change, as well as an emphasis in other areas (economics, personal finances, corporate regulation, technology development) that matches a right-leaning worldview. However, according to this <a href=\"https://forum.effectivealtruism.org/posts/S2Sonawxz2cY4YdXK/ea-survey-2018-series-community-demographics-and\">2018 survey </a>,  EA's lean left, more than 60%.</p>\n<p>There's some overlap or really, flexibility, in how lefties in California approach financial and economic issues. Their left-leaning ideology expresses itself with opinions on abortion, racism, and climate change, and less with opinions about taxation, corporate regulation, or technology development. Which leads me to conclude that it is not helpful for me to identify EA's with larger movements when dealing with EA views on specific issues. Better to focus on a specific EA brand of political ideology being developed inside the movement, and describe its formative influences (as the OP does), than to assume a more typical political ideology is present, such as liberal or conservative ideologies.</p>\n<p>You state:\n\"However, I think that this subject should be addressed with care. When you\u2019re talking about homogeneity, it\u2019s important to acknowledge effective altruist members of various groups underrepresented in effective altruism. Very few things are more unwelcoming than 'by the way, people like you don\u2019t exist here.'\"</p>\n<p>You think that acknowledging the diversity already present in EA is important, and I agree. The ConcernedEA's don't intend to insult or isolate any group. They are sincere in wanting to increase diversity in the EA movement, and their statements are to the effect that \"The EA movement lacks diversity that would strengthen it provided there were some necessary overlap in values held by all.\"</p>\n", "parentCommentId": "c6cKjmq8MnktPnzuM", "user": {"username": "Noah Scales"}}, {"_id": "hmLMajYMGbHKcbKgT", "postedAt": "2023-02-16T21:54:16.284Z", "postId": "aNttGqjyZmGEnhSjP", "htmlBody": "<p>While I haven't voted either way on this post, I think it is one of the least well done portions of the original larger post. Ozy's response, quoted in the comment above, shows how this post is harmful on its own terms.</p>\n", "parentCommentId": "mpF8YhQ6GBWibyfaQ", "user": {"username": "Jeff_Kaufman"}}, {"_id": "9rNSgxRABp5EM9ATj", "postedAt": "2023-02-16T22:03:17.304Z", "postId": "aNttGqjyZmGEnhSjP", "htmlBody": "<h1>About steel-manning vs charitably interpreting</h1>\n<p>The ConcernedEA's state:</p>\n<p>\"People with heterodox/'heretical' views should be actively selected for when hiring to ensure that teams include people able to play 'devil\u2019s advocate' authentically, reducing the need to rely on highly orthodox people accurately steel-manning alternative points of view\"</p>\n<p>I disagree. Ability to accurately evaluate the views of the heterodox minority depends on developing a charitable interpretation (not necessarily a steel-manning) of the views. Furthermore, if the majority can not or will not develop such a charitable interpretation, then the heretic must put their argument in a form that the majority will accept (for example, using jargon and selectively adopting non-conflicting elements of the majority ideology).  This unduly increases burden on the person with heterodox views.</p>\n<p>The difference between a charitably -interpreted view and a steel-manned view is that the steel-manned view is strengthened to seem like a stronger argument to the opposing side. Unfortunately, if there are differences in evaluating strength of evidence or relevance of lines of argument (for example, due to differing experiences between the sides),  then steel-manning will actually distort the argument. A charitable interpretation only requires that you accurately determine what the person holding the view intends to mean when they communicate it, not that you make the argument seem correct or persuasive to you.</p>\n<p>Sometimes I think EA's mean \"charitable interpretation\" when they write \"steel-manning\". Other times I think that they don't. So I make the distinction here.</p>\n<p>It's up to the opposing side to charitably interpret any devil's advocate position or heretical view. While you could benefit from including diverse viewpoints, the burden is on you to interpret them correctly, to gain any value available from them.</p>\n<h1>Developing charitable interpretation skills</h1>\n<p>To charitably interpret another's viewpoint takes Scout Mindset, first of all. With the wrong attitude, you'll produce the wrong interpretation no matter how well you understand the opposing side. It also takes some pre-existing knowledge of the opposing side's worldview, typical experiences, and typical communication patterns. That comes from research and communication skills training. Trial-and-error also plays a role: this is about understanding another's culture, like an anthropologist would. Immersion in another person's culture can help.</p>\n<p>However, I suspect that the demands on EA's to charitably interpret other people's arguments are not that extreme. Charitable interpretations are not that hard in the typical domains you require them. To succeed with including heterodox positions, though, demands on EA's empathy, imagination, and communication skills do go up.</p>\n<h2>About imagination, communication skills, and empathy for charitably interpreting</h2>\n<p>EA's have plenty of imagination, that is, they can easily consider all kinds of strange views, it's a notable strength of the movement, at least in some domains. However, EA's need training or practice in advanced communication skills and argumentation. They can't benefit from heterodox views without them. Their idiosyncratic takes on argumentation (adjusting Bayesian probabilities) and communication patterns (schelling points) fit some narrative about their rationalism or intelligence, I suppose, but they could benefit from long-standing work in communication, critical thinking, and informal logic. As practitioners of rationalism to the degree that mathematics is integral, I would think that EA's would have first committed their thinking to consistent analysis with easier tools, such as inference structures, setting aside word-smithing for argument analysis. Instead, IBT gives EA's the excuse not to grapple with the more difficult skills of analyzing argument structures, detailing inference types, and developing critical questions about information gaps present in an argument. EDIT: that's a generalization, but is how I see the impact of IBT in practical use among EA's.</p>\n<p>The movement has not developed in any strong way around communication skills specifically, aside from a commitment to truth-seeking and open-mindedness, neither of which is required in order to understand others' views, but are still valuable to empathy.</p>\n<p><em>There's a generalization that \"lack of communication skills\" is some kind of remedial problem. There are communication skills that fit that category, but those skills are not what I mean.</em></p>\n<p>After several communication studies courses, I learned that communication skills are difficult to develop, that they require setting aside personal opinions and feelings in favor of empathy, and that specific communication techniques require practice.  A similar situation exists with interpreting arguments correctly: it takes training in informal logic and plenty of practice. Scout mindset is essential to all this, but not enough on its own.</p>\n<p>Actually, Galef's podcast Rationally Speaking includes plenty of examples of  charitable interpretation, accomplished through careful questions and sensitivity to nuance, so there's some educational material there.</p>\n<p>Typically the skills that require practice are the ones that you (and I) intentionally set aside at the precise time that they are essential: when our emotions run high or the situation seems like the wrong context (for example, during a pleasant conversation or when receiving a criticism). Maybe experience helps with that problem, maybe not. It's a problem that you could address with cognitive aids, when feasible.</p>\n<h1>Is moral uncertainty important to collective morality?</h1>\n<p>Ahh, am I right that you see the value of moral uncertainty models as their use in establishing a collective morality given differences in the morality held by individuals?</p>\n", "parentCommentId": null, "user": {"username": "Noah Scales"}}, {"_id": "vopBssZ8a79PXg5gt", "postedAt": "2023-02-16T22:20:17.070Z", "postId": "aNttGqjyZmGEnhSjP", "htmlBody": "<p>I recall at least one, possibly both, of the other segments being in the negative at certain points in time before settling to weakly positive karma. My memory could be wrong, but that suggests that the early negative vote isn't primarily a function of this particular segment being problematic.</p>\n", "parentCommentId": "hmLMajYMGbHKcbKgT", "user": {"username": "Jason"}}, {"_id": "ETd8As8Yvb2GKuf3Y", "postedAt": "2023-02-16T23:51:44.756Z", "postId": "aNttGqjyZmGEnhSjP", "htmlBody": "<p>If there was no difference at all between the beliefs/values/behaviours of a the average member of this community, versus the average member of the human species - then there would be no reson for the concept \"Effective Altruism\" to exist at all.<br><br>It would be a terrible thing for our community to directly discriminate against traits which are totally irrelevant to what someone has offer to the EA project (such as race/gender/sexual preference) - and I've never heard anyone around here disagree with that.<br><br>But when it comes to a traits such as being highly intelligent, not being a political extremist, or having intellectual curiosity about any part of the universe other than our comparitively tiny planet (aka \"thinks space is cool\") - having these traits be &nbsp;over-represented in the community is an obviously good thing!<br><br>Dear authors, if you think the community at large has the wrong idea about moral philosophy, I think the best response is to present compelling arguments which criticize utilitarianism directly!<br><br>If you think the community at large has the wrong economic/political beliefs, please argue against these directly!<br><br>Or if you think there is a a particular organisation in the movement is making a particular mistake which they wouldn't have made had they consulted more domain experts, please lay out a compelling case for this as well!</p>", "parentCommentId": null, "user": {"username": "Xavier_ORourke"}}, {"_id": "nD58kypSHHpFnNnEd", "postedAt": "2023-02-17T06:24:11.490Z", "postId": "aNttGqjyZmGEnhSjP", "htmlBody": "<p>I upvoted this post due to this comment. I don\u2019t see a good reason for this to have negative karma either.</p>\n", "parentCommentId": "mpF8YhQ6GBWibyfaQ", "user": {"username": "casebash"}}, {"_id": "waphtFHMyFPnieBMo", "postedAt": "2023-02-17T11:12:42.175Z", "postId": "aNttGqjyZmGEnhSjP", "htmlBody": "<p>Personally, I don't think it's a problem if a substantial post has negative karma. Someone could read a post, agree that it was well-written and detailed, but still think it was bad and that they'd want to see fewer posts like it. A downvote seems like the right response there.</p><p>Overall, I think there's a tendency for people to upvote things more often when they are very long, and that this is one factor that pushes the average Forum post to be too long. This makes me especially wary about norms like \"negging a substantial post is somewhat unfriendly\".</p><p>That said, I'd be quite happy to see disagree-voting added to posts, since many people would find it useful (including me!).</p>", "parentCommentId": "vnd8hprDiTb8NDtjq", "user": {"username": "aarongertler"}}, {"_id": "2CtJccqo4fPmSxzXD", "postedAt": "2023-02-17T14:28:23.472Z", "postId": "aNttGqjyZmGEnhSjP", "htmlBody": "<p>I think I shut my epistemology brain off at \"make beliefs pay rent in anticipated experiences\" when I first got sequences pilled. Emphasizing predictions and being wrong, constraining anticipation, this is I think the most productive way to think about belief. I definitely kept grinding up applied epistemology by reading Jaynes or something like that. But I still haven't seen an adequate argument that I'm wrong about feeling like we solved ways of knowing. Sometimes a subset of philosophy gets solved! You can even bring in the merits of <a href=\"https://forum.effectivealtruism.org/posts/NzPwFfzJur5bMmHTg/\">standpoint epistemology</a> under the banner of making beliefs pay rent by celebrating how much demographic diversity improves your brier score, if you want, I think that'd be clearheaded and understandable!&nbsp;</p>", "parentCommentId": null, "user": {"username": "quinn"}}, {"_id": "KCkt9sE7bA9u8o6pw", "postedAt": "2023-02-17T18:11:09.411Z", "postId": "aNttGqjyZmGEnhSjP", "htmlBody": "<p>Agree on not upvoting for length; I meant \"substantial\" to exclude shower thoughts and similar material that should clearly should be a shortform.</p><p>I think a net karma of (say) +5 conveys pretty effectively that the community doesn't think much of the post and \"want[s] to see fewer posts like\" it. The difference between that and a net karma of -5 is that the latter comes across as a sanction. Although people ideally wouldn't take karma on their posts personally, people are also human and are prone to do so. And it's well-documented that people tend to view taking away something they had (say, $100) as significantly more negative than acquiring the same thing.</p><p>So, if posts were movies, ending up with +5 (where the median post gets much more) is somewhat like bombing at the box office and being panned by the critics. Everyone gets the message loud and clear. Getting -5 is inching closer to receiving a <a href=\"https://en.wikipedia.org/wiki/Golden_Raspberry_Awards\">Razzie</a>. That feels like potential overdeterrence to me unless there are strong reasons for the award.</p><p>Also, a downvote is a blunt instrument, and it's worth thinking about the message that assigning a net negative karma to a reasonably well-written, medium-or-higher effort post sends to newer and casual users. I fear that message will often come across as \"Better not write something the majority disagrees with; the same thing might happen to you.\" Any karma system almost inevitably incentivizes widely-acceptable bromides already, and I think assigning net negative karma to reasonably high-effort posts absent strong reason risks intensifying that tendency. (To be clear, I have standard downvoted at least two posts already in the negative this week, one for a click-baity title and one for excessive promotion of a for-profit enterprise, so I am not suggesting strong reasons do not occur.)</p><p>In the end, I don't think any marginal increase in signalling that is achieved by net negative (vs. very low positive) karma is worth the downsides of net negative karma in most cases of good-faith, rule-compliant, reasonable-effort posts.</p>", "parentCommentId": "waphtFHMyFPnieBMo", "user": {"username": "Jason"}}, {"_id": "8XDZitCbvHz5CciWh", "postedAt": "2023-02-18T01:32:27.880Z", "postId": "aNttGqjyZmGEnhSjP", "htmlBody": "<p>Thanks for continuing to engage so thoughtfully!</p><p>I agree that +5 and -5 will feel more different to most people than +5 and +15.</p><p>I think this reflects a common dilemma with karma systems, which is that people tend to use them in one of two ways:</p><ol><li>Voting based on how they feel about content, without regard for its current karma</li><li>Voting so that they bring content closer to the karma score they think it should have</li></ol><p>There are many cases where I've seen a comment at, say, -10, and I've had the thought \"I dislike this comment, but -10 seems too harsh\", and I've had to choose whether to upvote or downvote (or leave it alone).</p><p>My behavior in those cases isn't consistent \u2014 it depends on the context, my mood, etc.</p><p>&nbsp;</p><p>I expect that method (2) leads to fewer pile-ons and reduces echo chamber effects. But it also creates a weird dynamic where people are upvoting things they think are bad and vice-versa to make a more complicated point (<a href=\"https://electionscience.org/about/meet-the-team/\">what would Aaron Hamlin say?</a>).&nbsp;</p><p>If someone were deciding how to vote on my post, I think I'd want them to just express their feelings regardless of what other people had done, because that result would feel more \"true\" to me and give me more information about what readers actually thought.</p><p>&nbsp;</p><p>I'm not sure there is a right answer in the end, and I'm definitely not confident enough to try to push people in one direction or the other (to the point of calling it \"unfriendly\" to downvote posts below zero, or, say, \"dishonest\" to vote against one's feelings).</p>", "parentCommentId": "KCkt9sE7bA9u8o6pw", "user": {"username": "aarongertler"}}, {"_id": "GCxJRNENbZ9CumsMv", "postedAt": "2023-02-19T20:14:43.297Z", "postId": "aNttGqjyZmGEnhSjP", "htmlBody": "<p>I definitely think it\u2019s a good idea for EA to expand the variety of academic disciplines of its members. I certainly think that the social sciences would benefit EA- for example, sociology could give us a framework of the social, cultural, and institutional relationships that underlie the problems found within developing countries. This could inform how we direct our resources. I also think that EAs may be blindsided to the idea that diversity increases a group\u2019s collective intelligence because we assume that we already recruit the most talented people (e.g., highly educated people studying the most relevant subjects). Therefore, if we recruit the most talented people, then our epistemics is surely top-notch. This therefore excludes lots of people, especially those in poorer countries where education isn\u2019t as easily accessible, and ways of thinking/knowing.&nbsp;</p>", "parentCommentId": null, "user": {"username": "andrew_goldbaum"}}, {"_id": "8dz3GipRfEbMJYTAW", "postedAt": "2023-02-24T16:47:11.252Z", "postId": "aNttGqjyZmGEnhSjP", "htmlBody": "<p>Not sure at all how Doing EA Better is 'quite anti-semitic', and I certainly think accusations of anti-semitism shouldn't just be thrown around, particularly given how common a problem of anti-semitism actually is. I certainly don't see how &nbsp;a rather amusing sterotypical EA description as 'culturally Protestant' is antisemitic; whilst there are lots of us Jews in EA, I'm not sure I find it at all offensive to not be mentioned!</p><p>I also strongly disagree that Doing EA Better suggests having lots of Sams in it is bad (hell, they say that such a description fits 'Several of the authors of this post fit this description eerily well'), and so I'm not sure the accusations of, say, anti-neurodivergent people or antisemitism really hold much water. I also don't get how 'eats a narrow range of vegan ready meals' becomes 'think being vegan is bad'; it reads to me like a comment on how cultuyrally homogenous we are that huel, bol and planty etc could be a cultural thing, rather than all the other vegan foods out there&nbsp;</p>", "parentCommentId": "c6cKjmq8MnktPnzuM", "user": {"username": "Gideon Futerman"}}, {"_id": "gPnFgcH7WJwX9rWMp", "postedAt": "2023-02-27T08:49:04.530Z", "postId": "aNttGqjyZmGEnhSjP", "htmlBody": "<p>+1 to \"how is this anti-Semitic?\" (I'm also Jewish)</p>\n", "parentCommentId": "8dz3GipRfEbMJYTAW", "user": {"username": "Guy Raveh"}}]