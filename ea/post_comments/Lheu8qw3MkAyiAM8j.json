[{"_id": "2pceQHiGFgvjeiqHY", "postedAt": "2023-12-12T22:46:19.584Z", "postId": "Lheu8qw3MkAyiAM8j", "htmlBody": "<p>And if no one is working on it, is there an organisation that would be interested in starting working on it?</p>", "parentCommentId": null, "user": {"username": "WillPearson"}}, {"_id": "fxTNzEuq8kkpr2FwD", "postedAt": "2023-12-13T00:06:35.296Z", "postId": "Lheu8qw3MkAyiAM8j", "htmlBody": "<p>I don't currently understand what area of work you're trying to point out with this question. You might want to be more specific to get good answers.<br><br>Here are some different things which you might be trying to talk about:</p><p>&nbsp;</p><ol><li>From a philosophical perspective, when is ML itself unethical due to effectively causing the death of some agent? (Or replace ML with other selection techniques.)</li><li>If we have economic selection pressures over digital minds/AIs what sorts of predictable problematic outcomes result?</li><li>If we select ML systems to achieve good results according to a lossy reward signal we might run into issue (e.g. reward hacking), what can we do to resolve this?</li></ol><p>For (2) you might be interested in the sort of discussion in \"Age of EM\", though I expect that the situation is pretty different in the de novo AI case.</p>", "parentCommentId": null, "user": {"username": "Ryan Greenblatt"}}, {"_id": "PaeCKjGqitgnjDddT", "postedAt": "2023-12-13T00:38:45.874Z", "postId": "Lheu8qw3MkAyiAM8j", "htmlBody": "<p>I've clarified the question, does it make more sense now?</p>", "parentCommentId": "fxTNzEuq8kkpr2FwD", "user": {"username": "WillPearson"}}, {"_id": "ieDmXDw4HRahsYhg7", "postedAt": "2023-12-13T01:54:44.633Z", "postId": "Lheu8qw3MkAyiAM8j", "htmlBody": "<p>Yes.</p>", "parentCommentId": "PaeCKjGqitgnjDddT", "user": {"username": "Ryan Greenblatt"}}]