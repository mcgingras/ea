[{"_id": "jsvh2ZMdcEEoT8HWj", "postedAt": "2023-07-24T14:59:29.008Z", "postId": "YGsojZYtEsj2A3PjZ", "htmlBody": "<p>This is a useful pair of posts, thanks for writing. I've added them both to my <a href=\"https://forum.effectivealtruism.org/posts/NnygBgntvoGSuvsRH/ai-timelines-by-bio-anchors-the-debate-in-one-place\">bio anchors collection</a>.</p>", "parentCommentId": null, "user": {"username": "Will Aldred"}}, {"_id": "yDFxppaaFdijcpvpw", "postedAt": "2023-07-25T05:08:08.396Z", "postId": "YGsojZYtEsj2A3PjZ", "htmlBody": "<blockquote><ul><li>I haven\u2019t considered all of the inputs to Cotra\u2019s model, most notably the 2020 training computation requirements distribution. Without forming a view on that, I can\u2019t really say that ~53% represents my overall view.</li></ul></blockquote><p>Sorry to bang on about this again and again, but it's important to repeat for the benefit of those who don't know: The training computation requirements distribution is by far the biggest cruxy input to the whole thing; it's the input that matters most to the bottom line and is most subjective. If you hold fixed everything else Ajeya inputs, but change this distribution to something I think is reasonable, you get something like 2030 as the median (!!!) Meanwhile if you change the distribution to be even more extreme than Ajeya picked, you can push timelines arbitrarily far into the future.<br><br>Investigating this variable seems to have been beyond scope for the XPT forecasters, so this whole exercise is IMO merely that -- a nice exercise, to practice for the real deal, which is when you think about the compute requirements distribution.</p>", "parentCommentId": null, "user": {"username": "kokotajlod"}}, {"_id": "T44ojAutbd3oStKj4", "postedAt": "2023-07-25T08:39:12.539Z", "postId": "YGsojZYtEsj2A3PjZ", "htmlBody": "<p>Don't apologise, think it's a helpful point!</p><p>I agree that the training computation requirements distribution is more subjective and matters more to the eventual output.</p><p>I also want to note that while on your view of the compute reqs distribution, the hardware/spending/algorithmic progress inputs are a rounding error, this isn't true for other views of the compute reqs distribution. E.g. for anyone who <i>does</i> agree with Ajeya on the compute reqs distribution, the XPT hardware/spending/algorithmic progress inputs shift median timelines from ~2050 to ~2090, which is quite consequential. (See <a href=\"https://forum.effectivealtruism.org/posts/ccw9v9giKxg8nyLhp/xpt-forecasts-on-some-biological-anchors-inputs\">here</a>)</p><p>For someone like me, who hasn't thought about the compute reqs distribution properly, I basically agree that this is just an exercise (and in isolation doesn't show me much about what my timelines should be). But for those who have thought about it, the XPT inputs could either not matter at all (e.g. for you), or matter a lot (e.g. for someone with Ajeya's compute reqs distribution).</p>", "parentCommentId": "yDFxppaaFdijcpvpw", "user": {"username": "rosehadshar"}}, {"_id": "LeCHiQbFpDCdY4jBo", "postedAt": "2023-07-25T09:05:14.153Z", "postId": "YGsojZYtEsj2A3PjZ", "htmlBody": "<p>Do you have a write-up of your beliefs that lead you to 2030 as your median?</p>\n", "parentCommentId": "yDFxppaaFdijcpvpw", "user": {"username": "jooke"}}, {"_id": "BKdvAHAx2pgp9m5km", "postedAt": "2023-07-25T17:03:50.355Z", "postId": "YGsojZYtEsj2A3PjZ", "htmlBody": "<p>It's the crux between you and Ajeya, because you're relatively more in agreement on the other numbers. But  I think that adopting the xpt numbers on these other variables would slow down your own timelines notably, because of the almost complete lack of increase in spending.</p>\n<p>That said, if the forecasters agreed with your compute requirements, they would probably also forecast higher spending.</p>\n", "parentCommentId": "yDFxppaaFdijcpvpw", "user": {"username": "Lukas_Finnveden"}}, {"_id": "avt7MmLv3SMfsHxxu", "postedAt": "2023-07-26T09:29:09.616Z", "postId": "YGsojZYtEsj2A3PjZ", "htmlBody": "<blockquote><ul><li>I feel pretty uncertain about this sort of modeling in general. It feels very sensitive to assumptions and inputs. If it were really hard to get the model to put any significant probability on TAI this century, I\u2019d take that as an update (similarly with the model making TAI soon look very very likely). But for most middling values I\u2019m not personally inclined to base too much on them.</li></ul></blockquote><p>&nbsp;</p><p>Yes - this needs to be said again, and again, and again. And then people need to consider how valuable arguing about the details of these models really is.&nbsp;</p><p>And yes, I think that it's incredibly valuable for people to have done thinking about this in public, but the difference between 25% and 75% probability of AGI in a decade is a tiny rounding error for this type of modeling compared to the uncertainties and approximations, and the fact that we're talking about a loose proxy for an upper bound anyways!</p>", "parentCommentId": null, "user": {"username": "Davidmanheim"}}, {"_id": "y6p8ckiShzW3bLKAw", "postedAt": "2023-07-26T17:34:11.281Z", "postId": "YGsojZYtEsj2A3PjZ", "htmlBody": "<p>The XPT forecasters are so in the dark about compute spending that I just pretend they gave more reasonable numbers. I'm honestly baffled how they could be so bad. The most aggressive of them thinks that in 2025 the most expensive training run will be $70M, and that it'll take 6+ years to double thereafter, so that in 2032 we'll have reached $140M training run spending... do these people have any idea how much GPT-4 cost in 2022?!?!? Did they not hear about the investments Microsoft has been making in OpenAI? And remember that's what the most aggressive among them thought! The conservatives seem to be living in an alternate reality where GPT-3 proved that scaling doesn't work and an AI winter set in in 2020.</p>", "parentCommentId": "BKdvAHAx2pgp9m5km", "user": {"username": "kokotajlod"}}, {"_id": "GotQm4sshfa7ZsbmA", "postedAt": "2023-07-26T17:37:40.203Z", "postId": "YGsojZYtEsj2A3PjZ", "htmlBody": "<p>Perhaps this should be a top-level comment.</p>", "parentCommentId": "y6p8ckiShzW3bLKAw", "user": {"username": "kokotajlod"}}, {"_id": "eMkc2NfDRhEFTyLgi", "postedAt": "2023-07-26T17:59:24.551Z", "postId": "YGsojZYtEsj2A3PjZ", "htmlBody": "<p>No, alas. However I do have this short summary doc I wrote back in 2021: <a href=\"https://docs.google.com/document/d/1oqTuVMa5Lxf6z8ybF7eirtuWEFekJJ6nwudhE7ZjNSY/edit\">The Master Argument for &lt;10-year Timelines - Google Docs</a><br><br>And this sequence of posts making narrower points: <a href=\"https://www.lesswrong.com/s/5Eg2urmQjA4ZNcezy\">AI Timelines - LessWrong</a></p>", "parentCommentId": "LeCHiQbFpDCdY4jBo", "user": {"username": "kokotajlod"}}, {"_id": "9QnL798hcaNnZH9Bb", "postedAt": "2023-07-26T18:00:11.170Z", "postId": "YGsojZYtEsj2A3PjZ", "htmlBody": "<p>Also, if you do various searches on LW and Astral Codex Ten looking for comments I've made, you might see some useful ones maybe.</p>", "parentCommentId": "eMkc2NfDRhEFTyLgi", "user": {"username": "kokotajlod"}}, {"_id": "W9oxdjhKa99esTJvD", "postedAt": "2023-08-01T04:42:48.539Z", "postId": "YGsojZYtEsj2A3PjZ", "htmlBody": "<p>Remember these predictions were made in summer 2022, before ChatGPT, before the big Microsoft investment and before any serious info about GPT-4. They're still low, but not ridiculous.</p>\n", "parentCommentId": "y6p8ckiShzW3bLKAw", "user": {"username": "erickb"}}, {"_id": "ziJ7FZxCJ9shkxNvA", "postedAt": "2023-08-02T13:20:50.400Z", "postId": "YGsojZYtEsj2A3PjZ", "htmlBody": "<p>Fair, but still: In 2019 Microsoft invested a billion dollars in OpenAI, roughly half of which was compute: <a href=\"https://techcrunch.com/2023/01/23/microsoft-invests-billions-more-dollars-in-openai-extends-partnership/?guccounter=1&amp;guce_referrer=aHR0cHM6Ly93d3cuYmluZy5jb20v&amp;guce_referrer_sig=AQAAALKQpd4QcfDN7ZKjAUO11H7cdBe--cXpshRNfhS0bgGrgL7hx7kO2-UplAW-jpBMiHQSpMZnnV6qaJPB_c-C2A__bT_eXb9vD_e5j49b9HwD3oJLDtoE1_nc-P71zzrdP1J2UYH6-FYyhoG-21zpzdpAw_anRnzIGA66pUx-9ss4\">Microsoft invests billions more dollars in OpenAI, extends partnership | TechCrunch</a><br><br>And then GPT-3 happened, and was widely regarded to be a huge success and proof that scaling is a good idea etc.<br><br>So the amount of compute-spending that the most aggressive forecasters think could be spent on a single training run in 2032... is about 25% as much compute-spending as Microsoft gave OpenAI starting in 2019, before GPT-3 and before the scaling hypothesis. The most aggressive forecasters.<br><br><br>&nbsp;</p>", "parentCommentId": "W9oxdjhKa99esTJvD", "user": {"username": "kokotajlod"}}, {"_id": "BmZXSb4KLindh2JFk", "postedAt": "2023-07-24T16:25:30.887Z", "postId": "YGsojZYtEsj2A3PjZ", "htmlBody": null, "parentCommentId": null, "user": null}]