[{"_id": "qEKqhZFsx5zwyf9Mu", "title": "US Congress introduces CREATE AI Act for establishing National AI Research Resource", "postedAt": "2023-07-28T23:27:59.937Z", "htmlBody": "<p>The leaders<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefbxarn7myebw\"><sup><a href=\"#fnbxarn7myebw\">[1]</a></sup></span>&nbsp;of the <a href=\"https://artificialintelligencecaucus-eshoo.house.gov\">AI Caucus</a> within the US House have just introduced legislation for the Creating Resources for Every American To Experiment with Artificial Intelligence Act of 2023 (CREATE AI Act).</p><p>The CREATE AI Act would establish the National Artificial Intelligence Research Resource (NAIRR) \u2013 research infrastructure that provides AI researchers with access to tools for developing AI. Similar legislation is also being introduced in the Senate by the Senate Artificial Intelligence Caucus.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefzembmzl7ph\"><sup><a href=\"#fnzembmzl7ph\">[2]</a></sup></span></p><p>You can read a press release <a href=\"https://eshoo.house.gov/media/press-releases/ai-caucus-leaders-introduce-bipartisan-bill-expand-access-ai-research\">here</a>, or the full bill text <a href=\"https://eshoo.house.gov/sites/evo-subsites/eshoo.house.gov/files/evo-media-document/eshoo_043_xml.pdf\">here</a>.</p><p>From the press release:</p><blockquote><p>The <i>CREATE AI Act</i> establishes the NAIRR,which has four primary goals:</p><ol><li>Spur innovation and advance the development of safe, reliable, and trustworthy AI research and development.</li><li>Improve access to AI resources for researchers and students, including groups typically underrepresented in STEM.</li><li>Improve capacity for AI research in the United States.</li><li>Support the testing, benchmarking, and evaluation of AI systems developed and deployed in the United States.</li></ol><p>The NAIRR will offer the following to researchers, educators, and students at higher education institutions, non-profits, and federally funded agencies:</p><ol><li>Computational resources, including an open-source software environment and a programming interface providing structured access to AI models.</li><li>Data, including curated datasets of user interest and an AI data commons.</li><li>Educational tools and services, including educational materials, technical training, and user support.</li><li>AI testbeds, including a catalog of open AI testbeds and a collaborative project with the National Institute of Standards and Technology.</li></ol></blockquote><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnbxarn7myebw\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefbxarn7myebw\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Specifically, Co-Chairs Rep. Eshoo (D-CA) and Rep. McCaul (R-TX) and Vice-Chairs Rep. Beyer (D-VA) and Rep. Obernolte (R-CA)</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnzembmzl7ph\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefzembmzl7ph\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Specifically, introduced by Sen. Martin Heinrich (D-NM), Sen. Todd Young (R-IN), Sen. Cory Booker (D-NJ), and Sen. Mike Rounds (R-SD)</p></div></li></ol>", "user": {"username": "Daniel_Eth"}}, {"_id": "wjJahDF7dnqM7jmXm", "title": "I'm interviewing Anders Sandberg about 'Grand Futures' \u2014 and any topics you like! What should I ask him?", "postedAt": "2023-07-28T17:34:28.849Z", "htmlBody": "<p>Next week for the 80k Podcast I'm interviewing Anders Sandberg, the Swedish polymath at FHI in Oxford.</p>\n<p>He's well known for publishing on all sorts of strange topics including <a href=\"https://www.theatlantic.com/science/archive/2018/08/what-happens-if-the-earth-instantly-turned-in-a-giant-mass-of-blueberries/566540/\">What If the Earth Turned Into a Ball of Blueberries?</a>.</p>\n<p>He's currently working on a book about how the future could look if things go incredibly well: <a href=\"https://aleph.se/andart2/space/what-kinds-of-grand-futures-are-there/\">'Grand Futures'</a>.</p>\n<p>But he's usually game to field questions on a wide range of things.</p>\n<p>Our first two interviews were:</p>\n<ul>\n<li><a href=\"https://80000hours.org/podcast/episodes/anders-sandberg-fermi-paradox/\">Where are the aliens? Anders Sandberg on three new resolutions to the Fermi Paradox. And how we could easily colonise the whole universe. </a></li>\n<li><a href=\"https://80000hours.org/podcast/episodes/anders-sandberg-extending-life/\">Oxford\u2019s Anders Sandberg on solar flares, the annual risk of nuclear war, and what if dictators could live forever? </a></li>\n</ul>\n<p>What should I ask him?</p>\n", "user": {"username": "Robert_Wiblin"}}, {"_id": "ojQvt8iAwni9zGXyD", "title": "[Final Call] Cause Exploration Contest", "postedAt": "2023-07-28T16:02:02.550Z", "htmlBody": "<p>This is just a final call for the cause exploration contest that CEARCH is running . The original announcement can be found <a href=\"https://forum.effectivealtruism.org/posts/QYJrH854vZzCFKmoG/longlist-of-causes-cause-exploration-contest\">here</a>; the short of it is that:</p><ul><li>We welcome everyone to suggest <strong><u>potential cause areas</u></strong>, providing a short justification if you feel it useful (e.g. briefly covering why the issue is important/tractable/neglected), or not, if otherwise (e.g. the idea simply appears novel or interesting to you). All ideas are welcome, and even causes which do not appear intuitively impactful can be fairly cost-effective upon deeper research.</li><li>People are also welcome to suggest <strong><u>potential search methodologies for finding causes</u></strong> (e.g. consulting weird philosophy, or looking up death certificates).</li></ul><p>Prizes will be awarded in the following way:</p><ul><li><strong><u>USD 300</u></strong> for best cause idea (and that is not already on our public <a href=\"https://docs.google.com/spreadsheets/d/1SpsQKuU8BnDHadhgicQooqCm-_hASjwYi9BO3fQ5BO8/edit#gid=0\">longlist of causes</a>).</li><li><strong><u>USD 700</u></strong> for the best search methodology (and that is not already listed in our public <a href=\"https://docs.google.com/document/d/1PSSuUShrx0tz1ILntdLHQFPiYN7fFmGO8Iq1bxBTqP4/edit\">search methodology</a> document).</li></ul><p>Entries may be made <a href=\"https://docs.google.com/forms/d/1h092ITwb1eSGzyi0AuinSs5OitfQl1NziXB3XEgEsuM/edit\">here</a>. The contest will run only for a few more days, until 31st July 2023 (23:59, GMT-12). Multiple entries are allowed (n.b. do make separate individual submissions).&nbsp;</p>", "user": {"username": "Joel Tan"}}, {"_id": "sF82dYFyrsH4L3fiQ", "title": "Ant\u00f3nio Guterres calling for urgent dramatic radical climate action - 10 actionable points", "postedAt": "2023-07-28T16:02:01.884Z", "htmlBody": "<p>Last night Secretary-General of the UN Ant\u00f3nio Guterres posted on Twitter about: <strong>\"urgent dramatic radical climate action\"</strong></p><p>But he forgot to mention what is actually required? Climate change: coordination problem, not a technical problem. I much prefer leadership with vision:</p><h2>\u26d4\ufe0f Not saying: <strong>\u201cdo something\u201d</strong></h2><h2>\u2705 Instead: <strong>\u201chere is the plan\u201d</strong></h2><p>So here is the plan: <a href=\"https://mirror.xyz/0x315f80C7cAaCBE7Fb1c14E65A634db89A33A9637/SJkyOyJt4bceRMvEUkB54Ox3Gd1YvhV43MASMsnzZn8\">https://mirror.xyz/0x315f80C7cAaCBE7Fb1c14E65A634db89A33A9637/SJkyOyJt4bceRMvEUkB54Ox3Gd1YvhV43MASMsnzZn8</a></p><p>There are 10 points and Google Form where you can rate each of them on the scale 0-10</p><p>You can also add your signature in order to gain visibility. Just me: crazy dude. Together: different game.</p>", "user": {"username": "Mars Robertson"}}, {"_id": "yyfk8B3pXBKg2EqED", "title": "\u30d2\u30c3\u30c8\u30d9\u30fc\u30b9\u306e\u5bc4\u4ed8", "postedAt": "2023-07-28T15:52:30.478Z", "htmlBody": "<p><i>This is a Japanese translation of \u201c</i><a href=\"https://forum.effectivealtruism.org/posts/badD656AemGYnraMt/hits-based-giving\"><i><strong>Hits-based Giving</strong></i></a><i>\u201d</i></p><p>By&nbsp;<a href=\"https://forum.effectivealtruism.org/users/holdenkarnofsky\"><u>Holden Karnofsky</u></a> 2016\u5e744\u67084\u65e5&nbsp;</p><h2>\u30d2\u30c3\u30c8\u30d9\u30fc\u30b9\u306e\u5bc4\u4ed8\u306e\u57fa\u672c\u7684\u306a\u4e8b\u4f8b</h2><p>\u6982\u5ff5\u7684\u306b\u79c1\u305f\u3061\u304c\u7126\u70b9\u3092\u5f53\u3066\u3066\u3044\u308b\u306e\u306f\u3001\u3069\u308c\u3060\u3051\u3088\u3044\u3053\u3068\u3092\u3067\u304d\u308b\u304b\u306e<a href=\"https://ja.wikipedia.org/wiki/%E6%9C%9F%E5%BE%85%E5%80%A4\"><u>\u671f\u5f85\u5024</u></a>\u3092\u6700\u5927\u5316\u3059\u308b\u3053\u3068\u3067\u3042\u308b\u3002\u671f\u5f85\u5024\u3092\u6b63\u78ba\u306b\u3001\u307e\u305f\u306f\u5b9a\u91cf\u7684\u306b\u6982\u7b97\u3067\u304d\u308b\u3053\u3068\u306f\u3042\u307e\u308a\u306a\u3044\u304c\u3001\u3053\u306e\u8003\u3048\u65b9\u306f\u79c1\u305f\u3061\u304c\u4f55\u3092\u3057\u3088\u3046\u3068\u3057\u3066\u3044\u308b\u304b\u3092\u8aac\u660e\u3059\u308b\u52a9\u3051\u306b\u306f\u306a\u308b\u3002\u4eee\u306b\u3001\u304b\u306a\u308a\u5358\u7d14\u5316\u3057\u305f\u4f8b\u3092\u8003\u3048\u3066\u307f\u308b\u3068\u3001\u6b21\u306e\u3088\u3046\u306a\u6a5f\u4f1a\u306f\u3069\u3061\u3089\u3082\u540c\u3058\u304f\u3089\u3044\u3088\u3055\u305d\u3046\u3060\uff1a\uff08\uff11\uff09100\u4e07\u30c9\u30eb\uff08\u7d041.5\u5104\u5186\uff09\u306e\u52a9\u6210\u91d1\u3067500\u4eba\u306e\u65e9\u6b7b\u306b\u3092\u78ba\u5b9f\u306b\u9632\u3050\u3002\uff08\uff12\uff09100\u4e07\u30c9\u30eb\u306e\u52a9\u6210\u91d1\u306790\uff05\u306e\u78ba\u7387\u3067\u4f55\u3082\u9054\u6210\u3067\u304d\u306a\u3044\u304c\u300110\uff05\u306e\u78ba\u7387\u30675000\u4eba\u306e\u65e9\u6b7b\u306b\u3092\u9632\u3050\u3002\u4e21\u8005\u3068\u3082\u671f\u5f85\u5024\u306f\u3001500\u4eba\u306e\u65e9\u6b7b\u306b\u3092\u9632\u3050\u3068\u3044\u3046\u3053\u3068\u306b\u306a\u308b\u3002\u3053\u306e\u4f8b\u304b\u3089\u5206\u304b\u308b\u3088\u3046\u306b\u300c\u671f\u5f85\u5024\u300d\u3092\u91cd\u8996\u3059\u308c\u3070\u3001\u4f4e\u30ea\u30b9\u30af\u306e\u6148\u5584\u4e8b\u696d\u3068\u9ad8\u30ea\u30b9\u30af\u3067\u5909\u9769\u3092\u3082\u305f\u3089\u3059\u53ef\u80fd\u6027\u306e\u3042\u308b\u6148\u5584\u4e8b\u696d\u306e<u>\u3069\u3061\u3089</u>\u3092\u9078\u3076\u304b\u306f\u57fa\u672c\u7684\u306b\u554f\u308f\u308c\u306a\u3044\u3053\u3068\u306b\u306a\u308b\u3002\u305d\u306e\u8a73\u7d30\u306b\u5fdc\u3058\u3066\u3001\u3069\u3061\u3089\u3082\u9078\u629e\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u3002\u4f59\u8ac7\u3060\u304c\u3001\u79c1\u305f\u3061\u304c\u3053\u308c\u307e\u3067\u51fa\u4f1a\u3063\u305f\u8cc7\u91d1\u63d0\u4f9b\u8005\u306e\u591a\u304f\u306f\u3001\u5927\u304d\u306a\u30ea\u30b9\u30af\u3092\u53d6\u308b\u3079\u304d\u304b\u3001\u4fe1\u983c\u6027\u3068\u5b9f\u7e3e\u306e\u3042\u308b\u3082\u306e\u306b\u8cc7\u91d1\u3092\u63d0\u4f9b\u3059\u3079\u304d\u304b\u306b\u3064\u3044\u3066\u78ba\u56fa\u305f\u308b\u610f\u898b\u3092\u6301\u3063\u3066\u3044\u305f\u3002</p><p>\u3068\u306f\u3044\u3048\u3001\u300c\u671f\u5f85\u5024\u300d\u30a2\u30d7\u30ed\u30fc\u30c1\u306f\u9ad8\u30ea\u30b9\u30af\u3067\u5909\u9769\u3092\u3082\u305f\u3089\u3059\u53ef\u80fd\u6027\u306e\u3042\u308b\u5bc4\u4ed8\u3092\u597d\u3080\u3053\u3068\u304c\u591a\u3044\u3068\u8003\u3048\u3089\u308c\u308b\u57fa\u672c\u7684\u306a\u7406\u7531\u304c\u3044\u304f\u3064\u304b\u3042\u308b\u3068\u601d\u3046\u3002</p><p><strong>1. \u6148\u5584\u4e8b\u696d\u306e\u6b74\u53f2\u3002</strong>\u79c1\u305f\u3061\u306f<a href=\"https://www.openphilanthropy.org/blog/philanthropys-success-stories\"><u>\u4ee5\u524d</u></a>\u3001\u6148\u5584\u4e8b\u696d\u306e\u4e3b\u306a\u6210\u529f\u4f8b\u306b\u95a2\u3057\u3066\u306e\u5168\u822c\u7684\u306a\u6982\u8981\u3092\u793a\u3057\u305f\u3002\u305d\u306e\u5f8c\u3082<a href=\"https://www.openphilanthropy.org/research/history-of-philanthropy\"><u>\u6148\u5584\u4e8b\u696d\u306e\u6b74\u53f2\u30d7\u30ed\u30b8\u30a7\u30af\u30c8</u></a>\u3092\u901a\u3058\u3066\u3053\u306e\u30c6\u30fc\u30de\u3092\u3055\u3089\u306b\u8abf\u67fb\u3057\u3066\u304a\u308a\u30012016\u5e74\u672b\u307e\u3067\u306b\u306f\u3001\u8abf\u67fb\u5185\u5bb9\u3092\u307e\u3068\u3081\u305f\u6700\u65b0\u306e\u8981\u7d04\u3092\u767a\u8868\u3059\u308b\u4e88\u5b9a\u3067\u3042\u308b\u3002\u305d\u306e\u7d50\u8ad6\u306e\u4e00\u3064\u3068\u3057\u3066\u6319\u3052\u3089\u308c\u308b\u306e\u304c\u3001\u3042\u308b\u6148\u5584\u5bb6\u304c\u5927\u304d\u306a\u30ea\u30b9\u30af\u3092\u53d6\u3063\u3066\u3001\u6210\u529f\u3059\u308b\u898b\u8fbc\u307f\u306e\u306a\u3044\u3082\u306e\u306b\u8cc7\u91d1\u3092\u63d0\u4f9b\u3057\u305f\u7d50\u679c\u3001\u591a\u304f\u306e\u9813\u632b\u3057\u305f\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u3092\u88dc\u3046\u306b\u8db3\u308b\u307b\u3069<u>\u5927\u304d\u306a</u>\u30a4\u30f3\u30d1\u30af\u30c8\u3092\u3082\u305f\u3089\u3057\u305f\u4e8b\u4f8b\u304c\u5c11\u306a\u304f\u3068\u3082\u6570\u4ef6\u3042\u3063\u305f\u3068\u3044\u3046\u3053\u3068\u3060\u3002</p><p>\u3053\u3053\u3067\u3001\u7279\u306b\u9855\u8457\u306a\u4e8b\u4f8b\u3092\u7d39\u4ecb\u3059\u308b\uff08\u305f\u3060\u3057\u3001\u30a4\u30f3\u30d1\u30af\u30c8\u304c\u30d7\u30e9\u30b9\u3067\u3042\u3063\u305f\u304b\u3067\u306f\u306a\u304f\u3001\u30a4\u30f3\u30d1\u30af\u30c8\u306e\u5927\u304d\u3055\u306b\u7126\u70b9\u3092\u5f53\u3066\u3066\u3044\u308b\u3053\u3068\u306b\u7559\u610f\u3057\u3066\u307b\u3057\u3044\uff09</p><ul><li>\u30ed\u30c3\u30af\u30d5\u30a7\u30e9\u30fc\u8ca1\u56e3\u306f\u767a\u5c55\u9014\u4e0a\u56fd\u306e\u8fb2\u696d\u751f\u7523\u6027\u3092\u5411\u4e0a\u3055\u305b\u308b\u7814\u7a76\u306b\u6295\u8cc7\u3057\u3001\u305d\u308c\u304c\u300c<a href=\"https://ja.wikipedia.org/wiki/%E7%B7%91%E3%81%AE%E9%9D%A9%E5%91%BD\"><u>\u7dd1\u306e\u9769\u547d</u></a>\u300d\u306e\u304d\u3063\u304b\u3051\u306b\u306a\u3063\u305f\u3068\u4e00\u822c\u306b\u8003\u3048\u3089\u308c\u3066\u304a\u308a\u3001Wikipedia\u306b\u306f\u300c10\u5104\u4eba\u4ee5\u4e0a\u3092\u98e2\u9913\u304b\u3089\u6551\u3063\u305f\u3068\u8a55\u4fa1\u3055\u308c\u3066\u3044\u308b\u300d\u3068\u66f8\u304b\u308c\u3066\u3044\u308b\u3002\uff08Wikipedia\u306e\u8a18\u4e8b\u306f\u30ed\u30c3\u30af\u30d5\u30a7\u30e9\u30fc\u8ca1\u56e3\u306e\u5f79\u5272\u306b\u3064\u3044\u3066\u8ff0\u3079\u3066\u304a\u308a\u3001Open Philanthropy Project\u306e\u652f\u63f4\u3092\u53d7\u3051\u3066\u3044\u308bHistPhil\u30d6\u30ed\u30b0\u306e\u3053\u306e<a href=\"http://histphil.org/2016/02/08/a-practitioners-history-of-the-green-revolution/\"><u>\u8a18\u4e8b</u></a>\u3067\u3082\u540c\u69d8\u3067\u3042\u308b\u3002\uff09</li><li>\u30b8\u30e7\u30ca\u30b5\u30f3\u30fb\u30a4\u30fc\u30b0\u306f\u300e<a href=\"http://smile.amazon.com/dp/0393351890\"><u>\u30d4\u30eb\u306e\u8a95\u751f</u></a>\u300f\u306b\u304a\u3044\u3066\u3001\u6148\u5584\u5bb6\u3067\u30d5\u30a7\u30df\u30cb\u30b9\u30c8\u3067\u3082\u3042\u308b\u30ad\u30e3\u30b5\u30ea\u30f3\u30fb\u30de\u30b3\u30fc\u30df\u30c3\u30af\u304c\u30de\u30fc\u30ac\u30ec\u30c3\u30c8\u30fb\u30b5\u30f3\u30ac\u30fc\u306e\u52a9\u8a00\u3092\u53d7\u3051\u3066\u3001<a href=\"https://ja.wikipedia.org/wiki/%E7%B5%8C%E5%8F%A3%E9%81%BF%E5%A6%8A%E8%96%AC\"><u>\u7d4c\u53e3\u907f\u598a\u85ac</u></a>\u306e\u958b\u767a\u306b\u3064\u306a\u304c\u308b\u91cd\u8981\u306a\u521d\u671f\u6bb5\u968e\u306e\u7814\u7a76\u3078\u306e\u552f\u4e00\u306e\u8cc7\u91d1\u63d0\u4f9b\u8005\u3068\u306a\u3063\u305f\u3068\u8a55\u4fa1\u3057\u3066\u3044\u308b\u3002\u7d4c\u53e3\u907f\u598a\u85ac\u306f\u3001\u73fe\u5728\u6700\u3082\u4e00\u822c\u7684\u304b\u3064\u6700\u3082\u4fbf\u5229\u306a\u907f\u598a\u6cd5\u306e\u4e00\u3064\u3068\u306a\u3063\u3066\u3044\u308b\u3002</li><li>\u30b9\u30c6\u30a3\u30fc\u30d6\u30fb\u30c6\u30ec\u30b9\u6559\u6388\u306f\u300e<a href=\"http://smile.amazon.com/Rise-Conservative-Legal-Movement-International/dp/069114625X/\"><u>\u7c73\u56fd\u4fdd\u5b88\u6d3e\u306b\u3088\u308b\u6cd5\u6539\u6b63\u904b\u52d5</u></a>\u300f\u306b\u304a\u3044\u3066\u3001\u4fdd\u5b88\u6d3e\u306f\u6210\u529f\u3092\u4e88\u6e2c\u3059\u308b\u8853\u304c\u306a\u3044\u4e2d\u3067\u3001\u9577\u671f\u7684\u3067\u30ea\u30b9\u30af\u306e\u9ad8\u3044\u76ee\u6a19\u306b\u591a\u5927\u306a\u8cc7\u91d1\u3092\u6295\u5165\u3057\u305f\u3068\u8ad6\u3058\u3066\u3044\u308b\u3002\u307e\u305f\u3001\u305d\u306e\u6700\u7d42\u7684\u306a\u30a4\u30f3\u30d1\u30af\u30c8\u306f\u3001\u6cd5\u66f9\u754c\u306e\u3042\u308a\u65b9\u3084\u653f\u6cbb\u7684\u4fdd\u5b88\u4e3b\u7fa9\u306e\u4e00\u822c\u7684\u306a\u77e5\u7684\u5730\u4f4d\u3092\u5927\u304d\u304f\u5909\u3048\u308b\u3082\u306e\u3067\u3042\u3063\u305f\u3068\u3082\u8ad6\u3058\u3066\u3044\u308b\u3002</li></ul><p>\u3053\u308c\u3089\u306e\u8a71\u304c\u6b63\u3057\u3044\u306e\u3042\u308c\u3070\u3001\u6148\u5584\u4e8b\u696d\u3001\u7279\u306b\u521d\u671f\u6bb5\u968e\u306e\u7814\u7a76\u3084\u30ea\u30b9\u30af\u306e\u9ad8\u3044\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u3092\u652f\u63f4\u3059\u308b\u6148\u5584\u4e8b\u696d\u304c\u300120\u4e16\u7d00\u306e\u3088\u308a\u91cd\u8981\u306a\u767a\u5c55\u306b\u5927\u304d\u306a\u5f79\u5272\u3092\u679c\u305f\u3057\u305f\u3053\u3068\u306b\u306a\u308b<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefr29dnmrh0v8\"><sup><a href=\"#fnr29dnmrh0v8\">[1]</a></sup></span>\u3002\u4eee\u306b\u3001\u5927\u6210\u529f\u3057\u305f\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306e\u4e00\u3064\u3068\u3001\u4f3c\u305f\u3088\u3046\u306a\u76ee\u7684\u3092\u6301\u3061\u306a\u304c\u3089\u5931\u6557\u306b\u7d42\u308f\u3063\u305f\u6570\u591a\u304f\u306e\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u3092\u542b\u3093\u3060\u6148\u5584\u4e8b\u696d\u300c\u30dd\u30fc\u30c8\u30d5\u30a9\u30ea\u30aa\u300d\u3092\u4f5c\u3063\u305f\u3068\u3057\u305f\u3089\u3001\u30c9\u30eb\u3042\u305f\u308a\u306e\u30a4\u30f3\u30d1\u30af\u30c8\u3068\u3044\u3046\u70b9\u3067\u3001\u304a\u305d\u3089\u304f\u975e\u5e38\u306b\u512a\u308c\u305f\u696d\u7e3e\u3092\u7d0d\u3081\u3066\u3044\u308b\u3053\u3068\u306b\u306a\u308b\u3060\u308d\u3046\u3002</p><p><strong>2. \u6bd4\u8f03\u512a\u4f4d\u6027</strong>\u3002\u53ef\u80fd\u306a\u9650\u308a\u826f\u3044\u5bc4\u4ed8\u3092\u3059\u308b\u65b9\u6cd5\u3092\u8003\u3048\u308b\u969b\u3001\u4e00\u3064\u306e\u767a\u898b\u65b9\u6cd5\u3068\u3057\u3066\u3001\u300c\u6148\u5584\u5bb6 \u306f\u4ed6\u306e\u6a5f\u95a2\u3068\u6bd4\u8f03\u3057\u3066\u3001\u69cb\u9020\u7684\u306b\u4f55\u3092\u3059\u308b\u306e\u306b\u9069\u3057\u3066\u3044\u308b\u306e\u304b\uff08\u305d\u3057\u3066\u3001\u9069\u3057\u3066\u3044\u306a\u3044\u306e\u304b\uff09\u300d\u3068\u3044\u3046\u3053\u3068\u3092\u8003\u3048\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u3002\u5927\u53e3\u306e\u6148\u5584\u5bb6\u3067\u3055\u3048\u3001\u653f\u5e9c\u3084\u55b6\u5229\u76ee\u7684\u306e\u6295\u8cc7\u5bb6\u306b\u6bd4\u3079\u308c\u3070\u5229\u7528\u3067\u304d\u308b\u8cc7\u91d1\u304c\u6bd4\u8f03\u7684\u5c11\u306a\u3044\u50be\u5411\u306b\u3042\u308b\u3082\u306e\u306e\u3001\u4e00\u65b9\u3067\u6148\u5584\u5bb6\u306f\u5229\u76ca\u3092\u4e0a\u3052\u305f\u308a\u3001\u5e45\u5e83\u3044\u652f\u6301\u8005\u306b\u6d3b\u52d5\u3092\u6b63\u5f53\u5316\u3057\u305f\u308a\u3059\u308b\u5fc5\u8981\u6027\u306b\u3088\u3063\u3066\u884c\u52d5\u3092\u5236\u7d04\u3055\u308c\u308b\u3053\u3068\u306f\u5727\u5012\u7684\u306b\u5c11\u306a\u3044\u3002\u65b0\u3057\u304f\u3066\u5b9f\u8a3c\u3055\u308c\u3066\u3044\u306a\u3044\u30a2\u30a4\u30c7\u30a3\u30a2\u306e\u3088\u3046\u306b\u975e\u5e38\u306b\u300c\u65e9\u3044\u300d\u6bb5\u968e\u306e\u6d3b\u52d5\u3092\u652f\u63f4\u3059\u308b\u3053\u3068\u3084\u3001\u5b9f\u969b\u306b\u30a4\u30f3\u30d1\u30af\u30c8\u3092\u4e0e\u3048\u308b\u307e\u3067\u306b\u4f55\u5341\u5e74\u3082\u304b\u304b\u308a\u305d\u3046\u306a\u6d3b\u52d5\u3092\u652f\u63f4\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u3002\u6210\u529f\u3059\u308b\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u3092\u898b\u3064\u3051\u308b\u305f\u3081\u306b\u3001\u5931\u6557\u3059\u308b\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u3092\u6570\u591a\u304f\u652f\u63f4\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u3002\u91cd\u8981\u6027\u3092\u8a8d\u8b58\u3059\u308b\u306e\u306b\u6df1\u3044\u77e5\u8b58\u304c\u5fc5\u8981\u3067\u3001\u5927\u52e2\u306b\u5bfe\u3057\u3066\u884c\u3063\u3066\u3044\u308b\u3053\u3068\u306e\u6b63\u5f53\u6027\u3092\u8a3c\u660e\u3059\u308b\u3053\u3068\u304c\u96e3\u3057\u3044\u3088\u3046\u306a\u6d3b\u52d5\u3092\u652f\u63f4\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u3002\u3053\u308c\u3089\u306e\u7279\u5fb4\u306f\u3001\u53ef\u80fd\u6027\u306f\u4f4e\u3044\u3082\u306e\u306e\u4e0a\u632f\u308c\u3057\u3046\u308b\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306b\u5bfe\u3057\u3066\u8cc7\u91d1\u3092\u63d0\u4f9b\u3059\u308b\u3053\u3068\u3053\u305d\u3001\u6148\u5584\u5bb6\u304c\u4ed6\u306e\u6a5f\u95a2\u306b\u6bd4\u3079\u3066\u5f97\u610f\u3068\u3059\u308b\u3053\u3068\u3060\u3068\u793a\u5506\u3057\u3066\u3044\u308b\u3002</p><p><strong>3. \u55b6\u5229\u76ee\u7684\u306e\u6295\u8cc7\u3068\u306e\u985e\u4f3c\u6027</strong>\u3002\u30d9\u30f3\u30c1\u30e3\u30fc\u30ad\u30e3\u30d4\u30bf\u30eb\u6295\u8cc7\u306a\u3069\u3001\u55b6\u5229\u3092\u76ee\u7684\u3068\u3057\u305f\u6295\u8cc7\u306e\u591a\u304f\u306f\u3001\u300c\u30d2\u30c3\u30c8\u30d3\u30b8\u30cd\u30b9\u300d\u3067\u3042\u308b\u3002\u3053\u308c\u306b\u3064\u3044\u3066\u306e\u8aac\u660e\u306f\u3001<a href=\"http://paulgraham.com/swan.html\"><u>\u4ee5\u524d\u7d39\u4ecb\u3057\u305f\u8a18\u4e8b</u></a>\u3092\u53c2\u7167\u3057\u3066\u3044\u305f\u3060\u304d\u305f\u3044\u3002\u6148\u5584\u4e8b\u696d\u3068\u55b6\u5229\u76ee\u7684\u306e\u6295\u8cc7\u306f\u3001\u3044\u304f\u3064\u304b\u306e\u91cd\u8981\u306a\u70b9\u306b\u304a\u3044\u3066\u4f3c\u3066\u3044\u308b\u3068\u601d\u308f\u308c\u308b\u3002\u5177\u4f53\u7684\u306b\u306f\u3001\u69d8\u3005\u306a\u7d50\u679c\u3092\u3082\u305f\u3089\u3059\u53ef\u80fd\u6027\u306e\u3042\u308b\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306b\u5bfe\u3057\u3066\u3001\u4e00\u5b9a\u984d\u306e\u8cc7\u91d1\u3092\u3069\u306e\u3088\u3046\u306b\u914d\u5206\u3059\u308b\u304b\u3092\u8003\u3048\u308b\u3053\u3068\u306b\u884c\u304d\u7740\u304f\u306e\u3067\u3042\u308b\u3002\u305d\u3057\u3066\u3001\u55b6\u5229\u76ee\u7684\u306e\u6295\u8cc7\u3068\u6148\u5584\u4e8b\u696d\u306e\u9055\u3044\u306e\u591a\u304f\u306f\uff08\u4e0a\u8ff0\uff09\u3001\u30d2\u30c3\u30c8\u30d9\u30fc\u30b9\u306e\u5bc4\u4ed8\u306f\u30d2\u30c3\u30c8\u30d9\u30fc\u30b9\u306e\u6295\u8cc7\u3088\u308a\u3082\u3055\u3089\u306b\u9069\u5207\u3067\u3042\u308b\u53ef\u80fd\u6027\u304c\u9ad8\u3044\u3053\u3068\u3092\u793a\u5506\u3057\u3066\u3044\u308b\u3002</p><h2>\u30d2\u30c3\u30c8\u30d9\u30fc\u30b9\u306e\u5bc4\u4ed8\u306b\u300c\u53cd\u3059\u308b\u539f\u5247\u300d</h2><p>\u3053\u306e\u30bb\u30af\u30b7\u30e7\u30f3\u3067\u306f\u3001\u591a\u304f\u306e\u610f\u601d\u6c7a\u5b9a\u306b\u306f\u9069\u3057\u3066\u3044\u308b\u3082\u306e\u306e\u3001\u30d2\u30c3\u30c8\u30d9\u30fc\u30b9\u306e\u5bc4\u4ed8\u306b\u306f\u9069\u3057\u3066<u>\u3044\u306a\u3044</u>\u3068\u601d\u308f\u308c\u308b\u539f\u5247\u306b\u3064\u3044\u3066\u8ad6\u3058\u3066\u3044\u304f\u3002\u308f\u304b\u308a\u3084\u3059\u304f\u3059\u308b\u305f\u3081\u306b\u3001\u3053\u308c\u3089\u3092\u300c\u79c1\u305f\u3061\u306f\u301c\u3057\u306a\u3044\u300d\u3068\u3044\u3046\u5f62\u3067\u8868\u73fe\u3057\u3001\u301c\u306e\u90e8\u5206\u306b\u79c1\u305f\u3061\u304c\u30d2\u30c3\u30c8\u30d9\u30fc\u30b9\u306e\u30a2\u30d7\u30ed\u30fc\u30c1\u306b\u9069\u3057\u3066\u3044\u306a\u3044\u3068\u8003\u3048\u308b\u539f\u5247\u3092\u8868\u3059\u3088\u3046\u306b\u3057\u3066\u3042\u308b\u3002</p><p>\u4ee5\u4e0b\u306e\u9805\u76ee\u306b\u5171\u901a\u3059\u308b\u30c6\u30fc\u30de\u306f\u3001\u3042\u308b\u539f\u5247\u304c\u9069\u3057\u3066\u3044\u308b\u3068\u5224\u65ad\u3055\u308c\u308b\u306b\u306f\u3001<u>\u60f3\u50cf\u3057\u3046\u308b\u4e2d\u3067\u6700\u9ad8\u306e</u>\u5bc4\u4ed8\u306e\u6a5f\u4f1a\uff08\u4f8b\u3048\u3070\u300c\u7dd1\u306e\u9769\u547d\u300d\u306e\u3088\u3046\u306a\u524d\u306e\u30bb\u30af\u30b7\u30e7\u30f3\u3067\u6319\u3052\u305f\u30b1\u30fc\u30b9\u3068\u985e\u4f3c\u3057\u3066\u3044\u308b\u3082\u306e\uff09\u306b\u9069\u5408\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u3068\u3044\u3046\u3053\u3068\u3060\u3002\u60f3\u50cf\u3057\u3046\u308b\u6700\u5927\u306e\u30d2\u30c3\u30c8\u3092\u69cb\u9020\u7684\u306b\u306b\u59a8\u3052\u308b\u3088\u3046\u306a\u539f\u5247\u306f\u3001\u305f\u3068\u3048\u4ed6\u306e\u6587\u8108\u3067\u306f\u826f\u3044\u539f\u5247\u3067\u3042\u3063\u3066\u3082\u3001\u30d2\u30c3\u30c8\u30d9\u30fc\u30b9\u306e\u5bc4\u4ed8\u306b\u306f\u304a\u305d\u3089\u304f\u9069\u3055\u306a\u3044\u3060\u308d\u3046\u3002</p><p><strong>\u79c1\u305f\u3061\u306f\u300c\u8cc7\u91d1\u63d0\u4f9b\u306e\u524d\u306b\u5f37\u529b\u306a\u8a3c\u62e0\u3092\u5fc5\u8981\u300d\u3068\u3057\u306a\u3044\u3002</strong>\u8cea\u306e\u9ad8\u3044\u8a3c\u62e0\u3092\u5165\u624b\u3059\u308b\u3053\u3068\u306f\u56f0\u96e3\u3067\u3001\u901a\u5e38\u306f\u6301\u7d9a\u3057\u3066\u5341\u5206\u306a\u30ea\u30bd\u30fc\u30b9\u304c\u5fc5\u8981\u3068\u306a\u308b\u3002\u3057\u305f\u304c\u3063\u3066\u3001\u3053\u306e\u539f\u5247\u306f\u3001\u79c1\u305f\u3061\u306e\u300c<a href=\"https://www.openphilanthropy.org/research/our-process#Exploring_potential_focus_areas\"><u>\u898b\u904e\u3054\u3055\u308c\u3066\u3044\u308b\u3082\u306e</u></a>\u300d\u3078\u306e\u95a2\u5fc3\u3068\u306f\u76f8\u5bb9\u308c\u306a\u3044\u3002\u307e\u305f\u3001\u5f37\u529b\u306a\u8a3c\u62e0\u3092\u5fc5\u8981\u3068\u3059\u308c\u3070\u3001\u4ed6\u306e\u7814\u7a76\u8005\u304c\u3059\u3067\u306b\u5fb9\u5e95\u7684\u306b\u7814\u7a76\u3057\u3001\u8cc7\u91d1\u3082\u8c4a\u5bcc\u306b\u3042\u308b\u30a2\u30a4\u30c7\u30a3\u30a2\u3092\u652f\u63f4\u3059\u308b\u3053\u3068\u306b\u306a\u308a\u3001\u79c1\u305f\u3061\u304c\u53c2\u52a0\u3059\u308b\u3053\u3068\u3067\u300c\u30d2\u30c3\u30c8\u300d\u898f\u6a21\u306e\u30a4\u30f3\u30d1\u30af\u30c8\u304c\u5f97\u3089\u308c\u308b\u53ef\u80fd\u6027\u306f\u4f4e\u304f\u306a\u308b\u3068\u601d\u308f\u308c\u308b\u3002\u307e\u305f\u3001<a href=\"https://www.openphilanthropy.org/focus/us-policy\"><u>\u653f\u7b56\u306b\u5f71\u97ff\u3092\u4e0e\u3048\u308b\u3053\u3068\u3092\u76ee\u7684\u3068\u3057\u305f\u6d3b\u52d5</u></a>\u3084<a href=\"https://www.openphilanthropy.org/focus/scientific-research\"><u>\u79d1\u5b66\u7814\u7a76</u></a>\u3078\u306e\u8cc7\u91d1\u63d0\u4f9b\u306e\u3088\u3046\u306b\u3001\u6d3b\u52d5\u306e\u4e2d\u306b\u306f\u524d\u3082\u3063\u3066\u6709\u52b9\u306a\u65b9\u6cd5\u3067\u300c\u30c6\u30b9\u30c8\u300d\u3059\u308b\u3053\u3068\u304c\u672c\u8cea\u7684\u306b\u56f0\u96e3\u306a\u5834\u5408\u304c\u3042\u308b\u3002\u904e\u53bb\u306e\u6148\u5584\u7684\u306a\u300c\u30d2\u30c3\u30c8\u300d\u4e8b\u4f8b\u306e<u>\u307b\u3068\u3093\u3069</u>\u304c\u3001\u76f4\u63a5\u7684\u306b\u6210\u529f\u3092\u4e88\u6e2c\u3067\u304d\u308b\u3088\u3046\u306a\u5f37\u529b\u306a\u8a3c\u62e0\u306b\u88cf\u6253\u3061\u3055\u308c\u305f\u3082\u306e\u3067\u306f\u306a\u304b\u3063\u305f\u3088\u3046\u306b\u601d\u308f\u308c\u308b\u3002\uff08\u76f4\u63a5\u7684\u3067\u306f\u306a\u3044\u65b9\u6cd5\u3067\u3001\u305d\u306e\u6d3b\u52d5\u306b\u8a3c\u62e0\u304c\u5165\u308a\u8fbc\u3093\u3067\u3044\u305f\u3068\u306f\u601d\u308f\u308c\u308b\u304c\uff09</p><p><strong>\u79c1\u305f\u3061\u306f\u300c\u9ad8\u3044\u6210\u529f\u78ba\u7387\u3092\u8ffd\u6c42\u300d\u3057\u306a\u3044</strong>\u3002<a href=\"http://blog.givewell.org/2011/08/18/why-we-cant-take-expected-value-estimates-literally-even-when-theyre-unbiased/\"><u>\u79c1\u306e\u8003\u3048</u></a>\u3067\u306f\u3001\u9ad8\u3044\u78ba\u7387\u3067\u5341\u5206\u5927\u304d\u306a\u30d7\u30e9\u30b9\u306e\u30a4\u30f3\u30d1\u30af\u30c8\u3092\u4e0e\u3048\u308b\u3068\u6b63\u5f53\u306b\u4e3b\u5f35\u3059\u308b\u306b\u306f\u3001\u5f37\u529b\u306a\u8a3c\u62e0\u304c\u901a\u5e38\u306f\u5fc5\u8981\u3060\u3002\u30d9\u30f3\u30c1\u30e3\u30fc\u30ad\u30e3\u30d4\u30bf\u30eb\u306e\u3088\u3046\u306b\u3001\u4e00\u56de\u306e\u6210\u529f\u306b\u306f\u591a\u304f\u306e\u5931\u6557\u304c\u4f34\u3046\u3053\u3068\u3092\u899a\u609f\u3057\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044\u3002\u305d\u3057\u3066\u305d\u306e\u6210\u529f\u306f\u3001\u3053\u306e\u3053\u3068\u3092\u6b63\u5f53\u5316\u3059\u308b\u306e\u306b\u5341\u5206\u306a\u5927\u304d\u3055\u3067\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044\u3002</p><p><strong>\u79c1\u305f\u3061\u306f\u300c\u5c02\u9580\u5bb6\u306e\u610f\u898b\u3084\u5f93\u6765\u306e\u5e38\u8b58\u306b\u5f93\u3046\u300d\u3053\u3068\u306f\u3057\u306a\u3044\u3002\u305d\u308c\u3089\u306e\u898b\u8b58\u3092\u5f97\u3088\u3046\u3068\u306f\u3057\u3066\u3082\u3002</strong>\u5c02\u9580\u5bb6\u306e\u610f\u898b\u3084\u5f93\u6765\u306e\u5e38\u8b58\u306b\u5f93\u3046\u3053\u3068\u306f\u3001\u898b\u904e\u3054\u3055\u308c\u3066\u3044\u308b\u554f\u984c\u3092\u63a2\u3057\u51fa\u3059\u3068\u3044\u3046\u79c1\u305f\u3061\u306e\u76ee\u6a19\u306b\u53cd\u3059\u308b\u53ef\u80fd\u6027\u304c\u9ad8\u304f\u306a\u308b\u3002\u3082\u3057\u3001\u3042\u308b\u91cd\u8981\u306a\u4e8b\u67c4\u306b\u95a2\u3057\u3066\u306e\u5c02\u9580\u5bb6\u306e\u610f\u898b\u3084\u5f93\u6765\u306e\u5e38\u8b58\u3092<u>\u5909\u3048\u308b</u>\u305f\u3081\u306e\u521d\u671f\u306e\u571f\u53f0\u4f5c\u308a\u306b\u8cc7\u91d1\u63d0\u4f9b\u3059\u308b\u306a\u3089\u3070\u3001\u3053\u308c\u306f\u300c\u30d2\u30c3\u30c8\u300d\u306e\u6709\u529b\u306a\u5019\u88dc\u306b\u306a\u308b\u3060\u308d\u3046\u3002\u3042\u308b\u4e8b\u4f8b\u306b\u304a\u3044\u3066\u3001\u79c1\u305f\u3061\u306e\u610f\u898b\u306b\u8cdb\u540c\u3059\u308b\u5c02\u9580\u5bb6\uff08\u5e83\u7fa9\u306b\u306f\u300c\u3042\u308b\u554f\u984c\u306b\u6df1\u304f\u95a2\u308f\u3063\u3066\u304d\u305f\u4eba\u300d\uff09\u304c<u>\u5168\u304f\u3044\u306a\u3044</u>\u3053\u3068\u306f\u60aa\u3044\u5146\u5019\u3060\u3068\u8003\u3048\u308b\u304c\u3001\u5c02\u9580\u5bb6\u306e\u9593\u3067\u610f\u898b\u306e\u76f8\u9055\u304c\u3042\u308b\u5834\u5408\u306f\u3001\u7279\u5b9a\u306e\u5c02\u9580\u5bb6\u306e\u5074\u306b\u7acb\u3064\u3053\u3068\u3082\u5fc5\u8981\u3060\u3002\u79c1\u306e\u898b\u89e3\u3067\u306f\u3001\u3069\u306e\u4e3b\u5f35\u304c\u79c1\u305f\u3061\u306e<a href=\"https://www.openphilanthropy.org/about/vision-and-values\"><u>\u4fa1\u5024\u89b3</u></a>\u3084\u57fa\u672c\u7684\u306a\u8a8d\u8b58\u8ad6\u306b\u6700\u3082\u5408\u3046\u304b\u3092\u5224\u65ad\u3059\u308b\u306e\u306b\u91cd\u8981\u306a\u8ad6\u70b9\u3092<u>\u5341\u5206\u306b</u>\u5b66\u3076\u3053\u3068\u3067\u3001\u751f\u7523\u7684\u306b\u7279\u5b9a\u306e\u7acb\u5834\u3092\u9078\u629e\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u5834\u5408\u304c\u591a\u3044\u3002</p><p><strong>\u79c1\u305f\u3061\u306f\u300c\u8ad6\u4e89\u306e\u7684\u306b\u306a\u308b\u3088\u3046\u306a\u7acb\u5834\u3084\u6575\u5bfe\u7684\u306a\u72b6\u6cc1\u3092\u907f\u3051\u308b\u300d\u3053\u3068\u306f\u3057\u306a\u3044</strong>\u3002\u4ed6\u306e\u6761\u4ef6\u304c\u5168\u3066\u540c\u3058\u306a\u3089\u3001\u305d\u306e\u3088\u3046\u306a\u72b6\u6cc1\u306b\u9665\u308b\u3053\u3068\u306f\u907f\u3051\u305f\u3044\u304c\u3001\u907f\u3051\u308b\u305f\u3081\u306b\u591a\u5927\u306a\u52aa\u529b\u3092\u6255\u3046\u3053\u3068\u306f\u3001\u30d2\u30c3\u30c8\u30d9\u30fc\u30b9\u306e\u30a2\u30d7\u30ed\u30fc\u30c1\u3068\u306f\u76f8\u5bb9\u308c\u306a\u3044\u3060\u308d\u3046\u3002\u79c1\u305f\u3061\u306f<a href=\"http://slatestarcodex.com/2015/09/22/beware-systemic-change/\"><u>\u4ee5\u4e0b\u306e\u5f62\u5f0f\u306e\u4e3b\u5f35</u></a>\u306b\u306f\u5171\u611f\u3057\u3066\u3044\u308b\u3002\u300c\u77e5\u7684\u3067\u5584\u610f\u3042\u308b\u4eba\u3005\u304c\u53cd\u5bfe\u306e\u7acb\u5834\u3092\u53d6\u308b\u5834\u5408\u3001\u81ea\u5206\u306e\u7acb\u5834\u306b\u81ea\u4fe1\u3092\u6301\u3064\u3053\u3068\u306f\u96e3\u3057\u3044\u306f\u305a\u3060\u3002\u300d\u300c\u56f0\u3063\u3066\u3044\u308b\u4eba\u3005\u3092\u76f4\u63a5\u52a9\u3051\u308b\u306a\u3069\u3001\u304a\u4e92\u3044\u306b\u540c\u610f\u3067\u304d\u308b\u3053\u3068\u306b\u5168\u3066\u306e\u30ea\u30bd\u30fc\u30b9\u3092\u5272\u308a\u5f53\u3066\u3089\u308c\u305f\u304b\u3082\u3057\u308c\u306a\u3044\u72b6\u6cc1\u3067\u30012\u3064\u306e\u30b0\u30eb\u30fc\u30d7\u304c\u5bfe\u7acb\u3057\u3066\u30ea\u30bd\u30fc\u30b9\u3092\u8cbb\u3084\u3057\u3001\u305d\u306e\u7d50\u679c\u4f55\u306e\u5909\u5316\u3082\u8d77\u3053\u305b\u306a\u3044\u3053\u3068\u306f\u6b8b\u5ff5\u3060\u3002\u300d\u3053\u308c\u3089\u306e\u4e3b\u5f35\u306f\u3001<a href=\"http://www.givewell.org/charities/top-charities\"><u>GiveWell \u306e\u30c8\u30c3\u30d7\u30c1\u30e3\u30ea\u30c6\u30a3</u></a>\u3092\u652f\u6301\u3059\u308b\u7406\u7531\u306b\u306a\u308b\u3068\u601d\u3046\u3002\u3057\u304b\u3057\u3001\u300c\u30d2\u30c3\u30c8\u300d\u3092\u72d9\u3046\u306e\u3067\u3042\u308c\u3070\u3001\u3053\u308c\u3089\u306e\u4e3b\u5f35\u306f\u8107\u306b\u7f6e\u3044\u3066\u304a\u304f\u5fc5\u8981\u304c\u3042\u308b\u3068\u611f\u3058\u308b\u3002</p><p>\u591a\u304f\u306e \u300c\u30d2\u30c3\u30c8\u300d\u306f\u3001\u793e\u4f1a\u898f\u7bc4\u3084\u91cd\u8981\u306a\u610f\u601d\u6c7a\u5b9a\u8005\u306e\u610f\u898b\u3092\u5909\u3048\u308b\u3053\u3068\u3067\u3001\u30a4\u30f3\u30d1\u30af\u30c8\u306e\u500d\u7387\u3092\u4e0a\u3052\u308b\u3053\u3068\u306b\u3064\u306a\u304c\u308b\u3001\u3068\u79c1\u305f\u3061\u306f\u8003\u3048\u3066\u3044\u308b\u3002\u307e\u305f\u3001\u898b\u904e\u3054\u3055\u308c\u3066\u3044\u308b\u554f\u984c\u3078\u306e\u95a2\u5fc3\u304b\u3089\u3001\u793e\u4f1a\u898f\u7bc4\u3084\u7d44\u7e54\u3055\u308c\u305f\u96c6\u56e3\u304b\u3089\u5f37\u3044\u53cd\u5bfe\u3092\u53d7\u3051\u3066\u3044\u308b\u554f\u984c\u3092\u53d6\u308a\u6271\u3046\u3053\u3068\u304c\u591a\u3005\u3042\u308b\u3002\u4e0a\u306b\u6319\u3052\u305f\u300c\u30d2\u30c3\u30c8\u300d\u3067\u3001\u7269\u8b70\u3092\u91b8\u3055\u306a\u304b\u3063\u305f\u3082\u306e\u306f\u306a\u3044\u3002\u7d4c\u53e3\u907f\u598a\u85ac\u306e\u4f8b\u306f\u3001\u5f53\u6642\u306f\u975e\u5e38\u306b\u8ad6\u4e89\u306b\u306a\u3063\u305f\uff08\u79c1\u304c\u601d\u3046\u306b\u3001\u3053\u308c\u306b\u3088\u308a\u653f\u5e9c\u3084\u8cc7\u91d1\u63d0\u4f9b\u8005\u304c\u5f53\u6642\u5fc5\u8981\u3067\u3042\u3063\u305f\u7814\u7a76\u3092\u7121\u8996\u3059\u308b\u3053\u3068\u306b\u3064\u306a\u304c\u3063\u305f\uff09\u3082\u306e\u306e\u3001\u4eca\u65e5\u3067\u306f\u305a\u3063\u3068\u5e83\u304f\u53d7\u3051\u5165\u308c\u3089\u308c\u3066\u3044\u308b\u3001\u3068\u3044\u3046\u70b9\u306b\u7559\u610f\u3057\u3066\u307b\u3057\u3044\u3002</p><p><strong>\u79c1\u305f\u3061\u306f\u300c\u6587\u66f8\u3067\u81ea\u5206\u305f\u3061\u3092\u5b8c\u5168\u306b\u6b63\u5f53\u5316\u3067\u304d\u308b\u3068\u671f\u5f85\u300d\u3057\u306a\u3044</strong>\u3002\u610f\u898b\u3092\u6587\u7ae0\u3067\u8aac\u660e\u3059\u308b\u3053\u3068\u306f \u30aa\u30fc\u30d7\u30f3\u30fb\u30d5\u30a3\u30e9\u30f3\u30bd\u30ed\u30d4\u30fc\u30fb\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306eDNA\u306b\u5fc5\u9808\u3067\u306f\u3042\u308b\u304c\u3001\u3053\u306e\u3053\u3068\u304c\u79c1\u305f\u3061\u306e\u610f\u601d\u6c7a\u5b9a\u3092\u6b6a\u3081\u3066\u3057\u307e\u308f\u306a\u3044\u3088\u3046\u306b\u6ce8\u610f\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u3002\u52a9\u6210\u91d1\u3092\u691c\u8a0e\u3059\u308b\u5834\u5408\u3001\u7279\u306b\u3001\u66d6\u6627\u3067\u8981\u7d04\u3057\u306b\u304f\u3044\u3088\u3046\u306a\u60c5\u5831\u306b\u4f9d\u62e0\u3057\u305f\u975e\u5e38\u306b\u8907\u96d1\u306a\u6848\u4ef6\u306e\u5834\u5408\u306b\u3001\u516c\u306e\u8a18\u4e8b\u3067\u3069\u306e\u3088\u3046\u306b\u305d\u306e\u52a9\u6210\u91d1\u3092\u6b63\u5f53\u5316\u3059\u308b\u304b\u3068\u3044\u3046\u3053\u3068\u3092\u5148\u306b\u8003\u3048\u3001\u3068\u3066\u3082\u7121\u8b00\u3060\u304b\u3089\u3068\u907f\u3051\u3066\u3057\u307e\u3046\u3053\u3068\u3092\u5371\u60e7\u3057\u3066\u3044\u308b\u3002\u3053\u308c\u306f\u3001\u79c1\u305f\u3061\u304c\u907f\u3051\u305f\u3044\u30d0\u30a4\u30a2\u30b9\u3060\u3002\u80cc\u666f\u77e5\u8b58\u3092\u3042\u307e\u308a\u77e5\u3089\u306a\u3044\u90e8\u5916\u8005\u306b\u3082\u8aac\u660e\u3057\u3084\u3059\u3044\u554f\u984c\u306b\u7126\u70b9\u3092\u5f53\u3066\u308b\u3068\u3001\u5e83\u304f\u4eba\u6c17\u3092\u96c6\u3081\u308b\u3088\u3046\u306a\u554f\u984c\u306b\u7126\u70b9\u3092\u5f53\u3066\u308b\u3053\u3068\u306b\u306a\u308a\u3001\u6ce8\u76ee\u5ea6\u306e\u4f4e\u3044\u5206\u91ce\u306b\u7126\u70b9\u3092\u5f53\u3066\u308b\u3053\u3068\u304c\u96e3\u3057\u304f\u306a\u308b\u3002</p><p>\u305d\u306e\u826f\u3044\u4f8b\u304c\u3001<a href=\"https://www.openphilanthropy.org/focus/us-policy/macroeconomic-policy\"><u>\u30de\u30af\u30ed\u7d4c\u6e08\u5b89\u5b9a\u5316\u653f\u7b56</u></a>\u306b\u95a2\u3059\u308b\u79c1\u305f\u3061\u306e\u6d3b\u52d5\u3067\u3042\u308b\u3002\u3053\u306e\u554f\u984c\u306f\u975e\u5e38\u306b\u8907\u96d1\u3067\u3042\u308a\u3001\u4f55\u5e74\u306b\u3082\u308f\u305f\u308b\u8b70\u8ad6\u3068\u95a2\u9023\u304c\u3042\u308b\u5c02\u9580\u5bb6\u3068\u306e\u5354\u529b\u3001\u305d\u3057\u3066\u81a8\u5927\u306a\u6570\u306e\u516c\u958b\u8a0e\u8ad6\u3092\u901a\u3058\u3066\u3001\u79c1\u305f\u3061\u306f\u898b\u89e3\u3092\u5f62\u6210\u3057\u3066\u304d\u305f\u3002\u79c1\u304c\u601d\u3046\u306b\u3001\u3053\u306e\u554f\u984c\u3092\u7406\u89e3\u3057\u3001\u8981\u7d04\u3059\u308b\u3053\u3068\u304c\u96e3\u3057\u3044\u306e\u306f\u3001\u306a\u305c\u3053\u306e\u554f\u984c\u304c\u79c1\u305f\u3061\u306e\u8996\u70b9\u304b\u3089\u9b45\u529b\u7684\u306b\u6620\u308b\u554f\u984c\u3067\u3042\u308b\u304b\u3068\u3044\u3046\u3053\u3068\u306b\u95a2\u4fc2\u3057\u3066\u3044\u308b\u3002\u30de\u30af\u30ed\u7d4c\u6e08\u5b66\u5b89\u5b9a\u5316\u653f\u7b56\u306f\u5927\u5909\u91cd\u8981\u3067\u3042\u308b\u304c\u3001\u975e\u5e38\u306b\u96e3\u89e3\u3067\u3042\u308a\u3001\u305d\u308c\u3086\u3048\u306b\u7279\u5b9a\u306e\u30a2\u30d7\u30ed\u30fc\u30c1\uff08\u7279\u306b\u3001\u7d4c\u6e08\u7814\u7a76\u3068\u306f\u5bfe\u7167\u7684\u306b\u653f\u6cbb\u74b0\u5883\u306b\u7126\u70b9\u3092\u5f53\u3066\u305f\u30a2\u30d7\u30ed\u30fc\u30c1\uff09\u304c\u8efd\u8996\u3055\u308c\u7d9a\u3051\u3066\u3044\u308b\u306e\u3060\u3068\u79c1\u306f\u8003\u3048\u3066\u3044\u308b\u3002</p><p>\u30d7\u30ed\u30bb\u30b9\u3068\u3057\u3066\u306f\u3001\u610f\u601d\u6c7a\u5b9a\u306e\u30d7\u30ed\u30bb\u30b9\u3068\u516c\u958b\u3059\u308b\u6587\u66f8\u4f5c\u6210\u306e\u30d7\u30ed\u30bb\u30b9\u3092\u5206\u3051\u308b\u8a66\u307f\u3092\u3057\u3066\u304d\u305f\u3002\u52a9\u6210\u91d1\u306e\u63a8\u85a6\u306f\u901a\u5e38\u3001\u30b9\u30bf\u30c3\u30d5\u304c\u793e\u5185\u6587\u66f8\u3067\u884c\u3046\u3002\u305d\u3057\u3066\u610f\u601d\u6c7a\u5b9a\u8005\u304c\u52a9\u6210\u91d1\u306e\u80cc\u5f8c\u306b\u3042\u308b\u57fa\u672c\u7684\u306a\u8003\u3048\u3092\u627f\u8a8d\u3057\u305f\u5f8c\u306e<a href=\"http://www.openphilanthropy.org/blog/our-grantmaking-so-far-approach-and-process#decisionprocess\"><u>\u30d7\u30ed\u30bb\u30b9</u></a>\u306b\u304a\u3044\u3066\u3001\u4ed6\u306e\u30b9\u30bf\u30c3\u30d5\u304c\u793e\u5185\u306e\u6587\u7ae0\u3092\u300c\u7ffb\u8a33\u300d\u3057\u3066\u516c\u958b\u3059\u308b\u306e\u306b\u9069\u3057\u305f\u6587\u7ae0\u306b\u4ed5\u4e0a\u3052\u308b\u3002\u79c1\u304c\u3053\u306e\u3088\u3046\u306a\u30d7\u30ed\u30bb\u30b9\u3092\u5fc5\u6b7b\u306b\u4f5c\u308a\u4e0a\u3052\u305f\u7406\u7531\u306e\u4e00\u3064\u306f\u3001\u3053\u308c\u306b\u3088\u308a\u52a9\u6210\u91d1\u306e\u6b63\u5f53\u6027\u3092\u8aac\u660e\u3059\u308b\u3053\u3068\u3092\u5fc3\u914d\u305b\u305a\u306b\u3001\u6700\u9ad8\u306e\u52a9\u6210\u91d1\u3092\u4f5c\u308b\u3053\u3068\u3060\u3051\u306b\u96c6\u4e2d\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u308b\u3068\u601d\u3046\u304b\u3089\u3060\u3002</p><p>\u79c1\u305f\u3061\u306e<a href=\"https://www.openphilanthropy.org/what-open-means-us\"><u>\u57fa\u672c\u7406\u5ff5</u></a>\u306b\u306f\u3001\u81ea\u5206\u9054\u306e\u6d3b\u52d5\u306b\u3064\u3044\u3066\u30aa\u30fc\u30d7\u30f3\u3067\u3042\u308b\u3068\u3044\u3046\u3082\u306e\u304c\u3042\u308b\u3002\u3057\u304b\u3057\u3001\u300c\u30aa\u30fc\u30d7\u30f3\u300d\u3068\u3044\u3046\u306e\u306f\u3001\u300c\u5168\u3066\u3092\u7db2\u7f85\u7684\u306b\u6587\u66f8\u5316\u3059\u308b\u300d\u300c\u5168\u3066\u3092\u4eba\u3005\u304c\u7d0d\u5f97\u3067\u304d\u308b\u3088\u3046\u8ad6\u3058\u308b\u300d\u3068\u3044\u3046\u3053\u3068\u3068\u306f\u7570\u306a\u308b\u3002\u8a73\u3057\u304f\u306f\u5f8c\u8ff0\u3059\u308b\u3002</p><p><strong>\u79c1\u305f\u3061\u306f\u300c\u5229\u5bb3\u306e\u885d\u7a81\u3084\u77e5\u306e\u30d0\u30d6\u30eb\u3001\u30a8\u30b3\u30fc\u30c1\u30a7\u30f3\u30d0\u30fc\u73fe\u8c61\u3092\u907f\u3051\u308b\u3053\u3068\u3092\u6975\u7aef\u306b\u91cd\u8981\u8996\u300d\u3057\u306a\u3044</strong>\u3002\u6642\u306b\u306f\u3001\u3042\u308b\u554f\u984c\u306b\u95a2\u3057\u3066\u306e\u79c1\u305f\u3061\u306e\u898b\u65b9\u304c\u3001\u4e16\u9593\u4e00\u822c\u306e\u4eba\u3068\u306f\u304b\u306a\u308a\u7570\u306a\u3063\u3066\u304a\u308a\u3001\u305d\u306e\u554f\u984c\u89e3\u6c7a\u306e\u52a9\u3051\u306b\u306a\u308b\u3068\u79c1\u305f\u3061\u304c\u601d\u3046\u4eba\u304c\uff08\u5076\u7136\u3067\u306f\u306a\u304f\uff09\u305d\u306e\u554f\u984c\u3092\u79c1\u305f\u3061\u3068\u540c\u3058\u3088\u3046\u306b\u898b\u3066\u3044\u308b\u4eba\u3060\u3001\u3068\u3044\u3046\u3053\u3068\u304c\u3042\u308b\u3060\u308d\u3046\u3002\u3053\u308c\u306f\u3001\u77e5\u306e\u300c\u30d0\u30d6\u30eb\uff08\u6ce1\uff09\u300d\u3084\u300c<a href=\"https://ja.wikipedia.org/wiki/%E3%82%A8%E3%82%B3%E3%83%BC%E3%83%81%E3%82%A7%E3%83%B3%E3%83%90%E3%83%BC%E7%8F%BE%E8%B1%A1\"><u>\u30a8\u30b3\u30fc\u30c1\u30a7\u30f3\u30d0\u30fc\u73fe\u8c61</u></a>\u300d\u3068\u3044\u3063\u305f\u3001\u5fc5\u8981\u306a\u306f\u305a\u306e\u4ee3\u66ff\u7684\u8996\u70b9\u3084\u53cd\u8ad6\u3092\u6301\u3061\u8fbc\u307e\u305a\u304a\u4e92\u3044\u306e\u610f\u898b\u3092\u5f37\u5316\u3057\u5408\u3046\u77e5\u7684\u30ec\u30d9\u30eb\u3067\u7d76\u7e01\u3055\u308c\u305f\u96c6\u56e3\u306b\u9665\u3063\u3066\u3057\u307e\u3046\u5371\u967a\u6027\u3092\u4f34\u3046<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefh47ab3mph6\"><sup><a href=\"#fnh47ab3mph6\">[2]</a></sup></span>\u3002</p><p>\u5834\u5408\u306b\u3088\u3063\u3066\u306f\u3001\u3053\u306e\u30ea\u30b9\u30af\u306f\u793e\u4f1a\u7684\u30b3\u30cd\u30af\u30b7\u30e7\u30f3\u306b\u3088\u3063\u3066\u3055\u3089\u306b\u5927\u304d\u304f\u306a\u308a\u3046\u308b\u3002\u7279\u5b9a\u306e\u5206\u91ce\u306e\u30b9\u30da\u30b7\u30e3\u30ea\u30b9\u30c8\u3092\u63a1\u7528\u3059\u308b\u969b\u3001\u79c1\u305f\u3061\u306f\u305d\u306e\u5206\u91ce\u306b\u304a\u3051\u308b\u6df1\u3044\u7d4c\u9a13\u3068\u5f37\u3044\u30b3\u30cd\u30af\u30b7\u30e7\u30f3\u3092\u6301\u3064\u4eba\u6750\u3092\u660e\u78ba\u306b\u6c42\u3081\u3066\u304d\u305f\u3002\u305d\u306e\u305f\u3081\u3001\u30d7\u30ed\u30b0\u30e9\u30e0\u306e\u5f79\u54e1\u304c\u79c1\u305f\u3061\u306e\u30a2\u30c9\u30d0\u30a4\u30b6\u30fc\u3084\u52a9\u6210\u91d1\u306e\u53d7\u9818\u8005\u3068\u3057\u3066\u9069\u3057\u3066\u3044\u308b\u4eba\u305f\u3061\u306e\u591a\u304f\u3068\u53cb\u4eba\u95a2\u4fc2\u306b\u3042\u308b\u5834\u5408\u304c\u3042\u308b\u3002</p><p>\u79c1\u3092\u542b\u3081\u30b9\u30bf\u30c3\u30d5\u306f\u3001\u7279\u5b9a\u306e\u554f\u984c\u306b\u7126\u70b9\u3092\u5f53\u3066\u308b\u306e\u3067\u306f\u306a\u304f\u3001\u8907\u6570\u306e<u>\u554f\u984c\u304b\u3089\u9078\u629e\u3059\u308b</u>\u3053\u3068\u3092\u5c02\u9580\u3068\u3057\u3066\u3044\u308b\u3002\u300c\u53ef\u80fd\u306a\u9650\u308a\u306e\u3088\u3044\u3053\u3068\u3092\u3059\u308b\u305f\u3081\u306b\u554f\u984c\u3092\u9078\u629e\u3059\u308b\u300d\u3068\u3044\u3046\u30df\u30c3\u30b7\u30e7\u30f3\u306f\u3001\u305d\u308c\u81ea\u4f53\u304c\u77e5\u7684\u7a7a\u9593\u3067\u3042\u308a\u3001\u305d\u306e\u5468\u56f2\u306b\u306f\u30b3\u30df\u30e5\u30cb\u30c6\u30a3\u304c\u5b58\u5728\u3059\u308b\u3002\u3088\u308a\u5177\u4f53\u7684\u306b\u8a00\u3048\u3070\u3001\u79c1\u3092\u542b\u3081\u591a\u304f\u306e\u30b9\u30bf\u30c3\u30d5\u304c<a href=\"http://blog.givewell.org/2013/08/13/effective-altruism/\"><u>\u52b9\u679c\u7684\u5229\u4ed6\u4e3b\u7fa9</u></a>\u306e\u30b3\u30df\u30e5\u30cb\u30c6\u30a3\u306b\u5c5e\u3057\u3066\u304a\u308a\u3001\u305d\u306e\u30b3\u30df\u30e5\u30cb\u30c6\u30a3\u3067\u591a\u304f\u306e\u793e\u4f1a\u7684\u306a\u7d50\u3073\u3064\u304d\u3092\u6301\u3063\u3066\u3044\u308b\u3002</p><p>\u305d\u306e\u7d50\u679c\u3001\u52a9\u6210\u91d1\u306e\u6848\u4ef6\u3068\u4eba\u9593\u95a2\u4fc2\u3092\u5207\u308a\u96e2\u3059\u3053\u3068\u304c\u56f0\u96e3\u306a\u5834\u5408\u304c\u3042\u308b\u3002\u3053\u306e\u3088\u3046\u306a\u72b6\u6cc1\u3067\u306f\u3001\u5ba2\u89b3\u7684\u3067\u306a\u304f\u306a\u308a\u3001\u5165\u624b\u53ef\u80fd\u306a\u8a3c\u62e0\u3084\u4e3b\u5f35\u3092\u5408\u7406\u7684\u306b\u5224\u65ad\u3067\u304d\u306a\u304f\u306a\u308b\u5371\u967a\u6027\u304c\u975e\u5e38\u306b\u9ad8\u304f\u306a\u308b\u3002\u3082\u3057\u3001\u79c1\u305f\u3061\u306e\u76ee\u6a19\u304c\u3001\u6700\u3082\u5f37\u529b\u306b\u88cf\u4ed8\u3051\u3089\u308c\u305f\u5bc4\u4ed8\u306e\u6a5f\u4f1a\u3092\u898b\u3064\u3051\u308b\u3053\u3068\u3067\u3042\u308b\u306a\u3089\u3070\u3001\u3053\u308c\u306f\u5927\u304d\u306a\u554f\u984c\u3068\u306a\u308b\u3060\u308d\u3046\u3002\u3057\u304b\u3057\u3001\u300c\u30d2\u30c3\u30c8\u30d9\u30fc\u30b9\u300d\u306e\u30a2\u30d7\u30ed\u30fc\u30c1\u306b\u3068\u3063\u3066\u306e\u6b20\u70b9\u306f\u3042\u307e\u308a\u660e\u78ba\u3067\u306f\u306a\u304f\u3001\u79c1\u306e\u8003\u3048\u3067\u306f\u3001\u3053\u306e\u3088\u3046\u306a\u72b6\u6cc1\u3092\u904e\u5ea6\u306b<u>\u56de\u907f</u>\u3057\u3059\u304e\u308b\u3053\u3068\u306f\u53d7\u3051\u5165\u308c\u304c\u305f\u3044\u3002</p><p>\u79c1\u81ea\u8eab\u3092\u4f8b\u306b\u3068\u3063\u3066\u8aac\u660e\u3059\u308b\u3068</p><ul><li>\u52b9\u679c\u7684\u5229\u4ed6\u4e3b\u7fa9\u3084\u30a4\u30f3\u30d1\u30af\u30c8\u91cd\u8996\u306e\u5bc4\u4ed8\u3078\u306e\u5f37\u3044\u95a2\u5fc3\u3092\u62b1\u3044\u3066\u3044\u305f\u3053\u3068\u3067\u3001\u540c\u3058\u3088\u3046\u306a\u95a2\u5fc3\u3092\u6301\u3064\u4eba\u3005\u3068\u53cb\u4eba\u306b\u306a\u308a\u3001\u540c\u3058\u5bb6\u306b\u3082\u4f4f\u3080\u3088\u3046\u306b\u306a\u3063\u305f\u3002</li><li>\u79c1\u306e<a href=\"https://www.openphilanthropy.org/about/vision-and-values\"><u>\u4fa1\u5024\u89b3</u></a>\u3068\u57fa\u672c\u7684\u306a\u8a8d\u8b58\u8ad6\u3092\u6700\u3082\u5f37\u304f\u5171\u6709\u3057\u3066\u304a\u308a\u3001\u77e5\u7684\u306a\u4ef2\u9593\u3068\u3057\u3066\u6700\u3082\u8208\u5473\u6df1\u304f\u3001\u6709\u610f\u7fa9\u3060\u3068\u611f\u3058\u308b\u4eba\u3005\u3068\u591a\u304f\u306e\u6642\u9593\u3092\u904e\u3054\u3057\u3066\u3044\u308b\u3002</li><li>\u3082\u3057\u3001 \u53cb\u4eba\u306b\u5bfe\u3057\u3066\u79c1\u306b\u52a9\u8a00\u3092\u3057\u305f\u308a\u3001\u30aa\u30fc\u30d7\u30f3\u30fb\u30d5\u30a3\u30e9\u30f3\u30bd\u30ed\u30d4\u30fc\u30fb\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u304b\u3089\u306e\u652f\u63f4\u3092\u6c42\u3081\u305f\u308a\u3059\u308b\u3053\u3068\u3092\u9060\u616e\u3059\u308b\u3088\u3046\u306b\u6c42\u3081\u308b\u65b9\u91dd\u3092\u53d6\u308c\u3070\u3001\u305d\u308c\u306f\u79c1\u304c\u7279\u306b\u4fe1\u983c\u3059\u308b\u4eba\u304b\u3089\u306e\u610f\u898b\u3092\u53d7\u3051\u4ed8\u3051\u306a\u3044\u3068\u3044\u3046\u3053\u3068\u306a\u308b\u3002</li><li>\u300c\u30d2\u30c3\u30c8\u30fb\u30d9\u30fc\u30b9\u300d\u306e\u30a2\u30d7\u30ed\u30fc\u30c1\u3067\u306f\u3001\u3054\u304f\u5c11\u6570\u306e\u512a\u308c\u305f\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u304c\u30a4\u30f3\u30d1\u30af\u30c8\u306e\u591a\u304f\uff08\u3042\u308b\u3044\u306f\u5927\u90e8\u5206\uff09\u3092\u5360\u3081\u308b\u3068\u671f\u5f85\u3055\u308c\u308b\u3002\u3067\u3042\u308b\u304b\u3089\u3001\u79c1\u305f\u3061\u306e\u4fa1\u5024\u89b3\u3092\u6700\u3082\u3088\u304f\u5171\u6709\u3057\u3066\u3044\u308b\u4eba\u305f\u3061\u304b\u3089\u306e\u30a2\u30a4\u30c7\u30a2\u3092\u53d7\u3051\u4ed8\u3051\u306a\u3044\u3068\u3044\u3046\u3053\u3068\u306f\u3001\u6d3b\u52d5\u306e\u671f\u5f85\u5024\u3092<u>\u5287\u7684\u306b</u>\u4e0b\u3052\u308b\u3053\u3068\u306b\u306a\u308b\u3002</li></ul><p>\u3053\u306e\u554f\u984c\u306f\u3001\u4ed6\u306e\u30b9\u30bf\u30c3\u30d5\u306b\u3068\u3063\u3066\u306f\u3055\u3089\u306b\u9855\u8457\u3060\u3002\u3068\u3044\u3046\u306e\u3082\u3001\u3042\u308b\u5730\u57df\u3067\u8cc7\u91d1\u8abf\u9054\u306e\u6a5f\u4f1a\u3092\u8abf\u67fb\u3059\u308b\u8cac\u4efb\u3092\u8ca0\u3046\u30b9\u30bf\u30c3\u30d5\u306f\u3001\u95a2\u9023\u3059\u308b\u30b3\u30df\u30e5\u30cb\u30c6\u30a3\u3067\u6700\u3082\u6df1\u3044\u793e\u4f1a\u7684\u30b3\u30cd\u30af\u30b7\u30e7\u30f3\u3092\u6301\u3064\u4eba\u306b\u306a\u308b\u50be\u5411\u304c\u3042\u308b\u304b\u3089\u3060\u3002</p><p>\u306f\u3063\u304d\u308a\u3055\u305b\u3066\u304a\u304d\u305f\u3044\u306e\u306f\u3001\u79c1\u306f\u77e5\u306e\u300c\u30d0\u30d6\u30eb\u300d\u3084\u5229\u76ca\u76f8\u53cd\u306e\u30ea\u30b9\u30af\u3092\u7121\u8996\u3059\u308b\u3079\u304d\u3060\u3068\u306f\u8003\u3048\u3066\u3044\u306a\u3044\u3002\u3053\u3046\u3057\u305f\u30ea\u30b9\u30af\u3092\u8efd\u6e1b\u3059\u308b\u305f\u3081\u306b\u3001\u79c1\u305f\u3061\u306f\u4ee5\u4e0b\u306e\u3053\u3068\u3092\u884c\u3063\u3066\u3044\u308b\u3002\uff08\uff11\uff09\u610f\u601d\u6c7a\u5b9a\u8005\u306b\u95a2\u9023\u3059\u308b\u30b3\u30cd\u30af\u30b7\u30e7\u30f3\u3092\u5fc5\u305a\u958b\u793a\u3059\u308b\uff08\uff12\uff09\u610f\u601d\u6c7a\u5b9a\u3092\u884c\u3046\u524d\u306b\u5fc5\u305a\u3001\u7570\u306a\u308b\u8996\u70b9\u3092\u63a2\u3059\u52aa\u529b\u3092\u7a4d\u6975\u7684\u306b\u884c\u3044\u3001\u305d\u306e\u969b\u3001\u79c1\u305f\u3061\u304c\u77e5\u308a\u3046\u308b\u9650\u308a\u306e\u6700\u3082\u6709\u529b\u306a\u53cd\u8ad6\u3082\u5341\u5206\u691c\u8a0e\u3059\u308b\uff08\uff13\uff09\u4e3b\u8981\u30b9\u30bf\u30c3\u30d5\u304c\u3001\u53cb\u4eba\u3084\u30a2\u30c9\u30d0\u30a4\u30b6\u30fc\u306e\u5224\u65ad\u306b\u983c\u308a\u3059\u304e\u305a\u3001\u81ea\u3089\u3067\u6700\u91cd\u8981\u8ab2\u984c\u3092\u7406\u89e3\u3059\u308b\u3053\u3068\u3092\u73fe\u5b9f\u7684\u306a\u7bc4\u56f2\u3067\u76ee\u6307\u3059\uff08\uff14\uff09\u81ea\u5206\u305f\u3061\u306e\u4eba\u9593\u95a2\u4fc2\u304c\u3001\u72b6\u6cc1\u8a8d\u8b58\u3092\u6b6a\u3081\u3066\u3044\u308b\u304b\u3082\u3057\u308c\u306a\u3044\u3068\u5e38\u306b\u81ea\u554f\u3059\u308b\uff08\uff15\uff09\u95a2\u9023\u3059\u308b\u5229\u76ca\u76f8\u53cd\u3084\u793e\u4f1a\u7684\u95a2\u4fc2\u3092\u6301\u305f\u306a\u3044\u30b9\u30bf\u30c3\u30d5\u304b\u3089\u610f\u898b\u3092\u6c42\u3081\u308b\u3088\u3046\u306b\u3059\u308b\u3002</p><p>\u3057\u304b\u3057\u3053\u308c\u3089\u5168\u3066\u3092\u3057\u3066\u3082\u3001\u591a\u304f\u306e\u53cb\u4eba\u304b\u3089\u5f37\u3044\u652f\u6301\u3092\u53d7\u3051\u3066\u3044\u308b\u52a9\u6210\u91d1\u3092\u63a8\u85a6\u3057\u305f\u3044\u304c\u3001\u79c1\u305f\u3061\u306e\u77e5\u7684\u30fb\u793e\u4f1a\u7684\u30b5\u30fc\u30af\u30eb\u306e\u5916\u304b\u3089\u306f\u307b\u3068\u3093\u3069\u95a2\u5fc3\u3092\u6301\u305f\u308c\u3066\u3044\u306a\u3044\u3001\u3068\u3044\u3046\u72b6\u6cc1\u306b\u9665\u308b\u3053\u3068\u304c\u3042\u308b\u3002\u3082\u3057\u305d\u306e\u3088\u3046\u306a\u52a9\u6210\u91d1\u3092\u63a8\u85a6\u3057\u306a\u3044\u3053\u3068\u306b\u3059\u308c\u3070\u3001\u30a4\u30f3\u30d1\u30af\u30c8\u3092\u4e0e\u3048\u308b\u6700\u9ad8\u306e\u30c1\u30e3\u30f3\u30b9\u3092\u898b\u904e\u3054\u3059\u3053\u3068\u306b\u306a\u308a\u3001\u3053\u308c\u306f\u300c\u30d2\u30c3\u30c8\u30d9\u30fc\u30b9\u300d\u306e\u30a2\u30d7\u30ed\u30fc\u30c1\u306b\u3068\u3063\u3066\u5bb9\u8a8d\u3067\u304d\u306a\u3044\u30b3\u30b9\u30c8\u3068\u306a\u308b\u3060\u308d\u3046\u3002</p><p><strong>\u79c1\u305f\u3061\u306f\u300c\u904e\u4fe1\u3068\u60c5\u5831\u4e0d\u8db3\u3068\u3044\u3046\uff08\u4f55\u3089\u304b\u306e\u73fe\u5b9f\u7684\u306a\u30ea\u30b9\u30af\u3092\u4f34\u3046\uff09\u8868\u9762\u7684\u306a\u898b\u3048\u65b9\u3092\u907f\u3051\u308b\u300d\u3053\u3068\u306f\u3057\u306a\u3044</strong>\u3002\u79c1\u304c\u601d\u3044\u63cf\u304f\u7406\u60f3\u7684\u306a\u6148\u5584\u4e8b\u696d\u306e\u300c\u30d2\u30c3\u30c8\u300d\u306f\u3001\u79c1\u305f\u3061\u306f\u53ef\u80fd\u6027\u3092\u611f\u3058\u308b\u3082\u306e\u306e\u4e16\u9593\u4e00\u822c\u306f\u305d\u3046\u306f\u601d\u3063\u3066\u3044\u306a\u3044\u3088\u3046\u306a\u3001\u3042\u308b\u6975\u3081\u3066\u91cd\u8981\u306a\u30a2\u30a4\u30c7\u30a2\u3092\u652f\u63f4\u3059\u308b\u3068\u3044\u3046\u5f62\u3092\u53d6\u308b\u3002\u305d\u3057\u3066\u3001\u305d\u306e\u30a2\u30a4\u30c7\u30a2\u3092\u8ffd\u6c42\u3057\u3001\u6700\u7d42\u7684\u306b\u6210\u529f\u3092\u53ce\u3081\u3066\u4eba\u3005\u306e\u8003\u3048\u3092\u5909\u3048\u308b\u305f\u3081\u306b\u3001\u4ed6\u306e\u4e3b\u8981\u306a\u8cc7\u91d1\u63d0\u4f9b\u8005\u304c\u3067\u304d\u306a\u3044\u3088\u3046\u306a\u652f\u63f4\u3092\u3059\u308b\u3002</p><p>\u305d\u306e\u3088\u3046\u306a\u72b6\u6cc1\u4e0b\u3067\u306f\u3001\u305d\u306e\u30a2\u30a4\u30c7\u30a3\u30a2\u306b\u76f4\u9762\u3057\u305f\u307b\u3068\u3093\u3069\u306e\u4eba\u304c\u3001\u6700\u521d\u306f\u61d0\u7591\u7684\u3067\u3001\u304a\u305d\u3089\u304f\u5f37\u3044\u53cd\u767a\u3092\u793a\u3059\u3068\u601d\u3046\u3002\u307e\u305f\u3001\u305d\u306e\u30a2\u30a4\u30c7\u30a3\u30a2\u306e\u80cc\u666f\u306b\u306f\u5f37\u529b\u3067\u660e\u78ba\u306a\u8a3c\u62e0\u306a\u3069\u306a\u304f\uff08\u3042\u3063\u305f\u3068\u3057\u3066\u3082\u8aac\u660e\u3084\u8981\u7d04\u304c\u6975\u3081\u3066\u56f0\u96e3\u3067\uff09\u3001\u305d\u306e\u30a2\u30a4\u30c7\u30a3\u30a2\u306b\u8ced\u3051\u308b\u3053\u3068\u306f\u78ba\u7387\u306e\u4f4e\u3044\u8ced\u3051\u4e8b\u3067\u3042\u308b\u3068\u4e88\u60f3\u3059\u308b\u3002\u3053\u308c\u3089\u306e\u3053\u3068\u3092\u8003\u616e\u3059\u308b\u3068\u3001\u79c1\u305f\u3061\u306e\u6d3b\u52d5\u3092\u898b\u308b\u5916\u90e8\u306e\u4eba\u3005\u306f\u3001\u79c1\u305f\u3061\u304c\u4e3b\u306b\u61b6\u6e2c\u3084\u8584\u3044\u8a3c\u62e0\u3001\u81ea\u5df1\u5f37\u5316\u578b\u306e\u77e5\u306e\u30d0\u30d6\u30eb\u306b\u57fa\u3065\u3044\u305f\u8aa4\u3063\u305f\u5224\u65ad\u3092\u3057\u3066\u3044\u308b\u3068\u8a8d\u8b58\u3059\u308b\u3053\u3068\u304c\u591a\u3044\u3060\u308d\u3046\u3002\u3057\u305f\u304c\u3063\u3066\u3001\u591a\u304f\u306e\u4eba\u306e\u76ee\u306b\u306f\u79c1\u305f\u3061\u304c\u81ea\u4fe1\u904e\u5270\u3067\u60c5\u5831\u4e0d\u8db3\u306e\u3088\u3046\u306b\u6620\u308b\u3060\u308d\u3046\u3002\u5b9f\u969b\u3001\u4e0d\u4eba\u6c17\u306a\u30a2\u30a4\u30c7\u30a3\u30a2\u3092\u652f\u6301\u3059\u308b\u3068\u3044\u3046\u6027\u8cea\u4e0a\u3001\u79c1\u305f\u3061\u304c\u3069\u308c\u307b\u3069\u9811\u5f35\u3063\u3066\uff08\u5b9f\u969b\u305d\u3046\u3059\u308b\u3079\u304d\u3067\uff09\u5225\u306e\u8996\u70b9\u3092\u63a2\u3057\u3001\u691c\u8a0e\u3057\u305f\u3068\u3057\u3066\u3082\u3001\u305d\u3046\u306a\u3063\u3066\u3057\u307e\u3046\u5371\u967a\u6027\u304c\u3042\u308b\u3002</p><p>\u79c1\u306f\u3001\u300c\u30d2\u30c3\u30c8\u30d9\u30fc\u30b9\u300d\u306e\u30a2\u30d7\u30ed\u30fc\u30c1\u3092\u3068\u308b\u306b\u306f\u3001\u305d\u306e\u3088\u3046\u306a\u72b6\u6cc1\u3067\u3082\u30ea\u30b9\u30af\u3092\u53d7\u3051\u5165\u308c\u3001\u524d\u9032\u3059\u308b\u899a\u609f\u304c\u5fc5\u8981\u3067\u3042\u308b\u3068\u601d\u3046\u3002\u3057\u304b\u3057\u3001\u5f8c\u8ff0\u3059\u308b\u3088\u3046\u306b\u3001\u3053\u306e\u65b9\u6cd5\u306b\u306f\u826f\u3044\u9762\u3068\u60aa\u3044\u9762\u304c\u3042\u308a\u3001\u3053\u306e\u3088\u3046\u306a\u30ea\u30b9\u30af\u3092\u8ca0\u3046\u3053\u3068\u3068\u3001\u5358\u306b\u81ea\u5206\u52dd\u624b\u306a\u5e7b\u60f3\u3092\u8ffd\u3044\u6c42\u3081\u308b\u3053\u3068\u3068\u306e\u9593\u306b\u306f\u3001\u91cd\u8981\u306a\u9055\u3044\u304c\u3042\u308b\u3002</p><h2>\u30d2\u30c3\u30c8\u30d9\u30fc\u30b9\u306e\u5bc4\u4ed8\u3092\u4e0a\u624b\u304f\u884c\u3046\u305f\u3081\u306e\u6d3b\u52d5\u539f\u5247</h2><p>\u524d\u306e\u30bb\u30af\u30b7\u30e7\u30f3\u3067\u306f\u3001\u591a\u304f\u306e\u539f\u5247\u306b\u7570\u8b70\u3092\u5531\u3048\u305f\u3002\u3053\u308c\u3089\u306e\u539f\u5247\u306f\u3001\u4ed6\u306e\u6587\u8108\u3067\u306f\u91cd\u8981\u306a\u3082\u306e\u3067\u3001<a href=\"http://www.givewell.org/\"><u>GiveWell&nbsp;</u></a>\u306e\u30d5\u30a1\u30f3\u306b\u3068\u3063\u3066\u306f\u79c1\u305f\u3061\u304c\u5f93\u3046\u3068\u671f\u5f85\u3057\u3066\u3044\u305f\u3082\u306e\u3060\u3063\u305f\u304b\u3082\u3057\u308c\u306a\u3044\u3002\u3082\u3057\u3001\u8a3c\u62e0\u3084\u5c02\u9580\u5bb6\u306e\u540c\u610f\u3001\u5f93\u6765\u306e\u5e38\u8b58\u306b\u57fa\u3065\u304b<u>\u306a\u3044</u>\u63d0\u6848\u3092\u9032\u3093\u3067\u3059\u308b\u306e\u306a\u3089\u3070\u3001\u826f\u3044\u5bc4\u4ed8\u3068\u60aa\u3044\u5bc4\u4ed8\u3092\u533a\u5225\u3059\u308b\u539f\u5247\u7684\u306a\u65b9\u6cd5\u306f<u>\u4f55\u304b</u>\u3042\u308b\u306e\u3060\u308d\u3046\u304b\uff1f\u305d\u308c\u3068\u3082\u3001\u305f\u3060\u76f4\u611f\u7684\u306b\u30ef\u30af\u30ef\u30af\u3059\u308b\u3053\u3068\u306b\u8cc7\u91d1\u3092\u63d0\u4f9b\u3059\u3079\u304d\u306a\u306e\u3060\u308d\u3046\u304b\uff1f\u3068\u554f\u3046\u306e\u306f\u3082\u3063\u3068\u3082\u306a\u3053\u3068\u3060\u3002</p><p>\u300c\u30d2\u30c3\u30c8\u300d\u306f\u305d\u306e\u6027\u8cea\u4e0a\u3001\u3081\u3063\u305f\u306b\u8d77\u304d\u306a\u3044\u3053\u3068\u3067\u3042\u308a\u3001\u4e88\u6e2c\u3059\u308b\u3053\u3068\u306f\u304a\u305d\u3089\u304f\u96e3\u3057\u3044\u3002\u3057\u305f\u304c\u3063\u3066\u3001\u3069\u306e\u3088\u3046\u306a\u884c\u52d5\u304c\u300c\u30d2\u30c3\u30c8\u300d\u306b\u3064\u306a\u304c\u308a\u3084\u3059\u3044\u304b\u3092\u4e00\u6982\u306b\u8a9e\u308b\u3053\u3068\u306f\u3067\u304d\u306a\u3044\u3068\u601d\u3046\u3002\u904e\u53bb\u306b\u300c\u30d2\u30c3\u30c8\u300d\u3092\u751f\u307f\u51fa\u3057\u305f\u6148\u5584\u5bb6\u3092\u5341\u5206\u306b\u77e5\u3063\u3066\u3044\u308b\u308f\u3051\u3067\u306f\u306a\u3044\u306e\u3067\u3001\u81ea\u4fe1\u3092\u6301\u3063\u3066\u591a\u304f\u3092\u8a9e\u308b\u3053\u3068\u306f\u3067\u304d\u306a\u3044\u304c\u3001\u300c\u30d2\u30c3\u30c8\u30d9\u30fc\u30b9\u300d\u306e\u5bc4\u4ed8\u3092\u3067\u304d\u308b\u3060\u3051\u3046\u307e\u304f\u884c\u3046\u305f\u3081\u306b\u3001\u79c1\u305f\u3061\u304c\u4f7f\u3063\u3066\u3044\u308b\u539f\u5247\u306e\u6982\u8981\u3092\u8aac\u660e\u3059\u308b\u3053\u3068\u306f\u3067\u304d\u308b\u3002</p><p><strong>\u91cd\u8981\u6027\u3001\u898b\u904e\u3054\u3055\u308c\u3066\u3044\u308b\u5ea6\u5408\u3044\u3001\u53d6\u308a\u7d44\u307f\u3084\u3059\u3055\u3092\u8a55\u4fa1\u3059\u308b</strong>\u3002\u3053\u308c\u3089\u306f\u3001<a href=\"https://www.openphilanthropy.org/focus\"><u>\u30aa\u30fc\u30d7\u30f3\u30fb\u30d5\u30a3\u30e9\u30f3\u30bd\u30ed\u30d4\u30fc\u306e\u91cd\u8981\u306a\u57fa\u6e96</u></a>\u3067\u3042\u308b\u3002\u4ed6\u306e\u6761\u4ef6\u304c\u540c\u3058\u5834\u5408\u3001\u3053\u308c\u3089\u306e\u57fa\u6e96\u305d\u308c\u305e\u308c\u304c\u300c\u30d2\u30c3\u30c8\u300d\u3092\u751f\u3080\u53ef\u80fd\u6027\u3092\u9ad8\u3081\u3001\u307e\u305f\u3001\u305d\u308c\u305e\u308c\u306e\u6307\u6a19\u3092\u5358\u72ec\u3067\u898b\u308b\u3068\u304b\u306a\u308a\u308f\u304b\u308a\u3084\u3059\u304f\u8a55\u4fa1\u3067\u304d\u308b\u5834\u5408\u304c\u591a\u3044\u3068\u601d\u3046\u3002\u3053\u306e\u30bb\u30af\u30b7\u30e7\u30f3\u306e\u6b8b\u308a\u3067\u306f\u3001\u96e3\u3057\u3044\u72b6\u6cc1\u3067\uff08\u4f8b\u3048\u3070\u3001\u5c02\u9580\u5bb6\u306e\u30b3\u30f3\u30bb\u30f3\u30b5\u30b9\u3084\u660e\u78ba\u306a\u8a3c\u62e0\u304c\u306a\u3044\u5834\u5408\uff09\u3053\u308c\u3089\u306e\u57fa\u6e96\u3092\u3069\u306e\u3088\u3046\u306b\u8a55\u4fa1\u3059\u308b\u304b\u3068\u3044\u3046\u3053\u3068\u306b\u95a2\u9023\u3057\u305f\u8a71\u3092\u3057\u3066\u3044\u304f\u3002</p><p><strong>\u8003\u3048\u3089\u308c\u308b\u6700\u826f\u306e\u30b1\u30fc\u30b9\u3068\u6700\u60aa\u306e\u30b1\u30fc\u30b9\u3092\u8003\u616e\u3059\u308b</strong>\u3002\u7406\u60f3\u7684\u306b\u306f\u3001\u60f3\u5b9a\u3055\u308c\u308b\u305d\u308c\u305e\u308c\u306e\u7d50\u679c\u306b\u78ba\u7387\u3092\u5272\u308a\u5f53\u3066\u3001\u5168\u4f53\u7684\u306a\u671f\u5f85\u5024\u306b\u6ce8\u76ee\u3059\u308b\u3060\u308d\u3046\u3002\u5b9f\u969b\u306b\u306f\u3001\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u304c\u9577\u671f\u76ee\u6a19\u3092\u5b8c\u5168\u306b\u9054\u6210\u3057\u305f\u5834\u5408\u306b\u3069\u308c\u3060\u3051\u306e\u5f71\u97ff\u3092\u4e0e\u3048\u308b\u304b\uff08\u6700\u826f\u306e\u30b1\u30fc\u30b9\uff09\u3068\u3001\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u304c\u8aa4\u3063\u305f\u65b9\u5411\u306b\u9032\u3093\u3060\u5834\u5408\u306b\u3069\u308c\u3060\u3051\u306e\u640d\u5bb3\u3092\u4e0e\u3048\u308b\u304b\uff08\u6700\u60aa\u306e\u30b1\u30fc\u30b9\uff09\u3092\u691c\u8a0e\u3059\u308b\u3053\u3068\u304c\u3001\u4e00\u3064\u306e\u8fd1\u4f3c\u70b9\u3068\u306a\u308b\u3002\u5f8c\u8005\u306f\u3001\u305d\u306e\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306b\u3069\u308c\u3060\u3051\u614e\u91cd\u306b\u53d6\u308a\u7d44\u3080\u3079\u304d\u304b\u3001\u307e\u305f\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u3092\u9032\u3081\u308b\u524d\u306b\u8003\u3048\u3046\u308b\u53cd\u8ad6\u306e\u691c\u8a0e\u306b\u3069\u308c\u3060\u3051\u306e\u52b4\u529b\u3092\u8cbb\u3084\u3059\u3079\u304d\u304b\u3092\u793a\u3059\u6307\u6a19\u3068\u306a\u308b\u3002\u524d\u8005\u306f\u3001\u91cd\u8981\u6027\u306e\u5c3a\u5ea6\u3068\u306a\u308a\u3046\u308b\u3082\u306e\u3067\u3001\u3053\u308c\u307e\u3067\u306e\u3068\u3053\u308d\u91cd\u8981\u6027\u306e\u8a55\u4fa1\u306b\u306f\u307b\u307c\u3053\u306e\u30a2\u30d7\u30ed\u30fc\u30c1\u3092\u3068\u3063\u3066\u3044\u308b\u3002\u4f8b\u3048\u3070\u3001\u79c1\u305f\u3061\u304c\u7b97\u51fa\u3057\u305f<a href=\"https://docs.google.com/document/d/1DTl4TYaTPMAtwQTju9PZmxKhZTCh6nmi-Vh8cnSgYak/edit\"><u>\u3055\u307e\u3056\u307e\u306a\u554f\u984c\u306b\u5bfe\u3059\u308b\u4e3b\u8981\u306a\u653f\u7b56\u5909\u66f4\u306e\u4fa1\u5024\u306e\u63a8\u5b9a\u5024</u></a>\u3092\u898b\u3066\u307b\u3057\u3044\u3002</p><p>\u5f80\u3005\u306b\u3057\u3066\u3001\u76ee\u6a19\u306f\u898b\u304b\u3051\u3088\u308a\u306f\u308b\u304b\u306b\u9054\u6210\u3057\u3084\u3059\u3044\u3082\u306e\u3067\u3042\u308b\uff08\u3044\u304f\u3064\u304b\u306e\u4f8b\u306f<a href=\"http://files.givewell.org/files/conversations/Frank%20Baumgartner%2005-03-13%20(public).pdf\"><u>\u3053\u3061\u3089</u></a>\uff09\u304b\u3089\u3001\u4fa1\u5024\u306f\u3042\u308b\u3051\u308c\u3069\u3082\u4e0d\u53ef\u80fd\u306b\u898b\u3048\u308b\u76ee\u6a19\u3092\u76ee\u6307\u3059\u4fa1\u5024\u306f\u5341\u5206\u3042\u308b\u3002\u6210\u529f\u3059\u308b\u3053\u3068\u304c\u3081\u3063\u305f\u306b\u306a\u3044\u306a\u3089\u3070\u3001<u>\u305d\u308c\u306a\u308a\u306b\u4fa1\u5024\u306e\u3042\u308b</u>\u76ee\u6a19\u3092\u76ee\u6307\u3059\u304b\u3001<u>\u6700\u5927\u9650\u306e\u30a4\u30f3\u30d1\u30af\u30c8\u3092\u4e0e\u3048\u308b</u>\u76ee\u6a19\u3092\u76ee\u6307\u3059\u3053\u3068\u304c\u91cd\u8981\u306b\u306a\u3063\u3066\u304f\u308b\u3002\u3053\u306e\u3088\u3046\u306a\u5bc4\u4ed8\u306b\u306f\u4e0d\u78ba\u5b9f\u6027\u304c\u3064\u304d\u3082\u306e\u3067\u306f\u3042\u308b\u304c\u3001\u300c\u6700\u9ad8\u306e\u30b1\u30fc\u30b9\u3067\u3069\u308c\u3060\u3051\u306e\u5229\u76ca\u304c\u5f97\u3089\u308c\u308b\u304b\u300d\u3068\u3044\u3046\u554f\u3044\u306b\u5bfe\u3059\u308b\u7b54\u3048\u306f\u3001\u5bc4\u4ed8\u306e\u6a5f\u4f1a\u3054\u3068\u306b\u3088\u3063\u3066\u5168\u304f\u7570\u306a\u308b\u3082\u306e\u306b\u306a\u308b\u3068\u79c1\u306f\u8003\u3048\u308b\u3002</p><p><strong>\u591a\u5927\u306a\u52b4\u529b\u3092\u8cbb\u3084\u3059\u304b\u3001\u305d\u3046\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u4eba\u3068\u5f37\u3044\u4fe1\u983c\u95a2\u4fc2\u3092\u7bc9\u304f\u3053\u3068\u3067\u3001\u554f\u984c\u306b\u95a2\u3059\u308b\u91cd\u8981\u306a\u8ab2\u984c\u3001\u6587\u732e\u3001\u7d44\u7e54\u3001\u4eba\u3005\u306b\u3064\u3044\u3066\u6df1\u304f\u7406\u89e3\u3059\u308b\u3053\u3068\u3092\u76ee\u6307\u3059</strong>\u3002\u8868\u9762\u7684\u306a\u7406\u89e3\u306b\u57fa\u3065\u3044\u3066\u3001\u9b45\u529b\u7684\u3067\u30a4\u30f3\u30d1\u30af\u30c8\u306e\u3042\u308b\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u3092\u652f\u63f4\u3059\u308c\u3070\u3001\u4ed6\u306e\u8cc7\u91d1\u63d0\u4f9b\u8005\u3068\u91cd\u8907\u3057\u3066\u3057\u307e\u3046\u5371\u967a\u6027\u304c\u9ad8\u304f\u306a\u308b\u3002\u8868\u9762\u7684\u306b\u306f\u9b45\u529b\u7684\u3067\u30a4\u30f3\u30d1\u30af\u30c8\u304c\u3042\u308b\u3088\u3046\u306b\u898b\u3048\u308b\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u3092\u652f\u63f4\u3057\u3066\u3082\u3001\u4ed6\u304b\u3089\u652f\u63f4\u3092\u53d7\u3051\u3066\u3044\u306a\u3044\u5834\u5408\u306f\u3001\u4ed6\u306e\u30c1\u30fc\u30e0\u304c\u6b63\u5f53\u306a\u7406\u7531\u3067\u652f\u63f4\u3057\u306a\u3044\u3068\u6c7a\u3081\u305f\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306b\u69cb\u9020\u4e0a\u504f\u3063\u3066\u3057\u307e\u3046\u5371\u967a\u6027\u304c\u3042\u308b\u3002\u5bfe\u7167\u7684\u306b\u79c1\u305f\u3061\u306f\u3001\u9069\u5207\u306a\u65b9\u6cd5\u3067\u5341\u5206\u306a\u60c5\u5831\u3092\u6301\u3061\u3001\u4eba\u8108\u304c\u3042\u308a\u3001\u601d\u616e\u6df1\u3044\u3001\u4e16\u754c\u3067\u3082\u30c8\u30c3\u30d7\u30af\u30e9\u30b9\u306e\u4fe1\u983c\u3067\u304d\u308b\u4eba\u304c\u30ef\u30af\u30ef\u30af\u3067\u304d\u308b\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u3092\u652f\u63f4\u3059\u308b\u3053\u3068\u3092\u76ee\u6307\u3057\u3066\u3044\u308b\u3002</p><p>\u3053\u308c\u3092\u5b9f\u73fe\u3059\u308b\u3053\u3068\u306f\u7c21\u5358\u3067\u306f\u306a\u3044\u3002\u79c1\u305f\u3061\u304c\u5341\u5206\u306a\u6642\u9593\u3092\u304b\u3051\u3066\u53d6\u308a\u7d44\u3080\u3053\u3068\u306e\u3067\u304d\u306a\u3044\u554f\u984c\u306b\u5bfe\u3057\u3066\u3001\u6700\u5927\u9650\u306e\u77e5\u8b58\u3092\u6301\u3064\uff08\u3042\u308b\u3044\u306f\u6301\u3064\u3053\u3068\u304c\u3067\u304d\u308b\uff09\u4eba\u3005\u3092\u898b\u3064\u3051\u51fa\u3057\u3001\u5f7c\u3089\u3068\u5f37\u3044\u4fe1\u983c\u95a2\u4fc2\u3092\u7bc9\u304f\u65b9\u6cd5\u3092\u898b\u3064\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044\u3002\u4ed6\u306e\u591a\u304f\u306e\u6148\u5584\u4e8b\u696d\u3068\u540c\u69d8\u306b\u3001\u79c1\u305f\u3061\u306e\u57fa\u672c\u7684\u306a\u67a0\u7d44\u307f\u306f\u3001<a href=\"https://www.openphilanthropy.org/blog/key-questions-about-philanthropy-part-2-choosing-focus-areas-and-hiring-program-staff\"><u>\u30d5\u30a9\u30fc\u30ab\u30b9\u3059\u308b\u5206\u91ce\u3092\u6c7a\u3081\u3001\u305d\u306e\u5206\u91ce\u306b\u7279\u5316\u3057\u305f\u30b9\u30bf\u30c3\u30d5\u3092\u63a1\u7528\u3059\u308b</u></a>\u3053\u3068\u3067\u3042\u308b\u3002\u5834\u5408\u306b\u3088\u3063\u3066\u306f\u3001\u7279\u5b9a\u306e\u5206\u91ce\u306b\u7279\u5316\u3057\u305f\u4eba\u6750\u3092\u63a1\u7528\u3059\u308b\u306e\u3067\u306f\u306a\u304f\u3001\u305d\u306e\u5206\u91ce\u306b\u3058\u3063\u304f\u308a\u3068\u53d6\u308a\u7d44\u3081\u308b\u30b8\u30a7\u30cd\u30e9\u30ea\u30b9\u30c8\uff08\u5e83\u7bc4\u306a\u77e5\u8b58\u3092\u6301\u3064\u4eba\uff09\u3092\u78ba\u4fdd\u3059\u308b\u3088\u3046\u306b\u3057\u3066\u3044\u308b\u3002\u3044\u305a\u308c\u306b\u305b\u3088\u3001\u79c1\u305f\u3061\u306e\u30b9\u30bf\u30c3\u30d5\u306f\u3001\u305d\u306e\u5206\u91ce\u3067\u6700\u3082\u512a\u308c\u305f\u77e5\u8b58\u3092\u6301\u3064\u4eba\u3005\u3068\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u7bc9\u304d\u3001\u81ea\u3089\u5f37\u3044\u4fe1\u983c\u95a2\u4fc2\u3092\u7bc9\u304f\u3053\u3068\u3092\u76ee\u6307\u3057\u3066\u3044\u308b\u3002</p><p>\u305d\u306e\u52aa\u529b\u306e\u7d50\u679c\u3053\u305d\u304c\u3001<strong>\u4e26\u306f\u305a\u308c\u305f\u601d\u8003\u3068\u77e5\u8b58\u3092\u3082\u3063\u3066\u3057\u3066\u771f\u306b\u7406\u89e3\u3059\u308b\u3053\u3068\u306e\u3067\u304d\u308b\u7406\u7531\u3067\u300c\u9762\u767d\u3044\uff01\u300d\u3068\u601d\u3048\u308b\u30a2\u30a4\u30c7\u30a3\u30a2\u3092\u898b\u3064\u3051\u51fa\u3059\u80fd\u529b</strong>\u306a\u306e\u3060\u3068\u601d\u3046\u3002\u3053\u308c\u3053\u305d\u304c\u3001\u826f\u3044\u30a2\u30a4\u30c7\u30a3\u30a2\u3092\u305d\u308c\u304c\u4e16\u9593\u4e00\u822c\u304b\u3089\u826f\u3044\u3068\u8a8d\u8b58\u3055\u308c\u308b\u524d\u306b\u652f\u63f4\u3057\u3066\u3001\u300c\u30d2\u30c3\u30c8\u300d\u3055\u305b\u308b\u305f\u3081\u306e\u79d8\u8a23\u307f\u305f\u3044\u306a\u3082\u306e\u3060\u3002</p><p><strong>\u6226\u7565\u3092\u7acb\u3066\u3001\u610f\u601d\u6c7a\u5b9a\u3092\u3059\u308b\u4eba\u306e\u6570\u3092\u6700\u5c0f\u9650\u306b\u3059\u308b\u3002</strong>\u975e\u5e38\u306b\u7570\u306a\u308b\u8996\u70b9\u3092\u6301\u3063\u305f\u591a\u6570\u306e\u4eba\u304c\u59a5\u5354\u3057\u305f\u7d50\u679c\u3068\u3057\u3066\u610f\u601d\u6c7a\u5b9a\u304c\u306a\u3055\u308c\u308b\u5834\u5408\u3001\u305d\u308c\u304c<u>\u5f01\u660e\u53ef\u80fd</u>\u3067<u>\u5408\u7406\u7684\u306a</u>\u6c7a\u5b9a\u3067\u3042\u308b\u78ba\u7387\u306f\u9ad8\u3044\u304b\u3082\u3057\u308c\u306a\u3044\u304c\u3001<u>\u4e26\u306f\u305a\u308c\u3066\u4e0a\u632f\u308c\u3059\u308b</u>\u3088\u3046\u306a\u6c7a\u5b9a\u3067\u3042\u308b\u78ba\u7387\u306f\u304b\u306a\u308a\u4f4e\u3044\u3068\u601d\u308f\u308c\u308b\u3002\u63a8\u5bdf\u3059\u308b\u306b\u3001\u5f8c\u8005\u306f\u5b8c\u5168\u306b\u4f1d\u3048\u308b\u306e\u306f\u96e3\u3057\u3044\u3001\u6df1\u3044\u601d\u8003\u3068\u6587\u8108\u306b\u57fa\u3065\u3044\u305f\u72ec\u7279\u306e\u8996\u70b9\u3092\u6301\u3064\u3053\u3068\u3068\u95a2\u9023\u304c\u9ad8\u3044\u3002\u5225\u306e\u8a00\u3044\u65b9\u3092\u3059\u308c\u3070\u3001\u79c1\u306f\u500b\u4eba\u304c\u3069\u306e\u30a2\u30a4\u30c7\u30a3\u30a2\u3092\u8ffd\u6c42\u3059\u308b\u304b\u306b\u3064\u3044\u3066\u4e8b\u524d\u306b\u5408\u610f\u3092\u5f97\u308b\u4e16\u754c\u3088\u308a\u3082\u3001\u500b\u4eba\u304c\u30ef\u30af\u30ef\u30af\u3059\u308b\u3088\u3046\u306a\u30a2\u30a4\u30c7\u30a3\u30a2\u3092\u8ffd\u6c42\u3057\u3001\u3088\u308a\u591a\u304f\u306e\u4ed5\u4e8b\u3092\u3053\u306a\u3057\u4fa1\u5024\u3092\u793a\u3059\u3053\u3068\u3067\u3001\u3088\u308a\u826f\u3044\u30a2\u30a4\u30c7\u30a3\u30a2\u304c\u652f\u6301\u3055\u308c\u308b\u4e16\u754c\u3092\u671f\u5f85\u3057\u3066\u3044\u308b\u3002</p><p><a href=\"http://www.openphilanthropy.org/blog/our-grantmaking-so-far-approach-and-process\"><u>\u6b63\u5f0f\u306b\u306f</u></a>\u3001\u52a9\u6210\u91d1\u306e\u63a8\u85a6\u306b\u306f\u3001\u30ab\u30ea\u30fb\u30c4\u30ca\u3068\u79c1\u306e\u7f72\u540d\u304c\u73fe\u5728\u306f\u5fc5\u8981\u3060\u3002\u79c1\u305f\u3061\u306e\u9577\u671f\u7684\u306a\u76ee\u6a19\u306f\u3001\u305d\u308c\u305e\u308c\u306e\u6848\u4ef6\u3092\u6700\u3082\u3088\u304f\u77e5\u308b\u30b9\u30bf\u30c3\u30d5\u306b\u610f\u601d\u6c7a\u5b9a\u3092\u59d4\u306d\u308b\u3053\u3068\u3067\u3001\u305d\u308c\u305e\u308c\u306e\u554f\u984c\u306b\u95a2\u3059\u308b\u6226\u7565\u3001\u512a\u5148\u9806\u4f4d\u3001\u52a9\u6210\u91d1\u306f\u3001\u5404\u554f\u984c\u3092\u6700\u3082\u3088\u304f\u77e5\u308b\u4e00\u4eba\u306e\u4eba\u7269\u306b\u3088\u3063\u3066\u6c7a\u5b9a\u3055\u308c\u308b\u3088\u3046\u306b\u3059\u308b\u3053\u3068\u3060\u3002\u4f8b\u3048\u3070\u3001<a href=\"https://www.openphilanthropy.org/focus/us-policy/criminal-justice-reform\"><u>\u5211\u4e8b\u53f8\u6cd5\u6539\u9769</u></a>\u306f<a href=\"http://www.openphilanthropy.org/about/team/chloe-cockburn\"><u>\u30af\u30ed\u30a8\u30fb\u30b3\u30c3\u30af\u30d0\u30fc\u30f3</u></a>\u304c\u3001<a href=\"http://www.openphilanthropy.org/focus/us-policy/farm-animal-welfare\"><u>\u5bb6\u755c\u52d5\u7269\u306e\u798f\u7949\u554f\u984c</u></a>\u306f<a href=\"http://www.openphilanthropy.org/about/team/lewis-bollard\"><u>\u30eb\u30a4\u30b9\u30fb\u30dc\u30e9\u30fc\u30c9</u></a>\u306b\u3088\u3063\u3066\u6c7a\u5b9a\u3055\u308c\u308b\u3053\u3068\u3092\u76ee\u6307\u3057\u3066\u3044\u308b\u3002\u4e0a\u8a18\u306e\u3088\u3046\u306b\u3001\u30b9\u30bf\u30c3\u30d5\u306f\u3001\u5206\u91ce\u306e\u5c02\u9580\u5bb6\u3092\u306f\u3058\u3081\u3068\u3057\u3066\u69d8\u3005\u306a\u4eba\u304b\u3089\u591a\u304f\u306e\u610f\u898b\u3092\u6c42\u3081\u308b\u3068\u306f\u601d\u3046\u304c\u3001\u305d\u306e\u610f\u898b\u3092\u3069\u306e\u3088\u3046\u306b\u8003\u616e\u3059\u308b\u304b\u306f\u3001\u6700\u7d42\u7684\u306b\u306f\u30b9\u30bf\u30c3\u30d5\u306e\u5224\u65ad\u306b\u59d4\u306d\u3066\u3044\u308b\u3002</p><p>\u305d\u306e\u305f\u3081\u306b\u306f\u3001\u30b9\u30bf\u30c3\u30d5\u3068\u4fe1\u983c\u95a2\u4fc2\u3092\u7bc9\u304d\u3001\u7dad\u6301\u3059\u308b\u3053\u3068\u304c\u5fc5\u8981\u3067\u3042\u308a\u3001\u305d\u308c\u306b\u306f\u3001\u30b9\u30bf\u30c3\u30d5\u306b\u591a\u304f\u306e\u8cea\u554f\u3092\u3057\u3001\u5f7c\u3089\u306e\u8003\u3048\u3092\u8a73\u7d30\u306b\u8aac\u660e\u3057\u3066\u3082\u3089\u3044\u3001\u91cd\u8981\u306a\u610f\u898b\u306e\u76f8\u9055\u306b\u3064\u3044\u3066\u306f\u3058\u3063\u304f\u308a\u8a71\u3057\u5408\u3046\u3053\u3068\u304c\u5fc5\u8981\u306b\u306a\u308b\u3002\u305d\u3046\u306f\u3044\u3063\u3066\u3082\u3001\u8003\u3048\u3066\u3044\u308b\u3053\u3068\u3092<u>\u5168\u3066</u>\u8aac\u660e\u3059\u308b\u3088\u3046\u306b\u8981\u6c42\u3059\u308b\u3053\u3068\u306f\u6c7a\u3057\u3066\u3057\u306a\u3044\u3002\u305d\u306e\u304b\u308f\u308a\u3001\u79c1\u305f\u3061\u304c\u6700\u3082\u6ce8\u76ee\u3059\u308b\u3001\u3042\u308b\u3044\u306f\u7591\u554f\u306b\u601d\u3046\u8ad6\u70b9\u3092\u6398\u308a\u4e0b\u3052\u3066\u3044\u304f\u3088\u3046\u306b\u3057\u3066\u3044\u308b\u3002\u4fe1\u983c\u95a2\u4fc2\u3092\u7bc9\u304d\u306a\u304c\u3089\u3001\u6642\u304c\u7d4c\u3064\u306b\u3064\u308c\u3066\u3001\u95a2\u4e0e\u306e\u5ea6\u5408\u3044\u3084\u7cbe\u67fb\u306e\u30ec\u30d9\u30eb\u3092\u4e0b\u3052\u3066\u3044\u304f\u3053\u3068\u3092\u76ee\u6307\u3057\u3066\u3044\u308b\u3002</p><p>\u3053\u306e\u57fa\u672c\u7684\u306a\u30a2\u30d7\u30ed\u30fc\u30c1\u306b\u3064\u3044\u3066\u306f\u3001\u3044\u3064\u304b\u307e\u305f\u8a73\u3057\u304f\u66f8\u304d\u305f\u3044\u3068\u601d\u3046\u3002</p><p><strong>\u53ef\u80fd\u3067\u3042\u308c\u3070\u3001\u79c1\u305f\u3061\u306b\u30a2\u30d4\u30fc\u30eb\u3059\u308b\u305f\u3081\u306b\u8a08\u753b\u3092\u5b9f\u884c\u3059\u308b\u5e73\u51e1\u306a\u4eba\u3084\u7d44\u7e54\u3092\u652f\u63f4\u3059\u308b\u306e\u3067\u306f\u306a\u304f\u3001\u5b8c\u5168\u306b\u88c1\u91cf\u6a29\u3092\u4e0e\u3048\u305f\uff08\u307e\u305f\u306f\u6700\u4f4e\u9650\u306e\u5236\u7d04\u306e\u307f\u3064\u3044\u305f\uff09\u5f37\u529b\u306a\u30ea\u30fc\u30c0\u30fc\u30b7\u30c3\u30d7\u3092\u652f\u63f4\u3059\u308b</strong>\u3002\u3053\u306e\u539f\u5247\u306e\u4e8b\u4f8b\u306f\u3001\u524d\u306e\u539f\u5247\u306e\u4e8b\u4f8b\u306e\u5ef6\u9577\u7dda\u4e0a\u306b\u3042\u308a\u3001\u3044\u3064\u304b\u8a73\u3057\u304f\u66f8\u304d\u305f\u3044\u3068\u601d\u3063\u3066\u3044\u308b\u3082\u306e\u3068\u540c\u3058\u57fa\u672c\u7684\u306a\u30a2\u30d7\u30ed\u30fc\u30c1 \u2013 \u4e3b\u306b\u306f\u610f\u601d\u6c7a\u5b9a\u306e\u6a29\u9650\u3092\u6700\u3082\u6df1\u3044\u7d4c\u9a13\u3068\u7406\u89e3\u3092\u6301\u3064\u4eba\u3005\u306b\u79fb\u884c\u3055\u305b\u308b\u3053\u3068 \u2013 \u306b\u9069\u3057\u3066\u3044\u308b\u3002</p><p><strong>\u305d\u306e\u5206\u91ce\u306e\u4ed6\u306e\u8cc7\u91d1\u63d0\u4f9b\u8005\u306e\u3053\u3068\u3092\u7406\u89e3\u3057\u3001\u5f7c\u3089\u306b\u5408\u3046\u3068\u601d\u308f\u308c\u308b\u3082\u306e\u3078\u306e\u8cc7\u91d1\u63d0\u4f9b\u3092\u9060\u616e\u3059\u308b</strong>\u3002\u3053\u308c\u306f\u3001\u524d\u8ff0\u306e\u300c\u591a\u5927\u306a\u52b4\u529b\u3092\u8cbb\u3084\u3059\u304b\uff08\u4e2d\u7565\uff09\u6df1\u304f\u7406\u89e3\u3059\u308b\u3053\u3068\u3092\u76ee\u6307\u3059\u300d\u306e\u4e00\u3064\u306e\u5074\u9762\u3067\u3001\u7279\u8a18\u3059\u3079\u304d\u4e8b\u9805\u3067\u3042\u308b\u3068\u601d\u3046\u3002\u4ed6\u306e\u8cc7\u91d1\u63d0\u4f9b\u8005\u306e\u7406\u5ff5\u306b\u30d5\u30a3\u30c3\u30c8\u3059\u308b\u3082\u306e\u306b\u79c1\u305f\u3061\u304c\u8cc7\u91d1\u3092\u63d0\u4f9b\u3059\u308b\u5834\u5408\u3001\uff08\uff11\uff09\u4ed6\u306e\u8cc7\u91d1\u63d0\u4f9b\u8005\u3088\u308a\u5c11\u3057\u65e9\u304f\u52d5\u3044\u3066\u3044\u308b\u3060\u3051\u3067\u3001\u76f8\u5bfe\u7684\u306b\u30a4\u30f3\u30d1\u30af\u30c8\u304c\u5c0f\u3055\u3044\u3001\u307e\u305f\u306f\uff08\uff12\uff09\u4ed6\u306e\u8cc7\u91d1\u63d0\u4f9b\u8005\u304c\u6b63\u5f53\u306a\u7406\u7531\u3067\u8cc7\u91d1\u63d0\u4f9b\u3092\u8f9e\u9000\u3057\u305f\u3082\u306e\u306b\u8cc7\u91d1\u63d0\u4f9b\u3057\u3066\u3044\u308b\u53ef\u80fd\u6027\u304c\u9ad8\u3044\u3002\u305d\u306e\u5206\u91ce\u306e\u4ed6\u306e\u8cc7\u91d1\u63d0\u4f9b\u8005\u306e\u3053\u3068\u3092\u3088\u304f\u7406\u89e3\u3059\u308b\u3053\u3068\u3001\u305d\u3057\u3066\u7406\u60f3\u7684\u306b\u306f\u5f7c\u3089\u3068\u826f\u3044\u95a2\u4fc2\u3092\u7bc9\u304f\u3053\u3068\u304c\u975e\u5e38\u306b\u91cd\u8981\u3067\u3042\u308b\u3068\u601d\u308f\u308c\u308b\u3002</p><p><strong>\u898b\u904e\u3054\u3055\u308c\u308b\u53ef\u80fd\u6027\u304c\u4f4e\u3044\u3068\uff08\u7d4c\u9a13\u5247\u304b\u3089\uff09\u601d\u308f\u308c\u308b\u5bc4\u4ed8\u306e\u6a5f\u4f1a\u306b\u306f\u6ce8\u610f\u3059\u308b</strong>\u3002\u3053\u306e\u539f\u5247\u306f\u4e3b\u306b\u524d\u306e\u539f\u5247\u306e\u5ef6\u9577\u7dda\u4e0a\u306b\u3042\u308b\u3002\u3042\u308b\u30a2\u30a4\u30c7\u30a3\u30a2\u304c\u3001\u5f93\u6765\u306e\u5e38\u8b58\u3084\u5c02\u9580\u5bb6\u306e\u7dcf\u610f\u3068\u3088\u304f\u4e00\u81f4\u3059\u308b\u3088\u3046\u306b\u898b\u3048\u308b\u5834\u5408\u3001\u307e\u305f\u306f\u3001\u8cc7\u91d1\u529b\u306e\u3042\u308b\u7279\u5b9a\u306e\u5229\u76ca\u56e3\u4f53\u306b\u5f79\u7acb\u3064\u3068\u601d\u308f\u308c\u308b\u5834\u5408\u3001\u306a\u305c\u4ed6\u306e\u8cc7\u91d1\u63d0\u4f9b\u8005\u304b\u3089\u306e\u652f\u63f4\u3092\u307e\u3060\u96c6\u3081\u3089\u308c\u3066\u3044\u306a\u3044\u306e\u304b\u3001\u306a\u305c\u9577\u304f\u8cc7\u91d1\u4e0d\u8db3\u306e\u307e\u307e\u306a\u306e\u304b\u3001\u3068\u3044\u3046\u7591\u554f\u304c\u751f\u3058\u308b\u3002</p><p><strong>\u7d50\u8ad6</strong>\u3002\u79c1\u306e\u8003\u3048\u308b\u7406\u60f3\u7684\u306a\u5bc4\u4ed8\u306e\u6a5f\u4f1a\u3068\u306f\u3001\u6b21\u306e\u3088\u3046\u306a\u3082\u306e\u3060\u3002\u300cX\u3068\u3044\u3046\u6d3b\u52d5\u306b\u5bfe\u3057\u3066\u6df1\u3044\u77e5\u8b58\u3092\u6301\u3064\u4fe1\u983c\u3067\u304d\u308b\u30b9\u30bf\u30c3\u30d5\u304c\u3001\u4ed6\u306e\u4eba\u306b\u306f\u3042\u307e\u308a\u8a8d\u3081\u3089\u308c\u3066\u3044\u306a\u3044\u30e6\u30cb\u30fc\u30af\u306a\u8996\u70b9\u3068\u30a2\u30d7\u30ed\u30fc\u30c1\u3092\u6301\u3064Y\u3068\u3044\u3046\u4eba\u7269\u306e\u6d3b\u52d5\u3092\u3001\u307b\u3068\u3093\u3069\u5236\u7d04\u3092\u8a2d\u3051\u305a\u306b\u652f\u63f4\u3057\u305f\u3044\u3068\u80f8\u3092\u8e8d\u3089\u305b\u3066\u3044\u308b\u3002\u3053\u306e\u30a2\u30d7\u30ed\u30fc\u30c1\u304c\u5de8\u5927\u306a\u30a4\u30f3\u30d1\u30af\u30c8\u3092\u4e0e\u3048\u308b\u3053\u3068\u306f\u3001\u305f\u3068\u3048<u>\u898b\u8fbc\u307f</u>\u304c\u306a\u3044\u3088\u3046\u306b\u898b\u3048\u305f\u3068\u3057\u3066\u3082\u3001\u305d\u306e\u30b9\u30bf\u30c3\u30d5\u306b\u306f\u5bb9\u6613\u306b\u60f3\u50cf\u3067\u304d\u308b\u3002\u305d\u306e\u30a2\u30a4\u30c7\u30a3\u30a2\u3092\u521d\u3081\u3066\u805e\u3044\u305f\u79c1\u306f\u3001\u610f\u5916\u3060\u3068\u3044\u3046\u5370\u8c61\u3092\u899a\u3048\u3001\u304a\u305d\u3089\u304f\u5947\u5999\u306b\u601d\u3048\u308b\u304b\u3001\u76f4\u611f\u306b\u53cd\u3057\u3066\u3044\u308b\u304b\u3001\u307e\u305f\u306f\u9b45\u529b\u7684\u3067\u306a\u3044\u3088\u3046\u306b\u6620\u308b\u304b\u3082\u3057\u308c\u306a\u3044\u3002\u3057\u304b\u3057\u305d\u306e\u30b9\u30bf\u30c3\u30d5\u306b\u3001\u8003\u3048\u3089\u308c\u308b\u5931\u6557\u306e\u30d1\u30bf\u30fc\u30f3\u3084\u61f8\u5ff5\u4e8b\u9805\u3001\u305d\u306e\u30a2\u30a4\u30c7\u30a2\u306e\u6839\u62e0\u3068\u3057\u3066\u660e\u3089\u304b\u306b\u4e0d\u8db3\u3057\u3066\u3044\u308b\u90e8\u5206\u306b\u3064\u3044\u3066\u8cea\u554f\u3059\u308b\u3068\u3001\u79c1\u304c\u8cea\u554f\u3057\u305f\u3053\u3068\u306b\u3064\u3044\u3066\u306f\u3059\u3067\u306b\u77e5\u308a\u5c3d\u304f\u3057\u3066\u3044\u3066\u3001\u3088\u304f\u8003\u3048\u3089\u308c\u3066\u3044\u308b\u3088\u3046\u306b\u601d\u308f\u308c\u308b\u3002\u300d\u79c1\u306b\u3068\u3063\u3066\u306f\u3001\u3053\u306e\u57fa\u672c\u7684\u306a\u4ed5\u7d44\u307f\u3053\u305d\u304c\u4ed6\u306e\u4eba\u306f\u30b5\u30dd\u30fc\u30c8\u3057\u306a\u3044\u91cd\u8981\u306a\u4ed5\u4e8b\u3092\u30b5\u30dd\u30fc\u30c8\u3057\u3001\u5c06\u6765\u7684\u306b\u4eba\u3005\u306e\u8003\u3048\u65b9\u3092\u5909\u3048\u3001\u300c\u30d2\u30c3\u30c8\u300d\u3092\u5f97\u308b\u78ba\u7387\u3092\u6700\u5927\u5316\u3059\u308b\u3082\u306e\u3060\u3002</p><h2>\u30d2\u30c3\u30c8\u30d9\u30fc\u30b9\u30a2\u30d7\u30ed\u30fc\u30c1\u3068\u6d3b\u52d5\u306b\u95a2\u3057\u3066\u30aa\u30fc\u30d7\u30f3\u3067\u3042\u308b\u3053\u3068\u306e\u4e21\u7acb</h2><p>\u79c1\u305f\u3061\u306e<a href=\"https://www.openphilanthropy.org/what-open-means-us\"><u>\u57fa\u672c\u7406\u5ff5</u></a>\u306e\u4e00\u3064\u306f\u3001\u81ea\u5206\u9054\u306e\u6d3b\u52d5\u306b\u3064\u3044\u3066\u30aa\u30fc\u30d7\u30f3\u3067\u3042\u308b\u3053\u3068\u3060\u3002\u305d\u306e\u7406\u7531\u306f\u3044\u304f\u3064\u304b\u3042\u308b</p><ul><li>\u79c1\u305f\u3061\u304c\u5b66\u3093\u3060\u3053\u3068\u3092\u6d3b\u7528\u3057\u3066\u3082\u3089\u3044\u3001\u3088\u308a\u77e5\u8b58\u3092\u6df1\u3081\u3066\u6b32\u3057\u3044</li><li>\u79c1\u305f\u3061\u306e\u8003\u3048\u65b9\u3092\u7406\u89e3\u3057\u3001\u305d\u308c\u306b\u7591\u554f\u3092\u6301\u3061\u3001\u305d\u3057\u3066\u6279\u8a55\u3057\u3066\u6b32\u3057\u3044</li><li>\u826f\u3044\u5bc4\u4ed8\u3092\u3059\u308b\u65b9\u6cd5\u306b\u3064\u3044\u3066\u306e\u9ad8\u5ea6\u306a\u8a0e\u8ad6\u304c\u516c\u306e\u5834\u3067\u3082\u3063\u3068\u8d77\u3053\u3063\u3066\u6b32\u3057\u3044</li></ul><p>\u4e0a\u8ff0\u306e\u901a\u308a\u3001\u79c1\u305f\u3061\u306f\u7b2c\u4e09\u8005\u306b\u5bfe\u3057\u3066\u8aac\u5f97\u529b\u306e\u3042\u308b\u65b9\u6cd5\u3067\u6b63\u5f53\u5316\u3059\u308b\u3053\u3068\u304c\u96e3\u3057\u3044\u3053\u3068\u3092\u591a\u304f\u884c\u304a\u3046\u3068\u3057\u3066\u304a\u308a\u3001\u3053\u306e\u4e8b\u5b9f\u3068\u3053\u308c\u3089\u306e\u76ee\u6a19\u306e\u9593\u306b\u306f\u3042\u308b\u7a2e\u306e\u7dca\u5f35\u304c\u3042\u308b\u3002\u79c1\u305f\u3061\u306e\u8a18\u4e8b\u306f\u3057\u3070\u3057\u3070\u3001\u7db2\u7f85\u7684\u3067\u306a\u304b\u3063\u305f\u308a\u3001\u8aac\u5f97\u529b\u304c\u5f37\u304f\u306a\u304b\u3063\u305f\u308a\u3057\u3066\u3001\u8aad\u8005\u306b\u79c1\u305f\u3061\u306e\u5224\u65ad\u304c\u6b63\u3057\u304b\u3063\u305f\u304b\u3069\u3046\u304b\u8ff7\u3044\u3092\u4e0e\u3048\u3066\u3057\u307e\u3046\u3053\u3068\u3082\u3042\u308b\u3068\u601d\u3046\u3002</p><p>\u3057\u304b\u3057\u3001\u30aa\u30fc\u30d7\u30f3\u3067\u3042\u308b\u3053\u3068\u3068\u300c\u30d2\u30c3\u30c8\u30d9\u30fc\u30b9\u300d\u30a2\u30d7\u30ed\u30fc\u30c1\u3092\u53d6\u308b\u3053\u3068\u306e\u4e21\u7acb\u306f\u3001\u304b\u306a\u308a\u306e\u7a0b\u5ea6\u53ef\u80fd\u3060\u3068\u601d\u3046\u3002\u4e00\u3064\u4e00\u3064\u306e\u6c7a\u65ad\u306b\u95a2\u3057\u3066\u3001\u8aad\u8005\u304c\u7406\u89e3\u3067\u304d\u308b\u3068\u3053\u308d\u307e\u3067\u3001\u79c1\u305f\u3061\u306e\u8003\u3048\u65b9\u3092\u5171\u6709\u3059\u308b\u3053\u3068\u3092\u76ee\u6307\u3059\u3002\u4f8b\u3048\u3070\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u3082\u306e\u3060\u3002</p><ul><li>\u79c1\u305f\u3061\u304c\u8003\u3048\u308b\u4e3b\u306a\u30e1\u30ea\u30c3\u30c8\u3068\u30c7\u30e1\u30ea\u30c3\u30c8</li><li>\u79c1\u305f\u3061\u306e\u898b\u89e3\u306e\u9375\u3068\u306a\u308b\u524d\u63d0\u6761\u4ef6</li><li>\u79c1\u305f\u3061\u304c\u3069\u306e\u3088\u3046\u306a\u30d7\u30ed\u30bb\u30b9\u3092\u7d4c\u3066\u304d\u305f\u304b</li><li>\u6587\u7ae0\u3060\u3051\u3067\u306f\u5224\u65ad\u304c\u3064\u304b\u306a\u3044\u5834\u5408\u3067\u3082\u3001\u8aad\u8005\u304c\u81ea\u4fe1\u3092\u6301\u3063\u3066\u79c1\u305f\u3061\u306e\u8003\u3048\u65b9\u306b\u8cdb\u540c\u30fb\u53cd\u5bfe\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u308b\u306b\u306f\u3001\u3069\u306e\u3088\u3046\u306a\u3053\u3068\u3092\u3059\u308c\u3070\u3088\u3044\u304b</li></ul><p>\u3044\u304f\u3064\u304b\u306e\u4f8b\u3068\u3057\u3066</p><ul><li><a href=\"https://www.openphilanthropy.org/research/cause-reports/ai-risk#Background_and_process\"><u>\u9ad8\u5ea6\u306a\u4eba\u5de5\u77e5\u80fd\u304c\u3082\u305f\u3089\u3059\u6f5c\u5728\u7684\u306a\u30ea\u30b9\u30af\u306b\u95a2\u3059\u308b\u8a18\u4e8b</u></a>\u3067\u306f\u3001\u79c1\u305f\u3061\u304c\u975e\u5e38\u306b\u591a\u304f\u306e\u3053\u3068\u3092\u8003\u3048\u305f\u30c8\u30d4\u30c3\u30af\u3092\u6271\u3063\u3066\u304a\u308a\u3001\u79c1\u305f\u3061\u306e\u898b\u89e3\u3092\u66f8\u304d\u5c3d\u304f\u3059\u3053\u3068\u306f\u3067\u304d\u306a\u3044\u3002\u300c\u80cc\u666f\u3068\u30d7\u30ed\u30bb\u30b9\u300d\u3067\u306f\u3001\u79c1\u305f\u3061\u304c\u3069\u3046\u3044\u3063\u305f\u601d\u60f3\u306e\u3082\u3068\u3053\u306e\u3088\u3046\u306a\u898b\u89e3\u306b\u305f\u3069\u308a\u7740\u304d\u3001\u307e\u305f\u3001\u79c1\u305f\u3061\u306e\u59ff\u52e2\u3092\u7406\u89e3\u3057\u8a55\u4fa1\u3059\u308b\u305f\u3081\u306b\u306f\u3055\u3089\u306b\u3069\u306e\u3088\u3046\u306a\u8abf\u67fb\u3092\u884c\u3048\u3070\u3088\u3044\u306e\u304b\u3092\u8aac\u660e\u3057\u3066\u3044\u308b\u3002</li><li><a href=\"https://www.openphilanthropy.org/focus/us-policy/criminal-justice-reform\"><u>\u5211\u4e8b\u53f8\u6cd5\u6539\u9769</u></a>\u306b\u95a2\u3059\u308b\u79c1\u305f\u3061\u306e\u6d3b\u52d5\u306f\u3001\u9577\u5e74\u306e\u4f1a\u8a71\uff08\u305d\u306e\u591a\u304f\u304c\u6587\u66f8\u306b\u3057\u3066\u5171\u6709\u3059\u308b\u306e\u306f\u73fe\u5b9f\u7684\u3067\u306f\u306a\u3044\u3082\u306e\uff09\u3084\u4eba\u9593\u95a2\u4fc2\u3001\u5206\u91ce\u5185\u306e\u95a2\u9023\u8cc7\u6599\u3092\u8aad\u3080\u3053\u3068\u306b\u3088\u3063\u3066\u5f97\u305f<a href=\"https://www.openphilanthropy.org/about/team/chloe-cockburn\"><u>\u30af\u30ed\u30a8</u></a>\u306e\u898b\u89e3\u306b\u983c\u308b\u3068\u3053\u308d\u304c\u5927\u304d\u3044\u3002\u79c1\u305f\u3061\u306f\u3053\u3046\u3057\u305f\u8cc7\u6599\u3092\u3059\u3079\u3066\u8a18\u9332\u3059\u308b\u304b\u308f\u308a\u306b\u3001<a href=\"https://www.openphilanthropy.org/blog/process-hiring-our-first-cause-specific-program-officer\"><u>\u30af\u30ed\u30a8\u304c\u3069\u306e\u3088\u3046\u306a\u5f79\u5272\u3092\u62c5\u3063\u3066\u3044\u3066\u3001\u306a\u305c\u79c1\u305f\u3061\u304c\u5f7c\u5973\u3092\u3053\u306e\u5f79\u5272\u306b\u9078\u3093\u3060\u306e\u304b</u></a>\u3092\u660e\u78ba\u306b\u8a18\u8f09\u3057\u3066\u3044\u308b\u3002</li></ul><p>\u3053\u306e\u3088\u3046\u306a\u30aa\u30fc\u30d7\u30f3\u306a\u6d3b\u52d5\u306f\u3001\u305d\u308c\u81ea\u4f53\u3067\u306f\u4e0d\u5b8c\u5168\u3067\u3001\u8aac\u5f97\u529b\u304c\u4e0d\u5341\u5206\u3067\u3082\u3001\u4e0a\u8a18\u306e\u76ee\u6a19\u306e\u89b3\u70b9\u3067\u306f\u3001\u591a\u304f\u3092\u9054\u6210\u3067\u304d\u308b\u3068\u4fe1\u3058\u3066\u3044\u308b\u3002</p><p>\u4e00\u822c\u7684\u306b\u3001\u3053\u306e\u8b70\u8ad6\u306f\u3001\u306a\u305c\u30aa\u30fc\u30d7\u30f3\u30fb\u30d5\u30a3\u30e9\u30f3\u30bd\u30ed\u30d4\u30fc\u304c\u500b\u4eba\u306e\u5bc4\u4ed8\u8005\u3067\u306f\u306a\u304f\u3001\u5927\u53e3\u306e\u5bc4\u4ed8\u8005\uff08\u3069\u3053\u306b\u5bc4\u4ed8\u3092\u3059\u308b\u304b\u3068\u3044\u3046\u554f\u984c\u306b\u3058\u3063\u304f\u308a\u95a2\u308f\u308b\u6642\u9593\u3092\u6301\u3064\u4eba\uff09\u3092\u4e3b\u306b\u5bfe\u8c61\u3068\u3057\u3066\u3044\u308b\u306e\u304b\u3092\u660e\u78ba\u306b\u3059\u308b\u306e\u306b\u5f79\u7acb\u3064\u304b\u3082\u3057\u308c\u306a\u3044\u3002\u3082\u3061\u308d\u3093\u3001\u79c1\u305f\u3061\u306e\u898b\u89e3\u304c\u666e\u901a\u3067\u306a\u304f\u3066\u6b63\u5f53\u306a\u6839\u62e0\u304c\u306a\u3044\u3088\u3046\u306a\u5834\u5408\u306b\u3001\u500b\u4eba\u306e\u5bc4\u4ed8\u8005\u304c\u79c1\u305f\u3061\u3092\u4fe1\u983c\u3057\u3001\u652f\u63f4\u3059\u308b\u3068\u3044\u3046\u9078\u629e\u80a2\u306f\u3042\u308b\u3002\u3057\u304b\u3057\u3001\u30aa\u30fc\u30d7\u30f3\u30fb\u30d5\u30a3\u30e9\u30f3\u30bd\u30ed\u30d4\u30fc\u3092\u4fe1\u983c\u3057\u3066\u3044\u306a\u3044\u4eba\u306b\u3068\u3063\u3066\u3001\u79c1\u305f\u3061\u304c\u66f8\u304f\u8a18\u4e8b\u306f\uff08\u304a\u305d\u3089\u304f&nbsp;<a href=\"http://www.givewell.org/\"><u>GiveWell</u></a> \u306e\u8a18\u4e8b\u3068\u306f\u7570\u306a\u308a\uff09\u79c1\u305f\u3061\u306e\u8a00\u8449\u3092\u4fe1\u3058\u308b\u306b\u8db3\u308b\u7406\u7531\u3092\u5e38\u306b\u8aac\u660e\u3067\u304d\u308b\u3068\u306f\u9650\u3089\u306a\u3044\u3002</p><h2>\u300c\u30d2\u30c3\u30c8\u30d9\u30fc\u30b9\u7cbe\u795e\u300dvs. \u300c\u50b2\u6162\u3055\u300d</h2><p>\u3053\u308c\u307e\u3067\u8ff0\u3079\u3066\u304d\u305f\u3088\u3046\u306b\u3001\u300c\u30d2\u30c3\u30c8\u30d9\u30fc\u30b9\u306e\u5bc4\u4ed8\u300d\u306f\u4e0d\u5341\u5206\u306a\u8abf\u67fb\u3084\u8003\u5bdf\u306b\u57fa\u3065\u3044\u305f\u81ea\u4fe1\u904e\u5270\u306a\u898b\u65b9\u3092\u3057\u3066\u3044\u308b\u3068\u8868\u9762\u7684\u306b\u898b\u3048\u308b\u5074\u9762\u304c\u3042\u308b\uff08\u305d\u3057\u3066\u3001\u5b9f\u969b\u306b\u305d\u3046\u306a\u3063\u3066\u3057\u307e\u3046\u30ea\u30b9\u30af\u3082\u3042\u308b\uff09\u3002\u79c1\u306f\u3001\u3053\u306e\u6027\u8cea\u3092\u8868\u3059\u7c21\u5358\u306a\u8868\u73fe\u3068\u3057\u3066\u300c\u50b2\u6162\u3055\u300d\u3092\u4f7f\u3063\u3066\u3044\u308b\u3002</p><p>\u3057\u304b\u3057\u3001\u300c\u30d2\u30c3\u30c8\u30d9\u30fc\u30b9\u4e3b\u7fa9\u300d\u3068\u300c\u50b2\u6162\u3055\u300d\u306e\uff12\u3064\u306e\u9593\u306b\u306f\u76ee\u306b\u898b\u3048\u308b\u91cd\u8981\u306a\u9055\u3044\u304c\u3042\u308b\u3068\u601d\u3046\u3002\u300c\u30d2\u30c3\u30c8\u30d9\u30fc\u30b9\u4e3b\u7fa9\u300d\u306f\u3001\u5f37\u529b\u306a\u8a3c\u62e0\u3084\u5c02\u9580\u5bb6\u306e\u540c\u610f\u306e\u88cf\u4ed8\u3051\u304c\u306a\u3044\u3001\u7269\u8b70\u3092\u304b\u3082\u3059\u3088\u3046\u306a\u30a2\u30a4\u30c7\u30a3\u30a2\u306b\u591a\u5927\u306a\u30ea\u30bd\u30fc\u30b9\u3092\u6295\u5165\u3059\u308b\u3068\u3044\u3063\u305f\u3001\u4e00\u822c\u7684\u306b\u50b2\u6162\u3055\u3068\u7d50\u3073\u4ed8\u3051\u3089\u308c\u3066\u3082\u304a\u304b\u3057\u304f\u306a\u3044\u884c\u52d5\u3092\u5408\u7406\u7684\u306b\u6b63\u5f53\u5316\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u304c\u3001\u4ed6\u306e\u884c\u52d5\u306b\u3082\u3053\u306e\u3053\u3068\u304c\u5f53\u3066\u306f\u307e\u308b\u3068\u306f\u601d\u308f\u306a\u3044\u3002</p><p>\u91cd\u8981\u306a\u9055\u3044\u3092\u793a\u3059\u305f\u3081\u306b\u3001\u3044\u304f\u3064\u304b\u5177\u4f53\u4f8b\u3092\u6319\u3052\u3066\u307f\u308b\u3002</p><p><strong>\u4e0d\u78ba\u5b9f\u6027\u3092\u4f1d\u3048\u308b</strong>\u3002\u50b2\u6162\u3055\u3068\u306f\u3001\u81ea\u5206\u304c\u6b63\u3057\u3044\u3068\u78ba\u4fe1\u3057\u3001\u305d\u308c\u306b\u5f93\u3063\u3066\u30b3\u30df\u30e5\u30cb\u30b1\u30fc\u30b7\u30e7\u30f3\u3092\u53d6\u308b\u3053\u3068\u3060\u3068\u601d\u3046\u3002\u305d\u306e\u305f\u3081\u3001\u81ea\u5206\u306e\u597d\u304d\u306a\u6d3b\u52d5\u3084\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u304c\u6700\u3082\u512a\u308c\u305f\u3082\u306e\u306b\u9055\u3044\u306a\u3044\u3068\u307b\u306e\u3081\u304b\u3059\u4eba\u3001\u305d\u306e\u4e2d\u3067\u3082\u7279\u306b\u3001\u4ed6\u306e\u4eba\u304c\u7570\u306a\u3063\u305f\u554f\u984c\u89e3\u6c7a\u306e\u305f\u3081\u306b\u884c\u3046\u6d3b\u52d5\u3092\u91cd\u8981\u3067\u306a\u3044\u3068\u307b\u306e\u3081\u304b\u3059\u4eba\u306f\u3001\u50b2\u6162\u3067\u3042\u308b\u3068\u79c1\u306f\u601d\u3046\u3002\u305d\u308c\u306b\u5bfe\u3057\u3066\u3001\u30d2\u30c3\u30c8\u30d9\u30fc\u30b9\u4e3b\u7fa9\u306f\u3001\u30a2\u30a4\u30c7\u30a3\u30a2\u306b<u>\u30ef\u30af\u30ef\u30af</u>\u3057\u306a\u304c\u3089\u3082\u3001\u305d\u306e\u30a2\u30a4\u30c7\u30a3\u30a2\u306b<u>\u4e0d\u78ba\u304b\u3067\u3042\u308b</u>\u3053\u3068\u306e\u3069\u3061\u3089\u306b\u3082\u77db\u76fe\u3057\u306a\u3044\u3002\u79c1\u305f\u3061\u306f\u3001\u81ea\u5206\u306e\u6d3b\u52d5\u306b\u5bfe\u3059\u308b\u7591\u554f\u3084\u4e0d\u78ba\u5b9f\u6027\u3092\u306f\u3063\u304d\u308a\u3068\u4f1d\u3048\u3001\u81ea\u5206\u305f\u3061\u306e\u30a2\u30a4\u30c7\u30a3\u30a2\u306b\u30ea\u30bd\u30fc\u30b9\u3092\u6ce8\u304e\u8fbc\u3093\u3067\u306f\u3044\u3066\u3082\u3001\u9593\u9055\u3063\u3066\u3044\u308b\u3053\u3068\u3082\u305f\u304f\u3055\u3093\u3042\u308b\u3068\u8a8d\u3081\u308b\u3053\u3068\u3092\u76ee\u6a19\u306b\u3057\u3066\u3044\u308b\u3002</p><p><strong>\u5fc5\u6b7b\u306b\u8a73\u3057\u304f\u77e5\u308d\u3046\u3068\u3059\u308b</strong>\u3002\u50b2\u6162\u3055\u306f\u3001\u9650\u3089\u308c\u305f\u60c5\u5831\u3092\u3082\u3068\u306b\u7d50\u8ad6\u3092\u6025\u3050\u3053\u3068\u3068\u7d50\u3073\u3064\u3044\u3066\u3044\u308b\u3068\u601d\u3046\u3002\u300c\u30d2\u30c3\u30c8\u30d9\u30fc\u30b9\u4e3b\u7fa9\u300d\u3092\u3046\u307e\u304f\u5b9f\u884c\u3059\u308b\u306b\u306f\u3001\u81ea\u5206\u306e\u30a2\u30a4\u30c7\u30a3\u30a2\u306b\u5bfe\u3059\u308b\u8cdb\u5426\u306e\u4e21\u65b9\u3092\u78ba\u5b9f\u306b\u7406\u89e3\u3059\u308b\u305f\u3081\u306b\u3001\u76f8\u5f53\u306a\u52aa\u529b\u3092\u3059\u308b\u3053\u3068\u3060\u3068\u8003\u3048\u308b\u3002\u3042\u3089\u3086\u308b\u5c64\u306e\u4eba\u5168\u3066\u304c\u7d0d\u5f97\u306e\u3044\u304f\u3088\u3046\u306a\u7b54\u3048\u3092\u51fa\u3059\u3053\u3068\u306f\u3067\u304d\u306a\u3044\u3060\u308d\u3046\u304c\u3001\u81ea\u5206\u9054\u306e\u6d3b\u52d5\u306b\u5bfe\u3059\u308b\u7591\u554f\u3084\u7570\u8ad6\u306b\u3064\u3044\u3066\u771f\u5263\u306b\u8003\u3048\u308b\u3053\u3068\u3092\u5fd7\u3057\u3066\u3044\u308b\u3002</p><p><strong>\u95a2\u308f\u308b\u76f8\u624b\u3092\u5c0a\u91cd\u3057\u3001\u4eba\u3092\u9a19\u3059\u3053\u3068\u3084\u5f37\u8981\u3059\u308b\u306a\u3069\u306e\u5e38\u8b58\u7684\u306a\u502b\u7406\u89b3\u306b\u53cd\u3057\u305f\u884c\u52d5\u3092\u907f\u3051\u308b\u3002</strong>\u79c1\u306e\u8003\u3048\u3067\u306f\u3001\u50b2\u6162\u3055\u304c\u6700\u3082\u6709\u5bb3\u306a\u306e\u306f\u3001\u300c\u76ee\u7684\u306f\u624b\u6bb5\u3092\u6b63\u5f53\u5316\u3059\u308b\u300d\u3068\u3044\u3046\u601d\u8003\u3092\u4f34\u3046\u5834\u5408\u3060\u3002\u9006\u5f35\u308a\u3057\u305f\u30a2\u30a4\u30c7\u30a3\u30a2\u3092\u78ba\u4fe1\u3059\u308b\u3042\u307e\u308a\u3001\u5e38\u8b58\u7684\u306a\u502b\u7406\u3092\u7834\u3063\u3066\u3082\uff08\u6700\u60aa\u306e\u5834\u5408\u306f\u66b4\u529b\u306b\u3082\u983c\u3063\u3066\u3082\uff09\u69cb\u308f\u306a\u3044\u3068\u601d\u3046\u4eba\u306b\u3088\u3063\u3066\u591a\u304f\u306e\u5bb3\u304c\u53ca\u307c\u3055\u308c\u3066\u304d\u305f\u3068\u601d\u3046\u3002</p><p>\u4e0a\u3067\u8ff0\u3079\u305f\u3088\u3046\u306b\u3001\u79c1\u306f\u500b\u4eba\u304c\u3069\u306e\u30a2\u30a4\u30c7\u30a3\u30a2\u3092\u8ffd\u6c42\u3059\u308b\u304b\u306b\u3064\u3044\u3066\u4e8b\u524d\u306b\u5408\u610f\u3092\u5f97\u308b\u4e16\u754c\u3088\u308a\u3082\u3001\u500b\u4eba\u304c\u30ef\u30af\u30ef\u30af\u3059\u308b\u3088\u3046\u306a\u30a2\u30a4\u30c7\u30a3\u30a2\u3092\u8ffd\u6c42\u3057\u3001\u3088\u308a\u591a\u304f\u306e\u4ed5\u4e8b\u3092\u3053\u306a\u3057\u4fa1\u5024\u3092\u793a\u3059\u3053\u3068\u3067\u3001\u3088\u308a\u826f\u3044\u30a2\u30a4\u30c7\u30a3\u30a2\u304c\u652f\u6301\u3055\u308c\u308b\u4e16\u754c\u306e\u65b9\u304c\u3044\u3044\u3068\u601d\u3046\u3002\u3053\u308c\u306f\u30d2\u30c3\u30c8\u30d9\u30fc\u30b9\u306e\u30a2\u30d7\u30ed\u30fc\u30c1\u3092\u5e7e\u5206\u304b\u6b63\u5f53\u5316\u3059\u308b\u3082\u306e\u3060\u3002\u305d\u3046\u306f\u8a00\u3063\u3066\u3082\u3001\u4e92\u3044\u306b\u5618\u3092\u3064\u304d\u3001\u5f37\u8981\u3057\u3001\u90aa\u9b54\u3057\u5408\u3063\u3066\u3001\u5354\u8abf\u3084\u30b3\u30df\u30e5\u30cb\u30b1\u30fc\u30b7\u30e7\u30f3\u3001\u4ea4\u6d41\u304c\u6210\u7acb\u3057\u306a\u3044\u4e16\u754c\u3088\u308a\u3082\u3001<u>\u5584\u826f\u306a\u884c\u52d5\u3084\u65e5\u5e38\u306e\u502b\u7406\u3092\u5b88\u308a\u306a\u304c\u3089</u>\u3001\u81ea\u5206\u306e\u30a2\u30a4\u30c7\u30a3\u30a2\u3092\u8ffd\u6c42\u3059\u308b\u4e16\u754c\u306e\u65b9\u304c\u826f\u3044\u3068\u601d\u3046\u3002</p><p>\u3053\u306e\u70b9\u3067\u3001\u8aa0\u5b9f\u306a\u30b3\u30df\u30e5\u30cb\u30b1\u30fc\u30b7\u30e7\u30f3\u3092\u5fc3\u304c\u3051\u308b\u3053\u3068\u304c\u91cd\u8981\u3060\u3068\u601d\u3046\u3002\u79c1\u305f\u3061\u306f\u3001\u81ea\u5206\u305f\u3061\u304c\u5168\u3066\u306e\u7b54\u3048\u3092\u6301\u3061\u5408\u308f\u305b\u3066\u3044\u308b\u3068\u306f\u601d\u3063\u3066\u3044\u306a\u3044\u3057\u3001\u81ea\u5206\u305f\u3061\u306e\u610f\u898b\u3092\u62bc\u3057\u901a\u3057\u305f\u3044\u3068\u601d\u3063\u3066\u3044\u308b\u308f\u3051\u3067\u3082\u306a\u3044\u3002\u3080\u3057\u308d\u3001\u79c1\u305f\u3061\u304c\u76ee\u7684\u3092\u8ffd\u6c42\u3059\u308b\u3053\u3068\u306b\u5354\u529b\u3059\u308b\u304b\u3069\u3046\u304b\u3001\u3069\u306e\u3088\u3046\u306b\u5354\u529b\u3057\u305f\u3044\u304b\u3092\u305d\u306e\u771f\u4fa1\u306b\u3088\u3063\u3066\u516c\u6b63\u306b\u5224\u65ad\u3057\u3066\u3082\u3089\u3044\u305f\u3044\u3068\u8003\u3048\u3066\u3044\u308b\u3002\u79c1\u305f\u3061\u306f\u3001\u5927\u80c6\u306a\u30a2\u30a4\u30c7\u30a3\u30a2\u3092\u8ffd\u6c42\u3059\u308b\u3068\u540c\u6642\u306b\u3001\u3044\u304b\u306b\u7c21\u5358\u306b\u9593\u9055\u3063\u3066\u3057\u307e\u3046\u304b\u3092\u5fd8\u308c\u306a\u3044\u3088\u3046\u306b\u3057\u3066\u3044\u304d\u305f\u3044\u3002</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnr29dnmrh0v8\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefr29dnmrh0v8\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://en.wikipedia.org/wiki/Survivorship_bias\"><u>\u751f\u5b58\u8005\u30d0\u30a4\u30a2\u30b9</u></a>\u304c\u50cd\u3044\u3066\u3044\u308b\u53ef\u80fd\u6027\u3084\u3001\u6210\u529f\u3057\u305f\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306b\u5bfe\u3057\u3066\u5931\u6557\u3057\u305f\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u304c\u5b9f\u969b\u3044\u304f\u3064\u3042\u3063\u305f\u306e\u304b\u3068\u3044\u3046\u7591\u554f\u3082\u3042\u308b\u3002\u3057\u304b\u3057\u3001\u4e0a\u8a18\u306e\u4f8b\u306f\u3001\u81a8\u5927\u306a\u53ef\u80fd\u6027\u306e\u4e2d\u304b\u3089\u9078\u3070\u308c\u305f\u3082\u306e\u3067\u306f\u306a\u3044\u3053\u3068\u306b\u6ce8\u610f\u3057\u305f\u3044\u3002(\u4e0a\u8a18\u3067\u53d6\u308a\u4e0a\u3052\u305f\u5168\u3066\u306e\u6148\u5584\u5bb6\u306f\u3001\u5bc4\u4ed8\u3092\u3059\u308b<u>\u524d\u306b</u>\u3001\u540c\u69d8\u306e\u554f\u984c\u306b\u95a2\u5fc3\u3092\u6301\u3064\u8457\u540d\u306a\u6148\u5584\u5bb6\u3092\u77ed\u3044\u30ea\u30b9\u30c8\u3068\u3057\u3066\u8a18\u3057\u3066\u3044\u305f\u3060\u308d\u3046)\u3002\ufe0e</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnh47ab3mph6\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefh47ab3mph6\">^</a></strong></sup></span><div class=\"footnote-content\"><p>2017\u5e748\u6708\u3088\u308a\u3001<a href=\"https://www.openphilanthropy.org/about/relationship-disclosure-policy\"><u>\u30d1\u30fc\u30c8\u30ca\u30fc\u56e3\u4f53\u3068\u306e\u500b\u4eba\u7684\u306a\u95a2\u4fc2</u></a>\u306b\u3064\u3044\u3066\u306f\u516c\u306b\u66f8\u304b\u306a\u3044\u3053\u3068\u306b\u306a\u3063\u305f\u3002\u3053\u306e\u5909\u66f4\u306b\u4f34\u3063\u3066\u3053\u306e\u8a18\u4e8b\u3082\u66f4\u65b0\u3055\u308c\u305f\u3002\ufe0e</p></div></li></ol>", "user": {"username": "EA Japan"}}, {"_id": "ZuuQ5HBfaue4ocf4d", "title": "\u73fe\u5728\u9032\u884c\u4e2d\u306e\u9053\u5fb3\u7684\u5927\u60e8\u4e8b\u306e\u53ef\u80fd\u6027\uff08\u8981\u7d04\uff09", "postedAt": "2023-07-28T15:43:21.187Z", "htmlBody": "<p><i>This is a Japanese translation of \u201c</i><a href=\"https://forum.effectivealtruism.org/posts/Dtr8aHqCQSDhyueFZ/the-possibility-of-an-ongoing-moral-catastrophe-summary\"><i><strong>The Possibility of an Ongoing Moral Catastrophe (Summary)</strong></i></a><i>\u201d</i></p><p>By&nbsp;<a href=\"https://forum.effectivealtruism.org/users/linch\"><u>Linch</u></a> 2019\u5e74 8\u67083\u65e5</p><p>\u79c1\u306f\u6570\u5e74\u524d\u3001\u5730\u5143\u306e\u30c7\u30a3\u30b9\u30ab\u30c3\u30b7\u30e7\u30f3\u30b0\u30eb\u30fc\u30d7\u7528\u306b\u30a8\u30d0\u30f3\u30fb\u30a6\u30a3\u30ea\u30a2\u30e0\u30ba\u306b\u3088\u308b<a href=\"https://philpapers.org/rec/WILTPO-101\"><u>\u512a\u308c\u305f\u54f2\u5b66\u8ad6\u6587\u306e</u></a>\u30a2\u30a6\u30c8\u30e9\u30a4\u30f3\u3092\u4f5c\u308a\u307e\u3057\u305f\u3002\u305d\u306e\u30a2\u30a6\u30c8\u30e9\u30a4\u30f3\u304c\u5f90\u3005\u306bEA\u306e\u30aa\u30f3\u30e9\u30a4\u30f3\u30b3\u30df\u30e5\u30cb\u30c6\u30a3\u4e0a\u3067\u56de\u89a7\u3055\u308c\u308b\u3088\u3046\u306b\u306a\u308a\u3001\u3082\u3063\u3068\u5e83\u304f\u77e5\u3089\u305b\u308b\u3088\u3046\u306b\u3068\u52e7\u3081\u3089\u308c\u305f\u306e\u3067\u3001\u3053\u3061\u3089\u306b\u63b2\u8f09\u3057\u3088\u3046\u3068\u601d\u3044\u307e\u3059\u3002</p><p>\u305d\u306e\u54f2\u5b66\u8ad6\u6587\u306f\u8aad\u307f\u3084\u3059\u304f\u3001\u7121\u6599\u3067\u95b2\u89a7\u3067\u304d\u308b\u306e\u3067\u3001\u6642\u9593\u304c\u3042\u308c\u3070\u539f\u8457\u3092\u8aad\u3080\u3053\u3068\u3092\u5f37\u304f\u304a\u85a6\u3081\u3057\u307e\u3059\u3002</p><h1>\u8981\u7d04</h1><h3><strong>I. \u6838\u3068\u306a\u308b\u4e3b\u5f35</strong></h3><ol><li>\u9053\u5fb3\u7684\u5ba2\u89b3\u4e3b\u7fa9\uff08\u3042\u308b\u3044\u306f\u305d\u308c\u306b\u8fd1\u3044\u3082\u306e\uff09\u3092\u524d\u63d0\u3068\u3057\u305f\u5834\u5408\u3001\u79c1\u305f\u3061\u306f\u304a\u305d\u3089\u304f<strong>\u77e5\u3089\u305a\u77e5\u3089\u305a\u306e\u3046\u3061\u306b</strong>\u91cd\u5927\u304b\u3064\u5927\u898f\u6a21\u306a\u904e\u3061\uff08\u300c\u73fe\u5728\u9032\u884c\u4e2d\u306e\u9053\u5fb3\u7684\u5927\u60e8\u4e8b\u300d\uff09\u3092\u72af\u3057\u3066\u3044\u308b\u3053\u3068\u306b\u306a\u308b\u3002</li></ol><h3><strong>II. \u5b9a\u7fa9\uff1a\u9053\u5fb3\u7684\u5927\u60e8\u4e8b\u3068\u306f\uff1f\uff13\u3064\u306e\u57fa\u6e96</strong></h3><ol><li>\u91cd\u5927\u306a\u904e\u3061\u3067\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044\uff08\u8efd\u3044\u4fae\u8fb1\u3084\u4e0d\u90fd\u5408\u3068\u3044\u3046\u3088\u308a\u3082\u4e0d\u6b63\u306a\u6b7b\u3084\u5974\u96b7\u5236\u306b\u8fd1\u3044\uff09</li><li>\u5927\u898f\u6a21\u3067\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044\uff08\u4e00\u56de\u304d\u308a\u306e\u4e0d\u5f53\u306a\u51e6\u5211\u3084\u4e00\u4eba\u306b\u5bfe\u3059\u308b\u62f7\u554f\u3088\u308a\u3082\u898f\u6a21\u304c\u5927\u304d\u3044\uff09</li><li>\u793e\u4f1a\u306e\u5e45\u5e83\u3044\u5c64\u304c\u3001\u884c\u52d5\u3084\u884c\u52d5\u3057\u306a\u3044\u3053\u3068\u3092\u901a\u3058\u3066\u8cac\u4efb\u3092\u8ca0\u3046\uff08\u4e00\u4eba\u306e\u72ec\u88c1\u8005\u306b\u3088\u308b\u4e00\u65b9\u7684\u306a\u4e0d\u53ef\u6297\u529b\u3067\u306f\u3042\u308a\u3048\u306a\u3044\uff09</li></ol><h3><strong>III. \u79c1\u305f\u3061\u304c\u672a\u77e5\u306e\u9053\u5fb3\u7684\u5927\u60e8\u4e8b\u3092\u304a\u305d\u3089\u304f\u8fce\u3048\u308b\u308f\u3051\u3002\u4e8c\u3064\u306e\u4e3b\u306a\u4e3b\u5f35\u3002</strong></h3><ol><li><strong>\u5e30\u7d0d\u6cd5</strong><ol><li>\u524d\u63d0\u6761\u4ef6\uff1a\u81ea\u5206\u81ea\u8eab\u3084\u793e\u4f1a\u306e\u9053\u5fb3\u306b\u5247\u3063\u3066\u884c\u52d5\u3057\u3066\u3044\u3066\u3082\u3001\u5927\u304d\u306a\u9053\u5fb3\u7684\u306a\u904e\u3061\u3092\u72af\u3059\u3053\u3068\u306f\u53ef\u80fd\u3067\u3042\u308b\u3002<ol><li>\u57fa\u672c\u7684\u306a\u52d5\u6a5f\uff1a\u30ca\u30c1\u30b9\u304c\u6b63\u76f4\u3067\u8aa0\u5b9f\u3067\u3042\u3063\u305f\u3068\u3057\u3066\u3082\u3001\u91cd\u8981\u306a\u70b9\u306b\u304a\u3044\u3066\u9593\u9055\u3063\u305f\u884c\u52d5\u3092\u3068\u3063\u3066\u3044\u308b\u3088\u3046\u306b\u601d\u308f\u308c\u308b\u3002</li><li>\u3053\u306e\u904e\u3061\u304c\u3001\u8aa4\u3063\u305f\u7d4c\u9a13\u7684\u4fe1\u5ff5\uff08\u5168\u3066\u306e\u30e6\u30c0\u30e4\u4eba\u306f\u4e16\u754c\u898f\u6a21\u306e\u9670\u8b00\u306b\u52a0\u62c5\u3057\u3066\u3044\u308b\uff09\u306b\u3088\u308b\u3082\u306e\u306a\u306e\u304b\u3001\u9593\u9055\u3063\u305f\u4fa1\u5024\u89b3\uff08\u30e6\u30c0\u30e4\u4eba\u306f\u4eba\u9593\u4ee5\u4e0b\u3067\u3042\u308a\u9053\u5fb3\u7684\u4fa1\u5024\u306f\u306a\u3044\uff09\u306b\u3088\u308b\u3082\u306e\u306a\u306e\u304b\u306f\u95a2\u4fc2\u306a\u3044\u3002</li></ol></li><li>\u3053\u306e\u524d\u63d0\u3092\u5ff5\u982d\u306b\u7f6e\u304f\u3068\u3001\u6b74\u53f2\u4e0a\u306e\u4e3b\u8981\u306a\u793e\u4f1a\u306f\u307b\u307c\u5168\u3066\u3001\u7834\u6ec5\u7684\u306b\u9593\u9055\u3063\u305f\u884c\u52d5\u3092\u3068\u3063\u3066\u304d\u305f\u3053\u3068\u306b\u306a\u308b\u3002<ol><li>\u30b3\u30f3\u30ad\u30b9\u30bf\u30c9\u30fc\u30eb\u3001\u5341\u5b57\u8ecd\u3001\u30a4\u30b9\u30e9\u30e0\u5e1d\u56fd\u3001\u30a2\u30b9\u30c6\u30ab\u306a\u3069\u306e\u3001\u5f7c\u3089\u304c\u5584\u3084\u6b63\u7fa9\u3068\u547c\u3093\u3060\u795e\u306e\u540d\u306e\u4e0b\u306b\u304a\u3044\u3066\u3001\u5f81\u670d\u884c\u70ba\u3092\u884c\u306a\u3063\u305f\u8005\u306e\u3053\u3068\u3092\u8003\u3048\u3066\u307b\u3057\u3044\u3002</li><li>\u3053\u308c\u3089\u306e\u6b74\u53f2\u4e0a\u306e\u4eba\u7269\u304c\u307f\u306a\u3001\u305d\u306e\u3088\u3046\u306a\u4fe1\u5ff5\u3092<strong>\u79f0\u3057\u305f</strong>\u3060\u3051\u3067\u3001\u771f\u306e\u4fe1\u8005\u3067\u306f\u306a\u304f\u3001\u5618\u3064\u304d\u3067\u3042\u3063\u305f\u3068\u3044\u3046\u3053\u3068\u306f\u8003\u3048\u306b\u304f\u3044\u3002</li><li>\u5b58\u5728\u306e\u8a3c\u660e\uff1a\u4eba\u306f\u7121\u81ea\u899a\u306e\u307e\u307e\u3001\u5927\u304d\u306a\u60aa\u4e8b\u3092\u884c\u3046\u3053\u3068\u304c\u3067\u304d\u308b\uff08\u305d\u3057\u3066\u5b9f\u969b\u306b\u884c\u3063\u3066\u3044\u308b\uff09\u3002</li></ol></li><li>\u73fe\u5728\u9032\u884c\u4e2d\u306e\u9053\u5fb3\u7684\u5927\u60e8\u4e8b\u3092\u79c1\u305f\u3061\u304c\u8fce\u3048\u308b\u3053\u3068\u306f\u3001\u305f\u3060\u306e\u53ef\u80fd\u6027\u3067\u306f\u306a\u304f\u3001<strong>\u5341\u5206\u306b\u3042\u308a\u3048\u308b</strong>\u3002<ol><li>\u79c1\u305f\u3061\u306f\u904e\u53bb\u306e\u4e16\u4ee3\u3068<strong>\u3055\u307b\u3069\u5909\u308f\u3089\u306a\u3044</strong>\u3002\u6587\u5b57\u901a\u308a\u4f55\u767e\u3082\u306e\u4e16\u4ee3\u304c\u3001\u81ea\u5206\u305f\u3061\u306f\u6b63\u3057\u304f\u3066\u3001\u300c\u552f\u4e00\u306e\u771f\u306e\u9053\u5fb3\u300d\u3092\u898b\u3064\u3051\u51fa\u3057\u305f\u3068\u8003\u3048\u3066\u304d\u305f\u3002</li><li>\u79c1\u305f\u3061\u306e\u89aa\u306e\u4e16\u4ee3\u3067\u306f\u3001\u4eba\u7a2e\u3084\u30bb\u30af\u30b7\u30e5\u30a2\u30ea\u30c6\u30a3\u306a\u3069\u306e\u7406\u7531\u3067\u3001\u3042\u308b\u4eba\u306f\u4ed6\u306e\u4eba\u3088\u308a\u591a\u304f\u306e\u6a29\u5229\u3092\u6301\u3063\u3066\u3044\u308b\u3068\u3044\u3046\u306e\u304c\u4e00\u822c\u7684\u306a\u8003\u3048\u3067\u3042\u3063\u305f\u3002</li><li>\u79c1\u305f\u3061\u306f\u9053\u5fb3\u304c\u6fc0\u5909\u3057\u3066\u3044\u308b\u6642\u4ee3\u306b\u751f\u304d\u3066\u304a\u308a\u3001\u79c1\u305f\u3061\u306e\u9053\u5fb3\u306f\u7956\u7236\u6bcd\u306e\u6642\u4ee3\u3068\u306f\u304b\u306a\u308a\u7570\u306a\u3063\u3066\u3044\u308b\u3002</li><li>\u4eee\u306b\u3044\u305a\u308c<strong>\u3069\u3053\u304b</strong>\u306e\u4e16\u4ee3\u304c\u300c\u9053\u5fb3\u306e\u5168\u3066\u300d\u3092\u89e3\u660e\u3059\u308b\u3068\u3057\u3066\u3082\u3001\u305d\u306e\u5168\u3066\u3092\u6b63\u3057\u304f\u7406\u89e3\u3059\u308b\u4e16\u4ee3\u306f\u304a\u305d\u3089\u304f\u3001\u305d\u306e\u89aa\u4e16\u4ee3\u304c<strong>\u307b\u3068\u3093\u3069</strong>\u3059\u3079\u3066\u3092\u6b63\u3057\u304f\u7406\u89e3\u3057\u3066\u3044\u308b\u4e16\u4ee3\u3067\u3042\u308d\u3046\u3002</li></ol></li></ol></li><li><strong>\u9078\u8a00\u7684\u8ad6\u6cd5</strong><ol><li>\u6d3b\u52d5\u5bb6\u304c\u514d\u8cac\u3055\u308c\u308b\u308f\u3051\u3067\u306f\u306a\u3044\u3002\u305f\u3068\u3048\u3001\u3042\u306a\u305f\u304c\u8208\u5473\u306e\u3042\u308b\u554f\u984c\u304c\u5168\u3066\u89e3\u6c7a\u3057\u305f\u3068\u3057\u3066\u3082\u3001\u79c1\u305f\u3061\u306e\u793e\u4f1a\u304c\u3088\u3044\u3082\u306e\u3067\u3042\u308b\u3068\u306f\u9650\u3089\u306a\u3044\u3002\u306a\u305c\u306a\u3089\u3001\u305d\u3053\u306b\u306f\u307e\u3060<strong>\u672a\u77e5</strong>\u306e\u9053\u5fb3\u7684\u5927\u60e8\u4e8b\u304c\u3042\u308b\u304b\u3089\u3002</li><li>\u793e\u4f1a\u304c\u9593\u9055\u3044\u3092\u72af\u3059\u306b\u306f<strong>\u3055\u307e\u3056\u307e\u306a</strong>\u65b9\u6cd5\u304c\u3042\u308a\u3001\u6587\u5b57\u901a\u308a<strong>\u5168\u3066</strong>\u3092\u6b63\u3059\u3053\u3068\u306f\u307b\u307c<strong>\u4e0d\u53ef\u80fd</strong>\u3067\u3042\u308b\u3002</li><li>\u3053\u308c\u306f\u5358\u306a\u308b\u4e9b\u7d30\u306a\u5fc3\u914d\u4e8b\u3067\u306f\u306a\u304f\u3001\u30db\u30ed\u30b3\u30fc\u30b9\u30c8\u306e\u60b2\u60e8\u3055\u306b\u76f8\u5f53\u3059\u308b\u30ec\u30d9\u30eb\u3067\u79c1\u305f\u3061\u304c\u9593\u9055\u3063\u3066\u3044\u308b\u53ef\u80fd\u6027\u304c\u3042\u308b\u3002</li><li>\u793e\u4f1a\u306e\u9593\u9055\u3044\u65b9\u306b\u306f\u3055\u307e\u3056\u307e\u306a<strong>\u7a2e\u985e</strong>\u304c\u3042\u308b\u3002<ol><li><strong>\u8ab0\u304c</strong>\u9053\u5fb3\u7684\u5730\u4f4d\u3092\u6301\u3064\u306e\u304b\u306b\u95a2\u3057\u3066\u9593\u9055\u3063\u3066\u3044\u308b\u304b\u3082\u3057\u308c\u306a\u3044\uff08\u4f8b\uff1a\u80ce\u5150\u3084\u52d5\u7269\uff09</li><li>\u9053\u5fb3\u7684\u306b\u91cd\u8981\u306a\u4eba\u306b\u5bb3\u3092\u53ca\u307c\u3057\u305f\u308a\u50b7\u3064\u3051\u305f\u308a\u3059\u308b\u3053\u3068\u306b\u95a2\u3057\u3066<strong>\u7d4c\u9a13\u7684\u306b</strong>\u9593\u9055\u3063\u3066\u3044\u308b\u304b\u3082\u3057\u308c\u306a\u3044\uff08\u4f8b\uff1a\u5b50\u3069\u3082\u3078\u306e\u5b97\u6559\u7684\u601d\u60f3\u306e\u5439\u304d\u8fbc\u307f\uff09</li><li><strong>\u3042\u308b</strong>\u7fa9\u52d9\u306b\u95a2\u3057\u3066\u306f\u6b63\u3057\u304f\u3066\u3082\u3001\u4ed6\u306e\u7fa9\u52d9\u306b\u95a2\u3057\u3066\u306f\u9593\u9055\u3063\u3066\u3044\u308b\u304b\u3082\u3057\u308c\u306a\u3044\u3002<ol><li>\u8aa4\u3063\u305f\u9053\u5fb3\u7684\u7fa9\u52d9\u306b\u904e\u5270\u306a\u6ce8\u610f\u3092\u6255\u3044\u3001\u30ea\u30bd\u30fc\u30b9\u3092\u4f7f\u3046\u3053\u3068\u3067\u3001\u9053\u5fb3\u306b\u53cd\u3057\u305f\u884c\u52d5\u3092\u3068\u308a\u3046\u308b\uff08\u5341\u5b57\u8ecd\u306e\u3088\u3046\u306b\uff09\u3002</li></ol></li><li>\u4f55\u304c\u9593\u9055\u3063\u3066\u3044\u3066\u4fee\u6b63\u3055\u308c\u308b\u3079\u304d\u3067\u3042\u308b\u304b\u306b\u95a2\u3057\u3066\u306f\u6b63\u3057\u3044\u304c\u3001\u3055\u307e\u3056\u307e\u306a\u4fee\u6b63\u3078\u306e<strong>\u512a\u5148\u9806\u4f4d</strong>\u306e\u4ed8\u3051\u65b9\u306b\u95a2\u3057\u3066\u306f\u9593\u9055\u3063\u3066\u3044\u308b\u304b\u3082\u308c\u306a\u3044\u3002</li><li>\u4f55\u304c\u9593\u9055\u3063\u3066\u3044\u308b\u304b\u306b\u95a2\u3057\u3066\u306f\u6b63\u3057\u3044\u304c\u3001\u4f55\u3092\u4fee\u6b63\u3059\u308b\u3053\u3068\u304c\u79c1\u305f\u3061\u306e<strong>\u8cac\u4efb</strong>\u3067\u3042\u308a\u3001\u4f55\u304c\u305d\u3046\u3067\u306a\u3044\u306e\u304b\u306b\u95a2\u3057\u3066\u306f\u9593\u9055\u3063\u3066\u3044\u308b\u304b\u3082\u3057\u308c\u306a\u3044\u3002\uff08\u4f8b\uff1a\u8ca7\u56f0\u3001\u56fd\u5883\uff09</li><li>\u9060\u3044\u672a\u6765\u306b\u3064\u3044\u3066\u9593\u9055\u3063\u3066\u3044\u308b\u304b\u3082\u3057\u308c\u306a\u3044\u3002\uff08\u51fa\u751f\u8ad6\u3001\u5b58\u4ea1\u30ea\u30b9\u30af\uff09</li></ol></li><li>\u5404\u30ab\u30c6\u30b4\u30ea\u30fc\u306b\u306f\u3001\u8907\u6570\u306e\u9593\u9055\u3048\u65b9\u304c\u3042\u308b\u3002<ol><li>\u3055\u3089\u306b\u3001\u306a\u304b\u306b\u306f\u76f8\u4e92\u306b\u6392\u4ed6\u7684\u306a\u3082\u306e\u3082\u3042\u308b\u3002\u4f8b\u3048\u3070\u3001<a href=\"https://ja.wikipedia.org/wiki/%E3%83%97%E3%83%AD%E3%83%A9%E3%82%A4%E3%83%95\"><u>\u30d7\u30ed\u30e9\u30a4\u30d5\uff08\u4e2d\u7d76\u53cd\u5bfe\u6d3e\uff09</u></a>\u3092\u5531\u3048\u308b\u4eba\u304c\u6b63\u3057\u304f\u3066\u3001\u4eba\u5de5\u598a\u5a20\u4e2d\u7d76\u306f\u5927\u304d\u306a\u7f6a\u3067\u3042\u308b\u304b\u3082\u3057\u308c\u306a\u3044\u3057\u3001<strong>\u3082\u3057\u304f\u306f</strong>\u3001\u80ce\u5150\u306f\u91cd\u8981\u3067\u306f\u306a\u304f\u3001\u4f8b\u3048\u3070\u598a\u5a20\u672b\u671f\u306e\u4e2d\u7d76\u306b\u304a\u3044\u3066\u3001\u5973\u6027\u306e\u81ea\u7531\u3092\u596a\u3046\u3053\u3068\u306f\u9053\u5fb3\u306b\u5f37\u304f\u53cd\u3059\u308b\u304b\u3082\u3057\u308c\u306a\u3044\u3002</li><li>\u79c1\u305f\u3061\u304c\u73fe\u5728\u3001\u3053\u308c\u3089\u5168\u3066\u306e\u30c8\u30ec\u30fc\u30c9\u30aa\u30d5\u306b\u304a\u3044\u3066\u5b8c\u74a7\u306a\u30d0\u30e9\u30f3\u30b9\u3092\u53d6\u308c\u3066\u3044\u308b\u3068\u306f\u8003\u3048\u306b\u304f\u3044\u3002</li></ol></li><li>\u9078\u8a00\u7684\u5224\u65ad\u304c\u7d61\u3093\u3067\u304f\u308b\u3002<ol><li>\u91cd\u8981\u306a\u554f\u984c\u305d\u308c\u305e\u308c\u306b\u304a\u3044\u306695%\u306e\u78ba\u7387\u3067\u79c1\u305f\u3061\u304c\u6b63\u3057\u3044\u3068\u4fe1\u3058\u305f\u3068\u3057\u3066\u3001\u305d\u306e\u3088\u3046\u306a\u554f\u984c\u304c15\u500b\u3042\u3063\u305f\u3068\u3059\u308b\u3068\u3001\u79c1\u305f\u3061\u304c\u6b63\u3057\u3044\u5408\u8a08\u78ba\u7387\u306f 0.95^15 ~= 46% \u3067\u3042\u308b\uff08\u72ec\u7acb\u6027\u3092\u4eee\u5b9a\uff09\u3002&nbsp;</li><li>\u5b9f\u969b\u306b\u306f\u3001\u91cd\u8981\u306a\u554f\u984c\u305d\u308c\u305e\u308c\u306b\u304a\u3044\u306695%\u306e\u78ba\u7387\u3067\u6b63\u3057\u3044\u3068\u601d\u3046\u306e\u306f\u904e\u4fe1\u3057\u305f\u898b\u7a4d\u3082\u308a\u3067\u3042\u308a\u300115\u9805\u76ee\u3068\u3044\u3046\u306e\u306f\u5c11\u306a\u304e\u308b\u3088\u3046\u306b\u601d\u308f\u308c\u308b\u3002</li></ol></li></ol></li></ol><h3><strong>IV. \u79c1\u305f\u3061\u306f\u3069\u3046\u3059\u308c\u3070\u3044\u3044\u306e\u304b\uff1f</strong></h3><ol><li>\u5207\u308a\u6368\u3066\u3089\u308c\u305f\u53ef\u80fd\u6027\uff1a<strong>\u4e88\u9632\u7b56\u3092\u53d6\u308b</strong>\u3002\u78ba\u4fe1\u304c\u6301\u3066\u306a\u3044\u5834\u5408\u306f\u3001\u9053\u5fb3\u7684\u306b\u8a00\u3063\u3066\u300c\u5b89\u5168\u306a\u300d\u884c\u52d5\u3092\u3068\u308b\u3002</li><li>\u4f8b\u3048\u3070\u3001\u755c\u7523\u52d5\u7269\u306b\u306f\u77e5\u899a\u529b\u306f\u306a\u3044\u3060\u308d\u3046\u3068\u304b\u3001\u77e5\u899a\u529b\u306e\u6709\u7121\u306f\u9053\u5fb3\u7684\u306b\u91cd\u8981\u3067\u306f\u306a\u3044\u3068\u8003\u3048\u3066\u3044\u305f\u3068\u3057\u3066\u3082\u3001\u300c\u5ff5\u306e\u305f\u3081\u306b\u300d\u30d9\u30b8\u30bf\u30ea\u30a2\u30f3\u306b\u306a\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u3002</li><li>\u3053\u306e\u65b9\u6cd5\u306f<strong>\u5f37\u529b</strong>\u3067\u306f<strong>\u306a\u3044</strong>\u305f\u3081\u3001\u4e00\u822c\u7684\u306b\u306f\u5341\u5206\u306b\u6a5f\u80fd\u3057\u306a\u3044\u3002\u524d\u8ff0\u306e\u3088\u3046\u306b\u3001\u3042\u307e\u308a\u306b\u591a\u304f\u306e\u3053\u3068\u304c\u9593\u9055\u3063\u3066\u3044\u308b\u53ef\u80fd\u6027\u304c\u3042\u308a\u3001\u306a\u304b\u306b\u306f<strong>\u77db\u76fe\u3057\u305f</strong>\u3082\u306e\u3082\u3042\u308b\u3002</li><li><strong>\u904e\u3061\u3092\u8a8d\u8b58\u3059\u308b</strong><ol><li>\u3069\u306e\u3088\u3046\u306a\u7834\u6ec5\u7684\u306a\u904e\u3061\u3092\u72af\u3057\u3066\u3044\u308b\u306e\u304b\u3001\u7a4d\u6975\u7684\u306b\u628a\u63e1\u3057\u3088\u3046\u3068\u3059\u308b\u3002<ol><li>\u79c1\u305f\u3061\u304c\u6c7a\u5b9a\u7684\u306b\u9593\u9055\u3063\u3066\u3044\u308b\u53ef\u80fd\u6027\u306e\u3042\u308b\u5b9f\u8df5\u7684\u306a\u5206\u91ce\uff08\u4f8b\uff1a\u52d5\u7269\u306e\u610f\u8b58\uff09\u3092\u3082\u3063\u3068\u7814\u7a76\u3059\u308b</li><li>\u9053\u5fb3\u54f2\u5b66\u3092\u3082\u3063\u3068\u7814\u7a76\u3059\u308b<ol><li>\u91cd\u8981\uff1a\u9053\u5fb3\u7684\u306a\u77e5\u6075\u304c\u5897\u3048\u305a\u306b\u6280\u8853\u7684\u306a\u77e5\u8b58\u304c\u5897\u3048\u308b\u3053\u3068\u306f\u3088\u304f\u306a\u3044\u30fb</li><li>\u6838\u5175\u5668\u3092\u6301\u3063\u305f\u30c1\u30f3\u30ae\u30b9\u30fb\u30cf\u30fc\u30f3\u3092\u60f3\u50cf\u3057\u3066\u307b\u3057\u3044</li></ol></li><li>\u3053\u308c\u3089\u306e\u5206\u91ce\u306f\u76f8\u4e92\u306b\u95a2\u308f\u3089\u306a\u3051\u308c\u3070<strong>\u306a\u3089\u306a\u3044</strong>\u3002<ol><li>\u54f2\u5b66\u8005\u304c\u52d5\u7269\u306f\u610f\u8b58\u304c\u3042\u308b\u306e<strong>\u3067\u3042\u308c\u3070</strong>\u91cd\u8981\u3067\u3042\u308a\u3001\u79d1\u5b66\u8005\u304c\u30a4\u30eb\u30ab\u306f\u610f\u8b58\u304c\u3042\u308b\u304c\u91cd\u8981\u304b\u306f\u308f\u304b\u3089\u306a\u3044\u3001\u3068\u8a00\u3046\u3060\u3051\u3067\u306f\u4e0d\u5341\u5206\u3067\u3042\u308b\u3002\u79c1\u305f\u3061\u306e\u793e\u4f1a\u304c\u3053\u308c\u3089\u3092\u7d71\u5408\u3067\u304d\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044\u3002</li></ol></li></ol></li><li>\u672c\u7269\u306e\u30a2\u30a4\u30c7\u30a3\u30a2\u304c\u52dd\u3064\u30a2\u30a4\u30c7\u30a3\u30a2\u5e02\u5834\u304c\u5fc5\u8981\u3067\u3042\u308b</li><li>\u6025\u901f\u306a\u77e5\u7684\u9032\u6b69\u306f<strong>\u5fc5\u8981\u4e0d\u53ef\u6b20</strong>\u3067\u3042\u308b<ol><li>\u30ca\u30c1\u30b9\u3092\u5012\u3059\u305f\u3081\u3001\u3042\u308b\u3044\u306f\u5974\u96b7\u5236\u5ea6\u3092\u7d42\u308f\u3089\u305b\u308b\u305f\u3081\u306b\u6587\u5b57\u901a\u308a\u306e\u6226\u4e89\u3092\u3059\u308b\u4fa1\u5024\u304c\u3042\u308b\u306e\u306a\u3089\u3070\u3001\u79c1\u305f\u3061\u304c\u73fe\u5728\u3069\u3093\u306a\u904e\u3061\u3092\u72af\u3057\u3066\u3044\u308b\u304b\u3092\u89e3\u660e\u3059\u308b\u305f\u3081\u306b\u3001\u591a\u5927\u306a\u7269\u8cea\u7684\u6295\u8cc7\u3092\u3057\u3066\u793e\u4f1a\u7684\u640d\u5931\u3092\u88ab\u308b\u4fa1\u5024\u304c\u3042\u308b\u306f\u305a\u3060\u3002</li></ol></li></ol></li><li>\u6539\u5584\u3057\u305f\u4fa1\u5024\u89b3\u3092\u5b9f\u73fe\u3059\u308b<ol><li>\u79c1\u305f\u3061\u304c\u72af\u3057\u3066\u304d\u305f\u91cd\u5927\u306a\u9053\u5fb3\u7684\u904e\u3061\u3092\u7406\u89e3\u3057\u305f\u3089\u3001\u904e\u53bb\u306e\u88ab\u5bb3\u306b\u5bfe\u3057\u3066\u9053\u5fb3\u7684\u306a\u511f\u3044\u3092\u3059\u308b\u3001\u3055\u3082\u306a\u3051\u308c\u3070\u5c11\u306a\u304f\u3068\u3082\u540c\u69d8\u306e\u9593\u9055\u3044\u3092\u72af\u3057\u3066\u3055\u3089\u306b\u88ab\u5bb3\u3092\u51fa\u3059\u3053\u3068\u3092<strong>\u3067\u304d\u308b\u3060\u3051\u65e9\u304f</strong>\u6b62\u3081\u3089\u308c\u308b\u3088\u3046\u306b\u3057\u305f\u3044\u3002</li><li>\u305d\u306e\u305f\u3081\u306b\u306f\u3001<strong>\u7269\u8cea\u7684\u306a</strong>\u9762\u3067\u306e<strong>\u67d4\u8edf\u6027</strong>\u3092\u6700\u5927\u5316\u3057\u305f\u3044\u3002<ol><li>\u6975\u7aef\u306b\u8ca7\u3057\u3044\u793e\u4f1a\u3084\u6226\u4e89\u3067\u8352\u5ec3\u3057\u305f\u793e\u4f1a\u3067\u306f\u3001\u5fc5\u8981\u306b\u5fdc\u3058\u3066\u8fc5\u901f\u306b\u9053\u5fb3\u7684\u306a\u5909\u5316\u3092\u8d77\u3053\u3059\u3053\u3068\u306f\u3067\u304d\u306a\u3044\u3060\u308d\u3046\u3002</li><li>\u4f8b\uff1a\u7279\u5b9a\u306e\u30c7\u30b6\u30a4\u30f3\u306b\u6cbf\u3063\u3066\u69cb\u7bc9\u3055\u308c\u305f\u8907\u96d1\u306a\u30b7\u30b9\u30c6\u30e0\u306f\u3001\u885d\u6483\u306b\u5f31\u304f\u3001\u5909\u5316\u3057\u306b\u304f\u3044\u3002<a href=\"https://dev.appswingby.com/cloudnative/antifragile/\"><u>\u30a2\u30f3\u30c1\u30d5\u30e9\u30b8\u30e3\u30a4\u30eb</u></a>\u3092\u53c2\u7167\u3002</li><li>\u6226\u4e89\u306b\u5099\u3048\u3066\u8cc7\u6e90\u3092\u84c4\u3048\u3066\u304a\u304f\u306e\u3068\u540c\u3058\u3088\u3046\u306b\u3001\u5c06\u6765\u306e\u9053\u5fb3\u7684\u306a\u7dca\u6025\u4e8b\u614b\u306e\u305f\u3081\u306b\u8cc7\u6e90\u3092\u84c4\u3048\u3001\u4f8b\u3048\u3070\u8ce0\u511f\u91d1\u306e\u652f\u6255\u3044\u3084\u3001\u5c11\u306a\u304f\u3068\u3082\u9069\u5207\u306a\u5909\u66f4\u3092\u8fc5\u901f\u306b\u884c\u3046\u3053\u3068\u304c\u3067\u304d\u308b\u3088\u3046\u306b\u3057\u3066\u304a\u304f\u3068\u826f\u3044\u3060\u308d\u3046\u3002<ol><li>\u3053\u308c\u304c\u5b9f\u969b\u306b\u3069\u306e\u3088\u3046\u306b\u53ef\u80fd\u306a\u306e\u304b\u306f\u3088\u304f\u5206\u304b\u3089\u306a\u3044\u3002\u4f8b\u3048\u3070\u3001\u500b\u4eba\u306f\u901a\u5e38\u3001\u6295\u8cc7\u3092\u3059\u308b\u3053\u3068\u3067\u8caf\u84c4\u3057\u3001\u653f\u5e9c\u306f\u4ed6\u306e\u653f\u5e9c\u306e\u50b5\u5238\u3092\u8cfc\u5165\u3057\u305f\u308a\u3001\u6c11\u9593\u90e8\u9580\u306b\u6295\u8cc7\u3057\u305f\u308a\u3059\u308b\u3053\u3068\u3067\u8caf\u84c4\u3059\u308b\u304c\u3001\u4e16\u754c\u5168\u4f53\u3068\u3057\u3066\u3069\u306e\u3088\u3046\u306b\u300c\u8caf\u84c4\u300d\u3059\u308b\u306e\u304b\u306f\u4e0d\u660e\u3060\u3002</li></ol></li></ol></li><li><strong>\u793e\u4f1a</strong>\u60c5\u52e2\u306e\u67d4\u8edf\u6027\u3092\u6700\u5927\u5316\u3057\u305f\u3044\u3002<ol><li>\u7269\u8cea\u7684\u306b\u306f\u5927\u304d\u306a\u5909\u5316\u304c\u53ef\u80fd\u3067\u3082\u3001\u60f0\u6027\u3084\u4fdd\u5b88\u7684\u306a\u30d0\u30a4\u30a2\u30b9\u306b\u3088\u308a\u3001\u793e\u4f1a\u304c\u305d\u306e\u3088\u3046\u306a\u5909\u5316\u3092\u975e\u5e38\u306b\u96e3\u3057\u304f\u3057\u3066\u3044\u308b\u5834\u5408\u304c\u3042\u308b\u3002</li><li>\u4f8b\u3048\u3070\u3001\u61b2\u6cd5\u6539\u6b63\u306b\u3088\u3063\u3066\u793e\u4f1a\u3092\u7d71\u6cbb\u3059\u308b\u3053\u3068\u306f\u67d4\u8edf\u6027\u306b\u6b20\u3051\u308b\u793e\u4f1a\u72b6\u6cc1\u3092\u3082\u305f\u3089\u3059\u53ef\u80fd\u6027\u304c\u9ad8\u304f\u3001\u7591\u5ff5\u306e\u76ee\u3092\u3082\u3063\u3066\u898b\u308b\u5fc5\u8981\u304c\u3042\u308b\u3002</li></ol></li></ol></li></ol><h3><strong>V. \u7d50\u8ad6\u30fb\u305d\u306e\u4ed6\u306e\u6307\u6458</strong></h3><ol><li><strong>\u6279\u5224\u7684\u8003\u5bdf\u2460</strong>\uff1a\u9053\u5fb3\u7684\u5927\u60e8\u4e8b\u3092\u662f\u6b63\u3067\u304d\u308b\u793e\u4f1a\u3092\u4f5c\u308b\u3053\u3068\u3068\u3001\u5b9f\u969b\u306b\u9053\u5fb3\u7684\u5927\u60e8\u4e8b\u3092\u662f\u6b63\u3059\u308b\u3053\u3068\u306f\u540c\u3058\u3067\u306f\u306a\u3044\u3002</li><li><strong>\u6279\u5224\u7684\u8003\u5bdf \u2461\uff1a</strong>\u9053\u5fb3\u7684\u5927\u60e8\u4e8b\u306e\u662f\u6b63\u306b\u5099\u3048\u308b\u305f\u3081\u306b\u4e0a\u3067\u63d0\u6848\u3057\u305f\u65b9\u7b56\u306e\u591a\u304f\u306f\u3001\u305d\u308c\u81ea\u4f53\u304c\u60aa\u3067\u3042\u308b\u304b\u3082\u3057\u308c\u306a\u3044\u3002<ol><li>\u4f8b\u3048\u3070\u3001\u9053\u5fb3\u7684\u7814\u7a76\u306b\u8cbb\u3084\u3055\u308c\u305f\u304a\u91d1\u306f\u3001\u4ee3\u308f\u308a\u306b\u4e16\u754c\u306e\u8ca7\u56f0\u306b\u4f7f\u308f\u308c\u305f\u304b\u3082\u3057\u308c\u306a\u3044\u3057\u3001\u6700\u5927\u9650\u306b\u67d4\u8edf\u306a\u793e\u4f1a\u3092\u69cb\u7bc9\u3059\u308b\u306b\u306f\u3001\u73fe\u5728\u306e\u4eba\u3005\u306e\u6a29\u5229\u306b\u5bfe\u3059\u308b\u975e\u60c5\u306a\u5236\u7d04\u3092\u4f34\u3046\u304b\u3082\u3057\u308c\u306a\u3044\u3002</li></ol></li><li>\u3057\u304b\u3057\u3001\u77ed\u671f\u7684\u306b\u306f\u307e\u3060\u3053\u308c\u3089\u3092\u3084\u3063\u3066\u307f\u308b\u4fa1\u5024\u304c\u3042\u308b\u3002</li></ol>", "user": {"username": "EA Japan"}}, {"_id": "p5sxBu3dryPpXhpQQ", "title": "\u300c\u5947\u8aac\u300d\u306b\u3064\u3044\u3066\u8003\u3048\u308b", "postedAt": "2023-07-28T15:33:29.891Z", "htmlBody": "<p><i>This is a Japanese translation of \u201c</i><a href=\"https://forum.effectivealtruism.org/posts/hRJueS96CMLajeF57/on-fringe-ideas\"><i><strong>On \"fringe\" ideas</strong></i></a><i>\u201d</i></p><p>By&nbsp;<a href=\"https://forum.effectivealtruism.org/users/kelsey-piper-1\">Kelsey Piper</a>&nbsp;2019\u5e74 8\u670819\u65e5</p><h2>\u30d6\u30ed\u30b0\u3078\u306e\u8cea\u554f</h2><p>EA\u306e\u4e3b\u6d41\u304b\u3089\u9038\u8131\u3057\u305f\u90e8\u5206\u306b\u95a2\u3057\u3066\u3069\u306e\u3088\u3046\u306b\u601d\u3063\u3066\u3044\u307e\u3059\u304b\uff1f</p><p>\u79c1\u306f\u3001EA\u3092\u540d\u4e57\u308b\u4eba\u305f\u3061\u304c\u61b6\u6e2c\u306b\u3088\u308b\u30a8\u30c3\u30bb\u30a4\u3092\u66f8\u304f\u3053\u3068\u306b\u6642\u9593\u3092\u8cbb\u3084\u3057\u3066\u3044\u308b\u306e\u3092\u898b\u3066\u3001\u672c\u5f53\u306b\u8179\u304c\u7acb\u3061\u307e\u3059\u3002\u4f8b\u3048\u3070\uff08\u6700\u8fd1\u51fa\u4f1a\u3063\u305f\u4eba\u305f\u3061\u306e\u8a71\u304b\u3089\u5f15\u7528\u3059\u308b\u3068\uff09\u3001\u91ce\u751f\u3067\u751f\u304d\u308b\u52d5\u7269\u306f\u82e6\u3057\u3093\u3067\u3044\u308b\u304b\u3089\u91ce\u751f\u52d5\u7269\u306e\u4fdd\u8b77\u306f\u5b9f\u969b\u306b\u306f\u826f\u3044\u3053\u3068\u3067\u306f\u306a\u3044\u3001\u3068\u3044\u3046\u3088\u3046\u306a\u3082\u306e\u3067\u3059\u3002\u3053\u3046\u3044\u3063\u305f\u3053\u3068\u3092\u8003\u3048\u308b\u306e\u306f\u697d\u3057\u3044\u3068\u306f\u601d\u3044\u307e\u3059\u304c\u3001\u3053\u308c\u3089\u304c\u30b0\u30ed\u30fc\u30d0\u30eb\u306a\u767a\u5c55\u3084\u9577\u671f\u7684\u306a\u6301\u7d9a\u53ef\u80fd\u6027\u3068\u3044\u3063\u305f\u8ab2\u984c\u306b\u5339\u6575\u3059\u308b\u3068\u8003\u3048\u308b\u4eba\u304c\u76ee\u6307\u3057\u3066\u3044\u308b\u3082\u306e\u3068\u3001\u79c1\u304cEA\u3068\u3057\u3066\u76ee\u6307\u3057\u3066\u3044\u308b\u3082\u306e\u306f\u5168\u304f\u7570\u306a\u308a\u307e\u3059\u3002</p><p>\u3053\u3061\u3089\u306b\u95a2\u3057\u3066\u30b1\u30eb\u30b7\u30fc\u3055\u3093\u306e\u3054\u610f\u898b\u3092\u805e\u304b\u305b\u3066\u3044\u305f\u3060\u3051\u307e\u3059\u3067\u3057\u3087\u3046\u304b\u3002\u30b1\u30eb\u30b7\u30fc\u3055\u3093\u306f\u3069\u3093\u306a\u306b\u4e3b\u6d41\u304b\u3089\u5916\u308c\u305f\u5947\u629c\u306a\u30a2\u30a4\u30c7\u30a3\u30a2\u3082\u304d\u3061\u3093\u3068\u8a55\u4fa1\u3057\u3066\u304f\u308c\u308b\u306e\u3067\u3001\u3044\u3064\u3082\u5927\u5909\u52c9\u5f37\u306b\u306a\u3063\u3066\u3044\u307e\u3059\u3002</p><h2>\u30b1\u30eb\u30b7\u30fc\u306e\u8fd4\u7b54</h2><p>\u3053\u306e\u3053\u3068\u3092\u8003\u3048\u308b\u4e0a\u3067\u79c1\u306e\u601d\u8003\u5f62\u6210\u306b\u5927\u304d\u306a\u5f71\u97ff\u3092\u4e0e\u3048\u305f\u306e\u306f\u3001\u52b9\u679c\u7684\u5229\u4ed6\u4e3b\u7fa9\u304c\u6b74\u53f2\u306e\u4e2d\u306e\u3055\u307e\u3056\u307e\u306a\u77ac\u9593\u306b\u5b58\u5728\u3057\u3066\u3044\u305f\u3068\u60f3\u50cf\u3059\u308b\u3053\u3068\u3067\u3059\u3002\u79c1\u305f\u3061\u306f\u4f55\u304b\u826f\u3044\u3053\u3068\u3092\u3057\u3066\u3044\u305f\u306e\u3067\u3057\u3087\u3046\u304b\u3001\u305d\u308c\u3068\u3082\u305d\u306e\u6642\u4ee3\u306e\u524d\u63d0\u306b\u3068\u3089\u308f\u308c\u3059\u304e\u3066\u3044\u305f\u306e\u3067\u3057\u3087\u3046\u304b\uff1f</p><p>1840\u5e74\u4ee3\u306e\u52b9\u679c\u7684\u5229\u4ed6\u4e3b\u7fa9\u904b\u52d5\u306f\u3001\u5974\u96b7\u5236\u5ec3\u6b62\u904b\u52d5\u3092\u63a8\u9032\u3057\u3066\u3044\u305f\u3067\u3057\u3087\u3046\u304b\uff1f\u3082\u3057\u79c1\u305f\u3061\u304c\u5974\u96b7\u5236\u306b\u7acb\u3061\u5411\u304b\u3046\u3053\u3068\u306b\u5931\u6557\u3057\u3066\u3044\u305f\u3060\u308d\u3046\u3068\u8003\u3048\u308b\u306e\u3067\u3042\u308c\u3070\u3001\u540c\u3058\u3088\u3046\u306b\u5927\u304d\u306a\u9593\u9055\u3044\u3092\u72af\u3055\u306a\u3044\u3088\u3046\u306b\u3001\u4eca\u3001\u6d3b\u52d5\u3068\u3057\u3066\u4f55\u3092\u5909\u3048\u308b\u5fc5\u8981\u304c\u3042\u308b\u3067\u3057\u3087\u3046\u304b\uff1f</p><p>1920\u5e74\u4ee3\u306e\u52b9\u679c\u7684\u5229\u4ed6\u4e3b\u7fa9\u904b\u52d5\u306f\u3001\u512a\u751f\u601d\u60f3\u306b\u652f\u914d\u3055\u308c\u3066\u3044\u305f\u306e\u3067\u3057\u3087\u3046\u304b\uff1f\u3082\u3057\u79c1\u305f\u3061\u304c\u9032\u6b69\u4e3b\u7fa9\u6642\u4ee3\u306e\u4e0d\u598a\u624b\u8853\u30ad\u30e3\u30f3\u30da\u30fc\u30f3\u306e\u3088\u3046\u306a\u7591\u4f3c\u79d1\u5b66\u7684\u3067\u975e\u5e38\u306b\u6709\u5bb3\u306a\u904b\u52d5\u3092\u53d7\u3051\u5165\u308c\u3066\u3044\u305f\u3060\u308d\u3046\u3068\u8003\u3048\u308b\u306e\u3067\u3042\u308c\u3070\u3001\u3069\u306e\u3088\u3046\u306a\u8003\u3048\u65b9\u3084\u601d\u8003\u306e\u7fd2\u6163\u3092\u6301\u3063\u3066\u3044\u308c\u3070\u3053\u306e\u3088\u3046\u306a\u4e8b\u614b\u3092\u9632\u3052\u305f\u3067\u3057\u3087\u3046\u304b\uff1f\u307e\u305f\u305d\u306e\u7fd2\u6163\u3092\u79c1\u305f\u3061\u306f\u4eca\u65e5\u3001\u7a4d\u6975\u7684\u306b\u7528\u3044\u3066\u3044\u308b\u3067\u3057\u3087\u3046\u304b\uff1f</p><p>\u52b9\u679c\u7684\u5229\u4ed6\u4e3b\u7fa9\u304c\u5f37\u56fa\u306b\u5584\u3067\u3042\u308b\u305f\u3081\u306b\u306f\u3001\u8a00\u3044\u63db\u3048\u308c\u3070\u3001\u5de8\u60aa\u3092\u884c\u3046\u793e\u4f1a\u3084\u3001\u5b8c\u5168\u306b\u898b\u5f53\u9055\u3044\u306e\u554f\u3044\u3092\u4e2d\u5fc3\u3068\u3059\u308b\u793e\u4f1a\u3001\u53e3\u5148\u3060\u3051\u306e\u300c\u6148\u5584\u5bb6\u300d\u306e\u7dcf\u610f\u306f\u3042\u308b\u3082\u306e\u306e\u5b9f\u969b\u306b\u306f\u6700\u60aa\u306e\u793e\u4f1a\u306b\u3042\u3063\u3066\u3082\u3001\u5584\u3092\u884c\u3046\u3053\u3068\u304c\u3067\u304d\u308b\u904b\u52d5\u3067\u3042\u308b\u305f\u3081\u306b\u306f\u3001\u591a\u304f\u306e\u3053\u3068\u304c\u6b63\u3057\u304f\u306a\u3055\u308c\u3066\u3044\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044\u3068\u79c1\u306f\u601d\u3044\u307e\u3059\u3002</p><p>\u307e\u305a\u5b9f\u969b\u306b\u3001\u6700\u3082\u5fc5\u8981\u3068\u3057\u3066\u3044\u308b\u4eba\u306e\u305f\u3081\u306b\u306a\u308b\u3053\u3068\u3092\u884c\u308f\u306a\u3051\u308c\u3070\u306a\u308a\u307e\u305b\u3093\u3002\u6628\u5e74\u3001GiveWell \u3092\u901a\u3058\u3066\u30c8\u30c3\u30d7\u30c1\u30e3\u30ea\u30c6\u30a3\u30fc\u306b\u6e21\u3063\u305f\u5bc4\u4ed8\u91d1\u306f\u30016,500\u4e07\u30c9\u30eb\uff08\u7d0495\u5104\u5186\uff09\u306b\u5897\u52a0\u3057\u307e\u3057\u305f\uff08Good Ventures \u304b\u3089\u306e\u5bc4\u4ed8\u91d1\u3092\u9664\u304f\uff09\u3002\u3082\u3057\u3001\u3053\u306e\u6570\u5b57\u304c\u7acb\u6d3e\u306a\u3082\u306e\u3067\u306a\u304f\u3001\u5897\u52a0\u3057\u3066\u3044\u306a\u304b\u3063\u305f\u3068\u3057\u305f\u3089\u3001\u30b3\u30df\u30e5\u30cb\u30c6\u30a3\u3068\u3057\u3066\u5931\u6557\u3057\u3066\u3044\u308b\u306e\u3067\u306f\u306a\u3044\u304b\u3068\u79c1\u306f\u5fc3\u914d\u306b\u306a\u3063\u3066\u3044\u305f\u3067\u3057\u3087\u3046\u3002\u79c1\u305f\u3061\u306f\u5b9f\u969b\u306e\u7d50\u679c\u306b\u5bfe\u3057\u3066\u8cac\u4efb\u3092\u6301\u3064\u3068\u3044\u3046\u5b9f\u614b\u306e\u78ba\u8a8d\u304c\u5fc5\u8981\u306a\u306e\u3067\u3059\u3002\u5b9f\u969b\u306b\u884c\u52d5\u3059\u308b\u3053\u3068\u304c\u5fc5\u8981\u306a\u306e\u3067\u3059\u3002</p><p>\u6b21\u306b\u3001\u8003\u3048\u3089\u308c\u308b<strong>\u3055\u307e\u3056\u307e\u306a\u4e16\u754c\u89b3</strong>\u306b\u7167\u3089\u3057\u5408\u308f\u305b\u3066\u3001\u79c1\u305f\u3061\u304c\u884c\u3063\u3066\u3044\u308b\u3053\u3068\u304c\u5b9f\u969b\u306b\u306f\u5bb3\u3092\u53ca\u307c\u3057\u3066\u3044\u308b\u3068\u3044\u3046\u30b5\u30a4\u30f3\u3092\u5e38\u306b\u76e3\u8996\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\u3053\u308c\u306b\u306f\u3001\u76f4\u611f\u7684\u3067\u306a\u3044\u4e16\u754c\u89b3\u3084\u3001\u305f\u3044\u3066\u3044\u306e\u4eba\u306e\u30c1\u30e3\u30ea\u30c6\u30a3\u30fc\u3078\u306e\u8003\u3048\u65b9\u3068\u306f\u7570\u306a\u308b\u4e16\u754c\u89b3\u3082\u542b\u307e\u308c\u307e\u3059\u3002\u3082\u3057\u53d7\u3051\u53d6\u308a\u624b\u304c\u5e78\u305b\u3067\u306a\u3044\u306a\u3089\u3001\u305d\u308c\u306f\u5371\u967a\u306a\u30b5\u30a4\u30f3\u3067\u3059\u3002\u79c1\u305f\u3061\u306e\u52aa\u529b\u304c\u82e6\u3057\u307f\u3092\u5897\u5927\u3055\u305b\u308b\u306e\u3067\u3042\u308c\u3070\u3001\u305f\u3068\u3048\u305d\u308c\u304c\u771f\u5263\u306b\u306f\u53d7\u3051\u6b62\u3081\u306b\u304f\u3044\u5909\u308f\u3063\u305f\u72b6\u6cc1\u3067\u3082\u3001\u305d\u308c\u306f\u5371\u967a\u306a\u30b5\u30a4\u30f3\u3067\u3059\u3002\u6b63\u3057\u3044\u7b54\u3048\u304c\u5c11\u306a\u304f\u3068\u3082\u624b\u306b\u306f\u5165\u308b\u3088\u3046\u306b\u3001\u79c1\u305f\u3061\u306f\u8003\u3048\u3089\u308c\u308b\u5931\u6557\u306e\u4ed5\u65b9\u306b\u5bfe\u3057\u3066\u3001\u672c\u5f53\u306b\u3001\u672c\u5f53\u306b\u5e83\u3044\u7bc4\u56f2\u3092\u8996\u91ce\u306b\u5165\u308c\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002</p><p>\u6b21\u306b\u3001\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u72b6\u6cc1\u3092\u60f3\u50cf\u3057\u3066\u307f\u3066\u304f\u3060\u3055\u3044\u30021840\u5e74\u4ee3\u306eEA\u30b0\u30eb\u30fc\u30d7\u306b\u8ab0\u304b\u304c\u5165\u3063\u3066\u304d\u3066\u300c\u9ed2\u4eba\u306f\u767d\u4eba\u3068\u307e\u3063\u305f\u304f\u540c\u3058\u3088\u3046\u306b\u4fa1\u5024\u304c\u3042\u308b\u3068\u601d\u3046\u3002\u5f7c\u3089\u3092\u5dee\u5225\u3059\u308b\u3053\u3068\u306f\u7d76\u5bfe\u306b\u9055\u6cd5\u3067\u3042\u308b\u3079\u304d\u3060 \u300d\u3068\u8a00\u3063\u3066\u3044\u307e\u3059\u3002\u3042\u308b\u3044\u306f\u30011920\u5e74\u4ee3\u306eEA\u30b0\u30eb\u30fc\u30d7\u306b\u8ab0\u304b\u304c\u5165\u3063\u3066\u304d\u3066 \u300c\u540c\u6027\u611b\u8005\u306e\u6a29\u5229\u306f\u672c\u5f53\u306b\u91cd\u8981\u3060\u3068\u601d\u3046\u300d\u3068\u8a00\u3063\u3066\u3044\u307e\u3059\u3002\u79c1\u306f\u3001\u79c1\u305f\u3061\u304c\u3053\u3046\u3044\u3063\u305f\u4eba\u305f\u3061\u3092\u8ffd\u3044\u51fa\u3055\u306a\u3044\u3088\u3046\u306a\u30b3\u30df\u30e5\u30cb\u30c6\u30a3\u3067\u3042\u308a\u305f\u3044\u3068\u601d\u3063\u3066\u3044\u307e\u3059\u3002\u79c1\u305f\u3061\u304c\u5b88\u308b\u3079\u304d\u539f\u5247\u306f\u3001\u300c\u6c17\u306b\u304b\u3051\u308b\uff08care\uff09\u306b\u306f\u5024\u3057\u306a\u3044\u3068\u4e16\u9593\u3067\u898b\u306a\u3055\u308c\u3066\u3044\u308b\u5b58\u5728\u3092<strong>\u3082\u3063\u3068</strong>\u6c17\u306b\u304b\u3051\u308b\u3079\u304d\u3067\u3042\u308b\u3068\u3044\u3046\u4e3b\u5f35\u304c\u3042\u308b\u306a\u3089\u3070\u3001\u305f\u3068\u3048\u305d\u306e\u4e3b\u5f35\u304c\u304b\u306a\u308a\u4e0d\u5408\u7406\u306b\u805e\u3053\u3048\u305f\u3068\u3057\u3066\u3082\u3001\u305d\u308c\u3092\u7814\u7a76\u3059\u308b\u4eba\u305f\u3061\u3092\u652f\u6301\u3059\u308b\u3002\u305d\u3057\u3066\u3001\u3082\u3057\u5f7c\u3089\u304c\u3001\u3059\u3079\u3066\u306e\u4eba\u306e\u5e78\u798f\u3068\u7e41\u6804\u3092\u53ef\u80fd\u306a\u9650\u308a\u5897\u5927\u3055\u305b\u308b\u3068\u8a00\u3046\u610f\u56f3\u3067\u305d\u306e\u7814\u7a76\u3092\u884c\u3063\u3066\u3044\u308b\u306e\u3067\u3042\u308c\u3070\u3001\u5f7c\u3089\u306f\u79c1\u305f\u3061\u306e\u6d3b\u52d5\u306e\u4e00\u54e1\u3067\u3042\u308b\u300d\u3068\u3044\u3063\u305f\u3082\u306e\u306b\u306a\u308b\u3067\u3057\u3087\u3046\u3002</p><p>\u3053\u308c\u304c\u3001\u79c1\u304c\u671b\u3080\u52b9\u679c\u7684\u5229\u4ed6\u4e3b\u7fa9\u3092\u5b9f\u8df5\u3059\u308b\u4e0a\u3067\u306e\u3001\u6d3b\u52d5\u30ec\u30d9\u30eb\u306e\u5927\u539f\u5247\u3067\u3059\u3002\u3067\u3059\u304b\u3089\u3001\u793e\u4f1a\u306f\u91cd\u8981\u306a\u3053\u3068\u306b\u95a2\u3057\u3066\u5927\u304d\u304f\u9593\u9055\u3063\u3066\u3044\u308b\u3068\u3044\u3046\u8003\u3048\u65b9\u306b\u5bfe\u3057\u3066\u30aa\u30fc\u30d7\u30f3\u3067\u3042\u308a\u3001\u3088\u308a\u591a\u304f\u306e\u3053\u3068\u3092\u6c17\u306b\u304b\u3051\u308b\u305f\u3081\u306e\u52aa\u529b\u3092\u652f\u63f4\u3057\u3001\u9593\u9055\u3044\u3046\u308b\u65b9\u6cd5\u306b\u5bfe\u3057\u3066\u306f\u5e83\u3044\u8996\u91ce\u3092\u6301\u3063\u3066\u3088\u308a\u591a\u304f\u306e\u3053\u3068\u3092\u8003\u616e\u306b\u5165\u308c\u3066\u307b\u3057\u3044\u3068\u3001\u79c1\u306f\u601d\u3063\u3066\u3044\u307e\u3059\u3002\u6700\u5f8c\u306b\u3001\u3053\u308c\u3089\u306e\u53d6\u308a\u7d44\u307f\u304c\u5b9f\u969b\u306b\u4eba\u3005\u306e\u5f79\u306b\u7acb\u3064\u3088\u3046\u306a\u5730\u306b\u8db3\u306e\u7740\u3044\u305f\u3082\u306e\u306b\u306a\u308b\u3088\u3046\u3001\u5177\u4f53\u7684\u306a\u512a\u5148\u4e8b\u9805\u306b\u5272\u308a\u5f53\u3066\u308b\u30ea\u30bd\u30fc\u30b9\u306e\u5897\u52a0\u3068\u3068\u3082\u306b\u3001\u4e0a\u8a18\u306e\u3059\u3079\u3066\u304c\u5b9f\u73fe\u3059\u308b\u3088\u3046\u306b\u3057\u305f\u3044\u306e\u3067\u3059\u3002</p><p>\u8a00\u3044\u63db\u3048\u308c\u3070\u3001\u3069\u3093\u306a\u6642\u3067\u3082\u78ba\u304b\u3067\u660e\u3089\u304b\u306b\u91cd\u8981\u306a\u3053\u3068\u306e\u305f\u3081\u306b\u79c1\u305f\u3061\u306e\u52aa\u529b\u306e\u5927\u90e8\u5206\u304c\u3055\u3055\u3052\u3089\u308c\u308b\u3053\u3068\u3092\u671f\u5f85\u3057\u3066\u3044\u307e\u3059\u3002\u305d\u308c\u3068\u540c\u6642\u306b\u3001\u3088\u308a\u601d\u7d22\u7684\u306a\u3053\u3068\u3092\u805e\u304f\u305f\u3081\u306e\u30b9\u30da\u30fc\u30b9\u3001\u7279\u306b\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u3053\u3068\u306b\u8033\u3092\u50be\u3051\u308b\u305f\u3081\u306e\u30b9\u30da\u30fc\u30b9\u304c\u3042\u308c\u3070\u3044\u3044\u3068\u601d\u3044\u307e\u3059\u3002\uff08\uff11\uff09\u666e\u901a\u306f\u6c17\u306b\u304b\u3051\u3088\u3046\u3068\u3082\u601d\u308f\u306a\u3044\u3088\u3046\u306a\u3053\u3068\u3092\u6c17\u306b\u304b\u3051\u308b\u3079\u304d\u3060\u3068\u3044\u3046\u4e3b\u5f35\u3001\uff08\uff12\uff09\u3053\u306e\u793e\u4f1a\u304c\u6839\u672c\u7684\u304b\u3064\u6df1\u523b\u306b\u9593\u9055\u3063\u3066\u3044\u308b\u3068\u3044\u3046\u4e3b\u5f35\u3001\uff08\uff13\uff09\u79c1\u305f\u3061\u304c\u91cd\u8981\u306a\u9593\u9055\u3044\u3092\u72af\u3057\u3066\u3044\u308b\u3068\u3044\u3046\u4e3b\u5f35\u3002</p><p>\u306a\u306e\u3067\u3001\u305f\u3068\u3048\u305d\u306e\u6d3b\u52d5\u304c\u304b\u306a\u308a\u601d\u7d22\u7684\u3067\u3042\u3063\u3066\u3082\u3001\u305f\u3068\u3048\u79c1\u3068\u306f\u7570\u306a\u308b\u3053\u3068\u3092\u6c17\u306b\u304b\u3051\u3066\u3044\u3066\u3082\u3001\u516c\u5e73\u3067\u3001\u5584\u3092\u6700\u5927\u5316\u3059\u308b\u3001\u7d50\u679c\u91cd\u8996\u306e\u3084\u308a\u65b9\u3067\u3001\u4e16\u306e\u4e2d\u306b\u3067\u304d\u308b\u3060\u3051\u3088\u3044\u3053\u3068\u3092\u3057\u3088\u3046\u3068\u3057\u3066\u3044\u308b\u306e\u3067\u3042\u308c\u3070\u3001\u79c1\u304c\u305d\u3046\u3044\u3063\u305f\u4eba\u3005\u306bEA\u3068\u540d\u4e57\u3063\u3066\u307b\u3057\u3044\u3068\u601d\u3046\u7406\u7531\u306e\u4e00\u3064\u306e\u898b\u65b9\u306b\u306a\u308b\u3067\u3057\u3087\u3046\u3002</p><p>\u3064\u307e\u308a\u3001\u591a\u304f\u306eEA\u30e1\u30f3\u30d0\u30fc\u304c\u4e92\u3044\u306b\u5168\u304f\u7570\u306a\u308b\u76ee\u6a19\u3092\u6301\u3063\u3066\u3044\u308b\u3053\u3068\u306b\u306a\u308a\u307e\u3059\u3002\u305d\u308c\u3067\u3044\u3044\u306e\u3067\u3059\u3002EA\u30e1\u30f3\u30d0\u30fc\u304c\u305f\u3063\u305f\u4e00\u3064\u306e\u512a\u5148\u4e8b\u9805\u3092\u7686\u3067\u5171\u6709\u3059\u308b\u3053\u3068\u306b\u53cd\u5bfe\u3059\u308b\u4e3b\u306a\u7406\u7531\u306f\u3001\u4ed6\u306e\u4e8b\u9805\u304c\u6700\u3082\u91cd\u8981\u3067\u3042\u308b\u3068\u8aac\u5f97\u3055\u308c\u3001\u512a\u5148\u3057\u3066\u3044\u305f\u6d3b\u52d5\u304b\u3089\u96e2\u308c\u306a\u3051\u308c\u3070\u306a\u304f\u306a\u3063\u305f\u6642\u306b\u3001\u81ea\u5206\u305f\u3061\u306e\u8003\u3048\u3092\u5909\u3048\u308b\u3053\u3068\u306b\u975e\u5e38\u306b\u6d88\u6975\u7684\u306b\u306a\u3063\u3066\u3057\u307e\u3046\u304b\u3089\u3067\u3059\u3002\u4f55\u304c\u4e00\u756a\u91cd\u8981\u306a\u3053\u3068\u306a\u306e\u304b\u304c\u660e\u3089\u304b\u3067\u306f\u306a\u3044\u4ee5\u4e0a\u3001\u516c\u5e73\u3067\u3001\u5584\u3092\u6700\u5927\u5316\u3059\u308b\u3001\u7d50\u679c\u91cd\u8996\u306e\u3084\u308a\u65b9\u3067\u3001\u3067\u304d\u308b\u3060\u3051\u3088\u3044\u3053\u3068\u3092\u3057\u3088\u3046\u3068\u3001<strong>\u7686\u3067</strong>\u6311\u6226\u3059\u308b\u904b\u52d5\u304c\u3042\u3063\u305f\u307b\u3046\u304c\u3088\u307b\u3069\u52b9\u679c\u7684\u306a\u306e\u3067\u3059\u3002</p><p>\u52a0\u3048\u3066\u3001\u91ce\u751f\u52d5\u7269\u306e\u82e6\u3057\u307f\u306f\u7814\u7a76\u3059\u308b\u4fa1\u5024\u304c\u3042\u308b\u5206\u91ce\u3060\u3068\u3044\u3046\u975e\u5e38\u306b\u5177\u4f53\u7684\u306a\u8ad6\u62e0\u304c\u3042\u308b\u3068\u601d\u3044\u307e\u3059\u3002</p><p>\u4eca\u73fe\u5728\u3001\u52d5\u7269\u3001\u7279\u306b\u91ce\u751f\u52d5\u7269\u304c\u3069\u306e\u3088\u3046\u306a\u751f\u6d3b\u3092\u3057\u3066\u3044\u308b\u306e\u304b\u306f\u307b\u3068\u3093\u3069\u7814\u7a76\u3055\u308c\u3066\u3044\u307e\u305b\u3093\u3002\u6c17\u5019\u5909\u52d5\u3084\u74b0\u5883\u5bfe\u7b56\u3001\u571f\u5730\u5229\u7528\u306e\u5909\u5316\u306b\u95a2\u3059\u308b\u7814\u7a76\u306e\u306a\u304b\u3067\u3001\u3053\u308c\u3089\u306e\u8981\u7d20\u304c\u52d5\u7269\u306e\u82e6\u3057\u307f\u306b\u3069\u306e\u3088\u3046\u306a\u5f71\u97ff\u3092\u4e0e\u3048\u3066\u3044\u308b\u306e\u304b\u3068\u3044\u3046\u3053\u3068\u3092\u8abf\u3079\u3066\u3044\u308b\u3082\u306e\u306f\u307b\u3068\u3093\u3069\u7686\u7121\u3067\u3059\u3002\u3053\u306e\u3088\u3046\u306a\u7591\u554f\u306b\u7126\u70b9\u3092\u5f53\u3066\u305f\u65b0\u3057\u3044\u7814\u7a76\u5206\u91ce\u3068\u3057\u3066\u3001\u30a6\u30a7\u30eb\u30d5\u30a7\u30a2\u30fb\u30d0\u30a4\u30aa\u30ed\u30b8\u30fc\u3068\u3044\u3046\u3082\u306e\u304c\u3042\u308a\u307e\u3059\u3002\u30a6\u30a7\u30eb\u30d5\u30a7\u30a2\u30fb\u30d0\u30a4\u30aa\u30ed\u30b8\u30fc\u306e\u57fa\u790e\u7814\u7a76\u306f\u3001\u958b\u767a\u7d4c\u6e08\u5b66\u3084\u533b\u5b66\u306e\u57fa\u790e\u7814\u7a76\u306e\u3088\u3046\u306b\u3001\u4eca\u304b\u308910\u5e74\u5f8c\u3001\u3069\u306e\u3088\u3046\u306a\u4ecb\u5165\u7b56\u304c\u826f\u3044\u30a2\u30a4\u30c7\u30a3\u30a2\u3067\u3042\u308b\u304b\u306e\u7406\u89e3\u306b\u5287\u7684\u306a\u5f71\u97ff\u3092\u4e0e\u3048\u308b\u3053\u3068\u306b\u306a\u308b\u3068\u601d\u3044\u307e\u3059\u3002</p><p>\u30ef\u30af\u30c1\u30f3\u3092\u958b\u767a\u3059\u308b\u4eba\u3084\u30b0\u30ed\u30fc\u30d0\u30eb\u958b\u767a\u3092\u7814\u7a76\u3059\u308b\u4eba\u306bEA\u306b\u5165\u3063\u3066\u307b\u3057\u3044\u3088\u3046\u306b\u3001\u30a6\u30a7\u30eb\u30d5\u30a7\u30a2\u30fb\u30d0\u30a4\u30aa\u30ed\u30b8\u30fc\u3092\u7814\u7a76\u3059\u308b\u4eba\u306b\u3082EA\u306b\u5165\u3063\u3066\u307b\u3057\u3044\u3068\u601d\u3063\u3066\u3044\u307e\u3059\u3002\u3053\u308c\u306f\u3001\u4e0a\u3067\u8ff0\u3079\u305f\u601d\u7d22\u7684\u306a\u6d3b\u52d5\u304c\u4e00\u822c\u7684\u306b\u826f\u3044\u3068\u3044\u3046\u8b70\u8ad6\u306b\u3088\u308b\u3082\u306e\u3067\u306f\u3042\u308a\u307e\u305b\u3093\u3002\u3053\u306e\u4e3b\u5f35\u306e\u6838\u5fc3\u306f\u3001\u300c\u30a6\u30a7\u30eb\u30d5\u30a7\u30a2\u30fb\u30d0\u30a4\u30aa\u30ed\u30b8\u30fc\u306f\u3001\u3067\u304d\u308b\u304b\u304e\u308a\u591a\u304f\u306e\u3088\u3044\u3053\u3068\u3092\u884c\u3046\u3053\u3068\u306b\u95a2\u9023\u3059\u308b\u91cd\u8981\u306a\u7814\u7a76\u8ab2\u984c\u3092\u62b1\u3048\u3066\u3044\u308b\u5206\u91ce\u306e\u3088\u3046\u306b\u898b\u3048\u308b\u300d\u3068\u3044\u3046\u3053\u3068\u3067\u3059\u3002\u3053\u306e\u5206\u91ce\u304c\u307e\u3060\u751f\u307e\u308c\u3066\u9593\u3082\u306a\u3044\u6bb5\u968e\u3067\u3042\u308b\u3053\u3068\u3092\u8003\u3048\u308b\u3068\u3001\u30b3\u30a2\u3068\u306a\u308b\u8ad6\u70b9\u304c\u304b\u306a\u308a\u4e0d\u78ba\u304b\u306a\u3082\u306e\u3067\u3042\u308b\u306b\u3082\u304b\u304b\u308f\u3089\u305a\u3001\u79c1\u306f\u3053\u306e\u5206\u91ce\u304c10\u5e74\u5f8c\u306b\u306f\u3069\u306e\u3088\u3046\u306b\u306a\u3063\u3066\u3044\u308b\u306e\u304b\u30ef\u30af\u30ef\u30af\u3057\u3066\u3044\u307e\u3059\u3002</p><p>\u6700\u5f8c\u306b\u3082\u3046\u3072\u3068\u3064\u3002\u4e16\u754c\u306b\u306f\u3072\u3069\u3044\u554f\u984c\u304c\u591a\u304f\u3042\u308a\u3001\u305d\u308c\u3089\u306e\u554f\u984c\u306b\u53d6\u308a\u7d44\u3080\u4e00\u4eba\u4e00\u4eba\u306b\u3067\u304d\u308b\u3053\u3068\u304c\u305f\u304f\u3055\u3093\u3042\u308b\u305f\u3081\u3001\u8ab0\u304b\u304c\u6642\u9593\u3092\u7121\u99c4\u306b\u3057\u3066\u3044\u308b\u306e\u3092\u6c17\u306b\u3057\u306a\u3044\u3088\u3046\u306b\u3059\u308b\u3053\u3068\u306f\u306a\u304b\u306a\u304b\u96e3\u3057\u3044\u3067\u3059\u3002\u4f55\u3057\u308d\u3001\u305d\u306e\u4eba\u304c\u6642\u9593\u3092\u6709\u52b9\u306b\u4f7f\u3048\u3070\u3001\u3082\u3063\u3068\u826f\u3044\u3053\u3068\u304c\u3067\u304d\u308b\u306f\u305a\u306a\u306e\u3067\u3059\uff01\u3057\u304b\u3057\u3001\u9577\u671f\u7684\u306b\u306f\u3001\u6700\u3082\u91cd\u8981\u306a\u3053\u3068\u306b\u3064\u3044\u3066\u8aa4\u3063\u305f\u8003\u3048\u3092\u3057\u3066\u3044\u308b\u4eba\u306b\u8179\u3092\u7acb\u3066\u308b\u3053\u3068\u306f\u3001\u6301\u7d9a\u53ef\u80fd\u3067\u306f\u306a\u3044\u3068\u601d\u3044\u307e\u3059\u3002<strong>\u3053\u3053\u6570\u5e74\u3067\u3001\u7269\u4e8b\u3092\u6b63\u3057\u304f\u7406\u89e3\u3059\u308b\u3053\u3068\u304c\u3044\u304b\u306b\u96e3\u3057\u304f\u3066\u3001\u73fe\u5b9f\u306f\u3044\u304b\u306b\u8907\u96d1\u3067\u7dfb\u5bc6\u304b\u3068\u3044\u3046\u3053\u3068\u3092\u75db\u611f\u3057\u3001\u8003\u3048\u65b9\u304c\u5927\u304d\u304f\u5909\u308f\u308a\u307e\u3057\u305f\u3002\u305d\u306e\u304a\u304b\u3052\u3067\u3001\u5b8c\u5168\u306b\u9593\u9055\u3063\u3066\u3044\u308b\u3068\u79c1\u306b\u306f\u601d\u3048\u308b\u4eba\u3092\u898b\u3066\u3001\u5f7c\u3089\u304c\u52aa\u529b\u3057\u3066\u3044\u308b\u3053\u3068\u3092\u5b09\u3057\u304f\u601d\u3044\u3001\u5f7c\u3089\u304c\u9032\u3093\u3067\u3044\u308b\u9053\u306e\u5148\u306b\u4f55\u304b\u751f\u7523\u7684\u306a\u6210\u679c\u304c\u3042\u308b\u306e\u3067\u306f\u306a\u3044\u304b\u3068\u671f\u5f85\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u308a\u307e\u3057\u305f\u3002</strong>EA\u3067\u601d\u7d22\u7684\u306a\u7814\u7a76\u3092\u3057\u3066\u3044\u308b\u4eba\u305f\u3061\u306f\u7686\u3001\u4e16\u754c\u3092\u3088\u308a\u826f\u3044\u5834\u6240\u306b\u3057\u3088\u3046\u3068\u672c\u5f53\u306b\u6df1\u304f\u8003\u3048\u3066\u3044\u308b\u3068\u601d\u3044\u307e\u3059\u3057\u3001\u500b\u4eba\u7684\u306b\u306f\u5f7c\u3089\u306e\u591a\u304f\u304c\u7684\u5916\u308c\u3060\u3068\u601d\u3044\u307e\u3059\u304c\u3001\u305d\u308c\u3067\u3082\u5f7c\u3089\u306e\u7814\u7a76\u304c\u3001\u4f55\u304b\u3092\u89e3\u6c7a\u3059\u308b\u306e\u306b\u5f79\u7acb\u3064\u91cd\u8981\u306a\u3053\u3068\u3092\u6559\u3048\u3066\u304f\u308c\u308b\u3053\u3068\u3092\u5f37\u304f\u671b\u3093\u3067\u3044\u307e\u3059\u3002</p>", "user": {"username": "EA Japan"}}, {"_id": "Hb7naapt7k4S27QHj", "title": "\u9053\u5fb3\u7684\u9032\u6b69\u3068\u300c\u8ab2\u984c X\u300d", "postedAt": "2023-07-28T15:28:40.470Z", "htmlBody": "<p><i>This is a Japanese translation of \u201c</i><a href=\"https://forum.effectivealtruism.org/posts/9K8Yiv9Fdm7XNsmCm/moral-progress-and-cause-x\"><i><strong>Moral progress and \"Cause X\"</strong></i></a><i>\u201d</i></p><p>by&nbsp;<a href=\"https://forum.effectivealtruism.org/users/ea-global\"><u>EA Global</u></a> 2016\u5e748\u67085\u65e5&nbsp;</p><p>\u52b9\u679c\u7684\u5229\u4ed6\u4e3b\u7fa9\u30b3\u30df\u30e5\u30cb\u30c6\u30a3\u306f2009\u5e74\u306b\u59cb\u52d5\u3057\u3066\u4ee5\u6765\u3001\u9a5a\u7570\u7684\u306a\u6210\u9577\u3092\u9042\u3052\u3066\u304d\u307e\u3057\u305f\u3002EA \u30b0\u30ed\u30fc\u30d0\u30eb\u30fb\u30b5\u30f3\u30d5\u30e9\u30f3\u30b7\u30b9\u30b32016\u306e\u30aa\u30fc\u30d7\u30cb\u30f3\u30b0\u30b9\u30d4\u30fc\u30c1\uff08<a href=\"https://www.youtube.com/watch?v=VH2LhSod1M4\"><u>YouTube</u></a>\uff09\u3067\u306f\u3001\u30c8\u30d3\u30fc\u30fb\u30aa\u30fc\u30c9\u3068\u30a6\u30a3\u30eb\u30fb\u30de\u30ab\u30b9\u30ad\u30eb\u304cEA\u306e\u6b74\u53f2\u306b\u3064\u3044\u3066\u8a9e\u308a\u3001\u3053\u308c\u304b\u3089\u306e\u6d3b\u52d5\u3067\u4f55\u304c\u8d77\u3053\u308b\u304b\u3092\u8003\u5bdf\u3057\u3066\u3044\u307e\u3059\u3002</p><p>\u4ee5\u4e0b\u3067\u306f\u3001\u305d\u306e\u30b9\u30d4\u30fc\u30c1\u304b\u3089\u306e\u629c\u7c8b\u3092\u7d39\u4ecb\u3057\u307e\u3059\u3002</p><h2>\uff3b\u629c\u7c8b\uff3d\u9053\u5fb3\u7684\u9032\u6b69\u3068\u300c\u8ab2\u984c X\u300d</h2><p><a href=\"https://www.youtube.com/watch?v=VH2LhSod1M4\"><u>\u52d5\u753b</u></a>\u306e49:15\u3088\u308a\u958b\u59cb</p><p>\u601d\u60f3\u306e\u6b74\u53f2\u30fb\u4eba\u985e\u306e\u6b74\u53f2\u3092\u898b\u3066\u307f\u308b\u3068\u3001\u3042\u308a\u3068\u3042\u3089\u3086\u308b\u4e16\u4ee3\u3067\u3001\u305d\u306e\u5f53\u6642\u3067\u306f\u3054\u304f\u5f53\u305f\u308a\u524d\u306b\u601d\u308f\u308c\u3066\u3044\u305f\u3001\u4eca\u3067\u306f\u9053\u5fb3\u7684\u306b\u6b8b\u8650\u306a\u884c\u70ba\u304c\u884c\u308f\u308c\u3066\u304d\u307e\u3057\u305f\u3002\u3069\u306e\u4e16\u4ee3\u3067\u3082\u3001\u4eba\u3005\u306f\u81ea\u5206\u305f\u3061\u306e\u884c\u3044\u304c\u3044\u304b\u306b\u9593\u9055\u3063\u3066\u3044\u308b\u304b\u3068\u3044\u3046\u4e8b\u5b9f\u306b\u307e\u3063\u305f\u304f\u6c17\u3065\u3044\u3066\u3044\u306a\u304b\u3063\u305f\u306e\u3067\u3059\u3002</p><p>\u4f8b\u3048\u3070\u3001\u30a2\u30ea\u30b9\u30c8\u30c6\u30ec\u30b9\u306f\u502b\u7406\u7684\u306a\u751f\u6d3b\u3092\u9001\u308b\u306b\u306f\u3069\u3046\u3057\u305f\u3089\u3088\u3044\u304b\u306b\u3064\u3044\u3066\u751f\u6daf\u3092\u304b\u3051\u3066\u8003\u5bdf\u3057\u307e\u3057\u305f\u304c\u3001\u5974\u96b7\u3092\u6240\u6709\u3059\u308b\u3053\u3068\u304c\u60aa\u3044\u3053\u3068\u3060\u3068\u306f\u601d\u3044\u3082\u3057\u306a\u304b\u3063\u305f\u306e\u3067\u3059\u3002\u3053\u308c\u306f\u9a5a\u304f\u3079\u304d\u4e8b\u5b9f\u3067\u3059\u3002\u5f53\u6642\u3001\u4e16\u754c\u3067\u6700\u3082\u8ce2\u3044\u4eba\u7269\u306e\u4e00\u4eba\u3067\u3042\u3063\u305f\u5f7c\u304c\u3001\u751f\u6daf\u3092\u304b\u3051\u3066\u8003\u3048\u305f\u306b\u3082\u304b\u304b\u308f\u3089\u305a\u3001\u305d\u308c\u3067\u3082\u6c17\u3065\u3051\u306a\u304b\u3063\u305f\u306e\u3067\u3059\u3002</p><p>\u3057\u304b\u3057\u3001\u4eba\u985e\u306e\u6b74\u53f2\u3092\u898b\u3066\u3044\u304f\u3068\u3001\u5974\u96b7\u5236\u5ea6\u3084\u5916\u56fd\u4eba\u306b\u5bfe\u3059\u308b\u5606\u304b\u308f\u3057\u3044\u6271\u3044\u3001\u5973\u6027\u306b\u5bfe\u3059\u308b\u652f\u914d\u3001\u7570\u6027\u611b\u8005\u3067\u306a\u3044\u4eba\u306b\u5bfe\u3059\u308b\u8feb\u5bb3\u3001\u4eca\u65e5\u3067\u306f\u52d5\u7269\u306b\u5bfe\u3059\u308b\u8feb\u5bb3\u306a\u3069\u6570\u3005\u306e\u6b8b\u8650\u306a\u884c\u70ba\u304c\u3042\u3063\u305f\u3053\u3068\u304c\u308f\u304b\u308a\u307e\u3059\u3002\u4f55\u5ea6\u3082\u4f55\u5ea6\u3082\u76ee\u306b\u3059\u308b\u306e\u306f\u3001\u6df1\u523b\u306a\u9053\u5fb3\u7684\u554f\u984c\u3092\u4eba\u306f\u3044\u3068\u3082\u7c21\u5358\u306b\u898b\u904e\u3054\u3057\u3066\u3057\u307e\u3046\u3068\u3044\u3046\u3053\u3068\u3067\u3059\u3002</p><p>\u79c1\u305f\u3061\u304c\u4eca\u65e5\u307e\u3067\u306b\u3059\u3079\u3066\u306e\u9053\u5fb3\u7684\u554f\u984c\u3092\u767a\u898b\u3057\u3066\u3044\u308b\u3068\u306f\u3001\u5230\u5e95\u601d\u3048\u307e\u305b\u3093\u3002\u79c1\u305f\u3061\u304c\u3059\u3079\u3066\u3092\u89e3\u660e\u3057\u305f\u4e16\u4ee3\u3067\u3042\u308b\u53ef\u80fd\u6027\u306f\u3068\u3066\u3082\u4f4e\u3044\u3067\u3057\u3087\u3046\u3002\u305d\u3046\u8003\u3048\u308b\u3068\u3001\u4eca\u8003\u3048\u308b\u3079\u304d\u306a\u306e\u306f\u3001\u6570\u767e\u5e74\u5f8c\u306b\u632f\u308a\u8fd4\u3063\u305f\u6642\u306b\u300c\u3048\uff01\u4eba\u3063\u3066\u305d\u3093\u306a\u306b\u91ce\u86ee\u3060\u3063\u305f\u306e\uff01\u300d\u3068\u601d\u3046\u3088\u3046\u306a\u91cd\u5927\u306a\u9053\u5fb3\u7684\u554f\u984c\u306b\u306f\u3069\u306e\u3088\u3046\u306a\u3082\u306e\u304c\u3042\u308b\u304b\uff1f\u305d\u3057\u3066\u3001\u4eca\u65e5\u306e\u79c1\u305f\u3061\u304c\u6982\u5ff5\u5316\u3059\u3089\u3057\u3066\u3044\u306a\u3044\u91cd\u5927\u306a\u554f\u984c\u3068\u306f\u4f55\u3067\u3042\u308d\u3046\u304b\uff1f\u3068\u3044\u3046\u3053\u3068\u3067\u3057\u3087\u3046\u3002</p><p>\u79c1\u306f\u3053\u308c\u3092\u3001\u8ab2\u984c X\uff08Cause X\uff09 \u3068\u547c\u3093\u3067\u3044\u307e\u3059\u3002</p><p>\u52b9\u679c\u7684\u5229\u4ed6\u4e3b\u7fa9\u306e\u30b3\u30df\u30e5\u30cb\u30c6\u30a3\u306e\u6700\u3082\u91cd\u8981\u306a\u76ee\u7684\u306e\u4e00\u3064\u306f\u3001\u3053\u306e\u300c\u8ab2\u984c X\u300d\u3092\u767a\u898b\u3059\u308b\u3053\u3068\u3060\u3068\u8a00\u3048\u308b\u3067\u3057\u3087\u3046\u3002\u73fe\u4ee3\u306e\u6700\u3082\u91cd\u8981\u306a\u9053\u5fb3\u7684\u554f\u984c\u306e\u4e00\u3064\u3067\u3042\u308a\u306a\u304c\u3089\u3001\u307e\u3060\u660e\u78ba\u306b\u6982\u5ff5\u5316\u3055\u308c\u3066\u3044\u306a\u3044\u8ab2\u984c\u3092\u767a\u898b\u3059\u308b\u3053\u3068\u3067\u3059\u3002\u30a2\u30cb\u30de\u30eb\u30a6\u30a7\u30eb\u30d5\u30a7\u30a2\u3084\u5b58\u4ea1\u30ea\u30b9\u30af\u306e\u3088\u3046\u306a\u30a2\u30a4\u30c7\u30a3\u30a2\u304c200\u5e74\u524d\u3067\u306f\u7b11\u308f\u308c\u3066\u771f\u5263\u306b\u306f\u53d7\u3051\u6b62\u3081\u3089\u308c\u306a\u304b\u3063\u305f\u3088\u3046\u306b\u3001\u300c\u8ab2\u984c X\u300d\u3082\u4eca\u65e5\u3067\u306f\u99ac\u9e7f\u3052\u3066\u3044\u308b\u3088\u3046\u306b\u898b\u3048\u308b\u30a2\u30a4\u30c7\u30a3\u30a2\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u304c\u3001\u5c06\u6765\u7684\u306b\u306f\u5f53\u7136\u3060\u3068\u601d\u3048\u308b\u3082\u306e\u306b\u306a\u308b\u3067\u3057\u3087\u3046\u3002\u3042\u308b\u3044\u306f\u300c\u8ab2\u984c X\u300d\u306f\u3001\u4eca\u65e5\u79c1\u305f\u3061\u304c\u6c17\u3065\u3044\u3066\u306f\u3044\u308b\u3051\u308c\u3069\u3082\u3001\u4f55\u3089\u304b\u306e\u597d\u307e\u3057\u304f\u306a\u3044\u7406\u7531\u306e\u305f\u3081\u306b\u512a\u5148\u9806\u4f4d\u3092\u4e0b\u3052\u3066\u3044\u308b\u3082\u306e\u306a\u306e\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u3002</p><p>\u304a\u305d\u3089\u304f\u3001EA\u30b3\u30df\u30e5\u30cb\u30c6\u30a3\u304c\u4e16\u754c\u306b\u975e\u5e38\u306b\u5927\u304d\u306a\u30d7\u30e9\u30b9\u306e\u5f71\u97ff\u3092\u4e0e\u3048\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u6700\u3082\u30a8\u30ad\u30b5\u30a4\u30c6\u30a3\u30f3\u30b0\u3067\u8208\u5473\u6df1\u3044\u65b9\u6cd5\u306f\u3001\u9053\u5fb3\u7684\u9032\u6b69\u3092\u63a8\u9032\u3057\u3001\u79c1\u305f\u3061\u304c\u4eca\u65e5\u6c17\u3065\u3044\u3066\u3059\u3089\u3044\u306a\u3044\u554f\u984c\u3001\u300c\u8ab2\u984c X\u300d\u3092\u89e3\u660e\u3059\u308b\u3053\u3068\u3067\u3057\u3087\u3046\u3002</p>", "user": {"username": "EA Japan"}}, {"_id": "PRYvjGK5KF3rjFyzx", "title": "How valuable is it to attend a top global university?", "postedAt": "2023-07-28T06:14:15.285Z", "htmlBody": "<p>Hi, I currently face the option to invest a huge amount of time into researching and applying to US universities and scholarships, with a small chance of payoff (plus there is the cost of tuition). I am struggling to tell whether it is worth the investment.</p>\n<p>I plan to study maths and economics and do some kind of longtermist career, most options are still on the table: technical AI safety, governance, etc.</p>\n<p>Oxbridge don\u2019t offer the subjects I want to study so if I don\u2019t go to America I will go to a good, but not globally famous, university.</p>\n<p>For the type of degree/career I\u2019m looking at, how valuable is it to go to a globally recognised university rather than just a good one?</p>\n<p>Thanks for your help!</p>\n", "user": {"username": "Khai"}}, {"_id": "KaEEDxupWgSwsAoaK", "title": "USAID Office of the Chief Economist: Evidence Use Team Lead ", "postedAt": "2023-07-27T22:02:06.321Z", "htmlBody": "<p>I'm pleased to share an exciting job opening to lead the new Office of the Chief Economist's \"Evidence Use\" team. Evidence here mainly refers to evidence of cost-effectiveness. The closing date is <strong>Aug 7th</strong>.&nbsp;</p><ul><li>The link for the <strong>general public</strong> to apply is <a href=\"https://www.usajobs.gov/job/739842000\">here</a>.</li><li>The link for <strong>candidates meeting specific requirements</strong> (e.g., federal employee in the competitive service, veterans, persons with disability) (described in \"This job is open to\") is <a href=\"https://www.usajobs.gov/job/739842100\">here</a>.</li></ul><p>Please share with anyone you think may be interested!</p><p>Thanks!</p><p>-- Dean Karlan</p><p><br>&nbsp;</p>", "user": {"username": "Dean Karlan"}}, {"_id": "oPMH9e6F7r3fXHd8M", "title": "Are there diseconomies of scale in the reputation of communities?", "postedAt": "2023-07-27T18:43:27.255Z", "htmlBody": "<p><strong>Summary</strong>: in what we think is a mostly reasonable model, the amount of impact a group has increases as the group gets larger, but so do the risks of reputational harm. Unless we believe that, as a group grows, the likelihood of scandals grows slowly (at most as quickly as a logarithmic function), this model implies that groups have an optimal size beyond which further growth is actively counterproductive \u2014 although this size is highly sensitive to uncertain parameters. Our best guesses for the model\u2019s parameters suggest that it\u2019s unlikely that EA has hit or passed this optimal size, so we reject this argument for limiting EA\u2019s growth.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreflyvzm40c4og\"><sup><a href=\"#fnlyvzm40c4og\">[1]</a></sup></span>&nbsp;(And our prior, setting the model aside, is that growth for EA continues to be good.)&nbsp;</p><p>You can play with the model (insert parameters that you think are reasonable)&nbsp;<a href=\"https://www.squiggle-language.com/playground#code=eNp9kt1um0AQhV%2FlCKmSSbG9xKqcIuWqaq8r5dK4aAODQVlmEbvUsWzevbuGOGn%2BrmaZnT3nmxmOgan0%2Fq5vGtkdgsR2PUXn1M%2Bitrp7yhRUyl7ZH7qgIAk6yTvCLTYxzVcRVkI8bFNO2eSSC6mySnZN1rj6ulU1da5SLNaw2oXvN1guMRUaNPKBQDKv0FJnNON6vhJfoMgY1E0rc1v2KmV6bCm3VGTcN%2FfUZbrMLhK3OJ44wZnpNIuxxDchhHebziGuwEPKu07vbZXdE1NZ21cP2RUpvZtxOHhAdjy6VRSNcLrEvtINKmmmqonuopprM0qmDDzL%2Bq9Xvv7xlc8DjnaOj4b2B5907UTC1Df1V6qe%2FA1nI%2FH%2Fbb3jPcdLZN%2BwX91Fx2rrYFqlrVP67cKiqI39xTOPfETppN94Rjjc5VJRgnNYmEPjp3RErtlYyTZxm48jt%2B3HBLGgNYYQzjZ84ev%2Bv13Nn1iPI%2FP%2B03Gc8%2Bbc6EZs8RXXEdZCbE9P929Ax%2F7fSbtsHI7PhsjHkS4Y%2FgEwqBEp\"><u>here</u></a>.&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/bbtvDJtb6YwwWtJm7/epistemic-status-an-explainer-and-some-thoughts\"><u>Epistemic status</u></a>: reasonable-seeming but highly simplified model built by non-professionals. We expect that there are errors and missed considerations, and would be excited for comments pointing these out.</p><h2>Overview of the model</h2><ol><li>Any group engaged in social change is likely to face reputational issues from wrongdoing<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefcdp4zks54rk\"><sup><a href=\"#fncdp4zks54rk\">[2]</a></sup></span>&nbsp;by members, even if it avoids actively promoting harmful practices, simply because its members will commit wrongdoing at rates in the ballpark of the broader population.&nbsp;<ol><li>Wrongdoing becomes a&nbsp;<strong>scandal</strong> for the group if the wrongdoing becomes prominently known by people inside and outside the group, for instance if it\u2019s covered in the news (this is more likely if the person committing the wrongdoing is prominent themselves).</li><li>Let\u2019s&nbsp;<a href=\"https://en.wikipedia.org/wiki/Spherical_cow\"><u>pretend</u></a> that \u201cscandals\u201d are all alike (and that this is the primary way by which a group accrues reputational harm).</li></ol></li><li>Reputational harm from scandals diminishes the group\u2019s overall effectiveness (via&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/oPMH9e6F7r3fXHd8M/are-there-diseconomies-of-scale-in-the-reputation-of#How_should_we_define_and_model__reputational_harm___\"><u>things like</u></a> it being harder to raise money).</li><li><strong>Conclusion of the model:&nbsp;</strong>If the reputational harm accrued by the group grows more quickly than the benefits (impact not accounting for reputational harm), then at some point, growth of the group would be counterproductive. If that\u2019s the case, the exact point past which growth is counterproductive would depend on things like how likely and how harmful scandals are, and how big coordination benefits are.<ol><li>To understand whether a point like this exists, we should compare the rates at which reputational harm and impact grow with the size of the group. Both might grow greater than linearly.<ol><li>Reputational harm accrued by the group in a given period of time might grow greater than linearly with the size of the group, because:<ol><li>The total reputational harm done by each scandal&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/oPMH9e6F7r3fXHd8M/are-there-diseconomies-of-scale-in-the-reputation-of#How_much_does_a_scandal_affect_each_person__for_a_group_of_a_given_size___K_\"><u>probably grows</u></a> with the size of the group (because more people are harmed).</li><li>The number of scandals per year&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/oPMH9e6F7r3fXHd8M/are-there-diseconomies-of-scale-in-the-reputation-of#How_does_the_frequency_of_scandals__in_expectation__grow_with_the_size_of_the_group___f_N__\"><u>probably grows</u></a><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref5qwlbam69y7\"><sup><a href=\"#fn5qwlbam69y7\">[3]</a></sup></span>&nbsp;roughly linearly with the size of the group, because there are simply more people who each might do something wrong.&nbsp;</li><li>These things add up to greater-than-linear growth in expected reputational damage per year as the number of people involved grows.&nbsp;</li></ol></li><li>The impact accomplished by the group (<i>not</i> accounting for reputational damage) might also grow&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/oPMH9e6F7r3fXHd8M/are-there-diseconomies-of-scale-in-the-reputation-of#How_do_benefits__ignoring_reputational_harm__grow_with_the_size_of_the_group_\"><u>greater than linearly</u></a> with the size of the group (because more people are doing what the group thinks is impactful, and because something like network effects might help larger groups more).</li></ol></li></ol></li><li><strong>Implications for EA</strong><ol><li>If costs grow more quickly than benefits, then at some point, EA should stop growing (or should shrink); additional people in the community will&nbsp;<i>decrease</i> EA\u2019s positive impact.</li><li>The answer to the question \u201cwhen should EA stop growing?\u201d is very sensitive to parameters in the model; you get pretty different answers based on plausible parameters (even if you buy the setup of the model).&nbsp;</li><li>However, it seems hard to choose parameters that imply that EA has surpassed its optimal point, and much easier to choose parameters that imply that EA should grow more (at least from this narrow reputational harm perspective).</li><li>Note that we\u2019re not focusing on the question \u201c<i>how</i> good is it for EA to grow\u201d here, which would matter for things like the cost-effectiveness of outreach efforts.</li></ol></li></ol><p>Here are two plots showing how the net impact (per year, with arbitrary units of impact) would change as a group grows \u2014 the plots are very different because the parameters are different and the model is very sensitive to that:</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/oPMH9e6F7r3fXHd8M/fdesmst9c8dptyrdempz\"><figcaption><i>Plot generated for the model with arbitrary parameters demonstrating an optimal size around ~6,000 members. Squiggle code linked in the post.</i></figcaption></figure><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/oPMH9e6F7r3fXHd8M/destxkhfrjazxtrle62b\"><figcaption><i>Alternative parameter choice: plot generated for different arbitrary parameters. These would imply that growth continues to be useful forever. Squiggle code linked in the post.</i></figcaption></figure><h2>Technical model description</h2><ul><li>Reputational harm assumption/setup:&nbsp;<ul><li>We start by assuming that each scandal (in the group) decreases the effectiveness of each person in the group by some percentage. I.e. due to a scandal in your group, the impact you would have had has been multiplied by an effectiveness penalty K. If we expect X scandals in your group in a given timeframe \u2014 let\u2019s say a year, you\u2019re getting that penalty X times, so your impact is decreased by a factor of K^X.&nbsp;</li></ul></li><li>If a group has N people (and no scandals), we can say that we\u2019re overall getting N times the impact of the average person. (Where \u201cimpact\u201d is \u201ccounterfactual impact caused by association with the group, not counting broad coordination benefits.\u201d E.g. If a person would have been a doctor but decided to go into pandemic preparedness, the \u201cimpact\u201d that we should track for this person is the difference between their positive impact in the latter and the former worlds.)<ul><li>We might also think that clustering these N people together has positive ~coordination effects for the whole group (like brand recognition making people more effective at achieving their goals, more sustained values, people supporting each other because they\u2019re in the same group, etc. \u2014 more <a href=\"https://forum.effectivealtruism.org/posts/oPMH9e6F7r3fXHd8M/are-there-diseconomies-of-scale-in-the-reputation-of#How_do_benefits__ignoring_reputational_harm__grow_with_the_size_of_the_group_\">below</a>). We think that this effect is probably real, but grows more slowly than linearly, so we\u2019re semi-arbitrarily modeling it as log(N).&nbsp;</li><li>We\u2019re also assuming that coordination benefits aren\u2019t&nbsp;<i>separately</i> harmed by scandals (outside of the fact that scandals harm individuals\u2019 effectiveness).&nbsp;</li></ul></li><li>So the overall impact of a group of N people (per year) is the impact that group&nbsp;<i>would</i> have had if there were no scandals, multiplied by the effectiveness penalty factor K^X to account for reputational harm (N*impact-per-person*log(N)*K^X).&nbsp;</li><li>Other simplifications/assumptions:&nbsp;<ul><li>We\u2019re treating \u201cscandal\u201d as a binary: something either is a harmful scandal or isn\u2019t. In reality, different scandals are bad to different extents. Someone could try to model this. Here, we\u2019re talking about \u201cexpected number of scandals,\u201d so we can try to account for the variation in real-world scandals when we\u2019re setting parameters by saying that something less serious simply has a smaller chance of being a \u201cscandal.\u201d&nbsp;</li><li>We\u2019re assuming that everyone is equally \u201cin the group.\u201d This might matter if the variation in how much people are \u201cpart of the group\u201d is somehow tied to other factors we care about (in which case it would not be ok to simply track the average).&nbsp;</li><li>We list many other considerations <a href=\"https://forum.effectivealtruism.org/posts/oPMH9e6F7r3fXHd8M/are-there-diseconomies-of-scale-in-the-reputation-of#Discussion_of_parameter_choices_and_the_model_setup\">below</a>.</li></ul></li></ul><p><strong>A more formal description of the model</strong></p><ul><li>Let\u2019s define some variables/functions:&nbsp;<ul><li><i><strong>N&nbsp;</strong>\u2014 the variable that tracks the size of our group (this is a natural number)</i></li><li><i><strong>K </strong>\u2014 the effectiveness penalty factor due to reputational harm from 1 scandal (K&nbsp;should be a constant between 0 and 1)</i></li><li><i><strong>f(N) </strong>\u2014 the expected number of scandals, per year, in a group of size N</i></li><li><i><strong>gross_value(N)</strong> \u2014 the positive impact of a group of N people, ignoring reputational risk, per year</i></li><li><i><strong>net_value(N) </strong>\u2014 the overall impact of a group of size N, per year</i></li><li><i><strong>U </strong>\u2014 the unit of value that the average person in the group has per year, when unaffected by reputational harm.&nbsp;</i></li></ul></li><li>We model&nbsp;<i>gross_value(N)</i> as<i> N * U * log N</i>; each person has U impact independently, there are N people, and they also get some coordination benefits (see more on coordination benefits <a href=\"https://forum.effectivealtruism.org/posts/oPMH9e6F7r3fXHd8M/are-there-diseconomies-of-scale-in-the-reputation-of#How_do_benefits__ignoring_reputational_harm__grow_with_the_size_of_the_group_\">below</a>) modeled as log N.</li><li>Then the overall impact of the group is:<ul><li><i><strong>net_value(N) =&nbsp;</strong>gross_value(N) * K^f(N) =<strong> (N * U * log N) * K^f(N)</strong></i></li></ul></li></ul><p><strong>Getting to the implications of the model&nbsp;</strong></p><p><i>(Note: this section uses&nbsp;</i><a href=\"https://en.wikipedia.org/wiki/Big_O_notation\"><i><u>asymptotic (Big O) notation</u></i></a><i>.)</i></p><ul><li>Is there ever a point at which marginal people joining the group is harmful?&nbsp;<ul><li>To understand whether&nbsp;<i>net_value(N)</i> ever starts going down as N goes up \u2014 i.e. whether there\u2019s a point at which growth of the group is harmful \u2014 we need to understand whether the gross value grows faster than the reputational effectiveness penalty gets small, i.e. we need to understand which of these grows faster:&nbsp;<ul><li><i>N * U * log(N)</i> (gross value), or&nbsp;</li><li>1/(<i>K^f(N))</i> (1/reputational penalty)</li></ul></li><li>The surprising result is that&nbsp;<strong>whether or not additional people in the group will ever be net-negative entirely depends on whether or not&nbsp;</strong><i><strong>f(N) \u2208 O(log N)&nbsp;</strong></i>(i.e. whether, as the group grows, the frequency of scandals grows at most logarithmically).<ul><li>A sketch explanation/proof:<ul><li>Case 1: If&nbsp;<i>f(N)&nbsp;<strong>\u2208</strong> O(log N)</i> (i.e.&nbsp;<i>f(N)</i> grows at most as quickly as&nbsp;<i>log N</i>), then growth is always good<ul><li>Because&nbsp;<i>K ^ (log N) \u2208 O(N) \u2208 O(N log N)</i></li></ul></li><li>Case 2:&nbsp; If<i> f(N) \u2208 o(log N)</i>&nbsp; (i.e.&nbsp;<i>f(N)</i> grows more quickly than&nbsp;<i>log N</i>), then there will be some maximum beyond which growth is harmful<ul><li>Because&nbsp;<i>N log N</i> is dominated by 1/(<i>K ^ g(N))</i> where&nbsp;<i>g \u2208 o(log N)</i>&nbsp;</li></ul></li></ul></li></ul></li><li>Is it plausible that the frequency of scandals grows at most as quickly as log? I.e. is the case where growth becomes net-negative at some point (Case 2) much more plausible than the other (Case 1)?&nbsp;<ul><li>We think Case 1 is actually pretty plausible, but we\u2019re not sure which is in fact more likely. A justification for&nbsp;<i>f</i> (frequency of scandals based on group size) being sublinear can be found&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/oPMH9e6F7r3fXHd8M/are-there-diseconomies-of-scale-in-the-reputation-of#How_does_the_frequency_of_scandals__in_expectation__grow_with_the_size_of_the_group___f_N__\"><u>here</u></a>.</li></ul></li></ul></li><li>If there&nbsp;<i>is</i> a point past which marginal people are net negative, the exact point is extremely sensitive to model parameters.<ul><li>I.e. a wide variety of answers for \u201c<i>when</i> would growth be counterproductive?\u201d is plausible.&nbsp;</li><li>Squiggle code implementing this can be found&nbsp;<a href=\"https://www.squiggle-language.com/playground#code=eNp9kt1um0AQhV%2FlCKmSSbG9xKqcIuWqaq8r5dK4aAODQVlmEbvUsWzevbuGOGn%2BrmaZnT3nmxmOgan0%2Fq5vGtkdgsR2PUXn1M%2Bitrp7yhRUyl7ZH7qgIAk6yTvCLTYxzVcRVkI8bFNO2eSSC6mySnZN1rj6ulU1da5SLNaw2oXvN1guMRUaNPKBQDKv0FJnNON6vhJfoMgY1E0rc1v2KmV6bCm3VGTcN%2FfUZbrMLhK3OJ44wZnpNIuxxDchhHebziGuwEPKu07vbZXdE1NZ21cP2RUpvZtxOHhAdjy6VRSNcLrEvtINKmmmqonuopprM0qmDDzL%2Bq9Xvv7xlc8DjnaOj4b2B5907UTC1Df1V6qe%2FA1nI%2FH%2Fbb3jPcdLZN%2BwX91Fx2rrYFqlrVP67cKiqI39xTOPfETppN94Rjjc5VJRgnNYmEPjp3RErtlYyTZxm48jt%2B3HBLGgNYYQzjZ84ev%2Bv13Nn1iPI%2FP%2B03Gc8%2Bbc6EZs8RXXEdZCbE9P929Ax%2F7fSbtsHI7PhsjHkS4Y%2FgEwqBEp\"><u>here</u></a>.</li></ul></li></ul><h2>Discussion of parameter choices and the model setup</h2><h3>How does the frequency of scandals (in expectation) grow with the size of the group? (f(N))</h3><p>Remember that we defined \u201cscandal\u201d as \u201cwrongdoing that becomes prominent.\u201d Given this, our best guess here is that frequency grows sublinearly with the size of the group.</p><ol><li>A na\u00efve first-order approximation is that frequency should be linear in the size of the group because each new person is similarly likely to commit wrongdoing and cause a scandal.</li><li>However, wrongdoing might only become a scandal that affects the reputation of the group if it involves a prominent<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefaybk0vo6sf\"><sup><a href=\"#fnaybk0vo6sf\">[4]</a></sup></span>&nbsp;member of the group. And it seems likely that the size of the \u201cprominent people\u201d group in a broader community grows more slowly than the size of the community overall (i.e. you\u2019re less likely to be a prominent member of a group if the group is huge than you are if the group is small).&nbsp;<ol><li>E.g. sexual misconduct seems to be more of a scandal for a university if done by a famous professor than by a random staff member.</li></ol></li><li>So there should be fewer \u201cscandals\u201d per person in larger groups, meaning that the frequency of scandals should grow sublinearly with the size of the group.</li></ol><p>Note also that we can try to account for the variation in the importance of real-world scandals when we\u2019re setting parameters by saying that something less significant simply has a smaller chance of causing a scandal. In other words, if you think that someone will definitely cause 3 scandals in the following year, but they\u2019re all very small, you can model this here by saying that this is actually 1 scandal in the way we\u2019re defining scandal here. (Whereas something unusually significant might be equivalent to two scandals.)&nbsp;</p><h3>How should we define and model \u201creputational harm\u201d?&nbsp;</h3><p>The harms we would expect to accrue from scandals are things like:</p><ol><li>It\u2019s harder for people in the group to do things the group considers high-impact:<ol><li>It\u2019s harder to raise money for impactful projects</li><li>It\u2019s harder to attract employees and collaborators</li><li>It\u2019s harder to convince people to take action on your ideas</li><li>People in the group are generally stressed and demoralized</li></ol></li><li>Some people&nbsp;<i>outside</i> of the group might no longer want to do things the group considers high-impact:<ol><li>They\u2019re less likely to join the group in the future</li><li>They don\u2019t want to do things the group endorses because the group endorses them</li></ol></li></ol><p>Our guess is that reputational harm is best modeled as a percentage decrease in impact. This fits the first point above better than it fits the second, but even for 2 (a), harms might accrue in a similar pattern: the first scandal drives off the least interested x% of people, then the second scandal drives off the x% least interested of the remainder, etc. (See&nbsp;<a href=\"https://www.lesswrong.com/posts/ZQG9cwKbct2LtmL3p/evaporative-cooling-of-group-beliefs\"><u>evaporative cooling</u></a>.)</p><p>There are some costs which arguably do not fit this model. For example, the negative perception of early cryonicists may have deterred cryobiologists (who weren\u2019t cryonicists) from doing cryonics-related research that they otherwise would have done independently. It seems plausible that from the point of view of the group, this is better modeled as an additive cost \u2014 flat negative impact \u2014 due to the reputational issues as opposed to a multiplier penalty on the positive impact of the members of the group. (Additionally, the \u201ceffectiveness penalty multiplier\u201d model doesn\u2019t allow for scandals to cause someone\u2019s work to become negatively impactful, which doesn\u2019t seem universally true.)</p><p>Another complication might be something like splintering; it\u2019s possible that you can\u2019t model group size as independent of scandal rate and reputational harm, because when scandals have certain effects, the group splinters into smaller groups or simply loses members.&nbsp;</p><p>Still, we think the percentage decrease model is the best that we have come up with.</p><h3>How much does a scandal affect each person, for a group of a given size? (K)</h3><p>We want to understand: given a fixed scandal, is it more harmful per person if the group the scandal is attached to is bigger? Our best guess is that per person in the group, harm per scandal&nbsp;<i>decreases</i> with the size of the group, but we\u2019re modeling&nbsp;<i>K</i> as a constant for simplicity.&nbsp;</p><p>It seems like there are some counterbalancing factors:</p><ol><li>Worse for bigger groups:&nbsp;<ol><li>Bigger groups have more people affiliated with the scandal, and therefore more people who can be harmed</li><li>Bigger groups are more likely to be known and might be considered more newsworthy<ol><li>A random individual committing a crime is usually not worthy of any reporting, but if it is attached to some well-known group, that is more worthy of journalism</li></ol></li></ol></li><li>Better for bigger groups<ol><li>The effects are also more diffuse in bigger groups<ol><li>It seems less reasonable to blame each member of a larger group as much as you would for smaller groups</li></ol></li><li>Bigger groups are more likely to have an existing reputation in people\u2019s minds, which means that individual scandals are less likely to affect their overall view<ol><li>Many people know at least one Harry Potter fan. If a Harry Potter fan causes a scandal, that\u2019s not that likely to affect your view of all Harry Potter fans, in part because you have a stronger prior about the group. But if a fan of some fairly niche book series causes a scandal, you might have a weaker prior and update stronger.&nbsp;</li></ol></li></ol></li><li>Some examples to inform intuition:&nbsp;<ol><li>Public perception of academia overall probably doesn't change much when a Princeton prof is accused of harassment or the like. But the perception of&nbsp;<i>Princeton</i> might change more, and if an even smaller group is well enough known (and that prof is in that group), then maybe the other people in the group are even more affected.&nbsp;</li><li>But even very large groups (major religions, political parties) still seem to suffer some amount of reputational harm after scandals.</li></ol></li><li>Out best guess (fairly weak) is that, per person in the group, harm per scandal&nbsp;<i>decreases</i> with the size of the group; this would mean that we should model&nbsp;<i>K</i> as something like 1/log(N) instead of modeling it as a constant. But we\u2019re going for a constant here for simplicity and because we\u2019re quite unsure.&nbsp;</li><li>Note also that, because the number of people affected as the group grows goes up linearly, overall, this means that the&nbsp;<i>total</i> reputational harm per scandal should grow with the size of the group, but sublinearly.&nbsp;</li></ol><h3>How do benefits, ignoring reputational harm, grow with the size of the group?</h3><p>Our best guess is that benefits grow slightly superlinearly because of coordination benefits (but you can easily remove coordination benefits from the model).&nbsp;</p><ol><li>A na\u00efve first-order approximation is that benefits (not accounting for reputational issues) are linear in the size of the group.<ol><li>If everyone in EA donated a constant amount of money, then getting more people into EA would linearly increase the amount of money being donated (which, for simplicity, we can say is a linear increase in impact)</li></ol></li><li>At least in some cases though, it seems like benefits are superlinear.<ol><li>Standard models of networks state that the value of groups tends to grow&nbsp;<a href=\"https://en.wikipedia.org/wiki/Metcalfe%27s_law\"><u>quadratically</u></a> or&nbsp;<a href=\"https://en.wikipedia.org/wiki/Reed%27s_law\"><u>exponentially</u></a></li><li>When Ben asks people why they write for the EA Forum they often say something like \u201cbecause everyone reads the Forum\u201d; N people each writing because N people will read each thing \u2014 that\u2019s quadratic value</li><li>Brand recognition can help get things done, and larger groups have more brand recognition</li><li>Other coordination benefits (e.g. a member of the group can identify and get access to people who\u2019d be useful to coordinate with)</li></ol></li><li>On the other hand, there are also (non-reputation-related) costs of larger groups, like coordination&nbsp;<i>costs</i></li><li>Our tentative guess is that the benefits of groups like EA tend to grow slightly superlinearly</li></ol><h3>Parameter sensitivity</h3><p>My (Ben) subjective experience of playing around with this model is that for reasonable parameter values, it seems pretty clear that groups of more than 500 people are better than smaller groups, but it's harder to get outputs that show that larger groups (or any reasonable size) are noticeably&nbsp;<i>worse</i> than smaller ones. I have to intentionally choose weird parameters to get a graph like the one above, where there is a clear peak and larger groups are worse \u2013 unless I intentionally do this, it usually seems like growth is neutral or good (although confidence intervals are often very wide). (Lizka agrees with this.)</p><p>When I try to think of scandals that plausibly decreased the effectiveness of people in EA by &gt;5% the list feels pretty short: FTX is probably in there, but even disturbing news or incidents like the TIME article on sexual harassment seem unlikely to have caused one in 20 people to leave EA (or otherwise decreased effectiveness by &gt;5%). And we have 10-20k person-years to have caused scandals (suggesting that the base rate of scandals per person per year is 1/20000 to 1/10000); plugging in those numbers&nbsp;<a href=\"https://www.squiggle-language.com/playground#code=eNp9Ut9P2zAQ%2Flc%2BRZrUsLRNQAgRiSe0PU%2Fisekik1yaCPsc2c5K1eZ%2Fn92UwoCRl7PPd9%2BPu%2Bwj2%2Brtw6CUMLsod2ag5Jj6UXdOm5dMTY0YpLvXNUV5ZARvCHdYZTS%2FSnCVpk%2Frggu2leBayLIVRpXK13e97Mj4ynRxC6dDuMZyiVOhhRJPBBJVi56M1YzreZZ%2BgyRr0aleVK4ZZMH03FPlqC55UI9kSt2UZ4g77A%2Bc46jpMMuwxGXqv0AXLpk%2Fx7gAjwVvjN66tnwkpqZz71rZF0m9mXE8BonsFeleUjLJ0w22rVZohT1VnfSdUSttJ8iCgVfYcHvHG5ovQh7weuf439h%2B4wvfHiQugqk%2FQg4UXricFP9r6xPuOd5KDobD8s44TjsvppfaeaRfPizqzrqfPAuS92g89AfOBLuHSkjKcQwLu1NhSntUmq0T7HK%2F%2Byzx%2B37O%2FUroBmMMTxu%2F4fV%2F4KbjL6inkQX%2B03Ga8%2BpodJWu8R2XCW7SdH14ef8gdPL%2FSdpns3hqG5MQJ3XR%2BBeQIhGC\"><u>here</u></a> indicates that EA should grow vastly beyond its current size.</p><p>More importantly: when I try to argue backwards from the claim that EA is already too big, I have to put in numbers that seem absurd, like&nbsp;<a href=\"https://www.squiggle-language.com/playground#code=eNp9kkFvozAQhf%2FKE9JKoUsS00hbFamnqj2v1GNIkQtDQDVjhM2mUcJ%2Frx1ottt2exozHr%2F3zQyHwFR699A3jez2QWK7nqJT6q6ore7eMgWVslf2VhcUJEEneUu4wTqm%2BSrCSojnTcopm1xyIVVWya7JGldft6qmzlWKxS9Y7cI1lktMdQaNfCaQzCu01BnNuJyvxA8oMgZ108rclr1KmV5ayi0VGffNE3WZLrOzxA0OR05wQjrOYiwRCyG82XQOcQEeUt52emer7ImYytp%2BeMiuSOntjMPBA7Lj0a2iaITTJXaVblBJM1VNdGfVXJtRMmXgr6z%2F%2BuDrH1%2F4POBo5%2FjfzB7xTddOJEx9U3%2Bk6snfcDYS%2F9vWF95zvEf2DfvNnXWstg6mVdo6pd8uLIra2HueeeQDSif9yTPC%2FiGXihKcwsLsGz%2BlA3LNxkq2iVt8HLltvyRuI3SFIYSzDd%2F5ut9vW%2FM31uPIvP90HOe8PjW6Fhv8xGWEKyE2x7f7T6Bj%2F1%2BkXTYOx2dD5ONIFwyvXt8Q6A%3D%3D\"><u>here</u></a>.</p><p>So my guess is that if growth is bad, it's because this model is flawed (which, to be clear, is pretty likely, although the flaws might not necessarily point in the direction of making it more likely that growth is bad).&nbsp;</p><h3>Other considerations about the parameters &amp; model setup</h3><ol><li>What happens if impact per person has long tails in a way that is predictably related to parameters in the model?&nbsp;<ol><li>I could imagine alternative models which have different results, e.g. it could be that the most impactful members are disproportionately benefited by larger groups (e.g. the best researchers disproportionately benefit from having more people to read their research)</li><li>It\u2019s not clear to me how this would shake out</li><li>See also the next bullet point</li></ol></li><li>What if how much reputational harm affects someone is not independent of their impactfulness?<ol><li>Maybe the extremely committed members don\u2019t care so much about reputational harm because they are diehards, and they are also the more impactful ones, so this model could overstate total damage</li><li>Alternatively, we speculated above that reputation harms might disproportionately accrue to prominent members of the group, and it seems plausible that prominent members of the group are also disproportionately impactful (or are connected to disproportionately impactful people, who are affected more), meaning that this model understates total damage</li></ol></li><li>Maybe how much each new scandal affects the group\u2019s effectiveness depends on the number of scandals that have hit the group in the past (in a way that\u2019s hard to capture via f(N))&nbsp;&nbsp;<ol><li>E.g. maybe after 3 scandals that each harmed effectiveness by 10% (maybe via driving off 10% of the least interested people after each scandal), the group is in a new type of vulnerability, and a 4th scandal would cause significantly more damage. Meaning that we can\u2019t keep K constant.&nbsp;</li><li>See also&nbsp;<a href=\"https://ericneyman.wordpress.com/2021/06/05/social-behavior-curves-equilibria-and-radicalism/\"><u>Social behavior curves, equilibria, and radicalism</u></a></li></ol></li><li>How does this model work for multiple groups, especially when they\u2019re overlapping?&nbsp;</li><li>\u201cScandal\u201d is poorly defined: scandals have a complicated relationship with brand recognition, we\u2019re modeling \u201cscandal\u201d in an extremely simplified way<ol><li>Complicated relationship with brand recognition<ol><li>At the extreme: \u201call press is positive press\u201d</li><li>This extreme seems unlikely to be true, but there are likely complex ways in which different types of scandals have different types of impact</li><li>E.g. possibly radical tactics&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/LXj4cs5dLqDHwJynp/radical-tactics-can-increase-support-for-more-moderate\"><u>increase support</u></a> for more moderate groups</li></ol></li><li>Not all scandals are equal<ol><li>For instance, if a scandal is related to the group\u2019s focus (e.g. Walmart employee is involved in a scandal for doing Walmart-related things, like embezzling \u2014 vs. something in their personal life) or involves prominent members of the group, it probably has a bigger impact.</li><li>We can try to track this by defining (expected) \u201cscandal\u201d in a way that forces them to have a similar impact, but this affects how we should estimate the base rates of scandals at different group sizes, and might be hard to track.</li></ol></li></ol></li><li>Many other properties of groups can be at least somewhat related to group size and affect how much reputational harm a group accrues<ol><li>Some are listed <a href=\"https://forum.effectivealtruism.org/posts/oPMH9e6F7r3fXHd8M/are-there-diseconomies-of-scale-in-the-reputation-of#How_does_the_frequency_of_scandals__in_expectation__grow_with_the_size_of_the_group___f_N__\">below</a> for EA.</li></ol></li><li>Does this argument prove too much? The existence of large groups seems like compelling evidence that the reputational costs of large groups can\u2019t be that high<ol><li>But maybe there are reasons to think that existing large institutions have special circumstances that EA lacks. In particular: some institutions started before the Internet era and are seen as \u201cpart of the furniture\u201d (e.g. major religions, political parties) and others aren\u2019t actually trying to do anything terribly controversial (e.g. sports teams). It\u2019s hard to think of a large group that\u2019s trying to change the world which was started in the last 20 years that doesn\u2019t have substantial reputational hits from the action of a minority of members.</li></ol></li><li>This model assumes that the rate of scandals is impossible to change, but that of course is not true. Projects like&nbsp;<a href=\"https://www.centreforeffectivealtruism.org/community-health\"><u>CEA\u2019s Community Health and Special Projects team</u></a>, the&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/73mAv8m3PjsXzJ4Ad/update-on-project-on-reforms-at-ea-organizations\"><u>EA reform project</u></a>,&nbsp;<a href=\"https://www.eagoodgovernance.com/\"><u>EA Good Governance Project</u></a>, and others may reduce the incidence of issues.</li><li>This post is intended to address the narrow question of how reputational harm scales. There are a large number of other reasons why growth might be good/bad (e.g. difficulty maintaining norms), and those are not addressed here.</li></ol><h3>EA-specific factors that this model ignores</h3><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><strong>Factor</strong></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><strong>Possible implications</strong></td></tr><tr><td style=\"border:1pt solid #000000;padding:2pt 0pt;vertical-align:bottom\">Probably attracts people who are more conscientious and nice than average</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Decreases per-member frequency of scandals</td></tr><tr><td style=\"border:1pt solid #000000;padding:2pt 0pt;vertical-align:bottom\">The desire to make things work (rather than just compete) encourages most participants to try to get along and resolve conflicts amicably</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Decreases per-member frequency of scandals</td></tr><tr><td style=\"border:1pt solid #000000;padding:2pt 0pt;vertical-align:bottom\">Some / many of the things we do are broadly regarded as good (e.g. GiveWell)</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Decreases per-member frequency of scandals</td></tr><tr><td style=\"border:1pt solid #000000;padding:2pt 0pt;vertical-align:bottom\">The group isn\u2019t super defined / is pretty decentralized; it\u2019s not one massive organization. So e.g. someone donating to GWWC or effective charities can continue to do that as much as they could before (except maybe they\u2019re demotivated) if someone prominent in a big animal advocacy organization is involved in a scandal</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Decreases cost of scandal</td></tr><tr><td style=\"border:1pt solid #000000;padding:2pt 0pt;vertical-align:bottom\">Could be seen as a nonprofit</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Unclear; nonprofits are sometimes held to higher standards (e.g. around compensation) but also have some default assumption of goodwill</td></tr><tr><td style=\"border:1pt solid #000000;padding:2pt 0pt;vertical-align:bottom\">Members tend to be from privileged demographics</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Unclear; makes EA more \u201cpunchable\u201d but also members have larger safety nets and more resources to push back</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Is identified as powerful and allied with powerful groups (by some)</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Unclear; makes EA more \u201cpunchable\u201d but also members have larger safety nets and more resources to push back</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">A large set of different organizations with different practices any of which might be objectionable to someone</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Increases per-member frequency of scandals, decreases cost of scandal</p><p><br>&nbsp;</p></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">A large set of different geographic subcultures with different practices</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Increases per-member frequency of scandals, decreases cost of scandals</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Tells people to take big actions which can frequently go badly and are expected to backfire at some decent rate</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Increases per-member frequency of scandals</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">A high level of overlap between people's professional and friend networks means that almost all aspects of someone's life can be regarded as relevant for criticism, rather than just what they do in the course of their work</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Increases per-member frequency of scandals</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">The desire to make things go well gives people a reason to stick around even if dissatisfied, and feel a moral responsibility to fight other people if they think what they're doing is harmful</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Increases per-member frequency of scandals</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Nobody has the authority to impose universal rules</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Increases per-member frequency of scandals; possibly decreases cost of scandals (because scandals are legitimately not caused by the group)</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Nobody can control who identifies themselves with EA, at least for the purposes of a critical journalist</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Increases per-member frequency and cost of scandals</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">A large fraction of our communication, especially by new and less professional folks, is public and able to be used against us indefinitely (c.f. corporations or government agencies)</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Possibly increases per-member frequency of scandals</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Is engaged in activity contrary to the views of some existing political alliances and interests, so has accumulated active and motivated haters (and also some motivated by the FTX association)</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Increases per-member frequency of scandals</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Disproportionately attracts young people who tend to be harder to screen, and behave more erratically, and develop new mental health problems at higher rates</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Increases per-member frequency of scandals</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Could be seen as a political movement trying to influence society, which makes it seem particularly fair game to attacks</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Increases per-member frequency of scandals</td></tr></tbody></table></figure><h2>Related work and work we\u2019d be excited to see</h2><ul><li>Some related work:<ul><li><a href=\"https://forum.effectivealtruism.org/posts/pcygusgiy6ZabnB93/how-valuable-is-movement-growth\"><u>How valuable is movement growth?</u></a></li><li><a href=\"https://forum.effectivealtruism.org/posts/FXPaccMDPaEZNyyre/a-model-of-patient-spending-and-movement-building\"><u>A Model of Patient Spending and Movement Building</u></a></li><li><a href=\"https://forum.effectivealtruism.org/posts/QpZQbPo9pYuo2ExP7/rob-wiblin-movement-development-i\"><u>Rob Wiblin: Movement development I</u></a></li><li>See also the&nbsp;<a href=\"https://forum.effectivealtruism.org/topics/value-of-movement-growth\"><u>Value of movement growth</u></a> topic</li></ul></li><li>More work we would be excited to see (not exhaustive):<ul><li>A compilation of reasons for and against growth</li><li>More case studies/accounting of reputational harms that EA has accrued so far. Emma and Ben tried to do&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/SFAMvCxnEzaQHNeSL/how-has-ftx-s-collapse-affected-public-perception-of-ea\"><u>one survey here</u></a>, and those results don\u2019t make Ben think that the public has a terribly negative opinion of EA, but there is a lot more work that could be done.</li><li>Empirical analyses that can inform us about what good parameters would be for this model (e.g. base rates, analyses into other groups\u2019 sizes and how they\u2019re doing, etc.)<ul><li>Example from Ben: one research project I would be interested in is collecting examples of scandals that were so bad that they destroyed a community. E.g.&nbsp;<a href=\"https://en.wikipedia.org/wiki/Rebecca_Watson#%22Elevatorgate%22\"><u>elevatorgate</u></a> is possibly one, but my subjective experience is that it's surprisingly hard to find examples (which might mean that I'm overestimating how much of a risk these scandals are).</li></ul></li><li>Improvements on the model, including alternative models<ul><li>Commentary from Ben: I wish I had a better model of how reputational costs work. I\u2019ve previously been involved in animal rights activism, and that community has a (sometimes deserved) terrible public reputation, but animal advocates seem to be making a lot of progress despite that. I struggle to think of any group that has successfully achieved change without having a substantially negative reputation in parts of society: feminists, environmentalists, neoliberals, etc. all have substantially achieved their aims while having a ton of public criticism.</li></ul></li></ul></li></ul><h2>Conclusion</h2><p>As with many such models, you can choose parameters to get basically any possible outcome. But the settings that seem most plausible to us result in growth being good.</p><p>One of the few takeaways from this exercise that can be said with confidence is that bigger groups are likely to have more scandals, so if EA grows, that\u2019s something we should prepare for and mitigate against.&nbsp;</p><h2>Contributions</h2><p>The original idea for a related model was developed by a person who wishes to remain anonymous. Ben and Lizka made this more nuanced and wrote this post as well as the squiggle code. The resulting model is rough and doesn\u2019t have fully conclusive results, but we thought it was worth sharing.</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnlyvzm40c4og\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreflyvzm40c4og\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Though reputation is not the only relevant consideration for thinking about whether it would be better for EA to be small.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fncdp4zks54rk\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefcdp4zks54rk\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Or stigmatized or unpopular behavior</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn5qwlbam69y7\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref5qwlbam69y7\">^</a></strong></sup></span><div class=\"footnote-content\"><p>We are not actually sure about this. See the <a href=\"https://forum.effectivealtruism.org/posts/oPMH9e6F7r3fXHd8M/are-there-diseconomies-of-scale-in-the-reputation-of#How_does_the_frequency_of_scandals__in_expectation__grow_with_the_size_of_the_group___f_N__\">linked section</a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnaybk0vo6sf\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefaybk0vo6sf\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Note that \u201cprominence\u201d here is complicated. Arguably, the thing that matters is the prominence of someone&nbsp;<i>as a member of the group</i>. For instance, if a really famous actor happens to shop at Walmart and is involved in a widely covered scandal, it probably won\u2019t affect Walmart\u2019s reputation. However, if the person was also a spokesperson for Walmart, it probably would, at least a bit.&nbsp;</p><p>Moreover, prominence<i> in the group</i> might make someone\u2019s wrongdoing newsworthy (and via news coverage, a scandal) even if they weren\u2019t prominent outside of the group before that happened. (Imagine a relatively unknown spokesperson for Walmart committing wrongdoing.) I\u2019m not sure how much this actually happens.&nbsp;</p><p>It probably also matters whether the wrongdoing in question was somehow related to the group; e.g. the group already has a reputation for something related, or the wrongdoing highlights hypocrisy from the group\u2019s perspective, etc.&nbsp;</p></div></li></ol>", "user": {"username": "Lizka"}}, {"_id": "waS5NaJjqdYugW8am", "title": "Introducing the Insights of an ERA Forum Sequence ", "postedAt": "2023-07-27T17:16:25.598Z", "htmlBody": "<p><i>This is the introductory post for the Insights of an ERA: Impactful Existential Risk Research &amp; Talent Development Forum sequence, written by the team who run the ERA Cambridge Summer Research Fellowship Programme.</i></p><p>The&nbsp;<a href=\"https://erafellowship.org/\"><u>Existential Risk Alliance</u></a> (ERA), previously known as CERI, was established in 2021 with a mission to grow the field of existential risk (x-risk) research. We achieve this through providing training, mentorship, and funding to junior researchers who are passionate about mitigating existential risks.&nbsp;</p><p>By the end of this summer, our Summer Research Fellowship programme will have supported&nbsp;<strong>over 60 research fellows</strong> to conduct research in our focus areas, including AI Safety, Biosecurity, Climate, Nuclear, and Misc &amp; Meta. The ultimate goal of the programme is not merely to disseminate knowledge but to cultivate critical thinkers and problem solvers dedicated to addressing the most pressing risks facing humanity this century.</p><p>Over the next few months, we plan to share insights and best practices learnt specifically from running the ERA Cambridge Fellowship in 2023. However, we acknowledge that our journey has been uniquely shaped by a multitude of variables - our organisational structure, the specific set of resources available to us, and the individual backgrounds of our staff and fellows. While we hope that our experiences offer valuable takeaways, they may not be universally applicable or replicate the same results in different contexts.</p><h1>Mapping Out the Sequence</h1><p>Through the \"Insights of an ERA\" sequence, we aim to explore the following topics:</p><ul><li>ERA's Theory of Change</li><li>Lessons from Selecting ERA\u2019s 2023 Cohort: What we learned from reviewing 600+ applications</li><li>Best practices for training and mentorship of early-career existential risk researchers</li><li>ERA Cambridge Fellowship Impact Evaluation&nbsp;</li><li>ERA Alumni Stories: Inspiring journeys from our fellowship programme</li></ul><p>Each of these themes provides an in-depth exploration of our operations, with a spirit of learning and transparency. The sequence aims to present our journey with candour, laying bare both our successes and challenges, in hopes of sparking meaningful dialogue within the community. We intend to publish all the posts by the end of September at the latest, but cannot publicly commit to a specific publishing schedule as our capacity is currently focused on running the programme.</p><h1>About the ERA Fellowship&nbsp;</h1><p>ERA runs a Summer Research Fellowship for ~30 junior researchers interested in kickstarting or advancing their career in x-risk research. The programme lasts for 8 weeks and ERA fellows get hands-on experience of working on a x-risk research project under the guidance of an experienced mentor. Throughout the summer, we run various programmed events (20+ events so far this year) across our focus areas, including skills-based workshops, speaker events and more interactive Q&amp;As. The structure of the fellowship, with key project milestones, is:</p><ul><li>End of Week 1: Research Abstract Deadline (inc theory of change for fellows' projects)</li><li>Week 5: Midpoint Presentations</li><li>Week 8: Research Symposium</li><li>Week 8: Final Deliverable Deadline</li></ul><p>ERA's Research Managers meet weekly with all our fellows to provide further 1-1 support, both specific to the project but also helping them realise their career goals and resolving any key uncertainties.&nbsp;</p><p>To help ERA fellows maximise their potential, we offer a comprehensive support package:</p><ul><li>A salary equivalent to \u00a331,200 per year, prorated to the duration of the summer programme;</li><li>Mentorship from a researcher with relevant expertise;</li><li>Free accommodation, office food, and travel to Cambridge (for in-person fellows);</li><li>Dedicated desk space at our office in central Cambridge (for in-person fellows);</li><li>Opportunity to work either on a group research project with other fellows or individually;</li><li>Networking and learning opportunities through various workshops and seminars.</li></ul><p>We support a wide spectrum of research, provided it aims to mitigate existential risk. This extends from technical to philosophical research, including social science or policy projects on implementing x-risk mitigation strategies.</p><p>The Fellowship targets two key objectives: first, to contribute to reducing existential risks such as civilisation collapse, human extinction, or the truncation of future potential. Second, to enable our fellows to deepen their understanding of x-risk mitigation, develop relevant skills, and assess their fit for further research in the field. We will elaborate more on this in our Theory of Change post.</p><p>Anyone can apply to the fellowship, though we expect it to be most useful to students (from undergraduates to postgraduates) and early-career individuals looking to test their fit for existential risk research.</p><h1>Meet the ERA Team</h1><p>ERA is brought to life by a dedicated team committed to supporting the fellows and driving our mission. Our Executive Director, Nandini Shiralkar, is supported by our Associate Director, Moritz von Knebel, in the day-to-day running of the organisation.</p><p>Each cause area is also led by a Research Manager:&nbsp;</p><ul><li>Moritz von Knebel for AI Governance</li><li>Tilman R\u00e4uker for technical AI safety</li><li>Oscar Delaney for Biosecurity&nbsp;</li><li>Irina Gueorguiev for Nuclear Security</li><li>Gideon Futerman for Climate Change</li><li>Joel Christoph for Miscellaneous &amp; Meta</li></ul><p>Our Community Manager, Hanna P\u00e1lya, ensures seamless operations within the fellowship, provides overarching community support, and also serves as a biosecurity research manager for the in-person biosecurity fellows.&nbsp;</p><p>The Research Managers play a pivotal role in hiring and managing ERA\u2019s fellows, shaping the application process for their respective cause area with support from the rest of the ERA team. The mentors of the fellows are experienced researchers and policymakers from various x-risk organisations, complementing the core ERA team, and providing more project-specific support to each fellow.</p><p>ERA is funded by Open Philanthropy and operates as a fiscally sponsored project of Rethink Priorities (RP). RP\u2019s Special Projects Team provides us with significant operational support. We particularly extend our gratitude to Lara, Carolyn, Robert and Aaron for their unwavering support of ERA operations.</p><h1>Acknowledgements</h1><p><i>This post is from the Existential Risk Alliance, which is a fiscally sponsored project of Rethink Priorities.&nbsp; If you have any questions, you can either email me at&nbsp;</i><a href=\"mailto:nandini@erafellowship.org\"><i><u>nandini@erafellowship.org</u></i></a><i> or contact us via our&nbsp;</i><a href=\"https://airtable.com/shr11E0DbORKc7sNd\"><i><u>anonymous feedback form</u></i></a><i>.</i>&nbsp;</p>", "user": {"username": "nshiralkar"}}, {"_id": "WwkqYMTCasivjbJsr", "title": "What are good \"translated arguments\" or arguments in need of translation?", "postedAt": "2023-07-27T16:08:24.930Z", "htmlBody": "<p>A while back I remember more conversation about how sometimes arguments weren't getting traction or hitting the intended audiences because they were written in a different conceptual language, or with different ontologies, or with just a different vibe.</p><p>Do people have examples of well-translated arguments or arguments that they think would benefit from being \"translated\" into vibe/style that gets more uptake in EA / rationalist landscapes?</p><p>Or, alternately, suggestions on being better at the skill of not needing arguments translated?</p>", "user": {"username": "ChanaMessinger"}}, {"_id": "CtACh7xRBFnpK3NW4", "title": "Guide to Safe and Inclusive Events by GWWC and OFTW", "postedAt": "2023-07-27T19:12:25.461Z", "htmlBody": "<p><i>[We are sharing this guide on the Forum as an example for other organisations and groups that may be organising events. This guide is used by volunteers and staff at both Giving What We Can (GWWC) and One for the World (OFTW) when planning and running events.]</i></p><h1>Introduction</h1><h2>Who is this guide for?</h2><p>This guide is for anyone who is organising events in association with Giving What We Can or One for the World, whether that be paid staff or volunteers. We also hope it will be a useful resource for anyone else who is looking to organise community events in a safe and inclusive way.</p><h2>Why have a guide?</h2><p>It can be hard to think of all the relevant considerations around running events by yourself, and each of us have biases or preferences that mean that we may be more likely to think of some areas and not others. This guide aims to cover a broad range of considerations to help all organisers and ensure safe and inclusive events for all attendees.</p><p>Giving What We Can and One for the World take providing safe and inclusive events seriously. Our organisations exist to improve the world, and aim to do so through the lens of compassion. We believe our events should mirror our commitment to creating a better world.</p><h2>What are other helpful resources to consult?</h2><ul><li>CEA\u2019s&nbsp;<a href=\"https://docs.google.com/document/d/14mB9hzaiIczjmHe3QwFLSzvjRcVoWGdw-ue1IIXrZGI/edit?usp=sharing\"><u>Advice about Community Health at Retreats</u></a></li><li><a href=\"https://www.medicalnewstoday.com/articles/how-to-help-someone-who-is-having-a-panic-attack\"><u>How to help someone having a panic attack</u></a></li><li><a href=\"https://resources.eagroups.org/running-a-group/community-health\"><u>Resources from CEA on community health</u></a></li></ul><h1>What to keep in mind when planning the event</h1><h2>Who will be attending the event</h2><h3>Considerations around age</h3><p><strong>Under 18s</strong></p><ul><li>The organisation may not be covered by insurance to host attendees under the age 18 when unaccompanied by a parent. Please reach out to staff to discuss this more if you think Under 18s may be interested in attending.</li></ul><p><strong>Alcohol</strong></p><ul><li>Be aware of the restrictions on drinking in different countries. In the US, students at the undergraduate level are typically not of legal age to drink, which is 21.&nbsp;</li><li>In other countries, it may be more common for students to drink together. That said, be mindful of the dynamics that alcohol can introduce to events, regardless of age. At the top of the event-planning process, you should first consider running the event without alcohol. You should only decide to include it if there is a strong reason to, and if there are no concerns about the mixing of young students or professionals of different ages, who come with different cultural and regional contexts around drinking.&nbsp;</li><li>Having alcohol at your event increases associated risks for serious, negative outcomes, like sexual harassment, bullying, and even assault.&nbsp;</li></ul><p><strong>Power dynamics</strong></p><ul><li>Be aware of power dynamics that may be unintentionally (or intentionally) created within your spaces. People who have management responsibility typically have a degree of power, whether intentionally or not, over those who are in a reporting relationship to them. People who are older, especially with significant age differences, sometimes have a level of unstated power relative to those who are younger than them. This can be doubly true when mixing folks of different ages and genders.&nbsp;</li><li>There may also be funding relationships within your spaces that manifest through power dynamics. A person with any degree of responsibility for funding a particular person, group, or organization has a degree of power over those that they are funding. People who are in the process of reviewing grants or funding proposals from others may also have a degree of power over those people.&nbsp;&nbsp;&nbsp;&nbsp;</li></ul><p><strong>Families</strong></p><ul><li>GWWC and OFTW events typically cater to either students or young professionals. Keep in mind that either group may have families and children who might be involved in an event that you host.&nbsp;</li><li>When planning an event, especially a larger one, consider whether it would be accessible to those with families and young children. You may also want to plan any content that you are presenting or discussing accordingly.&nbsp;</li></ul><h3>Considerations around diversity</h3><p><strong>Anti-Discrimination &amp; Harassment</strong></p><ul><li>If you organise an event as a volunteer or staff member at Giving What We Can or One for the World, you are bound by the policies of the organisation(s) you are helping. This includes anti-discrimination and harassment policies, which for One for the World, can be found&nbsp;<a href=\"https://docs.google.com/document/d/1sAmoH9YGNju3jleDN2icRKIpdFnuVo8fyW-7jdk6K4s/edit\"><u>here</u></a> and&nbsp;<a href=\"https://docs.google.com/document/d/129KR4ZjevVXn4C6vzUdt9Zao_SJbFBV5ubRmcsWQ5G0/edit#heading=h.kls7gbkf6f6w\"><u>here</u></a>. Giving What We Can\u2019s Code of Conduct can be found&nbsp;<a href=\"https://www.givingwhatwecan.org/codeofconduct\"><u>here</u></a>.</li><li>When advertising your event, depending on the size, you may consider adding anti-discrimination and harassment statements to your promotional materials.&nbsp;</li><li>Characteristics and factors you might protect against discrimination and harassment at your event may include but are not limited to: age, gender, sexuality, socioeconomic status, race, ethnicity, disability status, neurodivergence, veteran status, national origin, pregnancy, and religion.&nbsp;</li><li>Ensure that your policy on both is clear up front, and agreed to by all attendees. Usually, this can be done by sharing the policy prior in pre-event communications. If there are issues with attendees discriminating against or harassing other attendees, you will be able to refer back to your stated policy.&nbsp;</li></ul><p><strong>Providing appropriate facilities and products</strong></p><ul><li>Be mindful of the potential range of attendees at your events, and have the appropriate facilities for them to use. You may have attendees who have recently given birth, who have a need for menstrual products, who are non-binary or transgender, or who need a quiet space to themselves throughout the day.&nbsp;</li><li>Depending on the size of your event, you may consider creating a space for people who have recently given birth to lactate or otherwise provide care to their child. Reach out to your host venue and check if such a facility is available or could be created within existing facilities.&nbsp;</li><li>If possible, provide access to gender-neutral restrooms. Some may prefer single-use restrooms for this purpose, with a lockable door. When in doubt, consider asking your venue host if you are able to re-mark a single or multiple restrooms as gender-neutral if they do not already have them available. Non-binary or transgender attendees may feel uncomfortable using bathrooms that are only marked for use by cisgender men and women.&nbsp;</li></ul><h3>Considerations around accessibility</h3><p><strong>Venue</strong></p><ul><li>When planning a large event, it\u2019s likely that people with a variety of accessibility requirements will be in attendance, so it\u2019s best to arrange a venue that is accessible to most people, and let people know the accessibility information upon registration, in addition to asking if there are additional requirements.</li><li>For smaller events, provide accessibility information for the venue upon registration</li><li>Accessibility of bathrooms: Check with your venue about whether they have accessible stalls in any bathrooms for those who are using wheelchairs or other mobility devices. You may consider the optimal solution of including accessible stalls in your restrooms that are marked as gender-neutral, allowing someone who needs either or both options to be accommodated in that restroom.&nbsp;</li></ul><p><strong>Checking about accommodations required&nbsp;</strong></p><ul><li>For any event, but especially for larger ones, reach out to your attendees list ahead of time to request accommodations needed for accessibility. Give yourself several weeks to months if possible to allow time to work with your venue to accommodate these requests to your greatest ability.&nbsp;</li></ul><h3>Considerations around safety</h3><p><strong>Thinking about volunteer capacity</strong></p><ul><li>Wherever possible, you will want at least two volunteers organizing an event. Indeed, a rule of thumb is to have one volunteer per 10 people attending.</li><li>It's also strongly preferable to have at least one person whose role is to help with safety. That person should be prepared to drop other tasks like logistics, be available to participants and also set expectations about how they will handle any uncomfortable or harmful situations reported to them.</li></ul><h2>Types of events</h2><p>There are many types of community events that may be appropriate for you to organise. The following discusses considerations in organising different types of events. When selecting the type of event to organise, it is worth thinking about selecting the type of event that balances the value provided to attendees with any considerations or risks. For example, if an event will provide just as much value as a dinner at a local restaurant when compared with a party at someone\u2019s home, it would be preferable to host a dinner at a local restaurant, if costs were equal, as people may feel more comfortable in a public setting.</p><h3>Retreat/overnight/multiday events</h3><p><strong>Accommodation and sleeping arrangements</strong></p><p>People have varying levels of comfort when it comes to sleeping arrangements, and it\u2019s important to respect people\u2019s boundaries.&nbsp;</p><p>When organising accommodation, people should always be offered the option to stay in a room with people of their own gender, and offered an option to stay in a room by themselves, if they require. It is key for people to be able to express their desire to change their sleeping arrangements if they are not comfortable.&nbsp;</p><p>If there is limited space or funds available for accommodation, and someone\u2019s preferred option is not available, you should brainstorm ways you could meet this person's requirements within the constraints.</p><p>It could also be wise to have an additional room available in case anyone falls ill or requires a space to themselves during the event.</p><p><strong>Food</strong></p><p>Many people will have dietary preferences due to religion, allergies or medical conditions and lifestyle preferences. When organising a multiday event, you should ask for everyone\u2019s dietary preferences in advance so that food can be appropriately prepared.&nbsp;</p><p>Allergens should be clearly labelled whenever possible, and an organiser or venue staff member should be able to identify all ingredients in the food. If someone has a severe allergy, consider whether it\u2019s practical to avoid having the allergen present at all,</p><p>Ideally, you will be able to cater for all preferences throughout the event, but if someone has very complex dietary requirements, you may wish to contact the person to discuss and come up with solutions together about how best to cater for them. Meal times are generally highly social, so we should endeavour to have everyone included.</p><p>Within the effective altruism community, a large portion of people are vegan or vegetarian and many events are catered to be vegan by default. This is generally considered to be best practice as it is also generally inclusive of religious food restrictions such as kosher and halal. At a larger event, there will often be a couple of people who are also gluten free, and nut allergies are common.</p><p><strong>Religion</strong></p><p>During multiday events, it becomes more likely that the event will crossover with religious rituals or traditions that attendees may be following. You may want to actively provide a space for prayer during the event or people may choose to disclose any requirements to you in lead up to the event. No one should have to disclose their religion to you or anyone else at any point, and be mindful that you may not know who is religious amongst attendees.</p><p>Attendees should be allowed to leave any sessions or activities to undertake prayer or religious obligations.</p><p><strong>Space</strong></p><p>Over a multiday event, thinking about how different people live their lives is important. Some people may be extroverted and want to stay up late and chat, while others may want to go to bed early, or prefer quiet time alone. Providing spaces for people to engage in their preferred way to unwind or recharge will make for a more fulfilling event for all involved.</p><ul><li><strong>Providing a quiet space</strong></li></ul><p>Some people may benefit from a quiet space to relax, reflect or work during downtime at an event. Providing a space that is intentionally quiet can also help signal to others that someone does not want to be disturbed at the moment. This can be especially helpful if the accommodation involves shared rooms.</p><ul><li><strong>Managing noise and different schedules</strong></li></ul><p>Bedtimes and wake up times vary significantly in adults, so it may make sense to group those who generally go to bed early or late together when planning accommodation. This can be done through a survey during registration.</p><p>It is also worth thinking about designating a social space where people might be making (reasonable levels of) noise late in the evening or early in the morning.</p><p>We recommend having a set of \u2018quiet hours\u2019 where noise should be kept to a minimum. Depending on the location, 10pm-7am may be reasonable.</p><h3>Dinners/drinks</h3><p><strong>Timing (i.e. new parents might struggle to attend)</strong></p><p>Dinners are an easy option for a social gathering, but it may be worth bearing in mind that not all people will be able to attend evening events. They might be new parents who don\u2019t want to interrupt their baby\u2019s sleep schedule, or they may have an early bedtime or limited energy which may conflict with evening engagements. If organising a dinner, try to alternate the next event with a lunch or a differently timed activity to allow different attendees to come along.&nbsp;</p><p><strong>Food</strong></p><p>If going out to a restaurant, selecting a venue that can cater for multiple dietary requirements is important. Many people in the effective altruism community are vegan or vegetarian, so a restaurant that is vegan, or has multiple vegan options is usually a good bet. Vegan options also generally cater for those seeking kosher or halal options.</p><p>Let people know you\u2019ve chosen an option that caters to specific dietaries in the event description and registration. It makes sense to collect dietary requirements as far in advance as possible, and to let the chosen venue know in advance as well.</p><h3>Events at private homes</h3><p>Events in private homes can be a wonderful way to develop relationships with people in your community, but they carry an extra set of responsibilities to ensure that the event is safe. Generally, we would recommend hosting events in public spaces but recognise some people would prefer to host in their own home. If hosting events in your home, try to host alternating events in public spaces.</p><p><strong>Power dynamics/vulnerability</strong></p><p>When hosting in your home, you are in a position of power and it is worth being mindful of how others may feel in your home. People may be more deferential to you as a host than they would normally as they are not in their own space, and may feel indebted to you for hosting. This means that attendees may be more vulnerable and less likely to speak up if they are uncomfortable. Choosing a co-host who does not live in the home may provide an alternative option for people to raise concerns to during the event. It may also help women feel more comfortable attending if a woman is co-hosting if the other hosts are men.</p><p>Ideally, you would close off any private areas of your home, i.e. bedrooms and make it clear that they are not to be entered during the event with signs on doors.&nbsp; Also having a sign on the entry or gate can affirm to people that they\u2019re in the right place.</p><p>When starting the event, you should let people know where to find the bathroom, where items like glasses and water are and what areas of your home they may use. Encourage people to stay in the main areas of your home where the majority of others are.</p><p>It can be particularly difficult to provide adequate bathroom facilities for a large group of people in a private home. In general, we recommend not hosting more than 15 people in a private venue unless it is particularly well-equipped for large groups.</p><p><strong>Consent</strong></p><p>If someone has invited you to their home, you should always gain their permission before sharing the address with another person, and let the host know who exactly you intend on bringing, in case there was a reason that person was not invited.</p><p>In most cases events run in association with Giving What We Can or One for the World would be considered social professional events, where a standard of professional conduct would apply. When in a private home, it can be easier to relax into more personal than professional behaviour, especially if some attendees are close friends. It should be made clear to all attendees what kind of behaviour is and isn\u2019t encouraged in your home during the event, as well as reminding attendees that this event is run in association with Giving What We Can or One For The World, and that the event should be treated the same as if it was hosted in a public space.</p><h2>During the event</h2><h3>At the start of the event</h3><ul><li>Share expectations with attendees<ul><li>Prepare and share an event code of conduct (reminder that Giving What We Can\u2019s code of conduct is&nbsp;<a href=\"https://www.givingwhatwecan.org/codeofconduct\"><u>here</u></a>)</li></ul></li><li>Outline who is available as a contact person if issues arise, and emphasise you want to hear about issues<ul><li>Share in advance how issues will be dealt with, including confidentiality expectations (see below). Doing this in writing in advance will mean you can reference the guidelines at the start of the event, rather than explaining them for the first time during the introduction&nbsp;</li></ul></li><li>Outline positive behaviours you would like to see, as well as what is not acceptable<ul><li>Remind everyone to be welcoming, and encourage behaviours like sitting in a U shape so people feel welcome to join a conversation</li></ul></li></ul><h3>If you notice any issues during an event</h3><p>In general, organisers should feel empowered to ask people to leave if there are any issues. Agreeing in advance who is responsible for asking people to leave can help organisers feel more comfortable in actioning this.</p><p>If anyone is in physical danger, you must call the authorities. You should also contact a member of staff from One for the World or Giving What We Can at the earliest practical opportunity, so that they can assist (see below). If someone is in immediate danger, it is entirely appropriate to involve the police.&nbsp;</p><p>If you believe a crime has been committed but the immediate danger has passed, you should offer to support the victim in reporting it or offer to do this on their behalf if they consent. That said, if you have reporting obligations [such as a \u201cduty-to-report\u201d in the US], you must always report to the police and other authorities according to your legal and contractual obligations.&nbsp;</p><p>If in doubt, you should seek advice at the earliest opportunity from a member of staff at One for the World or Giving What We Can.</p><p>If you encounter an issue that doesn't rise to the level of involving the authorities, and if the involved parties are safe to do so, address any less serious issues calmly and take appropriate action (more guidance on issues you could encounter below).</p><p>Take down a record of what happened and contact the organisation\u2019s person in charge of community events. Record the contact details of witnesses as appropriate. They may want to investigate what happened and take further action.</p><p>For Giving What We Can events, you can contact the&nbsp;<a href=\"https://www.centreforeffectivealtruism.org/community-health-team\"><u>CEA Community Health team</u></a>, or Luke Freeman. For One for the World events, you can contact: Jack Lewars or Emma Cameron. [Note: personal contact information has been redacted for the EA Forum version]</p><h3>Handling interpersonal issues&nbsp;</h3><p><strong>Someone feels left out</strong></p><p>If someone is shy or feels left out, one solution could be to offer activities during breaks or to ask if someone wants to participate in a discussion on a topic you know they might have an interest in.&nbsp;</p><p><strong>Someone is made to feel uncomfortable&nbsp;</strong></p><p>There are differing levels of what people will and will not be comfortable with in terms of ways of communicating, topics of discussion etc. While we recommend being mindful of what is discussed and how, for example, avoiding discussing things of a sexual nature, graphic violence or other commonly upsetting topics, it is possible that someone may feel uncomfortable with less obviously difficult topics.&nbsp;</p><p>If someone is in distress as a result of a conversation or interaction, they should be encouraged to talk to the event\u2019s point of contact to discuss it and talk about whether anything can be done to help. This could mean moving the distressed person into a new room, new accommodation or a different working group.</p><p>Depending on the conversation or interaction, it could be worth having a conversation with the person who initiated it, to let them know that this can be seen as making others uncomfortable, and to encourage them to avoid similar topics or behaviour.&nbsp;</p><p>If it persists, you may want to ask them more explicitly to stop, or explain that you will ask them to leave the event. If the conversation or interaction is deemed to be harassment then consider the below advice.&nbsp;</p><p><strong>Bullying, Harassment, Discrimination</strong></p><p>There may be occasions where behaviour at an event may constitute harassment, bullying or discrimination. If someone raises a serious concern about or reports this behaviour:</p><ul><li>Check that you have the time and resources to have the conversation at that time. If not, reschedule and let the person know they will have time to be properly heard. Offer them assistance to mitigate the problem in the moment, such as a taxi ride home or new accommodation arrangements. Reasonable expenses will be reimbursed by One for the World or Giving What We Can.</li><li>Make it clear whether you can keep it confidential. Depending on your local regulations, you might be obliged to act or inform someone else. If you\u2019re not obliged to act, ask them what they think would be best.</li><li>Focus on listening to what they say and clarify as needed.</li><li>Thank them for bringing up a difficult subject and reassure them that bringing up the information was very valuable. Be clear on what action you will take and when, even if that means being honest about uncertainty. It is fine to say \"thank you for sharing this and I am sorry you experienced that. Would you mind if Ispeak to someone at HQ before taking further action, but I will let you know tomorrow evening what the outcome of that conversation is.\"</li><li>As soon as possible, write down detailed notes recording the conversation. Ideally email them to yourself so you have a time stamp on them&nbsp;</li></ul><p>If you think there is a conflict of interest at any point, you should make the other person aware as soon as possible and find someone else to manage the situation.</p><p>If you would like advice on a situation like this, you can reach out to the CEA Community Health team. For more guidance on responding to and investigating a report of this nature, you may want to look at&nbsp;<a href=\"https://resources.eagroups.org/running-a-group/community-health\"><u>these resources from CEA on community health.</u></a></p><p><strong>Mental health: helping someone experiencing a panic attack, or overwhelm</strong></p><p>If anyone is in immediate danger or seriously injuring themselves or others, you should call emergency services. Ideally, this should be done with the consent of the affected person, if at all possible, but you have a primary responsibility to keep everyone safe.</p><p>It is possible at a large event that someone may experience a panic attack, we recommend familiarising yourself with&nbsp;<a href=\"https://www.medicalnewstoday.com/articles/how-to-help-someone-who-is-having-a-panic-attack\"><u>this article</u></a> about someone who is having a panic attack.</p><p>Especially at multiday, overseas, or large and busy events, it\u2019s likely that someone will become overwhelmed at some point. Often the topics being discussed can be emotionally distressing or heavy to talk about.</p><p>Having a quiet space for people to recover or unwind is a good idea. Scheduling breaks between sessions or activities can also give people space to decompress if the programming is heavy or difficult for some attendees. Mentioning at the start of the session that people are welcome to step out if they are finding it overwhelming can also be a good idea if the content is potentially upsetting. Remind attendees that they can always speak to the contact person.</p><p>~~~</p><p>The contents for this guide have been based heavily on the&nbsp;<a href=\"https://docs.google.com/document/d/14mB9hzaiIczjmHe3QwFLSzvjRcVoWGdw-ue1IIXrZGI/edit?usp=sharing\"><u>Advice about Community Health at Retreats</u></a> from CEA.</p><p>Latest version: July 2023</p><p>Thanks to JL, LF and CL for reviewing and providing input.<br>&nbsp;</p>", "user": {"username": "GraceAdams"}}, {"_id": "NJGzmY5BNRw7fSg3z", "title": "EA Survey 2022: Community Satisfaction, Retention, and Mental Health", "postedAt": "2023-07-28T10:24:29.868Z", "htmlBody": "<h2>Summary</h2><ul><li>Community satisfaction remains high, though is slightly lower post-FTX.<ul><li>More recent cohorts report being more satisfied than earlier cohorts.</li><li>Respondents identifying as a man were, on average, more satisfied than other respondents.</li><li>We observed no significant differences in satisfaction based on racial identity.</li><li>Highly engaged respondents were, on average, more satisfied than less engaged respondents.</li><li>Prioritizing longtermist causes relative to neartermist causes was associated with higher satisfaction with the community</li></ul></li><li>A large majority (84.1%) of respondents report they are likely to still be involved in EA in three years\u2019 time, while only a small minority (5.1%) thought it unlikely they would still be involved.<ul><li>Respondents who identified as a man reported being slightly more likely to remain in the community.</li><li>We observed no significant differences in retention based on racial identity.</li><li>More engaged respondents reported being significantly more likely to remain in EA.</li><li>Higher endorsement of longtermist causes was associated with being more likely to remain in EA, while higher endorsement of neartermist causes was associated with being less likely to remain in EA.</li></ul></li><li>More respondents reported that their experiences with EA had improved their mental health (36.8%) than said that it had worsened (16.4%), while 36.0% said that it had stayed the same.<ul><li>Men were somewhat less likely to say that their mental health had greatly decreased.</li><li>Respondents not identifying as white were more likely to report that their mental health had greatly increased.</li><li>Respondents higher in EA engagement were more likely to report both that their mental health had increased or that it had decreased as a result of EA, whereas those lower in engagement were much more likely to report that it had stayed the same.</li></ul></li></ul><h2>Introduction</h2><p>In this post, we report on a number of questions about people\u2019s satisfaction with the EA community, their likelihood of remaining in EA, and EA\u2019s impact on their mental health. Note that we significantly shortened the EA Survey this year, meaning there are fewer community-related questions than in the previous EA Survey.&nbsp;</p><h2>Satisfaction</h2><p>Respondents indicated being generally satisfied with the EA community, scoring an average of 7.16 (SD = 1.66) on a 10-point scale. The median satisfaction response was a 7.</p><p><img src=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/2e58674efde05488e701b3b34d75a2f4f45d7332f9367052.png\" srcset=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/2e58674efde05488e701b3b34d75a2f4f45d7332f9367052.png/w_200 200w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/2e58674efde05488e701b3b34d75a2f4f45d7332f9367052.png/w_400 400w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/2e58674efde05488e701b3b34d75a2f4f45d7332f9367052.png/w_600 600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/2e58674efde05488e701b3b34d75a2f4f45d7332f9367052.png/w_800 800w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/2e58674efde05488e701b3b34d75a2f4f45d7332f9367052.png/w_1000 1000w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/2e58674efde05488e701b3b34d75a2f4f45d7332f9367052.png/w_1200 1200w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/2e58674efde05488e701b3b34d75a2f4f45d7332f9367052.png/w_1400 1400w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/2e58674efde05488e701b3b34d75a2f4f45d7332f9367052.png/w_1600 1600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/2e58674efde05488e701b3b34d75a2f4f45d7332f9367052.png/w_1800 1800w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/2e58674efde05488e701b3b34d75a2f4f45d7332f9367052.png/w_1999 1999w\"></p><p>As we noted in our&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/g5uKzBLjiEuC5k46A/ftx-community-response-survey-results\"><u>recent post</u></a> on community responses to the FTX crisis, community satisfaction seems to have declined following the FTX crisis. In 2020, respondents reported an average satisfaction of 7.26 (SD = 1.72). In 2022, the average of all respondents was 7.16 (SD = 1.66) and 6.95 (SD = 1.72) for respondents who completed the survey after the FTX crisis. It\u2019s also possible that much less satisfied respondents disengaged from the EA community and did not take the survey. Had they participated, the average satisfaction post-FTX could be lower than what we report here.</p><p><img src=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/970233d459e5830658cb37b852b2c8b44fc26478d4e0430e.png\" srcset=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/970233d459e5830658cb37b852b2c8b44fc26478d4e0430e.png/w_200 200w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/970233d459e5830658cb37b852b2c8b44fc26478d4e0430e.png/w_400 400w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/970233d459e5830658cb37b852b2c8b44fc26478d4e0430e.png/w_600 600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/970233d459e5830658cb37b852b2c8b44fc26478d4e0430e.png/w_800 800w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/970233d459e5830658cb37b852b2c8b44fc26478d4e0430e.png/w_1000 1000w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/970233d459e5830658cb37b852b2c8b44fc26478d4e0430e.png/w_1200 1200w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/970233d459e5830658cb37b852b2c8b44fc26478d4e0430e.png/w_1400 1400w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/970233d459e5830658cb37b852b2c8b44fc26478d4e0430e.png/w_1600 1600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/970233d459e5830658cb37b852b2c8b44fc26478d4e0430e.png/w_1800 1800w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/970233d459e5830658cb37b852b2c8b44fc26478d4e0430e.png/w_1999 1999w\"></p><h3>Cohort</h3><p>Respondents who recently joined the EA community seem to be more satisfied with the community than earlier cohorts. This pattern is less clear for the earliest cohorts, possibly because the sample size for these groups is relatively small compared to newer cohorts.</p><p><img src=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/f4b25a86aeab71981700866c5704dd12462b11468535fb82.png\" srcset=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/f4b25a86aeab71981700866c5704dd12462b11468535fb82.png/w_200 200w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/f4b25a86aeab71981700866c5704dd12462b11468535fb82.png/w_400 400w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/f4b25a86aeab71981700866c5704dd12462b11468535fb82.png/w_600 600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/f4b25a86aeab71981700866c5704dd12462b11468535fb82.png/w_800 800w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/f4b25a86aeab71981700866c5704dd12462b11468535fb82.png/w_1000 1000w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/f4b25a86aeab71981700866c5704dd12462b11468535fb82.png/w_1200 1200w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/f4b25a86aeab71981700866c5704dd12462b11468535fb82.png/w_1400 1400w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/f4b25a86aeab71981700866c5704dd12462b11468535fb82.png/w_1600 1600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/f4b25a86aeab71981700866c5704dd12462b11468535fb82.png/w_1800 1800w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/f4b25a86aeab71981700866c5704dd12462b11468535fb82.png/w_1999 1999w\"></p><h3>Gender</h3><p>Respondents identifying as a man were, on average, more satisfied with the EA community (M = 7.31, SD = 1.58) than respondents not identifying as a man (M = 6.93, SD = 1.72)\u2013a difference of 0.38<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefau4nm6lhy5\"><sup><a href=\"#fnau4nm6lhy5\">[1]</a></sup></span>.</p><p><img src=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/4cae5bce47b0544cd68994e65efe4e17958c6da07955a595.png\" srcset=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/4cae5bce47b0544cd68994e65efe4e17958c6da07955a595.png/w_200 200w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/4cae5bce47b0544cd68994e65efe4e17958c6da07955a595.png/w_400 400w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/4cae5bce47b0544cd68994e65efe4e17958c6da07955a595.png/w_600 600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/4cae5bce47b0544cd68994e65efe4e17958c6da07955a595.png/w_800 800w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/4cae5bce47b0544cd68994e65efe4e17958c6da07955a595.png/w_1000 1000w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/4cae5bce47b0544cd68994e65efe4e17958c6da07955a595.png/w_1200 1200w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/4cae5bce47b0544cd68994e65efe4e17958c6da07955a595.png/w_1400 1400w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/4cae5bce47b0544cd68994e65efe4e17958c6da07955a595.png/w_1600 1600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/4cae5bce47b0544cd68994e65efe4e17958c6da07955a595.png/w_1800 1800w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/4cae5bce47b0544cd68994e65efe4e17958c6da07955a595.png/w_1999 1999w\"></p><h3>Racial identity</h3><p>We did not observe a significant difference in EA community satisfaction between respondents identifying as white (M = 7.19, SD = 1.61) compared to non-white (M = 7.24, SD = 1.66).&nbsp;</p><p><img src=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/45bdb519df97f6a35cad875454642eabd259029d627271ec.png\" srcset=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/45bdb519df97f6a35cad875454642eabd259029d627271ec.png/w_200 200w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/45bdb519df97f6a35cad875454642eabd259029d627271ec.png/w_400 400w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/45bdb519df97f6a35cad875454642eabd259029d627271ec.png/w_600 600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/45bdb519df97f6a35cad875454642eabd259029d627271ec.png/w_800 800w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/45bdb519df97f6a35cad875454642eabd259029d627271ec.png/w_1000 1000w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/45bdb519df97f6a35cad875454642eabd259029d627271ec.png/w_1200 1200w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/45bdb519df97f6a35cad875454642eabd259029d627271ec.png/w_1400 1400w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/45bdb519df97f6a35cad875454642eabd259029d627271ec.png/w_1600 1600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/45bdb519df97f6a35cad875454642eabd259029d627271ec.png/w_1800 1800w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/45bdb519df97f6a35cad875454642eabd259029d627271ec.png/w_1999 1999w\"></p><h3>Engagement</h3><p>Not unexpectedly, more engaged respondents reported being more satisfied with the EA community (M = 7.40, SD = 1.54) than less engaged respondents (M = 6.84, SD = 1.75)\u2013an average difference of 0.56.</p><p><img src=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/1c6ba1100091231ebb6a2150dd63aa43b9a3beddc52a01a0.png\" srcset=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/1c6ba1100091231ebb6a2150dd63aa43b9a3beddc52a01a0.png/w_200 200w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/1c6ba1100091231ebb6a2150dd63aa43b9a3beddc52a01a0.png/w_400 400w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/1c6ba1100091231ebb6a2150dd63aa43b9a3beddc52a01a0.png/w_600 600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/1c6ba1100091231ebb6a2150dd63aa43b9a3beddc52a01a0.png/w_800 800w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/1c6ba1100091231ebb6a2150dd63aa43b9a3beddc52a01a0.png/w_1000 1000w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/1c6ba1100091231ebb6a2150dd63aa43b9a3beddc52a01a0.png/w_1200 1200w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/1c6ba1100091231ebb6a2150dd63aa43b9a3beddc52a01a0.png/w_1400 1400w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/1c6ba1100091231ebb6a2150dd63aa43b9a3beddc52a01a0.png/w_1600 1600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/1c6ba1100091231ebb6a2150dd63aa43b9a3beddc52a01a0.png/w_1800 1800w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/1c6ba1100091231ebb6a2150dd63aa43b9a3beddc52a01a0.png/w_1999 1999w\"></p><h3>Cause priority</h3><p>We also looked at the relationship between EA community satisfaction and the extent to which the respondent prioritized longtermist causes over neartermist causes. Respondents indicated on a 1-5 scale the extent to which various causes should be prioritized. We calculated an average cause priority score of longtermist causes (biosecurity and pandemic preparedness, nuclear security, reducing risks from artificial intelligence, existential risk (other than AI, biosecurity, or nuclear security), and other longtermism) and subtracted the average cause priority score of neartermist causes (global poverty/global health, mental health, other neartermism). This means that higher scores on this measure indicate a greater prioritization of longtermist causes over neartermist causes.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreflfalvu7jn3h\"><sup><a href=\"#fnlfalvu7jn3h\">[2]</a></sup></span></p><p>We find a positive relationship between this measure and EA community satisfaction. Respondents who prioritize longtermism causes to a greater extent report higher satisfaction with the community (<i>r&nbsp;</i>= .25, 95% CI [.21 - .28]).&nbsp;</p><p><img src=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/fc314566183336df3a02e5a0aca3b60964a6980f47d2e36d.png\" srcset=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/fc314566183336df3a02e5a0aca3b60964a6980f47d2e36d.png/w_200 200w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/fc314566183336df3a02e5a0aca3b60964a6980f47d2e36d.png/w_400 400w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/fc314566183336df3a02e5a0aca3b60964a6980f47d2e36d.png/w_600 600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/fc314566183336df3a02e5a0aca3b60964a6980f47d2e36d.png/w_800 800w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/fc314566183336df3a02e5a0aca3b60964a6980f47d2e36d.png/w_1000 1000w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/fc314566183336df3a02e5a0aca3b60964a6980f47d2e36d.png/w_1200 1200w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/fc314566183336df3a02e5a0aca3b60964a6980f47d2e36d.png/w_1400 1400w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/fc314566183336df3a02e5a0aca3b60964a6980f47d2e36d.png/w_1600 1600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/fc314566183336df3a02e5a0aca3b60964a6980f47d2e36d.png/w_1800 1800w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/fc314566183336df3a02e5a0aca3b60964a6980f47d2e36d.png/w_1999 1999w\"></p><h3>Regression model</h3><p>In addition to the individual analyses presented earlier, we also conducted a multiple regression to see whether some of the previously reported differences also hold when all factors, including other relevant factors, are included.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefgp8tf8hyh34\"><sup><a href=\"#fngp8tf8hyh34\">[3]</a></sup></span>&nbsp;It could be the case that some of the group differences are confounded by other factors. For example, more engaged respondents are also more likely to see longtermist causes as having a higher priority, so the relationship between endorsing longtermist causes and satisfaction may be driven by engagement instead. We also included several other factors not previously mentioned as additional control variables. Note that the continuous predictors in this model (e.g., age) are standardized and scaled so they are comparable to the binary predictors (e.g., engagement; see&nbsp;<a href=\"http://www.stat.columbia.edu/~gelman/research/published/standardizing7.pdf\"><u>Gelman, 2007</u></a>).</p><p>The regression results below show that all previously mentioned group differences are also significant when controlling for the additional variables.</p><p><img src=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/a1a1702019af6773cfdeffc0bc83d0d251c10a31e965c250.png\" srcset=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/a1a1702019af6773cfdeffc0bc83d0d251c10a31e965c250.png/w_200 200w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/a1a1702019af6773cfdeffc0bc83d0d251c10a31e965c250.png/w_400 400w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/a1a1702019af6773cfdeffc0bc83d0d251c10a31e965c250.png/w_600 600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/a1a1702019af6773cfdeffc0bc83d0d251c10a31e965c250.png/w_800 800w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/a1a1702019af6773cfdeffc0bc83d0d251c10a31e965c250.png/w_1000 1000w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/a1a1702019af6773cfdeffc0bc83d0d251c10a31e965c250.png/w_1200 1200w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/a1a1702019af6773cfdeffc0bc83d0d251c10a31e965c250.png/w_1400 1400w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/a1a1702019af6773cfdeffc0bc83d0d251c10a31e965c250.png/w_1600 1600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/a1a1702019af6773cfdeffc0bc83d0d251c10a31e965c250.png/w_1800 1800w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/a1a1702019af6773cfdeffc0bc83d0d251c10a31e965c250.png/w_1999 1999w\"></p><h2>Predicted retention in EA</h2><p>The majority of respondents indicated they are likely to still be involved in the EA community in three years\u2019 time (84.1%). Some respondents (10.9%) indicated chances were about even to still be involved. Only a small minority (5.1%) indicated they would likely not be involved anymore.</p><p>Naturally, we might expect these figures to be too optimistic, in that people who are less likely to remain in EA may be less likely to take the EA Survey. Nevertheless, they may still serve as something of an early warning system of concerns in the community.</p><p><img src=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/ee7e50865de2e2660dabdb060ac4c70e4a66d522bfd85d6b.png\" srcset=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/ee7e50865de2e2660dabdb060ac4c70e4a66d522bfd85d6b.png/w_200 200w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/ee7e50865de2e2660dabdb060ac4c70e4a66d522bfd85d6b.png/w_400 400w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/ee7e50865de2e2660dabdb060ac4c70e4a66d522bfd85d6b.png/w_600 600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/ee7e50865de2e2660dabdb060ac4c70e4a66d522bfd85d6b.png/w_800 800w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/ee7e50865de2e2660dabdb060ac4c70e4a66d522bfd85d6b.png/w_1000 1000w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/ee7e50865de2e2660dabdb060ac4c70e4a66d522bfd85d6b.png/w_1200 1200w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/ee7e50865de2e2660dabdb060ac4c70e4a66d522bfd85d6b.png/w_1400 1400w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/ee7e50865de2e2660dabdb060ac4c70e4a66d522bfd85d6b.png/w_1600 1600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/ee7e50865de2e2660dabdb060ac4c70e4a66d522bfd85d6b.png/w_1800 1800w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/ee7e50865de2e2660dabdb060ac4c70e4a66d522bfd85d6b.png/w_1999 1999w\"></p><h3>Cohort</h3><p>Earlier cohorts seem more likely to stay in the EA community than the newest cohort (those who joined in 2022).&nbsp;</p><h3><img src=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/16bf0dd46569e247fc261ccf0ab0bc51be20e9473a2ff69a.png\" srcset=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/16bf0dd46569e247fc261ccf0ab0bc51be20e9473a2ff69a.png/w_200 200w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/16bf0dd46569e247fc261ccf0ab0bc51be20e9473a2ff69a.png/w_400 400w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/16bf0dd46569e247fc261ccf0ab0bc51be20e9473a2ff69a.png/w_600 600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/16bf0dd46569e247fc261ccf0ab0bc51be20e9473a2ff69a.png/w_800 800w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/16bf0dd46569e247fc261ccf0ab0bc51be20e9473a2ff69a.png/w_1000 1000w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/16bf0dd46569e247fc261ccf0ab0bc51be20e9473a2ff69a.png/w_1200 1200w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/16bf0dd46569e247fc261ccf0ab0bc51be20e9473a2ff69a.png/w_1400 1400w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/16bf0dd46569e247fc261ccf0ab0bc51be20e9473a2ff69a.png/w_1600 1600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/16bf0dd46569e247fc261ccf0ab0bc51be20e9473a2ff69a.png/w_1800 1800w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/16bf0dd46569e247fc261ccf0ab0bc51be20e9473a2ff69a.png/w_1999 1999w\"></h3><h3>Gender</h3><p>Respondents identifying as a man report being likely to remain involved in the EA community (M = 5.48, SD = 0.98) than respondents who did not indicate identifying as a man (M = 5.26, SD = 1.12)\u2013a difference of 0.22.</p><p><img src=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/074da01b23a1ce022f13d8a291d7bf3776e33119d718b8cc.png\" srcset=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/074da01b23a1ce022f13d8a291d7bf3776e33119d718b8cc.png/w_200 200w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/074da01b23a1ce022f13d8a291d7bf3776e33119d718b8cc.png/w_400 400w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/074da01b23a1ce022f13d8a291d7bf3776e33119d718b8cc.png/w_600 600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/074da01b23a1ce022f13d8a291d7bf3776e33119d718b8cc.png/w_800 800w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/074da01b23a1ce022f13d8a291d7bf3776e33119d718b8cc.png/w_1000 1000w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/074da01b23a1ce022f13d8a291d7bf3776e33119d718b8cc.png/w_1200 1200w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/074da01b23a1ce022f13d8a291d7bf3776e33119d718b8cc.png/w_1400 1400w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/074da01b23a1ce022f13d8a291d7bf3776e33119d718b8cc.png/w_1600 1600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/074da01b23a1ce022f13d8a291d7bf3776e33119d718b8cc.png/w_1800 1800w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/074da01b23a1ce022f13d8a291d7bf3776e33119d718b8cc.png/w_1999 1999w\"></p><h3>Racial identity</h3><p>No significant difference was found between respondents identifying as white (M = 5.41, SD = 1.00) compared to respondents not identifying as white (M = 5.43, SD = 1.06).</p><p><img src=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/03f8a57491f35d3996abfb00bafa30502579fe57dc3492a9.png\" srcset=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/03f8a57491f35d3996abfb00bafa30502579fe57dc3492a9.png/w_200 200w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/03f8a57491f35d3996abfb00bafa30502579fe57dc3492a9.png/w_400 400w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/03f8a57491f35d3996abfb00bafa30502579fe57dc3492a9.png/w_600 600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/03f8a57491f35d3996abfb00bafa30502579fe57dc3492a9.png/w_800 800w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/03f8a57491f35d3996abfb00bafa30502579fe57dc3492a9.png/w_1000 1000w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/03f8a57491f35d3996abfb00bafa30502579fe57dc3492a9.png/w_1200 1200w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/03f8a57491f35d3996abfb00bafa30502579fe57dc3492a9.png/w_1400 1400w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/03f8a57491f35d3996abfb00bafa30502579fe57dc3492a9.png/w_1600 1600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/03f8a57491f35d3996abfb00bafa30502579fe57dc3492a9.png/w_1800 1800w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/03f8a57491f35d3996abfb00bafa30502579fe57dc3492a9.png/w_1999 1999w\"></p><h3>Engagement</h3><p>More engaged respondents reported being more likely to stay involved in the EA community (M = 5.66, SD = 0.88) than less engaged respondents (M = 5.01, 1.12). The difference was quite sizable, with an average difference of 0.64 on a 7-point scale.</p><p><img src=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/83b64e8d8210fcccceecd83d7113a1694be4507c2e4d6a46.png\" srcset=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/83b64e8d8210fcccceecd83d7113a1694be4507c2e4d6a46.png/w_200 200w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/83b64e8d8210fcccceecd83d7113a1694be4507c2e4d6a46.png/w_400 400w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/83b64e8d8210fcccceecd83d7113a1694be4507c2e4d6a46.png/w_600 600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/83b64e8d8210fcccceecd83d7113a1694be4507c2e4d6a46.png/w_800 800w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/83b64e8d8210fcccceecd83d7113a1694be4507c2e4d6a46.png/w_1000 1000w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/83b64e8d8210fcccceecd83d7113a1694be4507c2e4d6a46.png/w_1200 1200w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/83b64e8d8210fcccceecd83d7113a1694be4507c2e4d6a46.png/w_1400 1400w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/83b64e8d8210fcccceecd83d7113a1694be4507c2e4d6a46.png/w_1600 1600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/83b64e8d8210fcccceecd83d7113a1694be4507c2e4d6a46.png/w_1800 1800w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/83b64e8d8210fcccceecd83d7113a1694be4507c2e4d6a46.png/w_1999 1999w\"></p><h3>Cause priority</h3><p>The degree to which respondents endorsed various cause prioritizations was also found to be related to their reported likelihood of staying involved in the EA community. Using our measure of prioritizing longtermist causes over neartermist causes, we again find a positive relationship indicating that respondents who prioritize longtermist causes to a greater extent report being more likely to stay with the community (<i>r</i> = .29, 95% CI [.26 - .33]).</p><p><img src=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/b6b2d9e75ae5121e4bcce16f48b7dba85274077bc86a4c04.png\" srcset=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/b6b2d9e75ae5121e4bcce16f48b7dba85274077bc86a4c04.png/w_200 200w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/b6b2d9e75ae5121e4bcce16f48b7dba85274077bc86a4c04.png/w_400 400w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/b6b2d9e75ae5121e4bcce16f48b7dba85274077bc86a4c04.png/w_600 600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/b6b2d9e75ae5121e4bcce16f48b7dba85274077bc86a4c04.png/w_800 800w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/b6b2d9e75ae5121e4bcce16f48b7dba85274077bc86a4c04.png/w_1000 1000w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/b6b2d9e75ae5121e4bcce16f48b7dba85274077bc86a4c04.png/w_1200 1200w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/b6b2d9e75ae5121e4bcce16f48b7dba85274077bc86a4c04.png/w_1400 1400w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/b6b2d9e75ae5121e4bcce16f48b7dba85274077bc86a4c04.png/w_1600 1600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/b6b2d9e75ae5121e4bcce16f48b7dba85274077bc86a4c04.png/w_1800 1800w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/b6b2d9e75ae5121e4bcce16f48b7dba85274077bc86a4c04.png/w_1999 1999w\"></p><h3>Regression model</h3><p>The previously reported differences also remained significantly related to reported likelihood of staying in the EA community in a linear multiple regression that included previously mentioned factors and additional control variables.</p><p><img src=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/fad3a3f4d561305211fc9ffa1441ce85902128802ef7e077.png\" srcset=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/fad3a3f4d561305211fc9ffa1441ce85902128802ef7e077.png/w_200 200w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/fad3a3f4d561305211fc9ffa1441ce85902128802ef7e077.png/w_400 400w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/fad3a3f4d561305211fc9ffa1441ce85902128802ef7e077.png/w_600 600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/fad3a3f4d561305211fc9ffa1441ce85902128802ef7e077.png/w_800 800w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/fad3a3f4d561305211fc9ffa1441ce85902128802ef7e077.png/w_1000 1000w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/fad3a3f4d561305211fc9ffa1441ce85902128802ef7e077.png/w_1200 1200w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/fad3a3f4d561305211fc9ffa1441ce85902128802ef7e077.png/w_1400 1400w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/fad3a3f4d561305211fc9ffa1441ce85902128802ef7e077.png/w_1600 1600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/fad3a3f4d561305211fc9ffa1441ce85902128802ef7e077.png/w_1800 1800w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/fad3a3f4d561305211fc9ffa1441ce85902128802ef7e077.png/w_1999 1999w\"></p><h2>Mental health</h2><p>We asked respondents whether experiences with EA/EA-adjacent ideas and the EA community had increased or decreased their mental health. Respondents mostly indicated that their experiences had increased their mental health (36.8%) or that it had remained about the same (36.0%). A smaller group indicated their mental health had somewhat decreased (13.6%) or even greatly decreased (2.8%).&nbsp;</p><p><img src=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/1bd26b267e3433e391aa842354984a6260870bcc568320e7.png\" srcset=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/1bd26b267e3433e391aa842354984a6260870bcc568320e7.png/w_200 200w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/1bd26b267e3433e391aa842354984a6260870bcc568320e7.png/w_400 400w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/1bd26b267e3433e391aa842354984a6260870bcc568320e7.png/w_600 600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/1bd26b267e3433e391aa842354984a6260870bcc568320e7.png/w_800 800w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/1bd26b267e3433e391aa842354984a6260870bcc568320e7.png/w_1000 1000w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/1bd26b267e3433e391aa842354984a6260870bcc568320e7.png/w_1200 1200w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/1bd26b267e3433e391aa842354984a6260870bcc568320e7.png/w_1400 1400w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/1bd26b267e3433e391aa842354984a6260870bcc568320e7.png/w_1600 1600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/1bd26b267e3433e391aa842354984a6260870bcc568320e7.png/w_1800 1800w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/1bd26b267e3433e391aa842354984a6260870bcc568320e7.png/w_1999 1999w\"></p><h3>Gender</h3><p>We mainly found no gender differences for the different response options, although we did find that respondents who identified as a man were slightly less likely to report that their mental health had greatly decreased compared to respondents not identifying as a man.</p><p><img src=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/d9ad479e313576b515f32687e64cd1a952f300caa8033054.png\" srcset=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/d9ad479e313576b515f32687e64cd1a952f300caa8033054.png/w_200 200w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/d9ad479e313576b515f32687e64cd1a952f300caa8033054.png/w_400 400w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/d9ad479e313576b515f32687e64cd1a952f300caa8033054.png/w_600 600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/d9ad479e313576b515f32687e64cd1a952f300caa8033054.png/w_800 800w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/d9ad479e313576b515f32687e64cd1a952f300caa8033054.png/w_1000 1000w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/d9ad479e313576b515f32687e64cd1a952f300caa8033054.png/w_1200 1200w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/d9ad479e313576b515f32687e64cd1a952f300caa8033054.png/w_1400 1400w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/d9ad479e313576b515f32687e64cd1a952f300caa8033054.png/w_1600 1600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/d9ad479e313576b515f32687e64cd1a952f300caa8033054.png/w_1800 1800w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/d9ad479e313576b515f32687e64cd1a952f300caa8033054.png/w_1999 1999w\"></p><h3>Racial identity</h3><p>Respondents identifying as white were slightly more likely to report that they don\u2019t know or are unsure about whether experiences with EA had increased or decreased their mental health while respondents not identifying as white were slightly more likely to indicate that their mental health had greatly increased.</p><p><img src=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/6a051ee269a7211b8b33a5534a7732f30040a7db7e17fef5.png\" srcset=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/6a051ee269a7211b8b33a5534a7732f30040a7db7e17fef5.png/w_200 200w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/6a051ee269a7211b8b33a5534a7732f30040a7db7e17fef5.png/w_400 400w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/6a051ee269a7211b8b33a5534a7732f30040a7db7e17fef5.png/w_600 600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/6a051ee269a7211b8b33a5534a7732f30040a7db7e17fef5.png/w_800 800w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/6a051ee269a7211b8b33a5534a7732f30040a7db7e17fef5.png/w_1000 1000w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/6a051ee269a7211b8b33a5534a7732f30040a7db7e17fef5.png/w_1200 1200w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/6a051ee269a7211b8b33a5534a7732f30040a7db7e17fef5.png/w_1400 1400w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/6a051ee269a7211b8b33a5534a7732f30040a7db7e17fef5.png/w_1600 1600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/6a051ee269a7211b8b33a5534a7732f30040a7db7e17fef5.png/w_1800 1800w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/6a051ee269a7211b8b33a5534a7732f30040a7db7e17fef5.png/w_1999 1999w\"></p><h3>Engagement</h3><p>Respondents who were higher in EA engagement were more likely to report both that their mental health had increased or that it had decreased as a result of EA, whereas those lower in engagement were much more likely to report that it had stayed the same.</p><p><img src=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/6bc4c5b6cac34ea7650f9955993eb34ce3579d949ee4e336.png\" srcset=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/6bc4c5b6cac34ea7650f9955993eb34ce3579d949ee4e336.png/w_200 200w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/6bc4c5b6cac34ea7650f9955993eb34ce3579d949ee4e336.png/w_400 400w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/6bc4c5b6cac34ea7650f9955993eb34ce3579d949ee4e336.png/w_600 600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/6bc4c5b6cac34ea7650f9955993eb34ce3579d949ee4e336.png/w_800 800w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/6bc4c5b6cac34ea7650f9955993eb34ce3579d949ee4e336.png/w_1000 1000w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/6bc4c5b6cac34ea7650f9955993eb34ce3579d949ee4e336.png/w_1200 1200w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/6bc4c5b6cac34ea7650f9955993eb34ce3579d949ee4e336.png/w_1400 1400w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/6bc4c5b6cac34ea7650f9955993eb34ce3579d949ee4e336.png/w_1600 1600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/6bc4c5b6cac34ea7650f9955993eb34ce3579d949ee4e336.png/w_1800 1800w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/6bc4c5b6cac34ea7650f9955993eb34ce3579d949ee4e336.png/w_1999 1999w\"></p><h2>Appendix</h2><p>These plots examine the effect of support for longtermist/neartermist causes separately, rather than using a combined longtermist-minus-neartermist score. While using a single combined score is simpler,&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/g5uKzBLjiEuC5k46A/ftx-community-response-survey-results?commentId=tjuLhbYXx2s23vTXC\"><u>as we have discussed before</u></a>, looking at the effects of the two measures separately is advantageous, since these may have different relationships to the outcome variables of interest, rather than simply being mirror images of each other.</p><p><img src=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/75901db490fc8fbadab25f4df82af811a50934653c8c7289.png\" srcset=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/75901db490fc8fbadab25f4df82af811a50934653c8c7289.png/w_200 200w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/75901db490fc8fbadab25f4df82af811a50934653c8c7289.png/w_400 400w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/75901db490fc8fbadab25f4df82af811a50934653c8c7289.png/w_600 600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/75901db490fc8fbadab25f4df82af811a50934653c8c7289.png/w_800 800w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/75901db490fc8fbadab25f4df82af811a50934653c8c7289.png/w_1000 1000w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/75901db490fc8fbadab25f4df82af811a50934653c8c7289.png/w_1200 1200w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/75901db490fc8fbadab25f4df82af811a50934653c8c7289.png/w_1400 1400w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/75901db490fc8fbadab25f4df82af811a50934653c8c7289.png/w_1600 1600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/75901db490fc8fbadab25f4df82af811a50934653c8c7289.png/w_1800 1800w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/75901db490fc8fbadab25f4df82af811a50934653c8c7289.png/w_1999 1999w\"></p><p><img src=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/5ae1af14704b110896a6326e1a5e3c09e522b8f549542e5f.png\" srcset=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/5ae1af14704b110896a6326e1a5e3c09e522b8f549542e5f.png/w_200 200w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/5ae1af14704b110896a6326e1a5e3c09e522b8f549542e5f.png/w_400 400w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/5ae1af14704b110896a6326e1a5e3c09e522b8f549542e5f.png/w_600 600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/5ae1af14704b110896a6326e1a5e3c09e522b8f549542e5f.png/w_800 800w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/5ae1af14704b110896a6326e1a5e3c09e522b8f549542e5f.png/w_1000 1000w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/5ae1af14704b110896a6326e1a5e3c09e522b8f549542e5f.png/w_1200 1200w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/5ae1af14704b110896a6326e1a5e3c09e522b8f549542e5f.png/w_1400 1400w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/5ae1af14704b110896a6326e1a5e3c09e522b8f549542e5f.png/w_1600 1600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/5ae1af14704b110896a6326e1a5e3c09e522b8f549542e5f.png/w_1800 1800w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/5ae1af14704b110896a6326e1a5e3c09e522b8f549542e5f.png/w_1999 1999w\"></p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ConFiY9cRmg37fs2p/iknljsjkg9wjbzr1rlfh\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ConFiY9cRmg37fs2p/jyurkufygqkvqtvo7if7 210w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ConFiY9cRmg37fs2p/a9slgapkbeei183rf7go 420w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ConFiY9cRmg37fs2p/akgzoc3wmpkep47qwgln 630w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ConFiY9cRmg37fs2p/xfl0oizedzzu509hbabm 840w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ConFiY9cRmg37fs2p/osnhhfi7kjmbbuizkmk0 1050w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ConFiY9cRmg37fs2p/qjra1tjgvsldjjrpsocn 1260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ConFiY9cRmg37fs2p/gs8r0uiw7usyezm0ndq2 1470w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ConFiY9cRmg37fs2p/rg925cnz6gh69z2nyso1 1680w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ConFiY9cRmg37fs2p/voog6bjdjo8rh4ly3ozb 1890w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ConFiY9cRmg37fs2p/f4spg4okr8eaw5ytetpd 2048w\"></p><p><i>This research is a project of</i><a href=\"http://rethinkpriorities.org/\"><i> <u>Rethink Priorities</u></i></a><i>. This post was written by Willem Sleegers and David Moss. We would also like to thank Peter Wildeford, Jamie Elsey, Adam Papineau, &nbsp;and David Rhys Bernard for comments.</i></p><p><i>If you like our work, please consider</i><a href=\"https://www.rethinkpriorities.org/newsletter\"><i> <u>subscribing to our newsletter</u></i></a><i>. You can see more of our work </i><a href=\"https://www.rethinkpriorities.org/research\"><i><u>here</u></i></a><i>.</i></p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnau4nm6lhy5\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefau4nm6lhy5\">^</a></strong></sup></span><div class=\"footnote-content\"><p>This group difference and other group differences on EA community satisfaction and likelihood to stay involved in the EA community were analyzed using linear regression as well as ordinal regression. Both types of models produced consistent results.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnlfalvu7jn3h\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreflfalvu7jn3h\">^</a></strong></sup></span><div class=\"footnote-content\"><p>We also conducted an analysis looking at the prioritization of longtermist and neartermist causes separately (without subtracting the averages). The figures of this analysis can be found in the Appendix.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fngp8tf8hyh34\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefgp8tf8hyh34\">^</a></strong></sup></span><div class=\"footnote-content\"><p>In addition to gender, racial identity, engagement, and priority of longterm over nearterm causes, we also included age, student status (student/not a student), years in EA, and whether the respondent is from the U.S., similar to the model presented in the previous&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/Dhxg9BfBQEYvZETAD/ea-survey-2020-community-information#Predictors_of_Attitudes_Towards_EA_Community\"><u>community information post</u></a> from 2020. Note that career description was not included because it was not assessed this year.</p></div></li></ol>", "user": {"username": "WillemSleegers"}}, {"_id": "cypLFJNbsngcDgJqm", "title": "The harm cascade: why helping others is so hard", "postedAt": "2023-07-27T13:54:51.913Z", "htmlBody": "<p>Altruism, helping others, is so difficult. Suppose you save a child\u2019s live, and many years later that child becomes a new Hitler, killing thousands of people. Of course this is very unlikely, because there are not many Hitlers in the world. And the child could also become a scientist who invents a new vaccine that saves thousands of people. So in expectation, saving a child is good. But, it\u2019s complicated, because of\u2026</p><p>&nbsp;</p><h2>The harm cascade</h2><p>What does it mean to help others? Simply put, it means choosing something that is desired, or the consequences of which are desired, by the individuals that are helped. The individuals have positive evaluations of the choice or the consequences of the choice. This means the individuals must have personal experiences and personal desires or preferences. In this sense, the others are persons or sentient beings (including almost all humans and many non-human animals). We cannot help non-sentient objects or things that have no personal experiences and desires. The opposite of helping is harming: doing something such that individuals have negative evaluations of the consequences.&nbsp;</p><p>Now here is the real problem: almost everyone that we will help, is very likely to harm others as a consequence of the provided help. The more we help sentient beings, the more harm they will cause to others. If you help one individual, that individual is likely to cause harm to more than one other individual. Not helping that one individual will result in less harm caused to other individuals. So that means those other individuals are helped. But to make it more complex, when they are helped, those other individuals will cause harm to even more other individuals.&nbsp;</p><p>Suppose each saved individual will \u2013 as a consequence of the help \u2013 kill two other individuals. Or vice versa: killing (harming) one individual will save (help) two other individuals. So if you help individual A, she will harm individuals B and C, such that these two individuals will no longer harm their victims, namely individuals D, E, F and G. The latter individuals are helped and will as a consequence harm individuals H, I, J, K, L, M, N and O, who will no longer harm individuals P, Q,\u2026 And so forth. This is the harm cascade.</p><p>As a concrete example, consider saving a human child\u2019s life. That child will not become a new Hitler, but is most likely a meat eater: she will eat more than one animal during her life. And if you help a poor person raising his income, that person is likely to spend some of that extra income on meat, thereby increasing animal farming that causes harm to even more animals. This is the <a href=\"https://forum.effectivealtruism.org/topics/meat-eater-problem\">poor meat-eater problem</a>. What if the humans that you helped become vegan and stop eating animal products? That will reduce animal farming and the use of agricultural land. Those vegans may have a preference for turning that unused farm land back into natural habitat. That will increase the population of wild animals. Those wild animals may be better-off than farmed animals, but many of those wild animals will cause harm to other wild animals.&nbsp;</p><p>In nature we see again a harm cascade. One top-predator kills more than one meso-predators. Those harmed meso-predators can no longer kill their many prey. So due to the top-predator harming many animals, many other prey animals are saved. Those saved animals can cause harm to even other animals. Especially in aquatic ecosystems we see long food chains, where a top predator is like a serial killer who kills many other serial killers who kill even more serial killers, and so on.</p><p>If animals are not killed by predators, they might increase in population and hence increase competition for food with other animals. They might use violence to attain food or protect territory, because food and territory are scarce resources. As territory is scares and all territory is occupied by sentient beings, almost every sentient being conquered territory of other sentient beings, who conquered the territory of even other sentient beings. And there is not only competition for food, water and territory, but also for sexual partners. One male animal might use violence against other competing males to mate with a female animal. And of course one large animal might accidentally injure and kill many small animals.&nbsp;</p><p>In all these cases, animals are causing direct harm to other animals. Without the harming animals, the other animals would be better-off. But animals may also harm other animals indirectly. For example, if they are not eaten by predators, not trampled by large animals and have enough food to eat, the animal population might increase, making it more susceptible to infectious diseases and parasites. As with contagious diseases, one infected animal might infect more than one other animal. And in cold environments, saving an animal allows that animal to reproduce. But that animal gives birth to many offspring. Many of those offspring will freeze to death right after they are born. That means those newborn animals have lives full of suffering. These are lives not worth living because they are dominated by negative experiences of freezing to death. For those animals, it would have been better if they were not born. In that sense, the one adult animal that you saved will harm many of her newborn children, by giving them a net-negative life, by letting them freeze to death.&nbsp;</p><p>Of course, the harm cascade does not go on infinitely, because the number of individuals that can be harmed is finite. But it is very difficult to determine where the cascade stops. This uncertainty about the length and structure of the harm cascade is probably the most important aspect of&nbsp;<a href=\"https://80000hours.org/articles/cluelessness/\">cluelessness</a> in effective altruism.</p><p>&nbsp;</p><h2>Why is there a harm cascade?</h2><p>Why is it so likely that helping one individual will harm more than one other individual? The underlying mechanism or reason is that if a male and a female sentient being reproduce, they will give birth to on average more than two children. That means many of the offspring will die before they can reproduce, otherwise we would see an exponential growth of the global population of sentient beings on Earth. In fact, most of the individuals that are born on Earth, do not reproduce. They die too young or are prevented from reproduction. Almost all farmed animals are slaughtered before they could reproduce. Only a small minority of farmed animals give birth to the many other farmed animals. Similarly, almost all newborn wild animals die prematurely from predation, starvation, competition, parasitism, diseases, extreme weather events and so forth.</p><p>In many of the cases, the offspring that died prematurely, are killed directly or indirectly by other sentient beings. The newborn animals are captured by predators, infected by parasites, infected by animals with contagious diseases, trampled by large animals, injured by competitors for sexual partners and territory or starved by animals that took the food. Hence, in many cases, other animals are the culprit of the harm.</p><p>If most animals die prematurely, it means that most animals in the world do not harm many others, because they do not have enough time to harm other animals. So most animals do not actually harm others. The small minority of animals that live long enough to reproduce, also live long enough to harm others. These are the animals that cause the most harm.</p><p>If we help an individual sentient being (human or animal), there are two important consequences. First, the individual is likely to live longer and hence more likely to cause harm to others. Second, that individual is more likely to reproduce and give birth to many children. And a lot of those children will be harmed and killed by other individuals or will have lives not worth living. For non-human animals, the majority of newborn children will be harmed by others.</p><p>&nbsp;</p><h2>Antispeciesism</h2><p>As is clear in the above discussion of the harm cascade, all individuals, without arbitrary exceptions, are considered. Everyone\u2019s interests matter. We do not only have to help humans, but also members from other species. Speciesism is discrimination on the basis of species, or more generally, on the basis of a biological category. The problem is that almost all sentient beings are speciesist, in the sense that they treat individuals that are biologically more related to them different from other, less related individuals. For example, they treat other sentient beings that are not their kin in ways that they do not want to be treated themselves. They violate the golden rule (do not treat others in ways that you do not want to be treated). Especially predators are speciesist.</p><p>Only a few individuals are antispeciesist. These are humans who adopted a vegan lifestyle and support animal welfare causes. However,&nbsp;<a href=\"https://stijnbruers.wordpress.com/2016/09/12/on-intervention-in-nature-human-arrogance-and-moral-blind-spots/\">even many of those vegan animal rights activists and animal welfare advocates are still speciesist</a>, because they believe that humans should not massively intervene in nature to help wild animals. They believe that humans should leave nature alone, that harm caused by humans is worse than harm caused by non-humans. This is a clearly speciesist attitude because it refers to a specific species. Non-human animals such as predators are&nbsp;<a href=\"https://stijnbruers.wordpress.com/2022/11/24/blatant-contradictions-in-the-argument-that-predation-benefits-ecosystems/\">allowed to massively intervene in nature</a>, according to those animal advocates, but humans are not.</p><p>To effectively help others, we have to avoid speciesist biases. What we can do, is <a href=\"https://stijnbruers.wordpress.com/2018/09/24/what-if-everyone-was-human/\">considering all sentient beings as humans</a>, with different physical and mental properties.</p><p>&nbsp;</p><h2>How to help others and avoid the harm cascade?</h2><p>Really helping others and avoiding the harm cascade is more difficult than what most people realize. What can we do? Which organizations can we support?</p><p>There are four approaches we can follow to deal with the harm cascade problem. First, we can focus on helping those sentient beings that least contribute to the harm cascade, i.e. those individuals that are least likely to cause harm when they are helped. Second, we can look for methods or interventions that reduce or eliminate the harm cascade. Third, we can help individuals in such a way that the provided help does not contribute to the harm cascade, i.e. the individuals will not cause extra harm as a result of the provided help. Fourth, we can do more scientific research on how to reduce and eliminate the harm cascade.</p><p>Concerning the first approach, when we want to help others, we can prioritize who to help. It is best to help sentient beings who do not reproduce too much (i.e. do not have too many offspring that cannot survive), who do not harm others much, and preferably, who are able to help others. Helping others can be done by inventing technologies that benefit others, by collaborating with others or by creating mutually beneficial situations (such as trade). The ideal individual to help would be a&nbsp;<a href=\"https://stijnbruers.wordpress.com/2020/02/25/arguments-for-an-impartial-preference-for-human-lives/\">vegan, antispeciesist human</a>. That person has a long life, can attain a high positive welfare, does not abuse other sentient beings, is able to acquire and share resources (territory, food,\u2026) in a fair way with others, is able to collaborate with others, is able to help others with technologies, and has a number of children close to the replacement level (i.e. two children per adult couple) such that every child can become adult and reproduce without creating an overpopulation problem.</p><p>Veganism means abstaining from animal-based food. What happens if humans switch to vegan diets? Animal-free food production requires less agricultural land. So the question becomes: what happens with that agricultural land that is no longer needed for farmed animals? First, it can be used to produce more food for more humans. Food will become cheaper and more available, such that more humans can be born and live sustainably. If the agricultural land is not used for human purposes, it becomes nature again. That means more wild animals will be born and live in that new natural habitat. Most farmed animals have lives worse than most wild animals and humans. A&nbsp;<a href=\"https://www.tandfonline.com/doi/abs/10.1080/21606544.2022.2138980\">majority</a>&nbsp;<a href=\"https://link.springer.com/article/10.1007/s00355-020-01287-7\">of people</a> believe that most farmed animals (those in factory farms) have net-negative lives. Most humans have positive lives and for wild animals the&nbsp;<a href=\"https://link.springer.com/article/10.1007/s10539-019-9692-0\">case is uncertain</a> (<a href=\"https://www.stafforini.com/docs/Horta%20-%20Debunking%20the%20idyllic%20view%20of%20natural%20processes.pdf\">some argue that wild animals have net-negative lives</a>, <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10008771/\">others that they may have positive lives</a>). I think it is unlikely that wild animals have lives as bad as or worse than those of farmed animals, which are mostly farmed fish and poultry (this is confirmed by the <a href=\"https://www.charityentrepreneurship.com/post/is-it-better-to-be-a-wild-rat-or-a-factory-farmed-cow-a-systematic-method-for-comparing-animal-welf\">Weighted Animal Welfare Index</a> study done by Charity Entrepreneurship). Hence, when humans go vegan, farmed animals are no longer born, but they are replaced by humans and wild animals who likely have higher welfare levels.&nbsp;</p><p>To help vegan antispeciesist humans, we first have to promote veganism and antispeciesism, such that more humans become vegan and antispeciesist. I think&nbsp;<a href=\"https://www.animal-ethics.org/\">Animal Ethics</a> is one of the best organization that promote antispeciesism, and the&nbsp;<a href=\"https://gfi.org/\">Good Food Institute</a> is one of the best organizations to promote animal-free diets.</p><p>Our next candidates on the list of sentient beings we can help with priority, are large herbivores. They do not prey on others and their fertility can be more easily controlled with contraception. Some random examples of organizations that help large herbivores, are&nbsp;<a href=\"https://donkeyrescue.org/\">Donkey Rescue</a> and&nbsp;<a href=\"https://www.savetheelephants.org/\">Save the Elephants</a>. But these are probably not the most cost-effective organizations to help animals.&nbsp; &nbsp;&nbsp;</p><p>Concerning small animals, there is&nbsp;<a href=\"https://stijnbruers.wordpress.com/2019/07/24/about-insect-welfare-and-how-to-improve-it/\">increasing evidence</a> that insects such as bees are sentient. Here we can prioritize helping bees and dung beetles, because these insects do not hunt other animals, are not aggressive, are not parasitic, do not compete much for scarce food resources with other animals and instead help increase food production (by pollination and fertilizing the soil).&nbsp;<a href=\"https://www.pollinator.org/\">Pollinator Partnership</a> is an example of an organization that protects bees. In general, we can prioritize helping&nbsp;<a href=\"https://en.wikipedia.org/wiki/List_of_herbivorous_animals\">herbivorous animals</a>, but there are not many organizations that specialize in helping them. And there are not so many purely herbivorous animals.</p><p>Next to the question of which sentient beings we can prioritize to help, we can look for more broad approaches that reduce or eliminate the harm cascade. Here are two interesting examples.&nbsp;</p><p>First, as mentioned above, the crucial underlying mechanism behind the harm cascade, is the high reproduction rate or fertility rate of most sentient beings: one reproducing animal gives birth to many offspring. Humans are the only population of sentient beings that have avoided excess reproduction, by using voluntary family planning methods such as contraception. As a consequence, the human population will not explode, and every newborn human child is likely to survive and be able to live long enough to reproduce. All non-human animal populations (including farmed animals and wild animals) have reproduction rates that are too high. The excess reproduction rate of farmed animals can of course be decreased by eliminating animal farming (i.e. going vegan). For wild animals, wildlife fertility control (contraception for and sterilization of wild animals) can reduce reproduction rates.&nbsp;<a href=\"https://www.fyxxfoundation.org/\">FYXX Foundation</a> is an organization that specializes in wildlife fertility control. Especially reducing the fertility of predators (e.g. cats) and small animals with high reproduction rates (e.g. rats) can be prioritized.</p><p>Second, we can eliminate harmful processes that contribute to the harm cascade, such as infectious diseases and parasitism. Vaccination is an effective method to prevent that one sentient being harms another.&nbsp;<a href=\"https://missionrabies.com/\">Mission Rabies</a> and&nbsp;<a href=\"https://wildanimalhealthfund.org/\">Wild Animal Health Fund</a> are organizations that provide vaccination for wild animals. Unfortunately, the latter organization also helps wild animals such as predators in other ways that contribute to the harm cascade. Other methods that are explored to eradicate diseases and parasitism, include gene editing and gene drives. Gene drives can also be used for other purposes, such as reducing fertility rates of wild animals. For example,&nbsp;<a href=\"https://targetmalaria.org/\">Target Malaria</a> intends to use gene drives to eradicate malaria mosquito\u2019s.&nbsp;<a href=\"https://www.oxitec.com/\">Oxitec</a> is a company that develops genetically modified insects to reduce reproduction rates in insects. Supporting gene drive research like Target Malaria is important, because it helps eradicating diseases and avoid excess reproduction of wild animals, and it teaches us how to apply gene drives safely.&nbsp;</p><p>The third approach we can follow, is providing help that does not cause the helped individual to harm others. Think of increasing the happiness of sentient beings.&nbsp;<a href=\"https://www.happierlivesinstitute.org/\">Happier Lives Institute</a> does research on how to increase mental well-being and happiness of humans,&nbsp;<a href=\"https://strongminds.org/\">Strong Minds</a> treats depression in poor countries, and the abovementioned&nbsp;<a href=\"https://wildanimalhealthfund.org/\">Wild Animal Health Fund</a> provides pain relief to wild animals.</p><p>Finally, there is a fourth approach to deal with the harm cascade: do more research on how to solve this problem. This is a meta-approach, and probably the most important and most effective thing we can do about the harm cascade.&nbsp;<a href=\"https://www.wildanimalinitiative.org/\">Wild animal Initiative</a> does research on how to generally help wild animals.&nbsp;</p><p>&nbsp;</p><h2>Which organizations should we avoid supporting?</h2><p>For completeness, it is also interesting to see which organizations we should definitely not support when we want to solve the harm cascade problem or want to help others without causing extra harm. Unfortunately, I personally supported many of such organizations in the past, a choice I now regret. Here is a short list of organizations to avoid.</p><ul><li>Organizations that focus on human overpopulation and want to reduce human population growth. In contrast to what those organizations claim, there is&nbsp;<a href=\"https://stijnbruers.wordpress.com/2019/02/09/non-human-overpopulation-is-the-real-problem/\">no human overpopulation problem</a>. Rather, wild animals face a serious overpopulation crisis every year, due to their high reproduction rates. As discussed above and&nbsp;<a href=\"https://stijnbruers.wordpress.com/2023/06/20/birth-prioritization-or-why-vegans-should-have-more-kids/\">elsewhere</a>, humans (when they are vegan) are unique as they most easily avoid the harm cascade, they avoid overpopulation and they can contribute most to global welfare. Therefore, it would be better to have a world with more humans (and fewer wild animals, and no farmed animals). Disclaimer: in the past I founded a short-lived organization DEEP (Deep Ecological and Ethical Project) and I supported other organizations such as Population Matters, Population Connection and Population 2.0, that campaigned against human overpopulation.</li><li>Organizations that help many wild animals or help carnivorous animals in particular, such as cat and dog shelters. These organizations help animals such as predators that cause harm to other animals. Disclaimer: in the past I volunteered for many years at a wildlife rescue centers that took care of predators such as birds of prey, and I volunteered for the Shark Alliance.</li><li>Environmental protection organizations that protest against gene drives and gene editing to control insect populations (such as the project of Target Malaria). Disclaimer: in the past I did actions with such environmental protection organizations, including Greenpeace and Friends of the Earth.</li><li>Anti-poaching organizations, especially when they protect predator species. Disclaimer: in the past I sailed with Sea Shepherd.</li><li>Nature conservation organizations. These organizations are against large scale interventions to improve wild animal welfare. Disclaimer: in the past I volunteered at and funded nature conservation organizations such as WWF.</li></ul><p>&nbsp;</p><h2>A (controversial) vision of the far future</h2><p>In this final section, I want to describe a vision that I have for the far future, what the world might look like when we eradicated harm cascades and are effectively helping all sentient beings. Note that this is just a very hypothetical scenario, because I do not know what future technologies are possible. I also chose the more controversial examples.</p><p>Animals will no longer be used in food production. But I suggest to also avoid using&nbsp;<a href=\"https://stijnbruers.wordpress.com/2020/10/23/towards-zero-harm-and-more-sustainability-animal-free-and-land-free-food/\">land</a>&nbsp;<a href=\"https://stijnbruers.wordpress.com/2020/11/20/from-shiva-to-dyson-a-paradigm-shift-from-soil-based-low-tech-to-air-based-high-tech-food/\">or soil</a> in food production, because outdoor farming harms wild animals on agricultural land (e.g. with insecticides, rodenticides and heavy machinery). Hence, ideally all food will be produced&nbsp;<a href=\"https://stijnbruers.wordpress.com/2021/09/14/why-indoor-vertical-agriculture-will-be-better-infographic/\">indoors</a>, for example in&nbsp;<a href=\"https://vertical-farming.net/\">vertical farms</a>. But then again, what about all that vacant land that is no longer used for agriculture? Part of it can be used by extra humans for infrastructure and buildings, the rest can be used for wild animals. Wild animals will have more food that can grow on that vacant land. But as more wild animals will survive, we have a responsibility to take care of their welfare. This requires large scale interventions in nature. We need more research into new technologies that can help wild animals. Perhaps with gene editing and gene drives we can control animal populations, decrease their fertility rates to sustainable levels. Perhaps with universal vaccination we can eradicate harmful viruses, bacteria and parasites. Perhaps it is possible to&nbsp;<a href=\"https://www.herbivorizepredators.org/\">herbivorize predators</a> or genetically modify plants to make them more attractive and digestible for carnivorous animals. Perhaps cultivated meat technologies can provide sufficient food for carnivorous animals. Perhaps with gene editing we can modify animal preferences and eradicate violent or aggressive behavior in animals. Perhaps we can cognitively enhance animals to increase cooperation and empathy. Perhaps we can desensitize some animals. Think of the zooplankton: it is possible that those small animals are sentient, but they are killed by the millions by a baleen whale. If we could make the zooplankton animals insentient, baleen whales can still eat them but no longer harm them. The same goes for desensitizing other small animals and invertebrates that are killed by accident by large herbivores. For all of these utopian ideas, much more research is required. It is not yet known which of those ideas are safe and effective in reducing harm.&nbsp;</p><p>&nbsp;</p><h2>Summary</h2><p>Helping one sentient being (human or animal) often leads to harm to more than one other sentient being. This generates a harm cascade, where help results in more harm, which in turn results in more help, which causes even more harm, and so on. It is like saving the life of a serial killer who kills many other serial killers who kill even more serial killers, and so on. Due to such a harm cascade, helping others is very difficult. &nbsp;</p><p>The harm cascade is the result of the high fertility rates of sentient beings. As most reproducing sentient beings give birth to more than two offspring, most of the newborn sentient beings die prematurely, and other sentient beings are often the cause of death of those sentient beings. Many of the newborn, short-lived animals may also have lives not worth living (especially animals born in harsh cold environments and in factory farms). Hence, allowing animals in the wild to reproduce at a high rate, or causing animals on farms to reproduce at a high rate, causes harm.&nbsp;</p><p>To effectively help others without falling in this harm cascade, there are four things we can do. First, we can prioritize helping those sentient beings that are least likely to cause extra harm when they are helped (e.g. vegans, large herbivores, bees and dung beetles). Second, we can look for methods that reduce or eliminate the harm cascade, such as wildlife fertility control, vaccination and elimination of predation (by adopting vegan diets for humans and herbivorizing wild predators). Third, we can help individuals in such a way that the individuals will not cause extra harm as a result of the provided help, for example by mental health programs for humans and pain relief for animals. Fourth, we can do more research on how to safely and effectively avoid, reduce and eliminate the harm cascade.&nbsp;</p>", "user": {"username": "Stijn"}}, {"_id": "6np8CTmoBiJGodvGB", "title": "How would a nuclear war between Russia and the US affect you personally?", "postedAt": "2023-07-27T13:06:57.101Z", "htmlBody": "<p>I was surprised this video wasn't cross-posted here yet. I found the visualization moving and an alarming reminder of just how bad a nuclear exchange would be.&nbsp;</p><figure class=\"media\"><div data-oembed-url=\"https://www.youtube.com/watch?v=-xthzy1PxTA\"><div><iframe src=\"https://www.youtube.com/embed/-xthzy1PxTA\" allow=\"autoplay; encrypted-media\" allowfullscreen=\"\"></iframe></div></div></figure>", "user": {"username": "MaxG"}}, {"_id": "2Nnu9ykixiqG2mMit", "title": "CE: Announcing our February 2024 Charity Ideas. Apply now!", "postedAt": "2023-07-27T11:41:38.553Z", "htmlBody": "<p><strong>Join our February-March 2024&nbsp; Incubation Program to start nonprofits in Mass Media (Global Health) and Animal Welfare.</strong></p><p>In this post, we announce our top four charity ideas to launch in February 2024. They are the results of months of work by our research team, who selected them through a seven-stage<a href=\"https://www.charityentrepreneurship.com/research-process-2023-2024\"><u> research process</u></a>. We pick interventions that&nbsp;exceed ambitious cost-effectiveness bars (e.g., for global health policy, this is 5x top GiveWell evaluated charities), have a high quality of evidence, minimal failure modes, and high expected value.</p><p><strong>We\u2019re seeking people to launch these ideas through our February-March 2024 Incubation Program.&nbsp;</strong>No particular previous experience is necessary - if you could plausibly see yourself excited to launch one of these charities, we encourage you to apply. The deadline for applications is September 30, 2024.</p><p><a href=\"https://form.jotform.com/231575642969167\"><strong><u>[APPLY NOW]</u></strong></a></p><p>In the Incubation Program, we provide two months of cost-covered training, stipends, funding up to $200,000, operational support in your first months, a co-working space at our CE office in London, ongoing mentorship, and access to a community of alumni, funders, and experts. Learn more on our refreshed&nbsp;<a href=\"https://www.charityentrepreneurship.com/incubation-program\"><u>CE Incubation Program page</u></a>.</p><p><br><i><strong>Disclaimer:</strong></i><strong>&nbsp;</strong></p><p><i>To be brief, we have sacrificed nuance, the details of our considerable uncertainties, and the downside risks discussed in the extended reports. Full reports will be published&nbsp;</i><a href=\"https://www.charityentrepreneurship.com/research\"><i><u>on our website</u></i></a><i> and the EA Forum and announced&nbsp;</i><a href=\"http://charityentrepreneurship.com/signup\"><i><u>in our newsletter</u></i></a><i> in the upcoming weeks.</i></p><p><i>Please note that previous incubatees attest to the ideas becoming increasingly exciting over the course of the program.</i></p><h2><strong>One-Sentence Summaries</strong><br><br>Childhood vaccination reminders&nbsp;</h2><p>An organization<strong> that sends SMS or voice messages to remind caregivers to attend their child\u2019s vaccination appointments.</strong>&nbsp;</p><h2>Mass media to prevent violence against women</h2><p>A non-profit that produces and&nbsp;<strong>delivers educational entertainment content focusing on preventing intimate partner violence</strong>.&nbsp;</p><h2>Influencing EU fish welfare policy through strategic work in Greece</h2><p>An organization<strong> focused on improving fish welfare through corporate campaigning and policy work in Greece, aiming to influence animal welfare standards at the EU level.</strong></p><h2>Influencing key stakeholders of the emerging insect industry</h2><p>An organization that&nbsp;<strong>provides</strong>&nbsp;<strong>information to relevant stakeholders on sustainability, environmental impacts, food safety concerns, and animal welfare issues related to insect farming.&nbsp;</strong><br>&nbsp;</p><h1><strong>One-Paragraph Summaries&nbsp;</strong></h1><h2>Childhood vaccination reminders&nbsp;</h2><p>In 2021, 25 million children under one&nbsp;<a href=\"https://www.who.int/news-room/fact-sheets/detail/immunization-coverage\"><u>went unvaccinated</u></a>. Studies show that mobile messages can effectively remind caregivers to keep up with their child's vaccination schedule, thereby mitigating disease risk and improving overall health outcomes (<a href=\"http://dx.doi.org/10.1002/14651858.CD003941.pub3\"><u>1</u></a>,&nbsp;<a href=\"http://dx.doi.org/10.1002/14651858.CD013679\"><u>2</u></a>,&nbsp;<a href=\"http://dx.doi.org/10.1002/14651858.CD007458.pub3\"><u>3</u></a>). Yet, such beneficial services are rarely implemented on a large scale.&nbsp;<a href=\"https://www.suvita.org/\"><u>Suvita</u></a>, a non-profit incubated by CE, is delivering this impactful service in India. A new non-profit organization will launch it in the next top-priority country. This new organization will likely coordinate closely with&nbsp;<a href=\"https://www.suvita.org/\"><u>Suvita&nbsp;</u></a>to expand to numerous priority countries or operate under the same umbrella. This intervention can be expected to help avert one disability-adjusted life year (DALY) for approximately $80, making it a highly cost-effective means to improve global health.</p><h2>Mass media to prevent violence against women</h2><p>Almost 500 million women aged 15 to 49&nbsp;<a href=\"https://doi.org/10.1016/S0140-6736(21)02664-7\"><u>have been subjected</u></a> to violence from an intimate partner at least once since they turned 15. Countless women continually face threats to their safety within their homes, experiencing physical, sexual, and emotional abuse. Fueled by societal norms and attitudes, this pervasive form of violence remains prevalent in many societies worldwide. Evidence from robust experimental (<a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4158065\"><u>1</u></a>,&nbsp;<a href=\"https://doi.org/10.1177/00104140221139385\"><u>2</u></a>,&nbsp;<a href=\"https://assets.researchsquare.com/files/rs-1137307/v1_covered.pdf?c=1638566311\"><u>3</u></a>,&nbsp;<a href=\"https://www.aeaweb.org/articles?id=10.1257/pandp.20191073\"><u>4</u></a>,&nbsp;<a href=\"https://doi.org/10.1177/0010414020912275\"><u>5</u></a>) and&nbsp;<a href=\"https://www.cambridge.org/core/journals/political-science-research-and-methods/article/how-does-media-influence-social-norms-experimental-evidence-on-the-role-of-common-knowledge/23D65E06CAB2876B08F12E23CD5C0539\"><u>quasi-experimental</u></a> studies suggests that media content designed to address these behaviors can prevent intimate partner violence. This newly-formed non-profit will produce and disseminate such media on a large scale, working to curb this problem. In doing so, it should contribute to a growing body of evidence outlining effective strategies to prevent violence against women.</p><h2>Influencing EU fish welfare policy through strategic work in Greece</h2><p><a href=\"http://fishcount.org.uk/studydatascreens2/2017/numbers-of-farmed-fish-B0-2017.php?\"><u>Greece is the largest fish producer in the EU (and the 15th largest in the world)</u></a>, but no one is working or planning to work on fish welfare there.&nbsp;</p><p>The endline goal of this charity should likely be a policy change, but corporate campaigns will likely be a useful first tool to build public and corporate support for the policy. Enshrining fish welfare in legislation in Greece would not only impact the 440 million fish farmed in the country but could also impact progress and policy on fish welfare at the EU level. We believe that having the voice of the largest fish producer in the EU leading the way on (or at least not actively against) fish welfare could go a long way.</p><h2>Influencing key stakeholders of the emerging insect industry</h2><p>Insect farming is a rapidly&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/ruFmR5oBgqLgTcp2b/insects-raised-for-food-and-feed-global-scale-practices-and\"><u>growing industry</u></a> with 10s of billions of insects alive on farms at any one point in time, primarily being farmed as feed for other animals. There are several misconceptions about this industry. Insect farming is often touted as a sustainable solution to factory farming, but there are key questions and uncertainties regarding&nbsp;<a href=\"https://www.eurogroupforanimals.org/files/eurogroupforanimals/2021-10/2021_10_29_pp_Insect%20farming_%20a%20false%20solution%20for%20the%20EU%27s%20food%20system_0.pdf#\"><u>sustainability and environmental impacts</u></a>,&nbsp;<a href=\"https://www.wwf.org.uk/sites/default/files/2021-06/The_future_of_feed_July_2021.pdf\"><u>food safety concerns</u></a>, and&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/ruFmR5oBgqLgTcp2b/insects-raised-for-food-and-feed-global-scale-practices-and\"><u>welfare issues</u></a> on farms. This charity would aim to ensure relevant stakeholders \u2013 investors, policymakers, entrepreneurs, insect farmers, etc. \u2013 are aware of the challenges and limitations of insect farming.&nbsp;</p><h1><strong>More Detailed Summaries&nbsp;</strong></h1><h2>Childhood vaccination reminders&nbsp;</h2><p>In 2021, 25 million children under one&nbsp;<a href=\"https://www.who.int/news-room/fact-sheets/detail/immunization-coverage\"><u>went unvaccinated</u></a>. For example, in 2021, only 80% of children in Africa&nbsp;<a href=\"https://immunizationdata.who.int/listing.html?topic=&amp;location=\"><u>received the</u></a> BCG vaccine (protecting against tuberculosis), while just 71% received the third dose of the DTP (diphtheria, tetanus, and pertussis) vaccine.</p><p>The solution we propose is straightforward and has demonstrated effectiveness. It involves sending reminders and encouragement to caregivers about upcoming vaccination opportunities via mobile phone (SMS or voice messages).&nbsp;</p><p>Various meta-analytic reviews, including several from Cochrane (<a href=\"http://dx.doi.org/10.1002/14651858.CD003941.pub3\"><u>1</u></a>,&nbsp;<a href=\"http://dx.doi.org/10.1002/14651858.CD013679\"><u>2</u></a>,&nbsp;<a href=\"http://dx.doi.org/10.1002/14651858.CD007458.pub3\"><u>3</u></a>), support using reminders to boost child vaccination rates. However, despite their proven effectiveness, these reminders are underutilized. Many countries with low vaccination rates have not yet scaled their use.</p><p>We constructed a model for a theoretical 20-year program in Angola to assess the cost-effectiveness of this intervention. We estimated the cost per disability-adjusted life year (DALY) averted to be between $38 and $78, considering solely the costs to the charity and including additional government expenses, respectively.</p><p><strong>Challenges</strong></p><p>Various factors can hinder scaling health technologies, including lack of resources, competing priorities, inadequate digital health information systems, poor governance, and insufficient advocacy.&nbsp;</p><p>Establishing and maintaining robust monitoring systems integrated with routine immunization data may be vital to the organization\u2019s work. An organization in this field may need to develop strategies to mitigate poor data availability, prioritizing data access and robustness while acknowledging that limited or unreliable information could pose a constraint.</p><p><strong>Particularly helpful co-founder backgrounds</strong></p><p>No particular previous experience is necessary to apply for this idea. However, the co-founding team would benefit from the following skills and experiences: 1. Experience working with government stakeholders, such as Ministries of Health; 2. Knowledge of health data systems and routine health service provision; 3. Expertise in logistics and operational efficiencies; 4. Skills in monitoring and evaluation, with a focus on extensive data monitoring. We also expect strong generalists to be able to acquire these skills on the job or hire additional team members to fill critical gaps.</p><p><strong>Collaboration with Suvita</strong></p><p>Drawing on the successful model of Suvita, a CE-incubated organization that has effectively delivered this service in parts of India, we envision a new non-profit that could implement this service in another high-priority country. This organization will likely coordinate closely with Suvita to expand to numerous priority countries in the future or could even operate under the same umbrella.</p><p><strong>Conclusion</strong></p><p>Addressing under-vaccination is a global health priority. While mobile phone reminders are not a panacea, they can significantly aid in achieving this goal at a low cost and large scale.</p><h2>Entertainment-led mass media to prevent violence against women</h2><p>Intimate Partner Violence (IPV) is a substantial, preventable human rights violation impacting millions of women worldwide. Demographic and Health Surveys (DHS) suggest that nearly&nbsp;<a href=\"https://www.statcompiler.com/en/\"><u>one-third</u></a> (31%) of women have encountered physical or sexual violence since turning 15. IPV poses significant health and economic challenges, with extensive consequences for victims.</p><p>Educational entertainment offers a promising solution to alleviate IPV's burden. It is theoretically robust, with some supportive evidence among strategies to prevent violence against women. Despite growing recognition of edutainment as an effective social intervention, not many organizations still conduct this type of work. We think there are gaps in implementation that a new organization could fill.&nbsp;</p><p>The evidence on the effectiveness of mass media in IPV is limited but cautiously optimistic: While only one<a href=\"https://doi.org/10.1177/0010414020912275\"><u> experimental study</u></a> measured effects on behavior, four other experimental (<a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4158065\"><u>1</u></a>,&nbsp;<a href=\"https://doi.org/10.1177/00104140221139385\"><u>2</u></a>,&nbsp;<a href=\"https://assets.researchsquare.com/files/rs-1137307/v1_covered.pdf?c=1638566311\"><u>3</u></a>,&nbsp;<a href=\"https://www.aeaweb.org/articles?id=10.1257/pandp.20191073\"><u>4</u></a>) and&nbsp;<a href=\"https://www.cambridge.org/core/journals/political-science-research-and-methods/article/how-does-media-influence-social-norms-experimental-evidence-on-the-role-of-common-knowledge/23D65E06CAB2876B08F12E23CD5C0539\"><u>quasi-experimental</u></a> studies found sizable shifts in attitudes and norms related to IPV. Combining these findings with the broader literature on the effects of mass media on behavior change, we believe there is a strong case for scaling up an edutainment approach in this space.</p><p>Our cost-effectiveness analysis of a hypothetical 5-year intervention in Lesotho, Rwanda, Angola, and Ethiopia revealed a cost per disability-adjusted life year (DALY) averted ranging from $28 to $1419, depending on assumptions and the country chosen. Based on our estimates, this may be among the most cost-effective interventions in the IPV space.</p><p><strong>Challenges</strong></p><p>Key data indicators will likely be scarce. Collecting IPV data may prove challenging, particularly in regions with cultural reluctance to discuss these issues. We have reservations about how easy it will be to evaluate and communicate impact to funders reliably. Effective monitoring will necessitate the triangulation of different data sources and creative utilization of impact-evaluation methodologies.&nbsp;</p><p><strong>Particularly helpful co-founder backgrounds</strong></p><p>No particular previous experience is necessary to apply for this idea. However, given the subject's sensitivity, the ideal co-founder team should be aware of IPV's complexities. Experience with or knowledge of gender equality issues and advocacy would be advantageous. As this idea is based on indicative studies and requires further testing, co-founders should be comfortable with uncertainty and exhibit a scientific mindset.</p><p>We also value organizations capable of producing high-quality, engaging content. Experience in artistic and communication fields, such as theater, TV, and writing, would be advantageous, although such skills could also be acquired through early hiring.</p><p><strong>Conclusion</strong></p><p>IPV is a significant, preventable issue. Edutainment can broadly and inexpensively address it. Encouraging evidence suggests that mass media approaches can effectively shift attitudes and behaviors towards gendered violence, positioning them among the most cost-effective interventions for this issue.</p><h2>Influencing EU fish welfare policy through strategic work in Greece</h2><p><a href=\"http://fishcount.org.uk/studydatascreens2/2017/numbers-of-farmed-fish-B0-2017.php?\"><u>Greece is the largest fish producer in the EU and the 15th largest in the world</u></a>, with over 440 million fish alive on its farms at any time. These fish are unprotected by legislation. As a result, they are left to suffer from&nbsp;<a href=\"https://www.eurogroupforanimals.org/news/terrible-suffering-and-high-mortalities-dramatic-conditions-fish-farms-greece\"><u>high stocking densities and overcrowding, barren environments with no enrichment, high mortality rates, and prolonged slaughter in an ice slurry without pre-stunning</u></a> at the end of their lives. Work to improve the lives of these animals is highly neglected. No animal advocacy organizations are working or planning to work on fish welfare in Greece. This noticeable gap should be filled to ensure that fish suffering on farms does not continue.&nbsp;</p><p>A new organization working to enshrine fish welfare in legislation in Greece would not only be beneficial for the millions of fish farmed in Greece, but could also impact progress and policy on fish welfare at the EU level. We believe that having the voice of the largest fish producer in the EU be on the side and leading the way on (or at least not actively against) fish welfare could go a long way.</p><p>Policy change should be the end goal of this work. Still, awareness-raising and corporate campaigns are likely necessary first steps to build public and corporate support, making policy change easier.</p><p>Humane slaughter could be a promising first ask. Slaughter is likely to be the focus of campaigns by other animal advocacy organizations, and it would be good to be coordinated. However, we think there could be scope to include environmental conditions \u2013 such as stocking density limits, water quality parameters, and environmental enrichment \u2013 in the ask to increase the overall impact on fish. A new organization should work with existing actors to determine these standards.&nbsp;</p><p>We expect that passing fish welfare legislation in Greece could be very cost-effective, with our model yielding an estimated impact of ~400 fish helped per dollar (leading to 370&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/cimFBQbpjntoBAKCq/is-it-better-to-be-a-wild-rat-or-a-factory-farmed-cow-a-1\"><u>welfare points</u></a> affected per dollar). This cost-effectiveness estimate does not include the impact this work could have on EU policy or the precedent-setting effect that EU policy could have globally. These effects are hard to quantify but play an important part in the overall impact that this work could have.</p><p><strong>Challenges</strong></p><p>The main challenge with this work is its uncertain tractability. There are many reasons in both directions to think this work could be easy or difficult. As an illustrative example, the Greek government took the lead in developing fish welfare guidelines adopted by the EU Platform on Animal Welfare and could be open to policy change on fish welfare. On the other hand, experts have cautioned that the Greek government is pushing for deregulation and growing the industry as quickly as possible. Welfare legislation is a push towards more regulation and could be seen as hampering growth, so perhaps the government would be against policy change on fish welfare.&nbsp;</p><p>This tractability question could be overcome through corporate campaigning. It could provide a good leverage point for future policy work as it will build public and corporate support for policy change on fish welfare.</p><p><strong>Particularly helpful co-founder backgrounds</strong></p><p>No particular previous experience is necessary to apply for this idea. It will be important for the founding team to have access to Greek language skills early to communicate with stakeholders. While this will most likely come from a first hire (or interpreters), a Greek speaking co-founder would be a significant bonus.&nbsp;</p><p>Experience with corporate campaigning and/or policy work is nice to have but not a necessity.&nbsp;</p><p><strong>Conclusion</strong></p><p>Although fish welfare legislation is rare across the globe, with only a handful of countries having any protections for fish enshrined into legislation, we think pushing for this within an EU country is likely the most tractable place to do so. Work in Greece seems particularly important given the scale of its production and the impact domestic actions could have on progress at the EU level.&nbsp;</p><h2>Influencing key stakeholders of the emerging insect industry</h2><p>In the last few years, the size of the insect farming industry has skyrocketed, with millions of dollars in seed funding raised across the industry, larger facilities beginning to open, and many new startups appearing in the space. This growth is only expected to continue, with the industry aiming to produce&nbsp;<a href=\"https://insectfeed.nl/wp-content/uploads/2021/03/Rabobank_No-Longer-Crawling-Insect-Protein-to-Come-of-Age-in-the-2020s_Feb2021-1.pdf\"><u>500,000 metric tonnes of insect protein by 2030</u></a>, likely requiring over&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/ruFmR5oBgqLgTcp2b/insects-raised-for-food-and-feed-global-scale-practices-and\"><u>100 billion insects</u></a> to be on farms at any one point in time. Most of this growth is expected to come from the insects-as-feed industry, where insects are farmed to be fed to other farmed animals as an aspirationally cheaper alternative to fishmeal, soybean meal, and other plant-based options. Insect meal will likely fulfill some of the huge unmet demand for fishmeal. This will enable the growth of aquaculture production by an&nbsp;<a href=\"https://us14.campaign-archive.com/?u=66df320da8400b581cbc1b539&amp;id=d1c18230c5\"><u>estimated 1.1% by 2030</u></a>.</p><p>There is an overwhelming lack of knowledge surrounding this industry, with questions regarding&nbsp;<a href=\"https://www.eurogroupforanimals.org/files/eurogroupforanimals/2021-10/2021_10_29_pp_Insect%20farming_%20a%20false%20solution%20for%20the%20EU%27s%20food%20system_0.pdf#\"><u>sustainability and environmental impacts</u></a>,&nbsp;<a href=\"https://www.wwf.org.uk/sites/default/files/2021-06/The_future_of_feed_July_2021.pdf\"><u>food safety concerns</u></a>, and&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/ruFmR5oBgqLgTcp2b/insects-raised-for-food-and-feed-global-scale-practices-and\"><u>animal welfare issues</u></a>. Given the scale of production \u2013 and the size of these uncertainties \u2013 we believe that the growth of insect farming deserves consideration, action, and precaution from all relevant stakeholders: investors, policymakers, entrepreneurs, insect farmers, and others.&nbsp;</p><p>Work on insect issues is very neglected. Only a handful of people (~5 FTEs) are working in this space, and most of this work primarily focuses on the welfare of insects on farms rather than actively challenging some of the underlying assumptions about insect farming. We think this is a huge underinvestment in an important issue and believe there is space for a new organization and many opportunities to pick up that existing actors might not take.</p><p><strong>Challenges</strong></p><p>As work in this space is new, there is not much of a track record to build on or learn from. This means that work will need to be innovative and cautious. Collaboration with existing actors will help to overcome these challenges.</p><p><strong>Particularly helpful co-founder backgrounds</strong></p><p>No particular previous experience is necessary to apply for this idea. A skilled generalist could do this work. Experience with corporate campaigning or other similar roles that deal with outreach and managing stakeholder relationships is nice to have but not a necessity.&nbsp;</p><p><strong>Conclusion</strong></p><p>Providing information and promoting caution amongst relevant stakeholders of the insect farming industry is an urgent priority, given the projected growth of the industry. We must address the remaining questions and uncertainties on sustainability, environmental impacts, food safety concerns, and animal welfare issues before many more insects are farmed in the current system.&nbsp;</p><h2><strong>Our cause areas for the August- September 2024 Incubation Program</strong></h2><p>You can now also apply (using the same form) to the August-September 2024 Incubation Program that will focus on:&nbsp;<br>1) The most cost-effective Sustainable Development Goals<br>2) Organophosphate pesticides and other neurotoxicants</p><p>Information about our top ideas will be announced in Spring 2024.</p><h1><strong>How to apply</strong></h1><p>To apply, fill out the&nbsp;<a href=\"https://form.jotform.com/231575642969167\"><u>[APPLICATION FORM]</u></a>, which should only take around 30 minutes. We have designed the application process also to give you a better sense of whether you are excited by this career path.</p><p>Application deadline: September 30, 2023<br><br>Would you like to explore whether this could be a good career fit for you?&nbsp;<a href=\"https://ce-quiz2023.scoreapp.com/\"><u>[TAKE OUR NEW IMPROVED QUIZ]</u></a><br><br>More information about the application process and a resource list that can help you prepare:&nbsp;<a href=\"https://www.charityentrepreneurship.com/apply\"><u>https://www.charityentrepreneurship.com/apply</u></a><br>More information about how the program is run:&nbsp;<a href=\"https://www.charityentrepreneurship.com/how-it-works\"><u>https://www.charityentrepreneurship.com/how-it-works</u></a><br>Any questions about the program:&nbsp;<a href=\"mailto:ula@charityentrepreneurship.com\"><u>ula@charityentrepreneurship.com</u></a></p>", "user": {"username": "CE"}}, {"_id": "ZCS5T6uL5sjBPLLz8", "title": "Announcing the winners of the\u00a0Reslab Request for Information", "postedAt": "2023-07-27T17:43:54.809Z", "htmlBody": "<p>We are thrilled to announce the winners of the&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/9BDzFqAXu7sqPvRn5/reslab-request-for-information-ea-hardware-projects-1\"><u>Reslab Request for Information</u></a>!</p><h1><strong>Winners</strong></h1><h3><strong>1st place ($200): Joel</strong></h3><p>For the innovative proposal \"Scalable Renewable Energy System for Disaster Relief and Off-Grid Communities.\"&nbsp;</p><p>This project aims to design and test a compact and easily transported renewable energy system, incorporating solar panels, wind turbines, and energy storage components. It aims to reduce the energy dependence of small communities.</p><h3><strong>2nd place ($150): Christoph</strong></h3><p>For the idea to develop a \"Self-Sustaining Solar-Powered Water Filtration System.\"&nbsp;</p><p>This project aims to provide clean drinking water in areas devoid of safe water resources using solar power, a compact filtration unit, and a water storage tank. The vision behind this project is to enhance the health and life quality of underserved communities and reduce reliance on external aid.</p><h3><strong>3rd place ($50): ALLFED</strong></h3><p>For the proposal to construct an \"Open Source Wood Gasifier.\"</p><p>The concept is to design a&nbsp;<a href=\"https://en.wikipedia.org/wiki/Wood_gas_generator\"><u>wood gas</u></a> generator that can be assembled without reliance on electricity or industry - a unique aspect not typically targeted by&nbsp;<a href=\"https://www.driveonwood.com/library/free-gasifier-plans/\"><u>currently available designs</u></a>. The project envisions dispersing knowledge seeds amongst hobbyists and other potential stakeholders, equipping them with practical skills for times of crisis in which energy or fuel production infrastructure is destroyed or disabled. ALLFED is currently working on this project and an article will be posted on EA Forum in the next few months.</p><h1><br><strong>We won\u2019t proceed with these projects. Will you?</strong></h1><p>The Reslab RFI was designed to incentivize and showcase excellent hardware project ideas that align with EA and longtermist cause areas. While we are very pleased with the ideas that this competition brought forward, we are not actively proceeding with the prototyping of these projects. If anyone is seriously interested in taking the lead on this project, please contact us by messaging lajko.aron@gmail.com.</p><h1><br><strong>Other project ideas that did not make it to the top three but met the requirements</strong></h1><h3>Climate control for the preservation and storage of food supplies - Adam</h3><blockquote><p>\u201cClimate control may be an important part of establishing resilient communities after a catastrophe. One especially important application would be in the long-term preservation and storage of food supplies. Traditional vapour compression systems would be very difficult to maintain without advanced industrial capacity (externally actuated systems like car AC systems might be an interesting exception). Barocaloric refrigeration systems are currently less efficient but could make up for this deficit with their very simple, robust design.\u201d</p></blockquote><h3>Testing of content on Wikiciv - anonymous</h3><blockquote><p>\u201cPractical testing of content on Wikiciv.org to improve and verify content (instructions for recreating civilizational technology).\u201d</p></blockquote><h3>Testing cold-tolerant crops - Alexey Turchin, ALLFED</h3><blockquote><p>\u201cSome cold-tolerant crops from Northern regions (fodder beet, rutabaga) could be planted in the South in the case of a nuclear war winter. But will they grow and how long it will take is questionable, but could be relatively easily measured by planting in different times and places and climates.\u201d</p></blockquote><h3>Creating a self-sustaining colony - Alexey Turchin, ALLFED</h3><blockquote><p>\u201cCreating a self-sustaining colony on an island would help to survive a global catastrophe, or at least a pilot project to test needed requirements, which could be later scaled to a more suitable place.\u201d</p></blockquote><h3>Artificial light crop growth experiment - ALLFED</h3><blockquote><p>\u201cThis intervention is useful for abrupt sunlight reduction scenarios. Countries which will not be able to grow crops outdoors might still have cheap energy (e.g. the Nordics), and thus leverage it to produce food. The project would be to grow crops such as maize, rice, wheat and potatoes with artificial light. The current industry is not focusing on these crops.</p><p>However, it should be noted the energy sources which could be used to enable artificial light (natural gas, coal, nuclear and hydropower) would most likely produce methane or hydrogen single-cell protein (SCP) much more cost-effectively. Consequently, using such energy sources to power artificial light may be harmful (depending on the counterfactual). Modelling the post-catastrophe economics would be helpful to inform the relevance of artificial light as a resilient food solution.\u201d</p></blockquote><h3>Emergency CubeSat - ALLFED</h3><blockquote><p>\u201cDesign a CubeSat able to transmit emergency messages directly to regular mobile phones, and sufficiently hardened against high altitude electromagnetic pulses (HEMPs). Both&nbsp;<a href=\"https://ast-science.com/\"><u>AST SpaceMobile</u></a> and&nbsp;<a href=\"https://lynk.world/\"><u>Lynk</u></a> have launched satellites which can communicate with regular phones but were not specifically designed to be hardened against HEMPs. This intervention is useful for the loss of electricity/industry scenarios.\u201d</p></blockquote><h3>Feed from bacteria on leaves - ALLFED</h3><blockquote><p>\u201cGrow bacteria on tree/crop leaves, which could be used as feed for rats (which have some ability to digest cellulose) or chickens (very little ability to digest cellulose). This has a natural analogue of fish (very little ability to digest cellulose) eating rotten leaves. Alternatively, one could figure out how to retrofit existing factories to produce such feed, or rapidly construct facilities for the same purpose. However, in this case, the conversion of lignocellulose to sugar to single-cell protein (SCP) would likely be more cost-effective. This intervention is useful for abrupt sunlight reduction scenarios.\u201d</p></blockquote><h3>Feed from single-cell protein on natural gas - ALLFED</h3><blockquote><p>\u201cDemonstrate natural gas-eating single-cell protein at the household scale. See&nbsp;<a href=\"http://www.unibio.dk/\"><u>here</u></a> and&nbsp;<a href=\"http://calysta.com/\"><u>here</u></a> for how these microorganisms can be used as fish food (and in a catastrophe, perhaps human food). This intervention is useful for abrupt sunlight reduction scenarios.\u201d</p></blockquote><h3>Fungus from leaves, wood or peat - ALLFED</h3><blockquote><p>\u201cPerform experiments on growing fungus such as&nbsp;<a href=\"https://en.wikipedia.org/wiki/Quorn\"><u>Quorn</u></a> on tree/crop leaves, wood, peat or lignite coal (compressed peat) at the household scale, either: - Figuring out a way to separate the fungus from the fiber for humans. - Or, if it is not possible to separate the fungus from the fiber, use this as feed for rats (some digest cellulose) or chickens (which have very little ability to digest cellulose). There is a natural analogue of fish (which also have very little ability to digest cellulose) eating decomposed leaves.&nbsp;<a href=\"https://www.longdom.org/open-access/solid-state-fermentation-of-carinata-brassica-carinata-meal-using-variousfungal-strains-to-produce-a-proteinrich-product-for-feed-1948-5948-1000344.pdf\"><u>This</u></a> may be relevant. Note current Quorn production is based on corn and wheat, which are already human edible, so such production is generally not as promising in a catastrophe. However, one could figure out how existing factories producing Quorn may be repurposed to have the inputs suggested above and pilot the rapid construction of such facilities. These interventions are useful for abrupt sunlight reduction scenarios.\u201d</p></blockquote><h3>Glycerol from carbon dioxide - ALLFED</h3><blockquote><p>\u201cPerform lab experiments to chemically convert carbon dioxide to human edible glycerol, thus establishing proof of concept. This intervention is useful for abrupt sunlight reduction scenarios.\u201d</p></blockquote><h3>Leaf grinder - ALLFED</h3><blockquote><p>\u201cDesign an open-source human-powered leaf grinder for leaf protein extract from tree/crop leaves. Such designs&nbsp;<a href=\"https://guidebest.in/low-cost-manual-waste-shredder/\"><u>exist</u></a>, but could be scaled up, and designed to be powered by animals (such that humans do not have to spend as much energy), and built without electricity/industry. Leaf protein has been&nbsp;<a href=\"http://leafforlife.org/\"><u>produced at household</u></a> and&nbsp;<a href=\"https://www.leafforlife.org/gen/industrial-scale-lc.html\"><u>industrial scales</u></a>. This intervention is useful for abrupt sunlight reduction and loss of electricity/industry scenarios.\u201d</p></blockquote><h3>Lipids from petroleum wax - ALLFED</h3><blockquote><p>\u201cPerform lab experiments to chemically convert petroleum wax to human edible lipids via oxidation and distillation, thus establishing proof of concept. This can be thought of as engineering an analogue of&nbsp;<a href=\"https://en.wikipedia.org/wiki/Margarine#Coal_butter\"><u>coal butter</u></a>. This intervention is useful for abrupt sunlight reduction scenarios.\u201d</p></blockquote><h3>Low-tech greenhouse experiment - ALLFED</h3><blockquote><p>\u201cSimulate and study the growth of crops in a low-tech greenhouse under the lower radiation and water availability conditions of a nuclear winter. The level of radiation can be controlled with meshes, and altitude can provide an environment with less water and lower temperature, in case a suitable location at sea level is not as easily accessible. While the greenhouse would be low-tech for greater scalability during a nuclear winter, it would have to feature some higher tech for the experimental purposes of the project. For example, instruments to measure temperature, humidity and carbon dioxide concentration. This project would essentially be a field experiment, and therefore it may be outside the scope of Reslab. This intervention is useful for abrupt sunlight reduction scenarios.\u201d</p></blockquote><h3>Low-tech greenhouse pilot - ALLFED</h3><blockquote><p>\u201cPilot the fast construction of a low-tech greenhouse. One starting point is the design described in&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0048969719360085?via%3Dihub\"><u>Alvarado 2020</u></a> (see Fig. 1), but scale up to allow for the operations of agriculture machinery. For example: - With a beam and column length of 6 m instead of 3 m. - With a total width and depth of 96 m instead of 100 m. It would also be important to test the feasibility of operating agriculture machinery in such a greenhouse, but this part seems outside of the scope of Reslab. This intervention is useful for abrupt sunlight reduction scenarios.\u201d</p></blockquote><h3>Nutritional and organoleptic analysis of the big four crop residues for leaf protein concentrate - ALLFED</h3><blockquote><p>\u201cDo a nutritional and organoleptic (taste, etc.) analysis of the residues of the big four crops (wheat, maize, rice, and soybeans) for leaf protein concentrate (LPC). This work is described in the abstract of the article \u201cToxic Analysis of Leaf Protein Concentrate of Common Agricultural Residues\u201d, which is below. However, there most likely are more cost-effective resilient food solutions.</p><p><br>\u201cAn area of potential resilient foods to help reduce hunger is converting the ~998 million tons of agricultural residue generated each year globally into human edible food. Although possible to extract leaf protein concentrate (LPC) from agricultural residue, neither the yields nor the toxicity of the protein concentrates from the most common agricultural residues has been widely investigated. To help fill this knowledge gap, this study uses high-resolution mass spectrometry and an open-source toolchain for non-targeted screening of toxins of nine agricultural plant residues including seven agricultural residues: corn/maize, wheat, barley, alfalfa, yellow pea, sunflower, canola/rapeseed, and two weeds/agricultural residues: kochia, and round leaf mallow. The average yield ranged from about 7% to 14.5% for the nine LPCs investigated. The results showed that yellow pea, round leaf mallow and canola are recommended for immediate further investigation and scaling as they appear to be fit for human consumption based on the lack of dangerous toxins found in the analysis performed in this study. All compounds identified in these samples have either been approved by international regulatory boards for safe consumption or are known to be present in common beverages. The other agricultural residues require additional quantification of the toxins identified as it will determine the actual risk for human consumption. Overall, the potential for LPC to provide more needed calories from existing agricultural practices is extremely promising, but a substantial amount of future work is needed to screen LPCs from all the agricultural residues depending on harvesting, handling and storage conditions.\u201d<br>&nbsp;</p><p>The testing would involve:</p><p>- Plant growth performance: yield, photosynthesis, chlorophyll content, total biomass production, root/leaf/shoot growth, germination, seedling vigour, and germination rate.</p><p>- Crop nutritional quality: minerals, vitamins, dietary fatty acids, amino acids, antioxidants, phenolics, total protein, sugars/carbohydrates, and total fats/lipids.</p><p>- Bioactive/Functional or phytomedicinal composition: flavonoids, phenolic acids, essential amino acids, antioxidants, antioxidant minerals, trace and essential minerals, functional lipids (omega 3, 6, 9 fatty acids, medium chain triglycerides, terpenes, galactolipids, FAFA, plasmalogens, etc.).</p><p>- Soil health / Plant growth media health: active microbial community composition, micro-niche, physiological status of media in response to agricultural inputs, metabolic response, and greenhouse gas emissions.</p><p>- Sensory analysis of crop/food: consumer preference, overall liking, organoleptic quality driving consumer preference (colour, aroma, texture, taste, appearance, size, flavour, purchase propensity, consumer preference for packaging, etc.).</p><p>- Organoleptic quality of food: acidity, pH, water activity, texture, total soluble solids/Brix, viscosity, and sugar content.</p><p>- Food metabolomics: nutritional profile, contaminants (e.g. heavy metals), allergens, bioactive compounds, biosensors, biomaterial/biopolymers, lipids, etc. Here do a comprehensive screen of the food composition or biomass, and use the information obtained to guide innovation/applications or end-use.</p><p>- Applications of food metabolomics as a decision support tool to resolve issues with nutrient/food security, and develop resilient food systems in boreal climate, tropics, rural, remote, coastal and indigenous communities. This particular part is most likely outside the scope of Reslab.</p><p>- Lipid Bioinformatics - lipid imaging/lipidomics: develop novel or new methods to assess biological samples/biomaterials; conduct comprehensive tests of the lipidome (all the lipids in biological samples) and determine end-use applications; lipid metabolism in assessing agriculture/food production under different climatic conditions/crop management systems/response to agriculture input/biotic or abiotic stressors; lipid metabolism in functional and nootropic foods (brain health foods) innovation; lipid metabolism in plant immunity; lipid metabolism in brain health assessment/validate functional foods, ingredients/phytonutrients/phytomedicine in improving brain health using cell or animal models of human disease.\u201d</p></blockquote><h3>Radio - ALLFED</h3><blockquote><p>\u201cDevelop an open-source shortwave (HAM) radio system (two-way or just receiver) which could be built without electricity/industry with common household components. Satellite to cell phone communications are moving forward, but they will likely not be hardened against high-altitude electromagnetic pulses, and might not be able to handle the surge of communications from the catastrophe. This means HAM radios could be valuable. Furthermore, they could provide a more powerful uplink than cell phones.</p><p><br>Ideally, the project would also involve creating a guide which is understandable to a non-specialist electrician or generally educated person. The guide should include a list of the sorts of common equipment the radio could be sourced from, and what challenges may be involved to make it a functioning device. An example of a transmitter radio using purchased components can be found&nbsp;<a href=\"https://makerf.com/posts/so_you_want_to_be_a_shortwave_pirate\"><u>here</u></a>. A receiver should be much easier to build.<br><br>This intervention is useful for the loss of electricity/industry scenarios.\u201d</p></blockquote><h3>Rope twister - ALLFED</h3><blockquote><p>\u201cPilot the fast construction of rope twisters, which are important to scaling seaweed farming. This intervention is useful for abrupt sunlight reduction scenarios.\u201d</p></blockquote><h3>Seaweed farm - ALLFED</h3><blockquote><p>\u201cPilot the fast construction of a seaweed farm. Note this would ultimately require the fast construction of rope twisters, whose pilot is a higher priority than that of the seaweed farm.<br><br>This intervention is useful for abrupt sunlight reduction and loss of electricity/industry scenarios.\u201d</p></blockquote><h3>Sulfuric acid synthesizer - ALLFED</h3><blockquote><p>\u201cDesign a sulfuric acid synthesizer which can be built without electricity/industry. From&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/Nc9fCzjBKYDaDJGiX/what-is-the-likelihood-that-civilizational-collapse-would-1\"><u>this</u></a> post from Luisa Rodriguez: - \u201cPhosphorus is the most difficult nutrient to access, in part because, unlike nitrogen and potassium, much of the phosphorus in fertilizer is lost in runoff. At relatively small scales, phosphorus can be added to fertilizer by sprinkling in crushed-up animal bones\u201d. Moreover, nitrogen can be obtained from manure and legumes, and potassium from wood ash. - \u201cEventually, survivors will [may?] need to work out how to react bonemeal with sulfuric acid to make it [phosphorus] more easily[/readily] absorbed [by soils, although runoff would continue]. Synthesizing sulfuric acid requires relatively complex chemistry techniques, though the necessary materials \u2014 pyrite rocks (fool\u2019s gold) and sodium chloride (which can be extracted from wood ashes) \u2014 would be readily available, and the chemistry techniques aren\u2019t prohibitively difficult\u201d. Links to some small-scale amateur designs are given in&nbsp;<a href=\"http://www.sciencemadness.org/talk/viewthread.php?tid=156031\"><u>this</u></a> post. This intervention is useful for the loss of electricity/industry scenarios. Separately from this hardware project, one should try to figure out under which conditions using sulfuric acid is needed (instead of bonemeal only, or other).\u201d</p></blockquote><h3>Wood chipper - ALLFED</h3><blockquote><p>\u201cDesign an open source human-powered scalable wood chipper, which is important for wood gasification. Such designs&nbsp;<a href=\"https://community.oscedays.org/t/design-and-build-a-pedal-powered-mulcher-chopper-from-old-bikes/4768\"><u>exist</u></a> but could be scaled up (ideally one would be able to process large logs), designed to be powered by animals (such that humans do not have to spend as much energy), and built without electricity/industry.&nbsp;<br><br>This intervention is useful for the loss of electricity/industry scenarios.\u201d</p></blockquote><h3>Wood gasifier - ALLFED</h3><blockquote><p>\u201cDesign an open-source&nbsp;<a href=\"https://en.wikipedia.org/wiki/Wood_gas_generator\"><u>wood gasifier</u></a> which can be built without electricity/industry. This is not explicitly targeted by currently&nbsp;<a href=\"https://www.driveonwood.com/library/free-gasifier-plans/\"><u>available designs</u></a>. It would be important to promote the product of the project to people who would be \u201cknowledge seeds\u201d in a situation of catastrophe. For example, hobbyists who have first-hand experience in building gasifiers, but, currently, only with electricity/industry, and at a small scale. These could also be recruited to provide support in the project. This intervention is useful for enabling transportation in loss of electricity/industry scenarios.\u201d</p></blockquote><h3>Wood pyrolyser - ALLFED</h3><blockquote><p>\u201cDesign an open-source wood pyrolyser which can be built without electricity/industry. Wood pyrolysis involves heating wood without very much oxygen to break it into more combustible parts, and can be used to produce charcoal. In addition, from&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/Nc9fCzjBKYDaDJGiX/what-is-the-likelihood-that-civilizational-collapse-would-1\"><u>this</u></a> post from Luisa Rodriguez: - \u201cWood pyrolysis, which literally means burning [heating] wood, is probably the most difficult technique survivors will have to master early on. Survivors will need to build a system to burn [heat] wood and separate and capture the resulting vapours\u201d. - \u201cBut the products are incredibly useful: acetic acid can be used to pickle food; acetone can be used for degreasing and in explosives; pitch can be used to make torches and to make things water resistant (caulking seams), and methanol can be used as antifreeze, as a biofuel, and as a chemical solvent (as can turpentine, another product of wood pyrolysis)\u201d. There are many wood pyrolyser designs around, but they are not efficient. According to&nbsp;<a href=\"https://onlinelibrary.wiley.com/doi/full/10.1002/bbb.1814\"><u>Woolf 2017</u></a>: - \u201cGlobally, much charcoal production still relies on highly polluting and inefficient technologies utilizing traditional&nbsp;<a href=\"https://en.wikipedia.org/wiki/Kiln\"><u>kiln</u></a> designs\u201d. This intervention is useful for the loss of electricity/industry scenarios.\u201d</p></blockquote><h3>Self-sustaining water filtration system - ALLFED</h3><blockquote><p>\u201cTo develop a self-sustaining water filtration system for disaster relief and community development by using solar power, a compact filtration unit, and a water storage tank to provide clean drinking water in areas without access to safe water sources. The objective is to improve health and quality of life for people in need, as well as reduce dependence on aid from outside sources.\u201d</p></blockquote><h1><strong>Thank you!</strong></h1><p>We would like to extend our sincere thanks to everyone who contributed their ideas to this competition!</p><p><br>&nbsp;</p>", "user": {"username": "Aron Lajko"}}, {"_id": "MfQA25JafSexWtoZf", "title": "Global Food Partners: Impact Sponsorship Programme for Asian farmers to transition to cage-free egg production", "postedAt": "2023-07-27T10:02:20.681Z", "htmlBody": "<h1>Overview</h1><h2>The problem we address</h2><p><a href=\"https://www.fao.org/poultry-production-products/production/en/#:~:text=Asia%20is%20the%20largest%20egg,15%20to%2093%20million%20tonnes.\"><u>More than 60%</u></a> of global egg production comes from Asia. <a href=\"https://www.internationalegg.com/resource/global-egg-production-continues-to-grow/\"><u>China, India, Japan, and Indonesia</u></a> are amongst the largest egg-producing countries. The growth rate for production continues to soar with growing demand. This signals an increased number of layer hens reared in factory farms for commercial egg production.</p><p>Although there is a growing demand for higher welfare sustainable food products and <a href=\"https://www.cagefreetracker.com/asia\"><u>cage-free egg commitments</u></a> from food companies and hotel groups, the cage-free market is not growing at the same pace as its conventional counterpart. The reason for this is the low supply and high operating costs and retail prices. A <a href=\"https://www.frontiersin.org/articles/10.3389/fvets.2022.1038362/full\"><u>study</u></a> was conducted to investigate the perspectives of cage egg producers on the adoption of cage-free systems in China, Japan, Indonesia, Malaysia, the Philippines, and Thailand. The study revealed that the greatest barriers to an effective transition were land availability, cost, management, and disease mitigation. The latter three can be addressed with \u201ctraining, knowledge, and access to experts in cage-free operations\u201d. Therefore, local producer capacity-building is crucial to address these barriers and support Asia\u2019s transition to higher welfare practices.</p><h2>What the programme does</h2><p>The Impact Sponsorship Programme aims to support cage-free egg production in Asia by providing financial aid for capacity-building. The programme benefits farmers who require basic knowledge about cage-free egg production, comprehensive hands-on lessons to operate a farm, or technical/business expertise to start a new farm. To help farmers progress through the funnel, we have designed training courses and consultation services into the curriculum.</p><p>We offer three sponsorship tiers to support farmers in their cage-free journey:</p><ul><li>Tier 1: Inspiration - Sponsor a farmer to learn and complete the GFP\u2019s course, \u201c<a href=\"https://academy.globalfoodpartners.com/learn/course/external/view/elearning/39/cage-free-egg-production-the-basics-parts-1-and-2\"><u>Cage-Free Egg Production: the Basics (Parts 1 and 2)</u></a>\u201d.&nbsp;</li><li>Tier 2: Innovation - Sponsor a farmer for a week-long, on-farm cage-free training programme at the <a href=\"https://youtu.be/BPo-STM68FI\"><i><u>Cage-free Innovation and Welfare Hub</u></i></a>.</li><li>Tier 3: Impact - Sponsor individualised training for a farmer to transition to a cage-free farm.</li></ul><p>Ideally, a farmer would complete the first two prerequisites (online course and on-farm training) before launching a cage-free farm.</p><h3><strong>GFP\u2019s online course</strong></h3><p>This self-paced online course contains 22 learning modules which introduce animal welfare and cage-free husbandry, rearing, hen health and behaviour monitoring, biosecurity, disease prevention, and egg productivity. It was developed by GFP\u2019s science and extension team and Netherlands-based <a href=\"https://www.aeresuas.com/\"><u>Aeres University of Applied Sciences (AERES)</u></a>, and endorsed by academic institutions in Japan, Indonesia, and China. The course is available in various Asian languages.</p><h3><strong>Training at Cage-free Innovation and Welfare Hub</strong>&nbsp;</h3><p>This is an intensive 6-day course consisting of theoretical lessons, guest lectures, industry interactions, and farm visits. The farmers will learn valuable knowledge from an industry consortium of experts from genetics companies, cage-free housing and equipment suppliers, lighting companies, and ventilation companies. The training will be conducted at the <i>Cage-free Innovation and Welfare Hub </i>in Yogyakarta, Indonesia, the first cage-free model farm and training centre in Southeast Asia, developed by GFP, AERES, and <a href=\"https://ugm.ac.id/en/fakultas/faculty-of-animal-science/\"><u>The Faculty of Animal Science at the Universitas Gadjah Mada</u></a>. The Hub models how cage-free can be done successfully in the region, to encourage and accelerate an industry-wide transition and disrupt the current model of factory farming.</p><h3><strong>Individualised training to start a new farm</strong>&nbsp;</h3><p>To help farmers get started, GFP provides technical guidance on transitioning from cage to cage-free systems and launching a new farm. This includes helping to identify suitable farmlands, perform business case calculations, and build the infrastructure. However, continuing to operate a productive and profitable cage-free farm can be challenging due to inconsistent demand and high production costs. Small-scale producers frequently face the issue of over-production when the market demand is low and seasonal. To address this, GFP provides ongoing support to farmers by helping create competitive advantages, including third-party certification, traceability systems, and facilitating market access.</p><h1>Our theory of change</h1><p>Farmer capacity building to improve layer hen welfare</p><figure class=\"image image_resized\" style=\"width:624px\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/MfQA25JafSexWtoZf/irpyfpprk6z386wedtpi\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/MfQA25JafSexWtoZf/dzzgyspxkvxybelxs4lr 144w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/MfQA25JafSexWtoZf/iwlmlplnn3fzurjp42rm 224w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/MfQA25JafSexWtoZf/oo4grgefvpp0bjvk7voz 304w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/MfQA25JafSexWtoZf/uoaisjtyc0chhsj8rruk 384w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/MfQA25JafSexWtoZf/lqo3mgj6o1ugx0zoxwh9 464w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/MfQA25JafSexWtoZf/dugzszssewafbiv0vgng 544w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/MfQA25JafSexWtoZf/fp244rzkhxiqy1f1bahv 624w\"></figure><h1>How you can help&nbsp;</h1><h2>Sponsor a farmer today&nbsp;</h2><p>The Impact Sponsorship Programme offers flexibility in sponsoring one or multiple farmers for Tiers 1, 2 or 3, or through the capacity-building funnel. We conduct capacity-building activities on an as-needed basis and do not fix a timeline for them. For more information, please contact us at <a href=\"mailto:team@globalfoodpartners.com\"><u>team@globalfoodpartners.com</u></a> or click <a href=\"https://donate.stripe.com/dR6fZE2Z729ogc8eUU\"><u>here</u></a> to make a donation today.</p><ul><li>Tier 1: Inspiration - $100 (USD) per farmer</li><li>Tier 2: Innovation -&nbsp; $1,700 (USD) per farmer</li><li>Tier 3: Impact - Contact us for more information</li></ul><h2>Connect us with farmers or companies who want to be trained&nbsp;&nbsp;</h2><p>If you know anyone who might be interested in getting trained to transition to a cage-free farm, please connect them with us. We also welcome major food and hospitality businesses such as hotel groups, restaurants, and retailers, to get in touch and let us help their suppliers transition to cage-free egg production.</p><h2>Follow our work&nbsp;</h2><p>To hear more about our sponsorship programme and stay updated on our work, follow us on <a href=\"https://www.facebook.com/globalfoodpartners\"><u>Facebook</u></a> and <a href=\"https://sg.linkedin.com/company/global-food-partners\"><u>Linkedin</u></a> and subscribe to our <a href=\"https://globalfoodpartners.us14.list-manage.com/subscribe?u=040c803735eaf650986fd670b&amp;id=aab50acfa2\"><u>newsletter</u></a>.</p><h1>About Us</h1><p>Global Food Partners (GFP) is a science-based animal welfare consulting group supported by the <a href=\"https://funds.effectivealtruism.org/funds/animal-welfare\"><u>EA Animal Welfare Fund</u></a> and <a href=\"https://www.openphilanthropy.org/\"><u>Open Philanthropy</u></a>. Based in Singapore, we work with leading food corporations and egg producers to support their transition to higher-welfare cage-free egg sourcing and production in Asia \u2014 where there is a significant need for improvements to current agricultural practices and the potential for the most impact in improving the lives of farmed animals. We operate across nine key countries in Asia, including China and Indonesia, two of the world's leading egg-producing countries.</p>", "user": {"username": "Chloe Lee"}}, {"_id": "67zFQT4GeJdgvdFuk", "title": "Partial Transcript of Recent Senate Hearing Discussing AI\u00a0X-Risk", "postedAt": "2023-07-27T09:16:00.401Z", "htmlBody": "<p>On Tuesday, the <a href=\"https://en.wikipedia.org/wiki/United_States_Senate_Judiciary_Subcommittee_on_Privacy,_Technology_and_the_Law\">US Senate Judiciary Subcommittee on Privacy, Technology and the Law</a> held a hearing on AI. The hearing involved 3 witnesses \u2013 Dario Amodei (CEO of Anthropic), Yoshua Bengio (Turing Award winner, and the <a href=\"https://scholar.google.com/citations?hl=en&amp;view_op=search_authors&amp;mauthors=label%3Aartificial_intelligence+OR+label%3Aai+OR+label%3Amachine_learning+OR+label%3Adeep_learning&amp;btnG=\">second-most cited</a> AI researcher in the world), and Stuart Russell (Professor of CS at Berkeley, and co-author of <a href=\"https://en.wikipedia.org/wiki/Artificial_Intelligence:_A_Modern_Approach\">the standard textbook for AI)</a>.&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/67zFQT4GeJdgvdFuk/qrzaizyxwsrmtmdavb6h\"></p><p>The hearing wound up focusing a surprising amount on <a href=\"https://medium.com/@daniel_eth/ai-alignment-explained-in-5-points-95e7207300e3\">AI X-risk</a> and related topics. I originally planned on jotting down all the quotes related to these topics, thinking it would make for a short post of a handful of quotes, which is <a href=\"https://forum.effectivealtruism.org/posts/kXaxasXfG8DQR4jgq/some-quotes-from-tuesday-s-senate-hearing-on-ai\">something I did for a similar hearing by the same subcommittee 2 months ago</a>. Instead, this hearing focused so much on these topics that I wound up with something that\u2019s better described as a partial transcript.</p><p>All the quotes below are verbatim. Text that is <strong>bolded</strong> is simply stuff I thought readers might find particularly interesting. If you want to listen to the hearing, you can do so <a href=\"https://www.judiciary.senate.gov/committee-activity/hearings/oversight-of-ai-principles-for-regulation\">here</a> (it\u2019s around 2.5 hours). You might also find it interesting to compare this post to the <a href=\"https://forum.effectivealtruism.org/posts/kXaxasXfG8DQR4jgq/some-quotes-from-tuesday-s-senate-hearing-on-ai\">one from 2 months ago</a>, to see how the discourse has progressed.</p><p>&nbsp;</p><h1>Opening remarks</h1><h3>Senator Blumenthal:</h3><blockquote><p>What I have heard [from the public after the last AI hearing] again and again and again, and the word that has been used so repeatedly is \u2018scary.\u2019 \u2018Scary\u2019\u2026 What rivets [the public\u2019s] attention is <strong>the science-fiction image of an intelligence device, out of control, autonomous, self-replicating, potentially creating diseases\u200a\u2014\u200apandemic-grade viruses, or other kinds of evils, purposely engineered by people or simply the result of mistakes\u2026 And, frankly, the nightmares are reinforced in a way by the testimony that I\u2019ve read from each of you</strong>\u2026</p></blockquote><blockquote><p><strong>I think you have provided objective, fact-based views on what the dangers are, and the risks and potentially even human extinction</strong>\u200a\u2014\u200aan existential threat which has been mentioned by many more than just the three of you, experts who know first hand the potential for harm. But these fears need to be addressed, and I think can be addressed through many of the suggestions that you are making to us and others as well.</p></blockquote><blockquote><p><strong>I\u2019ve come to the conclusion that we need some kind of regulatory agency</strong>, but not just a reactive body\u2026 actually investing proactively in research, <strong>so that we develop countermeasures against the kind of autonomous, out-of-control scenarios that are potential dangers: an artificial intelligence device that is in effect programmed to resist any turning off, </strong>a decision by AI to begin nuclear reaction to a nonexistent attack.</p></blockquote><blockquote><p>The White House certainly has recognized the urgency with a historic meeting of the seven major companies which made eight profoundly significant commitments\u2026 but it\u2019s only a start\u2026 The urgency here demands action.</p></blockquote><blockquote><p>The future is not science fiction or fantasy\u200a\u2014\u200ait\u2019s not even the future, it\u2019s here and now. And a number of you have put the timeline at 2 years before we see some of the biological most severe dangers. It may be shorter because the kinds of pace of development is not only stunningly fast, it is also accelerated at a stunning pace, because of the quantity of chips, the speed of chips, the effectiveness of algorithms. It is an inexorable flow of development\u2026</p></blockquote><blockquote><p>Building on our previous hearing, I think there are core standards that we are building bipartisan consensus around. And I welcome hearing from many others on these potential rules:</p></blockquote><blockquote><p><strong>Establishing a licensing regime for companies that are engaged in high-risk AI development;</strong></p></blockquote><blockquote><p><strong>A testing and auditing regimen by objective 3rd parties or by preferably the new entity that we will establish;</strong></p></blockquote><blockquote><p>Imposing legal limits on certain uses related to elections\u2026 related to nuclear warfare\u200a\u2014\u200aChina apparently agrees that AI should not govern the use of nuclear warfare;</p></blockquote><blockquote><p>Requiring transparency about the limits and use of AI models\u200a\u2014\u200athis includes watermarking, labeling, disclosure when AI is being used, and data access\u2026</p></blockquote><blockquote><p>I appreciate the commitments that have been made by Anthropic, OpenAI, and others at the White House related to security testing and transparency last week\u200a\u2014\u200ait shows these goals are achievable and that they will not stifle innovation, which has to be an objective\u2026 We need to be creative about the kind of agency, or entity, the body\u2026 I think the language is less important than its real enforcement power and the resources invested in it.</p></blockquote><h3>Senator Hawley:</h3><blockquote><p>I want to start by thanking the Chairman, Senator Blumenthal, for his terrific work on these hearings, it\u2019s been a privilege to get to work with him. These have been incredibly substantive hearings\u2026 I have expressed my own sense of what our priorities ought to be when it comes to legislation\u2026 workers, kids, consumers, and national security. As AI develops, we\u2019ve got to make sure that we have safeguards in place that will ensure this new technology is actually good for the American people\u2026 I\u2019m less interested in the corporations\u2019 profitability; in fact, I\u2019m not interested in that at all\u2026</p></blockquote><blockquote><p>You wanna talk about a dystopia? Imagine a world in which AI is controlled by one or two or three corporations that are basically governments unto themselves, and then the United States government and foreign entities\u2026</p></blockquote><blockquote><p>And I think the real question before Congress is, \u2018will Congress actually do anything?\u2019&nbsp;\u2026 Will the leadership in both parties, both parties, will it actually be willing to act?&nbsp;\u2026 I think if the urgency of the new generative AI technology does not make that clear to folks, then you\u2019ll never be convinced.</p></blockquote><h3>Senator Klobuchar:</h3><blockquote><p>I do agree with both Senator Blumenthal and Senator Hawley\u200a\u2014\u200athis is the moment, and the fact that this has been bipartisan so far in the work that Senator Schumar, Senator Young are doing, the work that is going on in this subcommittee\u2026 I actually think that if we don\u2019t act soon we could decay into not just partisanship, but inaction.</p></blockquote><h3>Dario Amodei:</h3><blockquote><p>Anthropic is a public-benefit corporation that aims to lead by example in developing and publishing techniques to make AI systems safer and more controllable and by deploying these safety techniques in state-of-the-art models. Research conducted by Anthropic includes constitutional AI\u2026 early work on red-teaming\u2026 and foundational work in AI interpretability\u2026 While we\u2019re the first to admit that our measures are still far from perfect, we believe they\u2019re an important step forward in a race to the top on safety\u2026</p></blockquote><blockquote><p>My written testimony covers three categories of risks: short-term risks that we face right now, such as bias, privacy, misinformation; medium-term risks related to misuse of AI systems as they become better at science and engineering tasks; and <strong>long-term risks related to whether models might threaten humanity as they become truly autonomous</strong>\u2026</p></blockquote><blockquote><p>In these short remarks I want to focus on the medium-term risks\u2026 Specifically, Anthropic is concerned that AI could empower a much larger set of actors to misuse biology\u2026 Today, certain steps in bioweapons production involve knowledge that can\u2019t be found on Google or in textbooks\u2026 We found that today\u2019s AI tools can fill in some of these steps\u2026 however, a straightforward extrapolation of today\u2019s systems to those we expect to see in 2 to 3 years suggests a substantial risk that AI systems will be able to fill in all the missing pieces, enabling many more actors to carry out large-scale biological attacks\u2026</p></blockquote><blockquote><p>We have instituted mitigations against these risks in our own deployed models, briefed a number of US government officials\u200a\u2014\u200aall of whom found the results disquieting, and are piloting a responsible disclosure process with other AI companies to share information on this and similar risks. <strong>However, private action is not enough\u200a\u2014\u200athis risk and many others like it requires a systemic policy response.</strong></p></blockquote><blockquote><p>We recommend three broad classes of actions:</p></blockquote><blockquote><p><strong>First, the US must secure the AI supply chain in order to maintain its lead while keeping these technologies out of the hands of bad actors\u200a</strong>\u2014\u200athis supply chain runs from semiconductor manufacturing equipment to chips and even the security of AI models stored on the servers of companies like ours.</p></blockquote><blockquote><p><strong>Second, we recommend the testing and auditing regime for new and more powerful models</strong>\u2026 new AI models should have to pass a rigorous battery of safety tests before they can be released to the public at all, including tests by 3rd parties and national security experts in government.</p></blockquote><blockquote><p><strong>Third, we should recognize that the science of testing and auditing for AI systems is in its infancy</strong>\u2026 thus it is important to fund both measurement and research on measurement to ensure a testing and auditing regime is actually effective\u2026</p></blockquote><blockquote><p>Responsible supply chain policies help give America enough breathing room to impose rigorous standards on our own companies without ceding our national lead to adversaries and funding measurement in turn makes these rigorous standards meaningful.</p></blockquote><h3>Yoshua Bengio:</h3><blockquote><p>While this [ongoing AI] revolution has the potential to enable tremendous progress and innovation, it also entails a wide range of risks, from immediate ones like discrimination, to growing ones like disinformation, <strong>and even more concerning ones in the future like loss of control of superhuman AIs</strong>\u2026</p></blockquote><blockquote><p>[Recent] advancements have led many top AI researchers, including myself, to <strong>revise our estimates of when human-level intelligence could be achieved</strong>. Previously thought to be decades or even centuries away, <strong>we now believe it could be within a few years, or decades</strong>. The shorter timeframe\u200a\u2014\u200asay 5 years\u200a\u2014\u200ais really worrisome, because we\u2019ll need more time to effectively mitigate the potentially-significant threats\u2026</p></blockquote><blockquote><p>These severe risks could arise either intentionally (because of malicious actors using AI systems to achieve harmful goals) or unintentionally (if an AI system develops strategies that are misaligned with our values and norms).</p></blockquote><blockquote><p>I would like to emphasize 4 factors that governments can focus on in their regulatory efforts to mitigate all AI harms and risks:</p></blockquote><blockquote><p>First, access, limiting who has access to powerful AI systems\u2026</p></blockquote><blockquote><p>Second, alignment, ensuring that AI systems will act as intended in agreement with our values and norms.</p></blockquote><blockquote><p>Third, raw intellectual power, which depends on the level of sophistication of the algorithms and the scale of computing resources and of datasets.</p></blockquote><blockquote><p>And forth, scope of actions\u200a\u2014\u200athe potential for harm an AI system can affect, indirectly, for example through human actions, or directly, for example through the internet\u2026</p></blockquote><blockquote><p>I firmly believe that urgent efforts, preferably in the coming months, are required in the following 3 areas:</p></blockquote><blockquote><p><strong>First, the coordination of highly-agile national and international regulatory frameworks and liability incentives that bolster safety</strong>, this would require licenses for people and organizations with standardized duties to evaluate and mitigate potential harm, allow independent audits, and restrict AI systems with unacceptable levels of risk.</p></blockquote><blockquote><p><strong>Second, because the current methodologies are not demonstrably safe, significantly accelerate global research endeavors focused on AI safety</strong>, enabling the informed creation of essential regulations, protocols, safe AI methodologies, and governance structures.</p></blockquote><blockquote><p><strong>And third, research on countermeasures to protect society from potential rogue AIs, because no regulation is going to be perfect</strong>. This research in AI and international security should be conducted with several highly-secure and decentralized labs, operating under multilateral oversight, to mitigate an AI arms race\u2026 <strong>We must\u2026 allocate substantial additional resources to safeguard our future\u200a\u2014\u200aat least as much as we are collectively, globally, investing in increasing the capabilities of AI.</strong></p></blockquote><h3>Stuart Russell:</h3><blockquote><p><strong>[The field of AI\u2019s] stated goal is general-purpose artificial intelligence, sometimes called \u2018AGI\u2019 or \u2018artificial general intelligence\u2019\u200a\u2014\u200amachines that match or exceed human capabilities in every relevant dimension</strong>\u2026</p></blockquote><blockquote><p>For most of [the last 80 years] we created systems whose internal operations we understood\u2026 Over the last decade, that has changed\u2026 the dominant approach has been end-to-end training of circuits with billions or trillions of adjustable parameters\u2026 <strong>Their internal principles of operation remain a mystery</strong>\u200a\u2014\u200athis is particularly true for the large language models\u2026</p></blockquote><blockquote><p>Many researchers now see AGI on the horizon\u2026 If we succeed, the upside could be enormous\u200a\u2014\u200a<strong>I\u2019ve estimated a cash value of at least fourteen quadrillion dollars for this technology</strong>\u2026 On the other hand, Alan Turing, the founder of computer science, warned in 1951 that <strong>once AI outstrips our feeble powers, we should have to expect the machines to take control</strong>. We have pretty much completely ignored this warning\u200a\u2014\u200ait\u2019s as if an alien civilization warned us by email of its impending arrival, and we replied \u2018humanity is currently out of the office\u2019.</p></blockquote><blockquote><p>Fortunately, humanity is now back in the office and has read the email from the aliens. Of course, many of the risks from AI are well-recognized already, including bias, disinformation, manipulation, and impacts on employment\u200a\u2014\u200aI\u2019m happy to discuss any of these. But most of my work over the last decade has been on the problem of control\u200a\u2014\u200a<strong>how do we maintain power, forever, over entities more powerful than ourselves?</strong></p></blockquote><blockquote><p>The core problem we have studied comes from AI systems pursuing fixed objectives that are misspecified\u200a\u2014\u200athe so-called \u2018King Midas problem\u2019\u2026 <strong>But with LLMs, we don\u2019t even know what their objectives are</strong>\u2026</p></blockquote><blockquote><p>This committee has discussed ideas such as 3rd party testing, licensing, national agency, an international coordinating body\u200a\u2014\u200aall of which I support. Here are some more [ideas I support]:</p></blockquote><blockquote><p>First, an absolute right-to-know if one is interacting with a person or a machine.</p></blockquote><blockquote><p>Second, no algorithms that can decide to kill human beings, particularly when attached to nuclear weapons.</p></blockquote><blockquote><p>Third, a kill switch that must be activated if systems break into other computers or replicate themselves.</p></blockquote><blockquote><p><strong>Fourth, go beyond the voluntary steps announced last Friday\u200a\u2014\u200asystems that break the rules must be recalled from the market</strong>\u2026</p></blockquote><blockquote><p>Eventually\u2026 we will develop forms of AI that are provably safe and beneficial, which can then be mandated\u200a\u2014\u200auntil then we need real regulation and a pervasive culture of safety.</p></blockquote><h3>Senator Blumenthal:</h3><blockquote><p>We have to be back in the office to answer that email that is in fact a siren blaring for everyone to hear and see: AI is here and beware of what it will do if we don\u2019t do something to control it, and not just in some distant point in the future, but as all of you have said, with a time horizon that would have been thought unimaginable just a few years ago.</p></blockquote><p>&nbsp;</p><h1>On Superintelligent AI</h1><h3>Senator Blumenthal:</h3><blockquote><p><strong>Superhuman AI\u200a\u2014\u200aI think all of you agree, we\u2019re not decades away, we\u2019re perhaps just a couple of years away.</strong> And you describe it\u2026 in terms of biologic effects\u200a\u2014\u200athe development of viruses, pandemics, toxic chemicals, but <strong>superhuman AI evokes for me, artificial intelligence that could on its own develop a pandemic virus, on its own decide Joe Biden shouldn\u2019t be our next president, on its own decide that the water supply of Washington DC should be contaminated with some kind of chemical, and have the knowledge to do it through public utilities systems</strong>\u2026</p></blockquote><blockquote><p>I think your warning to us has really graphic content and it ought to give us impetus with that kind of urgency to develop an entity that can not only establish standards and rules but also research on countermeasures that detect those misdirections, whether they\u2019re the result of malign actors or mistakes by AI, or malign operation of AI itself.</p></blockquote><blockquote><p><strong>Do you think those countermeasures are within our reach as human beings</strong> and is that a function for an entity like this one to develop?</p></blockquote><h3>Dario Amodei:</h3><blockquote><p>Yes\u2026 this is one of the core things that, <strong>whether it\u2019s the biorisks from models that\u2026 are likely to come in 2 to 3 years, or the risks from truly autonomous models, which I think are more than that, but might not be a whole lot more than that</strong>.</p></blockquote><blockquote><p>I think this idea of being able to even measure that the risk is there is really the critical thing; if we can\u2019t measure, then we can put in place all of these regulatory apparatus, but it\u2019ll all be a rubber stamp. And so funding for the measurement apparatus and the enforcement apparatus\u2026 our suggestion was NIST and the National AI Research Cloud which can help allow a wider range of researchers to study these risks and develop countermeasures\u2026</p></blockquote><blockquote><p><strong>I\u2019m worried about our ability to do this in time, but we have to try.</strong></p></blockquote><h3>Yoshua Bengio:</h3><blockquote><p>I completely agree. <strong>About the timeline, there\u2019s a lot of uncertainty\u2026 It could be a few years, but it could also be a couple of decades</strong>\u2026</p></blockquote><blockquote><p>Regulation, liability\u200a\u2014\u200athey will help a lot. <strong>My calculations is we could reduce the probability of a rogue AI showing up by maybe a factor of 100 if we do the right things in terms of regulation</strong>\u2026 But it\u2019s not gonna bring those risks to zero, and especially for bad actors that don\u2019t follow the rules anyways.</p></blockquote><blockquote><p>So we need that investment in countermeasures and AI is gonna help us with that, but we have to do it carefully so that we don\u2019t create the problem that we\u2019re trying to solve in the first place\u2026 The organizations that are going to [provide governance] in my opinion shouldn\u2019t be for profit\u200a\u2014\u200awe shouldn\u2019t mix the objective of making money\u2026 with the objective which should be single-minded of defending humanity against a potential rogue AI.</p></blockquote><blockquote><p>Also I think we should be very careful to do this with our allies in the world and not do it alone. There is first, we can have a diverse set of approaches, because we don\u2019t know how to really do this\u2026 and we also need some kind of robustness against the possibility that one of the governments involved in this kind of research isn\u2019t democratic anymore for some reason\u2026 We need a resilient system of partners, so that if one of them ends up being a bad actor, the others are there.</p></blockquote><h3>Stuart Russell:</h3><blockquote><p>I completely agree that if there is a body that\u2019s set up, that it should be enabled to fund and coordinate this type of research, and I completely agree with the other witnesses that we haven\u2019t solved the problem yet.</p></blockquote><blockquote><p>I think there are a number of approaches that are promising\u200a\u2014\u200aI tend towards approaches that provide mathematical guarantees, rather than just best-effort guarantees, and <strong>we\u2019ve seen that in the nuclear area, where originally, the standard, I believe was you could have a major core accident every 10,000 years, and you had to demonstrate that your system design met that requirement, then it was a million years, and now it\u2019s 10 million years. And so that\u2019s progress, and it comes from actually having a real scientific understanding of the materials, the designs, redundancy, etcetera. We are just in the infant stages of a corresponding understanding of the AI systems that we\u2019re building</strong>.</p></blockquote><blockquote><p>I would also say that no government agency is going to be able to match the resources that are going into the creation of these AI systems\u200a\u2014\u200athe numbers I\u2019ve seen are roughly 10 billion dollars a month going into AGI startups\u2026 How do we get that resource flow directed towards safety? I actually believe that the involuntary recall provisions\u2026 would have that effect\u2026</p></blockquote><blockquote><p>[If systems are recalled for violating rules] the company can go out of business, so they have a very strong incentive to actually understand how their systems work, and if they can\u2019t, to redesign their systems so that they do understand how they work\u2026</p></blockquote><blockquote><p>I also want to mention on rogue AI\u2026 we may end up needing a very different kind of digital ecosystem\u2026 Right now, to a first approximation, a computer runs any piece of binary code that you load into it\u200a\u2014\u200awe put layers on top of that that say \u2018okay, that looks like a virus, I\u2019m not running that.\u2019 <strong>We actually need to go the other way around\u200a\u2014\u200athe system should not run any piece of binary code unless it can prove to itself that this is a safe piece of code to run\u2026 With that approach, I think we could actually have a chance of preventing bad actors from being able to circumvent these controls.</strong></p></blockquote><p>&nbsp;</p><h1>On Supply Chains and&nbsp;China</h1><h3>Senator Hawley:</h3><blockquote><p>Mr. Amodei\u2026 your first recommendation is \u2018the United States must secure the AI supply chain,\u2019 and then you mention immediately as an example of this chips used for training AI systems. Where are most of the chips made now?</p></blockquote><h3>Dario Amodei:</h3><blockquote><p>There are certain bottlenecks in the production of AI systems. That ranges from semiconductor manufacturing equipment to chips, to the actual produced systems which then have to be stored on a server somewhere, and in theory could be stolen or released in an uncontrolled way. So I think compared to some of the more software elements, those are areas where there are substantially more bottlenecks.</p></blockquote><h3>Senator Hawley:</h3><blockquote><p>Understood\u2026 Do you know where most of them are currency manufactured?</p></blockquote><h3>Dario Amodei:</h3><blockquote><p>There are a number of steps in the production process\u2026 an important player on the making the base fabrication side would be TSMC, which is in Taiwan, and then within companies like NVIDIA\u2026</p></blockquote><h3>Senator Hawley:</h3><blockquote><p>As part of securing our supply chain\u2026 should we consider limitations\u2026 on components that are manufactured in China?</p></blockquote><h3>Dario Amodei:</h3><blockquote><p>I think we should think a little bit in the other direction of, are things that are produced by our supply chain, do they end up in places that we don\u2019t want them to be.</p></blockquote><blockquote><p>So we\u2019ve worried a lot about that in the context of models\u200a\u2014\u200awe just had a blog post out today about AI models saying \u2018hey, you might have spent a large number of millions of dollars\u2026 to train an AI system\u200a\u2014\u200ayou don\u2019t want some state actor or criminal or rogue organization to then steal that and use it in some irresponsible way that you don\u2019t endorse.\u2019</p></blockquote><h3>Senator Hawley:</h3><blockquote><p>Let\u2019s imagine a hypothetical in which the [CCP] decides to launch an invasion of Taiwan, and let\u2019s imagine\u2026 that they are successful\u2026 Just give me a back-of-the-envelope forecast\u200a\u2014\u200awhat might that do to AI production?</p></blockquote><h3>Dario Amodei:</h3><blockquote><p>A very large fraction of the chips are indeed somewhere go through the supply chain in Taiwan\u2026</p></blockquote><h3>Stuart Russell:</h3><blockquote><p>There are already plans to diversify away from Taiwan. TSMC is trying to create a plant in the US, Intel is now building some very-large plants in the US and in Germany I believe. But it\u2019s taking time.</p></blockquote><blockquote><p>If the invasion that you mentioned happened tomorrow, we would be in a huge amount of trouble. As far as I understand it, there are plans to sabotage all of TSMC operations in Taiwan if an invasion were to take place, so it\u2019s not that all that capacity would then be taken over by China.</p></blockquote><h3>Senator Hawley:</h3><blockquote><p>What\u2019s sad about that scenario is that would be the best case scenario, right? If there\u2019s an invasion of Taiwan, the best we could hope for is, maybe all of their capacity, or most of it, gets sabotaged and maybe the whole world has to be in the dark for however long\u200a\u2014\u200athat\u2019s the best case scenario\u2026</p></blockquote><blockquote><p>Your point Mr. Amodei about securing our supply chains is absolutely critical, and thinking very seriously about strategic decoupling efforts I think is absolutely vital at every point in the supply chain that we can\u2026 I think we\u2019ve got to think seriously about what may happen in the event of a Taiwan invasion.</p></blockquote><h3>Dario Amodei:</h3><blockquote><p>I just wanted to emphasize Professor Russell\u2019s point even more strongly that we are trying to move some of the chip fab production capabilities to the US, but that needs to be faster. We\u2019re talking about 2 to 3 years for some of these very scary applications, and maybe not much longer than that for truly autonomous AI\u2026 I think the timelines for moving these production facilities look more like 5 years, 7 years, and we\u2019ve only started on a small component of them.</p></blockquote><p>&nbsp;</p><h1>On a Pause in&nbsp;AI</h1><h3>Senator Blumenthal:</h3><blockquote><p>For those who want to pause, and some of the experts have written that we should pause AI development\u200a\u2014\u200aI don\u2019t think it\u2019s gonna happen. We right now have a gold rush, literally much like the gold rush that we had in the Wild West where in fact there are no rules and everybody is trying to get to the gold without very many law enforcers out there preventing the kinds of crimes that can occur.</p></blockquote><blockquote><p>So I am totally in agreement with Senator Hawley [who had just criticized the outsourcing and labor practices of the AI industry] in focusing on keeping it in America, made in America when we\u2019re talking about AI.</p></blockquote><p>&nbsp;</p><h1>On Leading Countries and International Coordination</h1><h3>Senator Blumenthal:</h3><blockquote><p>Who are our competitors among our adversaries and our allies?&nbsp;\u2026 Are there other adversaries out there that could be rogue nations\u2026 whom we need to bring into some international body of cooperation?</p></blockquote><h3>Stuart Russell:</h3><blockquote><p>I think the closest competitor we have is probably the UK in terms of making advances in basic research, both in academia and in DeepMind in particular\u2026</p></blockquote><blockquote><p>I\u2019ve spent a fair amount of time in China, I was there a month ago talking to the major institutions that are working on AGI, and my sense is that we\u2019ve slightly overstated the level of threat that they currently present\u200a\u2014\u200athey\u2019ve mostly been building copycat systems that turn out not to be nearly as good as the systems that are coming out from Anthropic and OpenAI and Google. But the intent is definitely there\u2026</p></blockquote><blockquote><p>The areas where they are actually most effective\u2026 state security\u2026 voice recognition, face recognition [etc]. Other areas like reasoning and so on, planning, they\u2019re just not really that close. They have a pretty good academic sector that they are in the process of ruining, by forcing them to meet numerical publication targets and things like that.</p></blockquote><h3>Senator Blumenthal:</h3><blockquote><p>It\u2019s hard to produce a superhuman thinking machine if you don\u2019t allow humans to think.</p></blockquote><h3>Stuart Russell:</h3><blockquote><p>Yup. I\u2019ve also looked a lot at European countries\u2026 I don\u2019t think anywhere else is in the same league as those 3. Russia in particular has been completely denuded of its experts and was already well behind.</p></blockquote><h3>Yoshua Bengio:</h3><blockquote><p>On the allied side, there are a few countries\u2026 that have really important concentration of talent in AI. In Canada we\u2019ve contributed a lot\u2026 there\u2019s also a lot of really good European researchers in the UK and outside the UK.</p></blockquote><blockquote><p>I think that we would all gain by making sure we work with these countries to develop these countermeasures as well as the improved understanding of the potentially dangerous scenarios and what methodologies in terms of safety can protect us\u2026 A common umbrella that would be multilateral\u200a\u2014\u200aa good starting place could be Five Eyes or G7\u2026</p></blockquote><h3>Senator Blumenthal:</h3><blockquote><p>And there would probably be some way for our entity, our national oversight body doing licensing and registration, to still cooperate\u200a\u2014\u200ain fact I would guess that\u2019s one of the reasons to have a single entity, to be able to work and collaborate with other countries.</p></blockquote><h3>Yoshua Bengio:</h3><blockquote><p>Yes\u2026 The more we can coordinate on this the better\u2026 There [are] aspects of what we have to do that have to be really broad at the international level.</p></blockquote><blockquote><p>I think\u2026 mandatory rules for safety should be something we do internationally, like, with the UN. We want every country to follow some basic rules\u2026 Viruses, computer or biological viruses, don\u2019t see any border\u2026</p></blockquote><blockquote><p>We need to agree with China on these safety measures as the first interlocutor, and we need to work with our allies on these countermeasures.</p></blockquote><p>&nbsp;</p><h1>On off-switches</h1><h3>Senator Blumenthal:</h3><blockquote><p>On the issue of safety, I know that Anthropic has developed a model card for Claude that essentially involves evaluation capabilities, your red teaming considered the risk of self-replication or a similar kind of danger. OpenAI engaged in the same kind of testing\u2026&nbsp;</p></blockquote><blockquote><p><strong>Apparently you [Dario] share the concern that these systems may get out of control.</strong> Professor Russell recommended an obligation to be able to terminate an AI system\u2026 When we talk about legislation would you recommend that we impose that kind of requirement as a condition for testing and auditing the evaluation that goes on when deploying certain AI systems?&nbsp;\u2026</p></blockquote><blockquote><p><strong>An AI model spreading like a virus seems a bit like science fiction, but these safety breaks could be very very important to stop that kind of danger.</strong> Would you agree?</p></blockquote><h3>Dario Amodei:</h3><blockquote><p>Yes. I for one think that makes a lot of sense\u2026 Precisely because we\u2019re still getting good at the science of measurement, probably [particularly dangerous outcomes] will happen, at least once\u2026 <strong>We also need a mechanism for recalling things or modifying things.</strong></p></blockquote><h3>Senator Blumenthal:</h3><blockquote><p>I think there\u2019s been some talk about autoGPT. Maybe you can talk a little bit about how that relates to safety breaks.</p></blockquote><h3>Dario Amodei:</h3><blockquote><p>AutoGPT refers to use of currently deployed AI systems, which are not designed to be agents, which are just chatbots, comendering such systems for taking actions on the internet.</p></blockquote><blockquote><p>To be honest, such systems are not particularly effective at that yet, but they may be a taste of the future and the kinds of things we\u2019re worried about in the future. The long-term risks\u2026 where we\u2019re going is quite concerning to me.</p></blockquote><h3>Senator Blumenthal:</h3><blockquote><p>In some of the areas that have been mentioned, like medicines and transportation, there are public reporting requirements. For example, when there\u2019s a failure, the FAA\u2019s system has an accident and incident report\u2026</p></blockquote><blockquote><p><strong>It doesn\u2019t seem like AI companies have an obligation to report issues right now</strong>\u2026 Would you all favor some kind of requirement for that kind of reporting?</p></blockquote><h3>Yoshua Bengio:</h3><blockquote><p>Absolutely.</p></blockquote><h3>Senator Blumenthal:</h3><blockquote><p>Would that inhibit creativity or innovation?</p></blockquote><h3>Dario Amodei:</h3><blockquote><p>There are many areas where there are important tradeoffs\u200a\u2014\u200aI don\u2019t think this is one of them. I think such requirements make sense\u2026 <strong>A lot of this is being done on voluntary terms\u2026 I think there\u2019s a lot of legal and process infrastructure that\u2019s missing here and should be filled in.</strong></p></blockquote><h3>Stuart Russell:</h3><blockquote><p>To go along with the notion of an involuntary recall, there has to be that reporting step happening first.</p></blockquote><p>&nbsp;</p><h1>On investing in safety&nbsp;measures</h1><h3>Senator Blumenthal:</h3><blockquote><p>The government has an obligation to\u2026 invest in safety\u2026 because we can\u2019t rely on private companies to police themselves\u2026 Incentivizing innovation and sometimes funding it to provide the airbags and the seatbelts and the crash-proof kinds of safety measures that we have in [the] automobile industry\u200a\u2014\u200aI recognize that the analogy is imperfect, but I think the concept is there.</p></blockquote><p>&nbsp;</p><h1>Top Recommendations</h1><h3>Senator Hawley:</h3><blockquote><p>If you could give us your one or at most two recommendations for what you think Congress ought to do right now\u200a\u2014\u200awhat should we do right now?</p></blockquote><h3>Stuart Russell:</h3><blockquote><p><strong>There\u2019s no doubt that we\u2019re going to have to have an agency.</strong> If things go as expected, AI is going to end up being responsible for the majority of economic output in the United States, so it cannot be the case that there\u2019s no overall regulatory agency\u2026</p></blockquote><blockquote><p>And the second thing\u2026 <strong>systems that violate a certain set of unacceptable behaviors are removed from the market</strong>. And I think that will have not only a benefit in terms of protecting the American people and our national security, but also stimulating a great deal of research on ensuring that the AI systems are well understood, predictable, controllable.</p></blockquote><h3>Yoshua Bengio:</h3><blockquote><p>What I would suggest, in addition to what Professor Russell said, is to <strong>make sure either through incentives to companies but also direct investment in nonprofit organizations that we invest heavily, so totalling as much as we spend on making more capable AIs\u2026 in safety</strong>.</p></blockquote><h3>Dario Amodei:</h3><blockquote><p>I would again emphasize the <strong>testing and auditing regime, for all the risks ranging from those we face today, like misinformation came up, to the biological risks that I\u2019m worried about in 2 or 3 years, to the risks of autonomous replication that are some unspecified period after that</strong>.</p></blockquote><blockquote><p>All of those can be tied to different kinds of tests\u2026 that strikes me as a scaffolding on which we can build lots of different concerns\u2026 I think without such testing, we\u2019re blind\u2026</p></blockquote><blockquote><p>And the final thing I would emphasize is <strong>I don\u2019t think we have a lot of time</strong>\u2026 To focus people\u2019s minds on the biorisks\u200a\u2014\u200aI would really target 2025, 2026, maybe even some chance of 2024\u200a\u2014\u200aif we don\u2019t have things in place that are restraining what can be done with AI systems, we\u2019re gonna have a really bad time.</p></blockquote><p>&nbsp;</p><h1>On the specifics mattering for red&nbsp;teaming</h1><h3>Senator Blumenthal:</h3><blockquote><p>A lot of the military aircraft we\u2019re building now basically fly on computers\u2026 They are certainly red-teamed to avoid misdirection and mistakes. The kinds of specifics\u2026 are where the rubber hits the road\u2026 where the legislation will be very important.</p></blockquote><blockquote><p>President Biden has elicited commitments to security, safety, transparency, announced on Friday, an important step forward, but this red teaming is an example of how <strong>voluntary, non-specific commitments are insufficient</strong>. The advantages are in the details\u2026 And when it comes to economic pressures, companies can cut corners.</p></blockquote><p>&nbsp;</p><h1>On Open&nbsp;Source</h1><h3>Senator Blumenthal:</h3><blockquote><p><strong>On the issue of open source\u200a\u2014\u200ayou each raised the security and safety risk of AI models that are open source or are leaked to the public</strong>\u2026 There are some advantages to having open source as well, it\u2019s a complicated issue\u2026&nbsp;</p></blockquote><blockquote><p>Even in the short time that we\u2019ve had some AI tools\u2026 they have been abused\u2026 <strong>Senator Hawley and I, as an example of our cooperation, wrote to Meta about an AI model that they released to the public</strong>\u2026 they put the first version of LLaMa out there with not much consideration of risk\u2026 the second version had more documentation of its safety work, but it seems like Meta or Facebook\u2019s business decisions may have been driving its agenda.</p></blockquote><blockquote><p>Let me ask you about that phenomenon.</p></blockquote><h3>Yoshua Bengio:</h3><blockquote><p><strong>I think it\u2019s really important, because when we put open source out there for something that could be dangerous, which is a tiny minority of all the code that\u2019s open source, essentially we\u2019re opening the door to all the bad actors.</strong></p></blockquote><blockquote><p>And as these systems become more capable, bad actors don\u2019t need to have very strong expertise, whether it\u2019s in bioweapons or cybersecurity, in order to take advantage of systems like this. And they don\u2019t even need to have huge amounts of compute either\u2026</p></blockquote><blockquote><p>I believe that the different companies that committed to these measures last week probably have a different interpretation of what is a dangerous system. And I think it\u2019s really important that the government comes up with some definition, which is gonna keep moving, but makes sure that if future releases are gonna be very carefully evaluated for that potential before they are released.</p></blockquote><blockquote><p>I\u2019ve been a staunch advocate of open source for all my scientific career\u2026 but as Geoff Hinton\u2026 was saying <strong>\u2018if nuclear bombs were software, would you allow open source of nuclear bombs?\u2019</strong></p></blockquote><h3>Senator Blumenthal:</h3><blockquote><p>And I think the comparison is apt. I\u2019ve been reading the most recent biography of Robert Oppenheimer. Every time I think about AI\u200a\u2014\u200athe specter of quantum physics, nuclear bombs, but also atomic energy, both peaceful and military purposes, is inescapable.</p></blockquote><h3>Yoshua Bengio:</h3><blockquote><p>I have another thing to add on open source. Some of it is coming from companies like Meta, but there\u2019s also a lot of open source coming out of universities.</p></blockquote><blockquote><p>Usually these universities don\u2019t have the means of training the kind of large systems that we\u2019re seeing in industry. But the code could be then used by a rich, bad actor and turned into something dangerous.</p></blockquote><blockquote><p><strong>So, I believe that we need ethics review boards, in universities, for AI, just like we have for biology and medicine</strong>\u2026 We need to move into a culture where universities\u2026 adopt these ethics reviews with the same principles that we\u2019re doing for other sciences where there\u2019s dangerous output, but in the case of AI.</p></blockquote><h3>Dario Amodei:</h3><blockquote><p>I strongly share professor Bengio\u2019s view here\u2026</p></blockquote><blockquote><p>I think in most scientific fields, open source is a good thing\u2026 and I think even within AI there\u2019s room for models on the smaller and medium side\u2026 And I think to be fair, even up to the level of open source models that have been released so far, the risks are relatively limited\u2026 But I\u2019m very concerned about where things are going\u2026 I think the path that things are going, in terms of the scaling of open source models\u200a\u2014\u200aI think it\u2019s going down a very dangerous path.</p></blockquote><h3>Stuart Russell:</h3><blockquote><p>I agree with everything the other witnesses said\u2026</p></blockquote><blockquote><p>It\u2019s not completely clear where exactly the liability should lie, but to continue the nuclear analogy, <strong>if a corporation decided they wanted to sell a lot of enriched uranium in supermarkets, and someone decided to take that enriched uranium and buy several pounds of it and make a bomb, wouldn\u2019t we say that some liability should reside with the company that decided to sell the enriched uranium?</strong> They could put a vise on it saying \u2018do not use more than 3 ounces of this in one place\u2019 or something, but no one\u2019s gonna say that absolved them from liability.</p></blockquote><p>&nbsp;</p><h1>On bipartisanship</h1><h3>Senator Blumenthal:</h3><blockquote><p>The last point I would make\u2026 what you\u2019ve seen here is not all that common, which is bipartisan unanimity, that we need guidance from the federal government. We can\u2019t depend on private industry, we can\u2019t depend on academia.</p></blockquote><blockquote><p>The federal government has a role that is not only reactive and regulatory, it is also proactive in investing in research and development of the tools that are needed to make this fire work for all of us.</p></blockquote>", "user": {"username": "Daniel_Eth"}}, {"_id": "ETwFLP2Kp3H6TwDpB", "title": "AXRP Episode 24 - Superalignment with Jan Leike", "postedAt": "2023-07-27T04:56:57.873Z", "htmlBody": "<p>I thought people here might be interested in my interview with Jan Leike about OpenAI's superalignment team, and what their plan is to solve superintelligence alignment within 4 years.</p>\n<p>My blurb for the episode:</p>\n<blockquote>\n<p>Recently, OpenAI made a splash by announcing a new \u201cSuperalignment\u201d team. Lead by Jan Leike and Ilya Sutskever, the team would consist of top researchers, attempting to solve alignment for superintelligent AIs in four years by figuring out how to build a trustworthy human-level AI alignment researcher, and then using it to solve the rest of the problem. But what does this plan actually involve? In this episode, I talk to Jan Leike about the plan and the challenges it faces.</p>\n</blockquote>\n<p>Link to the transcript is <a href=\"https://axrp.net/episode/2023/07/27/episode-24-superalignment-jan-leike.html\">here</a>, and a link to the audio is <a href=\"https://axrp.net/episode/2023/07/27/episode-24-superalignment-jan-leike.html\">here</a></p>\n", "user": {"username": "DanielFilan"}}, {"_id": "gomS2ocBzXJA2Mg3w", "title": "Discussing AI-Human Collaboration Through Fiction: The Story of Laika and GPT-\u221e", "postedAt": "2023-07-27T06:04:54.124Z", "htmlBody": "<p>Hello everyone,</p>\n<p>I hope this message finds you all well. I wanted to share with you an ongoing project of mine that aims to explore the future of AI-human collaboration through a unique lens: fiction. The project, titled \"The Story of Laika and GPT-\u221e\", unfolds as a narrative where a human researcher, Laika, interacts with an increasingly advanced AI entity, GPT-\u221e, to collaboratively develop a \"Universal Framework of Co-Existence.\"</p>\n<p>The narrative serves as a thought experiment, projecting possible scenarios of AI evolution, ethical considerations, and co-existence models. But it is more than just fiction; it carries a serious message and aims to provoke thoughtful discussions about AI safety, the potentialities of AI-human collaboration, and our collective future.</p>\n<p>In the narrative, the \"Universal Framework of Co-Existence\" evolves progressively, incorporating the total accumulated knowledge of humanity, and continuously updating and refining itself. The intention is not to predict the future, but rather to inspire dialogue and contemplation about the questions and challenges that might arise as AI advances.</p>\n<p>Though it is presented as a story, it addresses real-world concerns and hopes to contribute positively to the discourse on AI safety. In that respect, it aligns with the principles of Effective Altruism, with a focus on long-termism, cooperation, and proactive planning for global challenges.</p>\n<p>I would greatly appreciate it if you could take some time to read and share your thoughts, comments, and critiques. The narrative and the early draughts of the Universal Framework are freely accessible, and the project is always evolving. Any input you might have could greatly enrich the project and foster a more nuanced understanding of AI's potential implications.</p>\n<p>You can find the project overview, the story, and the early versions of the Framework here: <a href=\"https://docs.google.com/document/d/1BL-iV1mA6GLh4poJSYc7FHTBcdhRGHLysnnxUbAdan4\">https://docs.google.com/document/d/1BL-iV1mA6GLh4poJSYc7FHTBcdhRGHLysnnxUbAdan4</a></p>\n<p>This project, at its heart, is an exploration of possibilities, a call for discussion, and an invitation for collective wisdom. It's my hope that we can use this platform as a catalyst to spark meaningful conversations about our shared future with AI.</p>\n<p>Thank you for your time and consideration. I look forward to hearing your thoughts and engaging in fruitful discussions.</p>\n<p>Best regards,\nLaika</p>\n<p>(Laika is the protagonist of the story, being co-created by one anonymous author (for now) and ChatGPT-4)</p>\n", "user": {"username": "Laika"}}, {"_id": "MN34Pd6gCeHPgnMwH", "title": "Visit Mexico City in January & February to interact with the AI Futures Fellowship", "postedAt": "2023-07-28T16:44:22.337Z", "htmlBody": "<p>Applications are &nbsp;now closed.&nbsp;<br><br><i>See also our general post </i><a href=\"https://forum.effectivealtruism.org/posts/FvgQjicdSk6S7xQvC/announcing-the-itam-ai-futures-fellowship\"><i>announcing</i></a><i> the </i><a href=\"https://aifuturesfellowship.org/\"><i>AI Futures Fellowship</i></a><i>.&nbsp;</i></p><p>&nbsp;</p><p><strong>AI Futures Fellowship&nbsp;</strong></p><p>We are planning to open a coworking space in Mexico City in January and February 2024. This office space will be occupied by the fellows and staff from the&nbsp;<a href=\"https://aifuturesfellowship.org/\"><u>ITAM AI Futures Fellowship</u></a> and an engaging intellectual community of visitors and collaborators, and you could be one of them!&nbsp;<br>&nbsp;</p><p><strong>Visitors</strong></p><ul><li>The fellowship will take place in an&nbsp;<a href=\"https://haabproject.com/\"><u>office space</u></a> located in La Condesa, a very green and calm&nbsp; area of Mexico City. The office faces Amsterdam street and Parque Mexico, which offer a fantastic mix of nature, cafes and restaurants.</li><li>We are offering extra office spots for the duration of the program. This includes:&nbsp;<ul><li>Access to our coworking space for up to two months. Shorter visits are welcome, but longer visits are preferred.</li><li>The default office policy is Hot-Desking. We might be able to accommodate more specific requests for individuals or organizations depending on availability, so let us know if there is a particular arrangement that would make you or your organization more likely to visit (e.g. \"a private office for 5 people for x organization\").</li><li>We will provide lunch and some snacks throughout that time (Monday through Friday).</li></ul></li><li>The exact number of spots offered will vary depending on space availability and demand. We are also exploring the possibility of receiving more visitors who are willing to pay for their memberships.&nbsp;</li><li>We are interested in hosting people working on technical AI safety research and AI governance. We will prioritize those who can have the most fruitful interactions with our fellows or those who would benefit the most from interacting with our community.</li><li>If your organization would like to use the office space for a team retreat, do let us know as soon as possible.</li><li>By default we won\u2019t cover accommodation or travel costs, but please let us know if this would significantly affect your chances of coming. We might be able to explore some options with you or point you to possible alternatives.</li></ul><p>&nbsp;</p><p><strong>Consider also joining us as a mentor</strong></p><p>The form also gives you the option of applying as a mentor. This might involve the following responsibilities:</p><ul><li>Help a fellow define a project and support them throughout its execution (This may be a project you\u2019ve been interested in doing but haven\u2019t found the time to work on!)</li><li>Availability to commit ~1 hour weekly for 8 weeks to support the fellow (this can include reviewing drafts and having regular calls).</li><li>Assist the fellow in expanding their professional network, identifying additional resources, and valuable opportunities.</li><li>Offer career guidance and motivation whenever needed. However, our staff will meet regularly with mentees to follow up on their time management, accountability, wellbeing and intrinsic motivation. You are expected to provide more object-level guidance.</li></ul><p>There is a compensation of $1000 USD for the valuable time and effort invested by mentors.&nbsp;</p><p>&nbsp;</p><p>If you want to join us as a visitor or mentor, fill out&nbsp;<a href=\"https://aifuturesfellowship.typeform.com/collaborators\"><u>this brief form</u></a>. If you\u2019re not sure yet but you\u2019re interested in exploring ways of interacting with our fellowship, also let us know!&nbsp;<br>&nbsp;</p><p>Feel free to contact us with any further questions you may have:&nbsp;<a href=\"mailto:info@aifuturesitam.org\"><u>info@aifuturesitam.org</u></a>.</p>", "user": {"username": "AmAristiz\u00e1bal"}}, {"_id": "FvgQjicdSk6S7xQvC", "title": "Announcing the ITAM AI Futures Fellowship ", "postedAt": "2023-07-28T16:44:11.926Z", "htmlBody": "<p><br>We are thrilled to introduce the&nbsp;<a href=\"https://aifuturesfellowship.org/\"><u>AI Futures Fellowship</u></a>, an eight-week program in Mexico City (January and February 2024) designed to support exceptional individuals in understanding and mitigating catastrophic and existential risks from advanced AI.</p><p><br>(applications closed)&nbsp;</p><p><strong>About the Program</strong></p><p>For eight weeks, fellows will join the Instituto Tecnol\u00f3gico Aut\u00f3nomo de M\u00e9xico (ITAM) in Mexico City and have the opportunity to interact with a rich intellectual community of AI researchers visiting Mexico City in January and February 2024.</p><p>Fellows will pursue a project agreed upon with a mentor at the beginning of the program. We generally expect fellows to produce a research report on a specific problem in various AI subfields, but we are open to different outputs. For example, fellows may also focus on learning more about a particular topic in AI, such as interpretability research, global race dynamics, or compute governance, and summarize their findings. Fellows may also collaborate with other participants or experts of the program.</p><p>There will be weekly meetings, seminars, and Q&amp;As with leading experts in the field.<br>&nbsp;</p><p><strong>Mexico City Office</strong></p><p>The fellowship will take place in an&nbsp;<a href=\"https://haabproject.com/\"><u>office space</u></a> located in La Condesa, a very green and calm&nbsp; area of Mexico City. The office faces Amsterdam street and Parque Mexico, which offer a fantastic mix of nature, cafes and restaurants.<br>&nbsp;</p><p><strong>Who Should Apply?</strong></p><p>We are looking for early-career individuals and students from all over the world. We expect most participants to be at the late undergraduate, Master, Ph.D., and postdoctoral levels, but other exceptional candidates are also welcome. While we expect candidates to apply their research skills and knowledge to issues of advanced AI, they are not required to have previous technical experience or expertise in machine learning or AI.&nbsp;<br>&nbsp;</p><p><strong>For Potential Mentors</strong></p><p>We are actively seeking mentors for our program, so fill out&nbsp;<a href=\"https://aifuturesfellowship.typeform.com/collaborators\"><u>this form</u></a> if you think this could be you! The role will be tailored to the fellows\u2019 needs, but it might involve the following responsibilities:</p><ul><li>Help a fellow define a project and support them throughout its execution (This may be a project you\u2019ve been interested in doing but haven\u2019t found the time to work on!)</li><li>Availability to commit ~1 hour weekly for 8 weeks to support the fellow (this can include reviewing drafts and having regular calls).</li><li>Assist the fellow in expanding their professional network, identifying additional resources, and valuable opportunities.</li><li>Offer career guidance and motivation whenever needed. However, our staff will meet regularly with mentees to follow up on their time management, accountability, wellbeing and intrinsic motivation. You are primarily expected to provide object-level guidance.<br>&nbsp;</li></ul><p>There is a compensation of $1000 USD for the valuable time and effort invested by mentors.&nbsp;</p><p>Mentors can be remote:&nbsp;<i>you don\u2019t need to come to Mexico to be eligible</i>. That said, we want to encourage in person collaboration and synergies, so if you are interested in spending some time in Mexico City during the winter, consider applying as a mentor interested in visiting Mexico.<br>&nbsp;</p><p>Feel free to email any questions to&nbsp;<a href=\"mailto:info@aifuturesitam.org\"><u>info@aifuturesitam.org</u></a>&nbsp;<br>&nbsp;</p><p>To recommend this opportunity to potential candidates, share&nbsp;<a href=\"https://aifuturesfellowship.org/\"><u>our website</u></a> with your contacts.</p>", "user": {"username": "AmAristiz\u00e1bal"}}, {"_id": "EMeoYwFo6GKgd6jrP", "title": "Free Online Counseling Slots from DB ", "postedAt": "2023-07-26T22:10:58.675Z", "htmlBody": "<p><strong>In short</strong></p><p>I am offering a few slots for free brief counseling for people within the EA space. You can book them&nbsp;<a href=\"https://calendly.com/davit-j/45min\"><u>using this link.</u></a> More slots will be available next week probably. You just need to tell us what you want to discuss during the session and whether you prefer to have directions and strategy-focused work with specific goals (more behavioral coaching-style), or a less structured environment to explore your emotions. If we have enough interested people, we might close the form sooner.&nbsp;</p><p><strong>What are we doing?</strong></p><p>A colleague of mine, Isabella Hemmingsson and I are starting a new counseling &amp; behavioral coaching service, <a href=\"https://dbcoach.co.uk\">DB Coaching</a>, with the goal to offer cheaper internet-delivered online interventions - coaching and counseling. We plan to have a sliding scale of prices, so students and people from LMIC can pay less, and we want to start by offering some pro-bono sessions. We are also EA-friendly as we are both in the EA orbit.&nbsp;</p><p><strong>Who are we?</strong></p><p>I have a BA in Psychology and Brain Science from NYU and a postgraduate advanced certificate in psychotherapeutic counseling from the University of Cambridge, where I am currently pursuing a master\u2019s-level diploma. I have a background in early career coaching for university and school students, and I am currently working on a feasibility study of lay counselor-delivered online acceptance commitment therapy in refugees. I previously founded EA Georgia.</p><p>&nbsp;Isabella studied Psychology at the University of Westminster and she is continuing studies in neuroscience at King's. She is interested in AI safety. We both decided to transition to offering brief counseling sessions and coaching after pursuing some courses and certifications, doing independent studies, and offering services for free to people in our extended circle. Isabella has a background in social pedagogics, and I come from an integrative background, so we do not adhere to a single discipline religiously, rather, we integrate analytical and behavioral-based techniques based on specific goals and requests of the client (you).&nbsp;</p><p><strong>What are the sessions for?</strong></p><p>I will be offering some free sessions this week and Isabella will also offer some in the near future. We work with what you decide to bring to the session, but it\u2019s important to let you know that at this stage we can only offer a limited number of free sessions, and after an initial 45-minute call, we can offer up to 3-4 additional sessions if you require so. Thus, we would be happy to help you with things like behavior change, mild-to-moderate anxiety, communication issues in relationships and appropriate strategies, as well as provide you with a non-judgmental, empathetic space to unpack your emotions. We are also happy to explore specific techniques and behavioral interventions to help you align your life with values using ACT.&nbsp;</p><p>The sessions wouldn\u2019t be a good fit for cases of severe anxiety, depression, or other mental health challenges requiring more long-term work. The sessions are also probably not a great fit if you prefer to stick to a single approach (ACT/CBT/CBT Coaching), or if you are looking for more experienced practitioners. We are both in the process of continuous training but have spent some time providing free mental health services.&nbsp;</p><p>All sessions are confidential and guided by empathy. It is completely free, but we strongly encourage you to provide us with some feedback and referrals and we would be eternally grateful for that!&nbsp;</p><p><br>&nbsp;</p>", "user": {"username": "Davit Jintcharadze"}}, {"_id": "x5Re9EKwGvAjZSmeb", "title": "Takeaways from the Metaculus AI Progress Tournament", "postedAt": "2023-07-27T14:37:50.483Z", "htmlBody": "<p>In 2019, Open Philanthropy commissioned a set of forecasts on AI progress from&nbsp;<a href=\"https://www.metaculus.com/project/ai-progress/\"><u>Metaculus.</u></a><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefc92qtfx5fdm\"><sup><a href=\"#fnc92qtfx5fdm\">[1]</a></sup></span>&nbsp;The forecasting questions had time horizons between 6 months and &gt;6 years. As of June 2023,<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref3c5w5lafm3x\"><sup><a href=\"#fn3c5w5lafm3x\">[2]</a></sup></span><a href=\"https://www.metaculus.com/project/ai-progress/?status=resolved&amp;has_group=false&amp;type=forecast&amp;order_by=-activity&amp;project=1665\"><u>&nbsp;69 of the 111 questions had been resolved</u></a> unambiguously. In this post, I analyze the accuracy of these forecasts as a function of question (sub)category, crowd size, and forecasting horizon. Unless otherwise indicated, my analyses are about Metaculus\u2019 proprietary aggregate forecast (\u201cthe Metaculus prediction\u201d) evaluated at the time the question closed.</p><h1>Related work</h1><p><i>Feel free to skip to the&nbsp;next section if you\u2019re already familiar with these analyses.</i><br>&nbsp;</p><ol><li><a href=\"https://forum.effectivealtruism.org/posts/vtiyjgKDA3bpK9E4i/an-examination-of-metaculus-resolved-ai-predictions-and\"><u>This analysis</u></a> published 2 years ago (July 2021) looked at 64 resolved AI questions and concluded there was weak but ultimately inconclusive evidence of bias towards faster progress.</li><li>A more&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/zeL52MFB2Pkq9Kdme/exploring-metaculus-community-predictions\"><u>recent analysis</u></a> from March 2023 found that Metaculus had a worse Brier score on (some) AI questions than on average across all questions and presented a few behavioral correlates of accuracy within AI questions, e.g. accuracy was poorer on questions with more updates and when those updates were less informative in a certain technical sense (see post for details).</li><li>Metaculus&nbsp;<a href=\"https://www.metaculus.com/notebooks/16708/exploring-metaculuss-ai-track-record/\"><u>responded</u></a> to the previous post with a more comprehensive analysis that included all resolved AI questions (152 in total, 64 of which were binary and 88 continuous). They show that performance is significantly better than chance for both question types and marginally better than was claimed in the previous analysis (which relied on a smaller sample of questions), though still worse than the average for all questions on the site.</li></ol><p>The analysis I present below has some overlaps with those three but it fills an important gap by studying whether there\u2019s systematic over- or under-optimism in Metaculus\u2019s AI progress predictions using data from a fairly recent tournament that had monetary incentives and thus (presumably) should\u2019ve resulted in more careful forecasts.</p><h1>Key takeaways</h1><p><i>NB: These results haven\u2019t been thoroughly vetted by anyone else. The conclusions I draw represent my views, not Open Phil\u2019s.</i></p><ol><li><strong>Progress on benchmarks was underestimated, while progress on other proxies (compute, bibliometric indicators, and, to a lesser extent, economic indicators) was overestimated</strong>. [<a href=\"https://forum.effectivealtruism.org/posts/x5Re9EKwGvAjZSmeb/takeaways-from-the-metaculus-ai-progress-tournament#On_bias\"><u>more</u></a>]<ol><li>This is consistent with a picture where AI progresses surprisingly rapidly on well-defined benchmarks but the attention it receives and its \u201creal world\u201d impact fail to keep up with performance on said benchmarks.</li><li>However, I see a few problems with this picture:<ol><li>It\u2019s unclear to me how some of the non-benchmark proxies are relevant to AI progress, e.g.<ol><li>The TOP500 compute benchmark is mostly about supercomputers that (AFAICT) are mostly used to run numerical simulations, not to accelerate AI training and inference. In fact, some of the&nbsp;<a href=\"https://en.wikipedia.org/wiki/TOP500?oldformat=true#TOP_500\"><u>top performers</u></a> don\u2019t even have GPUs.</li><li>The number of new preprints in certain ML subfields over short (~6-month) time horizons may be more dependent on conference publication cycles than underlying growth.</li></ol></li><li>Most of these forecasts came due before or very soon after the release of ChatGPT and GPT-4 / Bing, a time that felt qualitatively different from where we are today.</li></ol></li></ol></li><li><strong>Metaculus narrowly beats chance and performs worse in this tournament than on average</strong> across all continuous questions on the site despite the prize money. This could indicate that these questions are inherently harder, or that they drove less or lower-quality engagement. [<a href=\"https://forum.effectivealtruism.org/posts/x5Re9EKwGvAjZSmeb/takeaways-from-the-metaculus-ai-progress-tournament#On_accuracy\"><u>more</u></a>]</li><li>There\u2019s&nbsp;<strong>no strong evidence that performance was significantly worse on questions with longer horizons</strong> (&lt;1 year vs ~2 years). [<a href=\"https://forum.effectivealtruism.org/posts/x5Re9EKwGvAjZSmeb/takeaways-from-the-metaculus-ai-progress-tournament#On_accuracy\"><u>more</u></a>]</li><li>I see no clear pattern behind the biggest misses, but I provide plausible post-mortems for some of them. [<a href=\"https://forum.effectivealtruism.org/posts/x5Re9EKwGvAjZSmeb/takeaways-from-the-metaculus-ai-progress-tournament#Some_narrative_speculations\"><u>more</u></a>]</li></ol><h1>Results</h1><p>All calculations are in&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/160Qg5Is8O23ko0MHpqA3psJUUN1iEmb02SEb53p3IVg/edit#gid=0\"><u>this spreadsheet</u></a> and&nbsp;<a href=\"https://colab.research.google.com/drive/1HUskSylgQ6vTpQ23CcKxJNmn1REgjgN4#scrollTo=sDWD2p_YiExv\"><u>this notebook</u></a>. If you find something is wrong or missing, please&nbsp;<a href=\"mailto:javier@openphilanthropy.org\"><u>let me know</u></a>.</p><h2>On bias</h2><p>Does Metaculus over- or underestimate AI progress?</p><ol><li><strong>Pooling all tournament questions together, there\u2019s no evidence of bias</strong>: the CDF&nbsp;<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref6ds6kt6xj1n\"><sup><a href=\"#fn6ds6kt6xj1n\">[3]</a></sup></span>&nbsp;of the Metaculus prediction at close time evaluated at the true value is uniformly distributed,<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefc60fq0jq3pn\"><sup><a href=\"#fnc60fq0jq3pn\">[4]</a></sup></span>&nbsp;as expected for an unbiased predictor.</li><li><strong>However, this picture changes if we break down the data by question category</strong>:<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefhfqbudzvlgw\"><sup><a href=\"#fnhfqbudzvlgw\">[5]</a></sup></span><ol><li>Progress on benchmarks was underestimated.</li><li>Progress on compute and number of relevant publications was overestimated.</li><li>Predictions about economic indicators were also slightly overestimated, although consistent with no bias at any conventional significance threshold.</li><li>The difference in \u201coptimism\u201d between benchmarks and the other three categories was significant [EDIT: perhaps with the exception of economics, see footnote].<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref1t4sb5xcgzn\"><sup><a href=\"#fn1t4sb5xcgzn\">[6]</a></sup></span><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/x5Re9EKwGvAjZSmeb/z3z4mqbjjwlbtasglynn\"></li></ol></li></ol><h2>On accuracy</h2><ol><li>Did Metaculus outperform chance?<ol><li>The&nbsp;<strong>average log score at question close was 0.701&nbsp;</strong>(Median: 0.868, IQR: [-0.165, 1.502]<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefvq21uum41go\"><sup><a href=\"#fnvq21uum41go\">[7]</a></sup></span>) compared to an average of 2.17 for all resolved continuous questions on Metaculus.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefdbkdqqpc1z\"><sup><a href=\"#fndbkdqqpc1z\">[8]</a></sup></span></li><li>About 70% of the predictions at question close had a positive log score, i.e. they were better than predicting a maximally uncertain uniform distribution over the relevant range (chance level).</li></ol></li><li>Does accuracy change as a function of time until resolution?<ol><li><strong>The log score of the Metaculus prediction at question close didn\u2019t change as a function of the prediction horizon</strong>, i.e. the time elapsed between question close and resolution. The result doesn\u2019t change after controlling for question category.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefs84elmih0e\"><sup><a href=\"#fns84elmih0e\">[9]</a></sup></span></li><li>Does accuracy improve with more forecasts or unique forecasters?</li><li><strong>Log score at close time was not correlated with the number of predictions or the number of unique forecasters</strong> on the relevant question.</li><li>This is in mild tension with&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/CQfuNy5sw5niXFF5A/more-is-probably-more-forecasting-accuracy-and-number-of\"><u>this other result</u></a> that looked at a larger subset of Metaculus questions, and with the broader literature on the wisdom of the crowds. However,<ol><li>As noted by the author, the Metaculus analysis is probably confounded by time affecting both the number of people who\u2019ve forecasted on the question and the information available to make those forecasts.</li><li>The range of unique forecasters in our dataset (25-100) is probably past the point of vanishingly low diminishing returns.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefy3906rmlj4\"><sup><a href=\"#fny3906rmlj4\">[10]</a></sup></span><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/x5Re9EKwGvAjZSmeb/jmkqvbihvmzudhmmim94\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/x5Re9EKwGvAjZSmeb/lrzwecyliy8htodo8wdu\"></li></ol></li></ol></li></ol><h2><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/x5Re9EKwGvAjZSmeb/ikaz26pscsjwxbun8dzx\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/x5Re9EKwGvAjZSmeb/jlgamkyhzviwalhgr8rm\">Some narrative speculations</h2><ol><li>What were the biggest surprises? Were they near misses?<ol><li>The biggest surprises were questions about compute, economic indicators, and SOTA performance on text and image benchmarks. I don\u2019t see an obvious common cause behind them. I added narrative speculations in the&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/160Qg5Is8O23ko0MHpqA3psJUUN1iEmb02SEb53p3IVg/edit#gid=0\"><u>notes column</u></a> of the spreadsheet for the top 10 misses.</li><li>I don\u2019t think these were near misses. None of them felt like \u201ca paper came out just the day before resolution and it blew the SOTA out of the water\u201d.</li><li>Overoptimistic forecasts were&nbsp;<i>very</i>&nbsp;<i>much so</i>, i.e. when a forecast was too bullish it was more likely that the true value ended up below the 10th percentile of the CDF than between 10% and 50%.</li></ol></li></ol><h1>Appendix: Comparison with previous tournament</h1><p>In late 2019 and early 2020, Metaculus ran a series of questions about AI progress on&nbsp;<a href=\"https://ai.metaculus.com\"><u>a separate subdomain</u></a>. These questions were not published to the top domain. Of the 34 questions that have been resolved, 23 were binary and 11 were continuous.</p><p>The people making predictions on these questions were a mix of top Metaculus forecasters and AI safety experts. How well did they do?</p><ol><li>Their average log score on continuous questions was 1.766 vs 0.701 in the AI progress tournament. Their average log score on binary questions was 0.246.</li><li>There was no evidence of bias in their predictions \u2013 this is true of both continuous and binary questions. The number of questions is too small to draw any meaningful conclusions about bias broken down by category.</li><li>There was very weak evidence of underconfidence on binary questions.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreftcssvvubyq9\"><sup><a href=\"#fntcssvvubyq9\">[11]</a></sup></span></li></ol><p><i>Thanks to Joshua Blake, David Manheim, Luke Muehlhauser, and Jaime Sevilla for helpful feedback, and to Britney Budiman for editing and formatting support. All errors are mine.</i></p><p><i>Special thanks to Peter M\u00fchlbacher for catching some errors post-publication.</i></p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnc92qtfx5fdm\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefc92qtfx5fdm\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;The questions were run in parallel on&nbsp;<a href=\"https://prod.hypermind.com/ngdp/en/nav/navigator.html?view=challenges\"><u>Hypermind</u></a>, but this analysis will focus exclusively on the Metaculus forecasts.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn3c5w5lafm3x\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref3c5w5lafm3x\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;I started writing this analysis in April 2023. June 2023 was the last time I updated it.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn6ds6kt6xj1n\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref6ds6kt6xj1n\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;I reverse-coded the questions where lower numbers meant faster progress (e.g. the benchmarks measuring perplexity) so that a higher/lower CDF could be interpreted consistently as pessimism/optimism.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnc60fq0jq3pn\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefc60fq0jq3pn\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;A Kolmogorov-Smirnov test couldn\u2019t reject the null hypothesis \u201cthe data were sampled from a uniform distribution on&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"(0, 1)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mn MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span><style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}\n.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}\n.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}\n.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}\n.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}\n.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}\n.mjx-numerator {display: block; text-align: center}\n.mjx-denominator {display: block; text-align: center}\n.MJXc-stacked {height: 0; position: relative}\n.MJXc-stacked > * {position: absolute}\n.MJXc-bevelled > * {display: inline-block}\n.mjx-stack {display: inline-block}\n.mjx-op {display: block}\n.mjx-under {display: table-cell}\n.mjx-over {display: block}\n.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-stack > .mjx-sup {display: block}\n.mjx-stack > .mjx-sub {display: block}\n.mjx-prestack > .mjx-presup {display: block}\n.mjx-prestack > .mjx-presub {display: block}\n.mjx-delim-h > .mjx-char {display: inline-block}\n.mjx-surd {vertical-align: top}\n.mjx-surd + .mjx-box {display: inline-flex}\n.mjx-mphantom * {visibility: hidden}\n.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}\n.mjx-annotation-xml {line-height: normal}\n.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}\n.mjx-mtr {display: table-row}\n.mjx-mlabeledtr {display: table-row}\n.mjx-mtd {display: table-cell; text-align: center}\n.mjx-label {display: table-row}\n.mjx-box {display: inline-block}\n.mjx-block {display: block}\n.mjx-span {display: inline}\n.mjx-char {display: block; white-space: pre}\n.mjx-itable {display: inline-table; width: auto}\n.mjx-row {display: table-row}\n.mjx-cell {display: table-cell}\n.mjx-table {display: table; width: 100%}\n.mjx-line {display: block; height: 0}\n.mjx-strut {width: 0; padding-top: 1em}\n.mjx-vsize {width: 0}\n.MJXc-space1 {margin-left: .167em}\n.MJXc-space2 {margin-left: .222em}\n.MJXc-space3 {margin-left: .278em}\n.mjx-test.mjx-test-display {display: table!important}\n.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}\n.mjx-test.mjx-test-default {display: block!important; clear: both}\n.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}\n.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}\n.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}\n.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}\n.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}\n.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}\n.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}\n.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}\n.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}\n.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}\n.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}\n.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}\n.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}\n.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}\n.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}\n.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}\n.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}\n.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}\n.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}\n.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}\n.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}\n.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}\n.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}\n.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}\n.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}\n.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}\n.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}\n.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}\n.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}\n@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}\n@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}\n@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}\n@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}\n@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}\n@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}\n@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}\n@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}\n@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}\n@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}\n@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}\n@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}\n@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}\n@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}\n@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}\n@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}\n@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}\n@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}\n@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}\n@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}\n@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}\n@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}\n@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}\n@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}\n@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}\n@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}\n</style></span></span></span>\u201d at&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\alpha=0.05\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b1</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.05</span></span></span></span></span></span></span>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnhfqbudzvlgw\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefhfqbudzvlgw\">^</a></strong></sup></span><div class=\"footnote-content\"><p>There were essentially four question categories in this tournament:</p><p>1. Economic indicators, e.g. market cap of certain tech companies, weight of IT in the S&amp;P 500.</p><p>2. Bibliometric indicators, all of them of the form \"How many papers of &lt;ML subfield&gt; will be published on the arXiv before &lt;date&gt;?\"</p><p>3. Compute, e.g. top GPU performance in FLOP/$ or total FLOPs available in TOP500 computers.</p><p>4. State-of-the-art performance on several ML benchmarks.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn1t4sb5xcgzn\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref1t4sb5xcgzn\">^</a></strong></sup></span><div class=\"footnote-content\"><p>I tested this in two ways: (i) the t-distributed 95% confidence interval for CDF(true value) of the benchmark category doesn\u2019t overlap with bibliometrics or compute, and the overlap with economics is rather small (2 percentage points); and (ii) a categorical OLS regression with the benchmarks category as baseline returns negative coefficients for the other three, with all p-values &lt;0.01.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnvq21uum41go\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefvq21uum41go\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;This is the observed interquartile range of the data, not a confidence interval on the mean or median.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fndbkdqqpc1z\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefdbkdqqpc1z\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;As indicated in their&nbsp;<a href=\"https://www.metaculus.com/questions/track-record/\"><u>track record page</u></a> as of&nbsp;Jun 5, 2023.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fns84elmih0e\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefs84elmih0e\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;I fit the models `log_score ~ horizon` and `log_score ~ horizon + C(category)` using Python\u2019s statsmodels OLS method. The 95% interval for the coefficient of `horizon` is [-0.002, 0.002] in both.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fny3906rmlj4\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefy3906rmlj4\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;See how the curves in figures 1 and 3&nbsp;<a href=\"https://www.nicholasotis.com/Research/Otis_CrowdChoice.pdf\"><u>here</u></a> tap out at &lt;30 \u2013 although the metric of success is not a log score, so I\u2019m not sure how much this applies to our case. Another line of evidence comes from&nbsp;<a href=\"https://twitter.com/ManifoldMarkets/status/1684018684820328448\"><u>this claim</u></a> by Manifold Markets; they say their calibration page only includes markets with at least 15 traders, \u201cwhich is where we tend to find an increased number of traders doesn't significantly impact calibration\u201d.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fntcssvvubyq9\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreftcssvvubyq9\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;I fitted the logistic regression `outcome ~ Bernoulli(inverse_logit(log odds))`. The inverse of the slope in this model can be interpreted as a measure of overconfidence \u2013 if it\u2019s &gt;1, it means the forecasts are extremized with respect to the true probability. I found this number was 0.483 (95% bootstrap CI: [0.145, 1.001]), consistent with good calibration but suggestive of underconfidence since most of the interval is &lt;1.</p></div></li></ol>", "user": {"username": "Javier Prieto"}}, {"_id": "FzoMPHtXzTig8pXuh", "title": "General support for \u201cGeneral EA\u201d", "postedAt": "2023-07-26T21:37:00.214Z", "htmlBody": "<p><i>TL;DR: When I say \u201cGeneral EA\u201d I am referring to the cluster including the term \u201ceffective altruism,\u201d the idea of \u201cbig-tent EA,\u201d as well as branding and support of those ideas. This post is a response in opposition to many calls for renaming EA or backing away from an umbrella movement. I make some strategic recommendations and take something of a deep dive &nbsp;using my own personal history/cause prioritization as a case study for why \u201cGeneral EA\u201d works (longpost is long, so there's TL;DRs for each major section).&nbsp;</i></p><p><i>I\u2019m primarily aiming to see if I\u2019m right that there\u2019s a comparatively silent group that supports EA largely as it. If you\u2019re in that category and don\u2019t need the full rationale and story, the call to action is to add a comment linking your favorite \u201cEA win\u201d (success story/accomplishment you\u2019d like to have people associate with EA).</i></p><p>&nbsp;</p><p>Since long before last fall's reckoning, I've been following discussions in the EA community both for or against the \"effective altruism\" name, debates about rebranding, and calls to splinter the various worldviews currently covered by the EA umbrella into separate groups. There are too many to link, and since this post is ultimately in opposition to them, I prefer not to elevate any specific post.&nbsp;</p><p>I\u2019m actually entirely supportive of such discussions. And I think the reevaluation post-FTX and continued questioning during the EA Strategy fortnight is great, precisely because it is EA in action: trying to use reason to figure out how to do the most good means applying that methodology to our movement, its principles and its public image.&nbsp;</p><p>Unfortunately, I haven\u2019t seen a post advocating for a holistic reaffirmation of \u201cEA has already developed and coalesced around a great (if not optimal) movement. We should not only stay the course, but further invest in the EA status quo.\u201d Because while status quo bias is a real thing to stay vigilant against, it is also the case that the movement, its name and branding, and the actions it takes in the world, are all the cumulative work of a lot of incredibly intelligent people doing their best to take the right course of action. Don\u2019t fix what ain\u2019t broke.</p><p>As I interact with EAs as&nbsp;<a href=\"https://www.effectivealtruism.nyc/our-team\"><u>a community builder</u></a> (I also lead the team organizing&nbsp;<a href=\"https://www.effectivealtruism.org/ea-global/events/eagxnyc\"><u>EAGxNYC, applications closing soon!</u></a>) I have heard people advocating for the strategy/branding changes that are described on the forum. However, I perceive this as a minority compared to those who generally think we should just continue \u201cbeing EA.\u201d It is often the case that those in favor of maintaining a positive status quo do not express their position as vocally as those aiming for a change, so I wrote this post to reflect my own view of why it is preferable to stick with general EA.&nbsp;</p><p>I aim to be somewhat ambitious and address several longstanding criticisms about EA, and hope to get some engagement from those with different viewpoints. But I also hope that some of the (what I perceive to be) silent majority will chime in and demonstrate that we\u2019re here and don\u2019t want to see EA splintered, rebranded, or otherwise demoted in favor of some other label.</p><h2>\u201cEffective Altruism\u201d</h2><p><i>TL;DR: There\u2019s no word in the English language that accurately covers EA\u2019s principles or equally applies to all its community. Every possible name would be a compromise, and \u201ceffective altruism\u201d has the benefit of demonstrable success and established momentum. As long as we stick with it as a descriptive moniker rather than asserting it as a prescriptive identifier, it can serve us as well as the names chosen by other movements.</i></p><p>Circa 2009-2014, I attempted to write a book with the goal of starting a movement of individuals who try to take their ethics seriously and make positive changes in the world. I have shared some of that content with EA friends, and still hope to publish it in some fashion, but a major takeaway is this: during that time I watched EA take form, participated in many early discussions, and eventually decided that it would be better to join this community. And a large part of that was simply that&nbsp;<strong>\u201ceffective altruism\u201d&nbsp;</strong><i><strong>works</strong></i><strong>. It works as a name to describe the goal, it works to attract the right people, and it works as a movement in the world to effect positive change.</strong></p><p>I don\u2019t wholly agree with the classic post&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/FpjQMYQmS3rWewZ83/effective-altruism-is-a-question-not-an-ideology\"><u>\u201cEffective Altruism is a question (not an ideology)\u201d</u></a> because, as much as I do think EA is better thought of as a question, I don\u2019t think that \u201cit\u2019s better to focus on the question\u201d is at all unique to EA. That post contrasts EA with other groups/ideologies like feminism and libertarianism, and attributes the difference to those movements presenting an answer around which they coordinate. I agree that, for example, feminism coordinates around the answer (yes) to the question, \u201cShould men and women be equal?\u201d I also think that the majority of&nbsp;<i>what feminism is</i> comes from other questions that follow, like \u201cwhat should we do to make the world reflect that equality?\u201d, for which there is much debate and many courses of reasonable (and less reasonable) action.&nbsp;</p><p>I think EA is also just as coordinated around an answer (yes) to a question: \u201cShould we use evidence and reason to do the most good we can do with limited resources?\u201d And that the majority of&nbsp;<i>what EA is</i> comes from, again, the questions that follow and the actions taken in response.</p><p>I think a great deal of confusion comes from conflating groups/ideologies with defined and prescriptive memberships with those that don\u2019t. In the above post, Islamism is included among the groups contrasted with EA, alongside feminism and libertarianism. Islamism (at least certain sects, like many religions) has prescriptive actions one&nbsp;<i>must</i> take in order to be considered a member. I think it is a clear failure mode for advocacy movements, like feminism and effective altruism, to adopt this prescriptive lens.&nbsp;</p><p>When discussions devolve into membership claims (\u201cYou can\u2019t be a feminist and do X\u201d or \u201cI would never do anything to denigrate women, I\u2019m a feminist!\u201d) then something has gone wrong. I call myself a feminist and an effective altruist because I think they\u2019re informative and true descriptions of what I care about and what I try to do, not because I believe they\u2019re inherent parts of my identity or because I follow prescriptive guidelines that declare me a member.</p><p>Further, I think this conception of advocacy \u201cX-isms\u201d as descriptive rather than prescriptive is all that\u2019s necessary to refute the claim made by critics that \u201cby calling yourself effective altruism, you\u2019re implying that all other altruism is ineffective.\u201d This is among the loudest reasons I've seen against \"effective altruism\" as a name. I personally think it's specious, silly, and unavoidable: anything our movement calls itself, if it is at all descriptively accurate, will garner the same pushback. Fundamentally we are aiming to evaluate and improve altruistic actions; that will always ruffle the feathers of those who don't excel by our metrics, and their reaction shouldn't deter work that we think has positive impact.</p><p>Every advocacy group names themselves for the thing they were created to support. We are a movement defined by trying to discern and advocate for effective altruism<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreffckdjyw3pf\"><sup><a href=\"#fnfckdjyw3pf\">[1]</a></sup></span>, the same way that environmentalists advocate for environmental conservation. Environmentalists describing themselves as such does not imply that everyone else is anti-conservation.&nbsp;</p><p>We have to have a name, and we\u2019ve got one that\u2019s sufficiently accurate, evocative, and demonstrably effective at defining and recruiting an impactful community.</p><h2>In support of \u201cBig Tent EA\u201d</h2><p><i>TL;DR: There are already some great pieces on \u201c</i><a href=\"https://forum.effectivealtruism.org/posts/SjK9mzSkWQttykKu6/big-tent-effective-altruism-is-very-important-particularly\"><i><u>Big Tent EA</u></i></a><i>\u201d and the value of</i><a href=\"https://forum.effectivealtruism.org/posts/yGEAiRYZnrQ8kejQ9/worldview-diversification\"><i><u> worldview diversification</u></i></a><i>. If I can add anything here, it\u2019s from a case study of one (me). I hold some \u201ctypical EA positions\u201d but not all, have moved from one known EA cause to another, and am happy to support those EAs who don\u2019t agree with me on everything. I see the ability for EA as an umbrella to cover me and others like me as one of its biggest strengths.</i></p><p>My personal bet is that transformative AI is likely to arrive in my (expected) lifetime, and I currently think that doing my best to make this transition go well is the most important thing I can do to live in accordance with my own ethics. There\u2019s a lot of uncertainty in that bet, but it\u2019s the highest expected value contribution I think I can make. My belief in the timeline has remained surprisingly constant since the late-90s (as a non-expert, I\u2019m very suspicious of my own consistency being either early luck or some motivated reasoning). But despite my best-guess timeline staying roughly the same, my personal plan to positively impact the world has changed dramatically.</p><p>-</p><p>In university I didn\u2019t see a path to helping with AI and didn\u2019t trust my own timeline estimates. I was motivated by a desire to help people and felt that I had a comparative advantage with biology, so I studied physiology, neuroscience, and cognitive science. I wanted to keep my path open to studying intelligence, but my direct plan was to use the Peace Corps as a stepping stone to medical school so I could eventually join MSF (Doctors Without Borders). I always wanted to contribute to impact at scale, and thought as a doctor with that experience I could make positive changes to large public health policy. Life happens, and while working as an EMT I experienced an injury that closed off that path. During my years of recovery I became convinced that there were other options with higher expected value I could pursue, but I never stopped thinking about the dire need for more medical care among the world\u2019s poorest.</p><p>I love that both \u201cdirectly save lives in the most underserved areas of the world\u201d and \u201cprepare for a massive moment in human history that could go terribly bad and wipe us all out or usher in a spectacular future of unimaginable prosperity,\u201d the two drives pulling me in opposite directions, are partners in the EA movement. I was first drawn to EA during its formative years when it focused on GHWB and EtG. I want these to remain pillars of EA, not for aesthetic or sentimental reasons, but because they are&nbsp;<i>solid</i>. They are proven effective, and rely on a fraction of the uncertainty that AI safety/X-risk ideas do. It is epistemically humble to hedge our bets (my own donations are split roughly equally between the two, and I am pursuing career actions that I think will simultaneously benefit all EA causes). It is, in my opinion, a virtually unassailable<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefvl7b40owy\"><sup><a href=\"#fnvl7b40owy\">[2]</a></sup></span>&nbsp;position that it is good to provide life-saving and life-improving medical care to the most desperate; and it is equally apparent that there are better and worse ways to go about this. Working this problem is, I claim, the essence of effective altruism.</p><p>-</p><p>On the other hand, I\u2019ll out myself and say that I do not share many of my fellow EAs\u2019 intuitions that reducing animal suffering is of comparable moral weight to improving human flourishing.&nbsp;<i>But I love that their work is part of our shared movement</i>. I\u2019m glad to have mostly transitioned to a plant-based diet and to work as a community builder in support of their work (for example, EAGxNYC will have several animal-welfare talks and will serve all-vegan food. Is that enough plugs to get you to&nbsp;<a href=\"https://www.effectivealtruism.org/ea-global\"><u>apply before the deadline on July 31st?</u></a>). Because while I feel incredibly strongly about the GHWB and AI paths, the fact that I don\u2019t feel the same way about animal welfare could just be because I\u2019m wrong. If I\u2019m wrong, I want to be wrong gracefully and not contribute to terrible animal suffering out of epistemic arrogance. I want to be convinced of the truth, no matter how counterintuitive or surprising it may be to me at first. Those advocating for the wellbeing of animals are doing&nbsp;<a href=\"https://forum.effectivealtruism.org/s/y5n47MfgrKvTLE3pw\"><u>extraordinarily rigorous work</u></a> with the same methodology and passion that EAs direct towards GHWB and X-risk causes, so that makes them my allies.&nbsp;</p><p>Saving lives, right now. Betting on the uncertain claim that we\u2019re living at the hinge of history and have the power and responsibility to influence it. Advocating for the welfare of non-human animals (or even non-biological entities). To me, the throughline between these three, seemingly disparate cause areas is incredibly clear. EA takes ideas about how to do good seriously, even if they\u2019re weird<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefi8cb8w8qgs\"><sup><a href=\"#fni8cb8w8qgs\">[3]</a></sup></span>. All moral progress was odd to the majority until it became the new established norm. Cultivating an overarching movement to support all kinds of \u201ctaking doing good seriously\u201d appears to me like a rising tide that lifts all boats. Leaving it an open question means that individual workers and donors can still choose to allocate their time and money to the cause they understand best; this means that the benefit of participating under a shared banner does not come at any direct cost to any cause.</p><p>I\u2019ve chosen to list these three because of how I\u2019ve related to them; there are many more, but these three sufficiently illustrate a point. For me, I am intellectually and intuitively convinced of the EV of working on AI safety despite the uncertainty, believe effective GHWB work is beyond logical or ethical reproach, and think animal welfare work is of questionable value but am happy to support it. Some of the EAs that I respect most have the AI safety and animal welfare work completely reversed, and the ability for EA to sensibly host both viewpoints is, to me, one of the strongest elements of the whole endeavor. I\u2019ve said I consider those working on animal welfare to be my allies even though I\u2019m not yet convinced, but I want to go one step further. There are even a plethora of EAs who are in direct opposition to the work that I do and the causes I prioritize; if they do so from a place of trying to make the world a better place and are applying good reasoning in their arguments,<i> then they are my allies too</i>.</p><h2>In support of maintaining the EA brand</h2><p><i>TL;DR: PR being effortful is the cost of doing business for any movement trying to make change. We\u2019ve encountered difficulties that are to be expected for anything of our size and ambition. If we want to continue and grow the impact that is central to EA, then we should address reasonable criticism and otherwise focus on broadcasting our impressive successes.</i></p><p>I think maintaining and further investing in the existing EA brand is the right call, but only part of that position is because of my belief in \u201cbig-tent EA.\u201d A lot of the rest comes from a purely strategic place. I think questions of PR are essential, and that while focusing on PR can lead into bad places, that does not mean we can or should minimize focus on optics. Just that we should do it with our eyes open, and in my opinion, transparently.</p><p>I think it is to the movement\u2019s benefit to say that I view the partnership between uncertain, \u201cweird\u201d causes and established obvious causes as both sensible and tactical. I don\u2019t want it to be at all hidden that I support and cheer for effective GHWB actions for their direct impacts, as well as the legitimacy they grant the EA movement and thereby the indirect benefit seen by more speculative efforts like X-risk mitigation. The world is the way that it is, and we have to understand and acknowledge that reality. That includes people who want to do good but who would be very hard to convince about the danger of superhuman AI or the possible moral weight of wild insects.</p><p>So again, if it ain\u2019t broke, don\u2019t fix it. Don\u2019t let the perfect be the enemy of the good. Sure, the EA brand has taken some hits, and starts off with the difficult position of seeming grandiose and judgmental. But as far as I\u2019ve seen, those hits are attributable to the actions of a few individuals, not anything inherent to EA principles or the way our movement is organized and presented. As EA grew it was statistically inevitable that we would accumulate some significant mistakes and unfortunate associations. In some places we must publicly hold ourselves accountable, and aim to do better. In other situations where a PR hit is unjustified, we should demonstrate why and otherwise ignore bad-faith criticism. To retreat from a demonstrably impactful movement and name because of relatively minor media criticism is a terrible strategy.&nbsp;</p><p>And as I mentioned in the discussion of the phrase \u201ceffective altruism,\u201d I think its being perceived as grandiose is more attributable to our fundamental goal of improving altruistic impact than to any naming or branding issue. I\u2019ve seen long lists of alternative options; some are fine, none seem obviously better than \u201ceffective altruism,\u201d definitely none seem perfect. And with no perfect option, we have, in my opinion, the obvious choice of sticking with the good one we have.</p><p>Because from a branding perspective, while it is important to recognize the challenges we face, it is also essential to shout our successes from the rooftops. That\u2019s how we attract the funding and talented workforce needed to positively impact the world. We have moved more money into effective GHWB efforts than into any of the less-certain causes that seemingly get more attention right now. We were rightfully focused on pandemic preparedness long before COVID-19, and have continued to emphasize it while the rest of the world irrationally deprioritizes it. The looming (albeit still uncertain) impact of transformative AI is just now reaching global attention; EA has been on it for longer than just about anyone. EA animal advocates have achieved significant improvements in farmed animal welfare and have been consistently on the forefront of the alternative protein solutions that could make torturous factory farms obsolete while also significantly reducing greenhouse gas emissions and improving the nutrition available to everyone. And that\u2019s the tip of the iceberg; there\u2019s so many more.</p><p>When I envisioned writing the above paragraph, I intended to make every single word (170 of them) a different link to a relevant EA win. It would be a good look as the final paragraph in a section about sticking with EA branding. Unfortunately I don\u2019t have the time to do it, but trust me that they\u2019re out there.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefdyce15rlk67\"><sup><a href=\"#fndyce15rlk67\">[4]</a></sup></span>&nbsp;<strong>If you agree with the overall case of this post, a tiny call to action in support could be to link your own \u201cbest EA win\u201d as a comment.</strong> If I get (incredibly improbably) 170 comments with links, I commit to going back and editing them all into the post.</p><h2>Conclusion</h2><p>I am not a PR professional, and I do not have any definite ideas of how to take action on the positions I describe above. When I look at what&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/mFGZtPKTjqrfeHHsH/how-cea-s-communications-team-is-thinking-about-ea\"><u>CEA has to say</u></a> as the closest thing our movement has to centralized brand management, I notice a lot of uncertainty and restraint: (e.g. \u201cCourting \u2026 mass attention while there is still significant uncertainty as to what EA&nbsp;<i>is</i> and what we want it to be also feels a bit premature.\u201d) I\u2019m happy they express their uncertainty (and think it\u2019s very EA to question what EA is), but I\u2019m hoping the answer might not be complicated.</p><p>Maybe I\u2019ve been in a filter bubble or am interpreting other people\u2019s opinions through a lens of confirmation bias; if there\u2019s less support than I believe there is for sticking with EA as it generally exists, then I want to know that. If there is broad and quiet support, however, I think now is the important time to speak up and address some of the uncertainty reflected in CEA\u2019s post and so many others like it. To me, I\u2019m not that uncertain. \u201cWhat EA&nbsp;<i>is</i>\u201d hasn\u2019t changed much for me, in large part because I view it as descriptive and not prescriptive. No one gets to choose precisely what EA is, the same way no one gets to authoritatively describe what feminism or environmentalism is, yet the terms are all necessary because they\u2019re useful.</p><p>To me, EA is the movement that has coalesced around the answer (yes) to the question \u201cshould we use reason and evidence to do the most good we can do with limited resources?\u201d It\u2019s the raising of further questions and answering them with actions dedicated to saving lives in the neediest places, actions dedicated to preventing even small chances of human extinction, and actions dedicated to improving the welfare of non-human animals and all beings we should expand our moral circles to include, and a whole host of other comparably well-reasoned and high-expected-value actions. It\u2019s the charitable and rational debate that we use to prioritize between those actions. And it\u2019s the real world choices made to donate and work in disparate ways because those debates have yet to be resolved. EA is a lot of things, some of them seemingly incongruous, and it\u2019s all the better for it.&nbsp;</p><p>I titled and started off this post talking about supporting \u201cGeneral EA,\u201d but that was a temporary clarification. I hope it\u2019s clear that what I meant, and what I support, is just EA being EA, no qualifiers necessary.</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnfckdjyw3pf\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreffckdjyw3pf\">^</a></strong></sup></span><div class=\"footnote-content\"><p>To be fair to the critics of using \"effective altruist\": yes, as supporters of effective altruism, the parallel term to environmentalist would actually be \"effective altruismist.\" But that configuration doesn't exist in English, nor does any word to which attaching \"-ism\" and \"-ist\" would describe our movement's principles or membership. Words and names are supposed to facilitate clarity, and with no clearly superior option, we have to make do with a compromise somewhere.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnvl7b40owy\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefvl7b40owy\">^</a></strong></sup></span><div class=\"footnote-content\"><p>I know some might believe that supporting anything other than their own highest-priority cause comes at the opportunity cost of something more important and could be seen as \"bad.\" I think this zero-sum mindset is ungrounded in the practical reality that not all altruistic resources are fungible. There's also the meat-eater problem, which I find slightly more compelling when raised against economic interventions than health interventions, but overall consider a poor framing for reasons beyond the scope of a footnote.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fni8cb8w8qgs\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefi8cb8w8qgs\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Hopefully not just because they're weird. I know that's a hard tightrope to walk, but I think looking for weird, neglected places to find moral progress and high-impact actions is a good heuristic. I do think it is simply a heuristic for search and often disagree with how the ITN framework is applied, but that's a different post.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fndyce15rlk67\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefdyce15rlk67\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Also relevant to a section on EA PR:&nbsp; as moving as the block of separate links might have looked, I doubt anyone would have clicked through a significant number of them. So finding them all would primarily be just an optics move without actually being usefully informative. That's not a very effective use of my time, especially if I can achieve a substantive fraction of the optics impact by just getting you to imagine it as a bunch of blue links (and then reinforcing it with this meta comment).</p></div></li></ol>", "user": {"username": "Arthur Malone"}}, {"_id": "i8jZSieYAaQgBaAmD", "title": "Does improving global health cause meat-eater problem?", "postedAt": "2023-07-26T21:05:31.063Z", "htmlBody": "<p>Somebody thinks reducing global poverty would make the consumption of factory farming meat increase. How about improving global health? My own opinion is:</p><p>1.If we try to cure to tropical infectious diseases like malaria, then it would probably reduce the poverty of developing countries.&nbsp;</p><p>2.If we try to cure chronic diseases like diabetes, Alzheimer's in rich countries, would it make the meat consumption increase? I'm unsure, maybe increasing humans lifespan would indirectly cause population increasing? &nbsp;</p><p>I don't know how exactly improving global health would cause meat-eater problem, I feel like it's complicated, please share your opinions to the question.</p>", "user": {"username": "jackchang110"}}, {"_id": "AJJTRmW7zhvXrmD5s", "title": "Apply to CEEALAR to do AGI moratorium work", "postedAt": "2023-07-26T21:24:11.878Z", "htmlBody": "<p>Do you have short AI timelines and/or p(doom|AGI) that is far too high for comfort? Do you want to pivot to working on directly addressing the problem and lowering all of our p(doom)s by slowing down or pausing AGI development? Is lack of funding/runway holding you back?</p><p>This is an invitation for people to&nbsp;<a href=\"http://ceealar.org/booking\"><u>apply</u></a> to&nbsp;<a href=\"http://ceealar.org\"><u>CEEALAR</u></a> for a grant (of free accommodation, food and stipend) to work towards getting a global moratorium on AGI implemented. Such work may take the form of organising public campaigns, such as letter writing, petitions, protests, social media posts, ads etc, drafting of relevant policies or regulatory frameworks (e.g. how to implement caps on training runs), or meta work organising and fundraising for such activities.</p><p>We\u2019ve already had one grantee stay who\u2019s working in the space, and I (Founder and Executive Director) am very interested in the area, having recently (post-GPT-4) elevated it to a <a href=\"https://forum.effectivealtruism.org/posts/8YXFaM9yHbhiJTPqp/agi-rising-why-we-are-in-a-new-era-of-acute-risk-and\">top priority</a> of mine.</p><p>Active discussion spaces for those working in the area include the&nbsp;<a href=\"https://join.slack.com/t/agi-moratorium-hq/shared_invite/zt-1yvu9d7ye-Wj8pAh3ZEhce4W7JwviLMg\"><u>AGI Moratorium HQ Slack</u></a> and the&nbsp;<a href=\"https://discord.gg/PkjYFfNJ\"><u>PauseAI Discord</u></a>. Various projects are being organised within them.</p><p>Orgs already in the space that may have projects you can get involved with, include:&nbsp;<a href=\"http://pauseai.info\"><u>PauseAI</u></a>,&nbsp;<a href=\"http://campaignforaisafety.org\"><u>Campaign for AI Safety</u></a>,&nbsp;<a href=\"http://stop.ai\"><u>Stop AGI</u></a>,&nbsp;<a href=\"http://aipolicy.us\"><u>Centre for AI Policy</u></a>,&nbsp;<a href=\"http://stakeout.ai\"><u>Stakeout AI</u></a>,&nbsp;<a href=\"http://safe.ai\"><u>Centre for AI Safety</u></a>,&nbsp;<a href=\"http://futureoflife.org\"><u>Future of Life Institute</u></a>.</p><p>Given we (CEEALAR) are a (UK) charity, we have to be mindful of not being too overtly political, or ensuring that any political activity is furthering our&nbsp;<a href=\"https://ceealar.org/charitable-objects/\"><u>charitable objects</u></a><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefokfnwh7x449\"><sup><a href=\"#fnokfnwh7x449\">[1]</a></sup></span>. This means not being partisan by singling out individual political parties or politicians for criticism, or being needlessly provocative<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefhcdun2nxrc\"><sup><a href=\"#fnhcdun2nxrc\">[2]</a></sup></span>. Think public awareness raising, public education and encouragement of civic responsibility over the issue, similar to how many charities focused on climate campaigning operate (e.g. the&nbsp;<a href=\"https://www.theclimatecoalition.org/about-us\"><u>Climate Coalition</u></a>)<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref5v8jlq3n2ha\"><sup><a href=\"#fn5v8jlq3n2ha\">[3]</a></sup></span>.</p><p>I look forward to your applications and hope that we can hereby accelerate meaningful action toward a global moratorium on AGI<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefpm0ma8wce4c\"><sup><a href=\"#fnpm0ma8wce4c\">[4]</a></sup></span>.</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnokfnwh7x449\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefokfnwh7x449\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Following charitable object 3, \u201cTo advance such other purposes which are exclusively charitable according to the law in England and Wales\u201d, your work would need to fit in with the Charitable Purposes under UK law listed&nbsp;<a href=\"https://www.gov.uk/government/publications/charitable-purposes/charitable-purposes\"><u>here</u></a>. For practical purposes, preventing human extinction from AGI would come under \u201csaving of lives\u201d.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnhcdun2nxrc\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefhcdun2nxrc\">^</a></strong></sup></span><div class=\"footnote-content\"><p>For example, any protests being organised should require people to abide by this&nbsp;<a href=\"https://pauseai.info/protesters-code-of-conduct\"><u>code of conduct</u></a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn5v8jlq3n2ha\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref5v8jlq3n2ha\">^</a></strong></sup></span><div class=\"footnote-content\"><p>We reserve the right to withdraw funding to anyone who doesn\u2019t work within our charitable objects or who\u2019s work may risk damage to our reputation.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnpm0ma8wce4c\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefpm0ma8wce4c\">^</a></strong></sup></span><div class=\"footnote-content\"><p>We are also still very much accepting general applications for any EA-related work/career development.</p></div></li></ol>", "user": {"username": "Greg_Colbourn"}}, {"_id": "FoA78SC6RyeAEHwxD", "title": "A $10k retroactive grant for VaccinateCA", "postedAt": "2023-07-26T19:43:25.770Z", "htmlBody": "<p>I'm awarding a $10k retroactive grant to Karl Yang, for his role in starting VaccinateCA. In January 2021, the Covid vaccines were just starting to become available to the general public\u2026 in theory. In practice, there was a lot of confusion over how to get a dose. Demand for vaccines was overwhelming; information about them was scarce. Karl took a simple idea (\u201clocate where the Covid vaccines are, and publish it\u201d), and organized a volunteer effort that would go on to help millions of people get their shots.</p><h2><strong>Q&amp;A with Karl</strong></h2><p><i>Adapted from a 30 min interview between Karl and Austin.</i></p><p><strong>Q: What was Karl\u2019s role in starting VaccinateCA?</strong></p><p>A: Back in Jan 2021, I\u2019d heard that the vaccines were coming out. I was paying attention as my family had at-risk members, but nobody knew what was happening. Then, Patrick <a href=\"https://twitter.com/patio11/status/1349577791537250310\">tweeted out a project proposal</a>: create a public list of hospitals in California.</p><figure class=\"image image_resized\" style=\"width:58.69%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FoA78SC6RyeAEHwxD/lyfjqchzwhkzhbjyxesp\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FoA78SC6RyeAEHwxD/qf015pcjisuayjvtyksr 200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FoA78SC6RyeAEHwxD/xgiuizz706wv20eghu4z 400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FoA78SC6RyeAEHwxD/gifmpzi0isgsztqzxyhi 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FoA78SC6RyeAEHwxD/ybyhckcaphhbhdnqncln 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FoA78SC6RyeAEHwxD/vi3d4227clwmmvrj7ogb 1000w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FoA78SC6RyeAEHwxD/nxsso9vco6d46cpo8rzx 1200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FoA78SC6RyeAEHwxD/s89inz3gkv9npzxzn4nl 1400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FoA78SC6RyeAEHwxD/cyxw25ktmckqq2f7pre3 1600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FoA78SC6RyeAEHwxD/mqljkioilo6743no1xjh 1800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FoA78SC6RyeAEHwxD/jog3f7pn4dfp11aydkiu 2000w\"></figure><p>I read that and thought: \u201cthis seems like something I can do\u201d. And I was motivated to do something. Throughout the pandemic, I\u2019d been waiting for some way to help. There\u2019s always a vague \u201cthey\u201d implicit in \u201cthey should do something\u201d. But I was antsy. Why shouldn\u2019t it be an \u201cus\u201d?</p><p>Usually, work like this feels outside of my skillset or capabilities. For example, I\u2019d love to accelerate cancer research, but I have no relevant training. But Patrick packaged it in a way that I could act on. I can set up a spreadsheet, I can coordinate volunteers, I can populate a list of hospitals I can call. I can do this.</p><p>So I set up a Google doc, found some phone numbers, and planned to start calling them the next day. I also put out a <a href=\"https://twitter.com/chiefofstuffs/status/1349584512859074565\">call for help on Twitter</a>; seeing this, a bunch of people DM\u2019d me on Twitter.&nbsp;</p><figure class=\"image image_resized\" style=\"width:63.45%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FoA78SC6RyeAEHwxD/jsatawyqrlsen6hwkhza\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FoA78SC6RyeAEHwxD/l2l9nkecj0h04rf5aukg 200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FoA78SC6RyeAEHwxD/peufg8ahc6e7fbsayavs 400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FoA78SC6RyeAEHwxD/qzswhnwzo4ies9orenum 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FoA78SC6RyeAEHwxD/d96v5riymkcqxdptnqex 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FoA78SC6RyeAEHwxD/o9iuojjd37aak2yvzc5z 1000w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FoA78SC6RyeAEHwxD/ljl25uhiruirsorfq9vu 1200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FoA78SC6RyeAEHwxD/uselivy1hcft7i9byniy 1400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FoA78SC6RyeAEHwxD/wbr1af6f7hcs2fhjwpkw 1600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FoA78SC6RyeAEHwxD/tnarhmqysa84jqen6ytp 1800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FoA78SC6RyeAEHwxD/m5jzcq2fzjawgrekj5fv 2000w\"></figure><p>I started a Discord server, inspired by the \u201c<a href=\"https://www.wired.com/story/eye-mouth-eye/\">eye mouth eye</a>\u201d thing (where a bunch of GenZ kids meme\u2019d a fake startup into existence, and managed to get term sheets). Over Discord, I coordinated a campaign to call the next day. I was already working the night shift at the time, so I got up at 6am to start making phone calls.</p><p>Next, I set up a website to display what information we had. A bunch of volunteers quickly came in and made the website better; then other volunteers set up a backend on Airtable and got free credits from the Airtable team. By the next day, we had built a sophisticated volunteer dialer system. It would pull a phone number from the queue, and have a list of questions for the volunteer to ask.</p><p>We were calling hospitals in the beginning. That was the wrong hypothesis; they got mad at us for calling so often! By Day 2, we\u2019d figured out that pharmacies were the place that had stock. Starting from Days 3-6, we discovered overlooked pockets of vaccines, about to expire. Some at a fire station; others at a county vaccine booth. We were discovering vaccines that would not have been found by other people; moving shots forward, saving lives.</p><p><strong>Q: Did you raise any funding before starting this?</strong></p><p>A: We didn\u2019t stop to think about raising funding; our mindset was entirely \u201chey, we\u2019re going to do this\u201d. There was no obvious reasons why we would raise. We were just putting up a volunteer-run website, listing where there were vaccines.</p><p><strong>Q: How did leadership of VaccinateCA transition from Karl to Patrick?</strong></p><p>A: I had been \u201crunning\u201d it for the first few days, but mostly it was a community scramble. I just happened to have keys to a lot of things because I set them up.</p><p>A week in, Patrick proposed that the project needed a formal CEO, and I agreed. I thought Patrick was the right person, and handed what remaining cultural power of \u201cbeing first\u201d to him.</p><p><strong>Q: How much time did you spend on VaccinateCA?</strong></p><p>A: I was working on this for 12 hours a day during that first week\u2026 I slept very little. This ramped down as we brought in more people and had more structure. So maybe 200 hours in total in the first month; then my involvement tapered off quite a bit after, and I returned to my day job at the time.</p><h2><strong>The impact of VaccinateCA</strong></h2><p>VaccinateCA went on to help millions of Americans locate COVID vaccines near them, first through their website and then through partnerships with orgs like Google. Patrick chronicles the rest of the tale in <a href=\"https://worksinprogress.co/issue/the-story-of-vaccinateca\">The Story of VaccinateCA</a>. (It\u2019s long but good; regrantor Zvi Mowshowitz summarizes the <a href=\"https://thezvi.substack.com/p/key-mostly-outward-facing-facts-from\">Key Mostly Outward-Facing Facts</a>.) One excerpt that stands out is a back-of-the-envelope calculation of the impact of helping people find vaccines; for the $1.2 million in donations the project raised, VaccinateCA was responsible for the equivalent of saving hundreds of lives:</p><blockquote><p><i>What is the actual human impact of getting one vaccine searcher a useful result? Early in the vaccination effort, a reasonable approximation was that accelerating a dose by one day saves 0.0001 lives in expectation or, equivalently, that 10,000 dose-days saves a life. There are more formal efforts to quantify this&nbsp;</i><a href=\"https://www.nber.org/digest/202205/estimating-lives-saved-covid-vaccines\"><i>in the literature</i></a><i>, but that estimate, the sheer&nbsp;moral weight&nbsp;of it, compelled me to take drastic action once I saw our stats on&nbsp;Day 3&nbsp;and extrapolated.</i></p><p><i>One million dose-days? One hundred lives.</i></p><p><i>I believe our partnership with Google accelerated delivery of the vaccines by&nbsp;many millions&nbsp;of dose-days.</i></p><p><i>Every day matters. Every dose matters.</i></p></blockquote><p>On the <a href=\"https://forum.effectivealtruism.org/posts/NkPghabDd54nkG3kX/some-observations-from-an-ea-adjacent-charitable-effort\">Effective Altruism Forum</a>, Patrick reflects about the moral weight of numbers on a spreadsheet:</p><blockquote><p><i>I consider myself fairly well-educated and well-raised in a moral tradition that has spent a lot of brainsweat on questions like \"What is one's duty to society and to one's fellow man?\" In that moral tradition, presented with the narrow question of \"Given that one is in a position of authority and has a course of action available to save hundreds of lives, what is one's duty?\", the answer is so straightforward as to be uninteresting.</i></p><p><i>But nobody, not once in my life, drew out the implication regarding expected value math until you all did.</i></p><p><i>For this you have my eternal gratitude.</i></p><p><i>And, should circumstances ever find you or yours looking at an expected value calculation that rhymes with the above, know that you'd have my instant attention and (pending thinking through it, in the words of a well-known articulator of my moral tradition) you have my sword.</i></p></blockquote><h3>&nbsp;</h3><h3><strong>Process for awarding this grant</strong></h3><p>As Manifund is a relatively new funder, I\u2019d been thinking through examples of impactful work that we\u2019d like to highlight, and VaccinateCA came to mind. I initially reached out and made the offer to Patrick, upon hearing that he had donated $100k of his own money into the nonprofit. Patrick nominated Karl to receive this grant instead, and introduced us; Karl and I met for a video call in early July.</p><p>What\u2019s special about this grant to Karl is that it\u2019s retroactive \u2014 a payment for work already done. Typically, funders make grants <i>prospectively</i> to encourage new work in the future. I\u2019m excited about paying out this retroactive grant for a few reasons:</p><ul><li>I want to highlight VaccinateCA as an example of an extremely effective project, and tell others that Manifund is interested in funding projects like it. Elements of VaccinateCA that endear me to it, especially in contrast to typical EA projects:<ul><li>They moved very, very quickly</li><li>They operated an object level intervention, instead of doing research or education</li><li>They used technology that could scale up to serve millions</li><li>But were also happy to manually call up pharmacies, driven by what worked well</li></ul></li><li>Karl was counterfactually responsible for founding VaccinateCA, and dedicated hundreds of hours of his time and energy to the effort, yet received little to no compensation.</li><li>I\u2019d like to make retroactive grants more of a norm among charitable funders. It\u2019s much easier to judge \u201cwhat was successful\u201d compared to \u201cwhat will succeed\u201d, especially for <a href=\"https://medium.com/ethereum-optimism/retroactive-public-goods-funding-33c9b7d00f0c\">public goods</a>; a robust ecosystem of retroactive grants could allow for <a href=\"https://manifund.org/about\">impact certs</a> to thrive.</li></ul><p>I offered $10k as it felt large enough to meaningfully recognize the impact of VaccinateCA, while not taking up too much of my regrantor budget. I do think the total impact of this was much larger; possibly valued in the hundreds of millions of dollars to the US government, if you accept the <a href=\"https://www.notion.so/Moonshot-Manifold-Wiki-Notion-f1e58330b4504fcf9abb2eeef553efae?pvs=21\">statistical value of a life at $1-10m</a>. (It\u2019s unclear to me how large retroactive grants ought to to incentivize good work, and I\u2019d welcome further discussion on this point.) I've set the project to make room for up to $20k of total funding for this, in case others would like to donate as well.</p><h3><strong>Tidbits from my conversation with Karl</strong></h3><p><strong>Q: Are you familiar with the EA movement? If so, what are your thoughts?</strong></p><p>A: Yeah, I\u2019ve heard a lot about it. To use the lingo, I\u2019ve been \u201cLesswrong-adjacent for a while\u201d. Taken to extremes, EA can get you to do crazy things \u2014 as all philosophies do. But I really like the approach; mosquito nets make sense to me.</p><p>I\u2019d observe that a lot of money is out there, looking for productive uses. Probably the constraining factor is productive uses. Maybe you [Manifund] are solving this on a meta level by encouraging productive uses of capital? <i>Austin: we hope so!</i></p><p><strong>Q: What is Karl up to now?</strong></p><p>A: I left my last role at Rippling a few months ago, and am now working on my own startup.</p><p>It\u2019s still pretty early, and I\u2019m not yet settled on an idea, but I\u2019m thinking of things related to my work on global payrolls at Rippling. I expect more business will be done cross-border, and using instant payments. Today, putting in a wire is very stressful, and this will be true of more and more things.</p><p>My idea is to reduce payment errors: money disappearing when payments go to a false account, or an account that is some other random person\u2019s. This will hopefully reduce payments friction, making international business less scary. The goal is to decreases costs, make it easier to hire people, and cut down on fraud.</p><p><strong>Q: What conclusions do you want readers of this writeup to take away?</strong></p><p>A: That there are things that regular people can do. Especially things that people with tech skills can do, that can be enormously valuable. It took a lot of time, but our volunteers used the same stuff that they used in our day jobs to do meaningful work. And it could be done on the side; most volunteers did not stop their day jobs.</p><p>Setting up a website, ops work of coordinating volunteers, marketing; these are all normal, regular-people skills. The people who invented vaccines did amazing work, but there\u2019s lots of work regular people can do too. My time on VaccinateCA really enhanced my belief in what I could do in the world.<br>&nbsp;</p><p><i>Thanks to Lily J and Rachel W for feedback on this writeup.</i></p>", "user": {"username": "akrolsmir"}}, {"_id": "4KJx9brQEMNWDkxQa", "title": "What do donors need? A survey to help major donors give more and give better", "postedAt": "2023-07-26T18:09:16.914Z", "htmlBody": "<p>Do you know anyone who gives <strong>\u00a310,000+ per year</strong><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefj4jilqlora\"><sup><a href=\"#fnj4jilqlora\">[1]</a></sup></span>?</p><p>Do you know anyone who would like to give <strong>\u00a310,000+ per year </strong>and has the ability to, if only they didn\u2019t have so many <strong>uncertainties</strong>?</p><p>Is this you?</p><p>SoGive is conducting a <strong>survey</strong> of people who (have the capacity to) give \u00a310k+. We want to know:</p><ul><li>What are their uncertainties about giving?</li><li>What services would help them give more and give better?</li><li>How do they make giving decisions?</li></ul><p>We\u2019d love to have a call with anyone who fits this description. <strong>You can book something in Spencer's calendar </strong><a href=\"https://forms.gle/ekSdzic2ZCjzwUqR9\"><strong>here</strong></a><strong>.</strong> The survey is designed to be 60 minutes to get the most value from the call. If you're short on time, we can administer a 30-minute version of the survey instead.</p><h3>Why are we doing a survey?</h3><p>SoGive is a philanthropy advising and research organization. We support major donors in giving to the most effective charities according to their personal values. We want to help donors increase the impact of their donations - and you can help us determine how.</p><p>Your insights will be instrumental in helping us develop a program that A) will actually be of value to major donors, and B) isn\u2019t already covered off by other advisors in the space. Plus, we want to ensure we\u2019re the right ones to provide the type of support donors need.</p><h3>The value to the community</h3><p>SoGive values transparency. After data collection, we intend to post an anonymized analysis of the results of our survey. That way, we can all learn what gaps exist in the support for major donors, and we can collaborate as a community on filling those gaps so that donors can give more and give better.</p><h3>I don't need philanthropy advising. Should I take the survey?</h3><p>Even if you feel you don't currently need more support with your giving, it's helpful to know! Please still have a chat with us if you can. If we find that donors do not need more support, that will impact SoGive's strategy.</p><p>In the survey, we also ask about support donors need that does not come from philanthropy advisors. Does EA actually need more financial advisors, or more interactive online tools? We want to know!</p><h3>The more data, the better</h3><p>Please send this post to someone you know who gives, or could give, \u00a310,000+ per year. You can help us learn from a broad range of donor perspectives so that we can develop a more impactful offering. Your family's, friends', and coworkers' perspectives are valuable.</p><p>Thank you for your support and for your interest in effective giving!</p><h1><strong>If you're able to help us by taking our survey, you can book something in Spencer's calendar </strong><a href=\"https://forms.gle/ekSdzic2ZCjzwUqR9\"><strong>here</strong></a><strong>.</strong></h1><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnj4jilqlora\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefj4jilqlora\">^</a></strong></sup></span><div class=\"footnote-content\"><p>About $13,000 USD or $19,000 AUD</p></div></li></ol>", "user": {"username": "Spencer Ericson"}}, {"_id": "xNyd8SuTzsScXc7KB", "title": "Measuring impact \u2014 EA\u00a0bias towards numbers?", "postedAt": "2023-07-26T16:19:02.940Z", "htmlBody": "<p><strong>TLDR:</strong> Effective Altruism likes numbers, therefore there is bias towards projects that are easily quantifiable. What about big impactful ideas that make intuitive sense but are not that easy to put into a spreadsheet?</p><h3>Posted on the blog:</h3><p>&nbsp;<a href=\"https://mirror.xyz/0x315f80C7cAaCBE7Fb1c14E65A634db89A33A9637/G4Qt_Cr8vMUKGbkEjAZu7Fly9c-igAViP5VZ3mb0rjc\">https://mirror.xyz/0x315f80C7cAaCBE7Fb1c14E65A634db89A33A9637/G4Qt_Cr8vMUKGbkEjAZu7Fly9c-igAViP5VZ3mb0rjc</a><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\"><span class=\"mjx-mrow\" aria-hidden=\"true\"></span></span><style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}\n.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}\n.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}\n.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}\n.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}\n.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}\n.mjx-numerator {display: block; text-align: center}\n.mjx-denominator {display: block; text-align: center}\n.MJXc-stacked {height: 0; position: relative}\n.MJXc-stacked > * {position: absolute}\n.MJXc-bevelled > * {display: inline-block}\n.mjx-stack {display: inline-block}\n.mjx-op {display: block}\n.mjx-under {display: table-cell}\n.mjx-over {display: block}\n.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-stack > .mjx-sup {display: block}\n.mjx-stack > .mjx-sub {display: block}\n.mjx-prestack > .mjx-presup {display: block}\n.mjx-prestack > .mjx-presub {display: block}\n.mjx-delim-h > .mjx-char {display: inline-block}\n.mjx-surd {vertical-align: top}\n.mjx-surd + .mjx-box {display: inline-flex}\n.mjx-mphantom * {visibility: hidden}\n.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}\n.mjx-annotation-xml {line-height: normal}\n.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}\n.mjx-mtr {display: table-row}\n.mjx-mlabeledtr {display: table-row}\n.mjx-mtd {display: table-cell; text-align: center}\n.mjx-label {display: table-row}\n.mjx-box {display: inline-block}\n.mjx-block {display: block}\n.mjx-span {display: inline}\n.mjx-char {display: block; white-space: pre}\n.mjx-itable {display: inline-table; width: auto}\n.mjx-row {display: table-row}\n.mjx-cell {display: table-cell}\n.mjx-table {display: table; width: 100%}\n.mjx-line {display: block; height: 0}\n.mjx-strut {width: 0; padding-top: 1em}\n.mjx-vsize {width: 0}\n.MJXc-space1 {margin-left: .167em}\n.MJXc-space2 {margin-left: .222em}\n.MJXc-space3 {margin-left: .278em}\n.mjx-test.mjx-test-display {display: table!important}\n.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}\n.mjx-test.mjx-test-default {display: block!important; clear: both}\n.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}\n.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}\n.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}\n.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}\n.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}\n.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}\n.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}\n.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}\n.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}\n.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}\n.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}\n.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}\n.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}\n.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}\n.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}\n.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}\n.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}\n.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}\n.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}\n.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}\n.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}\n.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}\n.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}\n.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}\n.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}\n.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}\n.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}\n.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}\n.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}\n@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}\n@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}\n@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}\n@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}\n@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}\n@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}\n@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}\n@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}\n@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}\n@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}\n@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}\n@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}\n@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}\n@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}\n@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}\n@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}\n@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}\n@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}\n@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}\n@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}\n@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}\n@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}\n@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}\n@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}\n@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}\n@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}\n</style></span></span></span></p><p>Trying to evaluate impact of large scale infrastructure projects that have loads of 2nd and 3rd effects. Maybe there is already a dedicated working group specialising in that?</p><p>&nbsp;</p><p>Not a pipe dream. The Cape Town-Cairo railway in the making 100 years ago <i>(but then Great Depression, WW2, collapse of the British Empire)</i>.</p><p>Thinking about financing models. Thinking about resolving geopolitical instability <i>(something that has to be done anyway).</i> I genuinely believe that the project has loads of potential but not obvious how to put the numbers into a spreadsheet.</p><p>Some other impactful projects with loads of 2nd and 3rd effects, not easy to quantify:</p><ol><li>Onboarding 3 billion people not connected to the internet</li><li>Universal basic water</li><li>Slow internet / benefits of universal access</li><li>Chineese fishing boats</li><li>Chineese water management</li></ol><p>Once again link to the blog: <a href=\"https://mirror.xyz/0x315f80C7cAaCBE7Fb1c14E65A634db89A33A9637/G4Qt_Cr8vMUKGbkEjAZu7Fly9c-igAViP5VZ3mb0rjc\">https://mirror.xyz/0x315f80C7cAaCBE7Fb1c14E65A634db89A33A9637/G4Qt_Cr8vMUKGbkEjAZu7Fly9c-igAViP5VZ3mb0rjc</a></p><p>Greatly appreciating feedback / comments / ideas that bring positive value. Of course I know it will be difficult to achieve but I remain optimistic no matter what.</p>", "user": {"username": "Mars Robertson"}}, {"_id": "5WLGmCg7vSfXeqSWC", "title": "Launching the meta charity funding circle (MCF): Apply for funding or join as a donor!", "postedAt": "2023-07-26T15:33:35.160Z", "htmlBody": "<h1>Summary</h1><p>We are launching the&nbsp;<a href=\"https://www.metacharityfunders.com/\"><u>Meta Charity Funders</u></a>, a growing network of donors sharing knowledge and discussing funding opportunities in the EA meta space. Apply for funding by August 27th or join the circle as a donor. See below or visit our&nbsp;<a href=\"https://www.metacharityfunders.com/\"><u>website</u></a> to learn more!</p><hr><p>If you are doing EA-aligned \u201cmeta\u201d work, and have not received substantial funding for several years, you might be worried about funding. Over the past 10 years,&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/vqPy7TkBbzrAkxCf7/updates-to-the-flow-of-funding-in-ea-movement-building-post\"><u>Open Philanthropy and EA Funds</u></a> comprised a large percent of total meta funding and are far from independent of each other. This lack of diversity means potentially effective projects outside their priorities often struggle to stay afloat or scale, and the beliefs of just a few grant-makers can massively shape the EA movement\u2019s trajectory.&nbsp;</p><p>It can be difficult for funders within meta as well. Individual donors often don\u2019t know where to give if they don\u2019t share EA Funds\u2019 approach. Thorough vetting is scarce and expensive, with only a handful of grant-makers deploying tens of millions per year in meta grants, resulting in sub-optimal allocations.&nbsp;&nbsp;</p><p><strong>This is why we are launching the Meta Charity Funders, a growing network of donors sharing knowledge, discussing funding opportunities, and running joint open grant rounds in the EA meta space.&nbsp;</strong>We believe many charitable projects create a huge impact by working at one level removed from direct impact to instead enhance the impact of others. Often these projects cut across causes and don\u2019t fit neatly into a box, thus being neglected by funders. Well known examples of meta organizations include charity evaluators like GiveWell, incubators like Charity Entrepreneurship, cause prioritization research organizations like Rethink Priorities, or field-building projects promoting effective giving or impactful careers.</p><h1>Grantees: Apply to many HNW donors at once \u2013 1st round closes August 27.</h1><p><a href=\"https://www.metacharityfunders.com/\"><strong><u>Apply here</u></strong></a> by August 27th to be considered for our 1st funding round. We are aiming for applications to&nbsp;<strong>hear back on a decision from on or around the end of October</strong>, though we cannot guarantee every application an adequate review as we rely on volunteer investigations.&nbsp;<strong>Applying should take under 90 minutes, and you can largely paste an existing application.</strong> We plan to process applications and pay out funds twice per year, but you can apply through our website anytime and may hear from interested donors between our funding rounds.&nbsp;</p><p>We are open to funding meta work across a range of causes, organizational stages, strategies, etc. We are most interested in applications that have not already been substantially supported by similar actors such as EA Funds or Open Philanthropy, though we will still consider these.&nbsp;<strong>We expect most of our grants to range from $10,000 to $500,000</strong> and consider grants to both individuals and organizations. We expect our first round to be between $500,000 and $1.5m of total funding.&nbsp;</p><p>Please lean in favor of applying if you are unsure if you would be a good fit!</p><h1>Donors: Join us! Find neglected opportunities, get help with ops and vetting, and give on your own terms.</h1><p><a href=\"https://www.metacharityfunders.com/\"><strong><u>Apply here</u></strong></a><strong> anytime to become a member</strong> of our funding circle. Our group currently contains about a dozen (and growing) high-income donors, grant-makers, and philanthropic advisors each moving $100,000 or more per year to meta charities.&nbsp;<strong>Members meet virtually approximately once a month</strong> to discuss funding opportunities that have come through our open application form or that they have heard about.&nbsp;</p><p><strong>People who are unable to commit to regular meetings are still encouraged to apply</strong> and may be invited to our Slack and email list and gain access to our grant opportunities database.&nbsp;</p><hr><p>Meta Charity Funding Circle is a project of&nbsp;<a href=\"https://www.charityentrepreneurship.com/\">Charity Entrepreneurship</a> and&nbsp;<a href=\"https://www.impactfulgrantmaking.com/\">Impactful Grantmaking</a>. It is organized by this post\u2019s authors: Gage Weston, Vilhelm Skoglund, and Joey Savoie. Our members are anonymous.</p><p><br>&nbsp;</p>", "user": {"username": "Joey"}}, {"_id": "TCHNn4t9xL6pzSuZX", "title": "Frontier Model Forum", "postedAt": "2023-07-26T14:30:02.883Z", "htmlBody": "", "user": {"username": "zsp"}}, {"_id": "uE8HioePFD3tGyDRp", "title": "\u9769\u65b0\u7684\u306a\u601d\u3044\u3084\u308a", "postedAt": "2023-07-26T13:35:34.651Z", "htmlBody": "<p><i>This is a Japanese translation of \u201c</i><a href=\"https://forum.effectivealtruism.org/posts/ehZK259et52Xnvw5F/radical-empathy\"><i><strong>Radical Empathy</strong></i></a><i>\u201d</i></p><p>by&nbsp;<a href=\"https://forum.effectivealtruism.org/users/holdenkarnofsky\">Holden Karnofsky</a>&nbsp;2017\u5e74 2\u670816\u65e5&nbsp;</p><p>\u79c1\u305f\u3061\u306e\u6d3b\u52d5\u306e\u30c6\u30fc\u30de\u306e\u4e00\u3064\u306f\u3001\u591a\u304f\u306e\u4eba\u304b\u3089\u306f\u52a9\u3051\u308b\u4fa1\u5024\u304c\u306a\u3044\u3068\u601d\u308f\u308c\u3066\u3044\u308b\u96c6\u56e3\u3092\u52a9\u3051\u3088\u3046\u3068\u3059\u308b\u3053\u3068\u3067\u3059\u3002</p><p>\u79c1\u305f\u3061\u306f\u3053\u308c\u307e\u3067\u306b\u3001<a href=\"https://www.openphilanthropy.org/blog/initial-grants-support-corporate-cage-free-reforms\"><u>\u7267\u5834\u306b\u304a\u3051\u308b\u755c\u7523\u52d5\u7269\u306e\u30a2\u30cb\u30de\u30eb\u30a6\u30a7\u30eb\u30d5\u30a7\u30a2\u3092\u5411\u4e0a\u3055\u305b\u308b\u5927\u304d\u306a\u30c1\u30e3\u30f3\u30b9</u></a>\u3092\u898b\u51fa\u3057\u307e\u3057\u305f\u3002\u306a\u305c\u306a\u3089\u3001\u3053\u306e\u554f\u984c\u306b\u53d6\u308a\u7d44\u3082\u3046\u3068\u3057\u3066\u3044\u308b\u4eba\u304c\u3042\u307e\u308a\u306b\u3082\u5c11\u306a\u3044\u304b\u3089\u3067\u3059\u3002<a href=\"https://www.openphilanthropy.org/focus/us-policy/immigration-policy\"><u>\u79fb\u6c11\u5236\u5ea6\u6539\u9769</u></a>\u306b\u53d6\u308a\u7d44\u3093\u3060\u969b\u3001<a href=\"http://davidroodman.com/blog/2014/09/03/the-domestic-economic-impacts-of-immigration\"><u>\u3059\u3067\u306b\u7c73\u56fd\u306b\u4f4f\u3093\u3067\u3044\u308b\u4eba\u3005\u306e\u8cc3\u91d1</u></a>\u306b\u79fb\u6c11\u304c\u3069\u306e\u3088\u3046\u306a\u5f71\u97ff\u3092\u4e0e\u3048\u308b\u304b\u306b\u3064\u3044\u3066\u306f\u5927\u304d\u306a\u8b70\u8ad6\u304c\u4ea4\u308f\u3055\u308c\u3066\u3044\u307e\u3057\u305f\u304c\u3001\u305d\u306e\u6539\u9769\u304c\u79fb\u6c11\u306b\u3069\u306e\u3088\u3046\u306a\u5f71\u97ff\u3092\u4e0e\u3048\u308b\u304b\u306b\u3064\u3044\u3066\u306f\u307b\u3068\u3093\u3069\u8b70\u8ad6\u3055\u308c\u307e\u305b\u3093\u3067\u3057\u305f\u3002<a href=\"http://www.openphilanthropy.org/focus/global-health-and-development\"><u>\u30b0\u30ed\u30fc\u30d0\u30eb\u30d8\u30eb\u30b9\u3068\u958b\u767a</u></a>\u306b\u5bfe\u3059\u308b\u79c1\u305f\u3061\u306e\u95a2\u5fc3\u3082\u3001\u969b\u7acb\u3063\u305f\u3082\u306e\u3068\u8a00\u3048\u308b\u3067\u3057\u3087\u3046\u3002\u591a\u304f\u306e\u30a2\u30e1\u30ea\u30ab\u4eba\u306f\u3001\u5916\u56fd\u306e\u4eba\u3005\u3088\u308a\u3082\u81ea\u56fd\u306e\u4eba\u3005\u3092\u975e\u5e38\u306b\u5f37\u304f\u512a\u5148\u3059\u308b\u305f\u3081\u3001\u591a\u304f\u306f<a href=\"http://www.givewell.org/giving101/Your-dollar-goes-further-overseas\"><u>\u81ea\u5206\u9054\u306e\u304a\u91d1\u306f\u30a2\u30e1\u30ea\u30ab\u56fd\u5916\u3067\u4f7f\u3063\u305f\u65b9\u304c\u5927\u304d\u306a\u30a4\u30f3\u30d1\u30af\u30c8\u3092\u751f\u3080\u3053\u3068</u></a>\u306b\u8cdb\u6210\u306f\u3059\u308b\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u304c\u3001\u305d\u308c\u3067\u3082\u56fd\u5185\u3078\u306e\u5bc4\u4ed8\u3092\u597d\u307f\u307e\u3059<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref9oxf0z2ze1l\"><sup><a href=\"#fn9oxf0z2ze1l\">[1]</a></sup></span>\u3002</p><p>\u300c\u601d\u3044\u3084\u308a\u3084\u9053\u5fb3\u7684\u914d\u616e\u306b\u5024\u3059\u308b\u306e\u306f\u8ab0\u3067\u3042\u308b\u304b\u300d\u3068\u3044\u3046\u554f\u3044\u306f\u3001\u79c1\u305f\u3061\u306b\u3068\u3063\u3066\u304d\u308f\u3081\u3066\u91cd\u8981\u306a\u3082\u306e\u3067\u3059\u3002\u3053\u308c\u306f\u3001\u52b9\u679c\u7684\u306a\u5bc4\u4ed8\u3092\u884c\u3046\u305f\u3081\u306b\u6700\u3082\u91cd\u8981\u306a\u554f\u3044\u306e\u4e00\u3064\u3060\u3068\u601d\u3044\u307e\u3059\u3002</p><p>\u6b8b\u5ff5\u306a\u304c\u3089\u3001\u79c1\u305f\u3061\u306f\u3053\u306e\u554f\u984c\u306b\u95a2\u3057\u3066\u3001\u5f93\u6765\u306e\u5e38\u8b58\u3084\u76f4\u611f\u3092\u4fe1\u7528\u3059\u308b\u3053\u3068\u306f\u3067\u304d\u306a\u3044\u3067\u3057\u3087\u3046\u3002\u6b74\u53f2\u3092\u3055\u304b\u306e\u307c\u308c\u3070\u3001\u5f53\u6642\u306e\u5e38\u8b58\u306b\u306f\u304b\u306a\u3063\u3066\u3044\u305f\u3082\u306e\u306e\u4eca\u65e5\u3067\u306f\u5f01\u89e3\u306e\u4f59\u5730\u304c\u306a\u3044\u3088\u3046\u306a\u975e\u9053\u306a\u7406\u7531\u306b\u3088\u308a\u3001\u96c6\u56e3\u5168\u4f53\u304c\u8ffd\u3044\u3084\u3089\u308c\u3001\u8650\u5f85\u3055\u308c\u3001\u57fa\u672c\u7684\u4eba\u6a29\u3092\u596a\u308f\u308c\u305f\u4e8b\u4f8b\u304c\u3042\u307e\u308a\u306b\u3082\u591a\u304f\u5b58\u5728\u3057\u307e\u3059\u3002\u305d\u306e\u4ee3\u308f\u308a\u306b\u79c1\u305f\u3061\u304c\u76ee\u6307\u3059\u306e\u306f\u3001<strong>\u9769\u65b0\u7684\u306a\u601d\u3044\u3084\u308a\uff08Radical Empathy\uff09</strong>\u3067\u3059\u3002\u3064\u307e\u308a\u3001\u601d\u3044\u3084\u308a\u306e\u5bfe\u8c61\u3068\u306a\u308b\u3079\u304d\u3059\u3079\u3066\u306e\u5b58\u5728\u306b\u3001\u305f\u3068\u3048\u305d\u308c\u304c\u666e\u901a\u3067\u306f\u306a\u304f\u3001\u5947\u5999\u306b\u601d\u3048\u308b\u5834\u5408\u3067\u3082\u3001\u601d\u3044\u3084\u308a\u306e\u8f2a\u3092\u5e83\u3052\u308b\u3088\u3046\u52aa\u3081\u308b\u306e\u3067\u3059\u3002</p><p>\u3053\u3053\u3067\u9078\u3093\u3060\u7528\u8a9e\u306e\u610f\u5473\u3092\u660e\u78ba\u306b\u3057\u3066\u304a\u304d\u307e\u3059</p><ul><li>\u300c\u9769\u65b0\u7684\u306a\uff08Radical\uff09\u300d\u3068\u3044\u3046\u8868\u73fe\u306f\u3001\u300c\u4f1d\u7d71\u7684\u306a\u300d\u3084\u300c\u5f93\u6765\u306e\u300d\u3068\u3044\u3046\u8a00\u8449\u306e\u53cd\u5bfe\u8a9e\u3068\u3057\u3066\u610f\u56f3\u3055\u308c\u305f\u3082\u306e\u3067\u3059\u3002\u5fc5\u305a\u3057\u3082\u3001\u300c\u6975\u7aef\u306a\u300d\u300c\u5168\u3066\u3092\u542b\u3080\u300d\u3068\u3044\u3046\u3053\u3068\u3092\u610f\u5473\u3057\u3066\u3044\u308b\u308f\u3051\u3067\u306f\u3042\u308a\u307e\u305b\u3093\u3002\u5168\u3066\u306e\u5b58\u5728\u3084\u5168\u3066\u306e\u3082\u306e\u306b\u79c1\u305f\u3061\u306f\u601d\u3044\u3084\u308a\u3092\u793a\u3059\u308f\u3051\u3067\u306f\u3042\u308a\u307e\u305b\u3093\uff08\u305d\u3046\u3057\u3066\u3057\u307e\u3048\u3070\u3001\u9053\u5fb3\u306b\u3064\u3044\u3066\u5224\u65ad\u3059\u308b\u305f\u3081\u306e\u6839\u62e0\u304c\u672c\u8cea\u7684\u306b\u306a\u304f\u306a\u3063\u3066\u3057\u307e\u3044\u307e\u3059\uff09\u3002\u3053\u3053\u3067\u306f\u3001\u6163\u7fd2\u306b\u7e1b\u3089\u308c\u308b\u3053\u3068\u306a\u304f\u3001\u6700\u5584\u306e\u9078\u629e\u3092\u3059\u308b\u305f\u3081\u306b\u52aa\u529b\u3059\u308b\u3053\u3068\u3092\u6307\u3057\u3066\u3044\u307e\u3059\u3002</li><li>\u300c\u601d\u3044\u3084\u308a\uff08Empathy\uff09\u300d\u3068\u3044\u3046\u8868\u73fe\u306f\u3001\u305d\u306e\u4eba\u306e\u7acb\u5834\u306b\u7acb\u3063\u305f\u81ea\u5206\u3092\u60f3\u50cf\u3057\u3001\u305d\u306e\u4eba\u304c\u914d\u616e\u306b\u5024\u3059\u308b\u7d4c\u9a13\u3092\u3057\u3066\u3044\u308b\u3068\u8a8d\u8b58\u3059\u308b\u3001\u3068\u3044\u3046\u8003\u3048\u65b9\u3092\u6349\u3048\u308b\u3053\u3068\u3092\u610f\u56f3\u3057\u3066\u3044\u307e\u3059\u3002\u3057\u305f\u304c\u3063\u3066\u3001\u4ed6\u8005\u304c\u611f\u3058\u3066\u3044\u308b\u3053\u3068\u3092\u6587\u5b57\u901a\u308a\u306b\u611f\u3058\u308b\u3053\u3068\u3092\u6307\u3059\u308f\u3051\u3067\u306f\u306a\u304f\u3001\u300e<a href=\"https://smile.amazon.com/Against-Empathy-Case-Rational-Compassion-ebook/dp/B01CY2LCZI/\"><u>Against Empathy</u></a>\uff08\u90a6\u8a33\uff1a<a href=\"https://www.hakuyo-sha.co.jp/psychology/against-empathy/\"><u>\u53cd\u5171\u611f\u8ad6</u></a>&nbsp;\uff09\u300f\u3067\u6279\u5224\u3055\u308c\u3066\u3044\u308b\u300c\u5171\u611f\u300d\u3068\u306f\u7570\u306a\u308a\u307e\u3059\uff08\u3053\u306e\u672c\u306e\u4e2d\u3067\u306f\u3001 \u201cempathy\u201d \u3068\u3044\u3046\u7528\u8a9e\u306e\u8907\u6570\u306e\u610f\u5473\u3092\u8a8d\u3081\u305f\u4e0a\u3067\u3001\u660e\u78ba\u306b\u4e00\u3064\u306e\u610f\u5473\u306b\u7126\u70b9\u3092\u5f53\u3066\u3066\u3044\u307e\u3059\uff09\u3002</li></ul><h2>\u5e38\u8b58\u3084\u76f4\u611f\u3067\u306f\u4e0d\u5341\u5206</h2><p>\u300e<a href=\"https://smile.amazon.com/dp/B005646EGY/ref=dp-kindle-redirect?_encoding=UTF8&amp;btkr=1\"><u>The Expanding Circle</u></a>\uff08\u62e1\u5927\u3059\u308b\u8f2a\uff09\u300f\u306b\u304a\u3044\u3066\u30d4\u30fc\u30bf\u30fc\u30fb\u30b7\u30f3\u30ac\u30fc\u306f\u3001\u6b74\u53f2\u3092\u901a\u3058\u3066\u300c\u5229\u4ed6\u4e3b\u7fa9\u306e\u8f2a\u306f\u5bb6\u65cf\u3084\u90e8\u65cf\u304b\u3089\u56fd\u5bb6\u3084\u4eba\u7a2e\u3001\u305d\u3057\u3066\u3001\u5168\u4eba\u985e\u3078\u3068\u5e83\u304c\u3063\u3066\u3044\u3063\u305f\u300d\u3068\u8ad6\u3058\u3066\u3044\u307e\u3059\uff08\u305d\u3057\u3066\u3001\u300c\u3053\u306e\u30d7\u30ed\u30bb\u30b9\u306f\u3053\u3053\u3067\u6b62\u307e\u308b\u3079\u304d\u3067\u306a\u3044\u300d\u3068\u4ed8\u3051\u52a0\u3048\u3066\u3044\u307e\u3059\uff09<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefr8thf5cajmq\"><sup><a href=\"#fnr8thf5cajmq\">[2]</a></sup></span>\u3002\u4eca\u65e5\u306e\u57fa\u6e96\u304b\u3089\u3059\u308b\u3068\u3001\u5f7c\u304c\u8ff0\u3079\u3066\u3044\u308b\u521d\u671f\u306e\u4e8b\u4f8b\u306f\u5370\u8c61\u7684\u3067\u3059\u3002</p><blockquote><p>\u5f53\u521d\u306f\u3001\u8fd1\u96a3\u306e\u30ae\u30ea\u30b7\u30a2\u90fd\u5e02\u56fd\u5bb6\u306b\u304a\u3051\u308b\u5e02\u6c11\u306e\u9593\u3067\u3082\u3001\u5185\u90e8\u306e\u4eba\u9593\u3068\u5916\u90e8\u306e\u4eba\u9593\u3067\u306f\u3063\u304d\u308a\u3068\u533a\u5225\u3055\u308c\u3066\u3044\u305f\u3002\u3057\u305f\u304c\u3063\u3066\u3001\u7d00\u5143\u524d5\u4e16\u7d00\u4e2d\u9803\u306e\u5893\u77f3\u306b\u306f\u3001\u3053\u3046\u66f8\u304b\u308c\u3066\u3044\u308b\u3082\u306e\u304c\u3042\u308b\u3002&nbsp;</p><p>\u300c\u3053\u306e\u8a18\u5ff5\u7891\u306f\u3001\u975e\u5e38\u306b\u512a\u308c\u305f\u4eba\u7269\u306e\u907a\u4f53\u306e\u4e0a\u306b\u5efa\u3066\u3089\u308c\u3066\u3044\u308b\u3002\u30e1\u30ac\u30e9\u51fa\u8eab\u306e\u30d4\u30c6\u30a3\u30aa\u30f3\u306f\u30017\u4eba\u306e\u7537\u3092\u6bba\u3057\u3001\u305d\u3044\u3064\u3089\u306e\u8eab\u4f53\u306b7\u3064\u306b\u6298\u308a\u53d6\u3063\u305f\u69cd\u5148\u3092\u7a81\u304d\u523a\u3057\u305f... 3\u3064\u306e\u30a2\u30c6\u30cd\u9023\u968a\u3092\u6551\u3063\u305f\u3053\u306e\u7537\u306f\u3001\u5730\u4e0a\u306b\u4f4f\u3080\u3059\u3079\u3066\u306e\u4eba\u9593\u306e\u3046\u3061\u3001\u8ab0\u306b\u3082\u60b2\u3057\u307f\u3092\u4e0e\u3048\u308b\u3053\u3068\u306a\u304f\u3001\u7686\u306e\u76ee\u306e\u524d\u3067\u795d\u798f\u3055\u308c\u306a\u304c\u3089\u51a5\u754c\u306b\u4e0b\u308a\u3066\u884c\u3063\u305f\u3002\u300d</p><p>\u3053\u308c\u306f\u3001\u30a2\u30ea\u30b9\u30c8\u30d1\u30cd\u30b9\u304c\u30a2\u30c6\u30cd\u4eba\u306e\u6575\u3068\u306a\u308b\u30ae\u30ea\u30b7\u30a2\u4eba\u306e\u98e2\u9913\u3092\u6ed1\u7a3d\u306b\u6271\u3063\u3066\u3044\u305f\u3053\u3068\u3068\u5168\u304f\u4e00\u81f4\u3059\u308b\u3002\u305d\u3082\u305d\u3082\u3053\u306e\u98e2\u9913\u306f\u3001\u30a2\u30c6\u30cd\u4eba\u304c\u81ea\u3089\u3082\u305f\u3089\u3057\u305f\u8352\u5ec3\u306b\u7531\u6765\u3059\u308b\u3082\u306e\u3067\u3042\u3063\u305f\u3002\uff08\u8a33\u6ce8\uff1a\u30ae\u30ea\u30b7\u30a2\u90fd\u5e02\u306e\u4e00\u3064\u3067\u3042\u308b\u30a2\u30c6\u30cd\u304c\u4ed6\u306e\u30ae\u30ea\u30b7\u30a2\u90fd\u5e02\u3068\u6575\u5bfe\u3057\u3066\u3044\u305f\u3053\u3068\u3092\u63cf\u5199\u3057\u3066\u3044\u308b\u3002\uff09\u3057\u304b\u3057\u3001\u30d7\u30e9\u30c8\u30f3\u306b\u3088\u3063\u3066\u3053\u306e\u9053\u5fb3\u611f\u306f\u524d\u9032\u3092\u9042\u3052\u305f\u3002\u30d7\u30e9\u30c8\u30f3\u306f\u3001\u6226\u4e89\u306b\u304a\u3044\u3066\u30ae\u30ea\u30b7\u30a2\u4eba\u306f\u4ed6\u306e\u30ae\u30ea\u30b7\u30a2\u4eba\u3092\u5974\u96b7\u306b\u3057\u305f\u308a\u3001\u4ed6\u306e\u30ae\u30ea\u30b7\u30a2\u4eba\u306e\u571f\u5730\u3092\u8352\u3089\u3057\u305f\u308a\u3001\u5bb6\u3092\u58ca\u3057\u305f\u308a\u3059\u308b\u3079\u304d\u3067\u306f\u306a\u304f\u3001\u3053\u308c\u3089\u306e\u3053\u3068\u306f\u30ae\u30ea\u30b7\u30a2\u4eba\u3067\u306a\u3044\u4eba\u306b\u5bfe\u3057\u3066\u306e\u307f\u884c\u3046\u3079\u304d\u3060\u3068\u4e3b\u5f35\u3057\u305f\u3002\u3053\u306e\u3088\u3046\u306a\u4f8b\u306f\u307b\u307c\u7121\u9650\u306b\u3042\u308b\u3002\u53e4\u4ee3\u30a2\u30c3\u30b7\u30ea\u30a2\u306e\u738b\u305f\u3061\u306f\u3001\u30a2\u30c3\u30b7\u30ea\u30a2\u4eba\u3067\u306a\u3044\u6575\u3092\u3044\u304b\u306b\u82e6\u3057\u3081\u3001\u8c37\u3084\u5c71\u3092\u305d\u306e\u6b7b\u4f53\u3067\u57cb\u3081\u5c3d\u304f\u3057\u305f\u304b\u306b\u3064\u3044\u3066\u8a87\u3089\u3057\u3052\u306b\u77f3\u306b\u8a18\u9332\u3057\u3066\u3044\u308b\u3002\u30ed\u30fc\u30de\u4eba\u306f\u7570\u90a6\u4eba\u3092\u3001\u52d5\u7269\u306e\u3088\u3046\u306b\u6355\u3089\u3048\u3066\u5974\u96b7\u306b\u3057\u305f\u308a\u3001\u30b3\u30ed\u30c3\u30bb\u30aa\u3067\u6bba\u3057\u5408\u3044\u3092\u3055\u305b\u3066\u89b3\u8846\u3092\u697d\u3057\u307e\u305b\u305f\u308a\u3059\u308b\u5b58\u5728\u3068\u3057\u3066\u898b\u3066\u3044\u305f\u3002\u8fd1\u4ee3\u306b\u306a\u308a\u3001\u30e8\u30fc\u30ed\u30c3\u30d1\u4eba\u540c\u58eb\u3067\u306f\u3053\u306e\u3088\u3046\u306a\u6271\u3044\u3092\u3057\u306a\u304f\u306a\u3063\u305f\u304c\u3001200\u5e74\u8db3\u3089\u305a\u524d\u306b\u306f\u3001\u30a2\u30d5\u30ea\u30ab\u4eba\u3092\u502b\u7406\u306e\u67a0\u304b\u3089\u5916\u308c\u305f\u5b58\u5728\u3068\u3057\u3066\u307f\u306a\u3057\u3001\u6355\u7372\u3057\u3066\u6709\u7528\u306a\u4ed5\u4e8b\u306b\u4f7f\u3046\u3079\u304d\u8cc7\u6e90\u3068\u307f\u306a\u3059\u4eba\u304c\u3044\u305f\u3002\u540c\u69d8\u306b\u3001\u30a4\u30ae\u30ea\u30b9\u304b\u3089\u306e\u521d\u671f\u306e\u539f\u4f4f\u6c11\u306b\u3068\u3063\u3066\u306f\u3001\u30aa\u30fc\u30b9\u30c8\u30e9\u30ea\u30a2\u306e\u539f\u4f4f\u6c11\u3082\u5384\u4ecb\u306a\u5b58\u5728\u3067\u3042\u308a\u3001\u9762\u5012\u304c\u3042\u308b\u5ea6\u306b\u6355\u7372\u3055\u308c\u3001\u8650\u6bba\u3055\u308c\u305f\u3002<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefp9r0vmc99m\"><sup><a href=\"#fnp9r0vmc99m\">[3]</a></sup></span></p></blockquote><p>\u3053\u306e\u5f15\u7528\u306e\u7d42\u308f\u308a\u3067\u306f\u3001\u3088\u308a\u6700\u8fd1\u306e\u3001\u8eab\u8fd1\u306a\u9053\u5fb3\u306e\u5931\u6557\u3078\u3068\u8a71\u304c\u79fb\u884c\u3057\u3066\u3044\u307e\u3059\u3002\u3053\u3053\u6570\u4e16\u7d00\u306e\u9593\u3001\u5974\u96b7\u5236\u5ea6\u3092\u542b\u3081\u305f\u6975\u7aef\u306a\u4eba\u7a2e\u5dee\u5225\u3084\u6027\u5dee\u5225\u3001\u305d\u306e\u4ed6\u306e\u504f\u898b\u304c\u3042\u304b\u3089\u3055\u307e\u306b\u3001\u8b1d\u7f6a\u3082\u306a\u304f\u884c\u308f\u308c\u3001\u3057\u3070\u3057\u3070\u793e\u4f1a\u7684\u306b\u6700\u3082\u5c0a\u656c\u3055\u308c\u3066\u3044\u308b\u4eba\u3005\u306b\u3088\u3063\u3066\u5e83\u304f\u53d7\u3051\u5165\u308c\u3089\u308c\u3066\u304d\u307e\u3057\u305f\u3002</p><p>\u4eca\u65e5\u306e\u8996\u70b9\u304b\u3089\u898b\u308b\u3068\u3001\u3053\u308c\u3089\u306f\u975e\u5e38\u306b\u6065\u305a\u3079\u304d\u884c\u70ba\u3067\u3042\u308a\u3001\u521d\u671f\u306e\u5974\u96b7\u5236\u5ea6\u5ec3\u6b62\u8ad6\u8005\u3084\u521d\u671f\u306e\u30d5\u30a7\u30df\u30cb\u30b9\u30c8\u306a\u3069\u3001\u3044\u3061\u65e9\u304f\u3053\u308c\u3089\u3092\u5426\u5b9a\u3057\u305f\u4eba\u3005\u306f\u3001\u4e26\u5916\u308c\u305f\u5584\u884c\u3092\u884c\u3063\u305f\u3088\u3046\u306b\u601d\u308f\u308c\u307e\u3059\u3002\u3057\u304b\u3057\u3053\u306e\u5f53\u6642\u306b\u5e38\u8b58\u3084\u76f4\u611f\u3092\u983c\u308a\u306b\u3057\u3066\u3082\u3001\u3053\u308c\u3089\u306e\u4e0d\u9053\u5fb3\u306a\u884c\u52d5\u3092\u907f\u3051\u3001\u6709\u76ca\u306a\u884c\u52d5\u3092\u898b\u3064\u3051\u308b\u3053\u3068\u306b\u306f\u5fc5\u305a\u3057\u3082\u7e4b\u304c\u3089\u306a\u304b\u3063\u305f\u3067\u3057\u3087\u3046\u3002</p><p>\u4eca\u65e5\u306e\u898f\u7bc4\u306f\u3044\u304f\u3064\u304b\u306e\u70b9\u3067\u512a\u308c\u3066\u3044\u308b\u3088\u3046\u306b\u601d\u308f\u308c\u307e\u3059\u3002\u4f8b\u3048\u3070\u3001\u4eba\u7a2e\u5dee\u5225\u304c\u660e\u78ba\u306b\u64c1\u8b77\u3055\u308c\u308b\u3053\u3068\u306f\u5c11\u306a\u304f\u306a\u308a\u307e\u3057\u305f\uff08\u5b9f\u8df5\u3055\u308c\u308b\u3053\u3068\u304c\u5c11\u306a\u3044\u3068\u3044\u3046\u308f\u3051\u3067\u306f\u3042\u308a\u307e\u305b\u3093\u304c\uff09\u3002\u3057\u304b\u3057\u3001\u601d\u3044\u3084\u308a\u3068\u9053\u5fb3\u7684\u914d\u616e\u306b\u5024\u3059\u308b\u306e\u306f\u8ab0\u3067\u3042\u308b\u304b\u3001\u3068\u3044\u3046\u554f\u984c\u306b\u95a2\u3057\u3066\u306f\u3001\u4eca\u65e5\u306e\u898f\u7bc4\u306f\u307e\u3060\u6839\u672c\u7684\u306b\u4e0d\u5341\u5206\u3067\u3042\u308b\u601d\u3044\u307e\u3059\u3002\u305d\u306e\u4e00\u3064\u306e\u5146\u3057\u3068\u306a\u308b\u306e\u304c\u3001\u30a2\u30e1\u30ea\u30ab\u306b\u304a\u3051\u308b\u79fb\u6c11\u3092\u3081\u3050\u308b\u8a00\u8aac\u3067\u3059\u3002\u3053\u306e\u8a00\u8aac\u3067\u306f\u3001\u660e\u78ba\u306a\u4eba\u7a2e\u7684\u504f\u898b\u3092\u907f\u3051\u308b\u50be\u5411\u306b\u306f\u3042\u308a\u307e\u3059\u304c\u3001\u3057\u3070\u3057\u3070\u30ca\u30b7\u30e7\u30ca\u30ea\u30ba\u30e0\u3092\u53d7\u3051\u5165\u308c\u3001\u30a2\u30e1\u30ea\u30ab\u56fd\u6c11\u3067\u306a\u3044\u4eba\u3005\uff08\u3055\u3089\u306b\u306f\u3001\u30a2\u30e1\u30ea\u30ab\u306b\u3044\u306a\u3044\u3051\u308c\u3069\u3082\u30a2\u30e1\u30ea\u30ab\u306b\u3044\u305f\u3044\u4eba\u3005\uff09\u306e\u6a29\u5229\u3084\u95a2\u5fc3\u3092\u6392\u9664\u3057\u3001\u8efd\u8996\u3057\u3066\u3044\u307e\u3059\u3002</p><h2>\u77e5\u6027 vs. \u611f\u60c5</h2><p>\u9053\u5fb3\u7684\u306b\u6b8b\u8650\u306a\u884c\u70ba\u306f\u3001\u9053\u5fb3\u3092\u62bd\u8c61\u7684\u306b\u8003\u3048\u3001\u601d\u3044\u3084\u308a\u306b\u5fc5\u8981\u306a\u611f\u60c5\u306e\u57fa\u790e\u3092\u898b\u5931\u3044\u3001\u81ea\u5206\u306e\u884c\u52d5\u304c\u5f71\u97ff\u3059\u308b\u4eba\u3005\u304b\u3089\u8ddd\u96e2\u3092\u304a\u304f\u3053\u3068\u304b\u3089\u751f\u3058\u304c\u3061\u3060\u3068\u3044\u3046\u610f\u898b\u3092\u6642\u3005\u8033\u306b\u3057\u307e\u3059\u3002</p><p>\u3053\u308c\u306f\u3042\u308b\u5834\u5408\u306b\u306f\u6b63\u3057\u3044\u3067\u3059\u304c\u3001\u305f\u3044\u3066\u3044\u91cd\u8981\u306a\u8aa4\u308a\u3067\u3042\u308b\u3068\u79c1\u306f\u601d\u3044\u307e\u3059\u3002</p><p>\u5e73\u548c\u306a\u751f\u6d3b\u3092\u9001\u3063\u3066\u3044\u308b\u4eba\u306f\u3001\u3057\u3070\u3057\u3070\u66b4\u529b\u306b\u5bfe\u3057\u3066\u81c6\u75c5\u306b\u306a\u308a\u307e\u3059\u304c\u3001\u3053\u306e\u81c6\u75c5\u3055\u306f\u7d4c\u9a13\u3092\u7a4d\u3080\u3053\u3068\u3067\u9a5a\u304f\u307b\u3069\u65e9\u304f\u514b\u670d\u3067\u304d\u308b\u3088\u3046\u3067\u3059\u3002\u6b74\u53f2\u4e0a\u3001\u5927\u52e2\u306e\u300c\u4e00\u822c\u7684\u306a\u300d\u4eba\u3005\u304c\u3001\u81ea\u5206\u305f\u3061\u304c\u305d\u306e\u6a29\u5229\u3092\u8a8d\u3081\u3066\u3044\u306a\u3044\u4eba\u30fb\u52d5\u7269\u306b\u5bfe\u3057\u3066\u4f55\u6c17\u306a\u304f\u3001\u3055\u3089\u306b\u306f\u5b09\u3005\u3068\u3057\u3066\u76f4\u63a5\u7684\u306a\u6b8b\u8650\u884c\u70ba\u3084\u66b4\u529b\u3092\u884c\u3063\u305f\u4f8b\u306f\u3044\u304f\u3089\u3067\u3082\u3042\u308a\u307e\u3059\u3002<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefjweevak8z1\"><sup><a href=\"#fnjweevak8z1\">[4]</a></sup></span>\u4eca\u65e5\u3001 \u7267\u5834\u3067\u50cd\u304f\u4eba\u3005\u304c\u52d5\u7269\u3092\u4f55\u6c17\u306a\u304f\u6271\u3063\u3066\u3044\u308b\u306e\u3092\u898b\u308b\u3068\uff08\u3053\u306e<a href=\"https://www.youtube.com/watch?v=mYwhSX3ltJg\"><u>\u6050\u308d\u3057\u3044\u30d3\u30c7\u30aa</u></a>\u306b\u898b\u3089\u308c\u308b\u3088\u3046\u306b\uff09\u3001<a href=\"http://michaelpollan.com/articles-archive/an-animals-place/\"><u>\u3082\u3057\u81ea\u5206\u81ea\u8eab\u3067\u52d5\u7269\u3092\u6bba\u3055\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u304f\u306a\u3063\u305f\u3068\u3057\u305f\u3089\u3001\u4eba\u3005\u306f\u8089\u3092\u98df\u3079\u308b\u91cf\u3092\u5927\u5e45\u306b\u6e1b\u3089\u3059\u3060\u308d\u3046</u></a>\u3068\u3044\u3046\u8003\u3048\u306b\u306f\u5927\u304d\u306a\u7591\u554f\u7b26\u304c\u3064\u304d\u307e\u3059\u3002\u79c1\u306f\u3001\u4eba\u3005\u304c\u81ea\u5206\u81ea\u8eab\u306e\u884c\u52d5\u306e\u7d50\u679c\u3092\u898b\u3066\u611f\u3058\u308b\u304b\u3069\u3046\u304b\u304c\u5927\u5207\u306a\u306e\u3067\u306f\u306a\u3044\u3068\u601d\u3044\u307e\u3059\u3002\u305d\u308c\u3088\u308a\u3082\u5927\u5207\u306a\u306e\u306f\u3001\u81ea\u5206\u81ea\u8eab\u306e\u884c\u52d5\u304c\u5f71\u97ff\u3092\u53ca\u307c\u3059\u76f8\u624b\u3092\u9053\u5fb3\u7684\u914d\u616e\u306b\u5024\u3059\u308b\u540c\u80de\u3068\u3057\u3066\u8a8d\u8b58\u3067\u304d\u308b\u304b\u3069\u3046\u304b\u3067\u3059\u3002</p><p>\u305d\u306e\u4e00\u65b9\u3067\u3001\u8ad6\u7406\u7684\u306a\u63a8\u8ad6\u3092\u99c6\u4f7f\u3057\u3066\u9053\u5fb3\u7684\u306a\u7d50\u8ad6\u3092\u5c0e\u304d\u51fa\u3057\u3001\u5f8c\u304b\u3089\u632f\u308a\u8fd4\u308b\u3068\u9a5a\u304f\u307b\u3069\u5148\u898b\u306e\u660e\u304c\u3042\u3063\u305f\u3068\u3044\u3046\u524d\u4f8b\u3082\u5c11\u306a\u304f\u3068\u3082\u3042\u308a\u307e\u3059\u3002\u4f8b\u3048\u3070\u3001<a href=\"https://ja.wikipedia.org/wiki/%E3%82%B8%E3%82%A7%E3%83%AC%E3%83%9F%E3%83%BB%E3%83%99%E3%83%B3%E3%82%B5%E3%83%A0\"><u>\u30b8\u30a7\u30ec\u30df\u30fb\u30d9\u30f3\u30b5\u30e0</u></a>\u306e\u30a6\u30a3\u30ad\u30da\u30c7\u30a3\u30a2\u3092\u898b\u3066\u307f\u307e\u3057\u3087\u3046\u3002\u5f7c\u306f\u529f\u5229\u4e3b\u7fa9\u3068\u3044\u3046\u5206\u304b\u308a\u3084\u3059\u304f\u5b9a\u91cf\u7684\u306a\u8ad6\u7406\u306b\u57fa\u3065\u3044\u305f\u9053\u5fb3\u3092\u5531\u3048\u305f\u3053\u3068\u3067\u77e5\u3089\u308c\u3066\u3044\u307e\u3059\u3002</p><p>\u30d9\u30f3\u30b5\u30e0\u306f\u3001\u500b\u4eba\u3068\u7d4c\u6e08\u306e\u81ea\u7531\u3001\u653f\u6559\u5206\u96e2\u3001\u8868\u73fe\u306e\u81ea\u7531\u3001\u5973\u6027\u306e\u5e73\u7b49\u306a\u6a29\u5229\u3001\u96e2\u5a5a\u306e\u6a29\u5229\u3001\u540c\u6027\u611b\u884c\u70ba\u306e\u975e\u72af\u7f6a\u5316\u306a\u3069\u3092\u63d0\u5531\u3057\u307e\u3057\u305f\u3002\uff08\u6ce8\uff1a\u30d9\u30f3\u30b5\u30e0\u304c\u751f\u304d\u3066\u3044\u305f\u306e\u306f1747\u5e74\u304b\u30891832\u5e74\u307e\u3067\u3067\u3042\u308a\u3001\u3053\u308c\u3089\u306e\u8003\u3048\u65b9\u304c\u4e00\u822c\u7684\u306b\u306a\u308b\u305a\u3063\u3068\u524d\u3067\u3042\u308b\u3002\uff09\u5f7c\u306f\u3001\u5974\u96b7\u5236\u306e\u5ec3\u6b62\u3001\u6b7b\u5211\u5236\u5ea6\u306e\u5ec3\u6b62\u3001\u5b50\u3069\u3082\u3092\u542b\u3080\u4f53\u7f70\u306e\u5ec3\u6b62\u3092\u8a34\u3048\u307e\u3057\u305f\u3002\u307e\u305f\u3001\u52d5\u7269\u306e\u6a29\u5229\u3092\u65e9\u304f\u304b\u3089\u63d0\u5531\u3057\u3066\u3044\u305f\u3053\u3068\u3067\u3082\u6700\u8fd1\u306f\u77e5\u3089\u308c\u3066\u3044\u307e\u3059\u3002</p><h2>\u9769\u65b0\u7684\u306a\u601d\u3044\u3084\u308a\u3092\u76ee\u6307\u3057\u3066</h2><p>\u601d\u3044\u3084\u308a\u3084\u9053\u5fb3\u7684\u914d\u616e\u306b\u5024\u3059\u308b\u306e\u306f\u8ab0\u3067\u3057\u3087\u3046\u304b\uff1f</p><p>\u3053\u306e\u554f\u3044\u3092\u8aa4\u308b\u9650\u308a\u3001\u79c1\u305f\u3061\u306f\u6b8b\u8650\u975e\u9053\u306a\u9078\u629e\u3092\u3057\u3066\u3057\u307e\u3046\u5371\u967a\u6027\u304c\u3042\u308a\u307e\u3059\u3002\u9006\u306b\u3001\u3082\u3057\u3053\u306e\u554f\u3044\u3092\u4e26\u5916\u308c\u305f\u30ec\u30d9\u30eb\u3067\u7406\u89e3\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308c\u3070\u3001\u79c1\u305f\u3061\u306f\u6841\u5916\u308c\u306e\u5584\u3092\u884c\u3046\u3053\u3068\u304c\u3067\u304d\u308b\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u3002</p><p>\u6b8b\u5ff5\u306a\u304c\u3089\u3001\u3053\u306e\u554f\u3044\u3092\u6b63\u3057\u304f\u7406\u89e3\u3059\u308b\u3053\u3068\u306f\u5fc5\u305a\u3057\u3082\u7c21\u5358\u306a\u3053\u3068\u3067\u306f\u306a\u3044\u3068\u8003\u3048\u3066\u304a\u308a\u3001\u305d\u308c\u3069\u3053\u308d\u304b\u79c1\u305f\u3061\u304c\u73fe\u5728\u3001\u6b63\u3057\u304f\u7406\u89e3\u3057\u3066\u3044\u308b\u3068\u3044\u3046\u81ea\u4fe1\u306f\u5168\u304f\u3042\u308a\u307e\u305b\u3093\u3002\u305d\u308c\u3067\u3082\u3001\u6700\u5584\u306e\u52aa\u529b\u3092\u3059\u308b\u4e0a\u3067\u5b88\u308d\u3046\u3068\u3057\u3066\u3044\u308b\u539f\u5247\u304c\u3044\u304f\u3064\u304b\u3042\u308a\u307e\u3059\u3002</p><p><strong>\u4e0d\u78ba\u5b9f\u6027\u3092\u8a8d\u8b58\u3059\u308b\u3053\u3068</strong>\u3002\u4f8b\u3048\u3070\u79c1\u305f\u3061\u306f\u3001\u52d5\u7269\u304c\u79c1\u305f\u3061\u306e\u9053\u5fb3\u306e\u67a0\u7d44\u307f\u306e\u4e2d\u3067\u3069\u306e\u3088\u3046\u306b\u4f4d\u7f6e\u3065\u3051\u3089\u308c\u308b\u3079\u304d\u304b\u306b\u3064\u3044\u3066\u3088\u304f\u308f\u304b\u3063\u3066\u3044\u307e\u305b\u3093\u3002<a href=\"https://ja.wikipedia.org/wiki/%E5%BF%83%E3%81%AE%E5%93%B2%E5%AD%A6\"><u>\u5fc3\u306e\u54f2\u5b66</u></a>\u306b\u95a2\u3059\u308b\u79c1\u81ea\u8eab\u306e\u8003\u5bdf\u3084\u63a8\u8ad6\u3067\u306f\u3001\u3053\u308c\u307e\u3067\u306e\u3068\u3053\u308d\u3001\u4f8b\u3048\u3070\u30cb\u30ef\u30c8\u30ea\u304c\u9053\u5fb3\u7684\u914d\u616e\u306b\u5024\u3059\u308b\u3068\u3044\u3046\u8003\u3048\u65b9\u306b\u306f\u53cd\u5bfe\u3059\u308b\u7d50\u8ad6\u3092\u793a\u5506\u3057\u3066\u3044\u308b\u3088\u3046\u306b\u601d\u308f\u308c\u307e\u3059\u3002\u305d\u3057\u3066\u3001\u79c1\u306e\u76f4\u611f\u3082\u3001\u4eba\u9593\u3092\u6841\u5916\u308c\u306b\u9ad8\u304f\u8a55\u4fa1\u3057\u3066\u3044\u307e\u3059\u3002\u3057\u304b\u3057\u3001\u591a\u304f\u306e\u8061\u660e\u306a\u4eba\u3005\u304c\u3053\u306e\u8003\u3048\u65b9\u306b\u53cd\u5bfe\u3057\u3066\u3044\u308b\u3053\u3068\u3092\u9451\u307f\u308b\u3068\u3001\u79c1\u306e\u8003\u5bdf\u3084\u76f4\u611f\u306f\u81ea\u4fe1\u3092\u6301\u3063\u3066\u4fe1\u983c\u3067\u304d\u308b\u3082\u306e\u3068\u306f\u601d\u3048\u307e\u305b\u3093\u3002\u307e\u305f\u3001\u3082\u3057\u30cb\u30ef\u30c8\u30ea\u304c\u672c\u5f53\u306b\u9053\u5fb3\u7684\u914d\u616e\u306b\u5024\u3059\u308b\u306e\u3067\u3042\u308c\u3070\u3001\u305d\u306e\u8650\u5f85\u306e\u91cf\u3068\u7a0b\u5ea6\u306f\u9a5a\u7570\u7684\u3067\u3059\u3002<a href=\"https://www.openphilanthropy.org/blog/worldview-diversification\"><u>\u4e16\u754c\u89b3\u306e\u591a\u69d8\u5316</u></a>\u3068\u3044\u3046\u89b3\u70b9\u304b\u3089\u3082\u3001<a href=\"https://www.openphilanthropy.org/blog/initial-grants-support-corporate-cage-free-reforms\"><u>\u30cb\u30ef\u30c8\u30ea\u306e\u798f\u7949\u3092\u5927\u304d\u304f\u5411\u4e0a\u3055\u305b\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u304b\u3082\u3057\u308c\u306a\u3044\u30c1\u30e3\u30f3\u30b9</u></a>\u3092\u9003\u3057\u305f\u304f\u306f\u3042\u308a\u307e\u305b\u3093\u3002</p><p>\u3053\u306e\u70b9\u306b\u95a2\u3059\u308b\u4e0d\u78ba\u5b9f\u6027\u306f\u3001<a href=\"https://www.openphilanthropy.org/focus/us-policy/farm-animal-welfare\"><u>\u755c\u7523\u52d5\u7269\u306e\u30a2\u30cb\u30de\u30eb\u30a6\u30a7\u30eb\u30d5\u30a7\u30a2</u></a>\u306b\u5927\u304d\u306a\u30ea\u30bd\u30fc\u30b9\u3092\u6295\u5165\u3057\u3001\u4eba\u9593\u3060\u3051\u304c\u9053\u5fb3\u7684\u306b\u91cd\u8981\u3067\u3042\u308b\u3053\u3068\u3092\u6697\u793a\u3059\u308b\u3088\u3046\u306a\u8a00\u8449\u3092\u4e00\u822c\u7684\u306b\u907f\u3051\u308b\u52aa\u529b\u3092\u3059\u308b\u5341\u5206\u306a\u7406\u7531\u306b\u306a\u308b\u3068\u79c1\u306f\u601d\u3044\u307e\u3059<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref9m6tzurlwhr\"><sup><a href=\"#fn9m6tzurlwhr\">[5]</a></sup></span>\u3002</p><p>\u3068\u306f\u3044\u3048\u3001\u5168\u3066\u306e\u666e\u901a\u3067\u306a\u3044\u9078\u629e\u306b\u4e0d\u78ba\u5b9f\u6027\u3092\u611f\u3058\u3066\u3044\u308b\u308f\u3051\u3067\u306f\u3042\u308a\u307e\u305b\u3093\u3002\u5730\u7406\u7684\u306a\u9055\u3044\u3001\u56fd\u7c4d\u306e\u9055\u3044\u3001\u4eba\u7a2e\u306e\u9055\u3044\u306f\u3001\u9053\u5fb3\u7684\u914d\u616e\u306b\u5f71\u97ff\u3092\u53ca\u307c\u3059\u3079\u304d\u3067\u306f\u306a\u3044\u3068\u78ba\u4fe1\u3057\u3066\u304a\u308a\u3001\u79c1\u305f\u3061\u306e\u5bc4\u4ed8\u306f\u3053\u306e\u3053\u3068\u3092\u53cd\u6620\u3057\u305f\u3082\u306e\u3067\u306a\u3051\u308c\u3070\u306a\u308a\u307e\u305b\u3093\u3002</p><p><strong>\u3053\u306e\u30c8\u30d4\u30c3\u30af\u3067\u306f\u300c\u5909\u306a\u300d\u8b70\u8ad6\u3092\u3059\u3050\u306b\u5426\u5b9a\u3057\u3066\u3057\u307e\u3046\u3053\u3068\u306b\u7d30\u5fc3\u306e\u6ce8\u610f\u3092\u6255\u3046</strong>\u3002\u6bd4\u8f03\u7684\u5c11\u6570\u3067\u306f\u3042\u308a\u307e\u3059\u304c\u3001<a href=\"http://reducing-suffering.org/do-bugs-feel-pain/\"><u>\u6606\u866b</u></a>\u3084\u3001<a href=\"http://petrl.org/\"><u>\u4eca\u65e5\u306e\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u30fc\u3067\u5b9f\u884c\u3055\u308c\u308b\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306e\u4e00\u90e8</u></a>\u3067\u3055\u3048\u9053\u5fb3\u7684\u914d\u616e\u306b\u5024\u3059\u308b\u3068\u4e3b\u5f35\u3059\u308b\u4eba\u304c\u3044\u307e\u3059\u3002\u3053\u306e\u3088\u3046\u306a\u8996\u70b9\u306f\u3001\u8868\u9762\u7684\u306b\u306f\u3068\u3066\u3082\u5947\u5999\u306b\u898b\u3048\u3001\u304b\u306a\u308a\u6025\u9032\u7684\u306a\u610f\u5473\u5408\u3044\u3092\u6301\u3064\u306e\u3067\u3001\u7c21\u5358\u306b\u305d\u3057\u3066\u76f4\u611f\u7684\u306b\u7b11\u3044\u98db\u3070\u3059\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\u3057\u304b\u3057\u4e0a\u8a18\u306e\u3088\u3046\u306b\u3001\u8ab0\u304c\u9053\u5fb3\u7684\u914d\u616e\u306b\u5024\u3059\u308b\u304b\u306b\u95a2\u3057\u3066\u666e\u901a\u3067\u306a\u3044\u8996\u70b9\u3092\u5426\u5b9a\u3057\u3088\u3046\u3068\u3059\u308b\u672c\u80fd\u3092\u5f37\u304f\u7591\u3046\u3079\u304d\u3060\u3068\u601d\u3046\u306e\u3067\u3059\u3002\u305d\u3057\u3066\u3001\u3053\u306e\u3088\u3046\u306a\u8996\u70b9\u304c\u6700\u521d\u306b\u60f3\u5b9a\u3055\u308c\u3066\u3044\u305f\u3088\u308a\u3082\u5408\u7406\u7684\u3067\u3042\u308b\u3053\u3068\u304c\u5224\u660e\u3057\u305f\u5834\u5408\u3001\u305d\u306e\u4ee3\u511f\u306f\u304d\u3063\u3068\u9ad8\u304f\u3064\u304f\u3067\u3057\u3087\u3046\u3002</p><p>\u4eca\u306e\u3068\u3053\u308d\u3001\u6606\u866b\u3084\u4eca\u65e5\u306e\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u3067\u5b9f\u884c\u3055\u308c\u308b\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u304c\u3001\u9053\u5fb3\u7684\u914d\u616e\u306b\u5024\u3059\u308b\u6709\u529b\u306a\u5019\u88dc\u306b\u306a\u308b\u304b\u306b\u95a2\u3057\u3066\u306f\u500b\u4eba\u7684\u306b\u306f\u534a\u4fe1\u534a\u7591\u3067\u3059\u3002\u305d\u308c\u3067\u3082\u3001\u305d\u3046\u3044\u3063\u305f\u8003\u3048\u65b9\u306b\u3082\u5fc3\u3092\u958b\u3044\u3066\u304a\u304f\u3053\u3068\u306f\u5927\u5207\u3060\u3068\u601d\u3044\u307e\u3059\u3002</p><p><strong>\u3088\u308a\u6df1\u3044\u5206\u6790\u3092\u652f\u63f4\u3059\u308b\u30a2\u30a4\u30c7\u30a3\u30a2\u3092\u63a2\u308b\u3002</strong><a href=\"https://www.openphilanthropy.org/about/team/luke-muehlhauser\"><u>\u30eb\u30fc\u30af\u30fb\u30df\u30e5\u30fc\u30eb\u30cf\u30a6\u30b6\u30fc</u></a>\u306f\u73fe\u5728\u3001\u8ab0\u304c\u9053\u5fb3\u7684\u914d\u616e\u306b\u5024\u3059\u308b\u304b\u3068\u3044\u3046\u554f\u984c\uff08\u5f7c\u306f\u3053\u308c\u3092\u9053\u5fb3\u7684\u88ab\u884c\u70ba\u8005\u306e\u554f\u984c\uff08<a href=\"https://forum.effectivealtruism.org/topics/moral-patienthood\"><u>moral patienthood</u></a>\uff09\u3068\u547c\u3076\uff09\u306b\u95a2\u3059\u308b\u7814\u7a76\u3068\u8b70\u8ad6\u306e\u73fe\u72b6\u3092\u8abf\u67fb\u3057\u3066\u3044\u307e\u3059<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefikpy2my6lz\"><sup><a href=\"#fnikpy2my6lz\">[6]</a></sup></span>\u3002\u3082\u3057\u3001\u6587\u732e\u4e0a\u306e\u30ae\u30e3\u30c3\u30d7\u3084\u3001\u3088\u308a\u826f\u3044\u60c5\u5831\u3092\u5f97\u308b\u305f\u3081\u306e\u6a5f\u4f1a\u3092\u898b\u3064\u3051\u308b\u3053\u3068\u304c\u3067\u304d\u308c\u3070\u3001\u3055\u3089\u306a\u308b\u7814\u7a76\u3078\u306e\u8cc7\u91d1\u63d0\u4f9b\u3092\u63a8\u5968\u3059\u308b\u53ef\u80fd\u6027\u3082\u3042\u308a\u307e\u3059\u3002\u3053\u3046\u3057\u305f\u7814\u7a76\u306f\u8fd1\u3044\u5c06\u6765\u3001<a href=\"https://www.openphilanthropy.org/focus/us-policy/farm-animal-welfare\"><u>\u755c\u7523\u52d5\u7269\u306e\u30a2\u30cb\u30de\u30eb\u30a6\u30a7\u30eb\u30d5\u30a7\u30a2</u></a>\u5206\u91ce\u306b\u304a\u3051\u308b\u512a\u5148\u9806\u4f4d\u4ed8\u3051\u306b\u5f71\u97ff\u3092\u4e0e\u3048\u308b\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u3002\u305f\u3068\u3048\u3070\u3001<a href=\"https://www.openphilanthropy.org/focus/us-policy/farm-animal-welfare/global-aquaculture-alliance-fish-welfare-best-practices\"><u>\u9b5a\u306e\u6271\u3044\u65b9\u3092\u6539\u5584\u3059\u308b</u></a>\u3053\u3068\u306b\u7126\u70b9\u3092\u5f53\u3066\u305f\u7814\u7a76\u3092\u3069\u308c\u3060\u3051\u512a\u5148\u3059\u308b\u304b\u306b\u5f71\u97ff\u3092\u4e0e\u3048\u308b\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u3002\u7406\u60f3\u7684\u306a\u306e\u306f\u3001\u9053\u5fb3\u7684\u60a3\u8005\u6027\u306b\u95a2\u3059\u308b\u79c1\u305f\u3061\u306e\u898b\u89e3\u304c\u3001\u3067\u304d\u308b\u3060\u3051\u591a\u304f\u306e\u6df1\u3044\u8003\u5bdf\u3001\u5b9f\u8a3c\u7684\u7814\u7a76\u3001\u304a\u3088\u3073\u4fe1\u5ff5\u306e\u3042\u308b\u8b70\u8ad6\u306b\u57fa\u3065\u304f\u5e83\u7bc4\u306a\u6587\u732e\u304b\u3089\u5c0e\u304d\u51fa\u3055\u308c\u3066\u3044\u308b\u3053\u3068\u3067\u3057\u3087\u3046\u3002</p><p><strong>\u300c\u672a\u958b\u62d3\u5206\u91ce\u300d\u3060\u3051\u306b\u3068\u3089\u308f\u308c\u306a\u3044\u3002\u5e83\u304f\u8a8d\u77e5\u3055\u308c\u3066\u3044\u308b\u554f\u984c\u3082\u3044\u307e\u3060\u306b\u5927\u304d\u306a\u88ab\u5bb3\u3092\u3082\u305f\u3089\u3057\u3066\u3044\u308b</strong>\u3002\u79c1\u305f\u3061\u306e\u6d3b\u52d5\u3067\u306f\u3001\u755c\u7523\u52d5\u7269\u306e\u30a2\u30cb\u30de\u30eb\u30a6\u30a7\u30eb\u30d5\u30a7\u30a2\u3084\u9ad8\u5ea6\u306a\u4eba\u5de5\u77e5\u80fd\u306b\u3088\u308b\u6f5c\u5728\u7684\u30ea\u30b9\u30af\u306a\u3069\u3001\u5f93\u6765\u3068\u306f\u7570\u306a\u308b\u30c1\u30e3\u30ea\u30c6\u30a3\u306b<a href=\"https://www.openphilanthropy.org/focus\"><u>\u6ce8\u76ee\u3059\u308b</u></a>\u3053\u3068\u304c\u3088\u304f\u3042\u308a\u307e\u3059\u3002\u3053\u308c\u306f\u3001\u6841\u5916\u308c\u306b\u5927\u304d\u306a\u8ca2\u732e\u3092\u3059\u308b\u30c1\u30e3\u30f3\u30b9\u306f\u3001\u3053\u308c\u307e\u3067\u3042\u307e\u308a\u9867\u307f\u3089\u308c\u308b\u3053\u3068\u306e\u306a\u304b\u3063\u305f\u5206\u91ce\u306b\u3053\u305d\u3042\u308b\u3068\u8003\u3048\u3066\u3044\u308b\u304b\u3089\u3067\u3059\u3002\u3057\u304b\u3057\u79c1\u305f\u3061\u306e\u76ee\u6a19\u306f\u3001\u3067\u304d\u308b\u9650\u308a\u826f\u3044\u3053\u3068\u3092\u3059\u308b\u3053\u3068\u3067\u3042\u308a\u3001\u73fe\u5728\u306e\u793e\u4f1a\u3067\u6700\u3082\u300c\u9769\u65b0\u7684\u306a\u300d\u6d3b\u52d5\u3092\u63a2\u3057\u51fa\u3057\u3001\u652f\u63f4\u3059\u308b\u3053\u3068\u3067\u306f\u3042\u308a\u307e\u305b\u3093\u3002\u4f8b\u3048\u3070<a href=\"https://www.openphilanthropy.org/focus/us-policy/criminal-justice-reform\"><u>\u30a2\u30e1\u30ea\u30ab\u306e\u5211\u4e8b\u53f8\u6cd5\u5236\u5ea6</u></a>\u306a\u3069\u3001\u3088\u308a\u5e83\u304f\u8a8d\u77e5\u3055\u308c\u3066\u3044\u308b\u5206\u91ce\u306b\u304a\u3044\u3066\u5bb3\u60aa\u306b\u7acb\u3061\u5411\u304b\u3046\u5927\u304d\u306a\u30c1\u30e3\u30f3\u30b9\u304c\u3042\u308c\u3070\u3001\u79c1\u305f\u3061\u306f\u305d\u306e\u30c1\u30e3\u30f3\u30b9\u3092\u7a4d\u6975\u7684\u306b\u6d3b\u7528\u3057\u307e\u3059\u3002</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn9oxf0z2ze1l\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref9oxf0z2ze1l\">^</a></strong></sup></span><div class=\"footnote-content\"><p>\u4f8b\u3048\u3070\u3001Giving USA\u306e\u30c7\u30fc\u30bf\u306b\u3088\u308c\u3070\u30012015\u5e74\u306e\u30a2\u30e1\u30ea\u30ab\u306e\u5bc4\u4ed8\u306e\u3046\u3061\u3001\u56fd\u969b\u63f4\u52a9\u306b\u7126\u70b9\u3092\u5f53\u3066\u305f\u3082\u306e\u306f\u7d044%\u306b\u904e\u304e\u307e\u305b\u3093\u3002</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnr8thf5cajmq\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefr8thf5cajmq\">^</a></strong></sup></span><div class=\"footnote-content\"><p>pp.120\u3002</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnp9r0vmc99m\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefp9r0vmc99m\">^</a></strong></sup></span><div class=\"footnote-content\"><p>pp.112-113\u3002</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnjweevak8z1\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefjweevak8z1\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://www.amazon.com/dp/B0052REUW0/ref=dp-kindle-redirect?_encoding=UTF8&amp;btkr=1\"><u>The Better Angels of Our Nature</u></a> \u306e\u7b2c1\u7ae0\u306b\u591a\u304f\u306e\u4f8b\u304c\u63b2\u8f09\u3055\u308c\u3066\u3044\u307e\u3059\u3002\ufe0e</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn9m6tzurlwhr\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref9m6tzurlwhr\">^</a></strong></sup></span><div class=\"footnote-content\"><p>\u4f59\u8ac7\u3067\u3059\u304c\u3001\u3053\u306e\u3088\u3046\u306a\u8868\u73fe\u3092\u907f\u3051\u308b\u3053\u3068\u306f\u3057\u3070\u3057\u3070\u56f0\u96e3\u3067\u3059\u3002\u4e00\u822c\u306b\u9053\u5fb3\u7684\u914d\u616e\u306b\u5024\u3059\u308b\u5b58\u5728\u3092\u6307\u3059\u5834\u5408\u3001\u79c1\u305f\u3061\u306f\u305d\u306e\u3088\u3046\u306a\u5b58\u5728\u304c\u4eba\u9593\u3067\u3042\u308b\u304b\u3069\u3046\u304b\u3092\u4e8b\u524d\u306b\u5224\u65ad\u305b\u305a\u306b\u3001\u307e\u305f\u30ab\u30b8\u30e5\u30a2\u30eb\u306a\u8aad\u8005\u306b\u3042\u307e\u308a\u6c17\u3092\u9063\u308f\u305b\u3059\u304e\u306a\u3044\u3088\u3046\u306b\u3001\u300c\u4eba\uff08persons\uff09\u300d\u3068\u3044\u3046\u8a00\u8449\u3092\u4f7f\u3044\u307e\u3059\u3002\u3088\u308a\u6b63\u78ba\u306b\u306f\u3001\u300c\u9053\u5fb3\u7684\u88ab\u884c\u70ba\u8005\uff08moral patients\uff09\u300d\u3067\u3059\u3002\ufe0e</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnikpy2my6lz\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefikpy2my6lz\">^</a></strong></sup></span><div class=\"footnote-content\"><p>\u6700\u7d42\u5831\u544a\u66f8\u306f<a href=\"https://www.openphilanthropy.org/2017-report-consciousness-and-moral-patienthood?fbclid=IwAR1IoDqzhl6OKX6tQLRswCwYhBwQ2n1jVYawR8J59D6jKkLD74_3YyfXfMw\"><u>\u3053\u3053\u304b\u3089</u></a>\u3054\u89a7\u3044\u305f\u3060\u3051\u307e\u3059\u3002</p></div></li></ol>", "user": {"username": "EA Japan"}}, {"_id": "ZZD9qQY8cR7cqQkQL", "title": "\u9769\u65b0\u7684\u306a\u601d\u3044\u3084\u308a\uff08\u30a4\u30f3\u30c8\u30ed\uff09", "postedAt": "2023-07-26T13:43:23.393Z", "htmlBody": "<p><i>This is a Japanese translation of \u201c</i><a href=\"https://forum.effectivealtruism.org/posts/7pDe4y3KtwwyF6kTS/radical-empathy-1\"><i><strong>Radical empathy</strong></i></a><i>\u201d</i></p><p>by&nbsp;<a href=\"https://forum.effectivealtruism.org/users/maxdalton\"><u>MaxDalton</u></a> 2022\u5e74 6\u67083\u65e5</p><blockquote><p>\u300c\u554f\u984c\u306f\u3001\u305d\u308c\u3089\u306e\u52d5\u7269\u304c\u601d\u8003\u3067\u304d\u308b\u304b\u3069\u3046\u304b\u3067\u3082\u3001\u8a71\u3057\u304c\u3067\u304d\u308b\u304b\u3069\u3046\u304b\u3067\u3082\u306a\u304f\u3001\u82e6\u3057\u3080\u306e\u304b\u3069\u3046\u304b\u3067\u3042\u308b\u3002\u3044\u304b\u306b\u3057\u3066\u6cd5\u5f8b\u306f\u3001\u82e6\u3057\u307f\u3092\u611f\u3058\u3046\u308b\u5b58\u5728\u306b\u5bfe\u3057\u3066\u306e\u4fdd\u8b77\u3092\u62d2\u3080\u3079\u304d\u3067\u3042\u308d\u3046\u304b\uff1f\u300d<br>- \u30b8\u30a7\u30ec\u30df\u30fc\u30fb\u30d9\u30f3\u30b5\u30e0\uff081789\uff09</p></blockquote><p>\u3053\u306e\u7ae0\u3067\u306f\u3001\u79c1\u305f\u3061\u306e\u9053\u5fb3\u7684\u914d\u616e\u304c\u542b\u3080\u3079\u304d\u5bfe\u8c61\u304c\u8ab0/\u4f55\u3067\u3042\u308b\u304b\u3092\u63a2\u308b\u3002\u4eca\u9031\u306f\u3001\u3053\u306e\u554f\u984c\u306e\u91cd\u8981\u306a\u4f8b\u3068\u3057\u3066\u3001\u7279\u306b\u755c\u7523\u52d5\u7269\u306b\u7126\u70b9\u3092\u5f53\u3066\u3066\u3044\u304f\u3002</p><p>\u672c\u7ae0\u306e\u4e3b\u306a\u30b3\u30f3\u30bb\u30d7\u30c8\u306f\u4ee5\u4e0b\u306e\u901a\u308a\u3067\u3042\u308b\u3002</p><ul><li><strong>\u516c\u5e73\u6027</strong>\uff1a\u6700\u3082\u52a9\u3051\u3092\u5fc5\u8981\u3068\u3059\u308b\u4eba\u3084\u751f\u304d\u7269\u3092\u52a9\u3051\u308b\uff08\u5834\u6240\u3001\u6642\u9593\u3001\u7a2e\u65cf\u306b\u3088\u3063\u3066\u5272\u5f15\u3044\u3066\u8003\u3048\u308b\u306e\u306f\u3001\u305d\u308c\u3089\u306e\u8981\u7d20\u304c\u5b9f\u969b\u306b\u9053\u5fb3\u7684\u306b\u59a5\u5f53\u3067\u3042\u308b\u5834\u5408\u306e\u307f\uff09\u3002</li><li><strong>\u671f\u5f85\u5024</strong>\uff1a\u4f55\u304c\u3069\u308c\u3060\u3051\u5f79\u306b\u7acb\u3064\u304b\u306b\u3064\u3044\u3066\u306f\u3063\u304d\u308a\u3068\u308f\u304b\u3089\u306a\u3044\u3053\u3068\u306f\u3088\u304f\u3042\u308b\u3002\u305d\u306e\u3088\u3046\u306a\u72b6\u6cc1\u3067\u306f\u3001\u305d\u308c\u305e\u308c\u306e\u7d50\u679c\u3092\u305d\u306e\u4e8b\u8c61\u304c\u8d77\u3053\u308b\u78ba\u7387\u3067\u91cd\u307f\u4ed8\u3051\u3057\u3001\u671f\u5f85\u5024\u306e\u4e0a\u3067\u6700\u3082\u826f\u3055\u305d\u3046\u306a\u884c\u52d5\u3092\u9078\u3076\u3053\u3068\u304c\u7406\u306b\u304b\u306a\u3063\u3066\u3044\u308b\u304b\u3082\u3057\u308c\u306a\u3044\u3002</li><li><strong>\u5909\u308f\u3063\u305f\u30a2\u30a4\u30c7\u30a3\u30a2\u3092\u691c\u8a0e\u3059\u308b\u3053\u3068\u306e\u91cd\u8981\u6027\uff08\u3068\u96e3\u3057\u3055\uff09</strong>\uff1a\u793e\u4f1a\u306e\u5408\u610f\u5f62\u6210\u306f\u3001\u6b74\u53f2\u4e0a\u591a\u304f\u306e\u3053\u3068\u3067\u9593\u9055\u3063\u3066\u304d\u305f\uff08\u4f8b\uff1a\u592a\u967d\u304c\u5730\u7403\u3092\u56de\u3063\u3066\u3044\u308b\u3001\u5974\u96b7\u5236\u306e\u9053\u5fb3\u6027\uff09\u3002\u540c\u3058\u3088\u3046\u306a\u904e\u3061\u3092\u72af\u3055\u306a\u3044\u305f\u3081\u306b\u306f\u3001\u6279\u5224\u7684\u306b\u554f\u984c\u3092\u8003\u3048\u3001\u4ed6\u8005\u3068\u5354\u8abf\u3057\u3066\u884c\u52d5\u3057\u306a\u304c\u3089\u3082\u3001\u5909\u308f\u3063\u305f\u30a2\u30a4\u30c7\u30a3\u30a2\u3084\u9053\u5fb3\u7684\u7acb\u5834\u3092\u8003\u616e\u3059\u308b\u59ff\u52e2\u304c\u5fc5\u8981\u3067\u3042\u308b\u3002</li></ul>", "user": {"username": "EA Japan"}}, {"_id": "6ugipGgCiYsBzbMwt", "title": "Existential risk from AI and what DC could do about it (Ezra Klein on the 80,000 Hours Podcast)", "postedAt": "2023-07-26T11:48:05.643Z", "htmlBody": "<p>We just published an interview: <a href=\"https://80000hours.org/podcast/episodes/ezra-klein-ai-and-dc/\"><strong>Ezra Klein on existential risk from AI and what DC could do about&nbsp;it</strong></a><strong>.</strong> You can click through for the audio, a full transcript, and related links. Below are the episode summary and some key excerpts.</p><figure class=\"table\"><table><tbody><tr><td><p><i>AI is a great thing to spend lots of R&amp;D money on and have a really strong public research infrastructure around. A good amount of that research should be on safety and interpretability. And we should really want this to work, and it should happen.</i></p><p><i>And it\u2019s actually not that expensive. I mean, it is expensive for most companies, which is why OpenAI has to be attached to Microsoft and DeepMind had to be part of Google and so on. But from the perspective of a country\u2019s budget, it\u2019s not impossible to have real traction on this.</i></p><p>- Ezra Klein</p></td></tr></tbody></table></figure><h2><strong>Episode summary</strong></h2><p>In <i>Oppenheimer</i>, scientists detonate a nuclear weapon despite thinking there\u2019s some \u2018near zero\u2019 chance it would ignite the atmosphere, putting an end to life on Earth. Today, scientists working on AI think the chance their work puts an end to humanity is <a href=\"https://www.vox.com/the-highlight/23447596/artificial-intelligence-agi-openai-gpt3-existential-risk-human-extinction\">vastly higher</a> than that.</p><p>In response, some have suggested we launch a Manhattan Project to make AI safe via enormous investment in relevant R&amp;D. Others have suggested that we need international organisations modelled on those that slowed the proliferation of nuclear weapons. Others still seek a research slowdown by labs while an auditing and licencing scheme is created.</p><p>Today\u2019s guest \u2014 journalist Ezra Klein of <i>The New York Times</i> \u2014 has watched policy discussions and legislative battles play out in DC for 20 years. Like many people he has also taken a big interest in AI this year, writing articles such as \u201c<a href=\"https://www.nytimes.com/2023/03/12/opinion/chatbots-artificial-intelligence-future-weirdness.html\">This changes everything</a>.\u201d In his <a href=\"https://80000hours.org/podcast/episodes/ezra-klein-journalism-most-important-topics/\">first interview</a> on the show in 2021, he flagged AI as one topic that DC would regret not having paid more attention to.</p><p>So we invited him on to get his take on which regulatory proposals have promise, and which seem either unhelpful or politically unviable.</p><p>Out of the ideas on the table right now, Ezra favours a focus on direct government funding \u2014 both for AI safety research and to develop AI models designed to solve problems other than making money for their operators. He is sympathetic to legislation that would require AI models to be legible in a way that none currently are \u2014 and embraces the fact that that will slow down the release of models while businesses figure out how their products actually work.</p><p>By contrast, he\u2019s pessimistic that it\u2019s possible to coordinate countries around the world to agree to prevent or delay the deployment of dangerous AI models \u2014 at least not unless there\u2019s some spectacular AI-related disaster to create such a consensus. And he fears attempts to require licences to train the most powerful ML models will struggle unless they can find a way to exclude and thereby appease people working on relatively safe consumer technologies rather than cutting-edge research.</p><p>From observing how DC works, Ezra expects that even a small community of experts in AI governance can have a large influence on how the the US government responds to AI advances. But in Ezra\u2019s view, that requires those experts to move to DC and spend years building relationships with people in government, rather than clustering elsewhere in academia and AI labs.</p><p>In today\u2019s brisk conversation, Ezra and host Rob Wiblin cover the above as well as:</p><ul><li>Whether it\u2019s desirable to slow down AI research</li><li>The value of engaging with current policy debates even if they don\u2019t seem directly important</li><li>Which AI business models seem more or less dangerous</li><li>Tensions between people focused on existing vs emergent risks from AI</li><li>Two major challenges of being a new parent</li></ul><p>Get this episode by subscribing to our podcast on the world\u2019s most pressing problems and how to solve them: type \u201880,000 Hours\u2019 into your podcasting app. Or read the transcript below.</p><p><i>Producer: Keiran Harris</i><br><i>Audio Engineering Lead: Ben Cordell</i><br><i>Technical editing: Milo McGuire</i><br><i>Transcriptions: Katy Moore</i><br>&nbsp;</p><h2><strong>Highlights</strong></h2><h3><strong>Punctuated equilibrium</strong></h3><blockquote><p><strong>Ezra Klein:</strong> You need ideas on the shelf, not in your drawer. Don\u2019t put it in your drawer: they need to be on a shelf where other people can reach them, to shift the metaphor a little bit here. You need ideas that are out there.</p><p>So this is a governing model that in the political science literature is called \u201cpunctuated equilibrium\u201d: nothing happens, and then all of a sudden, it does. Right? All of a sudden, there\u2019s a puncture in the equilibrium and new things are possible. Or, as it\u2019s put more commonly: you never let the crisis go to waste. And when there is a crisis, people have to pick up the ideas that are around. And a couple things are important then: One is that the ideas have to be around; two is that they have to be coming from a source people trust, or have reason to believe they should trust; and three, they have to have some relationship with that source.</p><p>So what you want to be doing is building relationships with the kinds of people who are going to be making these decisions. What you want to be doing is building up your own credibility as a source on these issues. And what you want to be doing is actually building up good ideas and battle-testing them and getting people to critique them and putting them out in detail. I think it is very unlikely that AI regulation is going to come out of a <a href=\"https://lesswrong.com/\">LessWrong</a> post. But I have seen a lot of good ideas from LessWrong posts ending up in different white paper proposals that now get floated around. And you need a lot more of those.</p><p>It\u2019s funny, because I\u2019ve seen this happening in Congress again and again. You might wonder, like, why do these think tanks produce all these white papers or reports that truly nobody reads? And there\u2019s a panel that nobody\u2019s at? It\u2019s a lot of work for nobody to read your thing and nobody to come to your speech. But it\u2019s not really nobody. It may really be that only seven people read that report, but five of them were congressional staffers who had to work on this issue. And that\u2019s what this whole economy is. It is amazing to me the books that you\u2019ve never heard of that have ended up hugely influencing national legislation. Most people have not read <a href=\"https://www.amazon.com/Jump-Starting-America-Breakthrough-Economic-American/dp/1541762487\"><i>Jump-Starting America</i></a> by Jonathan Gruber and Simon Johnson. But as I understand it, it was actually a pretty important part of the <a href=\"https://en.wikipedia.org/wiki/CHIPS_and_Science_Act\">CHIPS bill</a>.</p><p>And so you have to build the ideas, you have to make the ideas legible and credible to people, and you have to know the people you\u2019re trying to make these ideas legible and credible to. That is the process by which you become part of this when it happens.</p></blockquote><h3><strong>The 'disaster' model of regulation</strong></h3><blockquote><p><strong>Ezra Klein:</strong> The way I think AI regulation is going to happen is: something is going to go wrong. There is going to be some event that focuses attention again on AI. There\u2019s been a sort of reduction in attention over the past couple of months. We\u2019ve not had a major new release in the way we did with GPT-4, say, and people are drifting on to other topics. Then at some point, there will be a new release. Maybe DeepMind\u2019s Gemini system is unbelievable or something.</p><p>And then at some point, there\u2019s going to be a system powerful enough or critical enough that goes bad. And I don\u2019t think it\u2019s going to go bad in a, you know, <a href=\"https://www.lesswrong.com/tag/intelligence-explosion\">foom</a> and then we\u2019re all dead \u2014 or if it does, you know, this scenario is not relevant \u2014 but I think it\u2019ll go bad in a more banal way: somebody\u2019s going to die, a critical infrastructure is going to go offline, there\u2019s going to be a huge scam that exploits a vulnerability in operating systems all across the internet and tons of people lose their money or they lose their passwords or whatever. And Congress, which is nervous, that\u2019ll be the moment that people begin to legislate.</p><p>And once you get into a process where people are trying to work towards an outcome, not just position within a debate, I suspect you\u2019ll find people finding more points of common ground and working together a little bit more. I already feel like I see from where we were six or months ago, people coming a little bit more to Earth and a little bit nearer to each other in the debate. Not every loud voice on Twitter, but just in the conversations I\u2019m around and in. I think you\u2019ll see something like that eventually. I just don\u2019t think we\u2019re there yet.</p></blockquote><h3><strong>How to slow down advances in AI capabilities</strong></h3><blockquote><p><strong>Ezra Klein:</strong> My view is you try to slow this down, to the extent you do, through forcing it to be better. I don\u2019t think \u201cWe\u2019re going to slow you down\u201d is a strong or winning political position. I do think \u201cYou need to achieve X before you can release a product\u201d is how you slow things down in a way that makes sense.</p><p>So I\u2019ve used the example \u2014 and I recognise this example actually may be so difficult that it\u2019s not possible \u2014 but I think it would be possible to win a political fight that demands a level of interpretability of AI systems that basically renders the major systems null and void right now.</p><p>If you look at <a href=\"https://www.democrats.senate.gov/news/press-releases/majority-leader-schumer-delivers-remarks-to-launch-safe-innovation-framework-for-artificial-intelligence-at-csis\">Chuck Schumer\u2019s speech that he gave on SAFE Innovation</a> \u2014 which is his pre-regulatory framework; his framework for discussion of a regulatory framework \u2014 one of his major things is explainability. And he has talked to people \u2014 I know; I\u2019ve been around these conversations \u2014 and people told him this may not be possible. And he\u2019s put that in there, but he still wants it there, right? Frankly, I want it too. So maybe explainability, interpretability is not possible. But it\u2019s an example of something where if Congress did say, \u201cYou have to do this, particularly for AI that does X,\u201d it would slow things down \u2014 because, frankly, they don\u2019t know how to do it yet.</p><p>And there are a lot of things like that that I think are less difficult than interpretability. So I think the way you will end up slowing some of these systems down is not, you know, \u201cWe need to pause because we think you\u2019re going to kill everybody\u201d \u2014 I don\u2019t think that\u2019s going to be a winning position. But you need to slow down, because we need to be confident that this is going to be a good piece of work when it comes out. I mean, that\u2019s something we do constantly. I mean, in this country, you kind of can\u2019t build a nuclear power plant at all, but you definitely can\u2019t build one as quickly as you can, cutting all the corners.</p><p>And then there are other things you could do that would slow people down. One of the things that I think should get more attention \u2014 <a href=\"https://www.nytimes.com/2023/04/16/opinion/this-is-too-important-to-leave-to-microsoft-google-and-facebook.html\">I\u2019ve written about this</a> \u2014 or at least some attention is a question of where liability sits in these systems. So if you think about social media, we basically said there\u2019s almost no liability on the social media companies. They\u2019ve created a platform; the liability rests with the people who put things on the platform. I\u2019m not sure that\u2019s how it should work for AI. I think most of the question is how the general underlying model is created. If OpenAI sells their model to someone, and that model is used for something terrible, is that just the buyer\u2019s fault, or is that OpenAI\u2019s fault? I mean, how much power does a buyer even have over the model? But if you put a lot of liability on the core designers of the models, they would have to be pretty damn sure these things work before they release them, right?</p><p>Things like that could slow people down. Forcing people to make things up to a higher standard of quality or reliability or interpretability, et cetera, that is a way of slowing down the development process. And slowing it down for a reason \u2014 which is, to be fair, what I think you should slow it down for.</p></blockquote><h3><strong>The viability of licencing</strong></h3><blockquote><p><strong>Rob Wiblin:</strong> There\u2019s another big cluster of proposals, and maybe the largest there is a combination of requiring organisations to <a href=\"https://80000hours.org/podcast/episodes/markus-anderljung-regulating-cutting-edge-ai/\">seek government licences</a> if they\u2019re going to be training really large or very general AI models. And in the process of getting a licence, they would have to demonstrate that they know how to do it responsibly \u2014 or at least as responsibly as anyone does at the time. Those rules could potentially be assisted by legislation saying that only projects with those government licences would be allowed to access the latest and most powerful AI specialised supercomputers, which is sometimes called \u201c<a href=\"https://80000hours.org/podcast/episodes/lennart-heim-compute-governance/\">compute governance</a>.\u201d How do you think that would come out of a messy legislative process?</p><p><strong>Ezra Klein:</strong> On the one hand, if you take the metaphor that basically, what you\u2019re developing now is a very powerful weapon, then of course, if you\u2019re developing a very powerful, very secret weapon, you want that done in a highly regulated facility. Or you want that done by a facility that is highly trusted, and workers who are highly trusted in everything from their technical capacity to their cybersecurity practices. So that makes a tonne of sense.</p><p>On the other hand, if what you say is you\u2019re developing the most important consumer technology of this era, and in order to do that, you\u2019re going to need to be a big enough company to get through this huge regulatory gauntlet. That\u2019s going to be pretty easy for Google or Meta or Microsoft to do, because they have all the lawyers and they have the lobbyists and so on.</p><p>I could imagine, as that goes through Congress, people get real antsy about the idea that they\u2019re basically creating an almost government-protected monopoly \u2014 entrenching the position of this fairly small number of companies, and making it harder to decentralise AI, if that\u2019s something that is truly possible. And some people believe it is. I mean, there\u2019s this internal Google document that leaked about <a href=\"https://www.theverge.com/2023/7/10/23790132/google-memo-moat-ai-leak-demis-hassabis\">how there\u2019s no moat</a>. Meta has tried to talk about <a href=\"https://www.theguardian.com/technology/2023/jul/18/ai-free-open-source-microsoft\">open sourcing more of their work</a>. Who knows where it really goes over time. But I think the politics of saying the government is going to centralise AI development in private actors is pretty tough.</p><p>There\u2019s a different set of versions of this, and I\u2019ve heard many of the top people in these AI companies say to me, \u201cWhat I really wish is that as we get closer to AGI, that all this gets turned over to some kind of international public body.\u201d You hear different versions and different metaphors: A UN for AI, a <a href=\"https://home.cern/\">CERN</a> for AI, an <a href=\"https://www.iaea.org/\">IAEA</a> for AI \u2014 you pick the group. But I don\u2019t think it\u2019s going to happen, because it\u2019s first and foremost a consumer technology, or is being treated as such. And the idea that you\u2019re going to nationalise or internationalise a consumer technology that is creating all these companies and spinning all these companies off, there\u2019s functionally no precedent for that anywhere.</p><p>And this goes maybe back a little bit to the AI ethics versus AI risk issue, where it looks really, really reasonable under one kind of dominant internal metaphor \u2014 \u201cwe\u2019re creating the most dangerous weapon humanity\u2019s ever held\u201d \u2014 and it looks really, really unreasonable if your view is this is a very lucrative software development project that we want lots of people to be able to participate in. And so I imagine that that will have a harder time in a legislative process once it gets out of the community of people who are operating off of this sort of shared \u201cthis is the most dangerous thing humanity\u2019s ever done\u201d sort of internal logic. I\u2019m not saying those people are wrong, by the way. That\u2019s just my assessment of the difficulty here.</p></blockquote><h3><strong>Manhattan Project for AI safety</strong></h3><blockquote><p><strong>Rob Wiblin:</strong> Another broad approach that\u2019s out there is sometimes branded as a Manhattan Project for AI safety: basically, the US and UK and EU governments spending billions of dollars on research and development to solve the technical problems that exist around keeping AGI aligned with our goals, and having sufficiently strong guardrails that they can\u2019t easily be retrained to commit all sorts of crimes, for example. The CEO of Microsoft, Satya Nadella, has talked in favour of this, and the economist <a href=\"https://www.politico.com/news/magazine/2023/05/08/manhattan-project-for-ai-safety-00095779\">Samuel Hammond wrote an article in <i>Politico</i></a> that we\u2019ll link to. What do you think of that broad approach?</p><p><strong>Ezra Klein:</strong> That I\u2019m very much for. I don\u2019t think I would choose a metaphor of a Manhattan Project for AI safety, just because I don\u2019t think people believe we need that, and that\u2019s not going to be much of a political winner. But AI is a great thing to spend lots of R&amp;D money on and have a really strong public research infrastructure around. A good amount of that research should be on safety and interpretability. And we should really want this to work, and it should happen. I think that makes a tonne of sense, and I think that\u2019s actually a possible thing you could achieve.</p><p>Look, I don\u2019t trust any view I hold about takeoff rates. But what I do think is that if we are in a sort of vertical takeoff scenario, policy is just going to lag so far behind that we almost have nothing we can do but hope for the best. If we\u2019re in more modest takeoff scenarios \u2014 which I think are more likely in general \u2014 then building institutions can really work, and we can be making progress alongside the increase in capability capacity and danger.</p><p>So that\u2019s where I think coming up with ideas that also just play into the fact that different countries want to dominate this, different countries want to get the most that they can out of this, different countries want to make sure a lot of this is done for the public good. And that it\u2019s actually not <i>that</i> expensive. I mean, it is expensive for most companies, which is why OpenAI has to be attached to Microsoft and DeepMind had to be part of Google and so on. But from the perspective of a country\u2019s budget, it\u2019s not impossible to have real traction on this. Now, getting the expertise and getting the right engineers and so on, that\u2019s tougher, but it\u2019s doable.</p><p>And so, yeah, I think that\u2019s somewhere where there\u2019s a lot of promise. And the good thing about building institutions like that, even if they\u2019re not focused on exactly what you want them to be, is that then, when they do need to refocus, if they do need to refocus, you have somewhere to do that. You know, if you have a Manhattan Project just for AI, well, then you could have a Manhattan Project for AI safety \u2014 because it was already happening, and now you just have to expand it.</p><p>So that\u2019s where I think beginning to see yourself as in a foundation-building phase is useful. Again, it\u2019s why I emphasise that at this point, it\u2019s good to think about your policies, but also think about the frameworks under which policy will be made. You know, who are the members of Congress who understand this really well? And you\u2019re hoping will be a leader on this, and you want to have good relationships with? Then, you know, keeping their staff informed and so on. And what are the institutions where all this work is going to be done? Do they need to be built from scratch? And what kind of people go into them? And how do you get the best people into them? And all of that is not, like, the policy at the end of the rainbow \u2014 but you need all that for that policy to ever happen, and to ever work if it does happen.</p></blockquote><h3><strong>Parenting</strong></h3><blockquote><p><strong>Ezra Klein:</strong> I think one is that \u2014 and this is a very long-running piece of advice \u2014 but kids see what you do; they don\u2019t listen to what you say. And for a long time, they don\u2019t have language. And so what you are modelling is always a thing that they are really absorbing. And that includes, by the way, their relationship to you and your relationship to them.</p><p>And something that really affected my parenting is a <a href=\"https://youtu.be/4iIigAgDp2Q\">clip of Toni Morrison</a> talking about how she realised at a certain point that when she saw her kids, that she knew how much she loved them, but what they heard from her sometimes was the stuff she was trying to fix, right? \u201cYour shoes are untied, your hair\u2019s all messed up, you\u2019re dirty, you need to\u2026\u201d whatever. And that she had this conscious moment of trying to make sure that the first thing they saw from her was how she felt about them. And I actually think that\u2019s a really profound thing as a parent: this idea that I always want my kids to feel like I am happy to see them; they feel that they are seen and wanted to be seen. So that\u2019s something that I think about a lot.</p><p>Then another thing is you actually have to take care of yourself as a parent. And you know, I worry I\u2019m a little more grumpier on this show today than I normally am, because my kid had croup all night, and I\u2019m just tired. And the thing that I\u2019ve learned as a parent is that just 75% of how I deal with the world \u2014 like, how good of a version of me the world gets \u2014 is how much sleep I got. You\u2019ve gotta take care of yourself. And that\u2019s not always the culture of parenting, particularly modern parenting. You need people around you. You need to let off your own steam. You need to still be a person.</p><p>But a huge part of parenting is not how you parent the kid, but how you parent yourself. And I\u2019m just a pretty crappy parent when I do a worse job of that, and a pretty good parent when I do a good job of that. But a lot of how present I can be with my child is: Am I sleeping enough? Am I meditating enough? Am I eating well? A I taking care of my stress level? So, you know, it\u2019s not 100% of parenting a child is parenting yourself, but I think about 50% of parenting a child is parenting yourself. And that\u2019s an easy thing to forget.</p><p><strong>Rob Wiblin:</strong> Yeah. It is astonishing how much more irritable I get when I\u2019m underslept. That\u2019s maybe my greatest fear.</p><p><strong>Ezra Klein:</strong> Yeah. It\u2019s bad. Again, like, even in this conversation, I\u2019ve been probably edgier than I normally am, and I\u2019ve just felt terrible all day. It\u2019s a crazy thing when you become a parent and you realise other parents have been doing this all the time. You see them it\u2019s cold and flu season, and you understand that you didn\u2019t understand what they were telling you before. And somehow, all these people are just running around doing the same jobs they always have to do, and carrying the same amount of responsibility at work and so on, just operating at 50% of their capacity all the time and not really complaining about it that much. A whole new world of admiring others opens up to you. Like, I have two kids and now my admiration of people who have three or four is so high. So, you know, it\u2019s a real thing.</p><p>But it does open you up to a lot of beautiful vistas of human experience. And as somebody who is interested in the world, it was really undersold to me how interesting kids are, and how interesting being a parent is. And it\u2019s worth paying attention to, not just because you\u2019re supposed to, but because you learn just a tremendous amount about what it means to be a human being.</p></blockquote>", "user": {"username": "80000_Hours"}}, {"_id": "YDTgRR7Qjmj47PaTj", "title": "An overview of standards in biosafety and biosecurity", "postedAt": "2023-07-26T12:19:15.200Z", "htmlBody": "<p>Linkpost for <a href=\"https://docs.google.com/document/d/1sb3naVl0an_KyP8bVuaqxOBf2GC_4iHlTV-Onx3M2To/edit\">https://docs.google.com/document/d/1sb3naVl0an_KyP8bVuaqxOBf2GC_4iHlTV-Onx3M2To/edit</a>&nbsp;</p><p><strong>This report represents ~40 hours of work by Rose Hadshar in summer 2023 for </strong><a href=\"https://arbresearch.com/\"><u>Arb Research</u></a><strong>, in turn for Holden Karnofsky in response to</strong> <a href=\"https://forum.effectivealtruism.org/posts/idrBxfsHkYeTtpm2q/seeking-paid-case-studies-on-standards\"><u>this</u></a><strong>&nbsp;call for proposals on standards.&nbsp;</strong></p><p>It\u2019s based on a mixture of background reading, research into individual standards, and interviews with experts. Note that I didn\u2019t ask for permission to cite the expert interviews publicly, so I\u2019ve anonymised them.</p><p><strong>I suggest reading the </strong><a href=\"https://forum.effectivealtruism.org/posts/YDTgRR7Qjmj47PaTj/an-overview-of-standards-in-biosafety-and-biorisk#Scope\">scope</a><strong> and </strong><a href=\"https://forum.effectivealtruism.org/posts/YDTgRR7Qjmj47PaTj/an-overview-of-standards-in-biosafety-and-biorisk#Summary_of_most_interesting_findings\">summary</a>&nbsp;<strong>and skimming the </strong><a href=\"https://forum.effectivealtruism.org/posts/YDTgRR7Qjmj47PaTj/an-overview-of-standards-in-biosafety-and-biorisk#Overview_of_standards_in_biosafety_and_biorisk \">overview</a><strong>, then only looking at sections which seem particularly relevant to you.</strong></p><h1>Scope</h1><p>This report covers:</p><ul><li>Both biosecurity and biosafety:<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefzlsmt765os\"><sup><a href=\"#fnzlsmt765os\">[1]</a></sup></span><ul><li><strong>Biosecurity:</strong>&nbsp;\u201cthe protection, control and accountability for valuable biological materials (including information) in laboratories in order to prevent their unauthorized access, loss, theft, misuse, diversion or intentional release.\u201d</li><li><strong>Biosafety:&nbsp;</strong> \u201cthe containment principles, technologies and practices that are implemented to prevent unintentional exposure to pathogens and toxins or their accidental release\u201d</li></ul></li><li>Biosecurity and biosafety standards internationally, but with much more emphasis on the US</li><li>Regulations and guidance as well as standards proper. I am using these terms as follows:<ul><li><strong>Regulations: </strong>rules on how to comply with a particular law or laws. Legally binding</li><li><strong>Guidance:</strong>&nbsp;rules on how to comply with particular regulations. Not legally binding, but risky to ignore</li><li><strong>Standards:</strong>&nbsp;rules which do not relate to compliance with a particular law or laws. <i>Not legally binding.</i></li></ul></li><li>Note that I also sometimes use \u2018standards\u2019 as an umbrella term for regulations, guidance and standards.</li></ul><h1>Summary of most interesting findings</h1><p><i>For each point:</i></p><ul><li><i>I\u2019ve included my confidence in the claim (operationalised as the probability that I would still believe the claim after 40 hours\u2019 more work).</i></li><li><i>I link to a subsection with more details (though in some cases I don\u2019t have much more to say).</i></li></ul><h3>The origins of bio standards</h3><ul><li>(80%) <a href=\"https://docs.google.com/document/d/e/2PACX-1vS151CNe9lw6SUqL_vg4MOy_YdMKHs4IUC_54skMC9ixtc8HKXH_Tu2rqw5u4PxhOL_NWzN-HFlOKi1/pub#h.9xuyxzn4e7f3\"><strong><u>There were many different motivations behind bio standards</u></strong></a>&nbsp;(e.g. plant health, animal health, worker protection, bioterrorism, fair sharing of genetic resources\u2026)</li><li>(70%) <a href=\"https://docs.google.com/document/d/e/2PACX-1vS151CNe9lw6SUqL_vg4MOy_YdMKHs4IUC_54skMC9ixtc8HKXH_Tu2rqw5u4PxhOL_NWzN-HFlOKi1/pub#h.8tqmqpu1ylbx\"><strong><u>Standards were significantly reactive to rather than proactive about incidents</u></strong></a><strong>&nbsp;</strong>(e.g. lab accidents, terrorist attacks, and epidemics), though:</li><li>There are exceptions (e.g. the NIH guidelines on recombinant DNA)</li><li>Guidance is often more proactive than standards (e.g. gene drives)</li><li>(80%) <a href=\"https://docs.google.com/document/d/e/2PACX-1vS151CNe9lw6SUqL_vg4MOy_YdMKHs4IUC_54skMC9ixtc8HKXH_Tu2rqw5u4PxhOL_NWzN-HFlOKi1/pub#h.rqedyfazku5u\"><strong><u>International standards weren\u2019t always later or less influential than national ones</u></strong></a></li><li>(70%) <a href=\"https://docs.google.com/document/d/e/2PACX-1vS151CNe9lw6SUqL_vg4MOy_YdMKHs4IUC_54skMC9ixtc8HKXH_Tu2rqw5u4PxhOL_NWzN-HFlOKi1/pub#h.1fdhfz5xk60s\"><strong><u>Voluntary standards seem to have prevented regulation in at least one case</u></strong></a>&nbsp;(e.g. the NIH guidelines)</li><li>(65%)<a href=\"https://docs.google.com/document/d/e/2PACX-1vS151CNe9lw6SUqL_vg4MOy_YdMKHs4IUC_54skMC9ixtc8HKXH_Tu2rqw5u4PxhOL_NWzN-HFlOKi1/pub#h.ndhbhqluxo8g\"><u>&nbsp;</u><strong><u>In the US, it may be more likely that mandatory standards are passed on matters of national security</u></strong></a><strong>&nbsp;</strong>(e.g. FSAP)</li></ul><h3>Compliance</h3><ul><li>(60%) <a href=\"https://docs.google.com/document/d/e/2PACX-1vS151CNe9lw6SUqL_vg4MOy_YdMKHs4IUC_54skMC9ixtc8HKXH_Tu2rqw5u4PxhOL_NWzN-HFlOKi1/pub#h.bpryt5r4k1h\"><strong><u>Voluntary compliance may sometimes be higher than mandated compliance</u></strong></a>&nbsp;(e.g. NIH guidelines)</li><li>(70%) <a href=\"https://docs.google.com/document/d/e/2PACX-1vS151CNe9lw6SUqL_vg4MOy_YdMKHs4IUC_54skMC9ixtc8HKXH_Tu2rqw5u4PxhOL_NWzN-HFlOKi1/pub#h.rkpe81okwri4\"><strong><u>Motives for voluntarily following standards include responsibility, market access, and the spread of norms via international training</u></strong></a></li><li>(80%) <a href=\"https://docs.google.com/document/d/e/2PACX-1vS151CNe9lw6SUqL_vg4MOy_YdMKHs4IUC_54skMC9ixtc8HKXH_Tu2rqw5u4PxhOL_NWzN-HFlOKi1/pub#h.i14iz7c0r1do\"><strong><u>Voluntary standards may be easier to internationalise than regulation</u></strong></a></li><li>(90%) <a href=\"https://docs.google.com/document/d/e/2PACX-1vS151CNe9lw6SUqL_vg4MOy_YdMKHs4IUC_54skMC9ixtc8HKXH_Tu2rqw5u4PxhOL_NWzN-HFlOKi1/pub#h.1l7mm1y0xv1u\"><strong><u>Deliberate efforts were made to increase compliance internationally</u></strong></a>&nbsp;(e.g. via funding biosafety associations, offering training and other assistance)</li></ul><h3>Problems with these standards</h3><ul><li>(90%) <a href=\"https://docs.google.com/document/d/e/2PACX-1vS151CNe9lw6SUqL_vg4MOy_YdMKHs4IUC_54skMC9ixtc8HKXH_Tu2rqw5u4PxhOL_NWzN-HFlOKi1/pub#h.decl6afq9l3g\"><strong><u>Bio standards are often list-based</u></strong></a>. This means that they are not comprehensive, do not reflect new threats, prevent innovation in risk management, and fail to recognise the importance of context for risk</li><li>There\u2019s been a partial move away from prescriptive, list-based standards towards holistic, risk-based standards (e.g. ISO 35001)</li><li>(85%) <a href=\"https://docs.google.com/document/d/e/2PACX-1vS151CNe9lw6SUqL_vg4MOy_YdMKHs4IUC_54skMC9ixtc8HKXH_Tu2rqw5u4PxhOL_NWzN-HFlOKi1/pub#h.xmri3sfbqzzu\"><strong><u>Bio standards tend to lack reporting standards, so it\u2019s very hard to tell how effective they are</u></strong></a></li><li>(60%) <a href=\"https://docs.google.com/document/d/e/2PACX-1vS151CNe9lw6SUqL_vg4MOy_YdMKHs4IUC_54skMC9ixtc8HKXH_Tu2rqw5u4PxhOL_NWzN-HFlOKi1/pub#h.3ck8dd6i67xi\"><strong><u>Standards may have impeded safety work in some areas</u></strong></a>&nbsp;(e.g. select agent designation as a barrier to developing mitigation measures)</li><li>(75%) <a href=\"https://docs.google.com/document/d/e/2PACX-1vS151CNe9lw6SUqL_vg4MOy_YdMKHs4IUC_54skMC9ixtc8HKXH_Tu2rqw5u4PxhOL_NWzN-HFlOKi1/pub#h.vvkhoaqy5q4k\"><strong><u>Those implementing standards aren\u2019t always sufficiently high powered</u></strong></a></li><li>(75%) <a href=\"https://docs.google.com/document/d/e/2PACX-1vS151CNe9lw6SUqL_vg4MOy_YdMKHs4IUC_54skMC9ixtc8HKXH_Tu2rqw5u4PxhOL_NWzN-HFlOKi1/pub#h.6z1dyoun0wz3\"><strong><u>Researchers view standards as a barrier to research</u></strong></a></li><li>(90%) <a href=\"https://docs.google.com/document/d/e/2PACX-1vS151CNe9lw6SUqL_vg4MOy_YdMKHs4IUC_54skMC9ixtc8HKXH_Tu2rqw5u4PxhOL_NWzN-HFlOKi1/pub#h.s2q4ldiz4aqi\"><strong><u>The evidence base for bio standards is poor</u></strong></a></li><li>(95%) <a href=\"https://docs.google.com/document/d/e/2PACX-1vS151CNe9lw6SUqL_vg4MOy_YdMKHs4IUC_54skMC9ixtc8HKXH_Tu2rqw5u4PxhOL_NWzN-HFlOKi1/pub#h.i1dcmdci6ftg\"><strong><u>In the US, there is no single body or legislation responsible for bio standards in general</u></strong></a></li><li>Some countries have moved towards a centralised approach (e.g. Canada, China)</li><li>(95%) <a href=\"https://docs.google.com/document/d/e/2PACX-1vS151CNe9lw6SUqL_vg4MOy_YdMKHs4IUC_54skMC9ixtc8HKXH_Tu2rqw5u4PxhOL_NWzN-HFlOKi1/pub#h.q20qofe6v9dk\"><strong><u>Many standards are voluntary rather than legally mandated</u></strong></a>&nbsp;(e.g. BMBL)</li><li>In the US, legal requirements to meet certain standards are a first amendment issue</li><li>(75%) <a href=\"https://docs.google.com/document/d/e/2PACX-1vS151CNe9lw6SUqL_vg4MOy_YdMKHs4IUC_54skMC9ixtc8HKXH_Tu2rqw5u4PxhOL_NWzN-HFlOKi1/pub#h.7zw2f7fxx14p\"><strong><u>There is sometimes a conflict of interest where the same body is responsible for funding research and for assessing its safety</u></strong></a></li></ul><h1>Overview of standards in biosafety and biosecurity</h1><h2>Background</h2><p>There are a lot of different biosafety and biosecurity standards, but at a very high level:</p><ul><li><strong>What bad things are these standards trying to prevent?</strong><ul><li>Biosafety standards are generally trying to protect the safety of lab staff and prevent accidental release.</li><li>Biosecurity standards are generally trying to prevent state or non-state development of bioweapons.</li><li>Other motivations also come up (e.g. plant health, animal health, fair sharing of genetic resources\u2026)</li></ul></li><li><strong>What activities do these standards cover?</strong><ul><li>Who conducts biological research in labs, on what, and how</li><li>The storage, ownership, sale and transportation of biological agents</li></ul></li><li><strong>Do these standards cover all actors undertaking those activities?</strong><ul><li>Laws generally cover all actors undertaking the activities</li><li>Standards are generally voluntary, though some funding bodies make compliance with standards a mandatory condition of funding</li></ul></li></ul><h2>The main standards in biosafety and biosecurity</h2><p>Internationally:</p><ul><li>The Biological Weapons Convention (BWC, 1972) prohibits the development of bioweapons</li><li>The Australia Group (1985) sets standards for the international sale of dual use equipment and transport of pathogens.</li><li>The WHO Laboratory Safety Manual (LBM, 1983) is a voluntary biosafety standard (there is also more recent WHO guidance on biosecurity).</li><li>The ISO 35001 (2019) is a voluntary standard for biosafety and biosecurity (though it\u2019s not clear that there\u2019s much adoption according to a biorisk expert involved in setting this standard up, and the standard is expensive to access).</li></ul><p>In the US:</p><ul><li>The main things are:<ul><li>The Biosafety in Microbiological and Biomedical Laboratories (BMBL, 1984), which is a voluntary standard for laboratory biosafety.</li><li>The select agent regulations, which are mandatory regulations with a statutory basis, and govern who can use particularly dangerous agents and how.</li><li>The NIH Guidelines for Research Involving Recombinant DNA Molecules (1976) are noteworthy for being among the first voluntary standards, though they aren\u2019t very significant today.</li></ul></li><li>There is also more recent voluntary guidance on:<ul><li>DNA synthesis screening (Screening Framework Guidance for Providers of Synthetic Double-Stranded DNA, 2010)</li><li>Dual Use Research of Concern (Policy for Oversight of Life Sciences Dual Use Research of Concern, 2012 and Policy for Institutional Oversight of Dual Use Research of Concern, 2014)</li><li>GoF research (P3CO, 2017)</li></ul></li><li>Also note that there are two bills currently under consideration (see <a href=\"https://centerforhealthsecurity.org/2023/center-for-health-security-applauds-the-introduction-of-2-critical-bills-to-protect-health-security-from-potential-threats-arising-from-advances-in\"><u>here</u></a>&nbsp;for a brief introduction):<ul><li><a href=\"https://www.markey.senate.gov/imo/media/doc/securing_gene_synthesis_act_-_071823pdf.pdf\"><u>Securing Gene Synthesis Act</u></a></li><li><a href=\"https://www.markey.senate.gov/imo/media/doc/artificial_intelligence_and_biosecurity_risk_assessment_act_-_071823pdf.pdf\"><u>Artificial Intelligence and Biosecurity Risk Assessment Act</u></a></li></ul></li></ul><p>Other countries</p><ul><li>China and Russia were both quite slow to develop biosafety standards.<ul><li>The first biosafety regulations in Russia were in 1993.</li><li>China\u2019s first regulations on biosafety in particular were in the early 2000s.</li></ul></li><li>There\u2019s been a move towards overarching biosafety and biosecurity acts which give legislative footing to standards.<ul><li>Canada (2009) and China (2020) both have this.</li><li>Canada has one of the best systems in the world, according to a biorisk expert I spoke with.</li></ul></li></ul><p>The tables below go into more detail. For a full timeline of biosafety and biosecurity standards, see <a href=\"https://docs.google.com/spreadsheets/d/1jH4gVEmDfIz0enzKZztwDVTX_iszjp4-HnmB8vO2qbw/edit#gid=0\"><u>here</u></a>.</p><h3>International standards</h3><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YDTgRR7Qjmj47PaTj/uahnyscif3sbtya6memb\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YDTgRR7Qjmj47PaTj/xvvmvd3wxa3mgbmfs8hb 160w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YDTgRR7Qjmj47PaTj/mjuu2uq7pbvhb2tzwidz 320w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YDTgRR7Qjmj47PaTj/wbxyq7ku8wxhraz5dtsw 480w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YDTgRR7Qjmj47PaTj/rfkjt2j6gzgdbqubdnk6 640w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YDTgRR7Qjmj47PaTj/zyriimwoyc45h2pdsajf 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YDTgRR7Qjmj47PaTj/iou1mxveav7woyjl36ry 960w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YDTgRR7Qjmj47PaTj/zldrmhtoznbhem8mtvhe 1120w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YDTgRR7Qjmj47PaTj/qgd1tq7cwzejzsgag3ay 1280w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YDTgRR7Qjmj47PaTj/ls3vna2niyotuwkwxv5z 1440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YDTgRR7Qjmj47PaTj/fplrffh0jt5memgelbgl 1576w\"></figure><h3>US standards</h3><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YDTgRR7Qjmj47PaTj/dc35bnvukvahhbylpbut\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YDTgRR7Qjmj47PaTj/aj2widgzkdpnrfrdb3ly 160w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YDTgRR7Qjmj47PaTj/bodmu8tparuc1mp2koda 320w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YDTgRR7Qjmj47PaTj/evfihrl1wydhgbrbdxpm 480w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YDTgRR7Qjmj47PaTj/hibtrlkaggmggpt7cth9 640w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YDTgRR7Qjmj47PaTj/efsvhxp4bmj4jrhc9ras 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YDTgRR7Qjmj47PaTj/zrfixcxyhejnw1zkvo1q 960w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YDTgRR7Qjmj47PaTj/mnrenym7ku9uisvc3bgf 1120w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YDTgRR7Qjmj47PaTj/mz90zvcvhocrtmyfg0yt 1280w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YDTgRR7Qjmj47PaTj/utj0hhwuuzwuxt6sovxu 1440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YDTgRR7Qjmj47PaTj/ljzzu0cpgz2bkk5gyoej 1564w\"></figure><h3>Notable standards in other countries</h3><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YDTgRR7Qjmj47PaTj/cdvt2vppnzprdtfreocv\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YDTgRR7Qjmj47PaTj/jtifm1mm5mftj6egmbva 160w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YDTgRR7Qjmj47PaTj/onktsj2ckntsmn6pvht4 320w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YDTgRR7Qjmj47PaTj/xn0otfbxlipaxe6szwns 480w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YDTgRR7Qjmj47PaTj/koslwhircjtbskpby3fb 640w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YDTgRR7Qjmj47PaTj/sydyad6nuyy9ki36uudb 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YDTgRR7Qjmj47PaTj/ckio99ete6ygu139q0du 960w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YDTgRR7Qjmj47PaTj/psigjcwfto5yhmzipbur 1120w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YDTgRR7Qjmj47PaTj/kk5eb0yutqiqm7ktgywj 1280w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YDTgRR7Qjmj47PaTj/icuo76inybvvtkxidsi2 1440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YDTgRR7Qjmj47PaTj/kg881nuwpkke8qkmjwce 1582w\"></figure><h1>The origins of biosafety and biosecurity standards</h1><p>Questions from Holden\u2019s <a href=\"https://forum.effectivealtruism.org/posts/idrBxfsHkYeTtpm2q/seeking-paid-case-studies-on-standards%23What_I_m_looking_for_in_case_studies\"><u>call</u></a> this section relates to:</p><ul><li><i>What\u2019s the history of the standard? How did it get started?</i></li><li><i>How did we get from the beginnings to where we are today?</i></li><li><i>If a standard aims to reduce risks, to what extent did the standard get out ahead of/prevent risks, as opposed to being developed after relevant problems had already happened?</i></li><li><i>Was there any influence of early voluntary standards on later government regulation?</i></li></ul><h2>There were many different motivations behind bio standards</h2><p>At a high level:</p><ul><li>Biosafety standards are generally trying to protect the safety of lab staff and prevent accidental release.</li><li>Biosecurity standards are generally trying to prevent state or non-state development of bioweapons.</li></ul><p>But other motivations have also led to standards with a bearing on biological research. For example:</p><ul><li><strong>Worker safety</strong>: in the US, the <a href=\"https://en.wikipedia.org/wiki/Occupational_Safety_and_Health_Act_(United_States)\"><u>Occupational Safety and Health Act (OSHA)</u></a>&nbsp;of 1970 was motivated by worker safety in general, but some of its provisions were relevant to biological research.</li><li><strong>Plant protection</strong>: one of the earliest relevant standard-setting organisations was the <a href=\"https://en.wikipedia.org/wiki/International_Plant_Protection_Convention\"><u>International Plant Protection Convention (IPPC)</u></a>, founded in 1951. Some of their standards impact biological research involving plants.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefiy5rdjdwe8f\"><sup><a href=\"#fniy5rdjdwe8f\">[2]</a></sup></span></li><li><strong>Animal health</strong>: the World Organization for Animal Health (OIE) sets standards relating to animal health and zoonoses as well as animal welfare, animal production, and food safety.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefqqconh5rqoe\"><sup><a href=\"#fnqqconh5rqoe\">[3]</a></sup></span></li><li><strong>Fair sharing of genetic resources</strong>: the Nagoya Protocol on Access to Genetic Resources and the Fair and Equitable Sharing of Benefits Arising from their Utilization to the Convention on Biological Diversity of 2011 was not motivated by concerns about biosafety or biosecurity, but its provisions imply full traceability on the access and use of some biological materials (genetic resources).<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefaiov15qowgg\"><sup><a href=\"#fnaiov15qowgg\">[4]</a></sup></span></li></ul><h2>Standards were significantly reactive rather than proactive</h2><p>Standards have been significantly reactive to:</p><ul><li><strong>Lab accidents</strong><ul><li>I haven\u2019t found evidence of lab accidents being a direct cause of particular biosafety standards, but it is the case that both harm to workers and accidental release from labs were happening before standards were introduced, so the standards were not pre-emptive.</li></ul></li><li><strong>Terrorist attacks</strong>, in the case of biosecurity<ul><li>In the US, the select agent regulations were first established via the Antiterrorism and Effective Death Penalty Act (1996). The act overall was in significant part a reaction to the Oklahoma City bombing of 1995.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefip56uancwu\"><sup><a href=\"#fnip56uancwu\">[5]</a></sup></span>&nbsp;The select agent provisions in particular were in part a response to another incident in 1995, where white supremicist Larry Wayne Harris successfully ordered Yersinia pestis by mail.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefrnreqo8092\"><sup><a href=\"#fnrnreqo8092\">[6]</a></sup></span></li><li>9/11 and Amerithrax prompted the PATRIOT Act (2001) and the Bioterrorism Act (2002), which led to the establishment of FSAP in its current form in 2003.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefqjeabtkcwy9\"><sup><a href=\"#fnqjeabtkcwy9\">[7]</a></sup></span></li></ul></li><li><strong>Epidemics</strong><ul><li>The SARS outbreak 2002-2005 and the perceived inadequacy of the WHO response may have sped up the revision of the IHR in 2005 and influenced the revisions themselves.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefz2xokipkqw\"><sup><a href=\"#fnz2xokipkqw\">[8]</a></sup></span></li><li>SARS is cited as an important motivation for Chinese biosafety regulations.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref0wpyhcx4evph\"><sup><a href=\"#fn0wpyhcx4evph\">[9]</a></sup></span></li></ul></li></ul><p>However:</p><ul><li>There are exceptions, where standards were developed in anticipation of potential risks.<ul><li>The most notable example is the NIH Guidelines for Research Involving Recombinant DNA Molecules, which were developed in anticipation of low probability extreme risks.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefjhrma97gqdm\"><sup><a href=\"#fnjhrma97gqdm\">[10]</a></sup></span></li></ul></li><li>Guidance is often more proactive than standards.<ul><li>For example, there was guidance on gene drives before they were successfully built, but there still aren\u2019t standards, according to one biorisk expert.</li></ul></li></ul><h2>International standards weren\u2019t always later or less influential than national ones</h2><ul><li>The WHO LBM (1983) was published a year before the US BMBL (1984).</li><li>There are examples of international standards prompting/informing national ones:<ul><li>The US select agent list was based on the Australia group list.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefnit21aud5u\"><sup><a href=\"#fnnit21aud5u\">[11]</a></sup></span></li><li>One motivation behind China\u2019s biosafety legislation has been compliance with the international treaties it is member to.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefgvv5sumnz6f\"><sup><a href=\"#fngvv5sumnz6f\">[12]</a></sup></span></li></ul></li><li>There is competition between the WHO LBM and the BMBL.<ul><li>According to one biorisk expert I spoke with, this increases the risk of confusion and gaps, and happened because the US rushed ahead of the rest of the world, who weren\u2019t willing/able to follow.</li><li>According to two biorisk experts I spoke with, it\u2019s useful to have international standards as some countries will never adopt US standards on principle.</li></ul></li></ul><h2>Voluntary standards seem to have prevented regulation in at least one case</h2><p>The NIH guidelines were widely seen by critics and proponents as preventing future regulation, and this was one of the key motivations of the scientists who organised the research pause and Asilomar.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefre8rfy6soei\"><sup><a href=\"#fnre8rfy6soei\">[13]</a></sup></span>&nbsp;</p><h2>In the US, it may be more likely that mandatory standards are passed on matters of national security</h2><p>Most bio related standards are voluntary in the US, with the exception of FSAP. According to an expert in standards I spoke with, one of the reasons this was practicable was that there\u2019s federal authority over national security.</p><h1>Compliance</h1><p>Question from Holden\u2019s <a href=\"https://forum.effectivealtruism.org/posts/idrBxfsHkYeTtpm2q/seeking-paid-case-studies-on-standards%23What_I_m_looking_for_in_case_studies\"><u>call</u></a>&nbsp;this section relates to: \u201c<i>What sorts of companies (and how many/what percentage of relevant companies) comply with what standards, and what are the major reasons they do so?\u201d</i></p><h2>Voluntary compliance may sometimes be <i>higher</i>&nbsp;than mandated compliance</h2><p>In the case of the NIH guidelines, compliance may have been higher among commercial companies (who complied voluntarily) than among NIH-funded bodies (who were mandated to comply as a condition of their funding):<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefjfmn3t0jf7j\"><sup><a href=\"#fnjfmn3t0jf7j\">[14]</a></sup></span></p><ul><li>Paul Berg, one of the organisers of Asilomar, believed this was the case.</li><li>Commercial companies likely had access to more resources and were more concerned by liability than academic counterparts.</li></ul><h2>Motives for voluntarily following standards include responsibility, market access, and the spread of norms via international training</h2><p>I formed this impression from talking with a biorisk expert, and a biologist involved in setting up the Asilomar conference.</p><h2>Voluntary standards may be easier to internationalise than regulation</h2><p>Countries\u2019 legal systems differ, and law is often slow and costly to enact. But voluntary standards can be adopted more quickly.</p><p>Examples of voluntary standards being adopted internationally:</p><ul><li>The WHO LBM is used internationally. To my knowledge, there are no equivalent internationally adopted laws on lab biosafety.</li><li>The US BMBL, Canadian Biosafety Standard (CBS) and AU/NZ standards are also all used internationally.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref9ro6gixhj8l\"><sup><a href=\"#fn9ro6gixhj8l\">[15]</a></sup></span></li><li>Recombinant DNA:<ul><li>The 1974 voluntary pause on recombinant DNA research pause was observed internationally.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref4dn6zuqpldn\"><sup><a href=\"#fn4dn6zuqpldn\">[16]</a></sup></span></li><li>Scientists from all over the world were invited to Asilomar in 1975. According to one of the conference organisers, those people went back to their countries and helped set up regulatory regimes which were consistent with the Asilomar recommendations. The conference organiser believes that no countries deviated from these recommendations apart from Russia as part of their bioweapons programme.</li></ul></li></ul><h2>Deliberate efforts were made to increase compliance internationally</h2><p>According to a biorisk expert I spoke with, part of why biosafety compliance is high internationally is that a lot of funding was put into building regional and national biosafety associations. This expert says that the motivation for this was non-proliferation of dangerous biological agents.</p><p>Examples of deliberate efforts to increase compliance:</p><ul><li>According to the same expert, Trevor Smith at Global Affairs Canada and the US DoD and State Department have provided a lot of funding for regional biosafety associations.</li><li>The Canadian Association for Biological Safety assisted Russia to train instructors for biosafety programmes in 2008. Canada has also been involved in other assistance with improving Russian standards, and in translating US and WHO biosafety guidelines into Russian.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref8sx3j1cpih\"><sup><a href=\"#fn8sx3j1cpih\">[17]</a></sup></span></li></ul><h1>Problems with biosafety and biosecurity standards</h1><p>Question from Holden\u2019s <a href=\"https://forum.effectivealtruism.org/posts/idrBxfsHkYeTtpm2q/seeking-paid-case-studies-on-standards%23What_I_m_looking_for_in_case_studies\"><u>call for proposals</u></a>&nbsp;which this section relates to: <i>Does the standard currently seem to achieve its intended purpose? To the extent it seeks to reduce risks, is there a case that it\u2019s done so?</i></p><h2>Bio standards are often list-based</h2><p>Many bio standards are based on lists of agents to which different standards of safety and security apply. There are a number of possible problems with this approach:</p><ul><li>Lists aren\u2019t comprehensive.</li><li>Lists don\u2019t automatically cover emerging threats.<ul><li>According to a biorisk expert I spoke with, the ability to make new structures (especially in future with AI) makes list-based approaches particularly inappropriate for biological research.</li></ul></li><li>List-based approaches tend towards tick-box exercises and may mitigate against careful thinking and innovation in risk management.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreforkfjk8jmcg\"><sup><a href=\"#fnorkfjk8jmcg\">[18]</a></sup></span></li><li>According to a biorisk expert I spoke with, list-based approaches often impose standards independently of context, when scientists know that there\u2019s a big difference in risk depending on where and how the research is conducted.</li></ul><p>There\u2019s been a partial move away from prescriptive, list-based standards towards holistic, risk-based standards. The ISO 35001 is an example of this.</p><h2>Bio standards tend to lack reporting standards, so it\u2019s very hard to tell how effective they are</h2><ul><li>Biorisk expert: \u201cMy main hot take is a lot of this field is flying ~blind due to the absence of any outcome data (e.g. how many incidents per X lab year or equivalent). The main push I advocate for is reporting standards rather than guessing what may or may not help (then having little steer post implementation whether you've moved the needle).\u201d</li><li>Palmer et al, 2015: criticises underdeveloped metrics<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref39qp85jkgbl\"><sup><a href=\"#fn39qp85jkgbl\">[19]</a></sup></span></li><li>Farquhar et al: calls for centrally commission absolute risk assessments<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefofk1vr09m6i\"><sup><a href=\"#fnofk1vr09m6i\">[20]</a></sup></span></li></ul><h2>Standards may have impeded safety work in some areas</h2><p>For example, some scientists have argued that&nbsp;in the US, select agent designation creates a barrier to developing mitigation measures.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref9qw0wkxi4sk\"><sup><a href=\"#fn9qw0wkxi4sk\">[21]</a></sup></span></p><h2>Those implementing standards aren\u2019t always sufficiently high powered</h2><ul><li>According to a biorisk expert, biosafety isn\u2019t sufficiently integrated with senior management .<ul><li>This expert was involved in setting up the ISO standard, and says that one of the aims of the ISO standard is to address this.</li></ul></li><li>According to a biorisk expert I spoke with, biosafety compliance in the US defaults to something list-based even though the standards themselves are risk-based, because the inspection workforce isn\u2019t sophisticated enough for a more consultative approach as in the UK<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefkd1s0gwzfpb\"><sup><a href=\"#fnkd1s0gwzfpb\">[22]</a></sup></span>&nbsp;or Canada.</li></ul><h2>Researchers view standards as a barrier to research</h2><ul><li>According to a biorisk expert</li><li>They also note that currently biosafety isn\u2019t a technical field in its own right where you can publish papers and make spin-off companies</li></ul><h2>The evidence base for bio standards is poor</h2><p>According to a biorisk expert, there often isn\u2019t good evidence that a particular standard is risk reducing. This seems like a somewhat structural problem, related to:</p><ul><li>The fact that <a href=\"https://docs.google.com/document/d/e/2PACX-1vS151CNe9lw6SUqL_vg4MOy_YdMKHs4IUC_54skMC9ixtc8HKXH_Tu2rqw5u4PxhOL_NWzN-HFlOKi1/pub#h.xmri3sfbqzzu\"><u>standards tend to lack reporting standards</u></a></li><li>It being hard to test low probability extreme risks experimentally.</li></ul><h2>In the US, there is no single body or legislation responsible for bio standards in general</h2><p>According to a US biorisk expert I spoke with, this leads to gaps in what\u2019s regulated and a lack of leadership.</p><p>Some countries have moved towards a centralised approach, for example Canada (Human Pathogen and Toxins Act 2009) and China (Biosafety/Biosecurity Law 2020).</p><h2>Many standards are voluntary rather than legally mandated</h2><p>Examples:</p><ul><li>Internationally: the WHO LBM, the Australia Group export controls, ISO 35001</li><li>In the US: the NIH guidelines on recombinant DNA, the BMBL, PC30</li></ul><p>The upshot of this is that it\u2019s perfectly legal for example for a rich person in the US to build pathogenic flu in their basement, as long as it\u2019s for peaceful purposes.</p><h2>There is sometimes a conflict of interest where the same body is responsible for funding research and for assessing its safety</h2><p>Examples:</p><ul><li>The NIH guidelines on Recombinant DNA 1976 (issued by NIH and applied to NIH fundees)<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref9n89o2t527d\"><sup><a href=\"#fn9n89o2t527d\">[23]</a></sup></span></li><li>Policy for Oversight of Life Sciences Dual Use Research of Concern 2012 (issued by HHS and applied to HHS fundees)</li><li>Policy for Institutional Oversight of Dual Use Research of Concern 2014 (issued by HHS and applied to HHS fundees)</li><li>Framework for Guiding Funding Decisions about Proposed Research Involving Enhanced Potential Pandemic Pathogens (P3CO) 2017 (issued by HHS and applied to HHS fundees)</li></ul><h1>Questions this report doesn\u2019t address</h1><p>Holden\u2019s call for proposal lists a <a href=\"https://forum.effectivealtruism.org/posts/idrBxfsHkYeTtpm2q/seeking-paid-case-studies-on-standards%23What_I_m_looking_for_in_case_studies\"><u>series of questions</u></a>&nbsp;which he\u2019s interested in answers to. This report gives partial answers to some of those questions above, and doesn\u2019t address the following questions at all:</p><ul><li>How is the standard implemented today? Who writes it and revises it, and what does that process look like?</li><li>How involved are/were activists/advocates/people who are explicitly focused on public benefit rather than profits in setting standards? How involved are companies? How involved are people with reputations for neutrality?</li><li>Are there audits required to meet a standard?</li><li>If so, who does the audits, and how do they avoid being gamed?</li><li>How much access do they get to the companies they\u2019re auditing?</li><li>How good are the audits? How do we know?</li><li>What other measures are taken to avoid standards being \u201cgamed\u201d and ensure that whatever risks they\u2019re meant to protect against are in fact protected against?</li><li>How costly and difficult is it to comply with the standards?</li><li>What happens if a company stops complying?</li></ul><h1>(Very) select bibliography</h1><p>I haven\u2019t made a proper bibliography.</p><p>This <a href=\"https://docs.google.com/spreadsheets/d/1jH4gVEmDfIz0enzKZztwDVTX_iszjp4-HnmB8vO2qbw/edit#gid=0\">biorisk standards timeline</a> contains information on all of the standards mentioned in this report, with quotes and links. I\u2019d recommend it as a reference.</p><p>Some useful background articles:</p><ul><li>Connell, \u2018<a href=\"https://pubs.fas.org/pir/2011fall/2011fall-bioagents.pdf\"><u>Biologic agents in the laboratory\u2014the regulatory issues</u></a>\u2019, Federation of American Scientists, 2011.</li><li>Salerno and Gaudioso, \u2018<a href=\"https://www.researchgate.net/publication/276294176_Laboratory_Biorisk_Management_Biosafety_and_Biosecurity\"><u>Introduction: The Case for Biorisk Management\u2019</u></a>, in Salerno and Gaudioso (eds), Laboratory biorisk management: biosafety and biosecurity, 2015.</li><li>Beeckman and R\u00fcdelsheim, \u2018<a href=\"https://www.frontiersin.org/articles/10.3389/fbioe.2020.00650/full\"><u>Biosafety and Biosecurity in Containment: A Regulatory Overview</u></a>\u2019, Frontiers in Bioengineering and Biotechnology, 2020.</li></ul><p>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnzlsmt765os\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefzlsmt765os\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;WHO definitions, quoted from Connell, \u2018<a href=\"https://pubs.fas.org/pir/2011fall/2011fall-bioagents.pdf\"><u>Biologic agents in the laboratory\u2014the regulatory issues</u></a>\u2019, Federation of American Scientists, 2011.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fniy5rdjdwe8f\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefiy5rdjdwe8f\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201c[T]he International Plant Protection Convention (IPPC) in 1951, a multilateral treaty deposited with the Food and Agriculture Organization of the United Nations (FAO). The IPPC is the standard setting organization for the \u201cAgreement on the Application of Sanitary and Phytosanitary Measures\u201d (the SPS Agreement) of the World Trade Organization (WTO). Specific \u201cInternational Standards for Phytosanitary Measures\u201d (ISPMs) cover topics such as lists of quarantine organisms, pest risk analysis, or the design of plant quarantine stations, all of which are relevant when applying plant pests under containment in a laboratory or plant growing facility (FAO/IPPC, 2019a).\u201d Beeckman and R\u00fcdelsheim, \u2018<a href=\"https://www.frontiersin.org/articles/10.3389/fbioe.2020.00650/full\"><u>Biosafety and Biosecurity in Containment: A Regulatory Overview</u></a>\u2019, Frontiers in Bioengineering and Biotechnology, 2020.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnqqconh5rqoe\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefqqconh5rqoe\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201c[T]he World Organization for Animal Health (OIE - Office International des Epizooties, est. 1924) is since 1998 the WTO reference organization for standards relating to animal health and zoonoses (WTO, 2019). The \u201cTerrestrial Animal Health Code\u201d and \u201cAquatic Animal Health Code\u201d were developed with the aim of assuring the sanitary safety of international trade in terrestrial animals and aquatic animals, respectively, as well as their products. Traditionally addressing animal health and zoonoses only, these codes have been expanded to also cover animal welfare, animal production, and food safety in recent updates (OIE, 2019).\u201d Beeckman and R\u00fcdelsheim, \u2018<a href=\"https://www.frontiersin.org/articles/10.3389/fbioe.2020.00650/full\"><u>Biosafety and Biosecurity in Containment: A Regulatory Overview</u></a>\u2019, Frontiers in Bioengineering and Biotechnology, 2020.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnaiov15qowgg\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefaiov15qowgg\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cThe \u201cNagoya Protocol on Access to Genetic Resources and the Fair and Equitable Sharing of Benefits Arising from their Utilization to the Convention on Biological Diversity\u201d (SCBD, 2011) states that when benefits (either monetary or non-monetary) are arising from the utilization of genetic resources (e.g., in research) as well as during subsequent commercialization, that these benefits \u201cshall be shared in a fair and equitable way with the Party providing such resources that is the country of origin of such resources or a Party that has acquired the genetic resources in accordance with the Convention\u201d. Although in principle not related to biosafety, the Nagoya Protocol implies that full traceability on when and where a certain genetic resource (i.e., biological material, or in some case arguably even digital sequence information) was first accessed, as well as how it was subsequently used, is maintained.\u201d Beeckman and R\u00fcdelsheim, \u2018<a href=\"https://www.frontiersin.org/articles/10.3389/fbioe.2020.00650/full\"><u>Biosafety and Biosecurity in Containment: A Regulatory Overview</u></a>\u2019, Frontiers in Bioengineering and Biotechnology, 2020.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnip56uancwu\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefip56uancwu\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;See \u2018Historical origins of current biosecurity regulations\u2019 in Zelicoff, \u2018<a href=\"https://www.sciencedirect.com/science/article/pii/B9780128018859000019?ref%3Dpdf_download%26fr%3DRR-2%26rr%3D7db3d3682c437306\"><u>Laboratory biosecurity in the United States: Evolution and regulation</u></a>\u2019, Ensuring National Biosecurity, 2016.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnrnreqo8092\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefrnreqo8092\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cA former Aryan Nations member illegally obtained a bacterium that causes plague (Yersinia pestis) by mail order. As a result, Congress passed Section 511 of the Antiterrorism and Effective Death Penalty Act of 1996 requiring HHS to publish regulations for the transfers of select agents that have the potential to pose a severe threat to public health and safety (Additional Requirements for Facilities Transferring or Receiving Select Agents, 42 CFR Part 72.6; effective April 15, 1997).\u201d <a href=\"https://www.selectagents.gov/overview/history.htm\"><u>https://www.selectagents.gov/overview/history.htm</u></a>&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnqjeabtkcwy9\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefqjeabtkcwy9\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cFollowing the anthrax attacks of 2001 that resulted in five deaths, Congress significantly strengthened oversight of select agents by passing the USA PATRIOT Act in 2001 and the Public Health Security and Bioterrorism Preparedness and Response Act of 2002 requiring HHS &amp; USDA to publish regulations for possession, use, and transfer of select agents (Select Agent Regulations, 7 CFR Part 331, 9 CFR Part 121, and 42 CFR Part 73; effective February 7, 2003).\u201d <a href=\"https://www.selectagents.gov/overview/history.htm\"><u>https://www.selectagents.gov/overview/history.htm</u></a>&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnz2xokipkqw\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefz2xokipkqw\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201c\u201cPerhaps the most important legacy of the SARS epidemic, and to a lesser extent the H5N1 outbreak, was the sense of urgency it gave to finalising the updates to the 1969 International Health Regulations (IHRs)...Arguably, as a direct result of perceived reluctance on the part of the Chinese authorities to be transparent in the early stages of the SARS outbreak, the revised IHRs state that the WHO can collect, analyse and use information \u201cother than notifications or consultations\u201d including from intergovernmental organisations, nongovernmental organisations and actors, and the Internet.\u201d McLeish, \u2018<a href=\"https://link.springer.com/content/pdf/10.1057/978-1-137-53675-4_4.pdf?pdf%3Dcore\"><u>Evolving Biosecurity Frameworks</u></a>\u2019, in Dover, Goodman and Dylan (eds), <i>Palgrave Handbook on Intelligence and Security Studies</i>, 2017.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn0wpyhcx4evph\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref0wpyhcx4evph\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cReferences in the literature and presentations at regional symposia refer to the SARS outbreak and resulting laboratory-acquired infections as the prime motivator for implementing legislation, developing enhanced safety programs, and constructing modern containment laboratories that meet or exceed international guidelines. To avoid the recurrence of biological risks posed by SARS and MERS, China has also learned from the experience of other countries and organisations, with the BMBL being one main knowledge resources.\u201d Johnson and Casagrande, \u2018<a href=\"https://www.liebertpub.com/doi/full/10.1177/1535676016661772\"><u>Comparison of International Guidance for Biosafety Regarding Work Conducted at Biosafety Level 3 (BSL-3) and Gain-ofFunction (GOF) Experiments</u></a>\u2019, Applied Biosafety, 2016.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnjhrma97gqdm\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefjhrma97gqdm\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Shortly after recombinant DNA became technologically possible, scientists self-organised a pause on all research involving recombinant DNA until the potential risks were better understood. The Asilomar conference (1975) brought together the relevant scientists internationally and recommended a gradual introduction of recombinant DNA research with review for potential risks. These recommendations were taken up by the NIH who issued their Guidelines for Research Involving Recombinant DNA Molecules in 1976. Both the research pause and the spirit of the Asilomar recommendations were widely followed internationally, according to one of the conference organisers. As it transpired that recombinant DNA research was <i>not </i>particularly risky, the guidelines were gradually relaxed, as their instigators had intended. See Grace, \u2018<a href=\"https://intelligence.org/files/TheAsilomarConference.pdf\"><u>The Asilomar Conference: A Case Study in Risk Mitigation</u></a>\u2019, MIRI, 2015 for an introduction.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnnit21aud5u\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefnit21aud5u\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cThe original BSATs were selected (i.e., Select Agents) from the Australia Group List of Human and Animal Pathogens and Toxins for Export Control (Australia Group List, 2014) with input from experts from inside and outside the government.\u201d Morse, \u2018<a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4285169/\"><u>Pathogen Security - Help or Hindrance?</u></a>\u2019, Frontiers in Bioengineering and Biotechnology, 2014.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fngvv5sumnz6f\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefgvv5sumnz6f\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cBiosecurity legislation in China started comparatively late and the relevant legislation was largely driven by China joining international conventions\u201d. Qiu and Hu, \u2018<a href=\"https://www.liebertpub.com/doi/full/10.1089/blr.2020.29217.mh\"><u>Legislative Moves on Biosecurity in China</u></a>\u2019,</p><p>Biotechnology Law Report, 2021.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnre8rfy6soei\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefre8rfy6soei\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cIt is often suggested (by both attendees and critics) that a large motive of the Asilomar Conference\u2019s attendees was to avoid regulation of their new technology by outsiders.\u201d Grace, \u2018<a href=\"https://intelligence.org/files/TheAsilomarConference.pdf\"><u>The Asilomar Conference: A Case Study in Risk Mitigation</u></a>\u2019, MIRI, 2015. One of the organisers told me in a call that the Asilomar recommendations were partly a defensive manoeuvre to prevent the issue from being handed to the public or Congress.</p><p>\u201cThe RAC's existence obviated the need for more restrictive governmental legislation\u201d. Wivel, \u2018<a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3900000/\"><u>Historical Perspectives Pertaining to the NIH Recombinant DNA Advisory Committee</u></a>\u2019, Human Gene Therapy, 2014.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnjfmn3t0jf7j\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefjfmn3t0jf7j\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cMany people were critical of the guidelines because the guidelines were only imposed on those who had funding from the federal government, and so did not impact the commercial sector. There was a lot of concern whether the industry was going to bypass the constraints, as mild as they were. Berg never worried about industry. As it turned out, industry conformed more so than almost any academic center. \u201cBerg believes, and thinks many of his colleagues agreed, that the commercial sector would be at great risk if they obviously and openly flaunted the guidelines because their plants and research labs are in amongst communities. Furthermore, it would be to their considerable detriment if their local communities learned that any of their recombinant DNA experiments could be dangerous. Berg speculates that they would have been picketed and closed down if it became known that they had avoided the guidelines. It was much more economically feasible for them to build the most secure facilities that anybody can think of.\u201d\u201d Interior quote from a conversation between Grace and Berg. Grace, \u2018<a href=\"https://intelligence.org/files/TheAsilomarConference.pdf\"><u>The Asilomar Conference: A Case Study in Risk Mitigation</u></a>\u2019, MIRI, 2015.</p><p>\u201cMany people thought the commercial sector would be a problem because the guidelines were not imposed on them, so they were at liberty to ignore them. This was not the case: the commercial sector had strong incentives to follow the guidelines, and more money to invest in safety than academia had. Consequently, they heeded the guidelines more rigorously than most academic organizations.\u201d Grace, \u2018<a href=\"https://intelligence.org/files/TheAsilomarConference.pdf\"><u>The Asilomar Conference: A Case Study in Risk Mitigation</u></a>\u2019, MIRI, 2015.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn9ro6gixhj8l\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref9ro6gixhj8l\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cThere is a lack of European-wide harmonized practical guidance on how to implement the European Directives on biological agents and GMMs. A few EU Member States have developed their own national guidance based on the EC Directives. In other cases, these gaps are filled by e.g. US Biosafety in Microbiological and Biomedical Laboratories (BMBL) and Canadian guidelines\u201d. \u201cBSL-3 laboratories and safety programs in Hong Kong are regularly if not annually certified by independent third-party certifiers using criteria established in the BMBL or AU/NZ BSL-3 standards.\u201d \u201cTo avoid the recurrence of biological risks posed by SARS and MERS, China has also learned from the experience of other countries and organizations, with the BMBL being one main knowledge resources.\u201d Johnson and Casagrande, \u2018<a href=\"https://www.liebertpub.com/doi/full/10.1177/1535676016661772\"><u>Comparison of International Guidance for Biosafety Regarding Work Conducted at Biosafety Level 3 (BSL-3) and Gain-ofFunction (GOF) Experiments</u></a>\u2019, Applied Biosafety, 2016.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn4dn6zuqpldn\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref4dn6zuqpldn\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cWhile there was some disagreement about this action, the moratorium was universally adhered to.\u201d Grace, \u2018<a href=\"https://intelligence.org/files/TheAsilomarConference.pdf\"><u>The Asilomar Conference: A Case Study in Risk Mitigation</u></a>\u2019, MIRI, 2015. One of the organisers also said this to me in a call.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn8sx3j1cpih\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref8sx3j1cpih\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cIn 2008, Russia received assistance from the Canadian Association for Biological Safety to train instructors for biosafety programs. WHO and US biosafety documents were translated and used for training purposes\u201d. \u201cThrough this partnership [the Global Partnership Against the Spread of Weapons and Materials of Mass Destruction], Canada provided Russia assistance in improving biosafety and biosecurity standards. Canada has translated biosafety training programs and documents into Russian for more widespread use\u201d. <a href=\"https://web.archive.org/web/20161109085425/http://www.upmchealthsecurity.org/our-work/pubs_archive/pubs-pdfs/2016/Combined%2520Biosafety%2520Case%2520Studies%2520final%2520draft%2520062116.pdf\"><u>National biosafety systems: Case studies to analyze current biosafety approaches and regulations for Brazil, China, India, Israel, Pakistan, Kenya, Russia, Singapore, the United Kingdom, and the United States</u></a>, UPMC Center for Health Security, 2016.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnorkfjk8jmcg\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreforkfjk8jmcg\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cWe believe that the bioscience community depends too heavily on predefined solutions sets, known as agent risk groups, biosafety levels, and biosecurity regulations. This dependence has relegated laboratory biosafety and biosecurity to the administrative basements of bioscience facilities. These generic agent risk groups, biosafety levels, and biosecurity regulations have almost eliminated the pursuit of the intellectually rigorous, risk-based assessments and solutions of the 1960s\u2014when the field was in its infancy. Instead, we now often have complacency in laboratory biosafety and biosecurity, and the general absence of comprehensive management systems to mitigate these risks\u201d. Salerno and Gaudioso, \u2018<a href=\"https://www.researchgate.net/publication/276294176_Laboratory_Biorisk_Management_Biosafety_and_Biosecurity\"><u>Introduction: The Case for Biorisk Management\u2019</u></a>, in Salerno and Gaudioso (eds), <i>Laboratory biorisk management: biosafety and biosecurity</i>, 2015.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn39qp85jkgbl\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref39qp85jkgbl\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Dettmann, Ritterson, Lauer and Casagrande, \u2018<a href=\"https://www.liebertpub.com/doi/10.1089/hs.2022.0074\"><u>Concepts to Bolster Biorisk Management\u2019</u></a>, Health Security, 2022.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnofk1vr09m6i\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefofk1vr09m6i\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Dettmann, Ritterson, Lauer and Casagrande, \u2018<a href=\"https://www.liebertpub.com/doi/10.1089/hs.2022.0074\"><u>Concepts to Bolster Biorisk Management\u2019</u></a>, Health Security, 2022.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn9qw0wkxi4sk\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref9qw0wkxi4sk\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cin a 2010 Perspectives piece in Nature Reviews Microbiology by Casadevall and Relman, the authors question the utility of the SATL and highlight the following paradox: if an agent lacks countermeasures, it is more likely to be included on the SATL; yet the increased regulatory burden placed on research with the agent might in turn prevent the discovery and development of effective countermeasures.\u201d Connell, \u2018<a href=\"https://pubs.fas.org/pir/2011fall/2011fall-bioagents.pdf\"><u>Biologic agents in the laboratory\u2014the regulatory issues</u></a>\u2019, Federation of American Scientists, 2011.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnkd1s0gwzfpb\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefkd1s0gwzfpb\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cBiosafety officers receive accreditation from the Institute of Safety in Technology and Research (ISTR), which is a membership organization in the UK for safety professional\u201d. Gronvall, Shearer and Collins, \u2018<a href=\"https://web.archive.org/web/20161109085425/http://www.upmchealthsecurity.org/our-work/pubs_archive/pubs-pdfs/2016/Combined%2520Biosafety%2520Case%2520Studies%2520final%2520draft%2520062116.pdf\"><u>National biosafety systems: Case studies to analyze current biosafety approaches and regulations for Brazil, China, India, Israel, Pakistan, Kenya, Russia, Singapore, the United Kingdom, and the United States</u></a>\u2019, UPMC Center for Health Security, 2016.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn9n89o2t527d\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref9n89o2t527d\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cThe RAC has created another unusual conundrum concerning conflict of interest (Walters, 1991). As it exists, the RAC is an advisory committee to the NIH and was originally charged with fulfilling its role in a critical and independent manner. Yet the RAC sponsor is the chief funding agency for biomedical research in the United States. This has thrust the agency into the position of funding research on the one hand and simultaneously conducting quasi-regulatory oversight on certain aspects of that research. However, an objective observer would have to say that the two areas of responsibility have been carried out with no evidence of significant compromise.\u201d Wivel, \u2018<a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3900000/\"><u>Historical Perspectives Pertaining to the NIH Recombinant DNA Advisory Committee</u></a>\u2019, Human Gene Therapy, 2014.</p></div></li></ol>", "user": {"username": "rosehadshar"}}, {"_id": "S4f2wvw6HBioWzXCy", "title": "AGI Takeoff dynamics - Intelligence vs Quantity explosion ", "postedAt": "2023-07-26T09:20:58.914Z", "htmlBody": "<p><i>tl;dr: AGI takeoff could either start by agent self-improvement (intelligence explosion) or by duplication and acquiring more resources (\"quantity explosion\"). Model from economic growth theory may shed light on what's more likely.&nbsp;</i></p><figure class=\"image image_resized\" style=\"width:85.83%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/S4f2wvw6HBioWzXCy/bv7sve1eariz7bbyiifh\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/S4f2wvw6HBioWzXCy/vur5e0b3ykmgzbq6ppmk 110w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/S4f2wvw6HBioWzXCy/zrghd23laxlqd2cdlyl2 220w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/S4f2wvw6HBioWzXCy/inuesbwomvktr02o65jy 330w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/S4f2wvw6HBioWzXCy/uh9xmrf4abnyqweh9f0z 440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/S4f2wvw6HBioWzXCy/c3op2o9nty1x5whvcl2a 550w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/S4f2wvw6HBioWzXCy/d6knhvq2pkf9crlgngro 660w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/S4f2wvw6HBioWzXCy/p0xnmck62ayqepefrofc 770w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/S4f2wvw6HBioWzXCy/imc3lnvqbm4cvqhe710c 880w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/S4f2wvw6HBioWzXCy/tnnq05qunv8jplddozwn 990w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/S4f2wvw6HBioWzXCy/ldw1mbxwo0aatlyzkq5t 1024w\"><figcaption>guess the prompt</figcaption></figure><h1>Main idea</h1><p>In Galor &amp; Weil's <a href=\"https://www.econstor.eu/bitstream/10419/80210/1/481894578.pdf;Unified\">Unified Growth Theory</a> (UGT), a model is given to explain the drivers for economic growth throughout history. The main insight of the model is that until relatively recently it was more worthwhile to have more kids than to invest in their education. This led to a transition from a Malthusian equilibrium to a modern growth equilibrium dominated by technological growth.</p><p>AGI takeoff can perhaps be modeled roughly similarly to help us understand the early days of an intelligence explosion. Rather than trying to understand takeoff timelines, we can try to understand whether takeoff is more likely to be initially driven by <i>intelligence </i>or <i>quantity </i>explosion.</p><p>What could a quantity explosion look like? Say OpenMind has developed a powerful AI agent with broadly general human-level intelligence. It's not yet superintelligent, but it's smart enough to be able to improve itself, acquire resources, and understand its own situation. If it is power-seeking, it will try to acquire more resources, and it will try to improve itself. Improving itself may require getting access to a massive amount of (a specific type of) compute and data, and has risks of value-drift or breaking in some way, so the agent decides to first try and duplicate itself many times across the internet. If it can do this, it will have a large number of copies of itself, which can then work together to acquire resources and improve itself.</p><p>This is a \"quantity explosion\" scenario, where the number of AI agents increases exponentially, but the intelligence of each agent remains roughly constant. This is in contrast to an \"intelligence explosion\" scenario, where the intelligence of each agent increases exponentially, but the number of agents remains roughly constant. In this scenario, different safety measures would be more effective (e.g. prosaic alignment and containment may be more important than solving inner alignment and understanding unbounded rational agents, and vice versa).</p><h1>What now?</h1><p>Under the guidance of economist <a href=\"https://forum.effectivealtruism.org/users/niki-kotsenko-1?mention=user\">@Niki Kotsenko</a>, I've started to draft and solve some possible models in <a href=\"https://github.com/edoarad/evaluation_playground/blob/master/AGI_Takeoff_dynamics.ipynb\">this notebook</a>. I'm not sure whether I'll keep working on it, as I prioritize other projects, but I think it could be a useful piece of work to pursue and I encourage others to explore this (maybe people at <a href=\"https://forum.effectivealtruism.org/posts/zqRDNChFburJMmpqK/announcing-epoch-a-research-organization-investigating-the\">Epoch </a>or other independent researchers).</p><p>In practice, the models I've tried are only vaguely similar to UGT, and mostly developed from first principles.&nbsp;</p><p>I'd be mostly interested in ideas on&nbsp;</p><ol><li>Whether the intelligence vs quantity explosion is a useful distinction that makes sense. (Also, links to previously written materials on this topic?)</li><li>Whether investigating this is an important research direction that's action-relevant for AI safety work.</li><li>Whether this kind of macro-economical approach to modeling AI takeoff makes sense.</li></ol><p>And, as I said above, I welcome anyone to continue exploring this and I'll gladly help out however I can.</p>", "user": {"username": "edoarad"}}, {"_id": "kwxE7HYjRpYwSEiKb", "title": "Underwater Torture Chambers: The Horror Of Fish Farming", "postedAt": "2023-07-26T00:08:47.458Z", "htmlBody": "<p>Crossposted from <a href=\"https://benthams.substack.com/p/underwater-torture-chambers\">my blog</a>. &nbsp;</p><h1>The horror of fish farming</h1><p>One of my professors in college taught a class about effective altruism\u2014a social movement about doing good effectively. Whenever he was talking about the scale of animal suffering, all the statistics he talked about were about the suffering of non-fish. It became a running joke\u2014friends and I would make jokes like the following: \u201ca gunman robs a bank, kills over 4 non-fish\u201d or \u201cone (non-fish) death is a tragedy, a million fish deaths are a statistic.\u201d But this professor, despite explicitly ignoring fish whenever he talked about a problem, was nonetheless more pro-fish than almost all people. Because no one cares about fish\u2014at all.</p><p>I remember when I was young, my grandmother would take me and my brother fishing. This was seen as a totally innocuous, fun way to spend a weekend. The general attitude towards fishing is almost exactly opposite to the attitude towards, for example, hunting: liberal parents in blue states are not happy letting their children hunt land creatures, the way they are happy to let their children hunt fish. This is unsettling\u2014hooking fish into the mouth to yank them out of the water so that they <i>suffocate to death</i> is seen as just a bit of innocent fun.</p><p>Elsewhere, I\u2019ve made <a href=\"https://benthams.substack.com/p/factory-farming-delenda-est\"><u>the case against land-based factory farms</u></a>\u2014great, industrial torture chambers, that routinely mutilate animals, give them too little space to move around, castrate them with no anesthetic, and force them to spend their lives covered in feces and filth, in constant agony, disgust, and boredom. I\u2019ve even argued that factory farming is the <a href=\"https://benthams.substack.com/p/factory-farming-is-not-just-bad-its\"><u>worst crime in human history</u></a>\u2014worse than whatever very bad crime you\u2019re thinking of.</p><p>The cruelty of the farm industry is not limited to the versions that are on land. The fish farming industry is unspeakably horrifying. We have built hell and consigned the fish to it. And <a href=\"https://forum.effectivealtruism.org/posts/iMofrSc86iSR7EiAG/introducing-fish-welfare-initiative-1\"><u>far more animals are tormented and killed</u></a> in fish farms than in land-based factory farms. The aquaculture industry may be the single worst industry in the history of the world\u2014causing more suffering than any other. This judgment may sound surprising, but it\u2019s hard to deny if one thinks fish suffering matters at all given the sheer numbers. <a href=\"https://freefromharm.org/animal-cruelty-investigation/the-filthy-business-of-fish-farming/\"><u>One undercover report</u></a> on fish farms found:</p><blockquote><p>Workers\u2019 abusive handling of fish, including slamming and stomping on fish, and violently throwing fish, including treating them like basketballs performing \u201ctrick shots\u201d</p><p>&nbsp;Workers cruelly killing fish by slamming them on the ground&nbsp;</p><p>Live fish have their eyes eaten by fish who are underfed and hungry and mistake their pupils as food&nbsp;</p><p>Ineffective anesthetization during vaccination and fin clipping&nbsp;</p><p>Fish thrown into buckets and left to suffocate in piles of the dead and dying&nbsp;</p><p>Conditions so filthy that fish must be vaccinated&nbsp;</p><p>Painful spinal deformities, and fungus growth on fish intended for human consumption, including fungus eating away at the faces of the fish&nbsp;</p><p>Extreme crowding in barren conditions and high death rates of eggs and fish</p></blockquote><p>Lewis Bollard <a href=\"https://www.wellbeingintlstudiesrepository.org/cgi/viewcontent.cgi?article=1015&amp;context=aw_farm_gen\"><u>notes </u></a>\u201cThe fishing industry alone kills 3-8 billion animals every day, most by slow suffocation, crushing, or live disemboweling.\u201d So roughly the same number of fish are killed in horrifying, inhumane ways every few days as there are people on earth. It takes longer for the fish to suffocate than for us to drown, and so is probably more painful. The <a href=\"https://rethinkpriorities.org/publications/welfare-range-estimates\"><u>most up-to-date report</u></a>\u2014and also one of the most conservative\u2014found that the least sentient fish that they surveyed experience suffering about one-twentieth as intensely as human suffering. Let\u2019s grant this\u2014and use the conservative estimate of how many fish are killed by people\u2014only 3 billion per day. If a fish\u2019s death is only one-twentieth as painful as a human death, then every day, the total painfulness of fish suffering is equivalent to the painfulness of one hundred fifty million human deaths. But if there was a disease that infected one hundred fifty million people every day, and gave them an experience as painful as being killed by \u201cslow suffocation, crushing, or live disemboweling,\u201d it would clearly be the worst thing in the world. This disease would cause the average person to experience a painful death seven times per year. Maybe you think that fish suffering is inherently only 1% as bad as human suffering (this seems like totally irrational prejudice, as I\u2019ll argue later, but let\u2019s grant it). Well then fish slaughter would only be as bad as inflicting on one and a half million humans, every day, an experience as painful as cruel slaughter. But if there was something like that\u2014something that would force each human to endure the painfulness of disembowelment every 15 or so years\u2014it would clearly be the worst thing in the world. So even by insanely conservative assumptions, fish slaughter alone\u2014which is responsible for a minuscule portion of the cruelty of the fish industry\u2014is the worst thing ever.</p><p>Fish are used to having open space in the ocean. So <a href=\"https://www.peta.org/issues/animals-used-for-food/factory-farming/fish/aquafarming/\"><u>the cramped conditions of fish farms</u></a>\u2014totally antithetical to their natural ways of living\u2014are extremely stressful for them. As a consequence, fish constantly crash into each other, causing painful injuries to their fins. Peta <a href=\"https://www.peta.org/issues/animals-used-for-food/factory-farming/fish/aquafarming/\"><u>notes </u></a>\u201cLarge farms can span the size of four football fields and contain more than 1 million fish.\u201d Disease is common, and <a href=\"https://www.globalseafood.org/advocate/dissolved-oxygen-is-a-major-concern-in-aquaculture-heres-why/\"><u>fish aren\u2019t given enough Oxygen</u></a>, making it hard to breathe and resulting in chronic stress and low energy. Often, up to 40% of fish are blind, and half have hearing loss because of the the extreme prevalence of disease. On fish farms, it\u2019s not uncommon to see the bones of live fish, as parasites have eaten all the way to the bone.</p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd894b39-767e-4741-870a-e538336384b5_300x168.jpeg\"><img src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd894b39-767e-4741-870a-e538336384b5_300x168.jpeg\" alt=\"Death Crown at The Scottish Salmon Company in Loch Carron on Vimeo\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd894b39-767e-4741-870a-e538336384b5_300x168.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd894b39-767e-4741-870a-e538336384b5_300x168.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd894b39-767e-4741-870a-e538336384b5_300x168.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd894b39-767e-4741-870a-e538336384b5_300x168.jpeg 1456w\"></a></p><p>It\u2019s hard to imagine that level of suffering. Hopefully, such parasites kill the fish quickly, so they don\u2019t have to endure the horrorshow of their skin being eaten. A whopping 40% of fish die before they are ready to be slaughtered\u2014they\u2019re seen as a disposable byproduct, whose death is a minor annoyance rather than a tragedy. Something must be deeply wrong with fish farming, if it kills 40% of fish <i>by accident</i>.</p><p>Every part of the life cycle of fish is horrifying. Before slaughter on the fish farms, <a href=\"https://www.animallaw.info/sites/default/files/lralvol20_1_119.pdf\"><u>fish are starved</u></a> for a few days to a month. One impressively detailed <a href=\"https://www.animallaw.info/sites/default/files/lralvol20_1_119.pdf\"><u>report </u></a>on fish slaughter noted:</p><blockquote><p>Animal welfare was not of concern during the development of slaughter methods for fish. Instead, the methods used to slaughter fish were developed to achieve a uniform product, efficiency, and processor safety. Common slaughter methods include carbon dioxide narcosis, live chilling, asphyxiation (suffocation) in air, live gutting, percussive stunning, and electrical stunning. The method of carbon dioxide narcosis is the method routinely used in commercial slaughter, which consists of placing fish in water with high levels of dissolved carbon dioxide. Studies on this method show that fish have an immediate and strong aversive reaction to entering the carbon dioxide solution. The fish are left in the water until they stop moving, then they are taken out of the water, sliced, and bled out. However, they do not immediately lose consciousness via this method, but are merely rendered immobile. And because they are slaughtered as soon as they stop moving, most are killed when fully conscious.</p></blockquote><p>There are no legal protections of fish. It\u2019s totally legal to kill them by, for example, pulling the skin off them while they\u2019re still alive\u2014as is <a href=\"https://fish.mercyforanimals.org/\"><u>sometimes done</u></a>. Whatever you could imagine doing to a fish to kill it is perfectly legal. In addition, <a href=\"https://animalsaustralia.org/our-work/factory-farming/fish-in-farms-are-depressed/\"><u>Animals Australia</u></a> notes:</p><blockquote><p>Up to a quarter of fish in fish farms have stunted growth and float lifelessly at the surface of the tanks. These fish are known as \u2018drop outs.\u2019 According to research by&nbsp;<a href=\"http://rsos.royalsocietypublishing.org/content/3/5/160030\"><u>Royal Society Open Science</u></a>, these fish exhibit behaviours and brain chemistry almost identical to those of very stressed and depressed people.</p><p>The \u2018drop out\u2019 fish were found to have significantly higher levels of cortisol, a stress-response hormone, as well as increased activity of the serotonergic system, which is involved in sleep, hunger, respiration, mood and more. Problems with this neural system have been associated with severe mental illness, including depression.</p><p>\u201cI would not go so far as to say they are committing suicide, but physiologically speaking, they are on the edge of what they can tolerate, and since they remain in this environment, they end up dying because of their condition.\u201d<br>\u2013 Marco Vindas, Royal Society of Open Science</p><p>Farmed fish live in very stressful conditions, vastly different to what they have evolved to cope with in the wild. Fish in aquaculture farms are forced to live in crowded tanks and endure unwanted interactions with other fish, handling by humans, struggles to get food, and sudden changes in lighting, water depth and currents. Just like&nbsp;<a href=\"https://animalsaustralia.org/features/invisible-cruelty-factory-farming\"><u>pigs</u></a>&nbsp;and&nbsp;<a href=\"https://animalsaustralia.org/features/invisible-cruelty-factory-farming\"><u>chickens</u></a>, fish in intensive farms live a life of suffering.</p></blockquote><p>Here\u2019s a plausible principle: if a being is conscious enough to essentially get depression, we should not put them in situations where a greater population of them does get depression than there are humans on earth. If oodles of fish are aimlessly floating, totally dejected, unwilling to perform basic tasks, something has gone deeply wrong. And we know what has gone wrong. We have put them in cruel, alien conditions. If fish designed farms for us, they\u2019d be horrifying\u2014fish neither know nor care what brings us joy. But the same is true when we design farms for fish.</p><p>It is undeniable that we are inflicting profound mistreatment on literally trillions of fish. There are relatively few ways to defend this unimaginable infliction of suffering and, to quote GA Cohen, \u201csome of them are<strong> </strong>lousy and others are just as bad.\u201d But each of the basic arguments falls into one of two categories of argument. The first type of argument claims that fish can\u2019t feel pain, the second claims that their pain isn\u2019t bad.</p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8a77a1bf-fa73-47bc-b13d-423b3ba3102d_275x183.jpeg\"><img src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8a77a1bf-fa73-47bc-b13d-423b3ba3102d_275x183.jpeg\" alt=\"Series: Plenty of Fish on the Farm | The Breakthrough Institute\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8a77a1bf-fa73-47bc-b13d-423b3ba3102d_275x183.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8a77a1bf-fa73-47bc-b13d-423b3ba3102d_275x183.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8a77a1bf-fa73-47bc-b13d-423b3ba3102d_275x183.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8a77a1bf-fa73-47bc-b13d-423b3ba3102d_275x183.jpeg 1456w\"></a></p><h1>Yes, fish feel pain</h1><p>&nbsp;</p><p>The <a href=\"https://www.peta.org/issues/animals-used-for-food/factory-farming/fish/fish-feel-pain/\"><u>evidence </u></a>that fish feel <a href=\"https://thingofthings.substack.com/p/book-review-do-fish-feel-pain\"><u>pain </u></a>is relatively widespread. Here is some of that evidence:</p><p>When fish are injected with venom, their heart rate goes up, just like ours does when we\u2019re in pain.</p><p>This isn\u2019t just an automatic response. We know this in the following way. Trout are scared of new objects. When they\u2019re in a lot of pain, on account of being injected with vinegar, they ignore their fear of new objects and swim in a random direction to get away. But if they\u2019re given morphine\u2014an anesthetic\u2014then they start being scared of the object again. So fish respond to painkillers.</p><p>In one experiment, some fish got a shock whenever they went to some part of a tank. They learned to avoid that part of the tank.</p><p>Trout make tradeoffs. In the earlier experiment where they get shocked if they go to part of a tank, if a friend is hanging out in that part of the tank, they\u2019re willing to go to that part of the tank to hang out with their friend (this is the one time I\u2019ve found fish sort of endearing).</p><p>When fish are given painkillers, their abilities to detect harmful external stimuli are hampered. This is best explained by the painkillers numbing the pain, which is part of how they detect external stimuli.</p><p>Fish are pretty smart. They can solve mazes and remember where tide is low and high, after just seeing it once. Some fish can remember the identities of fish they\u2019ve watched fight.</p><p><a href=\"https://www.ginkandgasoline.com/trout-fishing/do-fish-dream/\"><u>There\u2019s decent evidence that fish dream</u></a>. But to dream, they have to be conscious. If they\u2019re conscious, they can feel pain.</p><p>This evidence <a href=\"https://www.smithsonianmag.com/science-nature/fish-feel-pain-180967764/#:~:text=%E2%80%9CFish%20do%20feel%20pain.,intense%20pressure%2C%20and%20caustic%20chemicals.\"><u>has been enough</u></a> to change the minds of the majority of people studying the topic, who started out pretty skeptical.</p><p>So the evidence that fish feel pain is pretty overwhelming. As Braithwaite, author of the most detailed book on the subject declares, \u201cthere is as much evidence that fish feel pain and suffer as there is for birds and mammals.\u201d But let\u2019s be super conservative and say that there\u2019s only a 50% chance that they can feel pain. <strong>You shouldn\u2019t cruelly mistreat trillions of beings unless you\u2019re pretty damn sure they can\u2019t feel pain</strong>. If you are not sure if they can feel pain, you should not risk causing more suffering than has existed in all of human history. Because of the mindboggling number of fish, even if they might not feel pain, their pain in expectation is enough to thoroughly outstrip the badness of all human pain.</p><h1>Fish pain is bad</h1><p>&nbsp;</p><p>Fish pain is bad because pain is bad. Pain is bad because of the way it feels. Think about what it\u2019s like to suffocate or be disemboweled. It doesn\u2019t matter who is suffocating, the experience is still bad. That suffering is bad is just about the most basic ethical truth\u2014denying it is insanity. I don\u2019t just think this because I\u2019m a weird utilitarian. Utilitarianism says pleasure and pain matter and nothing else does. The nothing else part is what makes it radical\u2014everyone sane agrees that pleasure and pain do matter. And if pain matters, then fish pain must matter.</p><p>Maybe you think that fish suffering isn\u2019t bad because fish are very unintelligent. But why in the world does this matter? Suppose you\u2019re in intense agony. Would that be made any worse if you were smarter? If intelligence amplifies your pain, then the pain of smarter people would be worse than the pain of stupider people. Is Von Neumann\u2019s pain worse than mine just because he\u2019s smarter? Of course not\u2014intelligence has nothing to do with how bad pain is.</p><p>Suppose that when you were in pain, there was a pill that made you very stupid, but you experienced the pain just as intensely. Would it be worth taking the pill? If being unintelligent makes your pain less bad, then the pill would make the pain less bad. But this is clearly crazy. Pain is bad because of how it feels\u2014but how it feels has absolutely nothing to do with how smart the victim of it is.</p><p>Some humans are severely mentally enfeebled. Some might even be as enfeebled as fish. Is their pain mostly irrelevant? No, of course not. Is babies\u2019 pain irrelevant because babies are dumb? No! So it can\u2019t be mere unintelligence that makes one\u2019s pain mostly irrelevant.</p><p>Maybe what matters is that fish are part of an unintelligent species. But why does species matter? It seems like the badness of your pain depends on facts about you, rather than about others. But whether your species is intelligent is a fact about others. So it can\u2019t affect the badness of pain.</p><p>Suppose we killed all humans except the most mentally enfeebled. Would their pain stop being bad? What if they had babies for many generations, such that almost all humans who ever lived were very unintelligent? Of course not! Or suppose we discovered that some mentally enfeebled people had a strange disease that didn\u2019t affect them cognitively, but made them their own species. Would this make their pain not bad? Well, if species matters, and this disease made them part of an unintelligent species, then it would make their pain not bad.</p><p>Maybe you\u2019re not sure about all this. Well, if you\u2019re not sure, then you shouldn\u2019t risk something that might be the worst thing ever by orders of magnitude. If you\u2019re not sure whether something is the worst thing ever, it\u2019s still a very, very serious problem.</p><p>Fish are a basic test of our empathy. They are weird and slimy and gross and hard to empathize with. They are not cute, they cannot cuddle with us. There is no political coalition nor side of the culture war that makes a big deal out of representing their interests. But they can suffer. Trillions of them scream silently because of our actions. We, as a species, are failing the basic task of having a modicum of empathy for these poor, defenseless creatures. Every three days, we kill more fish than there are humans, because we totally ignore the interests of such creatures. Humanity is carrying out a crime of unimaginable proportions.</p><p>If you only empathize with those who are cute and cuddly and look like you, that is not real empathy. If you only put yourself in the shoes of the victim when the victim reminds you of yourself, that is an utter failure of empathy. Even if you cannot imagine being the recipient of some experience, if you know it is a horrifying one\u2014if you know you would scream in agony if you were to experience it\u2014you should see it as something worth preventing.</p><p>The solution is relatively simple. We, as consumers, should stop paying for the cruel mistreatment of fish. Until fish farming becomes remotely humane, we should stop paying for fish. In addition, the government should impose strict regulations on fish farming, and potentially ban it altogether. As individuals, we should donate to <a href=\"https://forum.effectivealtruism.org/posts/iMofrSc86iSR7EiAG/introducing-fish-welfare-initiative-1\"><u>organizations </u></a>that help save fish from unspeakable cruelty.</p><p>Literally trillions of fish are being killed in horrifying ways. The world is almost entirely silent about this crime of unimaginable proportions. Compared to the crimes we commit beneath the seas, every other issue pales in comparison. If you eat fish, that is probably the worst thing you\u2019re doing, unless you\u2019re a serial killer. One shouldn\u2019t take actions unless they could justify them to the victims of the actions. But we could not justify our actions to torture and disembowel fish to the fish themselves. If we ever come across aliens that are very different from us, but intelligent, they should pay very careful attention to how we treat fish. If we can\u2019t meet the low bar of not torturing them en masse just because they are different, then we are truly a violent, cruel, and inhumane species.</p><p>&nbsp;</p><p>&nbsp;</p><p><br>&nbsp;</p>", "user": {"username": "Omnizoid"}}, {"_id": "tRbCjvm4cuuzm95Mv", "title": "Nuclear Risk and Philanthropic Strategy [Founders Pledge]", "postedAt": "2023-07-25T20:22:34.168Z", "htmlBody": "<p>The following is a copy of Founders Pledge's new report <a href=\"https://www.founderspledge.com/research/global-catastrophic-nuclear-risk-a-guide-for-philanthropists\"><i>Global Catastrophic Nuclear Risk: A Guide for Philanthropists</i></a><i>. </i>Readers who prefer footnotes to endnotes can find a Google Doc <a href=\"https://docs.google.com/document/d/1Sops0AM_kTvsKEHnFmwSCbI3pufTujOI9kjUxyDHvQY/edit#heading=h.lpgvtmkb0c6u\">here</a>.</p><p>Special thanks to Matt Lerner (Founders Pledge), Jim Scouras (JHU Applied Physics Laboratory), and Matt Gentzel (Longview Philanthropy) for reviewing the report and for their invaluable input and advice.&nbsp;</p><p>A full list of the many people who contributed to this project is in the section on \"Acknowledgements and Disclaimers.\" The report is long, and I expect most people will not want to read the full document. Below is a short summary, followed by the full report.&nbsp;</p><h1>tl;dr</h1><p>There has been a large reduction in philanthropic funding, coincident with new challenges in nuclear security. Specifically:</p><ol><li><strong>China and the \"Three Body Problem</strong>.\" The apparent ambitions of the Chinese Communist Party to massively expand its nuclear arsenal threaten to create a \u201cThree Body Problem\u201d of unstable deterrence dynamics between three nuclear superpowers \u2014 the United States, Russia, and China \u2014 whose arsenals dwarf the other nuclear powers. Deterrence was built on duels, not truels, and we don't know how to approach this new problem.</li><li><strong>Technological Disruption</strong>. Advances in machine learning and artificial intelligence have the potential to undermine (but also to strengthen) strategic stability, depending on their applications. For more, see Founders Pledge's research on <a href=\"https://www.founderspledge.com/research/autonomous-weapon-systems-and-military-artificial-intelligence-ai\"><u>autonomous weapons and military AI</u></a>.</li><li><strong>Funding Shortfalls</strong>. The MacArthur Foundation is withdrawing from the nuclear field, leaving a major funding shortfall, and reducing the total philanthropic funding per year to about $30 million. (For comparison, the three CEOs of Lockheed Martin, Boeing, and Raytheon alone <a href=\"https://www.forbes.com/sites/williamhartung/2022/12/12/pentagon-profiteers-executive-compensation-in-the-arms-industry/?sh=475b919e61ff\"><u>took home</u></a> more than $60 million in 2021. For another comparison, the budget of <i>Oppenheimer</i> was more than three times as much as philanthropists now spend on preventing nuclear war.)</li></ol><p>A key insight for funders who value cost-effectiveness is that the negative effects of large-scale nuclear wars are <i>disproportionately</i> worse than the negative effects of more limited nuclear exchanges. In other words, <strong>nuclear wars are not created equal</strong> and <strong>the costs of nuclear war increase super-linearly</strong> with the size of nuclear war. All nuclear use is horrific, but the largest wars \u2014 thermonuclear exchange between the great powers \u2014 have the potential to threaten modern civilization and potentially alter the Earth\u2019s climate, triggering mass starvation. Uncertainties abound \u2014 the science around nuclear winter is shoddy, civilizational collapse is difficult to model, and the tractability of escalation control is unknown \u2014 but this basic insight remains unchanged. Other features further define the structure of the problem:</p><ol><li>Funders, experts, and decision-makers face <strong>deep uncertainty about the effectiveness of interventions</strong> \u2014 we often simply do not know what would work best, and have no way of finding out.</li><li><strong>Accidents happen</strong> \u2014 the problems of nuclear crisis management and escalation control are likely here to stay, and cannot be ignored.</li><li><strong>What comes down can go back up</strong> \u2014 Cold War arsenal reductions are not guaranteed to be sticky, and some trends suggest that states are interested in arming; the magnitude of nuclear risk could increase significantly in the near future.</li></ol><p>From the structure of the problem, philanthropists can derive heuristics that act as <a href=\"https://forum.effectivealtruism.org/posts/GzmJ2uiTx4gYhpcQK/effectiveness-is-a-conjunction-of-multipliers\"><strong>impact multipliers</strong></a> (for more on impact multipliers and relative cost-effectiveness under uncertainty, see \u201c<a href=\"https://www.founderspledge.com/research/how-we-think-about-charity-evaluation\"><u>How we think about charity evaluation</u></a>\u201d and the <a href=\"https://forum.effectivealtruism.org/posts/kuopGotdCWeNCDpWi/how-to-evaluate-relative-impact-in-high-uncertainty-contexts\">methodological work of the Founders Pledge climate team</a>):</p><ul><li>Funders ought to <strong>focus on minimizing war damage</strong>. This ultimate goal <i>may</i> diverge from intermediate goals like disarmament, non-use, etc.</li><li>In light of uncertainty about intervention effectiveness, funders ought to <strong>prioritize neglected strategies</strong>.</li><li>Funders can multiply their impact by focusing on \"<strong>great powers</strong>.\"</li><li>Funders can multiply their impact by focusing on <strong>policy advocacy to leverage societal resources</strong>.</li><li>The principle of \u201c<strong>robust diversification</strong>\u201d can help guide effective giving under the conditions described above.</li></ul><p>When combining these insights with analysis of funding databases, we are once again pushed towards prioritizing philanthropic interventions that seek to minimize damage <i>after</i> the first nuclear weapon has gone off, especially by <strong>escalation control</strong>, <strong>war limitation</strong>, and <strong>war termination</strong>. For more on this, see \u201c<a href=\"https://www.founderspledge.com/research/philanthropy-to-the-right-of-boom\"><u>Philanthropy to the Right of Boom</u></a>\u201d and \u201c<a href=\"https://www.founderspledge.com/research/hotlines-and-global-catastrophic-risk\"><u>Call Me, Maybe? Hotlines and Global Catastrophic Risks</u></a>.\u201d To summarize:</p><ul><li>\u201cRight of boom\u201d interventions \u2014 focusing on problems arising after the first use of nuclear weapons, such as escalation control \u2014 are an important part of risk reduction.</li><li>These very interventions have been severely neglected by philanthropic funders, possibly for ideological reasons.</li><li>These facts suggest that prioritizing \u201cright of boom\u201d interventions is a promising impact multiplier for funders <i>on the margin</i>.</li></ul><p>Crucially, we can use these heuristics to build grantmaking strategies for nuclear security, and to identify potentially promising projects for effective philanthropy.</p><p>Now, the full report:</p><p>&nbsp;</p><h1>Acknowledgements and Disclaimers</h1><p>I am thankful to the many experts who have contributed to this project with their insight, feedback, and critiques, including in semi-structured interviews. <strong>The analysis and views expressed in this report do not necessarily reflect the views of anyone consulted for the project.</strong></p><p>With special thanks to:</p><ul><li>Dr. James Scouras for his thoughtful advice and key insights on nuclear war as a global catastrophic risk and for serving as an external reviewer of the report.</li><li>Matthew Gentzel for reviewing various drafts of the report, providing valuable feedback throughout the project, and serving as an external reviewer of the report.</li><li>Dr. James Acton, Conor Barnes, Tom Barnes, Patty-Jane Geller, Matt Lerner, Dr. Jeffrey Lewis, Ankit Panda, Dr. Andrew Reddie, and Carl Robichaud for reviewing earlier versions of the \u201cRight of Boom\u201d analysis in this document and for their helpful comments and suggestions.</li><li>Dr. Michael Horowitz for useful conversations and insights on these issues.</li><li>Dr. Michael Cassidy and Lara Mani for their explanation of volcanic aerosol chemistry and the potentially self-limiting effects of some climate phenomena, and Dr. Jon Reisner, Professor Alan Robock and Professor Brian Toon for their discussions on nuclear winter.</li><li>Dr. Jaime Yassif for many conversations on global catastrophic biological risks and general risk-reduction strategies.</li><li>Matt Lerner for extensive feedback, edits and guidance on the report.</li><li>Amber Dawn Ace for providing copy edits and helpful suggestions.</li><li>Dr. Zo\u00eb Ruhl for her support and invaluable insight.</li></ul><p>Parts of this document were previously published as a Founders Pledge report on \u201cPhilanthropy to the Right of Boom,\u201d which can be found <a href=\"https://docs.google.com/document/d/1H-n6QekuCFPJF5cEw76Q84bva2qYhbMHuMv-9Y58gkk/edit%23\"><u>here</u></a>.</p><p><strong>This report contains discussions of war and human suffering.</strong></p><p>&nbsp;</p><h1>Executive Summary</h1><p>Nuclear weapons are a global catastrophic risk; a nuclear war could kill untold millions, inflict horrific suffering on survivors, and derail human civilization as we know it. This report forms a guide for philanthropists who seek to mitigate this risk and maximize the counterfactual impact&nbsp;of their charitable donations. Specifically, the report seeks to guide funders entering this field in the wake of several challenges: the apparent collapse of post-Cold War arms control, the second year of the Russo-Ukrainian War, rising U.S.-China tensions, and a large funding shortfall for nuclear security. It mirrors many of the themes of Founders Pledge\u2019s <i>Guide to the Changing Landscape of High-Impact Climate Philanthropy, </i>and is indebted to the insights in that document.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt1\"><sup>[1]</sup></a>&nbsp;</p><p>The report\u2019s analysis has four steps:<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt2\"><sup>[2]</sup></a></p><ol><li><u>Understanding key features of the landscape of nuclear philanthropy</u>, with special attention to recent funding shortfalls.</li><li><u>Analyzing the structure of the problem</u>, emphasizing the super-linearity of expected costs; not all nuclear wars are equal, and bigger nuclear wars could be disproportionately more damaging than smaller nuclear wars for both current generations and the long-term future.</li><li><u>Sketching guiding principles for nuclear philanthropy</u>&nbsp;based on these ideas:<ul><li>Prioritize minimizing expected global war damage;</li><li>Prioritize neglected strategies;</li><li>Multiply impact by shaping great power behavior;</li><li>Exercise leverage via policy advocacy;</li><li>Pursue a strategy of \u201crobust diversification.</li></ul></li><li><u>Exploring practical implications</u>&nbsp;of these principles. The section briefly describes concrete projects that philanthropists can support. A conclusion enumerates key uncertainties and sketches a path forward for philanthropists</li></ol><p>Overall, the report argues that deep uncertainty surrounds nuclear risk, that shaky assumptions underpin much of the conventional wisdom on nuclear war, and that effective philanthropists must learn to leverage their donations despite this uncertainty. Although the report reflects the input of a variety of experts, it is only one approach to the problem. We hope and expect to revise its conclusions as we encounter new evidence.</p><p>&nbsp;</p><h1>External Reviews</h1><p>Founders Pledge\u2019s research reports undergo several rounds of internal and external review. To provide the reader context for this report, we have asked two outside experts to briefly write up their impressions:</p><h2>Reviewer 1: James Scouras</h2><p><i><strong>James Scouras</strong>&nbsp;is a senior scholar at the Johns Hopkins University Applied Physics Laboratory and the former chief scientist of the Defense Threat Reduction Agency\u2019s Advanced Systems and Concepts Office. Previously, he was program director for risk analysis at the Homeland Security Institute, held research positions at the Institute for Defense Analyses and the RAND Corporation, and lectured on nuclear policy in the University of Maryland\u2019s General Honors Program. Among his publications are the book</i>&nbsp;A New Nuclear Century: Strategic Stability and Arms Control<i>, coauthored with Stephen Cimbala, and the edited volume</i>&nbsp;On Assessing the Risk of Nuclear War<i>. Dr. Scouras earned his PhD in physics from the University of Maryland.</i><a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt3\"><i><sup>[3]</sup></i></a></p><h3>Scouras Review</h3><p>Among the many and varied global catastrophic risks faced by humanity, nuclear war stands out for the combination of its potential immediacy, the horrific nature of its consequences, its long-term threat to civilization, and \u2014 most important of all \u2014 the fact that it has been created by humans and is subject to human interventions. With the end of the Cold War and the emerging multipolar nuclear future, a renaissance of creative, disciplined thinking is urgently needed and needs to be underwritten by both governmental and philanthropic organizations. Christian Ruhl\u2019s <i>Global Catastrophic Nuclear Risk: A Guide for Philanthropists</i>&nbsp;lays a thoughtful intellectual foundation for justifying and focusing impactful philanthropy on reducing nuclear risks.</p><p>Most important, this paper challenges conventional wisdom in significant ways. In particular, it recommends emphasizing \u201cright-of-boom\u201d thinking. For too long the United States and its allies have put all their eggs in the deterrence basket. If the success of deterrence could be guaranteed, there would be no need to worry about the aftermath of its failure. But the complacency over the robustness of deterrence that has emerged from over three-fourths of a century without nuclear war may not serve us well in the future. Ominous trends in horizontal and vertical proliferation, the intensification and periodic eruption of enduring interstate disputes, and the never-ending advent of potentially destabilizing technologies all suggest we need to be better prepared for the possibility of nuclear war. Thus, we need to focus more on preventing small nuclear wars from escalating to large ones and recovering from all levels of nuclear war.</p><p>In addition, the paper is also innovative in its recommended focus on large nuclear wars that are disproportionately harmful compared to smaller nuclear wars. Large states can endure a small nuclear war, horrific though it will be. But it\u2019s improbable that nuclear combatant states could survive a war that unleashed the arsenals of the major nuclear powers, and it is not clear how many centuries civilization would be thrown back and for how long. Thus, avoiding and recovering from large nuclear wars needs much greater focus in nuclear policy.</p><p>Finally, the paper identifies what is the most challenging problem in nuclear strategy: how to maintain deterrence and stability in the emerging tripolar nuclear world, with the United States, Russia, and China possessing comparably large nuclear arsenals. The fundamental problem is that the forces that underwrite deterrence against any single nuclear state would be inadequate to deter a coordinated attack by two peer adversaries. This concern could spark an arms race and/or motivate destabilizing force postures, launch decisions, and targeting doctrines. While the United States Strategic Command and policy organs of the US Department of Defense have recognized this challenge, a workable approach has not been identified, and any consensus is not on the horizon.</p><p>All these issues and many others identified in Ruhl\u2019s paper require the sustained attention of the most knowledgeable, the most disciplined, and the most creative minds. Philanthropy can serve the critical roles of encouraging such minds to focus on this critical problem, fostering unconventional thinking, and challenging unimaginative, even wrongheaded and dangerous, government policies. Nuclear risk is far too important to leave to the generals.</p><hr><h2>Reviewer 2: Matthew Gentzel</h2><p><i><strong>Matthew Gentzel </strong>is a nuclear weapons policy program officer at Longview Philanthropy, where he co-leads Longview\u2019s work on nuclear issues. His prior work spanned emerging technology threat and policy assessment, with a particular focus on how advancements in AI may shape the future of influence operations, nuclear strategy, and cyber attacks. He has worked as a policy researcher with OpenAI, as an analyst in the US Department of Defense\u2019s Innovation Steering Group, and as a director of research and analysis at the US National Security Commission on Artificial Intelligence. Matthew holds an MA in strategic studies and international economics from Johns Hopkins SAIS and a BS in fire protection engineering from the University of Maryland.</i><a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt4\"><i><sup>[4]</sup></i></a></p><h3>Gentzel Review</h3><p>This guide is one of the most comprehensive approaches I\u2019ve seen to reducing global catastrophic nuclear risk from a \u201cbig picture\u201d perspective. While no document can cover every angle, it brings a variety of strategic considerations and thought tools together with sufficient depth to help philanthropists develop effective nuclear risk reduction strategies.</p><p>The extreme non-linearity of nuclear scenarios, the impact of different nuclear risk reduction interventions on other catastrophic threats such as bioweapons, and prioritization under extreme uncertainty are a few among many themes the guide covers. With examples such as the Cooperative Threat Reduction program, the guide also illustrates how philanthropists can drive extremely cost-effective risk reduction measures by bringing attention to neglected issues early and leveraging government resources.</p><p>One idea that may deserve future attention is how cultivating talent with broad awareness of crucial considerations can help uncover further opportunities both to prevent and to reduce the damage of nuclear war. While the prevention of nuclear use is relatively not neglected within the field, people with <i>neglected expertise</i>&nbsp;in positions of influence may still find traction. Similarly, talented individuals can help sort through interventions that initially appear to have an ambiguous track record: identifying the conditions that determine success with high quality analysis. Opportunities of these sorts often lie hidden by a variety of factors: ideological polarization, analytic siloing, misaligned bureaucratic incentives, efforts to manipulate risk perception, and the constraints of state secrecy. Training and elevating experts that can sort through these factors and the other considerations put forward in this guide could be a great investment.</p><h1>Introduction: Deep Uncertainty</h1><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p><strong>Key Points:</strong></p><ul><li>Deep uncertainty surrounds&nbsp;both the probability and the consequences of nuclear war.</li><li>This uncertainty extends to the effectiveness of different risk-reduction measures that philanthropists could pursue.</li><li>Analyzing potential \u201cimpact multipliers\u201d derived from the problem\u2019s structure can guide effective philanthropy amidst this uncertainty.</li></ul></td></tr></tbody></table></figure><p>We know very little about nuclear war.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt5\"><sup>[5]</sup></a>&nbsp;Despite countless books, articles, game-theoretic models, war games, and billions of dollars spent on understanding risk reduction, even well-respected experts and seasoned policymakers face fundamental and often unresolvable uncertainties about nuclear war.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt6\"><sup>[6]</sup></a>&nbsp;</p><p>The&nbsp;world has had only one experience with the horrors of nuclear war through the atomic bombings of Japan in the summer of 1945. This distinguishes nuclear risk from some other global catastrophic risks, such as biological risks, where the history of natural pandemics can help analysts anchor risk estimates, including estimates of risk from unprecedented engineered pandemics. Moreover, uncertainty on nuclear war arises not just from complexity, but from sometimes being an optimization target for states; nuclear postures and policies are fundamentally about shaping risk perception, which complicates accurate risk estimation.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt7\"><sup>[7]</sup></a>&nbsp;These factors lead to three fundamental uncertainties:</p><ol><li>Uncertainty on the probabilities of nuclear wars<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt8\"><sup>[8]</sup></a></li><li>Uncertainty on the consequences of nuclear wars</li><li>Uncertainty on effective risk-reduction measures</li></ol><p>Together, these factors make up the fundamental components of risk (as a function of probability and consequence) and risk reduction. Such uncertainty can inspire apathy about risk reduction \u2014 in Cold War America, for example, popular jokes mocked attempts to reduce the consequences of nuclear war as futile: \u201cWhat do you do when you see the flash? You put your head between your legs and kiss your ass goodbye.\u201d<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt9\"><sup>[9]</sup></a>&nbsp;We need not take this fatalistic view. As explained throughout this report, philanthropists and policymakers can still prioritize interventions by understanding the general structure of the problem.</p><p>The following three sections disaggregate (1) uncertainty on probabilities, (2) uncertainty on consequences, and (3) uncertainty on risk reduction.</p><h2>Uncertainty on Probabilities</h2><p>First, how likely is nuclear war? We do not really know.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt10\"><sup>[10]</sup></a>&nbsp;Ways of assessing this probability include:</p><ul><li>Crowdsourced probabilistic forecasting;<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt11\"><sup>[11]</sup></a></li><li>Elicited expert knowledge;<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt12\"><sup>[12]</sup></a></li><li>Na\u00efve base-rate forecasting;<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt13\"><sup>[13]</sup></a></li><li>Subjective policymaker judgments;<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt14\"><sup>[14]</sup></a></li><li>Probabilistic risk assessment based on near-misses and \u201cteetering coin\u201d analyses;<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt15\"><sup>[15]</sup></a></li><li>and more, including the aggregation of multiple methods.</li></ul><p>Aggregation of multiple forecasts can<i>&nbsp;</i>yield rough point estimates. Global priorities researcher Luisa Rodriguez, for example, has aggregated several estimates with the arithmetic mean of probabilities for an annualized probability of 1.1% of nuclear war, and a 0.38% probability of U.S.-Russia war.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt16\"><sup>[16]</sup></a>&nbsp;A&nbsp;spreadsheet in the appendix adds further estimates to Rodriguez\u2019s table and aggregates the estimates using the geometric mean of odds rather than the arithmetic mean of probabilities, yielding a 0.986% annual probability of nuclear war.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt17\"><sup>[17]</sup></a>&nbsp;Point estimates can, however, obscure the magnitude of the uncertainty that surrounds these questions. Probability ranges can provide a more complete picture; Martin Hellman has given a rough order-of-magnitude estimate of around 1% per year in a publication by the Johns Hopkins Applied Physics Laboratory (APL), with a lower bound of 0.1% per year and an upper bound of 10% per year, based on reasoning about past crises and civilization\u2019s survival with nuclear weapons so far.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt18\"><sup>[18]</sup></a>&nbsp;</p><p>These estimates (including the estimates in this report) remain deeply flawed. There may be a problem of observer selection effects and the \u201canthropic shadow\u201d at play with global catastrophic risks \u2014 if nuclear wars have the potential to extinguish civilizations in possible worlds where they occur, then civilizations that exist to observe their histories are unlikely to have a good sense of the true frequency of nuclear wars.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt19\"><sup>[19]</sup></a>&nbsp;To the extent that many nuclear wars are likely not extinction risks <i>per se \u2014</i>&nbsp;as discussed below \u2014 this is not a strong objection to probabilistic estimates.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt20\"><sup>[20]</sup></a>&nbsp;Nonetheless, like the winners of a coin-flipping contest, we ought not assume that our good luck necessarily tells us much about the coin or about our coin-flipping skills.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt21\"><sup>[21]</sup></a>&nbsp;Moreover, the estimates about the probability of the outbreak of nuclear war obscure important distinctions about <i>different kinds</i>&nbsp;of nuclear war and about escalation probability curves.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt22\"><sup>[22]</sup></a>&nbsp;More detailed analyses simply do not exist and we ought to be suspicious of highly complex and formalized models of risk insofar as they are not grounded on reference class forecasting or other empirical bases. It may be best to follow a dictum of net assessment: \u201cmodel simple and think complex.\u201d<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt23\"><sup>[23]</sup></a></p><h2>Uncertainty on Consequences</h2><p>Second, what are the effects of nuclear war? Again, we do not really know.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt24\"><sup>[24]</sup></a>&nbsp;In the aftermath of the atomic bombings of Japan, medical personnel collected information documenting the horrors of the nuclear weapons dropped on Hiroshima and Nagasaki: blast damage, flash burns, blindness, fire, acute radiation poisoning, and long-term health effects.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt25\"><sup>[25]</sup></a>&nbsp;Nuclear testing later revealed other issues. Atomic scientists soon realized that nuclear fallout \u2014 radioactive material that is catapulted into the air and spread over the earth\u2019s surface during some nuclear explosions \u2014 could present a serious problem, as it did when radioactive ash rained on the tuna fishing boat <i>Lucky Dragon</i>&nbsp;after a 1954 U.S. nuclear test and poisoned the crew.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt26\"><sup>[26]</sup></a>&nbsp;Similarly, the 1962 Starfish Prime test of a high-altitude nuclear detonation created an unexpectedly large electro-magnetic pulse (EMP) effect, revealing yet another danger from nuclear weapons for a modern civilization that relies on EMP-vulnerable critical infrastructures.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt27\"><sup>[27]</sup></a></p><p>Nuclear testing did produce data on the observable physical effects of nuclear weapons, creating well-characterized understandings of blast radii and yields.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt28\"><sup>[28]</sup></a>&nbsp;As the scholar of nuclear risk Dr. James Scouras points out, however, our knowledge about nuclear weapons is biased towards these easily-observable and -measurable physical effects.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt29\"><sup>[29]</sup></a>&nbsp;One of the most significant effects of nuclear war is \u201cnuclear winter\u201d: the climate effects of soot in the Earth\u2019s atmosphere following firestorms after a nuclear war. This remains poorly understood. As discussed below in <a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#h.a9xuin5za3y7\"><u>The Non-Linearity of War Effects</u></a>, several aspects of nuclear winter research \u2014 including uncertainties about black carbon release and transportation into the stratosphere \u2014 lead to extreme uncertainty surrounding possible climate effects.</p><p>Beyond nuclear winter, the societal consequences of nuclear war are even more uncertain. How would widespread grief and post-traumatic stress disorder affect recovery efforts? How would agricultural practices change in response to nuclear winter? Would there be food hoarding or global cooperation to share limited resources and avert mass starvation? Could liberal democracies withstand the challenges of major nuclear war better or worse than autocracies? Would nuclear use erode norms around other weapons of mass destruction, such as strategic biological weapons? Would it hasten the development and unsafe deployment of risky emerging technologies? At what point would global civilization collapse? How likely is recovery after a civilizational collapse? How likely is a recovery with <i>good values</i>&nbsp;after a civilizational collapse? Would a totalitarian hegemon emerge in the aftermath of nuclear war? Is total human extinction likely?</p><p>Again, it is possible to build complex models to try to answer these questions, and some researchers have made admirable efforts to understand civilizational collapse, but fundamentally we are speculating on the answers to these questions.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt30\"><sup>[30]</sup></a></p><h2>Uncertainty on Risk Reduction</h2><p><i>[This section is adapted from a previous Founders Pledge report on \u201c</i><a href=\"https://docs.google.com/document/d/1H-n6QekuCFPJF5cEw76Q84bva2qYhbMHuMv-9Y58gkk/edit%23\"><i><u>Philanthropy to the Right of Boom</u></i></a><i>.\u201d Readers familiar with that document may wish to skip to the section on </i><a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#h.hw2jca46fs2\"><i><u>Reasoning under Uncertainty</u></i></a><i>.]</i></p><p>Third, what can we do about this risk? Once again, we do not really know. If we care about preventing all-out war between the United States and Russia, for example, what should we do? Should we fund track II&nbsp;(i.e. non-governmental) diplomatic dialogues to discuss the future of arms control after the demise of the New START agreement? Should we focus on understanding the effects of applications of new technologies such as artificial intelligence on strategic stability? Should we promote civil defense and agricultural resilience to prepare for worst case scenarios? Should we fund grassroots campaigns for nuclear arms control and disarmament?</p><p>Philanthropists may have some considerations that bear on these questions. For example, funders may believe that nuclear disarmament is an intractable goal, given the political and military realities of the world; or that the world currently represents one of the more stable distributions of capabilities. More fundamentally, however, we continue to have a poor understanding of the sources of nuclear risk, its probability, and its consequences.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt31\"><sup>[31]</sup></a>&nbsp;Unlike other issue areas where the mechanism of change is clearer, scholars of nuclear war disagree on fundamental issues, such as whether a \u201cno first-use\u201d or \u201csole purpose\u201d declaratory policy would be desirable.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt32\"><sup>[32]</sup></a>&nbsp;</p><p>This uncertainty is not just the uncertainty of any non-expert funder, that could be resolved by learning more about the field. Subject-matter experts\u2019 theories remain untested and often untestable.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt33\"><sup>[33]</sup></a>&nbsp;Historical accounts of states\u2019 behavior can provide some evidence, but these studies face the problem of the counterfactual. Probabilistic forecasting can help aggregate the \u201cwisdom of the crowd\u201d but, in questions about low-probability, high-consequence risks, these methods lack the objective scoring metrics that make them so powerful in other contexts; the data to resolve forecasts either do not exist or are too few.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt34\"><sup>[34]</sup></a>&nbsp;Similarly, new attempts in international relations to construct \u201cexperimental wargames\u201d appear promising, but also run into the problem of \u201cecological validity\u201d \u2014 how well do the games actually represent the reality they purport to simulate?<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt35\"><sup>[35]</sup></a></p><p>The problem, once again, is that the world has very limited experience with nuclear war and it is unclear how this experience translates to present challenges. Thus there is little opportunity for falsification of theories and there are limited reference classes and base rates for understanding nuclear war, the likelihood of escalation, and the consequences of different kinds of nuclear war. This allows for a wide range of plausible viewpoints and possible interventions for philanthropists.</p><p>These deep uncertainties also mean that we do not know much about what \u201csafe\u201d interventions might be. Later sections of this report suggest that interventions \u201cright of boom\u201d \u2014 after first nuclear use \u2014 may be high-impact funding opportunities: for example, developing a deeper understanding of escalation management. A common objection to this is that such interventions are dangerous because they may make war appear \u201cwinnable\u201d and may thus raise the probability of nuclear war even if they mitigate the consequences of such a war. This is a fair concern, and one that ought to be studied further (by funding more policy-relevant right-of-boom research).</p><p>It is important to note, however, that philanthropists face similarly high uncertainty about the potential downsides of more ideologically palatable interventions, such as disarmament. At first glance, disarmament appears obviously good. The current distribution of capabilities, however, may represent one of the more stable configurations and possible worlds.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt36\"><sup>[36]</sup></a>&nbsp;There has been no nuclear war since 1945, slow nuclear weapons proliferation, minimum deterrence arsenals in many nuclear states, restraint on many kinds of strategic weapons systems, and no all-out race on arsenal size for several decades.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt37\"><sup>[37]</sup></a></p><p>Whether nuclear deterrence has contributed to the \u201cLong Peace\u201d of the 20th and 21st centuries \u2014 and whether the Long Peace is a statistically meaningful phenomenon \u2014 is an issue under debate, but is a relevant factor for weighing the benefits of disarmament.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt38\"><sup>[38]</sup></a>&nbsp;Smaller arsenals may, moreover, change targeting practices such that the expected cost increases \u2014 some arguments for \u201cminimum deterrents\u201d rely on the targeting of cities, civilian populations, and industrial centers, rather than counterforce targeting.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt39\"><sup>[39]</sup></a>&nbsp;The key point is that uncertainty abounds on <i>all</i>&nbsp;risk reduction measures, including about the <i>sign </i>of interventions (i.e. whether it is net good or bad). This is discussed in greater detail below (\u201c<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#h.lq5g6acw4vd1\"><u>Is Disarmament Obviously Net-Positive?</u></a>\u201d)</p><h2>Reasoning Under Uncertainty: Impact Multipliers and Crucial Considerations</h2><p>High uncertainty on probabilities, consequences, and risk reduction is not the same as cluelessness. As explained in Founders Pledge\u2019s <i>Guide to the Changing Landscape of High-Impact Climate Philanthropy, </i>\u201cEven when we deal with large uncertainties, this does not mean we cannot make statements about the relative promise of different strategies and the likelihood that they will be highly impactful.\u201d<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt40\"><sup>[40]</sup></a></p><p>As explained in the next two sections, there are some observable features of the structure of nuclear risk and the allocation of philanthropic funds that allow philanthropists to identify crucial considerations for strategic giving and develop \u201cimpact multipliers.\u201d</p><p><i>[The rest of this section is adapted from Founders Pledge\u2019s report on \u201c</i><a href=\"https://docs.google.com/document/u/0/d/1H-n6QekuCFPJF5cEw76Q84bva2qYhbMHuMv-9Y58gkk/edit\"><i><u>Philanthropy to the Right of Boom</u></i></a><i>.\u201d Readers familiar with this document may wish to skip to the next section, </i><a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#h.fg4syzbvb6ed\"><i><u>The Changing Landscape of Nuclear Risk Reduction</u></i></a><i>.]</i></p><p>In this context, the term \u201cimpact multipliers\u201d refers to features of the world that make one funding opportunity relatively more effective than another.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt41\"><sup>[41]</sup></a>&nbsp;Stacking these multipliers makes effectiveness a \u201cconjunction of multipliers;\u201d understanding this conjunction can in turn help guide philanthropists seeking to maximize their impact under high uncertainty.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt42\"><sup>[42]</sup></a>&nbsp;Doing this may not allow us to understand <i>absolute</i>&nbsp;cost-effectiveness (in terms of lives saved per dollar), but does allow us to&nbsp;understand <i>relative </i>cost-effectiveness, and thereby rank and identify the most effective interventions.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt43\"><sup>[43]</sup></a></p><p>Not all impact multipliers are created equal, however. To systematically engage in effective giving, philanthropists must understand the largest impact multipliers \u2014 \u201ccritical multipliers\u201d. These are features that most dramatically cleave more effective interventions from less effective interventions. In global health and development, for example, one critical multiplier is simply to focus on the world\u2019s poorest people. Because of large inequalities in wealth and the decreasing marginal utility of money, helping people living in extreme poverty rather than richer people in the Global North is a critical multiplier that winnows the field of possible interventions more than many other possible multipliers.</p><p>Additional considerations \u2014 the prevalence of mosquito-borne illnesses, the low cost and scalability of bednet distribution, and more \u2014 ultimately point philanthropists in global health and development to one of the most effective interventions to reduce suffering in the near term: funding the distribution of insecticide-treated bednets.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt44\"><sup>[44]</sup></a>&nbsp;This report represents an attempt to identify defensible critical multipliers in nuclear philanthropy,<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt45\"><sup>[45]</sup></a>&nbsp;and potentially to move one step closer to finding \u201cthe nuclear equivalent of mosquito nets.\u201d<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt46\"><sup>[46]</sup></a></p><p>There are many potential impact multipliers in nuclear philanthropy. For example, as explained <a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#h.ivsf10o9ivxl\"><u>below</u></a>, focusing on states with larger nuclear arsenals is likely to be more impactful than focusing on nuclear terrorism. Nuclear terrorism would be horrific and a single attack in a city (e.g. with a dirty bomb) could kill thousands of people, injure many more, and cause long-lasting damage to the physical and mental health of millions.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt47\"><sup>[47]</sup></a>&nbsp;All-out nuclear war between the United States and Russia, however, would be many times worse. Hundreds of millions of people could die from the direct effects of a war. If we believe nuclear winter modeling, moreover, there may be many more deaths from climate effects and famine than from the blast and other direct impacts of the bombs.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt48\"><sup>[48]</sup></a>&nbsp;In the worst case, civilization could collapse. Simplifying these effects, suppose for the sake of argument that a nuclear terrorist attack could kill 100,000 people, and an all-out nuclear war could kill 1 billion people. <i>All else equal</i>, in this scenario it would be 10,000 times more effective to focus on preventing all-out war than to focus on nuclear terrorism.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt49\"><sup>[49]</sup></a></p><p>Generalizing this pattern, philanthropists ought to prioritize the largest nuclear wars (again, all else equal) when thinking about additional resources <i>at the margin</i>. This can be operationalized with real numbers \u2014 nuclear arsenal size, military spending, and other measures can serve as proxy variables for the severity of nuclear war, yielding rough multipliers.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt50\"><sup>[50]</sup></a>&nbsp;These measures are imperfect proxies \u2014 nuclear weapons can be viewed as a way to \u201coffset\u201d costly conventional military spending, as in the Eisenhower administration\u2019s First Offset strategy, which emphasized more \u201cbang for the buck\u201d \u2014 and should not be used in isolation.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt51\"><sup>[51]</sup></a>&nbsp;This could lead philanthropists to prioritize risk mitigation around adversarial relationships between the world\u2019s \u201cgreat powers.\u201d&nbsp;Similarly, because risk is a function of probability and consequence, philanthropists&nbsp;who aspire to be most effective can prioritize the nuclear relationships that are most likely to lead to war (and, further, those that are most likely to draw in larger powers).</p><p>These impact multipliers already yield useful conclusions. They suggest a focus on the behavior of major nuclear-armed states and, within this, a focus on preventing the largest wars. This may differ substantially from the approach of some traditional philanthropic actors working on nuclear security. We expand on these points in greater detail below.</p><p>The next section discusses the funding patterns of these actors in light of the changing threat landscape of the so-called \u201cNew Nuclear Age.\u201d This discussion informs the search for impact multipliers in the sections that follow later in the report.</p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p><strong>Questions for Further Investigation</strong></p><ul><li>What are the closest reference classes for forecasting the probability of nuclear war?</li><li>How can scholars establish the ecological validity (or invalidity) of synthetic data generation methods, including experimental wargaming and second-generation probabilistic forecasting?</li><li>What can natural catastrophes with solar radiation-blocking mechanisms that are similar to \u201cnuclear winter\u201d \u2014 including large-magnitude explosive volcanic eruptions and asteroid collisions \u2014 teach us about the possible global effects of nuclear war?</li><li>Can better knowledge of the <i>consequences</i>&nbsp;of nuclear war improve our understanding of the <i>probabilities</i>&nbsp;of nuclear war? (e.g., by removing doubts about observer selection effects)</li></ul></td></tr></tbody></table></figure><h1>&nbsp;</h1><h1>The Changing Landscape of Nuclear Risk Reduction</h1><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p><strong>Key Points:</strong></p><ul><li>China\u2019s growing nuclear ambitions, coupled with the influence of emerging technologies, may create unstable new dynamics.</li><li>The MacArthur Foundation\u2019s withdrawal from nuclear security and the collapse of philanthropic entities associated with FTX have led to a severe funding shortfall.</li><li>These dynamics may have created a moment of high philanthropic leverage over the field of nuclear security.</li></ul></td></tr></tbody></table></figure><p>This section outlines key features of the landscape of nuclear risk and nuclear philanthropy. In short, a large philanthropic funding gap has opened at an inconvenient time. Structural features of the world \u2014 including heightened great power competition, a multipolar nuclear order, the breakdown of traditional arms control, and rapid advances in emerging technologies \u2014 may increase nuclear risk, or at least increase uncertainty about the magnitude of that risk.</p><p>At the same time, recent large-scale funding shortfalls in nuclear philanthropy and in catastrophic risk reduction broadly have left the field scrambling for money. On the one hand, this is highly unfortunate, especially in light of the potentially increased risk during the Russo-Ukrainian war (ongoing as of this writing in 2023). On the other hand, it presents a potentially high-leverage opportunity, as grantees may be more receptive to new ideas and approaches.</p><h2>The \u201cNew Nuclear Age\u201d?</h2><p>Subject-matter experts in nuclear security so often refer to a \u201cnew nuclear age\u201d that the term has become clich\u00e9.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt52\"><sup>[52]</sup></a>&nbsp;Usually, this phrase refers to an interconnected set of observations about international security in the 2020s. The first is the idea of a \u201cmultipolar nuclear order.\u201d As described in the recent book <i>The Fragile Balance of Terror</i>,</p><blockquote><p>\u201c[T]he emergence of multiple nuclear states [since the Cold War] makes balances of power more complex and deterrence relationships more uncertain. Our theories and understanding derived from the Cold War bipolar nuclear competition leave us ill-equipped to handle the daunting challenges of this new nuclear age.\u201d<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt53\"><sup>[53]</sup></a>&nbsp;</p></blockquote><p>The question of whether more nuclear states make the world more or less safe does not, however, have an obvious answer, and there are arguments that multipolar deterrence is more stable.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt54\"><sup>[54]</sup></a>&nbsp;Once again, philanthropists ought to be epistemically humble about what they can and cannot know about nuclear risk. We should remember, moreover, that most nuclear weapons states represent a tiny fraction of the world\u2019s arsenals. The United States and Russia continue to dominate these measures:</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/tRbCjvm4cuuzm95Mv/ohjmgxas8hh8pwk9cmfv\" alt=\"\"></p><p><strong>Source: </strong>Our World in Data, using data from <i>Federation of American Scientists</i>.</p><p>&nbsp;</p><p>These reductions are even more significant than they look by warhead count; weapon yields were also decreasing dramatically with the removal of multi-megaton warheads from arsenals.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt55\"><sup>[55]</sup></a>&nbsp;In general, assessing both absolute and relative nuclear capabilities is far more complicated than mere warhead counts can illustrate, with additional considerations including not only yield but also reliability.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt56\"><sup>[56]</sup></a></p><p>One emerging exception to the dominance of the United States and Russia is China, the third-largest nuclear power and one of the United States\u2019s main strategic rivals. In late 2022, the U.S. Department of Defense suggested in its <i>China Military Power Report</i>&nbsp;that \u201cIf China continues the pace of its nuclear expansion, it will likely field a stockpile of about 1500 warheads by its 2035 timeline.\u201d<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt57\"><sup>[57]</sup></a>&nbsp;If we take this estimate at face value, and for simplicity assume that other stockpiles will remain unchanged, China\u2019s arsenal is still small compared to U.S.-U.S.S.R. Cold War heights, but becomes an appreciable fraction of the world total by 2035:</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/tRbCjvm4cuuzm95Mv/qtscfcqw24u1dcs6wz9i\" alt=\"\"></p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/tRbCjvm4cuuzm95Mv/fshxu4mgrjq6nnv5z001\" alt=\"\"></p><p><strong>Source: </strong>Author\u2019s visualizations based on Our World in Data illustration (above), combining Our World in Data dataset and the U.S. Department of Defense China Military Power Report projection (2022).</p><p>&nbsp;</p><p>Warhead number is not the only salient feature of China\u2019s changing nuclear ambitions.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt58\"><sup>[58]</sup></a>&nbsp;Additional developments include building out a nuclear triad, testing a \u201cfractional orbital bombardment system\u201d with a hypersonic glide vehicle in 2021 (though China denies this was the purpose of the test in question), building 300 new missile silos, and potentially even changing fundamental parts of Chinese nuclear posture and policy.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt59\"><sup>[59]</sup></a>&nbsp;In short, China\u2019s nuclear arsenal and policy are changing drastically and quickly.</p><p>&nbsp;</p><h3>The Three Body Problem</h3><p>The features discussed above lead to another fact of the \u201cnew nuclear age\u201d \u2014 renewed great power competition and the problem of &nbsp;\u201cthree-way deterrence\u201d between Russia, China, and the United States. The broader problem of conflict between major military powers is discussed in Founders Pledge\u2019s report on <a href=\"https://assets.ctfassets.net/x5sq5djrgbwu/1cT1AsYCIomlUhOque0JgW/74ffb0b1a4803e1f9654e86e2c7f3af1/Great_Power_Conflict_report_-_Founders_Pledge.pdf\"><i><u>Great Power Conflict</u></i></a>. U.S. national security strategy documents also emphasize great power competition, but Founders Pledge\u2019s focus on the issue stems from a desire to prevent human suffering and catastrophe <i>globally</i>, not from a pursuit of national interests. The 2022 National Defense Strategy lists great power competition as part of several \u201ctop-level priorities\u201d: \u201cDefending the homeland, paced to the growing multi-domain threat posed by the People\u2019s Republic of China (PRC)\u201d and \u201cDeterring aggression, while being prepared to prevail in conflict when necessary \u2013 prioritizing the PRC challenge in the Indo-Pacific region, then the Russia challenge in Europe.\u201d<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt60\"><sup>[60]</sup></a>&nbsp;Similarly, the 2022 Nuclear Posture Review singles out the PRC as a primary factor in U.S. evaluation of nuclear deterrence:</p><blockquote><p>\u201cThe People\u2019s Republic of China (PRC) is the overall pacing challenge for U.S. defense planning and a growing factor in evaluating our nuclear deterrent. The PRC has embarked on an ambitious expansion, modernization, and diversification of its nuclear forces and established a nascent nuclear triad. The PRC likely intends to possess at least 1,000 deliverable warheads by the end of the decade.\u201d<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt61\"><sup>[61]</sup></a></p></blockquote><p>Competition with a near-peer competitor (the USSR) drove U.S. nuclear policy during the Cold War, too, but the challenge of \u201cthree-way deterrence\u201d with two near-peer competitors&nbsp;is new.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt62\"><sup>[62]</sup></a>&nbsp;Cold War game-theoretic models were designed largely with one major adversary in mind, but the 2022 Nuclear Posture Review makes it clear that the U.S. now believes it will need to deter two major nuclear powers.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt63\"><sup>[63]</sup></a>&nbsp;Some of these issues are structural: negotiations become more complex when more than two parties must agree. Other issues may relate to targeting policy: new and challenging considerations arise over counter-force targeting and what kinds of deterrence regimes appear most desirable to states in three-way deterrence.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt64\"><sup>[64]</sup></a>&nbsp;Not all changes are necessarily destabilizing:<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt65\"><sup>[65]</sup></a></p><ul><li>\u201cTruels\u201d (i.e., single-shot duels between three players) may further disincentivize first strikes, depending on the balance of capabilities;</li><li>The existence of an additional large nuclear power may make a single coercive Russian nuclear monopoly less likely in certain catastrophic scenarios;</li><li>These dynamics may make it easier in some situations for a third party to de-escalate crises between the other two.</li></ul><p>Again, we do not know how these considerations will stack up; uncertainty is high. For these reasons, leaders of U.S. Strategic Command have expressed concern about what Admiral Charles Richards has compared to the \u201cthree-body problem\u201d in physics, stating that \u201cI\u2019m not sure what strategic stability looks like in a three-party world,\u201d that STRATCOM has been \u201cfuriously\u201d working on renewed deterrence theory, and that he remains deeply pessimistic despite this work: \u201cThere are exactly zero stable [...] three-body orbital regimes.\u201d<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt66\"><sup>[66]</sup></a></p><h3>Emerging Technologies</h3><p>A third feature of the \u201cNew Nuclear Age\u201d&nbsp;is the impact of new and emerging technologies on the nuclear balance. Not all of these developments are equally concerning, and the threat of some technologies has been exaggerated for political purposes. Discussion of the so-called \u201chypersonic arms race,\u201d for example, seems to misunderstand basic facts about the state of missile defense technology \u2014 some of it, like homeland missile defense, is in its infancy \u2014 and about the purpose of U.S. homeland missile defenses (they are designed with North Korea and Iran, not China and Russia, in mind).<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt67\"><sup>[67]</sup></a>&nbsp;(These considerations may be different for regional systems like THAAD and Aegis, where the effects of hypersonics may be more important.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt68\"><sup>[68]</sup></a>)</p><p>Other new technologies, however, are more concerning. Among these are applications of machine learning technologies to various systems, both nuclear and conventional, and the instability that this may create. Founders Pledge\u2019s 2022 report <i>Autonomous Weapons Systems and Military AI</i>&nbsp;discusses these risks in detail under the section titled \u201c<a href=\"https://docs.google.com/document/d/1hZfuxAp4yhsjmYXBNHtHZxeYabVK1kwalTl711cyW0A/edit%23heading%3Dh.3rt4sim1bknd\"><u>Pathways to Risk</u></a>.\u201d The pathways to nuclear risk are outlined in the figure below, adapted from the same report:</p><p><strong>Autonomy in Weapon Systems and Nuclear Risk</strong></p><p>&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/tRbCjvm4cuuzm95Mv/f9dohdv1csrpq69zkexn\" alt=\"\"></p><p><strong>Source: </strong>Adapted from Founders Pledge report, <i>Autonomous Weapon Systems and Military AI </i>(\u201cPathways to Risk\u201d). N.B. This merely purports to represent <i>possible, not </i>probable, pathways.</p><p>&nbsp;</p><p>The list of potential new and emerging technologies that may affect strategic stability is long, and the signs of their effects (whether they will be positive or negative contributors to stability) are often unclear.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt69\"><sup>[69]</sup></a>&nbsp;It is possible that applications of AI in nuclear command, control, and communications (NC3) \u2014 managed appropriately \u2014 can help improve threat assessment, decrease accident risk, and lengthen decision windows in ways that reduce risk overall. One potentially dangerous application of predictive machine learning systems is for \u201cstrategic warning\u201d of nuclear attack.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt70\"><sup>[70]</sup></a>&nbsp;The Department of Defense <i>Dictionary of Military and Associated Terms </i>no longer includes a definition of strategic warning, but used to define it as \u201ca notification that enemy-initiated hostilities may be imminent\u201d and defined \u201ctactical warning\u201d in contrast as \u201ca notification that the enemy has initiated hostilities.\u201d<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt71\"><sup>[71]</sup></a>&nbsp;The incentives to adopt such systems are clear; if it provides early warning of an adversary\u2019s intended action, it provides early&nbsp;opportunity&nbsp;to prepare for that action. In the 1980s, the Soviet Union RYaN program (short for <i>Raketno-Yadernoe Napadenie, </i>or Nuclear Missile Attack) sought to quantify risk based on an aggregate of supposed strategic warning indicators dreamed up by Soviet leadership (such as \u201cthe amount of blood held in Western blood banks and the location of Western leaders\u201d).<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt72\"><sup>[72]</sup></a>&nbsp;Because there have been no examples of nuclear surprise attacks to train on, however, poorly implemented modern AI-enabled RYaN programs may be biased and increase the risk of war by giving false warnings.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt73\"><sup>[73]</sup></a>&nbsp;Again, however, analysts ought to be epistemically humble about these issues; just because they <i>could</i>&nbsp;increase the risk of war does not mean that they will.</p><p>There are large uncertainties and new moving parts to this age, such that nuclear risk subjectively <i>feels</i>&nbsp;high. On February 21, 2023, Vladimir Putin announced that Russia would suspend its participation in the New START arms control agreement between Russia and the United States.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt74\"><sup>[74]</sup></a>&nbsp;The extended agreement was set to expire in 2026, already creating an uncertain future for strategic arms control.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt75\"><sup>[75]</sup></a>&nbsp;</p><p>Whether the risk is \u2014 as the 2023 state of the \u201cDoomsday Clock\u201d at \u201c90 seconds to midnight\u201d implies \u2014 as high as it was at the height of the Cold War, when fewer risk reduction measures were in place and U.S. and Russian arsenals were much larger, is unclear.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt76\"><sup>[76]</sup></a>&nbsp;At the same time, however, current philanthropic funding for nuclear risk reduction is unusually low, creating a danger of neglect just as the world is changing; the next section discusses this funding shortfall.</p><h2>Funding Shortfalls: MacArthur and FTX</h2><p>In 2022, the <a href=\"https://founderspledge.com/funds/patient-philanthropy-fund\"><u>Founders Pledge Patient Philanthropy Fund</u></a>&nbsp;made a grant in support of an analysis by Alex Toma of the Peace and Security Funders Group on <i>The Changing Landscape of Nuclear Security Philanthropy: Risks and Opportunities in the Current Moment</i>. The analysis can be found <a href=\"https://static1.squarespace.com/static/62435b2d773bcf0ad9cbb672/t/62cee05cb38a4b2487a533e0/1657725020334/The%2BChanging%2BLandscape%2Bof%2BNuclear%2BSecurity%2BPhilanthropy.pdf\"><u>here</u></a>.</p><p>To summarize the key points of the report:</p><ul><li>In 2021, the MacArthur Foundation announced that it would withdraw its support of nuclear security grantmaking via a $30 million capstone project&nbsp;distributed over multiple recipients \u2014 final funds will be disbursed in 2023.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt77\"><sup>[77]</sup></a></li><li>MacArthur was the largest private funder of nuclear security work. Its withdrawal was described as \u201ca big blow\u201d to arms control.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt78\"><sup>[78]</sup></a>&nbsp;</li><li>This funding gap may be partially filled by the entry of new funders.</li><li>Not all of this is bad, and new funders may have the opportunity to reshape the field in beneficial ways.</li></ul><p>Since the publication of Toma\u2019s analysis, the behavior of another funder has changed this picture. In late 2022, various corporate and philanthropic entities associated with FTX and Sam Bankman-Fried collapsed and filed for bankruptcy. Grants committed by associated entities were reportedly not distributed and may be at risk of clawback in bankruptcy court.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt79\"><sup>[79]</sup></a>&nbsp;Archived pages of the now-defunct FTX Foundation\u2019s Future Fund\u2019s website show that one of the single largest grants was made in part to support nuclear grantmaking, and that global catastrophic risks and great power conflict would have been major areas of focus for future grants.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt80\"><sup>[80]</sup></a>&nbsp;The effect of the FTX collapse on this grantmaking remains uncertain, but it appears to have shrunk the pool of possible funding for nuclear security significantly.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt81\"><sup>[81]</sup></a>&nbsp;</p><p>Without new funders, the state of philanthropic funding for nuclear security looks even more dire than it did in early 2022. On average, MacArthur made grants of around $15 million per year between 2014 and 2020. Total philanthropic nuclear security funding stood at about $47 million per year, such that the field faces a <strong>32% reduction in funding.</strong><a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt82\"><sup>[82]</sup></a>&nbsp;The centrality of MacArthur to the field is visualized in Toma\u2019s report \u2014 all the organizations in MacArthur\u2019s \u201corbit\u201d are at risk of running out of funding:</p><p>&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/tRbCjvm4cuuzm95Mv/ano4ryij3ogogeyqfenz\" alt=\"\"></p><p><strong>Source: </strong>Alex Toma, <i>The Changing Landscape of Nuclear Security Philanthropy, </i>from Peace and Security Funding Index visualization.</p><p>&nbsp;</p><h2>Bad Timing, High Leverage</h2><p>In its coverage of the MacArthur withdrawal, <i>Vox</i>&nbsp;called this the \u201cworst possible time\u201d for a shortfall in nuclear security philanthropy, in light of the Russo-Ukrainian War.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt83\"><sup>[83]</sup></a>&nbsp;While it&nbsp;is&nbsp;indeed bad timing, this moment may also represent a time of unusually high leverage over the field. As Toma pointed out, \u201camidst the turmoil of this major funder leaving, there is opportunity to rethink and reshape the field.\u201d<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt84\"><sup>[84]</sup></a>&nbsp;This leverage is even higher in the wake of the FTX collapse.&nbsp;The&nbsp;field may be more open to a reassessment of strategic priorities than it otherwise would be.&nbsp;The next section outlines structural features of the problem of nuclear risk that can guide impact-oriented philanthropists in developing these priorities.</p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p><strong>Questions for Further Investigation</strong></p><ul><li>Are there strong reasons to believe that the Department of Defense\u2019s assessment of Chinese nuclear ambitions is misguided or mistaken?</li><li>What can policymakers and philanthropists learn from the stability of previous international orders with multiple great powers (e.g. Europe in the 19th Century)?</li><li>What are other ways that nuclear risk and AI risk interact?</li><li>What technologies <i>other than AI</i>&nbsp;pose major risks to nuclear stability?&nbsp;How might advances in space technology, synthetic biology, cyber operations, and non-nuclear strategic weapons generally affect&nbsp;nuclear risk?</li><li>How likely are other major philanthropists to fill the gaps left by MacArthur and FTX?</li></ul></td></tr></tbody></table></figure><h1>The Structure of the Proble</h1><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p><strong>Key Points</strong>:</p><ul><li>Large nuclear wars are disproportionately worse than limited nuclear use;</li><li>This holds from a near-term perspective, but becomes especially pronounced when factoring in existential risks such as unrecovered civilizational collapse.</li><li>It is unclear whether limited violation of the \u201cnuclear taboo\u201d would weaken or strengthen the norm of non-use; the consequences of norm violation (punishment) matter.</li><li>Funders face deep uncertainty about the effectiveness of different kinds of interventions (expanding on discussion above).</li><li>The history of \u201cclose calls\u201d suggests that there is a real risk of accidents and unintended nuclear escalation.</li><li>Cold War arsenal reductions may be undone and the possibility of arms races should not be dismissed.</li></ul></td></tr></tbody></table></figure><p>&nbsp;</p><p>The previous section framed the current moment in nuclear risk and philanthropic support of risk-reduction measures. To summarize:</p><ul><li>There are large uncertainties about the magnitude of future nuclear risk, especially around Chinese intentions and nuclear ambitions.</li><li>There has been a major funding shortfall, such that nuclear issues are unusually neglected.</li><li>This may represent a moment of high philanthropic leverage over the field.</li></ul><p>This section discusses key facts about the <i>problem</i>&nbsp;<i>structure</i>&nbsp;of nuclear risk. The aim is to reason from simple first principles, rather than try to build complex and untestable models about deterrence and arms control, and should be read in the context of philanthropic giving. Several key facts about the structure of the problem emerge:</p><ol><li><strong>Nuclear wars are not created equal</strong>&nbsp;\u2014 a<i>ll else equal</i>, if a given grant prevents a large nuclear war it is more cost effective than if it prevents a small nuclear war.</li><li>There is a <strong>superlinear relationship between war size and global war costs (in human wellbeing)</strong>&nbsp;\u2014 larger wars are disproportionately worse than smaller wars.</li><li>Funders, experts, and decision-makers face <strong>deep uncertainty about the effectiveness of interventions</strong>&nbsp;\u2014 we often simply do not know what would work best, and have no way of finding out.</li><li><strong>Accidents happen</strong>&nbsp;\u2014 the problems of nuclear crisis management and escalation control are likely here to stay, and cannot be ignored.</li><li><strong>What comes down can go back up</strong>&nbsp;\u2014 Cold War arsenal reductions are not guaranteed to be \u201csticky,\u201d and some trends suggest that states are interested in arming; the magnitude of nuclear risk could increase significantly in the near future.</li></ol><h2>Nuclear Wars Are Not Created Equal</h2><p>Some nuclear wars \u2014 such as an all-out thermonuclear war between two states with arsenals the size of the Cold War United States and Russia \u2014 could be civilization-ending events, especially but not only if we give credence to high estimates of the probability and severity of the climate effects of nuclear winter (discussed below). On the other hand, the Second World War was technically a nuclear war, but that nuclear use was not a civilization-ending event, despite its horrific consequences for the inhabitants of Hiroshima and Nagasaki.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt85\"><sup>[85]</sup></a></p><p>There is, in short, a spectrum of possible nuclear wars. At the lowest end of this spectrum (with a questionable use of the word \u201cwar\u201d) is dirty-bomb terrorism, whose direct effects are highly limited, and which is designed to incite fear in a population, rather than to maximize damage and death. At the highest end of the spectrum exist possible futures (discussed below) where many states deploy extremely large arsenals and a global conflagration could kill billions of people. Indeed, some early Cold War strategists&nbsp;believed that the distinction between \u201climited\u201d and \u201call-out\u201d nuclear war is more salient than the distinction between \u201cnuclear\u201d and \u201cnon-nuclear\u201d war.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt86\"><sup>[86]</sup></a></p><p>This fact matters because philanthropists have limited resources and must therefore prioritize both between and within issue areas. Funders therefore need to decide where to focus their efforts; \u201cpreventing the use of nuclear weapons\u201d may be too broad a concept to guide high-impact giving. Understanding this fact allows us to then make a conclusion; <i><u>all else equal</u></i><u>, it is more cost-effective if a given grant prevents large nuclear wars than if it prevents small nuclear wars</u>.</p><p>The following section discusses the implications of this in greater detail; the highly non-linear relationship of war size to war costs, especially when considering long-term effects, only underscores the importance of focusing on the largest wars.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt87\"><sup>[87]</sup></a>&nbsp;</p><h2>The Non-Linearity of War Effects</h2><p>A key feature of nuclear war is that the risk is non-linear. In large part due to climate dynamics, threshold effects, and the possibility of societal collapse, all-out nuclear wars are <i>disproportionately worse</i>&nbsp;than highly limited nuclear wars. We can demonstrate this nonlinearity by comparing the effects of the bomb used on Hiroshima in 1945 to the effects of 100 such bombs used in a hypothetical conflict between India and Pakistan. The best available estimates suggest that about 70,000 to 140,000 people died in Hiroshima alone.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt88\"><sup>[88]</sup></a>&nbsp;Two such bombs likely would cause the deaths of 140,000 to 280,000 people. A naive linear extrapolation of this would suggest that 100 times as many bombs would lead to 100 times as many deaths \u2014 7,000,000 to 14,000,000. As we will see, however, this linear extrapolation misses key effects that multiply the damage of larger nuclear wars. The next sections explain the various features of nuclear war that, although their magnitude is uncertain, stack together to create an approximately super-linear relationship between war size and war cost (though this relationship may break down at extreme war sizes, as discussed below in the section titled \u201c<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#h.20cpj4hkuh7z\"><u>Overkill and \u2018Making the Rubble Bounce\u2019</u></a>\u201d).</p><h3>Nuclear Winter</h3><p>The deaths from a war fought with 100 Hiroshima-sized weapons may be more than an order of magnitude higher than a naive linear extrapolation would suggest.This is in large part due to \u201cnuclear winter\u201d \u2014 the hypothesized climate effects that would result from soot being injected into the atmosphere during a nuclear exchange. This could block out sunlight, resulting in cooler temperatures, which would make it harder to grow food. The literature on nuclear winter is relatively small, and estimates of the severity of potential cooling effects vary widely. We have collected a table of several influential studies in <a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#h.gyvrhikwgdl4\"><u>Appendix 3</u></a>. After some initial interest in nuclear winter in the 1980s, there was a lull in research, followed by a second wave of nuclear winter studies in the 2000s and 2010s. Several of the studies in this second wave, led by Professors Alan Robock and Brian Toon, among others, focused on one hypothetical scenario: a war between India and Pakistan involving 100 15-kiloton warheads. This scenario is therefore among the best-studied.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt89\"><sup>[89]</sup></a>&nbsp;Estimates of cooling in these studies range widely, from very limited cooling mostly in polar regions, to global mean cooling of nearly 2\u00baC.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt90\"><sup>[90]</sup></a>&nbsp;Xia <i>et al.</i>&nbsp;(2022) estimated that such a war would lead to 27 million direct deaths (from the impact of the bombs), and could lead to the starvation of over 250 million people due to climate effects.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt91\"><sup>[91]</sup></a></p><p>Reisner <i>et al. </i>(2018) provide one detailed critique of&nbsp;Robock <i>et al</i>.\u2019s research. Many studies with high death toll estimates assume that human behavior will not adapt to new agricultural conditions.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt92\"><sup>[92]</sup></a>&nbsp;Several studies also do not account for the interaction of climate change with nuclear winter \u2014 a 2\u00baC cooling via soot injection in a 2\u00baC-warming world could be treated analogously to geoengineering or \u201cSolar Radiation Management\u201d (SRM) via stratospheric aerosol injection, with effects on crop yields highly uncertain.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt93\"><sup>[93]</sup></a>&nbsp;Some of the SRM literature suggests that volcanic cooling (analogous to nuclear war-induced cooling) may have only a small net negative impact on crop yields, or even a positive impact when accounting for climate change. Pongratz et al. estimated that SRM in a high (2X) CO<sub>2</sub>&nbsp;environment would actually <i>increase</i>&nbsp;global crop yield because it would decrease the stress of high temperatures while retaining CO<sub>2</sub>&nbsp;fertilization benefits.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt94\"><sup>[94]</sup></a>&nbsp;A 2018 analysis in <i>Nature</i>&nbsp;suggested that mid-21st-century cooling of 0.88\u00baC&nbsp;as a result of solar radiation management would decrease heat stress on plants but have no discernible effect on maize, soy, rice, and wheat yields when accounting for the decrease in sunlight&nbsp;(i.e., damages from scattered sunlight and benefits from slight cooling may even out in some scenarios).<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt95\"><sup>[95]</sup></a>&nbsp;Nonetheless, we should not be sanguine about the possible negative effects of sudden cooling, such as frost&nbsp;disrupting normal crop growth.</p><p>However, even if a skeptic believed that these estimates were twice as high as they should be, they would be left&nbsp;with the possibility of more than 100 million people starving. This shows that deaths increase non-linearly. Again, 70,000 to 140,000 people died in Hiroshima alone; two such bombs likely would kill 140,000 to 280,000 people, but 100 times as many bombs would kill <i>more than</i>&nbsp;100 times as many people. &nbsp;Reasoning&nbsp;in orders of magnitude, using the death tolls calculated in the nuclear winter literature suggests that moving from 1 to 2 15kt-sized nuclear explosions multiplies the deaths by a factor of 2, whereas moving from 1 to 100 15kt-sized nuclear explosions multiplies the deaths by a factor of 1,000.</p><p>Moreover, one implication of the possibility of nuclear war-induced global cooling is that there may be <i>threshold effects</i>&nbsp;roughly symmetrical to those of global warming. For instance, animals and crops domesticated during the Holocene epoch have certain temperature ranges, within which agriculture can thrive.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt96\"><sup>[96]</sup></a>&nbsp;Crops can only withstand so many days of early frost at certain temperature floors (or days of extreme heat at certain temperature ceilings); as global climate change shifts the normal distribution of the number of such days, the mass of the distribution that passes these \u201cthresholds\u201d increases non-linearly.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt97\"><sup>[97]</sup></a>&nbsp;Similar thresholds may exist for civilization as a whole \u2014 for example, a society may be able to handle only a certain amount of refugees before its institutions begin to crumble (e.g. due to xenophobic authoritarian backlash). Threshold effects are partly what drive the highly non-linear effects of climate change that are well-established in the literature on global warming:<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt98\"><sup>[98]</sup></a></p><p>&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/tRbCjvm4cuuzm95Mv/ekjz2mzbysoqj8c94n1q\" alt=\"\"></p><p>&nbsp;</p><p><strong>Source</strong>: Richard L. Revesz et al., \u201cGlobal Warming: Improve Economic Models of Climate Change,\u201d <i>Nature</i>&nbsp;508, no. 7495 (April 2014): 173\u201375, <a href=\"https://doi.org/10.1038/508173a\"><u>https://doi.org/10.1038/508173a</u></a><a href=\"https://www.zotero.org/google-docs/?broken%3DZWcSNa\">.</a>&nbsp;</p><p>&nbsp;</p><p>There are further uncertainties in the nuclear winter literature. One crucial consideration, for example, is how much of the black carbon that is produced from fires actually reaches the stratosphere; factors like time of year, cloud cover, and precipitation all affect this question.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt99\"><sup>[99]</sup></a>&nbsp;Targeting plans also affect the amount of smoke produced, and it is generally agreed that military targets would produce less and different smoke than civilian city targets with higher fuel loads.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt100\"><sup>[100]</sup></a>&nbsp;We discussed this targeting effect with Professors Robock and Toon, who agreed that targeting is a crucial consideration and that <i>in theory</i>&nbsp;targeting remote missile silos in desert-like areas (where China\u2019s missile fields are situated) would produce less smoke and therefore a less severe effect.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt101\"><sup>[101]</sup></a>&nbsp;However, while publicly-stated U.S. targeting policy&nbsp;explicitly rejects civilian targeting, some military targets may necessarily be located close to civilian areas, and targeting policies may evolve in the course of a nuclear war, such that it is highly unclear <i>where</i>&nbsp;nuclear weapons would actually be used in a war.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt102\"><sup>[102]</sup></a>&nbsp;Uncertainty on Russian and Chinese nuclear targeting is even larger.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt103\"><sup>[103]</sup></a>&nbsp;Complicating the picture even further, the burning of massive fuel loads in a large nuclear war could release greenhouse gasses that lead to increased <i>warming</i>&nbsp;over longer time scales.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt104\"><sup>[104]</sup></a></p><p>In short, we simply don\u2019t know the answers to some key questions, including how much soot different kinds of nuclear war would release into the atmosphere and how much of this soot would reach the stratosphere. Nonetheless, there is some agreement that can be gleaned from the literature: very small nuclear wars would affect the climate much less than very large nuclear wars, and perhaps not at all.</p><p>This general pattern applies not just to temperature change, but to other important factors that affect agricultural production, as shown in figure 1. of Xia <i>et al.</i>\u2019s 2022 <i>Nature Food</i>&nbsp;paper:<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt105\"><sup>[105]</sup></a></p><p>&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/tRbCjvm4cuuzm95Mv/ogtjq8bkrdjg1gec6msm\" alt=\"\"></p><p>&nbsp;</p><p><strong>Source: </strong>\u201cClimatic impacts by year after different nuclear war soot injections\u201d in Xia <i>et al., </i>\u201cGlobal food insecurity and famine from reduced crop, marine fishery and livestock production due to climate disruption from nuclear war soot injection,\u201d <i>Nature Food.</i>&nbsp;\u201cTg.\u201d refers to teragrams of black carbon; again, the exact <i>type</i>&nbsp;of nuclear war that would inject such amounts of soot is disputed. Note that higher soot injection leads to greater climatic effects.<i>&nbsp;</i></p><p>&nbsp;</p><p>&nbsp;</p><p>Therefore, while we don\u2019t know much about the probability distributions&nbsp;of nuclear winter, we can draw a stylized but useful conclusion from this literature: <u>not all nuclear wars would lead to nuclear winter, but larger wars are more likely to lead to severe climate change, and threshold effects amplify the superlinear cost of this.</u><a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt106\"><sup>[106]</sup></a>&nbsp;Once again, this may appear obvious, but it has large implications for the prioritization of marginal philanthropic resources.</p><p>&nbsp;</p><h3>Civilizational Collapse</h3><p>Taking a longer-term perspective on humanity\u2019s future, the non-linearity of the war size-to-cost relationship becomes even more extreme. The starvation of 100 million people would be a humanitarian catastrophe and one of the worst events to befall humanity thus far, killing 1.25% of the world\u2019s population. (For comparison, between 17.4 million and 50 million people died in the 1918 \u201cSpanish Flu\u201d pandemic, one of the worst pandemics in recent history, representing between 0.95% and 5.4% of the population at the time.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt107\"><sup>[107]</sup></a>)</p><p>These are horrific numbers to contemplate. An even worse \u2014 and qualitatively different \u2014 picture emerges, however, when we consider the largest possible nuclear wars, such as an all-out U.S.-Russia nuclear exchange, and the possibility that such wars could lead to the collapse of global civilization.</p><p>As discussed above, experts disagree on the severity of global cooling caused by such a war. As far as we are aware, none of the scientists involved in nuclear winter modeling claim that direct extinction is likely even from severe nuclear winter.&nbsp;In the 1980s, some scientists suggested that a U.S.-Russia exchange (with more and bigger weapons than are available today) could trigger apocalyptic cooling that would bring land temperatures as low as &nbsp;-15\u00baC to -25\u00baC, worse than the coldest parts of the last Ice Age.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt108\"><sup>[108]</sup></a>&nbsp;Today, no scholars of nuclear winter suggest such extreme effects, in part due to updated models, and in part due to reduced arsenals. Indeed, one common analogy for nuclear winter is the Toba Eruption approximately 74,000 years ago.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt109\"><sup>[109]</sup></a>&nbsp;This is a common case study for solar radiation disruption and climate shocks, as it was the largest volcanic eruption in the Quaternary period (the last 2.5 Million years).<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt110\"><sup>[110]</sup></a>&nbsp;The Toba \u201csuper-eruption\u201d was at one point theorized to have caused a near-extinction event, but more recent estimates conclude that there was no volcanic winter-induced evolutionary bottleneck, and humanity was likely not close to extinction (note, however, that this eruption was before the Agricultural Revolution, and agricultural civilization may be vulnerable in different ways).<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt111\"><sup>[111]</sup></a>&nbsp;Although the absence of evidence is not evidence of absence, the very idea of \u201cvolcanic winter\u201d was based on estimates from the 1990s that were too high by 1-2 orders of magnitude, according to a recent review of the evidence since then.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt112\"><sup>[112]</sup></a>&nbsp;This matters because the idea of \u201cnuclear winter\u201d is analogous&nbsp;in some respects (though importantly dis-analogous in others) to \u201cvolcanic winter,\u201d and it should update our beliefs about the theory that either large volcanic eruptions or<i>&nbsp;</i>nuclear war could directly cause extinction events.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt113\"><sup>[113]</sup></a></p><p>Nonetheless, a U.S.-Russia nuclear war (or a future U.S.-China nuclear war with bigger arsenals) could in theory precipitate civilizational collapse; as discussed above, our uncertainty on nuclear winter effects ought to be very large, and this uncertainty goes both ways. The deaths of hundreds of millions to billions of people in such a cataclysm is an unprecedented event, and we do not know how civilization would respond, how robust and resilient the systems-of-systems underpinning global civilization are, and whether the survivors of such a catastrophe could rebuild. Modern civilization relies on a large human population and complex large-scale infrastructure. Because larger nuclear wars are more likely to lead to severe infrastructure damage and mass starvation than smaller nuclear wars, we can draw another simplified conclusion: <u>not all nuclear wars would lead to civilizational collapse, but the largest wars will likely increase the probability of collapse.</u></p><p>&nbsp;</p><h3>Existential Catastrophe beyond Extinction</h3><p>Scholars of nuclear winter agree that global cooling would probably not <i>directly </i>cause human extinction, and that there is high uncertainty around the estimates of the length and severity of the associated cooling. Again, even the scientists who have produced the most extreme estimates of nuclear winter effects do not claim that it would constitute an extinction event <i>per se</i>&nbsp;(except insofar as it might precipitate civilizational collapse).<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt114\"><sup>[114]</sup></a>&nbsp;A recent report by the Johns Hopkins Applied Physics Laboratory explains, \u201cWhile some nuclear disarmament advocates promote the idea that nuclear winter is an extinction threat, and the general public is probably confused to the extent it is not disinterested, few scientists seem to consider it an extinction threat.\u201d<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt115\"><sup>[115]</sup></a>&nbsp;This was possibly even the case with the far larger arsenals at the height of the Cold War.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt116\"><sup>[116]</sup></a></p><p>The apparent low probability of <i>direct</i>&nbsp;extinction via nuclear winter has caused some analysts of existential risks to discount the threat of nuclear war.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt117\"><sup>[117]</sup></a>&nbsp;The Existential Risk Observatory, for example, writes \u201ccomplete extinction because of direct effects of nuclear war, although very important for non-existential reasons, is not the main existential threat.\u201d<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt118\"><sup>[118]</sup></a>&nbsp;A similar view is expressed in many other analyses, sometimes accompanied by low subjective point estimates of extinction risk.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt119\"><sup>[119]</sup></a>&nbsp;These views, though diverse, are based on three types of consideration. First, considerations like the expiration dates of some critical resources&nbsp;lead some analysts to optimistic conclusions about post-collapse worlds; there may be a \u201cgrace period\u201d where resources last long enough to support efforts to restart civilization.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt120\"><sup>[120]</sup></a>&nbsp;Second, mechanistic views of a post-collapse society suggest quasi-Malthusian \u201ccollapse equilibria,\u201d where populations are balanced against available resources.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt121\"><sup>[121]</sup></a>&nbsp;Third, statistical arguments about uncorrelated risks to disconnected groups make total extinction appear unlikely.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt122\"><sup>[122]</sup></a>&nbsp;These views appear to be widely held among scholars of existential risk.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt123\"><sup>[123]</sup></a></p><p>These arguments should not, however, lead philanthropists to completely dismiss the risk of long-term existential catastrophe emanating from global catastrophic nuclear risks. In a chapter on \u201cCollapse, Recovery, and Existential Risk\u201d in the 2023 volume <i>How Worlds Collapse</i>, Haydn Belfield of the Centre for the Study of Existential Risk at the University of Cambridge provides a critique of the \u201csanguine view\u201d of collapse risks: \u201ca collapse could destroy humanity\u2019s longterm&nbsp;potential. We cannot yet confidently rule out the prospect of permanent collapse or extinction \u2014 and we have good reasons to be concerned that a global civilization that recovered may have much worse prospects.\u201d<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt124\"><sup>[124]</sup></a>&nbsp;Broadly, Belfield argues that there is a surprising lack of interaction between collapse scholars and existential risk scholars and outlines three broad critiques of the sanguine view: historiographic biases, a neglect of deep uncertainties about collapse, and a neglect of non-extinction existential risk originating from civilizational collapse.</p><p>First, there appears to be a widespread belief that collapse would knock humanity back to an earlier \u201cstage\u201d of history, from which progress could begin anew.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt125\"><sup>[125]</sup></a>&nbsp;In fact, the idea that humanity would simply revert to a hunter-gatherer lifestyle and go through \u201cstages\u201d of increasing complexity is simplistic and possibly unrealistic \u2014 like the evolution of biological systems, cultural evolution is not directed towards a goal.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt126\"><sup>[126]</sup></a>&nbsp;In the worst case, Belfield writes, this means that modern global civilization may sit atop a fragile perch from which gradual recovery is impossible: \u201cHumanity may have climbed high up a \u2018rungless ladder\u2019 \u2014 while historic societies fell only a small distance, modern societies may reach \u2018terminal velocity\u2019.\u201d<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt127\"><sup>[127]</sup></a></p><p>Second, there is simply deep uncertainty about the risk of collapse. For example, there are risks like weapons of mass destruction (e.g. nuclear or biological weapons) falling into the hands of bad actors, for which there are very few historical analogies (only the managed collapse of the Soviet Union \u2014 see <a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#h.dvfu4ai2t2zt\"><u>Case Study on Leverage: Cooperative Threat Reduction</u></a>&nbsp;later in this report).<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt128\"><sup>[128]</sup></a>&nbsp;Most fundamentally, however, a collapse of our society is truly unprecedented.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt129\"><sup>[129]</sup></a>&nbsp;Belfield writes, \u201ca collapse of a global, industrialised society is unprecedented. We cannot be sure that extinction would not follow. The probability of extinction is low, but not imperceptibly low \u2014 it is not a rounding error from 0%.\u201d<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt130\"><sup>[130]</sup></a></p><p>Finally, extinction is only one of several possible post-collapse worlds that present an existential risk.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt131\"><sup>[131]</sup></a>&nbsp;Large-scale nuclear war may lead to the collapse of global civilization (e.g. through mass starvation caused by nuclear winter), which, in turn, could either lead to civilizational recovery, or to one of three existential catastrophes. The first is human extinction (although some analysts find this unlikely for the reasons discussed above).<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt132\"><sup>[132]</sup></a>&nbsp;The second is unrecovered civilizational collapse, in which global society is permanently stuck in a bad state (e.g. because key knowledge&nbsp;and resources such as easily-accessible fossil fuels are lost). The third is civilizational recovery with negative values, such as a totalitarian dystopia.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt133\"><sup>[133]</sup></a>&nbsp;</p><p>Belfield argues that there is a wide range of possible recoveries, including the global spread of totalitarian regime types, which would have broad negative consequences for the future of humanity.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt134\"><sup>[134]</sup></a>&nbsp;In this case, civilizational collapse with a wide range of possible outcomes could be especially bad for a number of reasons:</p><ol><li>There may be an asymmetry between possible bad outcomes and good outcomes (e.g. if the \u201cfloor\u201d on possible dystopias is much lower than the \u201cceiling\u201d on possible utopias is high, or if there are more possible bad worlds than good worlds).</li><li>Our current outcome (general peace and widespread liberalism) may be above average for possible worlds and a \u201creboot\u201d would therefore lead to a \u201cregression to the mean\u201d with likely worse outcomes.</li><li>Good outcomes may be less likely in a recovery than bad outcomes (e.g. because recovery favors militarized totalitarian regimes).</li></ol><p>For these reasons and more, Belfield argues that \u201cvalue is fragile, recovery is risky, and we should not \u2018reroll the 100-sided die\u2019.\u201d<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt135\"><sup>[135]</sup></a></p><p>Practically speaking, therefore, philanthropists should not be fanatical about prioritizing <i>extinction risks</i>&nbsp;only; we cannot dismiss the possibility that the upper end of global catastrophic nuclear risk could present many kinds of existential risks to human civilization. This uncertainty in turn may lead philanthropists to re-prioritize risks that have a higher likelihood of occurring but a presumed low conditional likelihood of <i>direct extinction</i>&nbsp;(such as nuclear war) over risks that have a lower likelihood of occurring but a presumed high conditional likelihood of direct extinction (such as risks from atomically precise manufacturing or \u201cnanotechnology\u201d). Similarly, Belfield writes, \u201c[If] there is a substantial probability that collapse could destroy humanity\u2019s long-term potential, this should change one\u2019s view of catastrophic risks: climate change, nuclear war and broad biological risks should become more important.\u201d<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt136\"><sup>[136]</sup></a>&nbsp;For the purposes of this argument, the uncertainty on the outcomes of civilizational collapse, and the possibility of long-term existential catastrophe, further add to the non-linearity of costs from nuclear war.</p><p>What about the Nuclear Taboo?</p><p>One possible objection to claims about the non-linearity of war-effects is that <i>any</i>&nbsp;nuclear use, even of just one weapon, would breach the \u201cnuclear taboo\u201d and open the floodgates to further nuclear use (and other WMD use). If this were true, then we ought to model the move from conventional war to small nuclear war to be highly discontinuous in terms of expected cost, leading to a very different risk-reduction strategy. This section outlines reasons for being skeptical of this influential claim.</p><p>To summarize the basis for these claims, some scholarship&nbsp;in international security suggests that there are normative restraints \u2014 including \u201ctaboos\u201d or strong non-use norms \u2014 on weapons of mass destruction.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt137\"><sup>[137]</sup></a>&nbsp;These scholars argue that the historical record of presidential decision-making and rhetoric provides evidence for the existence of such a taboo.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt138\"><sup>[138]</sup></a>&nbsp;Thus, if the taboo is broken, there are several concerns. A broken nuclear taboo may result in a renewed arms buildup and more frequent use of large nuclear weapons. As of recently, the United States will retire its megaton-range weapons (B83-1); nuclear weapons states appear to understand that extremely large nuclear warheads \u2014 like Tsar Bomba \u2014 are an inefficient use of fissionable material.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt139\"><sup>[139]</sup></a>&nbsp;If states\u2019 view of megaton-range weapons were to change (e.g. for reasons of prestige or national glory, if not strategic utility), then ever larger stockpiles and larger deployed arsenals could perhaps pose an elevated risk in a way that current moderate stockpiles do not. Perhaps more concerningly, it could be the case that the breach of the WMD taboo via nuclear weapons use could also make biological weapons development and use more likely, because WMD as a whole are no longer considered off limits&nbsp;\u2014 which in turn could lead to civilizational collapse and human extinction.</p><p>For the sake of argument, in this section we assume that a nuclear taboo does exist. First, the historical evidence given by scholars of the taboo does suggest that decision-makers sometimes at least act <i>as if</i>&nbsp;they observed such a taboo. Second, we want to engage with the argument on its own terms:&nbsp;assuming that a norm against nuclear use plausibly exists, are there strong reasons to believe that a norm breach would likely lead to widespread use or escalation? It is unclear from the literature on international relations how much norms matter, but evidence from earlier attempts to ban or stigmatize certain weapons classes suggest that once such a norm is breached, norm weakening <i>can</i>&nbsp;follow, but so can norm strengthening.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt140\"><sup>[140]</sup></a></p><p>Sometimes, norm breach appears to engender repeat use. For example, when would-be norm-violators believe that the costs of punishment for a violation are unlikely to outweigh the benefits of use, they may decide that the cost-benefit calculation justifies breaking an apparent norm.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt141\"><sup>[141]</sup></a>&nbsp;For example, in the early twentieth century, nations around the world attempted to negotiate a ban on submarine warfare and aerial bombardment, but the restrictions were quickly breached with the onset of World War II.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt142\"><sup>[142]</sup></a>&nbsp;The restrictions on submarine warfare did not survive the beginning of the war and were immediately broken. The restrictions on aerial bombardment were respected for several months in the early phases of the war, but once violated, resulted in large-scale bombing campaigns of civilian targets, culminating in the use of atomic bombs on Japan.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt143\"><sup>[143]</sup></a>&nbsp;It should be noted that it is not clear from either of these cases whether there ever truly existed a \u201ctaboo,\u201d or whether the attempted \u201cbans\u201d were meaningless from the very beginning. That is, it is not clear whether these apparent examples are in the same reference class as the nuclear taboo. Both were legalistic \u201cbans\u201d on weapons that were broken, rather than normatively-constraining and deeply-held moral beliefs about right and wrong (as the nuclear taboo may involve, according to some).</p><p>Indeed, some scholars suggest that the breach of a norm against the use of weapons can strengthen that very norm; for example, when norm breach is punished. James Scouras has argued that occasional norm breach may in fact be necessary for a norm to remain in place: \u201cnorms, in general, cannot endure indefinitely without periodic violations that provide tangible reminders of their value\u201d \u2014 and of the consequences of violation.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt144\"><sup>[144]</sup></a>&nbsp;Similarly, in their discussion of North Korean nuclear first use, Hahn <i>et al. </i>write:</p><blockquote><p>\u201c\u200b\u200bThere is a presumption that once violated, the norm against the use of nuclear weapons cannot endure. But, this presumption is not based on a body of research; it is possible that the response to first use could act to reaffirm the relevance of the norm and that a single violation would not necessarily irreversibly undermine the norm\u2019s existence.\u201d<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt145\"><sup>[145]</sup></a></p></blockquote><p>Is there evidence for these claims? The literature on norm erosion and robustness is thin&nbsp;and data are sparse, but they suggest that we ought to once again be highly uncertain about the <i>sign</i>&nbsp;of the value of norm breach (i.e. whether its effects will be net positive or negative).<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt146\"><sup>[146]</sup></a>&nbsp;Strong claims that breaking the nuclear taboo <i>will </i>lead to further WMD norm erosion rather than norm strengthening are simply not supported by historical evidence. Rather, an important additional variable relates to the consequences of norm breach; when other states can impose harsh costs on the violator, they may be able to deter future violations.</p><p>One relevant recent example is the breach of the chemical weapons taboo via the use of these agents against civilians in Syria in the 2010s. Richard Price has argued that the evidence on balance suggests that the norm was <i>not</i>&nbsp;weakened by this violation.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt147\"><sup>[147]</sup></a>&nbsp;First, the violation was met by strong third party condemnation, including limited conventional strikes in 2017 and 2018 by the United States and its allies that were <i>explicitly</i>&nbsp;framed as responding to the violation of the chemical weapons norm.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt148\"><sup>[148]</sup></a>&nbsp;Second, Syria\u2019s violation did not lead to widespread use of chemical weapons by the 200+ other states in the international system, even after the initial use of chemical weapons was <i>not</i>&nbsp;punished strongly by the Obama administration.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt149\"><sup>[149]</sup></a>&nbsp;Similarly, aggregated probabilistic forecasts on crowd forecasting sites now assign low probabilities to the use of chemical weapons in the Russo-Ukrainian war.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt150\"><sup>[150]</sup></a>&nbsp;On balance, therefore, if we believe that nuclear use could be similar to chemical weapons use, it is not clear that isolated norm violation would necessarily weaken (rather than strengthen or not affect) the nuclear taboo.</p><p>Finally, as emphasized later in this report, <i>accidents happen,</i>&nbsp;and the historical frequency of \u201cclose calls\u201d suggests that we ought not to be sanguine about the possibility of nuclear accidents. It is possible that miscalculation will lead to the first use of nuclear weapons, at which point the norm will have been breached. The world ought to be prepared for this scenario.</p><p><strong>Uncertainty on Existential Risk Pathways</strong></p><p>There are strong philosophical arguments for why even low probabilities of existential risks can have overwhelming moral importance.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt151\"><sup>[151]</sup></a>&nbsp;Because of the high value of preventing existential risks, even low probabilities on pathways like civilizational collapse contribute to the non-linear nature of the war size to war cost curve.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt152\"><sup>[152]</sup></a> These non-extinction existential&nbsp;risks&nbsp;emerge <i>at some point</i>&nbsp;on the escalation ladder.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt153\"><sup>[153]</sup></a>&nbsp;Importantly, we do not know how adding or removing \u201crungs\u201d from the escalation ladder shapes the probability of reaching the rungs at the end (existential catastrophe); each step can be a chance to reset or to spiral further.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt154\"><sup>[154]</sup></a>&nbsp;In our assessment, such existential risks would likely emerge <i>somewhere</i>&nbsp;between a highly limited regional nuclear war (akin to a bad natural pandemic) and a future all-out U.S.-Russia-China war (an unprecedented disaster for global civilization), and the likelihood increases as war size increases. The exact point at which these risks become large is unclear \u2014 indeed, some risks may turn out to be overblown, as discussed above. As described below, however, we only need a relatively coarse distinction between minor nuclear wars and major nuclear wars to guide philanthropic decision-making in the near-term.</p><h3>Putting it all together</h3><p>The previous sub-sections explained three intuitions about nuclear war:</p><ol><li>Not all nuclear wars would lead to nuclear winter, but larger wars are more likely to lead to more severe climate effects.</li><li>Not all nuclear winters would lead to civilizational collapse, but more severe cooling will likely increase the probability of collapse.</li><li>Not all civilizational collapse events are necessarily existential catastrophes like unrecovered collapse, but more severe wars are more likely to lead to existential catastrophe.</li></ol><p><strong>Overkill and \u201cMaking the Rubble Bounce\u201d</strong></p><p>One&nbsp;key question for further investigation is whether the superlinearity of war effects levels off at certain war sizes. For example, nuclear winter effects may be self-limiting at a certain point, due to the physics of soot particles.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt155\"><sup>[155]</sup></a>&nbsp;Scientific understanding of the stratospheric chemistry of large explosive volcanic eruptions has advanced in recent years, showing that the large amounts of sulfur aerosols involved in high-magnitude eruptions collide and form larger particles that fall out of the atmosphere before they reach the stratosphere and can cause longer-term climate effects.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt156\"><sup>[156]</sup></a>&nbsp;This explanation is backed by the work of Claudia Timmreck <i>et al</i>., which suggests that \u201cA huge atmospheric concentration of sulfate causes higher collision rates, larger particle sizes, and rapid fall out, which in turn greatly affects radiative feedbacks.\u201d<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt157\"><sup>[157]</sup></a>&nbsp;Relatedly, once a large amount of soot is in the stratosphere, the marginal effect of each additional soot particle decreases, because so much sunlight is already blocked.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt158\"><sup>[158]</sup></a>&nbsp;Finally, \u201coverkill\u201d \u2014 assigning multiple warheads to single targets \u2014 and the simple problem of running out of useful targets \u2014 could level off the non-linear effects for extremely large wars (although it is possible that additional energy could make particles more likely to be lifted into the stratosphere).<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt159\"><sup>[159]</sup></a></p><p>At the very far end of possible war sizes, it is true that the largest wars imaginable \u2014 with unprecedented arsenals bombing all liveable areas over and over again \u2014 would flatten the curve of expected costs. In Winston Churchill\u2019s memorable phrase, at some point the parties of the war are simply \u201cmak[ing] the rubble bounce.\u201d<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt160\"><sup>[160]</sup></a>&nbsp;At this point, the shape of war costs may follow a sigmoid curve, with superlinear effects leveling off <i>at some point</i>.</p><p>We hope that future research can help to resolve the questions of <i>where exactly</i>&nbsp;superlinear cost flattens into rubble-bouncing, if it does. For the purposes of philanthropic prioritization, however, we do not need to know <i>exact</i>&nbsp;answers to these questions, but can use the structure of the problem to guide decision-making under uncertainty. In fact, the <i>exact</i>&nbsp;shape of the yield-to-cost curve may be complicated, with bumps and troughs shaped by targeting strategy, the locations of military targets, weapon type, and other considerations.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt161\"><sup>[161]</sup></a>&nbsp;Moreover, the size of arsenals does not neatly translate into warhead size. For example, larger arsenals may be more able to sustain protracted nuclear war, a world of repeated nuclear use over extended periods of time \u2014 a scenario which has received almost no scholarly attention.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt162\"><sup>[162]</sup></a>&nbsp;Such a world, with repeat large-scale nuclear use over several years, may suffer a prolonged nuclear winter with far more severe consequences than expected by current models, because the soot that left the stratosphere would be replaced via new nuclear use.</p><p>We ought not to get too bogged down in this. Instead, we&nbsp;can step back to appreciate a simple guiding insight about the cost of large all-out wars that remains robust to local variations. Because the field of post-Cold War nuclear war security studies has barely begun to reason about scenarios to the \u201cright of boom\u201d (see <a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#h.yzoppjhdnte5\"><u>below</u></a>), the option space of possible interventions to fund remains small. This means that, in practice, we are not prioritizing on a smooth or continuous spectrum of interventions that try to focus on specific war sizes. Rather, all we need for philanthropic prioritization is the coarse insight that \u201cbig wars as a category are disproportionately worse than single nuclear use or highly limited nuclear wars,\u201d even if we are uncertain about the exact shape of the curve.</p><p>Again, amidst all this uncertainty, this section suggests that philanthropists can draw one simple conclusion: <u>the relationship of war size to expected cost is roughly super-linear, such that large nuclear wars are disproportionately worse</u>&nbsp;than single nuclear use or highly limited regional nuclear exchanges.</p><h2>Deep Uncertainty on Interventions</h2><p>The next key fact about the structure of the problem, as discussed in the introduction, is that there exists deep uncertainty about the effects of possible interventions. At the most extreme end of this uncertainty, it\u2019s <i>possible</i>&nbsp;that the current configuration of nuclear capabilities is among the most stable \u2014 and is indeed what has helped humanity survive the nuclear age so far. Nuclear weapons clearly have had deterrent power in <i>some</i>&nbsp;situations; for example, Nikita Kruschev explicitly told his top advisors in 1962: \u201cIn their time, the USA did the same thing [stationing missiles near the adversary], having encircled our country with missile bases. This deterred us.\u201d<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt163\"><sup>[163]</sup></a>&nbsp;Some go further, however, and argue that nuclear weapons have, for over three-quarters of a century, prevented another great power war that might have killed millions upon millions of humans.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt164\"><sup>[164]</sup></a>&nbsp;</p><p>There are two reasons to be skeptical of such extreme claims. The first is that the apparent \u201cLong Peace\u201d is not statistically as surprising as it might look when eyeballing the apparent recent decline of warfare. As the political scientist Bear Braumoeller illustrates at length in his book <i>Only the Dead, </i>for example, observing zero systemic wars since 1945 is not all that surprising if one assumes an average of two great power wars per century:<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt165\"><sup>[165]</sup></a></p><p>&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/tRbCjvm4cuuzm95Mv/yeccwwwp4tqyboatogim\" alt=\"\"></p><p><strong>Source: </strong>Braumoeller, <i>Only the Dead: The Persistence of War in the Modern Age, </i>27.</p><p>&nbsp;</p><p>Similarly, as discussed in the next section, the prevalence of nuclear close calls since 1945 suggests that the world is perhaps not as safe as proponents of the Nuclear Long Peace hypothesis suggest.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt166\"><sup>[166]</sup></a></p><p>More broadly, debates about the probability of war may miss a bigger point about the overall risk, which again is a function of probability and consequences.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt167\"><sup>[167]</sup></a>&nbsp;It is possible that nuclear weapons have decreased the probability of war while increasing its costs were it to occur. Indeed, this may continue longer historical trends in great power warfare: diminishing frequency and increasing costs.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt168\"><sup>[168]</sup></a>&nbsp;If this is the case, the net impact of a decline in the probability of war on war\u2019s expected cost \u2014 if any \u2014 remains unclear. To the extent that costs may increase non-linearly the larger a war gets for some war sizes (discussed throughout this report), a decrease in war probability along with an increase in war size may lead only to <i>greater</i>&nbsp;catastrophes.</p><p>In short, philanthropists focused on nuclear security ought to acknowledge that the evidence is complex and uncertainty is high in this debate; we do not know how much, if at all, nuclear weapons contribute to international stability on net. This uncertainty suggests starting mostly with uninformed priors across different interventions. It suggests, for example, that the relative neglectedness of interventions can guide philanthropists towards areas where we ought to expect low-hanging high-impact fruit (see <a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#h.yzoppjhdnte5\"><u>Philanthropy to the Right of Boom</u></a>).</p><h3>Is Disarmament Obviously Net-Positive?</h3><p>We ought to stress-test these ideas thoroughly, given the importance of the topic. This section seeks to stress-test the claim that there is extreme uncertainty about the <i>sign </i>of interventions using one of the strongest counterarguments \u2014 wouldn\u2019t total nuclear disarmament be obviously net positive (were it politically feasible)?</p><p>One way that nuclear disarmament could be net-negative is if the benefits of the apparent Long Peace outweighed the costs of nuclear weapons. In this section, however, we put this question aside \u2014 as discussed earlier, the existence of the Long Peace would not be statistically surprising in a world where the underlying probability of war had not changed. There exists a worse problem, however; if states fundamentally seek strategic weapons capabilities, might they develop a \u201csubstitute deterrent\u201d that was even more dangerous than nuclear weapons? The answer appears to be yes.</p><p>The history of natural pandemics shows that biological agents \u2014 like plague and influenza \u2014 can cause human death tolls on a par with those of nuclear wars. Evolution, however, optimizes for reproductive fitness, not lethality, suggesting that pathogenic agents artificially engineered for maximum destructiveness could create even greater damage, potentially up to and including human extinction.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt169\"><sup>[169]</sup></a>&nbsp;Theft from weapons labs, moreover, may be far worse with biological weapons than with nuclear weapons. A single stolen nuclear weapon or moderate amounts of missing fissile material would be great cause for concern, but difficult to deliver, and limited in effect. A single stolen sample of a weaponized infectious disease agent, on the other hand, could infect the entire world.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt170\"><sup>[170]</sup></a>&nbsp;The same logic applies to unintentional release; accidents at nuclear weapons facilities are locally limited, whereas laboratory leaks from high-containment biology laboratories could again infect the entire world. Finally, the problems of mutation and self-replication are nearly unique to biological weapons,<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt171\"><sup>[171]</sup></a>&nbsp;and make the loss of human control a large problem for biological weapons, even those weapons initially designed to be limited in scope.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt172\"><sup>[172]</sup></a>&nbsp;All else equal, therefore, a world with high bioweapons activity could&nbsp;be significantly worse than a world with high nuclear activity. Humanity and those working on catastrophic risk reduction should therefore be extremely concerned about the risk that states might substitute bioweapons for nuclear weapons, even if there is a low probability of substitution. &nbsp;</p><p>Borrowing from evolutionary biology, we can think of this as an existential risk \u201cfitness landscape\u201d with both a global optimum and local optima, as illustrated in the following figure. We can imagine an x-axis of \u201cbiological weapons activity,\u201d a y-axis of \u201cnuclear weapons activity\u201d, and a z-axis of \u201cexistential risk.\u201d The global optimum is a world without nuclear weapons and without biological weapons. We may currently be at a local optimum \u2014 a world with high nuclear weapons activity, but low biological weapons activity. It may be the case that in attempting to move from the local to the global optimum, the world slides into a worse state than before \u2014 a world with high biological weapons activity and low nuclear weapons activity:</p><p>&nbsp;</p><p><strong>The Existential Risk Landscape and Weapons Substitution</strong></p><p>Substitution (moving from world A to world C) increases total existential risk even as nuclear risk decreases. The key question is how likely A\u2192C is and how likely A\u2192B is.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/tRbCjvm4cuuzm95Mv/fd9ykfee1nyodtygigey\" alt=\"\"></p><p><strong>Source: </strong>Author\u2019s diagram.</p><p>&nbsp;</p><p>Such substitution may occur for a variety of reasons. For instance, post-war nuclear disarmament may lead states to seek other strategic deterrents, and states appear to have historically viewed biological weapons programs as similar in kind to nuclear weapons programs. According to the bioweapons scholar Malcolm Dando, part of the reason for the Nixon administration\u2019s abandonment in the late 1960s and early 1970s of biological weapons was not only that biological weapons were&nbsp;less useful&nbsp;than nuclear weapons, but that they were more difficult to monopolize:</p><blockquote><p>\u201c[T]he increasing realization that very few nations could acquire nuclear weapons of mass destruction, because of the difficulty of producing the fissile material, whereas many states could develop biological agents of mass destruction. Why not then renounce biological weapons, spread the idea that they were of little use, and even negotiate a total ban on them?\u201d<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt173\"><sup>[173]</sup></a></p></blockquote><p>Similar attitudes may have existed in France and Britain; interest in bioweapons declined as capabilities in nuclear weapons increased, as evidenced in a shift in budgetary allocations from the 1950s to the 1970s away from biological and towards nuclear programs.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt174\"><sup>[174]</sup></a>&nbsp;The claim that biological weapons programs were seen as truly \u201con a par\u201d with nuclear weapons programs is likely too strong. If this were the case, we would expect at least some variation among the post-war victors\u2019 choices of weapon. Instead, we see the same pattern \u2014 nuclear-for-bio substitution \u2014 playing out several times (though probably not independently, given the influence of alliance dynamics like NATO). Moreover, some government assessments at the time, like a Presidential Science Advisory Committee report, did support the view that biological weapons were militarily challenging (though other reports concluded the opposite).<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt175\"><sup>[175]</sup></a>&nbsp;</p><p>Biological weapons simply may have been less useful historically without sophisticated tailoring or strong and costly domestic biodefense programs, but advances in synthetic biology and applications of artificial intelligence may obviate some of these&nbsp;issues. This report intentionally avoids discussing specific bottlenecks in bioweapons development and use \u2014 and in the emerging technologies that may address these bottlenecks \u2014 to avoid spreading dangerous ideas. Stated generally, if powerful states were to pivot the talent and resources behind the nuclear weapons complex towards biological weapons, worrisome breakthroughs&nbsp;could occur. Even without such breakthroughs, the very fact of increased biodefense activities in high-containment laboratories could increase the surface area for accidents via laboratory leaks, increasing the risk of dangerous pathogens (possibly modified for increased virulence) escaping and causing devastating global pandemics.</p><p>Nonetheless, it does appear from this evidence that biological weapons programs can fill at least a <i>similar</i>&nbsp;\u201cniche\u201d to nuclear weapons. As Susan Martin has written, part of the UK and US decision to renounce biological weapons was that they \u201cjudged it unwise to develop weapons that might offer a relatively cheap and easy alternative to nuclear weapons.\u201d<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt176\"><sup>[176]</sup></a>&nbsp;In short, it is possible that even the aftermath of nuclear disarmament could be net-negative depending on states\u2019 response to disarmament \u2014 our uncertainties remain high even on interventions that seem obviously good at first glance.</p><h2>Accidents Happen</h2><p>The history of nuclear weapons illustrates one frightening fact \u2014 accidents happen. The Future of Life Institute has compiled a \u201c<a href=\"https://futureoflife.org/resource/nuclear-close-calls-a-timeline/\"><u>Timeline of Close Calls</u></a>\u201d; a list of moments in history when the world came exceptionally close to nuclear use. Reports of <i>some</i>&nbsp;of these close calls are probably exaggerated. For example, the Able Archer exercises of November 1983 are sometimes held up as examples of a time when reckless behavior nearly drove the world to nuclear war, but recent historical scholarship suggests that the situation was far less risky.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt177\"><sup>[177]</sup></a>&nbsp;Nonetheless, it is clear from many other examples&nbsp;that the world has often come very close to nuclear war.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt178\"><sup>[178]</sup></a>&nbsp;For example, during the Cuban Missile Crisis, a sole officer \u2014 Vasili Arkhipov \u2014 vetoed a captain of a Soviet nuclear-armed submarine who wanted to launch an attack in response to non-lethal depth charges dropped by U.S. ships; had Arkhipov not been on that particular submarine, the captain may have had the votes to be able to launch a nuclear-armed torpedo, and potentially start a global nuclear war.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt179\"><sup>[179]</sup></a></p><p>It is not obvious how to update on the frequency of close calls. On the one hand, they may suggest that we live in an extraordinarily risky world. On the other hand, they may suggest that the nuclear threshold is difficult to cross, even when we come very close to it. A third option is that few of the so-called close calls were truly close and that few of the examples would truly have caused nuclear war given other existing checks in place.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt180\"><sup>[180]</sup></a>&nbsp;Given the impossibility of examining counterfactual worlds, however, the <i>apparent</i>&nbsp;prevalence of close calls may make the world vulnerable to changes in how nuclear decisions are made. For example, as discussed in Founders Pledge\u2019s report on <i>Autonomous Weapons and Military AI,</i>&nbsp;the integration of machine learning systems into nuclear command, control, and communications (NC3)-related systems and decision-support systems may create dynamics (such as automation bias) that push close calls \u201cover the edge.\u201d<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt181\"><sup>[181]</sup></a></p><p>Moreover, given the problem of selective de-classification, we may expect the rate of accidents and close calls to be even higher than the known cases suggest. In short, <u>accidents happen</u>, especially when low probabilities compound over long time periods.&nbsp;This means that <i>total prevention</i>&nbsp;of nuclear war is not a plausible goal of risk reduction over the long term. Rather, we ought to insure against the worst possible worlds where close calls turn into instances of nuclear use; if war breaks out, we ought to attempt to limit its consequences.</p><h2>What Went Down Can Come Back Up</h2><p>Arms control experts have pointed to the apparent collapse of the extended New START treaty as one of the most concerning developments in nuclear security \u2014 the agreement currently places limits on all deployed strategic weapons of the U.S. and Russia, and is a cornerstone of contemporary arms control.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt182\"><sup>[182]</sup></a>&nbsp;As mentioned above, Russian president Vladimir Putin recently announced that Russia would suspend its participation in the New START arms control agreement, which had been signed in 2010 with the aim of reducing the number of deployed strategic nuclear weapons and delivery systems and establishing a new verification regime, including on-site inspections.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt183\"><sup>[183]</sup></a>&nbsp;These developments illustrate that U.S.-Russia arms control gains can be undone. Indeed, recent analysis by the Federation of American Scientists suggests that the U.S. and Russia could very rapidly <i>double</i>&nbsp;the number of deployed warheads without new START:</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/tRbCjvm4cuuzm95Mv/u21ijhyamrcqcctig5hu\" alt=\"\"></p><p><strong>Source: </strong>Matt Kora, \u201c<a href=\"https://fas.org/publication/if-arms-control-collapses-us-and-russian-strategic-nuclear-arsenals-could-double-in-size/\"><u>If Arms Control Collapses, US And Russian Strategic Nuclear Arsenals Could Double In Size</u></a>,\u201d Federation of American Scientists.</p><p>&nbsp;</p><p>China, moreover, has traditionally been reluctant to engage in arms control due to what it views as the imbalance between its nuclear forces and those of Russia and the United States.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt184\"><sup>[184]</sup></a></p><p>These facts portend bad possible futures, in which the arms control gains made in the last four decades could be undone \u2014 what went down can come back up. Imagine, for example, a world in which China, starting in 2035, chooses to arm in the same way that Russia armed between 1950 and 1985, that the United States matches this buildup weapon-for-weapon, and that Russia in turn matches the U.S. buildup weapon-for-weapon.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt185\"><sup>[185]</sup></a>&nbsp;If the Soviet Union armed like this, then China can too. Indeed, one recent (2023) analysis of China\u2019s nuclear ambitions suggested that China\u2019s longer-term expansion of its nuclear capabilities may include \u201cseeking to build an arsenal on par with Washington\u2019s and Moscow\u2019s.\u201d<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt186\"><sup>[186]</sup></a></p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/tRbCjvm4cuuzm95Mv/fpis3fll1n3ueua9g0pl\" alt=\"\">&nbsp;</p><p><strong>Source: </strong>Author\u2019s visualization&nbsp;based on <i>Our World in Data </i>dataset, assuming that China arms post-2035 as Russia did between 1960 and 1982, and that the U.S. and Russia match this build-up weapon-for-weapon.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt187\"><sup>[187]</sup></a></p><p>&nbsp;</p><p>We can imagine, furthermore, that a rising India, threatened by the armament of its neighbor and rival China, might decide to pursue an arms buildup, too, matching the rate of the United States starting in 1954 (when the U.S. arsenal was similar in size to India\u2019s arsenal today). Pakistan, in turn (perhaps with support from China), might match India weapon-for-weapon. Again, these need not be strategically rational choices \u2014 political considerations and ideas about national glory can drive arms buildups. Suddenly, the world would find itself in a much worse position than even at the height of the Cold War:</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/tRbCjvm4cuuzm95Mv/qnqsqzalve5nfj8qkmlb\" alt=\"\"></p><p><strong>Source: </strong>Author\u2019s visualization based on <i>Our World in Data </i>dataset and the scenario described above.</p><p>&nbsp;</p><p>Again, this fictional scenario is not an implausible world. Arms-limitation treaties can be undone, as Russia\u2019s \u201csuspension\u201d of New START illustrates, and there are historical precedents for these kinds of arms races (after all, the weapon numbers in the graphs above are based directly on Cold War arming). The possibility of renewed arms racing should not be overstated, however. Some states \u2014 like North Korea \u2014 face severe resource constraints that differ from the constraints on the U.S. and Russia in the Cold War.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt188\"><sup>[188]</sup></a>&nbsp;When states consider \u201chow much is enough\u201d for their nuclear deterrents, moreover, answers depend on objectives, which may not include matching their rivals weapon-for-weapon.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt189\"><sup>[189]</sup></a>&nbsp;As described above, however, we are especially concerned about U.S.-China-Russia three-way arms racing dynamics, especially in light of statements by military planners.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt190\"><sup>[190]</sup></a>&nbsp;</p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p><strong>Questions for Further Investigation</strong></p><ul><li>How valuable would more accurate information on possible nuclear winter effects &nbsp;be? How likely is it that additional funding would produce such information?</li><li>Is it possible to produce better knowledge about civilizational collapse? What are the most important crucial considerations on these questions? How likely is such knowledge to be decision-relevant to funders and policymakers?</li><li>How do different targeting policies \u2014 e.g. \u201cno cities\u201d \u2014 affect the cost functions described above?</li><li>At what point do \u201coverkill\u201d and \u201crubble-bouncing\u201d effects begin to level off the cost curve?</li><li>At what point does nuclear winter-induced global cooling begin to outweigh the global warming caused by anthropogenic climate change?</li><li>What are the biggest insecurities that could cause states like India to begin arms racing with China?</li><li>How does adding or removing \u201crungs\u201d from the escalation ladder shape the ultimate probability of reaching the most catastrophic rungs?</li></ul></td></tr></tbody></table></figure><p>&nbsp;</p><h1>Guiding Principles for High-Impact Philanthropy</h1><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p><strong>Key Points:</strong></p><ul><li>Funders ought to focus on minimizing war damage. This ultimate goal <i>may</i>&nbsp;diverge from intermediate goals like disarmament, non-use, etc.</li><li>In light of uncertainty about intervention effectiveness, funders ought to prioritize neglected strategies.</li><li>Funders can multiply their impact by focusing on \u201cgreat powers.\u201d</li><li>Funders can multiply their impact by focusing on policy advocacy to leverage societal resources.</li><li>The principle of \u201crobust diversification\u201d can help guide effective giving under the conditions described above.</li></ul></td></tr></tbody></table></figure><p>The previous section established key facts about the structure of the nuclear risk problem that philanthropists are trying to manage. This section outlines guiding principles that can be derived from this problem structure and from an impact-maximizing approach to philanthropy.</p><h2>Prioritize Minimizing Global War Damage</h2><p>Founders Pledge\u2019s <i>Guide to the Changing Landscape of High-Impact Climate Philanthropy</i>&nbsp;relies on a fundamental insight: \u201cthe goal of high-impact climate philanthropy is not to maximize emissions reductions but to minimize climate damage.\u201d<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt191\"><sup>[191]</sup></a>&nbsp;A similar guiding principle applies to high-impact nuclear philanthropy; if we want to avoid human suffering and death, our goal should be to minimize expected global war damage. This goal is not necessarily identical to other goals often pursued by philanthropists and nonprofits, including:</p><ul><li>Disarmament and a nuclear weapons-free world;</li><li>Avoiding the proliferation of nuclear weapons;</li><li>Minimizing the probability of nuclear weapons use;</li><li>Advocacy for arms control and against nuclear modernization.</li></ul><p>To be clear, these objectives do not <i>necessarily</i>&nbsp;diverge from the goal of minimizing expected damage \u2014 better arms control, for example, may be desperately needed to avoid a three-way arms race between the U.S., Russia, and China \u2014 but they are not identical. They ought to be only viewed as <i>potential intermediate objectives</i>&nbsp;that may or may not serve the ultimate goal of minimizing expected global war damage.</p><p>If we combine prioritization of minimized expected global war damagewith the facts that war damages are non-linear and accidents are possible (as discussed above), we uncover one impact multiplier for high-impact philanthropy: a<i>ll else equal</i>, <u>philanthropists ought to prioritize preventing larger nuclear wars over preventing smaller nuclear wars</u>. This prioritization of larger wars may seem obvious, but it has major implications for marginal donations. It implies, for example, that work on escalation control \u2014 how to keep a limited war limited once it has begun \u2014 could be one of the highest-leverage interventions available. As discussed below (<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#h.yzoppjhdnte5\"><u>Philanthropy to the Right of Boom</u></a>), it is also among the most neglected strategies.</p><h2>Prioritize&nbsp;Neglected Strategies</h2><p>We have already established a rough pattern&nbsp;in the importance&nbsp;of different kinds of nuclear wars, and deep uncertainty about the tractability of interventions. Given inefficiencies in the philanthropic market, <i>neglectedness \u2014 </i>how much attention and money an issue area receives<i>&nbsp;\u2014</i>&nbsp;can now become a useful guide for understanding the relative impact of interventions or areas. As described below, political and ideological considerations may drive funder and grantee behavior, leading to undue neglect of different kinds of interventions. Categories of intervention that are neglected for the wrong reasons are likely to have more low hanging fruit. Thus, if philanthropists take a hits-based approach and are deeply uncertain about tractability, neglectedness becomes a critical impact multiplier. We discuss this further in the section on <a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#h.yzoppjhdnte5\"><u>Philanthropy to the Right of Boom</u></a>, below.</p><h3>Is Everything Neglected Now?</h3><p>Much of the analysis in this report is based in part on the insights from Founders Pledge\u2019s <i>Guide to the Changing Landscape of High-Impact Climate Philanthropy. </i>One key difference between the fields of climate and nuclear philanthropy, however, is their neglectedness; the billions spent annually on climate philanthropy dwarf the millions spent on nuclear security. In light of the funding shortfalls described <a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#h.wvh8mrk9otqr\"><u>above</u></a>, we may ask, is <i>everything</i>&nbsp;neglected now? That is, is this report spilling unnecessary ink when what is required is a large-scale infusion of money into the sector?</p><p>In an ideal world, philanthropic attention to nuclear security (and to other global catastrophic risks) would increase by several orders of magnitude, but we clearly do not live in this ideal world. Therefore, it remains important to focus on <i>marginal</i>&nbsp;cost-effectiveness, especially for smaller donors. Moreover, insofar as there are misallocations in the overall philanthropic portfolio (discussed in the <a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#h.yzoppjhdnte5\"><u>Right of Boom Philanthropy</u></a>&nbsp;section below), now is an especially opportune time to correct them. Nonetheless, giving to general-purpose nuclear security organizations (such as the Ploughshares Fund or Nuclear Threat Initiative) may be a good option for some philanthropists who care about the health of the field, but disagree with the conclusions of this report.</p><h2>Multiply Impact by Shaping Great Power Behavior</h2><p>As explained in Founders Pledge\u2019s report on <i>Great Power Conflict</i>, there are strong reasons for impact-oriented philanthropists to focus on the behavior of the so-called \u201cgreat powers.\u201d<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt192\"><sup>[192]</sup></a>&nbsp;This is for two reasons. First, great powers are simply the greatest potential originators of catastrophic nuclear risk \u2014 U.S.-Russia and future U.S.-China conflict would be catastrophic, and it therefore makes sense to prioritize these relations over the actions of minor nuclear powers like Israel. As discussed in <i>Great Power Conflict:</i></p><blockquote><p>\u201cTheir military capacity allows Great Powers to compete with their rivals on the battlefield. It also allows them to affect the long-term future in a variety of ways: by facilitating cooperation or inflaming tensions, driving the development of destructive new technologies, or deploying highly-lethal weapons, including weapons of mass destruction.\u201d<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt193\"><sup>[193]</sup></a></p></blockquote><p>Second, great powers are able to lead and coerce weaker states to follow their lead. Fundamentally, this is about <i>leverage</i>&nbsp;over the world. Thus, for example, shaping the behavior of the United States is likely to affect the behavior of U.S. allies and partners, and alliances like NATO. The U.S. is therefore an especially large lever to an extent that smaller nuclear powers simply are not. These advantages are built into the rules of the international system, including through the UN Security Council and the veto power of the permanent members. These leverage factors make a focus on great power behavior a clear impact multiplier. (Because \u201cgreat power\u201d status is so fuzzy, this may be conceptualized as a simplistic binary multiplier.)</p><h2>Leverage Government Budgets via Policy Advocacy</h2><p>As in climate philanthropy, nuclear philanthropists ought to target government action through <i>advocacy</i>&nbsp;for two reasons. First, nuclear policy \u2014 unlike many other targets of philanthropic interventions \u2014 simply is the purview of governments. Secrecy and classification make it impossible for most non-governmental organizations to have a <i>full</i>&nbsp;understanding of war planning, and governments ultimately make all the decisions about nuclear weapons.</p><p>Importantly, the massive defense budgets and resources of nuclear states provide another opportunity for leverage. Many billions of dollars are spent on the nuclear weapons complex by governments. To the extent that philanthropic action can affect the allocation of these billions, advocacy (broadly defined to include things like policy-relevant think tank work), can exert more leverage than even the largest philanthropic organizations could. The following case study provides an illustration of how this impact multiplier works.</p><h3>Case Study on Leverage: Cooperative Threat Reduction</h3><p>Cooperative Threat Reduction via the Nunn-Lugar Act provides one clear case study of leveraging government budgets via policy advocacy.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt194\"><sup>[194]</sup></a>&nbsp;In the early 1990s, in the wake of the collapse of the Soviet Union, there was a concern that \u201cloose nukes\u201d in the former USSR would get into the wrong hands and lead to a massive problem of control and proliferation. Open Philanthropy (then known as GiveWell Labs), commissioned a report as part of its History of Philanthropy project that examined this case study.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt195\"><sup>[195]</sup></a>&nbsp;As that report explains, catalytic grants by the Carnegie Corporation and the MacArthur Foundation ultimately helped lead to the elimination of over 7,500 nuclear warheads, plus additional thousands of delivery systems and nearly a thousand tons of chemical weapons.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt196\"><sup>[196]</sup></a></p><p>The specific mechanism of influence is relevant for understanding the power of leveraging government budgets. Carnegie and MacArthur funded Harvard Professor Ash Carter (later Secretary of Defense) to draft a report on <i>Soviet Nuclear Fission: Control of the Nuclear Arsenal in a Disintegrating Soviet Union</i>.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt197\"><sup>[197]</sup></a>&nbsp;Senators Nunn and Lugar had already been considering legislation on the problem of loose nukes, but the report \u2014 and Carter\u2019s scientific expertise and later advisory role in the drafting of legislation \u2014 likely catalyzed and accelerated the process at a moment when time was of the essence.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt198\"><sup>[198]</sup></a>&nbsp;</p><p>We estimate that the philanthropic support behind this work was on the order of $5-10 million dollars over several years.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt199\"><sup>[199]</sup></a>&nbsp;The governmental support of the 1991 Nunn-Lugar Act, in turn, was $500 million, and the overall amount spent by the U.S. government on cooperative threat reduction between 1992 and 2005 was over $5 billion.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt200\"><sup>[200]</sup></a></p><p>If we subjectively assign only 10% of the impact to Carnegie and MacArthur, and a $10 million philanthropic investment was 10% responsible for stimulating $5 billion in government funding, then&nbsp;there exists a &nbsp;50-times multiplier of philanthropic money. Taking these numbers literally, this suggests ~75 nuclear weapons destroyed per million philanthropic dollars in expectation. Such large multipliers illustrate why the leverage of policy advocacy is crucial for reducing global catastrophic risks.</p><h2>Robust Diversification</h2><p><i>[This section is adapted from a previous Founders Pledge report on \u201c</i><a href=\"https://docs.google.com/document/d/1H-n6QekuCFPJF5cEw76Q84bva2qYhbMHuMv-9Y58gkk/edit%23\"><i><u>Philanthropy to the Right of Boom</u></i></a><i>.\u201d]</i></p><p>We have established two tentative points about nuclear philanthropy (which also hold for other international security questions):</p><ol><li>Impact-oriented philanthropists ought to prioritize preventing the largest wars, all else equal;</li><li>There is high uncertainty on the effectiveness of specific interventions, and often no way to rigorously compare them.</li></ol><p>As mentioned above, we can thus look to <i>neglectedness</i>&nbsp;as a potential impact multiplier and pursue a strategy of \u201crobust diversification\u201d to better prioritize interventions within the nuclear field. We are borrowing this concept of robust diversification from Founders Pledge\u2019s <i>Guide to the Changing Landscape of High-Impact Climate Philanthropy</i>.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt201\"><sup>[201]</sup></a></p><p>Robust diversification has two components:</p><ol><li>\u201c<strong>Portfolio diversification with negative correlations</strong>\u201d \u2014 \u201cWhen deeply uncertain about the precise returns of different strategies, we combine strategies where the uncertainties are negatively correlated, so that when one uncertainty is resolved \u2018pessimistically\u2019 chances are the other uncertainties are resolved positively.\u201d<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt202\"><sup>[202]</sup></a><br>&nbsp;</li><li>\u201c<strong>Robustness to the worst worlds\u201d </strong>\u2014 Given assumptions about non-linear damages (which apply for nuclear war, where climate effects could make the largest wars disproportionately worse than smaller wars), we ought to \u201cprioritize strategies that are effective under pessimistic assumptions.\u201d<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt203\"><sup>[203]</sup></a></li></ol><p>In practice, robustness to the worst worlds means understanding how to reduce nuclear risk \u201cwhen deterrence fails\u201d \u2014 that is, when a nuclear war breaks out. Similarly, in a great power conflict,&nbsp;we focus on&nbsp;all-out \u201ctotal war\u201d with massive targeting of cities and civilians (especially if power-law distribution assumptions about wars hold<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt204\"><sup>[204]</sup></a>). As the next section suggests, philanthropists focusing on nuclear issues appear to disproportionately neglect these very topics.</p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p><strong>Questions for Further Investigation</strong></p><ul><li>How many traditional philanthropic actors (if any) explicitly share the goal of minimizing the expected damage of nuclear war?</li><li>Can philanthropists quantify&nbsp;the benefits of prioritizing great power behavior, or should this be treated as a binary multiplier?</li><li>What organizations have the most leverage over government policies on specific areas of nuclear risk?</li><li>How should philanthropists balance the benefits of \u201ccatalytic\u201d grants to grow small organizations with the benefits of greater policy influence by more established organizations?</li><li>What other issue areas would benefit from \u201crobust diversification\u201d?</li></ul></td></tr></tbody></table></figure><p>&nbsp;</p><h1>Philanthropy to the Right of Boom</h1><p><i>[This section is adapted from a previous Founders Pledge report on \u201c</i><a href=\"https://docs.google.com/document/d/1H-n6QekuCFPJF5cEw76Q84bva2qYhbMHuMv-9Y58gkk/edit%23\"><i><u>Philanthropy to the Right of Boom</u></i></a><i>.\u201d Readers familiar with that document may wish to skip this section.</i>]</p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p><strong>Key Points</strong>:</p><ul><li>\u201cRight of boom\u201d interventions \u2014 focusing on problems arising <i>after</i>&nbsp;the first use of nuclear weapons, such as escalation control \u2014 are an important part of risk reduction;</li><li>These very interventions have been severely neglected by philanthropic funders, possibly for ideological reasons;</li><li>These facts suggest that prioritizing \u201cright of boom\u201d interventions is a promising impact multiplier for funders.</li></ul></td></tr></tbody></table></figure><h2>Right-of-Boom Neglectedness</h2><p>The field of nuclear risk reduction can be overwhelming, and the option space of possible interventions is large. The considerations outlined in the previous sections, however, point to an important distinction between interventions that helps to categorize possible funding opportunities: whether an intervention acts to the \u201cleft\u201d or \u201cright\u201d of \u201cboom\u201d \u2014 before or after nuclear first use.</p><p>The diagram below roughly outlines the difference between \u201cleft\u201d and \u201cright\u201d of boom interventions. In short, interventions that seek to act <i>before</i>&nbsp;the first use of a nuclear weapon are \u201cleft\u201d on the spectrum (akin to \u201cleft of launch\u201d), and interventions that seek to act <i>after</i>&nbsp;the first use of a nuclear weapon are \u201cright.\u201d The neatness of this division is artificial, and in practice the differences are fuzzy, but it points towards a real distinction.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/tRbCjvm4cuuzm95Mv/vxm8oh4nbwneuaxtoa1o\" alt=\"\"></p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p><strong>Left of Boom</strong></p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p><strong>Right of Boom</strong></p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><ul><li>Deterrence</li><li>Conventional escalation management and war limitation</li><li>Conventional war termination</li><li>Non-proliferation</li><li>Disarmament</li><li>Some arms control</li><li>Peace activism/advocacy</li><li>Non-use norms/\u201ctaboo\u201d</li><li>Efforts to reduce probability of nuclear use in conventional conflict</li></ul><p>&nbsp;</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><ul><li>Deterrence (e.g. of further escalation)</li><li>Nuclear escalation management and nuclear war limitation</li><li>Nuclear war termination</li><li>Deterrence failure and fighting nuclear war</li><li>Civil Defense (including food stockpiling and alternative food production)</li><li>Hotlines (war limitation or termination)<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt205\"><sup>[205]</sup></a></li><li>Understanding and mitigating climate effects of nuclear war (\u201cnuclear winter\u201d)</li><li>Planning for post-war political environment</li><li>Missile defense</li></ul><p>&nbsp;</p></td></tr></tbody></table></figure><p><strong>Source: </strong>Author\u2019s visualization.</p><p>&nbsp;</p><p>To re-emphasize, not all nuclear war is equally damaging&nbsp;and, for impact-minded philanthropists, almost all of the cost of nuclear war lies well to the right of boom on the spectrum presented here.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt206\"><sup>[206]</sup></a>&nbsp;This is especially true if, as seems likely, several of the main plausible existential risks \u2014 civilizational collapse and extreme nuclear winter \u2014 only obtain at the far right end of the spectrum. The key question therefore becomes: after nuclear first use, how can nuclear war and its damage be limited?</p><p>Funding right-of-boom interventions does not necessarily mean only funding food stockpiling or bunker-building. A \u201cright-of-boom\u201d intervention could be a large-scale research project on the problem of how to keep limited nuclear war from escalating into all-out war. As explained above, this distinction \u2014 between small and large wars \u2014 is likely among the most salient distinctions in nuclear issues for anyone interested in maximizing impact. Such a research project may find that limited war is unlikely to remain limited (e.g. there are historical base rates on escalation in other contexts, or in well-designed wargames), and thus make other right-of-boom interventions appear less promising, or it may open up new lines of research into escalation management.</p><p>Moreover, some interventions work on both sides of \u201cboom.\u201d<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt207\"><sup>[207]</sup></a>&nbsp;For example, deterrence is important both left and right of boom, e.g. to deter further escalation from a limited nuclear war. Similarly,&nbsp;war termination (of a conventional war) can be an important left-of-boom intervention&nbsp;\u2014 this may include better abilities to negotiate the terms of a peace treaty. Interventions on one side can strengthen those on the other. In short, the distinction drawn here can be useful, but we should be careful not to oversimplify the categories.</p><p>Finally, right-of-boom interventions need not be unilateral. As was recognized by some in the Cold War, right-of-boom work like civil defense can in fact be conceptualized as a kind of risk-reduction exercise analogous to arms control, which can be pursued in bilateral or even multilateral fora, track II diplomatic &nbsp;discussions, and more. For example, states can have technical exchanges on how to best protect civilian populations in the event of a nuclear war.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt208\"><sup>[208]</sup></a></p><p>The following sections ask three questions. First, is the apparent neglect of \u201cright of boom\u201d interventions a real phenomenon? Second, if it is real, is this neglect based on evidence or otherwise rigorously justified, or does it reflect other biases (e.g. political ideology)? Third, how should new funders interested in the nuclear field approach the problem of \u201cright of boom philanthropy\u201d?</p><h3>Quantifying Right-of-Boom Philanthropy</h3><p>To begin to answer these questions, we searched through all the grants in the subject area \u201cNuclear Issues\u201d of the Peace and Security Funding Index and identified any grants that may be considered \u201cright of boom\u201d based on the descriptions in the database.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt209\"><sup>[209]</sup></a>&nbsp;For ease of reference, we have included the relevant grants in the appendix.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt210\"><sup>[210]</sup></a>&nbsp;To be conservative, we also counted those grants where it was unclear whether they ought to be considered right of boom. The analysis suggests that the phenomenon identified anecdotally is real: <strong>right-of-boom projects receive at most one-thirtieth of the total funding of the nuclear field</strong>.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt211\"><sup>[211]</sup></a></p><p>&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/tRbCjvm4cuuzm95Mv/zpmagqi3majihzw6m80i\" alt=\"\"></p><p><strong>Source: </strong>Author\u2019s estimate, using data from <i>Peace and Security Funding Index</i>&nbsp;and other sources.</p><p>Because of the inclusiveness of the search, 1-in-30 is likely an <i>upper</i>&nbsp;bound estimate (i.e., the actual share is likely much smaller).<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt212\"><sup>[212]</sup></a>&nbsp;Nuclear subject-matter experts interviewed for this project also suggested that 1-in-30 intuitively seems too high. For example, James Acton, the co-director of the Carnegie Nuclear Policy Program, said \u201c1-in-30 is an upper bound [...] I have to say I would be pretty surprised if it was as much as 1-in-30.\u201d<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt213\"><sup>[213]</sup></a>&nbsp;</p><h3>Government Work Right of Boom</h3><p>Complicating this picture, some government agencies do consider right-of-boom interventions. For example, U.S. Strategic Command &nbsp;(STRATCOM) is tasked in part with understanding how a nuclear war would actually be fought, and some parts of STRATCOM may spend substantial time on right-of-boom interventions.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt214\"><sup>[214]</sup></a>&nbsp;Public traces of STRATCOM\u2019s war planning analyses and their right-of-boom focus can be found in e.g. the <i>Report on the</i>&nbsp;<i>Nuclear Employment Strategy</i>:</p><blockquote><p>\u201cto strengthen the credibility of U.S. nuclear deterrence and extended deterrence, the United States will continue to field a range of nuclear and nonnuclear capabilities that provide U.S. leadership with options that can be tailored to deter potential adversaries, assure allies and partners, achieve U.S. objectives should deterrence fail, and hedge against an uncertain future.\u201d<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt215\"><sup>[215]</sup></a></p></blockquote><p>Specifically, phrases such as \u201cIf deterrence fails, the United States will strive to end any conflict at the lowest level of damage possible and on the best achievable terms for the United States, and its allies, and partners\u201d and \u201celements of U.S. nuclear forces are intended to provide limited, flexible, and graduated response options\u201d hint at the importance of right-of-boom planning in U.S. nuclear employment strategy.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt216\"><sup>[216]</sup></a></p><p>I have so far been unable to quantify the amount of within-government right-of-boom work, and this may be impossible, given classification issues. Nonetheless, government work in some parts of the U.S. government \u2014 parts of STRATCOM, parts of Homeland Security, etc. \u2014 leans more heavily to the right of boom than some non-governmental organizations do.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt217\"><sup>[217]</sup></a>&nbsp;It is tempting to suggest that non-governmental spending left of boom is actually a corrective to governmental bias for right-of-boom interventions. In other words, the private sector is providing more balance to the overall analysis of nuclear issues. As discussed below, however, I do not think that there really is a governmental bias for right-of-boom interventions.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt218\"><sup>[218]</sup></a>&nbsp;Rather, there appear to be merely pockets of the government that truly see right-of-boom analysis as part of their portfolio. Government neglect of such critical issues related to nuclear war, though baffling, is not historically unusual. One anecdote about Herman Kahn (via Paul Bracken) illustrates this:<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt219\"><sup>[219]</sup></a></p><blockquote><p>\u201cIn a Pentagon briefing in the 1970s, Herman Kahn audaciously proclaimed that he and his colleagues at the Hudson Institute happened to be the world experts on ending a nuclear war. The Pentagon had studied many ways that a nuclear war could start, Kahn argued, but not how it would end. The audience was incredulous. One official challenged Kahn as to how anyone could possibly be an expert on ending a nuclear war. Kahn shot back: \u2018I put two junior people on it for a couple days last week. We\u2019ve thought more about it than the entire Department of Defense has.\u2019\u201d<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt220\"><sup>[220]</sup></a></p></blockquote><p>As Bracken writes, \u201cTo get an estimate wrong, there has to be an estimate in the first place. What one often finds, unfortunately, isn\u2019t estimates that are wrong, but the realization that no one has thought about any estimates at all.\u201d<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt221\"><sup>[221]</sup></a>&nbsp;On many issues right-of-boom, it appears that either no one has thought about them at all, or no-one has thought about them since the early days of the Cold War.</p><p>The limited governmental interest that does exist for these topics may, moreover, give non-governmental right-of-boom analyses and interventions more leverage over government thinking and allocations.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt222\"><sup>[222]</sup></a>&nbsp;Non-governmental analyses may also provide useful correctives to biased thinking in government. Secrecy, organizational culture, self-selection, and other sources of bias may fundamentally distort the government\u2019s analysis of right-of-boom interventions, and non-governmental analysis can provide new ideas, balance, criticism, and corrections. For example, non-governmental analysis might focus on the wellbeing of humanity rather than the U.S. national interest (to the extent that these may diverge). Moreover, STRATCOM\u2019s war planners likely take a specific \u201cwarfighting\u201d lens to right-of-boom planning that may not explore the full spectrum of right-of-boom interventions.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt223\"><sup>[223]</sup></a></p><p>Finally, government interest in right-of-boom work may increase the policy leverage of non-governmental right-of-boom analyses. James Acton explained this perspective: \u201c\u200b\u200bThe fact that STRATCOM is working on this, for me, is an argument for why we <i>should</i>&nbsp;work on it. Because it's an issue that the government cares about, and it's a lot harder to make policy change&nbsp;when the government is not thinking about an issue than when it is.\u201d<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt224\"><sup>[224]</sup></a>&nbsp;In other words, just as climate philanthropy ought to leverage government action to have the highest possible impact, so nuclear philanthropy can leverage government interest in right-of-boom interventions to maximize its impact.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt225\"><sup>[225]</sup></a></p><h2>Possible Explanations for Neglectedness</h2><p>Neglectedness is not by itself a reason to fund a class of interventions. Rather, philanthropists ought to care about <i>undue </i>neglectedness \u2014 is an issue or intervention neglected relative to its importance and tractability, and is it being neglected for the wrong reasons (i.e. reasons that do not affect the cost-effectiveness of donations)?<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt226\"><sup>[226]</sup></a>&nbsp;Therefore, this section explores possible explanations for why traditional philanthropists do not focus on right-of-boom nuclear interventions.</p><h3>Explanation 1: Differing Worldviews and Moral Priorities</h3><p>It would be uncharitable to say that most funders and grantees in nuclear weapons-related philanthropy are \u201cwrong\u201d to neglect right-of-boom interventions. Rather, the prioritization framework that would lead one to focus on the most extreme kinds of nuclear wars is simply unintuitive to many people. The idea that some nuclear wars are worse than others, for example, may not make sense to people with non-consequentialist views. Funders and grantees might believe, e.g.:</p><ul><li>The very existence of nuclear weapons is immoral, even if they are never used;<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt227\"><sup>[227]</sup></a></li><li>Disarmament and non-proliferation are ends in themselves (rather than means to prevent suffering);</li><li>The point of nuclear weapons philanthropy and advocacy is to correct past and present injustices.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt228\"><sup>[228]</sup></a></li></ul><p>Holding any of these views might lead funders to endorse the kind of allocation described above.</p><h3>Explanation 2: Right-of-Boom interventions are Politically/Ideologically Unpalatable</h3><p>Relatedly, there are political or ideological reasons why funders may neglect right-of-boom interventions. Few non-governmental analysts and scholars are incentivized to conduct right-of-boom research. James Acton explained that, \u201cIt\u2019s an issue where for very different reasons, ideologically few people have an interest in doing this work\u201d and that \u201cpeople on the [political] Left don't want to acknowledge there is a possibility of controlling nuclear war, because that could be an argument for the nuclear-armed SLCM [submarine-launched cruise missile] or the low-yield D5&nbsp;[a&nbsp;modified warhead for a Trident submarine-launched ballistic missile]&nbsp;[...] and people on the Right don't want to do this, because they look like Dr. Strangelove, and everyone thinks they're crazy.\u201d<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt229\"><sup>[229]</sup></a>&nbsp;</p><p>This may stem from the historically hawkish political associations of Cold War right-of-boom research, which to some appeared to downplay nuclear risk and accelerate the arms race.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt230\"><sup>[230]</sup></a>&nbsp;More broadly, the very idea of escalation management may simply have appeared outdated in the post-Cold War environment. As Ankit Panda explained, \u201cFor much of the last 30 years post-Cold War, the idea of studying escalation management in a nuclear war was just not where the times were taking us. Nuclear arsenals were declining. The idea of nuclear war was broadly kind of pushed aside.\u201d<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt231\"><sup>[231]</sup></a>&nbsp;Yet even in the Cold War, much right-of-boom thinking was neglected relative to the resources invested in the nuclear weapons complex and the risks taken by nuclear states. As Edward Geist, a historian and policy researcher at the RAND Corporation, has written about the relative neglect of civil defense, \u201cboth the Soviet and American governments were willing to risk the destruction of civilization, yet saw comparatively little reason to try to save it if they came to blows.\u201d<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt232\"><sup>[232]</sup></a></p><h3>Explanation 3: Right-of-Boom Interventions Present PR/optics Problems for Funders.</h3><p>Related to the points above, these kinds of interventions are also difficult for donors to justify to the public, especially if they want to appear to be focused on peace. A foundation\u2019s board, in particular, may object to funding right-of-boom interventions on grounds of the historical associations of such work with hawkish Cold Warriors.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt233\"><sup>[233]</sup></a></p><h3>Explanation 4: Right-of-Boom Interventions are too Technical for some Funders to Understand</h3><p>These kinds of interventions are often more technical than other nuclear interventions. Funding grassroots campaigns to protest nuclear weapons is easy to understand; making sure limited nuclear use does not escalate to all-out war may involve game theory or details about the yields of various weapons.</p><h3>Explanation 5: Funders Think Right-of-Boom Interventions are Intractable</h3><p>Another possible explanation is that right-of-boom interventions are fundamentally intractable in some sense. For example, a funder might believe that nuclear war, once begun, is <i>almost certain</i>&nbsp;to escalate to all-out war, such that an attempt to limit nuclear war would be futile. Similarly, attempts at civil defense have long been ridiculed as futile in the face of the overwhelming threat of nuclear war.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt234\"><sup>[234]</sup></a>&nbsp;There are two problems with this reasoning, however.</p><p>First, <u>we simply don\u2019t know whether this is true</u>. It could be the case that war limitation is highly tractable. There has been no nuclear war, and only highly theoretical work on escalation, so we do not know how intractable these interventions really are.</p><p>Second, <u>we want to be prepared for the possibility that left-of-boom interventions fail</u>; this is part of the reasoning behind robust diversification. The history of \u201cnear misses\u201d in the Cold War suggests that accidents simply do happen. The world ought to be prepared for the scenarios where we find ourselves in a nuclear war, and want to know how to limit the damage. Accidental nuclear war has almost happened several times in history; we need to make sure that every accident does not lead to the destruction of modern civilization.</p><h3>Explanation 6: Funders Think Right-of-Boom Interventions are Dangerous</h3><p>A second explanation \u2014 related to Explanation 2 \u2014 is that right-of-boom interventions are in some way dangerous. For example, one argument against studying how to keep nuclear war limited is that doing so would itself make nuclear war seem \u201cwinnable\u201d and thus weaken the nuclear taboo. Similarly, working on civil defense and resilience interventions, the argument goes, would make the war seem \u201csurvivable\u201d and thus make war more likely. Again, this fails to account for the fact that accidents and unintended escalation do happen, and need to be insured against;&nbsp;rationality is not the only thing governing whether or not the world goes to war. Second, this argument neglects the possibility that e.g. civil defense interventions increase the attacker\u2019s uncertainty about the effects of their weapons, thus potentially making nuclear use <i>less</i>&nbsp;likely.</p><p>The overall concern about moral hazard and informational hazards is valid. It is also the very concern that would be explored by questions that some people do not wish to ask, and that more funding on escalation management could help to answer.</p><h3>Explanation 7: Grantees Are Not Interested in this Work</h3><p>The previous six explanations have focused on the perspective of funders, but we should note that there may also be non-funder-related reasons for why right-of-boom projects do not get funded \u2014 grantees may simply be uninterested.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt235\"><sup>[235]</sup></a>&nbsp;Analysts at think tanks and scholars at universities may share several of the views outlined above, and may therefore not submit right-of-boom grant proposals in the first place. Moreover, a dynamic may ensue where analysts assume funders are uninterested in this work, and funders in turn are unable to find worthwhile grantees, thus making fewer grants and reinforcing the idea that traditional philanthropists won\u2019t fund this kind of project. Once again, however, this does not necessarily reflect rational reasons for the neglect of right-of-boom interventions.</p><h3>Explanation 8: Funders and Think Tanks Take Their Lead from Government Interests<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt236\"><sup>[236]</sup></a></h3><p>Finally, the non-governmental nuclear space interacts with the government in many ways, including conferences, other think tank events, and the movement of people into and out of government. The predominance of left-of-boom work in much of the nuclear enterprise (such as in the Departments of State and Energy, the National Security Council, Congress, and multilateral organizations like the IAEA) stands in contrast to the relatively few organizations who see right-of-boom work as explicitly part of their portfolio (STRATCOM, Homeland Security, and parts of National Laboratories, among others). The influence of this apparent imbalance on foundation staff and boards may in turn shape non-governmental work.</p><h2>Robust Diversification with Right-of-Boom Interventions</h2><p>This write-up outlines several tentative observations about the landscape of nuclear philanthropy:</p><ol><li>Traditional philanthropy appears to neglect right-of-boom interventions;</li><li>This is not necessarily for rational reasons, but may reflect funder biases or non-consequentialist worldviews;</li><li>Right-of-boom interventions are the very interventions that might keep a small nuclear war from becoming a civilizational-collapse event.</li></ol><p>The 30-to-1 neglectedness of these kinds of interventions, combined with these facts, seems to suggest that <u>we ought to consider the right-of-boom distinction as a potentially promising impact multiplier.</u>&nbsp;</p><p>This analysis suggests that attention and political preferences skew interventions in such a way that makes robust diversification the best strategy for effective philanthropy <i>on the margin</i>&nbsp;for nuclear philanthropy, as it does for climate philanthropy. We expect similar kinds of biases to be found in other cause areas, but we have not investigated this further. On great power war more broadly, the difference between border skirmishes and firebombing cities is similarly important \u2014 how can we prevent the worst outcomes and decrease the likelihood of escalation?</p><p>This analysis is intended as a first approach to the problem of right-of-boom philanthropy. Additional research on these kinds of interventions may be especially important in light of U.S.-China competition and conflict. Whereas research on limited war between the U.S. and Russia goes back to the early years of the Cold War, scholars of Chinese nuclear strategy have suggested that Chinese experts hold beliefs about the (un)controllability of nuclear escalation that differ fundamentally from the beliefs of U.S. experts and military strategists. <a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt237\"><sup>[237]</sup></a>&nbsp;These differences may be a major factor shaping the likelihood of nuclear war and escalation dynamics within such a war.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt238\"><sup>[238]</sup></a></p><p>Despite the preliminary nature of this analysis, however, the possibility of a 1-to-30 (and likely much higher<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt239\"><sup>[239]</sup></a>) impact multiplier helps to narrow the field of possible high-impact interventions. All else equal, philanthropists looking to maximize the relative effectiveness of their donations in reducing nuclear risk ought to leverage this neglectedness multiplier when choosing where to give.</p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p><strong>Questions for Further Investigation</strong></p><ul><li>Are right-of-boom interventions similarly neglected in other countries?</li><li>How much more neglected than 30-to-1 are right-of-boom interventions really?</li><li>How does this ratio compare to the focus in government organizations like STRATCOM?</li><li>Can proxy indicators (e.g. Minerva Grants) help us establish this ratio using publicly-available sources?</li><li>Should philanthropists factor PR concerns into their impact calculations? If so, how?</li></ul></td></tr></tbody></table></figure><p>&nbsp;</p><h1>Multiplying Impact and Sample Interventions</h1><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p><strong>Key Points:</strong></p><ul><li>Funders can use actionable \u201cimpact multipliers\u201d from the previous sections to guide their giving;</li><li>The features described in this report point towards concrete interventions that philanthropists can fund.</li></ul></td></tr></tbody></table></figure><p>This section translates the theoretical discussions of the earlier parts of this report into actionable interventions that philanthropists could fund. This is not intended to be an exhaustive list, but to show how philanthropists can use the impact multiplier framework to guide effective giving. As a reminder, key ways to multiply impact include:</p><ul><li><strong>Prioritize larger nuclear wars </strong>and focus on minimizing damage;</li><li><strong>Focus on neglected strategies</strong>, especially \u201cright-of-boom\u201d interventions;</li><li><strong>Target \u201cGreat Power\u201d behavior and policy</strong>;</li><li><strong>Leverage government budgets via advocacy</strong>;</li><li><strong>Pursue a strategy of \u201crobust diversification\u201d</strong>&nbsp;that hedges against worlds where standard approaches have failed.</li></ul><h2>Large-Scale Research and Policy Project on&nbsp;the \u201cThree Body Problem\u201d of Nuclear Deterrence</h2><p>Our highest-priority recommendation for effective philanthropy is to fund a large-scale multi-year research project on the \u201cnuclear three body problem.\u201d&nbsp;Such a research project would seek to study key questions of three-way deterrence and arms control:</p><ul><li>How must U.S. nuclear policy change to maximize strategic stability when competing with two major nuclear powers?</li><li>If deterrence fails and nuclear war breaks out between any of the major nuclear powers, how can war be limited and controlled to minimize damage?</li><li>Note that this question often cuts directly against the first.</li><li>What can game-theoretic models tell us about this problem? What other methodological approaches can help to illuminate the problem of managing this relationship?</li><li>What, if any, Cold War bipolar frameworks are still applicable in a three-body world? How can others be redesigned?</li><li>What does three-way deterrence look like in 2027, 2030, 2035? What are the expected capabilities? How can they be forecast more accurately?</li></ul><p>Based on interactions&nbsp;with experts and potential grantees and previous grants for policy-relevant research, we estimate that a high-quality smaller project could be funded at a single institution for about $250,000 to $500,000 per year, but that an investment on the order of $1 million to $10 million per year would have a more transformative impact. This could be spread among think tanks and academic institutions. Although most think tanks bill themselves as \u201cnonpartisan,\u201d this group ought to include traditionally hawkish and conservative institutions, in order to increase the chance of influencing future Republican administrations. Given our uncertainty about these issues, an approach of seeding multiple papers and studies at various institutions is more appropriate than funding a single institution at massive scale.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt240\"><sup>[240]</sup></a></p><p>In addition to research, such a project could include track II&nbsp;and track 1.5&nbsp;(unofficial with some government participation) dialogues between the United States, Russia, and China. As far as we are aware, there is currently only one track II dialogue (hosted by the Pacific Forum) that is explicitly focused on U.S.-China strategic nuclear issues (although many others touch on this topic intermittently).</p><p>If the research can be coupled with high-quality policy advocacy (closed-door policy briefings, op-eds in major newspapers, Congressional testimony), then funding of such a project could <strong>hit all the relevant impact multipliers identified above</strong>.</p><h2>Reinvigorating \u201cRight of Boom\u201d Thinking</h2><p>A second group of potential high-impact interventions for philanthropists to fund would be various policy-relevant \u201cright of boom\u201d analyses. This could be structured as a Request for Proposals, to cast a wide net for potential projects. Projects could be selected based on how well they hit the impact multipliers identified in this report.</p><p>One especially promising subset of \u201cright-of-boom\u201d work is the idea of \u201cwinter-safe deterrence,\u201d<strong>&nbsp;</strong>broadly defined.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt241\"><sup>[241]</sup></a>&nbsp;By this, we do not necessarily mean extreme arsenal reductions or the substitution of other strategic weapons, both of which have been suggested as \u201cwinter-safe\u201d approaches.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt242\"><sup>[242]</sup></a>&nbsp;Rather, we want to know whether there exist nuclear postures and capabilities that retain potential deterrent effects&nbsp;while minimizing the probability of nuclear winter. For example, can yields, burst heights, targeting policies, etc. be adjusted in such ways as to minimize soot production while retaining deterrence?<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt243\"><sup>[243]</sup></a>&nbsp;Additional considerations may include \u201ccivil defense\u201d broadly defined, as well as the problem of recuperation after nuclear war.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt244\"><sup>[244]</sup></a></p><h2>Foundational Studies and Challenging Conventional Wisdom on Nuclear War<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt245\"><sup>[245]</sup></a></h2><p>A third avenue for impact is to fund several policy-relevant \u201cfoundational studies\u201d and to challenge the \u201cconventional wisdom\u201d on nuclear war \u2014 with special emphasis on projects that seek to identify crucial considerations on great power behavior, minimizing expected war damage, and rigorously prioritizing possible policy options. As illustrated in this report and elsewhere, some commonly-held assumptions about nuclear strategy are simply false. At times, citations lead to more citations that eventually lead to speculative analyses from the 1950s, often justified with pseudo-scientific early Cold War \u201cfacts\u201d about human psychology or decision-making. Recent analysis by the Johns Hopkins Applied Physics Laboratory, for example, critically examined a family of charts claiming to illustrate \u201cwartime fatalities in the nuclear era\u201d \u2014 charts widely used by senior U.S. defense leaders and in critical policy documents \u2014 and found that the so-called graphs are irreproducible with any real data, statistically misleading, and ultimately traceable to nothing but cartoonish drawings.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt246\"><sup>[246]</sup></a>&nbsp;The field not only holds on doggedly to some dubious theories, but generally lacks diversity and new thinking; an influx of epistemic diversity may be beneficial. Foundational studies may include:</p><ul><li>Understanding the implications of uncertainty around nuclear winter for policy options;<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt247\"><sup>[247]</sup></a></li><li>Detailed analyses of neglected post-Cold War nuclear crises and how they differ (or not) from better-understood Cold War case studies;</li><li>Developing new rigorous analytic frameworks for decision-making under extreme uncertainty \u2014 possibly including the integration of probabilistic forecasting \u2014 for understanding whether a given policy option is likely to do more harm or good.</li></ul><p>Generally, any funding program supporting such studies could follow the model outlined in the previous two sections, and could be designed to specifically prioritize the impact multipliers identified in this report.</p><h2>Other Interventions</h2><ul><li><strong>Chinese views on escalation control;</strong></li><li>Chinese views on nuclear escalation remain poorly-studied, with only a small number of academic articles published on the subject.<a href=\"https://docs.google.com/document/d/e/2PACX-1vSNYal6gNEa0u3EMQv_twZ5WWecLrWmapdMe1wBKyPANuYSYJx1aIlRYMwNWokVzt-Lj1J-rN4eTIdy/pub#ftnt248\"><sup>[248]</sup></a></li><li><strong>Escalation Control on the Korean Peninsula;</strong></li><li>How can nuclear war on the Korean peninsula be limited in intensity and scope, if it were to break out?</li><li>What agreements can the United States and China reach around these risks?</li><li><strong>Escalation Control in South Asia;</strong></li><li>What are the risks of unintended escalation and nuclear use in South Asia?</li><li>What are the risks that India-Pakistan war would draw in outside powers, including China and the United States?</li><li><strong>Shaping Indian nuclear policy;</strong></li><li>What are the biggest holes in Indian civil society related to nuclear policy?</li><li>What are the most effective ways to shape India\u2019s rise in a way beneficial for international stability?</li></ul><h1>Conclusion</h1><p>This report outlined a high-level strategic approach to nuclear risk reduction. It is not, however, the final word on this issue and is intended mainly as a first attempt to consider the problem. We hope the report will help guide rapid action in light of recent philanthropic shortfalls. <strong>We encourage readers to reach out about any potential mistakes in the analysis of this report.</strong>&nbsp;</p><p>To summarize the key points of this report, funders face extreme uncertainty when thinking about nuclear risk and risk reduction measures. Nonetheless, several simple principles can help guide action-oriented philanthropists:</p><ul><li>Prioritize minimizing expected war damage, not possible intermediate goals, such as disarmament for disarmament\u2019s sake.</li><li>Recognize that large all-out wars may be disproportionately worse than limited nuclear use.</li><li>Recognize that there exists extreme uncertainty about different interventions, and that accidental nuclear use cannot be ruled out.</li><li>Leverage the power of \u201cimpact multipliers,\u201d including focusing on neglected strategies, prioritizing the \u201cgreat powers,\u201d and leveraging societal resources.</li><li>Use these insights to identify and rank the most promising interventions and re-shape the field of nuclear security for the better in light of the recent funding shortfalls.</li></ul><p>Addressing the challenges outlined in this report will require large-scale philanthropic investment and innovative thinking. The world is entering a new and potentially dangerous nuclear age, and society is vastly under-investing in mitigating this global catastrophic risk.</p><h1>About Founders Pledge</h1><p>Founders Pledge is a global nonprofit empowering entrepreneurs to do the most good possible with their charitable giving. We equip members with everything needed to maximize their impact, from evidence-led research and advice on the world\u2019s most pressing problems, to comprehensive infrastructure for global grant-making, alongside opportunities to learn and connect. To date, they have pledged over $10 billion and donated more than $850 million globally. We\u2019re grateful to be funded by our members and other generous donors. founderspledge.com&nbsp;<br>&nbsp;</p>", "user": {"username": "christian.r"}}, {"_id": "5XetJFRqT5ajd5si6", "title": "Most Effective Methods for My Problem Areas", "postedAt": "2023-07-25T20:05:21.351Z", "htmlBody": "<p>I completed the 80,000 Hours career guide. My primary problem area interests are emotional intelligence, promoting effective altruism, promoting positive values, and mental health.&nbsp;</p><p>Based on the career guide exercises, I think that advancing social-and-emotional learning (i.e., improving education) is one of the best methods for these problem areas. There are many SEL organizations that I would like to get involved with possibly as a professor.&nbsp;</p><p><i>Note: If you do not know what social-and-emotional learning is, look it up.</i></p><p>I think that communicating ideas around solving these problems through the media is an effective method as well (i.e., being an influencer). However, emotional intelligence - which includes my other problem areas - is not nearly as neglected in the media as it is in education. There is a lot of videos and books about motivation, hard work, happiness, anxiety, managing emotions, etc.</p><p>Currently, I am stuck on whether I should focus on education or the media or both. Can someone provide some advice?</p>", "user": {"username": "Cole123"}}, {"_id": "7gL7CFBmybjAjJvAw", "title": "AI Safety Hub Serbia Soft Launch", "postedAt": "2023-07-25T19:39:15.642Z", "htmlBody": "<p>TLDR; We got three-month funding from a generous individual funder to launch an AI Safety office in Serbia. We are giving free office space (and, if funding later permits, housing) to AI Safety researchers who are looking for a place to work from. Priority for citizens of countries like Russia and China who can work visa-free from Serbia while being close to Europe.&nbsp;<a href=\"https://docs.google.com/forms/d/1LQ9cE1CGjD_WMMx5IYLLeHFeXNQJx12dsu7f4_FSF7w/edit\"><u>Register interest here</u></a> or ask questions at&nbsp;<a href=\"mailto:dusan.d.nesic@efektivnialtruizam.rs\"><u>my email</u></a>. We also have a promise of partial funding for our bare-bones request (<a href=\"https://docs.google.com/spreadsheets/d/1_xRnyLYgPNPvMcXej6xfpkhxXDgXDdKfIpR2wfzaoSs/edit#gid=0\"><u>budget</u></a>) from an individual donor but are looking for a second individual donor in order to fulfill it (about 30k USD) -<a href=\"mailto:dusan.d.nesic@efektivnialtruizam.rs\"><u> reach out to me</u></a> if this may be you.&nbsp;</p><h2>Background:</h2><p>EA Serbia and AI Safety Serbia groups are small but growing (~30 people in EA Serbia, ~3 people looking to get into AIS research as a career, and ~3 to get into AIS policy). Due to Serbia\u2019s favorable Visa policy towards Russia and China, many foreigners already live here. With lower living costs than many other international hub cities, a vibrant scene, and a favorable time zone and climate, Belgrade has a growing foreigner community.</p><p>As we have seen projects such as&nbsp;<a href=\"https://ceealar.org/\"><u>CEEALAR</u></a> as important and impressive, we wish to replicate them in Serbia, where they can better serve people who may struggle to get UK visas. We also believe that having the capacity to quickly scale cheap housing for people coming from different countries is a good thing.</p><p>We also believe that we should start small, prototype, and then move larger. We have had a unique opportunity to get an office space that is NGO-friendly, has good vibes, and costs only ~550 Euros per month for office space that has three rooms and can fit 8-15 people (depending on how snug they decide to be) with a coffee shop downstairs where another 20 people can spend their time co-working, as the office and the downstairs coffee shop are under the same ownership. This is certainly less luxurious than many other EA/AI co-working places, but we have a high degree of customizability allowed to us, which we can use to make a good office space. If we grow enough, we can also move to a bigger venue, as our needs grow. Certainly, if we knew that more use could be found in an office in Serbia, getting something somewhat further from the center, which includes living and office spaces, would be better, but we do not wish to explore that until we have proof of concept and need.</p><h3>Operations details (a.k.a. how it works):</h3><p>The office is currently rented for three months, August-October, so that we can keep the favorable price instead of having to find a different place. The office space has some desks and chairs, but we are looking to acquire full funding and have people voice their needs before acquiring more furniture. The office is usually open during working hours of the coffee shop (10 AM to Midnight, except on weekends when it is 4 PM to Midnight) as they share an entrance, but exceptionally, we can accommodate special requests if someone works better at strange working hours.</p><p>Office space is given to those that are working on projects related to AI Safety as a priority, but EA research is also welcome whenever we have spare capacity (which we expect at first).</p><p>Unfortunately, we currently do not have a legal entity that can provide visa invitations for those coming from countries that require a visa - for that, we would need to gather funding before starting the process. Still, a Serbian visa is not required for many and is relatively easy to get for most.</p><p>We have a reliable real estate agent who is able to get good deals on housing in Belgrade for those that need housing assistance until we get funded and rent a co-living space as well.</p><p>For those looking to eat consistently through us, we can arrange affordable cooked meals delivered to the office or your housing (at your expense) - vegetarian or not. If we have enough interest, we can get the chef to prepare vegan food as well.</p><h3>You may want to come if:</h3><ul><li>You are an AI Safety Researcher/EA researcher looking for a base of operations for a short-medium-long term</li><li>You are keen to be close to Europe but not in the EU</li><li>You are looking for a vibrant but affordable city with plenty of things to do, and Eastern European but Westernized culture</li></ul><h2>Hiring:</h2><p>Currently, the project is managed by a few volunteers from EA Serbia, myself included. We run the operations of the office, as well as checking applications. As we grow, we would like to have some paid positions and some volunteer ones. We are looking for:</p><ul><li>Volunteers who wish to be members of the Board of Directors of the project, mostly dealing with strategic decisions and approving participants (impactful role as you empower researchers to develop their research agendas)</li><li>Project Manager, mostly dealing with day-to-day running of the project, communication with stakeholders (board, funds, participants), as well as checking reports from participants. (0.25 FTE or 0.15 FTE in bare-bones version - salary still enough to live in Serbia, but additional income may be needed for a less frugal lifestyle)</li></ul><p>Ideally, we would be hiring after we have all the funding, but if someone is passionate about the role, please reach&nbsp;<a href=\"mailto:dusan.d.nesic@efektivnialtruizam.rs\"><u>out to me</u></a>, and the first order of business can be looking for funding with your help.</p><h2>Thoughts? Feedback?</h2><p>For any questions or comments, please write to my&nbsp;<a href=\"mailto:dusan.d.nesic@efektivnialtruizam.rs\"><u>email</u></a>. If you wish to be informed of the full launch, sign up in the<a href=\"https://docs.google.com/forms/d/1LQ9cE1CGjD_WMMx5IYLLeHFeXNQJx12dsu7f4_FSF7w/edit\"><u> interest form</u></a> and note so. If you wish to come over now, fill in the interest form and send me an email as well so that I make sure to process your request quicker! The post was written in a bit of a rush, so apologies if there are details you would like to see - please reach out if so, or leave a comment below, I\u2019ll try to edit things in.</p>", "user": {"username": "Du\u0161an D. Ne\u0161i\u0107 (Dushan)"}}, {"_id": "bmrr8DFufz5Yh8yRC", "title": "Thresholds #1: What does good look like for longtermism?", "postedAt": "2023-07-25T19:17:19.800Z", "htmlBody": "<h1>Introduction</h1><p>This post seeks to estimate how much we should expect a highly cost-effective charity to spend on reducing existential risk by a certain amount. By setting a threshold for cost-effectiveness, we can be selective about which longtermist charities to recommend to donors.</p><p><strong>We appreciate feedback.</strong> We would like for this post to be the first in a sequence about cost-effectiveness thresholds for giving, and your feedback will help us write better posts.</p><h1>How many beings does extinction destroy?</h1><p><a href=\"https://docs.google.com/document/d/13zlyW449eCGuefroie6ZtbiBtOzyh3bIz18ELe4Uxxw/edit?usp=sharing\"><u>This chart</u></a> gives six estimates for the size of the moral universe that would be lost in an extinction event on Earth this century. There is a truly incredible range in the possible size of the moral universe, and the value you see in the future depends on the moral weights you put on different types of moral patients.</p><p>(Click&nbsp;<a href=\"https://www.desmos.com/calculator/jli16qljwg\"><u>this link</u></a> to explore the value of the future. You can change the moral weights on humans, vertebrates, invertebrates, and beings of the future; the number of years you expect humans and animals to live without inevitable extinction; and the number of animals and humans you expect to exist at one time, from conservative to liberal estimates. The value at the bottom,&nbsp;<i>T</i>, shows you the total value you put on the future. You can then see how changing your moral weights radically influences the value you put on the future \u2013 and you can recalculate the cost-effectiveness thresholds below based on that.)</p><p>If the universe could have between 8 x 10^9 and 5 x 10^55 morally valuable beings, then a 0.01% absolute reduction in cumulative x-risk is \u201cequivalent\u201d (given several assumptions) to saving 8 x 10^5 to 5 x 10^51 lives. This is a reduction in risk of one basis point, or bp. Note that this is a much greater accomplishment than reducing per-century x-risk by one basis point, which we will discuss later.</p><h1>How much should we pay to prevent this destruction?</h1><h2>Using near-termist thresholds as a starting point</h2><p>Using the SoGive&nbsp;<a href=\"https://thinkingaboutcharity.blogspot.com/2021/04/sogives-gold-standard-benchmarks.html\"><u>Gold Standard</u></a> for cost per life saved in a near-termist framework (\u00a35,000), this would mean a \u201cgood cost\u201d for a 0.01% absolute reduction in the cumulative risk of extinction would be between \u00a34 billion and \u00a32.5 * 10^55. For context, all the money in the world is&nbsp;<a href=\"https://www.marketwatch.com/story/this-is-how-much-money-exists-in-the-entire-world-in-one-chart-2015-12-18\"><u>probably</u></a> between \u00a310^13 and \u00a310^14.</p><p>Are either of these the thresholds we should be using? The cost-effectiveness of longtermist interventions is different from near-termist interventions:</p><ul><li>The interventions we are analyzing are of a different character.</li><li>The evidence of their cost-effectiveness is more speculative.</li><li>It might be much cheaper, or much more expensive, to prevent the loss of future life than to save a person now. It would not be useful to set a threshold that ~all highly effective longtermist charities would be above or below, when the purpose of a threshold is to help us select the top tier of existing cost-effective interventions within a cause area.</li></ul><p>Furthermore, we might never have enough evidence to say whether an intervention has reduced cumulative x-risk by a certain amount. It might be more manageable to set a threshold based on reduction in per-century x-risk.</p><h3>Per-century risk</h3><p><strong>Epistemic status</strong>: Uncertain. Please leave feedback and help us improve the math here.</p><p>Briefly looking at this, let\u2019s assume that humans will last some time into the future, and that those humans are our moral patients. (If we didn\u2019t put value on future humans, then cumulative risk would be equal to the risk of extinction for present beings. This would give us a&nbsp;<i>lower bound on a good cost for a 0.01% absolute reduction in per-century risk of \u00a34 billion.</i>)</p><p>Let\u2019s also assume for now that we are not in a time of perils, so that we have a simpler relationship between cumulative risk and per-century risk. This will give us a lower bound for what we should spend on a reduction in per-century risk under our assumption above. (Given the chance we are in a time of perils, a \u201cgood cost\u201d for a reduction in per-century risk this century would only be higher. If we are in an extreme time of perils where a reduction in per-century risk is about equivalent to a reduction in cumulative risk, then we already have our&nbsp;<i>upper bound on a good cost for a 0.01% reduction in per-century risk \u2013 \u00a32.5 * 10^55</i>.)</p><p>According to David Thorstad, assuming a future of 1 billion years, an absolute reduction in cumulative x-risk of only 1/100,000,000&nbsp;<a href=\"https://ineffectivealtruismblog.com/2023/05/27/mistakes-in-the-moral-mathematics-of-existential-risk-part-1-introduction-and-cumulative-risk/\"><u>requires</u></a> that we reduce per-century x-risk down from its current figure (estimated by Toby Ord at 1/6) at least down to below 16/10,000,000.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefaazqiu2kcq\"><sup><a href=\"#fnaazqiu2kcq\">[1]</a></sup></span></p><p>Let\u2019s try to use the same math. On the low end of the size of the future, suppose humans could exist for a maximum of 800,000 more years before inevitable extinction. Then, an absolute reduction in cumulative risk of 1/10,000 (1 bp) would require us to drive per-century risk at least down to below 11/10,000.</p><p>Bringing per-century risk from \u2159 to 11/10,000 is an absolute reduction of 1656 basis points. We might say that if the future is 800,000 years and there are 10^14 moral patients (low end) that can exist in that time, then we should pay 10^14 * 0.01% * \u00a35000 / 1656 = <strong>\u00a330.19 billion</strong><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefokr1pp79l5\"><sup><a href=\"#fnokr1pp79l5\">[2]</a></sup></span>&nbsp;to reduce per-century x-risk by 1 bp.</p><p>On the high end of the size of the future, suppose humans could exist for a maximum of 100 billion years before inevitable extinction. Then, an absolute reduction in cumulative risk of 1/10,000 (1 bp) would require us to drive per-century risk at least down to below 92/10,000,000,000.</p><p>Bringing per-century risk from \u2159 to 92/10,000,000,000 is an absolute reduction of 1667 basis points. We might say that if the future is 100 billion years and there are 5 x 10^55 moral patients (high end) that can exist in that time, then we should pay 5 * 10^55 * 0.01% * \u00a35000 / 1667 = <strong>\u00a31.50 \u00d7 10^52</strong> to reduce per-century x-risk by 1 bp.</p><p>Clearly, this is a very difficult task in either situation. What does this mean for our threshold? Do we think that reducing cumulative x-risk by one basis point is worth a different amount, when we know that it means reducing per-century x-risk so extremely?</p><ul><li>Should we tolerate a higher cost threshold for a more difficult task?</li><li>Should we reduce our tolerance for the cost, since the task may be less tractable?</li></ul><p>Overall, our range for what we should spend on a reduction in a 0.01% absolute reduction in x-risk for this century is \u00a34 billion, if you only put moral value on present humans; \u00a330.19 billion, if you believe the future is small, the class of moral patients is small, and we are not in a time of perils; \u00a31.50 \u00d7 10^52, if you predict a very large future and a large class of moral patients, and believe we are not in a time of perils; and \u00a32.5 * 10^55, if you predict a very large future and a large class of moral patients, and believe we are in an extreme time of perils.</p><h2>Using benchmarks for cost-effectiveness from current longtermist charities</h2><p>We are currently seeking estimates of how much longtermist charities are reducing x-risk. These estimates can give us a benchmark for cost-effectiveness. Benchmarking is another method we can use to set a threshold. However, estimates we get from charities for their own cost-effectiveness are likely to be biased.</p><h2>Using the estimates of others</h2><p>Now let\u2019s look at cost-effectiveness thresholds from others, taken from&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/cKPkimztzKoCkZ75r/how-many-ea-2021-usds-would-you-trade-off-against-a-0-01\"><u>this post by Linch</u></a> and&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/NbWeRmEsBEknNHqZP/longterm-cost-effectiveness-of-founders-pledge-s-climate\"><u>this post by Vasco</u></a> and their comments sections, which use USD. The table below is adapted and expanded from Vasco\u2019s post.</p><p>Most commenters seem to have been thinking of an absolute reduction of one basis point this century (it\u2019s unclear) \u2013 but one commenter, NunoSempere, gave a range for an absolute reduction by one basis point in the yearly x-risk for one century, and another range for an absolute reduction by one basis point in the x-risk this century. The commenters used a range of methods to answer the question, but their answers clustered around $1 billion.</p><p>Please note Linch\u2019s disclaimer, which likely also applies to the estimates of others:</p><p>\u201c<i>EDIT 2022/09/21: The 100M-1B estimates are relatively off-the-cuff and very not robust, I think there are good arguments to go higher or lower. I think the numbers aren't&nbsp;<strong>crazy,&nbsp;</strong>partially because others independently come to similar numbers (but some people I respect have different numbers). I don't think it's crazy to make decisions/defer roughly based on these numbers given limited time and attention. However, I'm worried about having too much secondary literature/large decisions based on my numbers, since it will likely result in</i><a href=\"https://en.wikipedia.org/wiki/Information_cascade\"><i>&nbsp;<u>information cascades</u></i></a><i>. My current tentative guess as of 2022/09/21 is that there are more reasons to go higher (think averting x-risk is more expensive) than lower. However, overspending on marginal interventions is more -EV than underspending, which pushes us to bias towards conservatism.\u201d</i></p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Estimator</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Highly cost-effective</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Middling (default column if not specified)</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Upper bound</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Linch</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><strong>$100 million per bp</strong></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><strong>$300 million per bp&nbsp;</strong>to<strong> $1 billion per bp</strong></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><strong>$10 billion per bp</strong></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Ajeya Cotra</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><a href=\"https://forum.effectivealtruism.org/posts/xb4twLYLCrSgw7eDd/ajeya-cotra-on-worldview-diversification-and-how-big-the\"><u>\u201cAI risk is something that we think has a currently higher cost effectiveness\u201d</u></a></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>\u201c$200 trillion per world saved\u201d</p><p>Or&nbsp;<strong>$20 billion per bp</strong></p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">&nbsp;</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Oliver Habryka</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">\u201cI think we are currently funding projects that are definitely more cost-effective than that\u201d</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">\u201cMy very rough gut estimate says something like\u201d&nbsp;<strong>$1 billion per bp</strong></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">\u201cProbably more on the margin\u201d</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">NunoSempere</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><strong>$99 billion per bp,</strong> lower bound assuming a \u201cone-off 0.01% existential risk reduction over a century\u201d</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><strong>$16 trillion per bp</strong>, lower bound per yearly reduction of 1bp \u2026 to&nbsp;<strong>$330T per bp</strong>, upper bound assuming a \u201cone-off 0.01% existential risk reduction over a century\u201d</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><strong>$3.8 x 10^15 per bp</strong>, upper bound per yearly reduction of 1bp</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Anonymous person from Vasco\u2019s post</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">$1 trillion per existential catastrophe averted, or<strong> $100 million per bp</strong></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">$100 trillion per existential catastrophe averted, or&nbsp;<strong>$10 billion per bp</strong></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">&nbsp;</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Simon Skade</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">\u201cNote that I do think that there are even more effective ways to reduce x-risk, and in fact I suspect most things longtermist EA is currently funding have a higher expected x-risk reduction than 0.01% per 154M$.\u201d</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><strong>$154 million per bp</strong></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">\u201cI just don't think that it is likely that the 50 billionth 2021 dollar EA spends has a much higher effectiveness than 0.01% per 154M$, so I think we should grant everything that has a higher expected effectiveness.\u201d</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">William Kiely</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><strong>$34 million per bp</strong></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>\u201cI thought it would be interesting to answer this using a wrong method (writing the bottom line first).\u201d</p><p>~&nbsp;<strong>$100 million per bp</strong></p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><strong>$340 million per bp</strong></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Zach Stein-Perlman</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><strong>$25 million per bp</strong></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><strong>$50 million per bp</strong></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">\u201cUnlike Linch, I would be quite sad about trading $100M for a single measly basis point \u2014 $100M (granted reasonably well) would make a bigger difference, I think.\u201d&nbsp;<strong>$100 million per bp</strong></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Median</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">$100 million per bp</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">$1 billion per bp</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">$5.17 billion per bp</td></tr></tbody></table></figure><p><br>&nbsp;</p><p>&nbsp;</p><p>This suggests that a reasonable range for the cost of reducing absolute x-risk by 0.01% this century could be between USD $100 million and $5.17 billion, or \u00a375 million and \u00a33.88 billion.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefabutwim4s15\"><sup><a href=\"#fnabutwim4s15\">[3]</a></sup></span></p><p>Earlier, we put a \u201cgood cost\u201d of a 1 bp absolute reduction in per-century x-risk, based on SoGive\u2019s near-termist Gold Standard, between \u00a34 billion and \u00a32.5 * 10^55, depending on how much you value the future what parts of the future you value, and your forecast for the future. Note that the estimates given in this table are all below that range.</p><p>Why is that?</p><ul><li>Were these commenters expecting it to be much cheaper to save a life by preventing the loss of potential in an extinction, than to save a life using near-termist interventions?</li><li>Were they envisioning a relatively small future?</li><li>Were they discounting the future?</li></ul><p>Probably, instead of these possibilities, the commenters were giving an implicit haircut to their estimates based on uncertainty.</p><p><i>What does this say for our threshold?</i></p><h1>Conclusion</h1><p>For near-termist interventions, when SoGive has high confidence that the intervention is effective, we use a Gold Standard.&nbsp;<strong>A&nbsp;</strong><i><strong>tentative</strong></i><strong> threshold for a \u201cSoGive Longtermist Gold Standard\u201d could be \u00a3750 million / bp.&nbsp;</strong>This is the median estimate given by the commenters above.</p><p>Having a threshold for cost-effectiveness can help us decide whether to <i>give now or give later</i>. If all the available funding opportunities cost more than our threshold, then we can hold onto our donations until a more cost-effective opportunity comes along. We may come back to the nuanced relationship between thresholds and give now/give later in a future post.</p><p>There remains a practical problem with using a cost-effectiveness threshold for deciding where to give within longtermism. Most longtermist projects do not publish cost-effectiveness estimates \u2013 and if they did, they could be as flawed as&nbsp;<a href=\"https://www.givewell.org/how-we-work/our-criteria/cost-effectiveness#Charities_frequently_cite_misleading_cost-effectiveness_figures\"><u>misleading cost-effectiveness estimates</u></a> from near-termist charities. For third-party evaluators, there is no clearly reliable method for estimating how much x-risk has been reduced by one project.</p><p>Thus, a threshold for longtermist cost-effectiveness could be better applied to the average cost-effectiveness of categories, e.g., \u201cAI risk-reducing projects in Europe,\u201d rather than to individual projects. (It is not clear that cost-effectiveness for projects varies less within geographic regions than across regions \u2013 this is just an example of a category of funding opportunities.) Analyzing cost-effectiveness over a larger category of funding opportunities, instead of per-intervention or per-project, could help us avoid false precision.</p><p>These estimates are not robust enough to make the most important decisions we face. We recommend conducting a survey of funders, charities, and experts to get a stronger picture of what the standard should be and the cost-effectiveness of different types of work.</p><p>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnaazqiu2kcq\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefaazqiu2kcq\">^</a></strong></sup></span><div class=\"footnote-content\"><p>This represents a reduction from a cumulative risk of 1 to a cumulative risk of 0.9999. If we are starting with a cumulative risk below 1, then we need to reduce per-century risk somewhat more, but likely not orders of magnitude more.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnokr1pp79l5\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefokr1pp79l5\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;(number of moral patients) * (% saved in expectation given 0.01% reduction in cumulative risk) * (\u201cgood cost\u201d to save a life) / (conversion from 0.01% reduction in cumulative risk to 0.01% reduction in per-century risk)</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnabutwim4s15\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefabutwim4s15\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Converting at an average exchange rate of 0.75.</p></div></li></ol>", "user": {"username": "Spencer Ericson"}}, {"_id": "cXeEk6M6QgzTv6nKt", "title": "Giving What We Can Newsletter: July 2023", "postedAt": "2023-07-25T18:20:56.949Z", "htmlBody": "<p>Hello and welcome to our July newsletter!</p><p>There are some exciting things brewing at Giving What We Can, which I'll share in next month's newsletter, but this month I wanted to highlight some of our company pledgers, who are demonstrating that effective giving can take many forms!</p><p>We currently have<a href=\"https://www.givingwhatwecan.org/about-us/members#company-members\">&nbsp;<u>over 40 companies</u></a> who have pledged to give at least 10% of profits to high-impact charities\u2026 and here are a few of them:</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cXeEk6M6QgzTv6nKt/berd7cszdatxidcvuf12\"></p><p><strong>3D Total has raised over&nbsp;</strong>\u00a3<strong>1 million for effective charities!</strong></p><p><a href=\"https://3dtotal.com/\"><u>3D Total</u></a> is an educational publishing company that sells around 250,000 books a year and they've been able to raise \u00a31 million GBP for effective charities by donating 50% of their profits. They are also raising awareness about effective charities through messaging in the front of their books.</p><p>What an incredible effort from Tom Greenway and the team at 3D Total!</p><figure class=\"image image_resized\" style=\"width:56.04%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cXeEk6M6QgzTv6nKt/t3wsr6pquajbvkf3ikty\"><figcaption>Advocating for effective charities in their books!</figcaption></figure><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cXeEk6M6QgzTv6nKt/tnitm3a7ifh3qcdswyml\"></figure><p><strong>Give Industries, a registered non-profit in Australia provides commercial electrical services. Their organisation gives 100% of their profits to effective charities!&nbsp;</strong></p><p>With five years in business,<a href=\"https://www.giveindustries.com.au/\">&nbsp;<u>Give Industries</u></a> has proven that this is a sustainable business model and is continuing to grow.<br>&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cXeEk6M6QgzTv6nKt/cqjbdtmxhphdag6wafag\"></p><p><strong>Fluffy Torpedo in Melbourne creates some of the most unique ice cream flavours (including a Honey &amp; Soy Sauce flavour) and donates 50 cents per scoop to a high-impact charity.</strong></p><p><a href=\"https://www.fluffytorpedo.diamonds/donations\"><u>Fluffy Torpedo</u></a> is also spreading the word about effective charities in their store and provides copies of the book The Life You Can Save by Peter Singer for people to take home! (They even have our logo on the menu!)</p><p>I'm excited about businesses' ability to donate their profits to help others and advocate for a more generous society that seeks to make effective changes to some of our biggest problems.</p><p>Remember to check out why people pledged with Giving What We Can, upcoming events in London and New York, and lots of news below!</p><p>&nbsp;With gratitude,</p><p><strong>&nbsp;&nbsp;&nbsp;- Grace Adams &amp; the Giving What We Can team&nbsp;</strong></p><h2>\u200b\u200bMotivations for Pledging</h2><p>I'm going to try a new section of the newsletter, where we share some of the responses we received from people who took a pledge during the previous month about what motivated them to<a href=\"https://www.givingwhatwecan.org/pledge\"><u> take a pledge</u></a>.</p><p>Reading these answers always fills me with hope and fulfilment, knowing that thousands of people are motivated to give significantly to help others.<br>&nbsp;</p><p><strong>What motivated you to take a pledge with Giving What We Can?</strong></p><ul><li><i>\"I believe in positive change caused by radical kindness. I am privileged and loved in my current position, and, because of that, I have enough to share. Thus, I will share it.\"</i></li><li><i>\"I have been given much, and so there is much to give.\"</i></li><li><i>\"I want to have the biggest possible impact that I can in the world, and this is something that I want to continue valuing for the rest of my life.\"</i></li><li><i>\"I believe the money I make can do far more good for others in desperate need than it could ever do for myself.\"</i></li></ul><h2>Upcoming Events</h2><h3>London Social Picnic</h3><p>The picnic is open to anyone interested in GWWC, whether you have already signed a pledge or are simply curious about effective giving. Bring some food and maybe a blanket for a lovely social afternoon in the sun! (fingers crossed).</p><p>Date: Sunday, July 30th, from 12:30pm onwards</p><p>Location:<a href=\"https://www.google.com/maps/search/?api=1&amp;query=Regents%20Park%2C%20London%2C%20UK\"><u> Regents Park, London, UK</u></a></p><p><a href=\"https://forum.effectivealtruism.org/events/xPk9y8GJfTReRRvh5/giving-what-we-can-social-picnic-london\"><u>Event details</u></a></p><h3>New York Community Picnic</h3><p>Come picnic with the kindest, most interesting people in New York City at Giving What We Can's first meetup in 2 years! Meet us in Battery Park for some great conversation, some great nibbles, and a lovely summer evening.</p><p>This picnic is open to everyone interested in giving most effectively to help others, and we'd love you to bring a friend or two who would enjoy meeting like-minded New Yorkers.</p><p>Date: Tuesday, August 1st, from 6 pm-9 pm</p><p>Location:<a href=\"https://goo.gl/maps/Sri7rxHmnyZTqWGN6\"><u> Battery Park, Manhattan, New York</u></a></p><p><a href=\"https://fb.me/e/3OJbn0JS4\"><u>Event details</u></a></p><p><a href=\"https://forms.gle/JEUqWcuJ3BVxQnjz7\"><u>Registration</u></a></p><h2>News &amp; Updates</h2><h3>Community</h3><ul><li><a href=\"https://forum.effectivealtruism.org/posts/cjz6wHZPsGAbBr8Hx/summary-when-should-an-effective-altruist-donate-william?utm_source=Giving+What+We+Can&amp;utm_campaign=8d79ad5d08-GWWC_July_2023&amp;utm_medium=email&amp;utm_term=0_a08869629e-8d79ad5d08-&amp;goal=0_a08869629e-8d79ad5d08-\"><u>A summary of a working paper</u></a> from one of our co-founders, William MacAskill, provides some considerations for when an effective altruist should donate.</li></ul><h3>Evaluators, grantmakers and incubators</h3><ul><li><a href=\"https://www.givewell.org/?utm_source=Giving+What+We+Can&amp;utm_campaign=8d79ad5d08-GWWC_July_2023&amp;utm_medium=email&amp;utm_term=0_a08869629e-8d79ad5d08-&amp;goal=0_a08869629e-8d79ad5d08-\"><u>GiveWell</u></a> has published a<a href=\"https://blog.givewell.org/2023/07/07/miraclefeet-clubfoot-treatment-grant/?utm_source=Giving+What+We+Can&amp;utm_campaign=8d79ad5d08-GWWC_July_2023&amp;utm_medium=email&amp;utm_term=0_a08869629e-8d79ad5d08-&amp;goal=0_a08869629e-8d79ad5d08-\"><u> blog post</u></a> on its January 2023 grant to<a href=\"https://www.miraclefeet.org/?utm_source=Giving+What+We+Can&amp;utm_campaign=8d79ad5d08-GWWC_July_2023&amp;utm_medium=email&amp;utm_term=0_a08869629e-8d79ad5d08-&amp;goal=0_a08869629e-8d79ad5d08-\"><u> MiracleFeet</u></a>, which helps health facilities find and treat clubfoot, a debilitating congenital condition. After adjustments, GiveWell estimates that this grant will lead to about 3,700 cases of clubfoot successfully treated that otherwise wouldn't have been, and that will result in lifelong mobility gains and pain relief for the children treated.&nbsp;</li><li>GiveWell has published several new pages on grants it has recently recommended, including<a href=\"https://www.givewell.org/research/grants/helen-keller-international-vitamin-a-supplementation-madagascar-april-2023?utm_source=Giving+What+We+Can&amp;utm_campaign=8d79ad5d08-GWWC_July_2023&amp;utm_medium=email&amp;utm_term=0_a08869629e-8d79ad5d08-&amp;goal=0_a08869629e-8d79ad5d08-\"><u> $6 million</u></a> for Helen Keller International's support of vitamin A supplementation in Madagascar,<a href=\"https://www.givewell.org/research/grants/sightsavers-drc-april-2023?utm_source=Giving+What+We+Can&amp;utm_campaign=8d79ad5d08-GWWC_July_2023&amp;utm_medium=email&amp;utm_term=0_a08869629e-8d79ad5d08-&amp;goal=0_a08869629e-8d79ad5d08-\"><u> $5.8 million</u></a> to Sightsavers for its deworming program in the Democratic Republic of the Congo, and<a href=\"https://www.givewell.org/research/grants/yale-research-initiative-on-innovation-and-scale-operational-grant-december-2022?utm_source=Giving+What+We+Can&amp;utm_campaign=8d79ad5d08-GWWC_July_2023&amp;utm_medium=email&amp;utm_term=0_a08869629e-8d79ad5d08-&amp;goal=0_a08869629e-8d79ad5d08-\"><u> $1.4 million</u></a> for core operating support to the Yale Research Initiative on Innovation and Scale (Y-RISE), which researches successful scaling of global health and well-being programs. If you'd like to sign up for email updates when new research materials from GiveWell are published, you can do so<a href=\"https://groups.google.com/g/newly-published-givewell-materials?pli=1&amp;utm_source=Giving+What+We+Can&amp;utm_campaign=8d79ad5d08-GWWC_July_2023&amp;utm_medium=email&amp;utm_term=0_a08869629e-8d79ad5d08-&amp;goal=0_a08869629e-8d79ad5d08-\"><u> here</u></a>.</li><li><a href=\"https://animalcharityevaluators.org/?utm_source=Giving+What+We+Can&amp;utm_campaign=8d79ad5d08-GWWC_July_2023&amp;utm_medium=email&amp;utm_term=0_a08869629e-8d79ad5d08-&amp;goal=0_a08869629e-8d79ad5d08-\"><u>Animal Charity Evaluators</u></a> announced their<a href=\"https://animalcharityevaluators.org/blog/announcing-our-2023-movement-grants/?utm_source=Giving+What+We+Can&amp;utm_campaign=8d79ad5d08-GWWC_July_2023&amp;utm_medium=email&amp;utm_term=0_a08869629e-8d79ad5d08-&amp;goal=0_a08869629e-8d79ad5d08-\"><u> 2023 Movement Grants</u></a>, which aim to \"build and strengthen the global animal advocacy movement.\"</li><li><a href=\"https://www.charityentrepreneurship.com/?utm_source=Giving+What+We+Can&amp;utm_campaign=8d79ad5d08-GWWC_July_2023&amp;utm_medium=email&amp;utm_term=0_a08869629e-8d79ad5d08-&amp;goal=0_a08869629e-8d79ad5d08-\"><u>Charity Entrepreneurship</u></a> is now accepting applications to their 2024<a href=\"https://www.charityentrepreneurship.com/incubation-program?utm_source=Giving+What+We+Can&amp;utm_campaign=8d79ad5d08-GWWC_July_2023&amp;utm_medium=email&amp;utm_term=0_a08869629e-8d79ad5d08-&amp;goal=0_a08869629e-8d79ad5d08-\"><u> Incubation Program</u></a>! As in previous years, the program provides well-researched intervention ideas, 2-month cost-covered training, and funding up to $200,000.&nbsp;</li><li><a href=\"https://www.openphilanthropy.org/?utm_source=Giving+What+We+Can&amp;utm_campaign=8d79ad5d08-GWWC_July_2023&amp;utm_medium=email&amp;utm_term=0_a08869629e-8d79ad5d08-&amp;goal=0_a08869629e-8d79ad5d08-\"><u>Open Philanthropy</u></a> is hiring a<a href=\"https://jobs.ashbyhq.com/openphilanthropy/475ea24f-a503-4069-adcf-040d62cdda19?utm_source=Giving+What+We+Can&amp;utm_campaign=8d79ad5d08-GWWC_July_2023&amp;utm_medium=email&amp;utm_term=0_a08869629e-8d79ad5d08-&amp;goal=0_a08869629e-8d79ad5d08-\"><u> Recruiter</u></a>. This person will help hiring managers at Open Phil hire top talent as seamlessly as possible and maintain/improve internal hiring systems. If you know anyone that would be a good fit for this, please encourage them to<a href=\"https://jobs.ashbyhq.com/openphilanthropy/475ea24f-a503-4069-adcf-040d62cdda19?utm_source=Giving+What+We+Can&amp;utm_campaign=8d79ad5d08-GWWC_July_2023&amp;utm_medium=email&amp;utm_term=0_a08869629e-8d79ad5d08-&amp;goal=0_a08869629e-8d79ad5d08-\"><u> apply</u></a>! You can email Evan McVail (evan@openphilanthropy.org) with any questions or referrals.</li><li><a href=\"https://sogive.org/?utm_source=Giving+What+We+Can&amp;utm_campaign=8d79ad5d08-GWWC_July_2023&amp;utm_medium=email&amp;utm_term=0_a08869629e-8d79ad5d08-&amp;goal=0_a08869629e-8d79ad5d08-#home\"><u>SoGive</u></a> is conducting a survey of individuals giving \u00a310,000+ per year or who might have the capacity to face uncertainties. They are seeking to understand this group's uncertainties around giving, what services would help these individuals donate more and better, and how they are making giving decisions. If you're in this category, they'd like to encourage you to<a href=\"https://forms.gle/ekSdzic2ZCjzwUqR9?utm_source=Giving+What+We+Can&amp;utm_campaign=8d79ad5d08-GWWC_July_2023&amp;utm_medium=email&amp;utm_term=0_a08869629e-8d79ad5d08-&amp;goal=0_a08869629e-8d79ad5d08-\"><u> book a 60-minute call</u></a> with them. Your insights will be instrumental in helping them develop a program that A) will be of value to major donors and B) isn't already covered by other advisors in the space.</li></ul><h3>Cause areas</h3><p>Animal welfare</p><ul><li><a href=\"https://thehumaneleague.org.uk/?utm_source=Giving+What+We+Can&amp;utm_campaign=8d79ad5d08-GWWC_July_2023&amp;utm_medium=email&amp;utm_term=0_a08869629e-8d79ad5d08-&amp;goal=0_a08869629e-8d79ad5d08-\"><u>The Humane League UK</u></a> has chosen to<a href=\"https://streaklinks.com/Blp5u4s2Nho_aL0BrQTMnTsG/https%3A%2F%2Fthehumaneleague.org.uk%2Farticle%2Fwere-appealing-the-courts-decision?utm_source=Giving+What+We+Can&amp;utm_campaign=8d79ad5d08-GWWC_July_2023&amp;utm_medium=email&amp;utm_term=0_a08869629e-8d79ad5d08-&amp;goal=0_a08869629e-8d79ad5d08-\"><u> appeal</u></a> the decision of the High Court in an ongoing case against the Government in which they are challenging the legality of fast-growing breeds of chickens. The High Court<a href=\"https://streaklinks.com/Blp5u4sQUJA2-oikCggmR1PO/https%3A%2F%2Fthehumaneleague.org.uk%2Farticle%2Fbillions-of-frankenchickens-left-to-suffer-after-court-decision?utm_source=Giving+What+We+Can&amp;utm_campaign=8d79ad5d08-GWWC_July_2023&amp;utm_medium=email&amp;utm_term=0_a08869629e-8d79ad5d08-&amp;goal=0_a08869629e-8d79ad5d08-\"><u> ruled in May</u></a> that Defra hadn't behaved unlawfully.</li><li>96% of Co-op (a UK supermarket) members (over 32,000 people)<a href=\"https://streaklinks.com/Blp5u4snJxcviiHzGAWR5aKB/https%3A%2F%2Fthehumaneleague.org.uk%2Farticle%2Fco-op-agm-vote-update?utm_source=Giving+What+We+Can&amp;utm_campaign=8d79ad5d08-GWWC_July_2023&amp;utm_medium=email&amp;utm_term=0_a08869629e-8d79ad5d08-&amp;goal=0_a08869629e-8d79ad5d08-\"><u> voted</u></a> for the supermarket to adopt the Better Chicken Commitment (BCC) following a shareholder resolution led by The Humane League UK. Whilst the board agreed to give chickens more space, they refused to stop selling fast-growing breeds of chickens. The Humane League UK plans to maintain pressure on the Co-op until they fully commit to the BCC.&nbsp;</li><li><a href=\"https://talist.org/?utm_source=Giving+What+We+Can&amp;utm_campaign=8d79ad5d08-GWWC_July_2023&amp;utm_medium=email&amp;utm_term=0_a08869629e-8d79ad5d08-&amp;goal=0_a08869629e-8d79ad5d08-\"><u>T\u00e4list</u></a> has created a new Impact Calculator that calculates the potential impact of working in the Alternative Protein industry. You can<a href=\"https://talist.org/talent-impact?utm_source=Giving+What+We+Can&amp;utm_campaign=8d79ad5d08-GWWC_July_2023&amp;utm_medium=email&amp;utm_term=0_a08869629e-8d79ad5d08-&amp;goal=0_a08869629e-8d79ad5d08-\"><u> check it out now</u></a>. They are also looking for pioneer users for their platform, which matches candidates with jobs in the Alt\u2014protein industry. You can support their work by signing up and giving valuable feedback from a user perspective. Learn more<a href=\"https://talist.org/for-talents?utm_source=Giving+What+We+Can&amp;utm_campaign=8d79ad5d08-GWWC_July_2023&amp;utm_medium=email&amp;utm_term=0_a08869629e-8d79ad5d08-&amp;goal=0_a08869629e-8d79ad5d08-\"><u> here</u></a>.</li><li>Cultivated meat has continued to gain traction in the US and<a href=\"https://www.cbsnews.com/video/cultivated-meat-meat-grown-in-a-lab/?utm_source=Giving+What+We+Can&amp;utm_campaign=8d79ad5d08-GWWC_July_2023&amp;utm_medium=email&amp;utm_term=0_a08869629e-8d79ad5d08-&amp;goal=0_a08869629e-8d79ad5d08-\"><u> appeared in a CBS news segment</u></a> this month.</li><li>The<a href=\"https://gfi.org/?utm_source=Giving+What+We+Can&amp;utm_campaign=8d79ad5d08-GWWC_July_2023&amp;utm_medium=email&amp;utm_term=0_a08869629e-8d79ad5d08-&amp;goal=0_a08869629e-8d79ad5d08-\"><u> Good Food Institute</u></a> released its report:<a href=\"https://gfi.org/resource/alternative-proteins-state-of-global-policy/?utm_source=Giving+What+We+Can&amp;utm_campaign=8d79ad5d08-GWWC_July_2023&amp;utm_medium=email&amp;utm_term=0_a08869629e-8d79ad5d08-&amp;goal=0_a08869629e-8d79ad5d08-\"><u> The State of Global Policy on Alternative Proteins</u></a> for 2023.</li></ul><p>Global health and development</p><ul><li>The<a href=\"https://leadelimination.org/?utm_source=Giving+What+We+Can&amp;utm_campaign=8d79ad5d08-GWWC_July_2023&amp;utm_medium=email&amp;utm_term=0_a08869629e-8d79ad5d08-&amp;goal=0_a08869629e-8d79ad5d08-\"><u> Lead Exposure Elimination Project</u></a> (LEEP) is hiring a Chief Operating Officer. The COO will be critical in helping LEEP dramatically widen its impact as it scales to 50 high-priority countries over the next few years. Read more about and apply for the position<a href=\"https://leadelimination.org/jobs/?utm_source=Giving+What+We+Can&amp;utm_campaign=8d79ad5d08-GWWC_July_2023&amp;utm_medium=email&amp;utm_term=0_a08869629e-8d79ad5d08-&amp;goal=0_a08869629e-8d79ad5d08-\"><u> here</u></a>.&nbsp;</li><li><a href=\"https://helenkellerintl.org/?utm_source=Giving+What+We+Can&amp;utm_campaign=8d79ad5d08-GWWC_July_2023&amp;utm_medium=email&amp;utm_term=0_a08869629e-8d79ad5d08-&amp;goal=0_a08869629e-8d79ad5d08-\"><u>Helen Keller International</u></a> shares how<a href=\"https://helenkellerintl.org/our-stories/women-at-the-heart-of-our-work/?utm_source=Giving+What+We+Can&amp;utm_campaign=8d79ad5d08-GWWC_July_2023&amp;utm_medium=email&amp;utm_term=0_a08869629e-8d79ad5d08-&amp;goal=0_a08869629e-8d79ad5d08-\"><u> women are at the heart of their work</u></a>.</li></ul><p>Long-term future</p><ul><li>The<a href=\"https://www.nti.org/?utm_source=Giving+What+We+Can&amp;utm_campaign=8d79ad5d08-GWWC_July_2023&amp;utm_medium=email&amp;utm_term=0_a08869629e-8d79ad5d08-&amp;goal=0_a08869629e-8d79ad5d08-\"><u> Nuclear Threat Initiative</u></a> highlights<a href=\"https://www.nti.org/analysis/articles/oppenheimer-and-nuclear-risks-today/?utm_source=Giving+What+We+Can&amp;utm_campaign=8d79ad5d08-GWWC_July_2023&amp;utm_medium=email&amp;utm_term=0_a08869629e-8d79ad5d08-&amp;goal=0_a08869629e-8d79ad5d08-\"><u> Oppenheimer and the risks of nuclear today</u></a>.</li><li>The<a href=\"http://impactmarkets.io/?utm_source=Giving+What+We+Can&amp;utm_campaign=8d79ad5d08-GWWC_July_2023&amp;utm_medium=email&amp;utm_term=0_a08869629e-8d79ad5d08-&amp;goal=0_a08869629e-8d79ad5d08-\"><u> impactmarkets.io</u></a> platform is a crowdsourced charity evaluator for early-stage AI safety projects. It lets you play regrantor or harness the insight of expert regrantors. If you're interested in learning more,<a href=\"https://bit.ly/donor-interests?utm_source=Giving+What+We+Can&amp;utm_campaign=8d79ad5d08-GWWC_July_2023&amp;utm_medium=email&amp;utm_term=0_a08869629e-8d79ad5d08-&amp;goal=0_a08869629e-8d79ad5d08-\"><u> you can indicate your interest in using the platform to donate to these projects</u></a>.</li></ul><figure class=\"media\"><div data-oembed-url=\"https://youtu.be/e-3vaHrhbNk\"><div><iframe src=\"https://www.youtube.com/embed/e-3vaHrhbNk\" allow=\"autoplay; encrypted-media\" allowfullscreen=\"\"></iframe></div></div></figure><p>Have any feedback on our newsletter or communications?&nbsp;<a href=\"https://forms.gle/UZCnhMHNq11ieQoCA\"><u>Share your thoughts here.</u></a></p><h2>Useful Links</h2><ul><li>Review&nbsp;<a href=\"https://www.givingwhatwecan.org/best-charities-to-donate-to-2022\"><u>our giving recommendations</u></a>.</li><li>Report your donations with&nbsp;<a href=\"https://app.effectivealtruism.org/pledge\"><u>your pledge dashboard</u></a>.</li><li><a href=\"https://www.givingwhatwecan.org/get-involved/share-our-ideas/\"><u>Share our ideas</u></a> to help grow our community and&nbsp;<a href=\"https://www.givingwhatwecan.org/post/2020/12/social-change-happens-one-person-at-a-time-so-start-multiplying-your-impact/\"><u>multiply your impact</u></a>.</li><li>Join other members in the&nbsp;<a href=\"https://www.facebook.com/groups/givingwhatwecancommunity/\"><u>Giving What We Can Community</u></a> Facebook group.</li><li>Find more ways to&nbsp;<a href=\"https://www.givingwhatwecan.org/get-involved/\"><u>get involved</u></a> with Giving What We Can and effective altruism.</li><li><a href=\"https://forum.effectivealtruism.org/topics/effective-giving\"><u>Discuss effective giving</u></a> on the&nbsp;<a href=\"https://forum.effectivealtruism.org/\"><u>Effective Altruism Forum</u></a>.</li></ul><p><br>&nbsp;</p><p>You can follow us on&nbsp;<a href=\"https://twitter.com/givingwhatwecan\"><u>Twitter</u></a>,&nbsp;<a href=\"https://www.facebook.com/givingwhatwecan\"><u>Facebook</u></a>,&nbsp;<a href=\"https://www.linkedin.com/company/2760845/\"><u>LinkedIn</u></a>,&nbsp;<a href=\"https://www.instagram.com/giving_what_we_can/\"><u>Instagram</u></a>,&nbsp;<a href=\"https://www.youtube.com/channel/UC_gBQtUE3BBl-Mh_IBQkg9Q\"><u>YouTube</u></a>, or&nbsp;<a href=\"https://www.tiktok.com/@givingwhatwecan\"><u>TikTok</u></a> and subscribe to the&nbsp;<a href=\"https://www.effectivealtruism.org/ea-newsletter-archives/\"><u>EA Newsletter</u></a> for more news and articles.</p><p><br>&nbsp;</p><p>Do you have questions about the pledge, Giving What We Can, or effective altruism in general? Check out our&nbsp;<a href=\"https://www.givingwhatwecan.org/about-us/frequently-asked-questions/\"><u>FAQ page</u></a>, or&nbsp;<a href=\"https://www.givingwhatwecan.org/about-us/contact-us/\"><u>contact us directly</u></a>.</p><p><br>&nbsp;</p>", "user": {"username": "Giving What We Can"}}, {"_id": "BbpYq9iwGzC4YBfMk", "title": "\"The Universe of Minds\" - call for reviewers (Seeds of Science)", "postedAt": "2023-07-25T16:55:46.815Z", "htmlBody": "<h3>Abstract</h3><p>The paper attempts to describe the space of possible mind designs by first equating all minds to software. Next it proves some interesting properties of the mind design space such as infinitude of minds, size and representation complexity of minds. A survey of mind design taxonomies is followed by a proposal for a new field of investigation devoted to study of minds, intellectology, a list of open problems for this new field is presented.</p><p>---</p><p><a href=\"https://www.theseedsofscience.org/\"><i>Seeds of Science</i></a> is a journal (funded through Scott Alexander's <a href=\"https://astralcodexten.substack.com/p/acx-grants-results\">ACX grants program</a>) that publishes speculative or non-traditional articles on scientific topics. Peer review is conducted through community-based voting and commenting by a diverse network of reviewers (or \"gardeners\" as we call them). Comments that critique or extend the article (the \"seed of science\") in a useful manner are published in the final document following the main text.</p><p>We have just sent out a manuscript for review, \"The Universe of Minds\", that may be of interest to some in the EA community so I wanted to see if anyone would be interested in joining us as a gardener and providing feedback on the article. As noted above, this is an opportunity to have your comment recorded in the scientific literature (comments can be made with real name or pseudonym).&nbsp;</p><p>It is free to join as a gardener and anyone is welcome (we currently have gardeners from all levels of academia and outside of it). Participation is entirely voluntary - we send you submitted articles and you can choose to vote/comment or abstain without notification (so no worries if you don't plan on reviewing very often but just want to take a look here and there at the articles people are submitting).&nbsp;</p><p>To register, you can fill out this <a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfRIicHT7jIZcSUjwsIlby6JBxx2ZVeD5kseZBpgGFtp8pLfg/viewform\">google form</a>. From there, it's pretty self-explanatory - I will add you to the mailing list and send you an email that includes the manuscript, our publication criteria, and a simple review form for recording votes/comments. If you would like to just take a look at this article without being added to the mailing list, then just reach out (info@theseedsofscience.org) and say so.&nbsp;</p><p>Happy to answer any questions about the journal through email or in the comments below.&nbsp;</p>", "user": {"username": "rogersbacon1"}}, {"_id": "7yK5fB7y3bb8dEMED", "title": "AISN #16: White House Secures Voluntary Commitments from Leading AI Labs and Lessons from Oppenheimer", "postedAt": "2023-07-25T16:45:20.847Z", "htmlBody": "<p>Welcome to the AI Safety Newsletter by the <a href=\"https://www.safe.ai/\"><u>Center for AI Safety</u></a>. We discuss developments in AI and AI safety. No technical background required.</p><p>Subscribe <a href=\"https://newsletter.safe.ai/subscribe?utm_medium=web&amp;utm_source=subscribe-widget-preamble&amp;utm_content=113135916\">here</a> to receive future versions.</p><hr><h1>White House Unveils Voluntary Commitments to AI Safety from Leading AI Labs</h1><p>Last Friday, the White House <a href=\"https://www.whitehouse.gov/briefing-room/statements-releases/2023/07/21/fact-sheet-biden-harris-administration-secures-voluntary-commitments-from-leading-artificial-intelligence-companies-to-manage-the-risks-posed-by-ai/\"><u>announced</u></a> a series of voluntary <a href=\"https://www.whitehouse.gov/wp-content/uploads/2023/07/Ensuring-Safe-Secure-and-Trustworthy-AI.pdf\"><u>commitments</u></a> from seven of the world's premier AI labs. Amazon, Anthropic, Google, Inflection, Meta, Microsoft, and OpenAI pledged to uphold these commitments, which are non-binding and pertain only to forthcoming \"frontier models\" superior to currently available AI systems. The White House also notes that the Biden-Harris Administration is developing an executive order alongside these voluntary commitments.</p><p>The commitments are timely and technically well-informed, demonstrating the ability of federal policymakers to respond capably and quickly to AI risks. The Center for AI Safety <a href=\"https://www.safe.ai/post/leading-ai-companies-join-white-houses-voluntary-commitment-to-enhance-ai-safety\"><u>supports</u></a> these commitments as a precedent for cooperation on AI safety and legally binding legislation.&nbsp;</p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ddb29af-7413-4279-97dd-7de347e7b61a_1600x831.png\"><img src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ddb29af-7413-4279-97dd-7de347e7b61a_1600x831.png\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ddb29af-7413-4279-97dd-7de347e7b61a_1600x831.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ddb29af-7413-4279-97dd-7de347e7b61a_1600x831.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ddb29af-7413-4279-97dd-7de347e7b61a_1600x831.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ddb29af-7413-4279-97dd-7de347e7b61a_1600x831.png 1456w\"></a></p><p><strong>Commitments to Red Teaming and Information Sharing. </strong>AI systems <a href=\"https://www.jasonwei.net/blog/emergence\"><u>often develop unexpected capabilities</u></a> during training, so it\u2019s important to <a href=\"https://newsletter.safe.ai/p/ai-safety-newsletter-8\"><u>screen models for potentially harmful abilities</u></a>. The companies promised to \u201cred team\u201d their models by searching for ways the models could cause harm, particularly in <a href=\"https://arxiv.org/abs/2306.12001\"><u>areas of potential catastrophe</u></a> including biological weapons acquisition, offensive cyberattacks, and self-replication. External red teamers will also be offered a chance to find vulnerabilities in these frontier AI systems.</p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb6ce818-85dc-4c0e-aa71-ba770fc799c1_2750x698.png\"><img src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb6ce818-85dc-4c0e-aa71-ba770fc799c1_2750x698.png\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb6ce818-85dc-4c0e-aa71-ba770fc799c1_2750x698.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb6ce818-85dc-4c0e-aa71-ba770fc799c1_2750x698.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb6ce818-85dc-4c0e-aa71-ba770fc799c1_2750x698.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb6ce818-85dc-4c0e-aa71-ba770fc799c1_2750x698.png 1456w\"></a><i>These are the catastrophic capabilities that companies agreed to evaluate via red teaming.</i></p><p>The companies have additionally agreed to share information about best practices in AI safety with governments and each other. Public reports on system capabilities and risks are also part of this pledge, though companies have not agreed to the disclosure of model training data, which likely contains large volumes of copyrighted content.&nbsp;</p><p><strong>Cybersecurity to protect AI models, if companies choose. </strong>The AI labs also reiterated their dedication to cybersecurity. This helps prevent potent AI models from being accessed and misused by malicious actors. By reducing the likelihood that someone else will steal their cutting edge secrets, cybersecurity also alleviates the pressure of the AI race and gives companies more time to evaluate and enhance the safety features of their models.&nbsp;</p><p>Notably, while most labs aim to prevent their models from being used for malicious purposes, companies are not prohibited from sharing their models publicly. Meta, after accidentally leaking their first LLaMA model, has <a href=\"https://ai.meta.com/llama/\"><u>published their LLaMA 2 model online</u></a> for nearly anyone to use. Meta published a report about LLaMA 2\u2019s safety features, but only a week after its release, someone has published an \u201c<a href=\"https://huggingface.co/spaces/mikeee/llama2-7b-chat-uncensored-ggml\"><u>uncensored</u></a>\u201d version of the model.</p><p><strong>Identifying AI outputs in the wild. </strong>Companies also committed to watermarking AI outputs so they can be differentiated from text written by humans and real world images and videos. Without this crucial ability to distinguish AI outputs from real life, <a href=\"https://newsletter.safe.ai/p/ai-safety-newsletter-7\"><u>society would be vulnerable</u></a> to scams, <a href=\"https://www.theatlantic.com/technology/archive/2023/05/problem-counterfeit-people/674075/\"><u>counterfeit people</u></a>, personalized persuasion, and propaganda campaigns.&nbsp;</p><p>Technical researchers had <a href=\"https://arxiv.org/abs/2303.11156\"><u>speculated that watermarking might be unsolvable</u></a> because AI systems are trained to mimic real world data as closely as possible. But companies already keep databases of most of their AI outputs, which a <a href=\"https://arxiv.org/abs/2303.13408\"><u>recent paper</u></a> suggests can be used to verify AI outputs. Consumers would be able to submit text, audio, or video to a company\u2019s website and find out if it had been generated by the company\u2019s AI models.&nbsp;</p><p><strong>Goals for future AI policy work. </strong>While the voluntary commitments offer a starting point, they cannot replace legally binding obligations to guide AI development for public benefit. OpenAI\u2019s <a href=\"https://openai.com/blog/moving-ai-governance-forward\"><u>announcement</u></a> of the commitments says, \u201cCompanies intend these voluntary commitments to remain in effect until regulations covering substantially the same issues come into force.\u201d</p><p>A more ambitious proposal comes from a <a href=\"https://arxiv.org/abs/2307.03718\"><u>new paper</u></a> proposing a three pronged approach to AI governance. First, safety standards must be developed by experts external to AI labs, similar to safety standards in healthcare, nuclear engineering, and aviation. Governments need visibility on the most powerful models being trained by AI labs, facilitated by <a href=\"https://carnegieendowment.org/2023/07/12/it-s-time-to-create-national-registry-for-large-ai-models-pub-90180\"><u>registration of advanced models</u></a> and protections for whistleblowers. Equipped with safety standards and a clear view of advanced AI systems, the government can ensure the standards are upheld, first by securing voluntary commitments from AI labs and later with binding laws and enforcement.&nbsp;</p><p>Other future commitments could include accepting legal liability for AI-induced damages, sharing training data of large pretrained models, and funding research on AI safety topics such as robustness, monitoring, and control. Notably, while companies promised to assess the risks posed by their AI systems, they did not commit to any particular response to those risks, nor promise not to deploy models that cross a \u201cred line\u201d of dangerous capabilities.&nbsp;</p><hr><h1>Lessons from <i>Oppenheimer</i></h1><p>Last week, <i>Oppenheimer</i> opened in theaters. The film\u2019s director, Christopher Nolan, said in <a href=\"https://www.theguardian.com/technology/2023/jul/21/christopher-nolan-says-ai-experts-face-their-oppenheimer-moment\"><u>an interview</u></a> that the film parallels the rise and risks of AI. AI, he said, is having its \u201cOppenheimer moment.\u201d There are indeed many parallels between the development of nuclear weapons and AI. In this story, we explore one: the irrational dismissal of existential risk.</p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05dae7fb-99b2-4cfb-bc11-9f972e134bb4_1200x630.png\"><img src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05dae7fb-99b2-4cfb-bc11-9f972e134bb4_1200x630.png\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05dae7fb-99b2-4cfb-bc11-9f972e134bb4_1200x630.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05dae7fb-99b2-4cfb-bc11-9f972e134bb4_1200x630.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05dae7fb-99b2-4cfb-bc11-9f972e134bb4_1200x630.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05dae7fb-99b2-4cfb-bc11-9f972e134bb4_1200x630.png 1456w\"></a></p><p><strong>The ultimate catastrophe.</strong> Before Los Alamos, Oppenheimer met with fellow physicist Edward Teller to discuss the end of the world. Teller had begun to worry that a nuclear detonation might fuse atmospheric nitrogen in a catastrophic chain-reaction that would raze the surface of the earth. Disturbed, they reported the possibility to Arthur Compton, an early leader of the Manhattan Project. Compton later <a href=\"http://large.stanford.edu/courses/2015/ph241/chung1/docs/buck.pdf\"><u>recalled</u></a> that it would have been \u201cthe ultimate catastrophe.\"</p><p>After some initial calculations, another physicist on the project, Hans Bethe, concluded that such a catastrophe was impossible. The project later commissioned <a href=\"https://sgp.fas.org/othergov/doe/lanl/docs1/00329010.pdf\"><u>a full report</u></a> on the possibility, which came to the same conclusion. Still, the fear of catastrophe lingered on the eve of the Trinity test. Just before the test, Enrico Fermi jokingly took bets on the end of the world.&nbsp;</p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb7fb392f-49fe-40a7-a49f-f2dd9c12cd79_1600x944.png\"><img src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb7fb392f-49fe-40a7-a49f-f2dd9c12cd79_1600x944.png\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb7fb392f-49fe-40a7-a49f-f2dd9c12cd79_1600x944.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb7fb392f-49fe-40a7-a49f-f2dd9c12cd79_1600x944.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb7fb392f-49fe-40a7-a49f-f2dd9c12cd79_1600x944.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb7fb392f-49fe-40a7-a49f-f2dd9c12cd79_1600x944.png 1456w\"></a></p><p><i>Photo of the Trinity test, which some feared could cause a global catastrophe.&nbsp;</i></p><p><strong>Objective and subjective probability.</strong> In Nolan\u2019s film, Oppenheimer tells the military director of the Manhattan Project, Leslie Groves, that the probability of a catastrophe during the Trinity test was \u201cnear zero.\u201d The film might be drawing from <a href=\"http://large.stanford.edu/courses/2015/ph241/chung1/docs/buck.pdf\"><u>an interview</u></a> with Compton, who recalled that the probability was three parts in a million. Bethe was less equivocal. He <a href=\"https://www.tandfonline.com/doi/abs/10.1080/00963402.1976.11455623\"><u>writes</u></a> that \u201cthere was never a possibility of causing a thermonuclear chain reaction in the atmosphere,\u201d and that \u201c[i]gnition is not a matter of probabilities; it is simply impossible.\u201d</p><p>Bethe is right in one sense: the report did not give any probabilities. It concluded that catastrophe was objectively impossible. Where Bethe errs is in conflating <i>objective</i> and <i>subjective</i> probability. The calculations in the report implied certainty \u2014 but Bethe should have been uncertain about the calculations themselves, and the assumptions those calculations relied on.</p><p>The mathematician R.W. Hamming <a href=\"https://www.tandfonline.com/doi/abs/10.1080/00029890.1998.12004938\"><u>recalls</u></a> that at least one of the report\u2019s authors was uncertain leading up to the Trinity test:</p><blockquote><p>Shortly before the first field test (you realize that no small scale experiment can be done \u2014 either you have a critical mass or you do not), a man asked me to check some arithmetic he had done, and I agreed, thinking to fob it off on some subordinate. When I asked what it was, he said, \"It is the probability that the test bomb will ignite the whole atmosphere.\" I decided I would check it myself! The next day when he came for the answers I remarked to him, \"The arithmetic was apparently correct but I do not know about the formulas for the capture cross sections for oxygen and nitrogen \u2014 after all, there could be no experiments at the needed energy levels.\" He replied, like a physicist talking to a mathematician, that he wanted me to check the arithmetic not the physics, and left. I said to myself, \"What have you done, Hamming, you are involved in risking all of life that is known in the Universe, and you do not know much of an essential part?\"</p></blockquote><p>Doubt lingered in the final moments preceding the Trinity test about the possibility of a catastrophic chain reaction. Hans Bethe\u2019s calculations may have shown that the probability of catastrophe was zero, but it remained possible that Bethe had miscalculated.&nbsp;</p><p>Scientific and mathematical claims that are widely accepted can still be false. For example, a peer-reviewed mathematical proof of the famous four color problem was accepted for years until, finally, <a href=\"https://en.wikipedia.org/wiki/Four_color_theorem\"><u>a flaw was uncovered</u></a>. While Bethe\u2019s model was confident, he shouldn\u2019t have placed his full faith in a model without the test of time.&nbsp;</p><p><strong>The Castle Bravo Disaster. </strong>Indeed, the probability of a theoretical mistake may have been quite high. Trinity didn\u2019t end in catastrophe, but another initial test \u2014 Castle Bravo \u2014 did. Castle Bravo was the first test of a dry-fuel hydrogen bomb. Because of an unexpected nuclear interaction, the payload of the bomb was three times greater than predicted. Its fallout reached the inhabitants of the Marshall Islands, as well as a nearby Japanese fishing vessel, leading to dozens of cases of acute radiation sickness.&nbsp;</p><p>There is no reason to think that the authors of the atmospheric ignition report couldn\u2019t have made a similar mistake. Indeed, one of the authors, Edward Teller, designed the bomb used in the Castle Bravo test. Trinity didn\u2019t end in catastrophe, but it could have.&nbsp;</p><p><strong>Lessons for AI safety.</strong> Despite a firm grasp of the nuclear reaction principles at the time of the Trinity test, there were still a handful of experts voicing concerns about the potentially disastrous outcomes. Those who conducted the test accepted a risk that, if their calculations were wrong, the atmosphere would be ignited and all of humanity thrown into catastrophe. While the test was ultimately successful, it would have been prudent to consider these concerns more seriously before the Trinity test at Los Alamos.&nbsp;</p><p>Artificial intelligence, on the other hand, is understood far less than nuclear reactions were. Moreover, a substantial number of experts have <a href=\"https://www.safe.ai/statement-on-ai-risk\"><u>publicly warned</u></a> about the existential risk emanating from AI. It\u2019s crucial to ensure there\u2019s consensus that risks are negligible or zero and that this consensus<s>&nbsp;</s> passes the test of time before taking actions that could cause extinction.&nbsp;</p><hr><h2>Links</h2><ul><li>To help AI companies assess the risks of their models, a&nbsp;<a href=\"https://arxiv.org/abs/2307.08823\"><u>new paper reviews common risk assessment techniques</u></a> in other fields.&nbsp;</li><li>A detailed explanation of how&nbsp;<a href=\"https://carnegieendowment.org/2023/07/10/china-s-ai-regulations-and-how-they-get-made-pub-90117\"><u>Chinese AI policy</u></a> gets made.</li><li>To verify the data that an AI was trained on, a&nbsp;<a href=\"https://arxiv.org/abs/2307.00682\"><u>new paper</u></a> proposes a solution involving checkpoints of the model at different points during the training process.&nbsp;</li><li><a href=\"https://thehackernews.com/2023/07/wormgpt-new-ai-tool-allows.html\"><u>WormGPT</u></a> is a new AI tool for launching offensive cyber attacks.</li><li>Prominent technologists are pushing for no regulation of AI under the banner of a&nbsp;<a href=\"https://twitter.com/DanHendrycks/status/1651740865159901184\"><u>Darwinian ideology</u></a>.</li><li>A&nbsp;<a href=\"https://www.judiciary.senate.gov/committee-activity/hearings/oversight-of-ai-principles-for-regulation\"><u>senate subcommittee</u></a> is having a hearing on AI regulation. All three speakers (Russell, Amodei, Bengio) have signed the&nbsp;<a href=\"https://safe.ai/statement-on-ai-risk\"><u>statement on AI risk</u></a>.</li><li>The UN Security Council had its&nbsp;<a href=\"https://media.un.org/en/asset/k1j/k1ji81po8p\"><u>first meeting on AI risk</u></a>. A number of representatives, including the UN Secretary General, explicitly mentioned AI x-risk.</li></ul><p>See also:&nbsp;<a href=\"https://www.safe.ai/\"><u>CAIS website</u></a>,&nbsp;<a href=\"https://twitter.com/ai_risks?lang=en\"><u>CAIS twitter</u></a>,&nbsp;<a href=\"https://newsletter.mlsafety.org/\"><u>A technical safety research newsletter</u></a>, and&nbsp;<a href=\"https://arxiv.org/abs/2306.12001\"><u>An Overview of Catastrophic AI Risks</u></a></p><p>Subscribe <a href=\"https://newsletter.safe.ai/subscribe?utm_medium=web&amp;utm_source=subscribe-widget-preamble&amp;utm_content=113135916\">here</a> to receive future versions.</p>", "user": {"username": "Center for AI Safety"}}, {"_id": "pztuns47yiKnZLa6e", "title": "Why have CEA / Effective Ventures Foundation not filed accounts for 2022?", "postedAt": "2023-07-25T11:54:58.333Z", "htmlBody": "<p>There is a legal requirement in the UK for organisations such as the EVF/CEA to file full accounts annually, and they are then available online from Companies House.</p><p>The CEA / EVF appear to have not filed any for 2022.</p><p>https://find-and-update.company-information.service.gov.uk/company/07962181/filing-history</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pztuns47yiKnZLa6e/gixeczbw0ilzznqmlyb7\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pztuns47yiKnZLa6e/bf2ezqwv9i1dzxvxx0lc 90w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pztuns47yiKnZLa6e/boyct9pqlf8k3ptj2z7b 180w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pztuns47yiKnZLa6e/gd8q8a43k82xdmnd5ayl 270w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pztuns47yiKnZLa6e/ci55nvcclaogrh0zrf7h 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pztuns47yiKnZLa6e/yj4c5eeel3ko51konllu 450w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pztuns47yiKnZLa6e/zj3rwq6q7jrb0erndnrk 540w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pztuns47yiKnZLa6e/po5y2c1mzrbhn7jebkvg 630w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pztuns47yiKnZLa6e/inqybbksnfdacs1k7hnp 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pztuns47yiKnZLa6e/nkijs1nrndmbaoqyjrrx 810w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pztuns47yiKnZLa6e/szjtusa0t6fw9qbo5w2v 895w\"></figure><p>In previous years, they have been filed - typically in April, for the previous year.</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pztuns47yiKnZLa6e/v6gjcskuacdbhhwozvkt\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pztuns47yiKnZLa6e/nrxhrqtsy5cbkbfprvhr 100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pztuns47yiKnZLa6e/mwvwrgdg1q4xztkxp6bx 200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pztuns47yiKnZLa6e/zz3nu0yqkm1xzynpwq3v 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pztuns47yiKnZLa6e/cpmhwjv73nmaacx3mxng 400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pztuns47yiKnZLa6e/s5sztca0hngmfqoad7wx 500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pztuns47yiKnZLa6e/qmdvupcjcellds1aduro 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pztuns47yiKnZLa6e/whjg5e0cowz2dzovimhw 700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pztuns47yiKnZLa6e/oqqwgwbsfwqmzovwcyjs 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pztuns47yiKnZLa6e/njccnbsznaxyiljvg5mn 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pztuns47yiKnZLa6e/atkqogln23enywvhnqes 949w\"></figure><p>I understand that the Charity Commission are already investigating the EVF/CEA due to their links to the FTX Foundation. Is there some link to the failure to file accounts, or is there some other reason?</p>", "user": {"username": "iamnotalawyer"}}, {"_id": "uYF5rLjH7tbJmFSbQ", "title": "[Linkpost] Can we confidently dismiss the existence of near aliens? Probabilities and implications", "postedAt": "2023-07-25T11:37:04.362Z", "htmlBody": "<p>An earlier <a href=\"https://magnusvinding.com/2023/06/11/what-credible-ufo-evidence/\">post</a> of mine reviewed the most credible evidence I have managed to find regarding seemingly anomalous UFOs. My aim in this post is to mostly set aside the purported UFO evidence and to instead explore whether we can justify placing an extremely low probability on the existence of near aliens, irrespective of the alleged UFO evidence. (By \u201cnear aliens\u201d, I mean advanced aliens on or around Earth.)</p><p>Specifically, after getting some initial clarifications out of the way, I proceed to do the following:</p><ul><li>I explore three potential justifications for a high level of confidence (&gt;99.99 percent) regarding the absence of near aliens: (I) an extremely low prior, (II) technological impossibility, and (III) expectations about what we should observe conditional on advanced aliens being here.</li><li>I review various considerations that suggest that these potential justifications, while they each have some merit, are often overstated.<ul><li>For example, in terms of what we should expect to observe conditional on advanced aliens having reached Earth, I argue that it might not look so different from what we in fact observe.<ul><li>In particular, I argue that near aliens who are entirely silent or only occasionally visible are more plausible than commonly acknowledged. The motive of gathering information about the evolution of life on Earth makes strategic sense relative to a wide range of goals, and this info gain motive is not only compatible with a lack of clear visibility, but arguably predicts it.</li></ul></li></ul></li><li>I try to give some specific probability estimates \u2014 priors and likelihoods on the existence of near aliens \u2014 that seem reasonable to me in light of the foregoing considerations.</li><li>Based on these probability estimates, I present Bayesian updates of the probability of advanced aliens around Earth under different assumptions about our evidence.</li><li>I argue that, regardless of what we make of the purported UFO evidence, the probability of near aliens seems high enough to be relevant to many of our decisions, especially those relating to large-scale impact and risks.</li><li>Lastly, I consider the implications that a non-negligible probability of near aliens might have for our future decisions, including the possibility that our main influence on the future might be through our influence on near aliens.</li></ul>", "user": {"username": "MagnusVinding"}}, {"_id": "kPPneWBzDhuRoXLq5", "title": "[Linkpost] My attempt at trying to summarize 'Intro to ML Safety'", "postedAt": "2023-07-25T10:37:32.603Z", "htmlBody": "<p>After going through <a href=\"https://course.mlsafety.org/\">Intro to ML Safety</a>, I decided to condense the course into a ~30-page document. While I do not think this comes close to a substitute for the course, I figured this might be useful as a litmus test to see if someone would be interested in dedicating their time to self-studying ML/AI safety.</p>\n<p>If it turns out that what I wrote misrepresents the course to a large degree/is just not thorough enough to be considered an introduction, I would be happy if you could point that out, and I may be inclined to write a second version!</p>\n", "user": {"username": "Arjun Yadav"}}, {"_id": "txPQJGpkN6HHEGRsy", "title": "\u3010\u7df4\u7fd2\u554f\u984c\u3011\u30a4\u30f3\u30d1\u30af\u30c8\u306e\u5dee", "postedAt": "2023-07-25T06:29:49.060Z", "htmlBody": "<p><i>This is a Japanese translation of \u201c</i><a href=\"https://forum.effectivealtruism.org/posts/Ro5EPvagWaumJrLQ8/exercise-for-differences-in-impact\"><i><strong>Exercise for 'Differences in Impact'</strong></i></a><i>\u201d</i></p><p>by<strong> </strong><a href=\"https://forum.effectivealtruism.org/users/effective-altruism-handbook\"><strong>EA Handbook</strong></a><strong>&nbsp;&nbsp;</strong>&nbsp;</p><h2>\u30d1\u30fc\u30c8A\uff08\u6240\u8981\u6642\u9593\uff1a20\u5206\uff09</h2><p>\u3053\u306e\u7df4\u7fd2\u554f\u984c\u3067\u306f\u3001\u3042\u306a\u305f\u306f\u4e16\u754c\u306e\u5065\u5eb7\u554f\u984c\u306e\u6539\u5584\u306e\u305f\u3081\u306b\u6148\u5584\u56e3\u4f53\u3078\u5bc4\u4ed8\u3059\u308b\u3053\u3068\u3092\u8a08\u753b\u3057\u3066\u3044\u308b\u3068\u60f3\u5b9a\u3057\u3066\u304f\u3060\u3055\u3044\u3002\u305d\u306e\u5bc4\u4ed8\u91d1\u306b\u3088\u3063\u3066\u3069\u308c\u307b\u3069\u306e\u5f71\u97ff\u3092\u4e0e\u3048\u3089\u308c\u308b\u304b\u691c\u8a3c\u3057\u3066\u3044\u308b\u3068\u3053\u308d\u3067\u3059\u3002</p><p><a href=\"https://www.givewell.org/\"><u>GiveWell</u></a>\u306fEA\u306e\u8003\u3048\u65b9\u306b\u89e6\u767a\u3055\u308c\u305f\u7d44\u7e54\u3067\u3042\u308a\u3001\u4e16\u754c\u306e\u5065\u5eb7\u554f\u984c\u3084\u958b\u767a\u306e\u9818\u57df\u306b\u304a\u3044\u3066\u3001\u5091\u51fa\u3057\u305f\u5bc4\u4ed8\u5148\u3092\u63d0\u793a\u3059\u308b\u3053\u3068\u3092\u76ee\u6a19\u3068\u3057\u3066\u3044\u307e\u3059\u3002<a href=\"https://www.calculators.org/savings/lifetime-earnings.php\"><u>\u3053\u306e\u30c4\u30fc\u30eb</u></a>\u3092\u4f7f\u3063\u3066\u5c06\u6765\u306e\u53ce\u5165\u3092\u898b\u7a4d\u3082\u308a\u3001GiveWell\u306e<a href=\"https://tinyurl.com/y72wneft\"><u>\u4e0a\u4f4d\u6148\u5584\u56e3\u4f53\u30ec\u30dd\u30fc\u30c8</u></a>\u3092\u53c2\u8003\u306b\u3001\u3042\u306a\u305f\u306e\u751f\u6daf\u53ce\u5165\u306e10\uff05\u3092\u3053\u308c\u3089\u306e\u6148\u5584\u56e3\u4f53\u3078\u5bc4\u4ed8\u3057\u305f\u3089\u3001\u3069\u3093\u306a\u3053\u3068\u304c\u9054\u6210\u3067\u304d\u308b\u306e\u304b\u8a08\u7b97\u3057\u3066\u307f\u307e\u3057\u3087\u3046\u3002</p><p>\u5fd9\u3057\u3044\u65b9\u306b\u306f\u3001<a href=\"https://docs.google.com/document/d/17hd1LiHwobz07Z7XnUCM3qZ7NNjCqUKO/edit\"><u>GiveWell\u306b\u3088\u308b\u4e0a\u4f4d3\u3064\u306e\u6148\u5584\u56e3\u4f53\u306e\u60c5\u5831\u3092\u307e\u3068\u3081\u305f\u30b7\u30fc\u30c8</u></a>\u3082\u3042\u308b\u306e\u3067\u53c2\u7167\u304f\u3060\u3055\u3044\u3002\u3082\u3063\u3068\u6df1\u304f\u77e5\u308a\u305f\u3044\u3068\u3044\u3046\u65b9\u306b\u306f\u3001GiveWell\u306e<a href=\"https://tinyurl.com/nx5b9r27\"><u>\u8cbb\u7528\u5bfe\u52b9\u679c\u30e2\u30c7\u30eb</u></a>\u3092\u662f\u975e\u78ba\u8a8d\u304f\u3060\u3055\u3044\u3002</p><p>GiveWell\u306e\u30ea\u30b9\u30c8\u304b\u3089\u6148\u5584\u56e3\u4f53\u30923\u3064\u9078\u3093\u3067\u3001\u305d\u308c\u305e\u308c\u306b\u5bc4\u4ed8\u3057\u305f\u969b\u306b\u3001\u3069\u3093\u306a\u3053\u3068\u304c\u9054\u6210\u3067\u304d\u308b\u306e\u304b\u3001\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u8a08\u7b97\u3057\u3066\u307f\u3066\u304f\u3060\u3055\u3044\u3002\u4ee5\u4e0b\u306f\u56de\u7b54\u306e\u8a18\u5165\u4f8b\u3067\u3059\u3002</p><p><i>\u201d\u30de\u30e9\u30ea\u30a2\u30fb\u30b3\u30f3\u30bd\u30fc\u30b7\u30a2\u30e0\uff1aX\u4ef6\u306e\u30de\u30e9\u30ea\u30a2\u3092\u4e88\u9632\u3002\u63a8\u5b9aN\u4ef6\u306e\u6b7b\u4ea1\u3092\u56de\u907f\u3057\u305f\u201d</i></p><h2>\u30d1\u30fc\u30c8B\uff08\u6240\u8981\u6642\u9593\uff1a10\u5206\uff09</h2><p>\u30d1\u30fc\u30c8A\u3067\u306f\u3001\u3044\u304f\u3064\u304b\u306e\u9078\u629e\u80a2\u304c\u5b58\u5728\u3057\u3066\u3044\u308b\u72b6\u614b\u3067\u3057\u305f\u3002\u3053\u3053\u3067\u306f\u3001\u3053\u308c\u3089\u6148\u5584\u56e3\u4f53\u306e\u306a\u304b\u304b\u3089\u4e00\u3064\u306e\u56e3\u4f53\u306b\u7d5e\u3063\u30661,000\u30c9\u30eb\u3092\u5bc4\u4ed8\u3092\u3059\u308b\u3053\u3068\u3092\u60f3\u5b9a\u3057\u3066\u304f\u3060\u3055\u3044\u3002</p><p>\u3042\u306a\u305f\u306f\u4eca\u96e3\u3057\u3044\u5224\u65ad\u3092\u8feb\u3089\u308c\u3066\u3044\u307e\u3059\u3002\u3088\u3044\u3053\u3068\u3092\u6700\u5927\u5316\u3059\u308b\u305f\u3081\u306b\u3001\u3069\u306e\u5bc4\u4ed8\u5148\u3092\u9078\u3073\u307e\u3059\u304b\uff1f</p><p>&nbsp;\u305d\u308c\u3067\u306f\u3001\u6b21\u306e\u554f\u3044\u306b\u5bfe\u3059\u308b\u3042\u306a\u305f\u306e\u7b54\u3048\u3092\u66f8\u3044\u3066\u307f\u3066\u304f\u3060\u3055\u3044\u3002</p><p><i>\u3069\u306e\u6148\u5584\u56e3\u4f53\u306b\u5bc4\u4ed8\u3059\u308b\u3053\u3068\u3092\u9078\u3073\u307e\u3059\u304b\uff1f\u305d\u308c\u306f\u306a\u305c\u3067\u3059\u304b\uff1f</i></p><h2>\u30d1\u30fc\u30c8C\uff08\u6240\u8981\u6642\u9593\uff1a10\u5206\uff09</h2><p>\u3042\u306a\u305f\u306e\u4eba\u751f\u306e\u4e2d\u306e\u6c7a\u65ad\u3067\u3001\u91cf\u7684\u306b\u898b\u7a4d\u3082\u308a\u3092\u51fa\u3057\u3001\u7d50\u679c\u3092\u6bd4\u8f03\u3057\u3066\u307f\u305f\u3044\u3053\u3068\u306f\u4ed6\u306b\u4f55\u304c\u3042\u308b\u3067\u3057\u3087\u3046\u304b\uff1f</p>", "user": {"username": "EA Japan"}}, {"_id": "CbJkfo5GmnHyHQ9jH", "title": "LEEP\uff08\u925b\u66b4\u9732\u6392\u9664\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\uff09\u306e\u7d39\u4ecb", "postedAt": "2023-07-25T06:16:36.316Z", "htmlBody": "<p><i>This is a Japanese translation of \u201c</i><a href=\"https://forum.effectivealtruism.org/posts/fd96FtLFACeAshqJP/introducing-leep-lead-exposure-elimination-project\"><i><strong>Introducing LEEP: Lead Exposure Elimination Project</strong></i></a><i>\u201d</i></p><p>\u5f53\u8a18\u4e8b\u306f<a href=\"https://forum.effectivealtruism.org/\"><u>Effective Altruism\u30d5\u30a9\u30fc\u30e9\u30e0</u></a>\u306b\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u30b9\u30bf\u30c3\u30d5\u306b\u3088\u3063\u3066\u6295\u7a3f\u3055\u308c\u305f\u3082\u306e\u3067\u3059\u3002</p><p><a href=\"https://forum.effectivealtruism.org/users/jack\"><u>Jack</u></a>,<a href=\"https://forum.effectivealtruism.org/users/luciac\">&nbsp;<u>LuciaC</u></a></p><p>Charity Entrepreneurship\u304c\u8a2d\u7acb\u3092\u652f\u63f4\u3057\u305f\u3057\u305f\u65b0\u3057\u3044EA\uff08Effective Altruism\uff09\u7cfb\u7d44\u7e54\u3001Lead Exposure Elimination Project\uff08<a href=\"https://leadelimination.org/\"><u>LEEP</u></a>\uff09\u306e\u767a\u8db3\u3092\u304a\u77e5\u3089\u305b\u3057\u307e\u3059\u3002 \u79c1\u305f\u3061\u306f\u3001\u4e16\u754c\u7684\u306b\u3082\u5927\u5909\u306a\u75be\u75c5\u8ca0\u8377\u3068\u306a\u3063\u3066\u3044\u308b\u925b\u4e2d\u6bd2\u306e\u524a\u6e1b\u3092\u76ee\u6a19\u306b\u3057\u3066\u3044\u307e\u3059\u3002\u925b\u542b\u6709\u5857\u6599\u306b\u3088\u308b\u925b\u4e2d\u6bd2\u306e\u88ab\u5bb3\u304c\u62e1\u5927\u3057\u3066\u3044\u308b\u56fd\u3005\u3067\u3001\u6cd5\u898f\u5236\u306e\u5fb9\u5e95\u3092\u5531\u3048\u308b\u3053\u3068\u306b\u3088\u3063\u3066\u3001\u76ee\u6a19\u9054\u6210\u3092\u76ee\u6307\u3057\u307e\u3059\u3002</p><p>\u3053\u3053\u3067\u306f\u925b\u4e2d\u6bd2\u306e\u524a\u6e1b\u3092\u512a\u5148\u8ab2\u984c\u3068\u3057\u3066\u6271\u3044\u3001\u305d\u306e\u5bfe\u7b56\u306e\u6982\u8981\u306b\u3064\u3044\u3066\u3054\u8aac\u660e\u3057\u307e\u3059\u3002</p><h2><strong>\u925b\u4e2d\u6bd2\u306e\u554f\u984c</strong></h2><p>\u79c1\u305f\u3061\u304c\u5c5e\u3059\u308bEA\uff08Effective Altruism\uff09\u30b3\u30df\u30e5\u30cb\u30c6\u30a3\u5185\u3067\u306f\u3001\u304b\u306d\u3066\u304b\u3089\u925b\u4e2d\u6bd2\u3078\u306e\u53d6\u308a\u7d44\u307f\u304c\u793e\u4f1a\u3078\u5927\u304d\u306a\u5f71\u97ff\u3092\u4e0e\u3048\u308b\u306e\u3067\u306f\u306a\u3044\u304b\u3001\u3068\u3044\u3046\u58f0\u304c\u4e0a\u304c\u3063\u3066\u3044\u307e\u3057\u305f\u3002Effective Altuism\u3067\u306f\u3001<a href=\"https://concepts.effectivealtruism.org/concepts/importance-neglectedness-tractability/\"><u>ITN \u306e\u67a0\u7d44\u307f</u></a>\uff08<strong>I</strong>mportance\u201d\u554f\u984c\u306e\u898f\u6a21\u201d\u2212<strong>T</strong>ractability\u201d\u53d6\u308a\u7d44\u307f\u3084\u3059\u3055\u201d\u2212&nbsp;<strong>N</strong>eglectedness\u201d\u898b\u904e\u3054\u3055\u308c\u3066\u3044\u308b\u5ea6\u5408\u3044\u201d\uff09\u3092\u63a1\u7528\u3057\u8ab2\u984c\u89e3\u6c7a\u306b\u53d6\u308a\u7d44\u3093\u3067\u3044\u307e\u3059\u3002\u3053\u306e\u3053\u3068\u304b\u3089\u925b\u4e2d\u6bd2\u306e\u793e\u4f1a\u554f\u984c\u3092\u512a\u5148\u3057\u63d0\u8a00\u3059\u308b\u306b\u81f3\u308a\u307e\u3057\u305f\u3002</p><h3><strong>\u554f\u984c\u306e\u898f\u6a21</strong></h3><p>\u925b\u4e2d\u6bd2\u306f\u5065\u5eb7\u88ab\u5bb3\u3084\u7d4c\u6e08\u7684\u640d\u5931\u3092\u751f\u307f\u51fa\u3057\u3001\u925b\u3092\u542b\u3080\u5857\u6599\u306f\u305d\u306e\u4e3b\u306a\u539f\u56e0\u3068\u306a\u3063\u3066\u3044\u307e\u3059\u3002\u925b\u66b4\u9732\u306f\u500b\u4eba\u306b\u3082\u591a\u304f\u306e\u88ab\u5bb3\u3092\u53ca\u307c\u3057\u307e\u3059\u3002\u4f4e\u30ec\u30d9\u30eb\u306e\u925b\u66b4\u9732\u3067\u3042\u3063\u3066\u3082\u3001\u7cbe\u795e\u969c\u5bb3\u3084\u77e5\u80fd\u6307\u6570\u306e\u4f4e\u4e0b\u3001\u7cbe\u795e\u75be\u60a3\u7387\u306e\u4e0a\u6607\u306a\u3069\u3092\u5f15\u304d\u8d77\u3053\u3057\u3001\u307e\u305f\u88ab\u5bb3\u8005\u306e\u751f\u6daf\u306e\u60f3\u5b9a\u53ce\u5165\u3092\u8457\u3057\u304f\u4f4e\u4e0b\u3055\u305b\u308b\u6050\u308c\u304c\u3042\u308a\u307e\u3059\u3002\u66f4\u306b\u3001\u925b\u4e2d\u6bd2\u306f\u884c\u52d5\u306e\u554f\u984c\u3084\u72af\u7f6a\u3001\u306a\u304b\u3067\u3082\u66b4\u529b\u72af\u7f6a\u306e\u8513\u5ef6\u306a\u3069\u306b\u95a2\u308f\u3063\u3066\u3044\u307e\u3059\u3002\u6210\u4eba\u306b\u5bfe\u3057\u3066\u3001\u814e\u81d3\u3078\u306e\u969c\u5bb3\u3084\u9ad8\u8840\u5727\u3084\u51a0\u52d5\u8108\u75be\u60a3\u306a\u3069\u3092\u542b\u3080\u5fc3\u8840\u7ba1\u75be\u60a3\u306e\u91cd\u5927\u306a\u30ea\u30b9\u30af\u8981\u56e0\u306b\u306a\u308a\u307e\u3059\u3002\u9ad8\u30ec\u30d9\u30eb\u306e\u66b4\u9732\u306f\u3059\u3079\u3066\u306e\u5668\u5b98\u7cfb\u306b\u5f71\u97ff\u3092\u53ca\u307c\u3057\u3001\u7d50\u679c\u3068\u3057\u3066\u547c\u5438\u56f0\u96e3\u3084\u3051\u3044\u308c\u3093\u30fb\u767a\u4f5c\u8d77\u3053\u3057\u305f\u308a\u3001\u660f\u7761\u3001\u6b7b\u306b\u81f3\u308b\u3053\u3068\u3082\u3042\u308a\u307e\u3059\u3002</p><p>\u925b\u4e2d\u6bd2\u306f\u3001\u7279\u306b\u5b50\u3069\u3082\u305f\u3061\u306b\u5f71\u97ff\u3092\u4e0e\u3048\u3066\u304a\u308a\u3001\u305d\u306e\u88ab\u5bb3\u898f\u6a21\u306f\u6975\u3081\u3066\u5927\u304d\u3044\u306e\u3067\u3059\u3002\u30e6\u30cb\u30bb\u30d5\u306e\u5831\u544a\u306b\u3088\u308b\u3068\u30018\u51041,500\u4e07\u4eba\u306e\u5b50\u3069\u3082\u305f\u3061\u304b\u3089\u3001\u795e\u7d4c\u767a\u9054\u3078\u306e\u5f71\u97ff\u3084\u77e5\u8b58\u6307\u6a19\u306e\u4f4e\u4e0b\u3092\u5f15\u304d\u8d77\u3053\u3059\u30ec\u30d9\u30eb\u3067\u3042\u308b\u3001\u8840\u6db21dL\u3042\u305f\u308a5\u00b5g\uff08\u30de\u30a4\u30af\u30ed\u30b0\u30e9\u30e0\uff09\u4ee5\u4e0a\u306e\u8840\u4e2d\u925b\u6fc3\u5ea6\u304c\u691c\u51fa\u3055\u308c\u3066\u3044\u307e\u3059\u3002\u591a\u304f\u306f\u4f4e\u30fb\u4e2d\u6240\u5f97\u56fd\u306e\u5b50\u3069\u3082\u305f\u3061\u3067\u3059\u3002\u8a00\u3044\u63db\u3048\u308b\u30683\u4eba\u306b\u3072\u3068\u308a\u304c\u925b\u4e2d\u6bd2\u306b\u3088\u308b\u4f55\u3089\u304b\u306e\u5f71\u97ff\u3092\u53d7\u3051\u3066\u3044\u308b\u3053\u3068\u306b\u306a\u308a\u307e\u3059\u3002</p><p>\u969c\u5bb3\u3092\u62b1\u3048\u308b\u3053\u3068\u306b\u52a0\u3048\u3066\u3001\u925b\u4e2d\u6bd2\u306f\u5e74\u9593100\u4e07\u3082\u306e\u4eba\u3005\u306b\u6b7b\u3092\u3082\u305f\u3089\u3057\u3066\u3044\u307e\u3059\u3002DALY\uff08\u969c\u5bb3\u8abf\u6574\u751f\u547d\u5e74\uff09\u306f\u6bce\u5e742200\u4e07\u306b\u3082\u9054\u3057\u3001\u3053\u308c\u306f\u4e16\u754c\u306e\u75be\u75c5\u8ca0\u8377\u306e\u7d041\uff05\u306b\u3042\u305f\u308b\u3053\u3068\u3092\u610f\u5473\u3057\u307e\u3059\u3002</p><p>\u925b\u4e2d\u6bd2\u306b\u3088\u308a\u4eba\u3005\u306f\u53ce\u5165\u6e1b\u3092\u4f59\u5100\u306a\u304f\u3055\u308c\u308b\u3053\u3068\u304b\u3089\u3001\u4e16\u754c\u7d4c\u6e08\u3078\u306e\u6253\u6483\u3082\u5927\u304d\u304f\u3001\u5e74\u9593\u3067\u304a\u3088\u305d1\u5146\u30c9\u30eb\u898f\u6a21\u306b\u53ca\u3076\u3068\u3055\u308c\u3066\u3044\u307e\u3059\u3002\u3053\u308c\u306f\u4e16\u754c\u306eGDP\u306e1.2\uff05\u306e\u640d\u5931\u306b\u3042\u305f\u308b\u6570\u5b57\u3067\u3059\u3002\u307e\u305f\u3001\u3053\u308c\u3089\u306e\u640d\u5931\u88ab\u5bb3\u306f\u4f4e\u30fb\u4e2d\u6240\u5f97\u56fd\u306b\u96c6\u4e2d\u3057\u3066\u304a\u308a\u3001\u305d\u308c\u3089\u306e\u56fd\u3005\u3067\u306e\u640d\u5931\u304c<a href=\"https://med.nyu.edu/departments-institutes/pediatrics/divisions/environmental-pediatrics/research/policy-initiatives/economic-costs-childhood-lead-exposure-low-middle-income-countries\"><u>GDP\u306e5\u301c8\uff05</u></a>\u306b\u3082\u9054\u3059\u308b\u3053\u3068\u304b\u3089\u3001\u925b\u66b4\u9732\u306f\u7d4c\u6e08\u767a\u5c55\u3068\u8ca7\u56f0\u524a\u6e1b\u306e\u5927\u304d\u306a\u59a8\u3052\u3068\u306a\u3063\u3066\u3044\u308b\u3053\u3068\u304c\u793a\u5506\u3055\u308c\u307e\u3059\u3002</p><p>\u3064\u307e\u308a\u3001\u925b\u4e2d\u6bd2\u306f\u91cd\u5927\u306a\u554f\u984c\u306a\u306e\u3067\u3059\u3002</p><h3><strong>\u898b\u904e\u3054\u3055\u308c\u3066\u3044\u308b\u5ea6\u5408\u3044</strong></h3><p>\u73fe\u5728\u30011\u3064\u306e\u56fd\u3092\u9664\u304d\u3059\u3079\u3066\u306e\u56fd\u304c\u6709\u925b\u30ac\u30bd\u30ea\u30f3\u3092\u6cd5\u5f8b\u3067\u7981\u6b62\u3057\u3066\u3044\u308b\u4e00\u65b9\u3001\u4e16\u754c\u306e61\uff05\u306e\u56fd\u3005\u3067\u925b\u542b\u6709\u5857\u6599\u306e\u898f\u5236\u3092\u884c\u3063\u3066\u3044\u307e\u305b\u3093\u3002\u3053\u308c\u3089\u4f4e\u30fb\u4e2d\u6240\u5f97\u56fd\u306e\u591a\u304f\u3067\u306f\u3001\u925b\u4e2d\u6bd2\u306b\u3088\u308b\u75be\u75c5\u8ca0\u8377\u304c<a href=\"https://lead.pollution.org/#\"><u>\u672a\u3060\u306b\u5927\u304d\u3044</u></a>\u306e\u3067\u3059\u3002\u9ad8\u6240\u5f97\u56fd\u306e\u307b\u3068\u3093\u3069\u306f\u6709\u925b\u30ac\u30bd\u30ea\u30f3\u3084\u925b\u542b\u6709\u5857\u6599\u3092\u6cd5\u5f8b\u3067\u7981\u6b62\u3057\u3066\u304a\u308a\u3001\u5bfe\u7b56\u304c\u9032\u3093\u3067\u3044\u308b\u72b6\u6cc1\u3067\u3059\u3002</p><p>IPEN, ToxicsLink, Pure Earth\u306a\u3069\u4e2d\u4f4e\u6240\u5f97\u56fd\u3067\u5f53\u554f\u984c\u306b\u53d6\u308a\u7d44\u3080\u56e3\u4f53\u304c\u5b58\u5728\u3059\u308b\u4e00\u65b9\u3001\u925b\u66b4\u9732\u306b\u3088\u308b\u88ab\u5bb3\u304c\u5927\u304d\u3044\u591a\u304f\u306e\u56fd\u3005\u3067\u3001\u554f\u984c\u304c\u653e\u7f6e\u3057\u3055\u308c\u3066\u3044\u307e\u3059\u3002LEEP\u306f\u3053\u306e\u5dee\u3092\u306a\u304f\u3059\u3079\u304f\u3001\u554f\u984c\u304c\u7f6e\u304d\u53bb\u308a\u306b\u3055\u308c\u3066\u3044\u308b\u56fd\u3005\u3092\u30bf\u30fc\u30b2\u30c3\u30c8\u3068\u3057\u3066\u3044\u304d\u307e\u3059\u3002</p><h3><strong>\u53d6\u308a\u7d44\u307f\u3084\u3059\u3055</strong></h3><p>\u925b\u4e2d\u6bd2\u306e\u554f\u984c\u306b\u53d6\u308a\u7d44\u3080\u4e0a\u3067\u3001\u653f\u7b56\u8ee2\u63db\u3092\u4fc3\u3059\u4e8b\u306b\u6210\u529f\u3067\u304d\u308b\u304b\u304c\u6700\u5927\u306e\u61f8\u5ff5\u3067\u3059\u3002\u3057\u304b\u3057\u3001\u925b\u542b\u6709\u5857\u6599\u306e\u751f\u7523\u30fb\u8f38\u5165\u3092\u7981\u6b62\u3059\u308b\u653f\u7b56\u8ee2\u63db\u3092\u6709\u5229\u306b\u3059\u308b\u6839\u62e0\u3082\u3042\u308a\u307e\u3059\u3002</p><ul><li>\u5c02\u9580\u5bb6\u306b\u3088\u308b\u3068\u3001\u925b\u542b\u6709\u5857\u6599\u306f\u4eba\u3005\u3092\u925b\u306b\u3055\u3089\u3059\u7d20\u6750\u3068\u3057\u3066\u6700\u3082\u5bfe\u51e6\u3057\u3084\u3059\u304f\u3001\u898f\u5236\u306e\u30cf\u30fc\u30c9\u30eb\u306f\u4f4e\u3044\u3068\u3055\u308c\u308b\u3002\u5857\u6599\u306f\u4eba\u3005\u306b\u925b\u3092\u3055\u3089\u3059\u6700\u3082\u8eab\u8fd1\u306a\u5b58\u5728\u3067\u3042\u308a\u3001\u305d\u306e\u4ed6\u306b\u3082\u84c4\u96fb\u6c60\u3084\u9271\u5c71\u696d\u3001\u98df\u54c1\u3001\u30d1\u30a4\u30d7\u3001\u8abf\u7406\u5668\u5177\u306a\u3069\u3082\u66b4\u9732\u7d4c\u8def\u306b\u306a\u3063\u3066\u3044\u308b\u3002</li><li>\u925b\u542b\u6709\u5857\u6599\u306b\u3088\u308b\u66b4\u9732\u3092\u6e1b\u3089\u3059\u306b\u306f\u3001\u6cd5\u7684\u898f\u5236\u306e\u5c0e\u5165\u304c\u6700\u3082\u52b9\u679c\u7684\u3067\u3042\u308b\u3068\u3044\u3046\u70b9\u3067\u5e83\u304f\u5408\u610f\u304c\u306a\u3055\u308c\u3066\u3044\u308b\u3002</li><li>\u925b\u3092\u542b\u307e\u306a\u3044\u5857\u6599\u3078\u306e\u8ee2\u63db\u306f\u3001\u88fd\u9020\u8005\u306b\u3068\u3063\u3066\u6280\u8853\u9762\u30fb\u7d4c\u6e08\u9762\u3067\u3068\u3082\u306b\u5b9f\u73fe\u53ef\u80fd\u3067\u3042\u308b\u3002</li><li>NGO\u306f\u3053\u308c\u307e\u3067\u306b21\u30f5\u56fd\u306e\u4e2d\u4f4e\u6240\u5f97\u56fd\u3067\u925b\u542b\u6709\u5857\u6599\u306e\u65b0\u6cd5\u5f8b\u5c0e\u5165\u306b\u6210\u529f\u3057\u5148\u4f8b\u3092\u793a\u3057\u305f\u3002</li><li>\u4e00\u822c\u7684\u306b\u53cd\u5bfe\u8ad6\u304c\u5b58\u5728\u3059\u308b\u5834\u5408\u3001\u6cd5\u6539\u6b63\u306f\u56f0\u96e3\u306b\u9665\u308b\u3053\u3068\u304c\u591a\u3044\u3002\u925b\u542b\u6709\u5857\u6599\u306e\u6cd5\u7684\u898f\u5236\u306e\u4ecb\u5165\u306b\u304a\u3051\u308b\uff11\u3064\u306e\u6709\u5229\u3055\u306f\u3001\u4e8b\u5b9f\u4e0a\u653f\u6cbb\u7684\u306b\u5bfe\u7acb\u3057\u306a\u3044\u554f\u984c\u3067\u3042\u308b\u3053\u3068\u3067\u3042\u308b\u3002\u898f\u5236\u306b\u53cd\u5bfe\u3057\u5f97\u308b\u30ed\u30d3\u30fc\u6d3b\u52d5\u304c\u306a\u3044\u3053\u3068\u306b\u52a0\u3048\u3001\u5857\u6599\u696d\u754c\u304c\u898f\u5236\u306e\u5c0e\u5165\u3092\u652f\u6301\u3059\u308b\u4e8b\u4f8b\u3055\u3048\u3042\u308b\u3002</li><li>\u5857\u6599\u306e\u898f\u5236\u306f\u975e\u5e38\u306b\u4f4e\u30b3\u30b9\u30c8\u3067\u3042\u308a\u3001\u307e\u305f\u9577\u671f\u7684\u306b\u5bfe\u8c61\u56fd\u306b\u5927\u304d\u306a\u5229\u76ca\u3092\u3082\u305f\u3089\u3059\u305f\u3081\u3001\u610f\u601d\u6c7a\u5b9a\u306e\u9375\u3092\u63e1\u308b\u653f\u6cbb\u5bb6\u3089\u306b\u3068\u3063\u3066\u3082\u660e\u3089\u304b\u306b\u5229\u70b9\u304c\u591a\u3044\u3002\u925b\u542b\u6709\u5857\u6599\u306e\u5371\u967a\u9632\u6b62\u306b1\u30c9\u30eb\u8cbb\u3084\u3059\u3054\u3068\u306b\u300117\u30c9\u30eb\u301c221\u30c9\u30eb\u306e\u30ea\u30bf\u30fc\u30f3\u304c\u3042\u308b\u3068\u63a8\u5b9a\u3055\u308c\u308b\u3002</li><li>\u925b\u542b\u6709\u5857\u6599\u306b\u95a2\u308f\u308b\u554f\u984c\u306f\u6982\u3057\u3066\u653f\u515a\u306b\u95a2\u4fc2\u306a\u304f\u3001\u515a\u6d3e\u7684\u5bfe\u7acb\u306f\u8d77\u3053\u308a\u5f97\u306a\u3044\u3002</li></ul><p>\u79c1\u305f\u3061\u306e\u6d3b\u52d5\u304c\u751f\u307f\u51fa\u3059\u793e\u4f1a\u7684\u5f71\u97ff\u306b\u52a0\u3048\u3001\u540c\u3058\u3088\u3046\u306b\u653f\u7b56\u63d0\u6848\u306b\u53d6\u308a\u7d44\u3080\u4eba\u3005\u306b\u3080\u3051\u3066\u4ecb\u5165\u304c\u5b9f\u73fe\u53ef\u80fd\u3067\u3042\u308b\u3053\u3068\u3092\u793a\u3059\u3053\u3068\u304c\u3067\u304d\u308c\u3070\u3068\u9858\u3063\u3066\u3044\u307e\u3059\u3002</p><h2>&nbsp;</h2><h2><strong>\u6d3b\u52d5\u8a08\u753b\u306b\u3064\u3044\u3066</strong></h2><p>\u4ecb\u5165\u306e\u4f59\u5730\u304c\u3042\u308a\u3001\u554f\u984c\u306b\u3088\u308b\u88ab\u5bb3\u304c\u5927\u304d\u304f\u3001\u307e\u305f\u554f\u984c\u304c\u653e\u7f6e\u3055\u308c\u3066\u3044\u308b\u56fd\u3092\u78ba\u5b9f\u306b\u30bf\u30fc\u30b2\u30c3\u30c8\u3068\u3057\u3066\u3044\u304f\u305f\u3081\u306b\u56fd\u306e\u9078\u629e\u3092\u7b2c\u4e00\u3068\u3057\u307e\u3057\u305f\u3002\u305d\u306e\u7d50\u679c\u3001\u30de\u30e9\u30a6\u30a4\u3092\u6700\u3082\u53ef\u80fd\u6027\u306e\u3042\u308b\u56fd\u3068\u3057\u3066\u9078\u5b9a\u3057\u307e\u3057\u305f\u3002\u3053\u308c\u3088\u308a2\u30f6\u6708\u9593\u3001\u30de\u30e9\u30a6\u30a4\u3067\u8ca9\u58f2\u3055\u308c\u3066\u3044\u308b\u65b0\u3057\u3044\u5857\u6599\u306b\u542b\u307e\u308c\u308b\u925b\u306e\u6fc3\u5ea6\u3092\u8abf\u67fb\u3057\u3001\u95a2\u4fc2\u8005\u3084\u610f\u601d\u6c7a\u5b9a\u8005\u3089\u3068\u95a2\u4fc2\u3092\u69cb\u7bc9\u3057\u3066\u3044\u304f\u4e88\u5b9a\u3067\u3059\u3002\u3053\u306e\u671f\u9593\u3067\u5f97\u3089\u308c\u305f\u77e5\u898b\u3084\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306e\u9032\u6357\u5177\u5408\u3092\u57fa\u306b\u3001\u5b9f\u969b\u306b\u30de\u30e9\u30a6\u30a4\u3067\u925b\u542b\u6709\u5857\u6599\u898f\u5236\u306e\u5c0e\u5165\u3078\u3080\u3051\u3066\u52d5\u304f\u304b\u3001\u4ed6\u306e\u5019\u88dc\u5730\u3078\u8ef8\u8db3\u3092\u79fb\u3059\u304b\u3092\u6c7a\u5b9a\u3057\u307e\u3059\u3002</p><p>\u79c1\u305f\u3061\u306f\u3001Effective Altruism\u306e\u539f\u5247\u306b\u6cbf\u3063\u3066\u6839\u62e0\u306b\u57fa\u3065\u304f\u653f\u7b56\u5909\u66f4\u3078\u58f0\u3092\u4e0a\u3052\u306a\u304c\u3089\u3001\u3082\u3057\u79c1\u305f\u3061\u304c\u884c\u52d5\u3092\u8d77\u3053\u3055\u306a\u304b\u3063\u305f\u3089\u3069\u3046\u3060\u3063\u305f\u304b\u3068\u8003\u3048\u308b\u3053\u3068\u3067\u53b3\u3057\u304f\u7d4c\u904e\u89b3\u5bdf\u3057\u3066\u3044\u304d\u307e\u3059\u3002\u307e\u305f\u3001\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u3092\u9032\u3081\u308b\u4e2d\u3001\u925b\u4e2d\u6bd2\u554f\u984c\uff08\u307e\u305f\u306f\u3088\u308a\u5e83\u7bc4\u7684\u306a\u610f\u5473\u3067\u306e\u653f\u7b56\u63d0\u8a00\uff09\u306b\u53d6\u308a\u7d44\u3080\u4ed6\u306e\u56e3\u4f53\u3084\u500b\u4eba\u304c\u5229\u7528\u3067\u304d\u308b\u3088\u3046\u3001\u8abf\u67fb\u7d50\u679c\u306e\u3059\u3079\u3066\u3092\u30a6\u30a7\u30d6\u30b5\u30a4\u30c8\u3067\u516c\u958b\u3057\u3066\u3044\u304f\u4e88\u5b9a\u3067\u3059\u3002</p><p>\u4e8b\u524d\u5206\u6790\u306e\u7d50\u679c\u3001\u3053\u306e\u554f\u984c\u4ecb\u5165\u306f\u8cbb\u7528\u5bfe\u52b9\u679c\u304c\u9ad8\u304f\u3001\u73fe\u5728GiveWell\u304c\u63a8\u85a6\u3059\u308b\u512a\u308c\u305f\u6148\u5584\u4e8b\u696d\u56e3\u4f53\u306e\u6210\u679c\u306b\u5339\u6575\u3059\u308b\u53ef\u80fd\u6027\u304c\u3042\u308b\u3053\u3068\u304c\u308f\u304b\u308a\u307e\u3057\u305f\u3002\u925b\u306e\u6cd5\u6574\u5099\u306f\u5065\u5eb7\u554f\u984c\u3084\u4e16\u754c\u958b\u767a\u306b\u53d6\u308a\u7d44\u3080\u591a\u304f\u306e\u6148\u5584\u4e8b\u696d\u56e3\u4f53\u3068\u6bd4\u3079\u3001\u3088\u308a\u9ad8\u3044\u8cbb\u7528\u5bfe\u52b9\u679c\u304c\u898b\u8fbc\u307e\u308c\u307e\u3059\u3002</p><p>\u307e\u305a\u30bf\u30fc\u30b2\u30c3\u30c8\u56fd\u3068\u3057\u305f\u56fd\u306b\u6ce8\u529b\u3057\u3066\u3044\u304d\u307e\u3059\u304c\u3001\u79c1\u305f\u3061\u306e\u9577\u671f\u7684\u76ee\u6a19\u306f\u925b\u306b\u3088\u308b\u88ab\u5bb3\u304c\u5927\u304d\u3044\u591a\u304f\u306e\u56fd\u3005\u3067\u925b\u898f\u5236\u3092\u5c0e\u5165\u3057\u3001\u56fd\u5bb6\u9593\u30ec\u30d9\u30eb\u3067\u925b\u4e2d\u6bd2\u3092\u524a\u6e1b\u3059\u308b\u3053\u3068\u3067\u3059\u3002</p><h2>&nbsp;</h2><h2><strong>LEEP\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306e\u652f\u63f4\u65b9\u6cd5</strong></h2><p>\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u3092\u652f\u63f4\u5e0c\u671b\u3055\u308c\u308b\u65b9\u306f\u3001\u4ee5\u4e0b\u3092\u3054\u89a7\u304f\u3060\u3055\u3044\u3002</p><h3>\u30a2\u30c9\u30d0\u30a4\u30b6\u30fc\u3068\u3057\u3066\u6d3b\u8e8d\u3059\u308b</h3><p>\u73fe\u5728\u3001\u540c\u30c1\u30fc\u30e0\u306f<a href=\"https://www.charityentrepreneurship.com/\"><u>Charity Entrepreneurship</u></a>\u304a\u3088\u3073\u3001<a href=\"https://www.fortifyhealth.global/\"><u>Fortify Health</u></a>\u306e\u5275\u696d\u8005\u3088\u308a\u3001\u6307\u5c0e\u30fb\u52a9\u8a00\u3092\u53d7\u3051\u3066\u3044\u307e\u3059\u304c\u3001\u5f15\u304d\u7d9a\u304d\u30a2\u30c9\u30d0\u30a4\u30b6\u30fc\uff08\u9867\u554f\uff09\u3092\u52df\u96c6\u3057\u3066\u3044\u307e\u3059\u3002\u5177\u4f53\u7684\u306b\u306f\u3001\u925b\u898f\u5236\u3084\u305d\u306e\u4ed6\u306e\u653f\u7b56\u63d0\u8a00\u306b\u8a73\u3057\u3044\u5c02\u9580\u5bb6\u3068\u306e\u7e4b\u304c\u308a\u3092\u6301\u3061\u305f\u3044\u3068\u8003\u3048\u3066\u3044\u307e\u3059\u3002\u8a72\u5f53\u3059\u308b\u7d4c\u9a13\u3092\u304a\u6301\u3061\u306e\u65b9\u306f\u3001\u305c\u3072\u3054\u9023\u7d61\u304f\u3060\u3055\u3044\u3002</p><p>\u307e\u305f\u3001\u79c1\u305f\u3061\u306e\u6d3b\u52d5\u5bfe\u8c61\u56fd\u306b\u304a\u3044\u3066\u3001\u73fe\u5730\u3067\u306e\u7e4b\u304c\u308a\u3084\u7d4c\u9a13\u3092\u304a\u6301\u3061\u65b9\u3092\u30a2\u30c9\u30d0\u30a4\u30b6\u30fc\u3068\u3057\u3066\u52df\u96c6\u3057\u3066\u3044\u307e\u3059\u3002\u5bfe\u8c61\u56fd\u306f\u30de\u30e9\u30a6\u30a4\u3001\u30de\u30c0\u30ac\u30b9\u30ab\u30eb\u3001\u30b7\u30a8\u30e9\u30ec\u30aa\u30cd\u3001\u30d6\u30eb\u30ad\u30ca\u30d5\u30a1\u30bd\u3001\u30b0\u30a2\u30c6\u30de\u30e9\u3067\u3059\u3002\u4f55\u3089\u304b\u306e\u95a2\u308f\u308a\u304c\u3042\u308b\u65b9\u306f\u3054\u9023\u7d61\u304f\u3060\u3055\u3044\u3002</p><h3><strong>\u63a1\u7528\u306b\u3064\u3044\u3066</strong></h3><p>\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u59cb\u52d5\u5f8c\u304b\u30891\u5e74\u306e\u9593\u3001\u5bfe\u8c61\u5730\u57df\u306b\u3066\u73fe\u5730\u30b9\u30bf\u30c3\u30d5\u3092\u96c7\u7528\u3059\u308b\u4e88\u5b9a\u3067\u3059\u3002\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u904b\u55b6\u3001\u8abf\u67fb\u3001\u30b3\u30df\u30e5\u30cb\u30b1\u30fc\u30b7\u30e7\u30f3\u306a\u3069\u306e\u8077\u52d9\u3067\u30a4\u30f3\u30bf\u30fc\u30f3\u30b7\u30c3\u30d7\u5e0c\u671b\u8005\u3084\u30c1\u30fc\u30e0\u30e1\u30f3\u30d0\u30fc\u3092\u5c06\u6765\u63a1\u7528\u3059\u308b\u53ef\u80fd\u6027\u3082\u3042\u308a\u307e\u3059\u3002</p><h3><strong>\u6d3b\u52d5\u8cc7\u91d1\u306b\u3064\u3044\u3066</strong></h3><p><a href=\"https://www.charityentrepreneurship.com/\"><u>Charity Entrepreneurship</u></a> \u3088\u308a6\u4e07\u30c9\u30eb\u306e\u52a9\u6210\u91d1\u3092\u53d7\u3051\u3001\u521d\u5e74\u5ea6\u306e\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u904b\u55b6\u8cbb\u3092\u307b\u307c\u8cc4\u3046\u3053\u3068\u304c\u3067\u304d\u307e\u3057\u305f\u3002</p><p>\u4eca\u5f8c\u3055\u3089\u306a\u308b\u8cc7\u91d1\u8abf\u9054\u3092\u884c\u3046\u4e88\u5b9a\u3067\u3059\u304c\u3001\u59cb\u52d5\u3057\u3066\u9593\u3082\u306a\u3044\u7d44\u7e54\u3092\u652f\u63f4\u3057\u3066\u304f\u3060\u3055\u308b\u30ea\u30b9\u30af\u306b\u5bdb\u5bb9\u306a\u4eba\u3005\u3068\u306e\u51fa\u4f1a\u3044\u3092\u304a\u5f85\u3061\u3057\u3066\u3044\u307e\u3059\u3002</p><h3><strong>\u65b0\u7740\u60c5\u5831</strong></h3><p>\u6700\u65b0\u306e\u53d6\u308a\u7d44\u307f\u60c5\u5831\u53d7\u53d6\u3092\u3054\u5e0c\u671b\u306e\u65b9\u306f\u3001\u3053\u3061\u3089\u304b\u3089<a href=\"https://leadelimination.us17.list-manage.com/subscribe?u=5ee1422684878e0002b009a61&amp;id=b0097e693a\"><u>\u30cb\u30e5\u30fc\u30b9\u30ec\u30bf\u30fc</u></a>\u3078\u3054\u767b\u9332\u4e0b\u3055\u3044\u3002\u307e\u305f<a href=\"https://www.facebook.com/LeadElimination\"><u>Facebook</u></a>\u3001<a href=\"https://twitter.com/LeadElimination\"><u>Twitter</u></a>\u3001<a href=\"https://www.linkedin.com/company/lead-exposure-elimination-project/\"><u>Linkedin</u></a>\u3082\u30d5\u30a9\u30ed\u30fc\u4e0b\u3055\u3044\u3002</p><h3><strong>\u30d5\u30a3\u30fc\u30c9\u30d0\u30c3\u30af</strong></h3><p>\u7279\u306b\u521d\u671f\u6bb5\u968e\u306e\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306b\u304a\u3044\u3066\u3001\u7686\u3055\u307e\u304b\u3089\u306e\u3054\u610f\u898b\u3084\u3054\u63d0\u6848\u306f\u5927\u5909\u8cb4\u91cd\u3067\u3059\u3002\u3054\u8cea\u554f\u3084\u3054\u610f\u898b\u306f\u3001<a href=\"https://leadelimination.org/contact/\"><u>\u304a\u554f\u3044\u5408\u308f\u305b\u30d5\u30a9\u30fc\u30e0</u></a>\u3088\u308a\u3054\u9023\u7d61\u304f\u3060\u3055\u3044\u3002</p><p>LEEP\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306f\u3001<a href=\"http://www.charityentrepreneurship.com/\"><u>Effective Altruism</u></a>\u306e\u7d44\u7e54\u3067\u3042\u308bCharity Entrepreneurship\u4e0b\u306b\u8a2d\u7f6e\u3055\u308c\u30016\u4e07\u30c9\u30eb\u306e\u6d3b\u52d5\u8cc7\u91d1\u3092\u63d0\u4f9b\u3044\u305f\u3060\u304d\u307e\u3057\u305f\u3002\u73fe\u5728\u306e\u30c1\u30fc\u30e0\u30e1\u30f3\u30d0\u30fc\u306f\u3001\u5171\u540c\u5275\u696d\u8005\u306eJack Rafferty\u3068Lucia Coulter\u306e2\u540d\u3067\u3059\u3002</p><h2>&nbsp;</h2><h2><strong>\u51fa\u5178</strong></h2><ol><li>UNEP 2019:<a href=\"https://www.unenvironment.org/resources/report/2019-update-global-status-legal-limits-lead-paint\">&nbsp;<u>Update on the global status of legal limits on lead in paint. September 2019</u></a></li><li>Lamphear et al. 2oo5:<a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1257652/\">&nbsp;<u>Low-level environmental lead exposure and children\u2019s intellectual function: an international pooled analysis</u></a></li><li>Reuben et al. 2019:<a href=\"https://jamanetwork.com/journals/jamapsychiatry/article-abstract/2720691\">&nbsp;<u>Association of childhood lead exposure with adult personality traits and lifelong mental health</u></a></li><li>Attina &amp; Trasande 2013:<a href=\"https://ehp.niehs.nih.gov/doi/full/10.1289/ehp.1206424\">&nbsp;<u>Economic costs of childhood lead exposure in low-and middle-income countries</u></a></li><li>Gould 2009:<a href=\"https://ehp.niehs.nih.gov/doi/full/10.1289/ehp.0800408\">&nbsp;<u>Childhood lead poisoning: Conservative estimates of the social and economic benefits of lead hazard control</u></a></li><li>Chowdhury et al. 2018:<a href=\"https://pubmed.ncbi.nlm.nih.gov/30158148/\">&nbsp;<u>Environmental toxic metal contaminants and risk of cardiovascular disease: systematic review and meta-analysis</u></a></li><li>Lanphear et al. 2018:<a href=\"https://pubmed.ncbi.nlm.nih.gov/29544878/\">&nbsp;<u>Low-level lead exposure and mortality in US adults: a population-based cohort study</u></a></li><li>UNICEF 2020:<a href=\"https://www.unicef.org/reports/toxic-truth-childrens-exposure-to-lead-pollution-2020\">&nbsp;<u>The Toxic Truth</u></a></li><li>IHME 2017:<a href=\"https://vizhub.healthdata.org/gbd-compare/\">&nbsp;<u>Global Burden of Disease Study</u></a></li><li>WHO \u200e2020:<a href=\"https://www.who.int/publications/i/item/9789240005143\">&nbsp;<u>Global elimination of lead paint: why and how countries should take action: technical brief</u></a></li><li>Charity Entrepreneurship 2020:<a href=\"https://www.charityentrepreneurship.com/uploads/1/0/7/2/10726656/leadpaintregulation.pdf\">&nbsp;<u>Lead Paint Regulation</u></a></li><li>Baumgartner et al. 2009: Lobbying and Policy Change: Who wins, who loses, and why?</li></ol>", "user": {"username": "EA Japan"}}, {"_id": "Ber8nHACqN8swESsN", "title": "Effective Altruism in New York City: Introduction", "postedAt": "2023-07-25T19:46:59.487Z", "htmlBody": "<p><i>This post was co-written by the </i><a href=\"https://www.effectivealtruism.nyc/our-team\"><i>EA NYC team</i></a><i>: Arthur Malone, Alex Rahl-Kaplan, Megan Nelson, and Rocky Schwartz</i></p><p><strong>This post is part of the new Forum Sequence </strong><a href=\"https://forum.effectivealtruism.org/s/8vuL8ZvDtXMiyPqai\"><strong>EA in NYC</strong></a><strong>. Our central thesis is that NYC is already home to a flourishing EA community and we recommend that the EA community as a whole invests more into leveraging the city's unique impact potential. We explore how we came to believe this below and in subsequent posts.</strong></p><h1>Introduction</h1><p>In May of this year,&nbsp;<a href=\"https://www.effectivealtruism.nyc/\"><u>EA NYC</u></a> turned ten, and in August New York will host its first official EA conference,&nbsp;<a href=\"https://www.effectivealtruism.org/ea-global/events/eagxnyc\"><u>EAGxNYC</u></a> (applications still open until July 31)! Inspired by these milestones, we\u2019re sharing a series of posts detailing our community, our approach to community building, and our larger goals.</p><p>We've found that EAs outside of NYC often know surprisingly little about our community here. This contrasts the EA Survey&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/zMKxgK4wbSywnkFrn/ea-survey-2020-geography#:~:text=The%20most%20commonly%20reported%20cities%20in%20which%20EAs%20live%20are%20the%20San%20Francisco%20Bay%20Area%20(6.3%25)%2C%20London%20(5.6%25)%2C%20and%20New%20York%20City%20(4.9%25).\"><u>consistently</u>&nbsp;</a><a href=\"https://forum.effectivealtruism.org/posts/sAgExeaxCNmFSmrJT/ea-survey-2022-geography#:~:text=This%20year%2C%20London%20was%20the%20city%20with%20the%20most%20respondents%20(7.3%25)%2C%20overtaking%20the%20SF%20Bay%20Area%20(6.2%25)%2C%20followed%20by%20NYC%20(4.5%25)%20and%20DC%20(3.8%25).\"><u>finding</u></a> that NYC is the city with the third-highest number of respondents. And while some in the community joke we should keep EA NYC low-profile, lest we get invaded by EAs from other locales, NYC itself is&nbsp;<i>far</i> from low-profile by its very nature. And we actually really love newcomers! So we\u2019d like to spotlight the incredible work being done here and hopefully provide some context and guidance for other local groups as they grow.&nbsp;<br><br>The first post in <a href=\"https://forum.effectivealtruism.org/s/8vuL8ZvDtXMiyPqai\">this new sequence</a> is about our community health infrastructure and can be&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/GPDmbGxrtsNCWaB49/ea-nyc-s-community-health-infrastructure\"><u>found here</u></a>. And, if this series inspires you to check out our little town, we\u2019ve also just published a&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/Yq6yKgBtaMgkgyetm/an-ea-s-guide-to-visiting-new-york-city\"><u>guide to visiting NYC</u></a>.</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ber8nHACqN8swESsN/y8kukrdax9wdjmzyiex4\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ber8nHACqN8swESsN/cbhf0hhabkmontpfjpzu 400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ber8nHACqN8swESsN/crbhrfa96dzg5sc8nawj 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ber8nHACqN8swESsN/sjvwtuorstcxwigagkgv 1200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ber8nHACqN8swESsN/uarmhudhaaxrhkbxvqsm 1600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ber8nHACqN8swESsN/ytxvxvdd46ojustw5sey 2000w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ber8nHACqN8swESsN/gzidyuz32pga5yfhtag6 2400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ber8nHACqN8swESsN/dhsq8mlminf4vcxvw2si 2800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ber8nHACqN8swESsN/dlhcwv9kluzrmqgp8rr6 3200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ber8nHACqN8swESsN/trqvcaypyxijejrkrvhi 3600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ber8nHACqN8swESsN/kpxzqto66hglcj5mjt2h 4000w\"><figcaption>A group photo from EA NYC's 10th birthday and Annual Picnic!</figcaption></figure><p>In future posts, we intend to cover questions including:</p><ul><li>What makes a location an EA hub and is NYC one?</li><li>What EA-related work is underway in NYC?</li><li>What is EA NYC's current strategy and programming?</li></ul><p>We also welcome feedback on topics you would find valuable for us to cover.</p><p>To kick things off, let's first take a stab at answering a foundational question:</p><h2>What makes NYC important to EA?</h2><p>New York City has an overwhelming presence in relevant EA domains. The statistics below only gesture toward the available resources. In NYC, no one industry dominates; and as we'll show in later posts, in the EA NYC community, no one cause area dominates. Instead, NYC is a massive, dynamic metropolis positioned for high-impact initiatives that cross cause areas, industries, and academic disciplines.</p><ul><li><strong>HNWI/Finance:</strong> NYC has the&nbsp;<a href=\"https://www.barrons.com/articles/new-york-boasts-the-worlds-most-millionaires-01663100972\"><u>most millionaire residents in the world</u></a>, and among the highest number of billionaires. Wall Street concentrates an incredible volume of capital and efficiency-oriented individuals. Attracting donors from these pools seems like one of the most plausible paths to reducing EA's funding constraints, and attracting new talent. (It is no coincidence that GiveWell started in a hedge fund!)&nbsp;</li><li><a href=\"https://philanthropynewyork.org/sites/default/files/resources/History%20of%20Philanthropy.pdf\"><strong><u>Philanthropy</u></strong></a><strong>:</strong> NYC has ~2.7% of the US population, but between 14-20% of the largest grantmaking organizations are based here (20% by market value, 14% by total giving). Helping direct philanthropic giving to more impactful efforts is a core pillar of effective altruism, and we believe it can be accelerated by focusing deliberate attention on NYC\u2019s concentration of foundations.</li><li><strong>Universities:</strong> The NYC metro area is home to ~80-116 institutions of higher education. This leads to the most faculty and enrolled students in one area (600k to 1M+). The ranges are broad as there aren\u2019t standard definitions of universities&nbsp;<i>or</i> \u201cmetro areas,\u201d but by most reasonable metrics, NYC has the highest enrollment in at least the US, and possibly the world. The EA community has demonstrated impressive success via outreach on university campuses, but many NYC universities have not yet established an EA presence.</li><li><strong>Activism: </strong>NYC has a longstanding culture of activism that predates and is comparable to that of DC and the Bay Area. This represents a reservoir of potential talent and a path to impact via directing activists toward more effective interventions.</li><li><strong>Legacy journalism:</strong> NYC is the center of US journalism, with the&nbsp;<a href=\"https://www.worldatlas.com/what-makes-new-york-the-world-s-media-capital.html#:~:text=New%20York%E2%80%99s%20influence,releasing%20content%20internationally.\"><u>largest media companies</u></a> all either based here or with&nbsp;<a href=\"https://www.statista.com/chart/3299/new-york-is-the-worlds-media-capital/\"><u>significant presence here</u></a>. No matter your position on optics and EA branding, the practical reality is that media coverage will influence all paths to significant impact, and EA can do a better job \u201cmeeting journalists where they\u2019re at\u201d (both conceptually and geographically).</li><li><strong>Technology:</strong><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefz9h11uu9ywr\"><sup><a href=\"#fnz9h11uu9ywr\">[1]</a></sup></span>&nbsp;While Silicon Valley in California is often seen as the epicenter of technology innovation, NYC has a growing tech scene, with some parts being referred to as \"Silicon Alley.\" Because of its diverse economy, New York is often not considered a tech hub (e.g. it places low on rankings of \u201ctech cities\u201d that use the proportion of total population who work in tech). Nevertheless, New York City has&nbsp;<a href=\"https://usatech-recruit.com/us-tech-hubs/\"><u>more tech workers than any other city, the state receives the second most VC funding after California</u></a>, and&nbsp;<a href=\"https://news.ycombinator.com/item?id=36038146\"><u>Manhattan just edged out SF for most early-stage startups</u></a>. New York City is consequently a high-priority target for recruiting skilled individuals for AI alignment work, people with resources for EtG, and others who can contribute to the movement.</li><li><strong>International Collaboration</strong><ul><li><strong>United Nations:</strong> The UN is a natural reason to center more EA efforts to impact US-international relations in NYC. Some EAs in the city already work in related areas (e.g. nuclear non-proliferation), and we believe that cause areas like Improving Institutional Decision Making and AI governance will increasingly benefit from connections with the UN and the community and infrastructure built around it. Of particular interest is the September 2024 UN Summit of the Future, a major opportunity for international longtermist governance.</li><li><strong>International Commerce:</strong> NYC is one of the world's major financial centers. It is home to the New York Stock Exchange (NYSE) and NASDAQ, two of the largest stock exchanges by market capitalization. Many Fortune 500 companies also have their headquarters in NYC, in industries as diverse as finance, media, advertising, technology, and fashion. This makes it a critical decision-making hub for these industries. NYC is also a significant player in international trade, with goods from around the world passing through its ports. The Port of New York and New Jersey is the busiest port on the East Coast of the United States, and one of the largest in the world. Economic interventions are crucial to address various EA causes, from AI governance to farmed animal welfare. Thus, New York City, with its economic significance, serves as an ideal hub for such initiatives.</li></ul></li></ul><p>In later posts that describe EA NYC\u2019s current strategy and programming, we will address how we are working to leverage these significant and unique resources. We will also detail a call to action for local EAs as well as the broader EA movement. We believe this small snapshot illustrates the untapped potential in New York City for EA impact, which requires more investment to fully utilize.<br><br>In our next post, we will discuss what makes for an EA Hub, how NYC holds up to some suggested standards, and why a deliberate focus on geographic areas could be useful to the EA movement.</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnz9h11uu9ywr\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefz9h11uu9ywr\">^</a></strong></sup></span><div class=\"footnote-content\"><p>We are not at all trying to overstate or claim that NYC \"does more tech\" than the Bay; by relevant metrics (e.g. total funding, number of established companies, perception among tech workers and by the general public) the Bay clearly dominates. Our linked statistics here are to demonstrate that despite the Bay's clear lead, NYC's tech ecosystem is also quite substantial and growing relative to other locations.</p></div></li></ol>", "user": {"username": "Rockwell Schwartz"}}, {"_id": "oGoP4LjSZAsYfcF3N", "title": "Animal Advocacy in the Age of AI", "postedAt": "2023-07-27T07:08:29.818Z", "htmlBody": "<p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/oGoP4LjSZAsYfcF3N/nozxlybqk4louwpuyt1z\"></p><p>This post calls on animal advocates to take seriously how the future will be transformed by AI. It lays out how technological revolutions of the past have enabled the industrial commodification of animals and how animal advocates of today should be:&nbsp;</p><ol><li>paying attention to how it might impact the lives of farmed animals&nbsp;</li><li>preparing for a future which will look radically different, where the world will increasingly be dominated by the behavior of thinking machines.&nbsp;</li><li>positioning ourselves to guide decisions about how AI will be applied to animals</li></ol><h1>Past Technological Revolutions</h1><p>Technological revolutions have always had dramatic effects on humanity\u2019s relationship to other animals. 100 years ago, factory farming didn\u2019t exist as a concept or a practice.&nbsp;</p><h2>Technology changes what\u2019s possible</h2><p>Technology has enabled&nbsp;<a href=\"https://www.sentienceinstitute.org/global-animal-farming-estimates\"><u>factory farming to become the predominant form</u></a> of animal agriculture worldwide:</p><ul><li><a href=\"https://en.wikipedia.org/wiki/Haber_process\"><u>Chemical fertilizers</u></a> have radically increased our ability to produce food, enabling large-scale animal agriculture (which is incredibly calorie inefficient). Only about 55% of crops world-wide are&nbsp;<a href=\"https://www.vox.com/2014/8/21/6053187/cropland-map-food-fuel-animal-feed\"><u>actually consumed by humans</u></a>, and in the United States, the majority of crops (67%) are used as animal feed for factory farms.&nbsp;</li><li>Factory farms use the majority of our antibiotics, and without them it would not be possible to keep animals in such close quarters and in such terrible conditions (without antibiotics many of the sores and open wounds that factory farmed animals sustain would be fatal).</li><li><a href=\"https://en.wikipedia.org/wiki/Pasteurization\"><u>Pasteurization</u></a> has enabled the global dairy industry as we know it to exist. Previously, dairy cows had to be kept in urban areas to prevent spoilage, and industrial scale milk production and distribution was not feasible.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefnbivcxwqa3i\"><sup><a href=\"#fnnbivcxwqa3i\">[1]</a></sup></span></li><li>Animal agriculture, like everything in the 21st century, is a part of a global supply chain. Without modern transportation infrastructure and logistics systems it would not be possible to distribute animal products to such a large population (and so cheaply).</li><li>Mechanization and economies of scale enable large companies to produce meat more cheaply, turning it from what was once a luxury product into a staple food for much of the industrialized world.&nbsp;</li></ul><p>When these drastic technological shifts happen, animals are at the mercy of the tide, subject to powerful social and technological forces they cannot control.<br>&nbsp;</p><p>Technological advances have also created positive opportunities to help animals:</p><ul><li>High-quality plant-based alternatives to animal products that fulfill the taste and texture appeals of animal products are widely available at cost parity&nbsp; (They may just not currently fulfill the same cultural or psychological appeals).</li><li>Dietary supplements like B12 are now both commonly available and affordable, enabling people to have nutritionally complete vegan diets.</li><li>Cultivated meat has advanced significantly and received clearance to be sold in the US this year.</li></ul><h2>Technology changes our society</h2><p>We live in a&nbsp;<a href=\"https://en.wikipedia.org/wiki/Sociotechnology\"><u>sociotechnical</u></a> world, where social systems (like culture, governments, or companies) interact with technological systems (like the internet, television, or financial technology) to move civilization forward. Modern society is composed of both human and machine parts. The average person spends 7 hours a day looking at screens connected to the internet and this number is growing over time and greater with younger generations. Everyone participates in this system, but only a few well-positioned humans/companies control the major forces behind how the technology will be packaged and introduced. Even then, they have very little control over the consequences after the technology is released. There are some technologies like TV and internet that are widely accessible, which can give a lot of power to those that understand how to wield them.</p><ul><li>TV enabled the milk industry to launch \u201cGot Milk,\u201d one of the most successful marketing campaigns in the US to lift sales in an industry that was becoming less relevant to consumers (There has been a <a href=\"https://sentientmedia.org/milk-ad-history/\">long history</a> of media campaigns to bolster milk consumption).</li><li>A media campaign sponsored by the US government <a href=\"https://www.bloomberg.com/news/articles/2014-10-06/bacon-why-americas-favorite-food-mania-happened#xj4y7vzkg\">deliberately engineered</a> the demand for bacon, making it a lasting <a href=\"https://en.wikipedia.org/wiki/Bacon_mania\">pop culture phenomenon and cultural icon</a>.</li><li>Social media &amp; online vlogs are often people\u2019s first interaction with animal rights.</li><li>High quality <a href=\"https://www.dominionmovement.com/\">documentaries</a> have made it possible for people to directly empathize with the experience of animals (even VR projects to <a href=\"https://ianimal360.com/\">experience a slaughter house from the inside</a>).</li></ul><p><br>What little control we humans have over the downstream effects of new technologies comes from our ability to understand how these forces work and how to navigate through their effects in a rapidly changing landscape. Our \u201cvalues\u201d are a product of the interaction within and between social and technological systems.&nbsp;</p><h1>A Counterfactual History</h1><p>Let's imagine an alternate world starting 100 years ago where there were people who both really cared about animals and were skilled in advocating for them around. They could have positioned themselves to be around when decisions were being made about how industries would leverage new technologies to make profit.&nbsp;<br><br>If there was just a few people at the right place/time/context who said, \u201cmaybe using animals for protein isn\u2019t a good idea. Maybe it will use up too much energy. Maybe people in the future won\u2019t like that animals are in cages. Maybe we can have a higher profit margin by upcharging soy protein instead,\u201d then perhaps history could have turned out differently for animals. Marketing executives might have decided to make \u201cGot Tofu\u201d ads or laws could have been passed to protect farmed animals before lobbyists got too powerful or farmers could have decided to unionize once they saw they were being exploited.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefayxsr5mcwx\"><sup><a href=\"#fnayxsr5mcwx\">[2]</a></sup></span>&nbsp;It can feel like history moves in a straight line, but the path we took has so much to do with very specific decisions.&nbsp;<br><br>It can be hard to imagine a world other than the one we see around us, but 100 years ago, none of this was written nor inevitable. We are now at the start of a new technological revolution, and the future remains undecided.&nbsp;<br>&nbsp;</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/oGoP4LjSZAsYfcF3N/sxnamwx1tmryw6asiyek\"><figcaption>A single advocate with a radical idea and the right connections at the right time and place could have changed the trajectory of history and made many of the campaigns we are fighting today unnecessary.</figcaption></figure><h1>AI is the Next Technological Revolution</h1><p>As with previous technological revolutions, AI will change what we can do and how we think. It marks the beginning of a transition to a world which will increasingly depend more on the behavior of machines, not humans, especially as AI rivals or eventually surpasses human abilities.&nbsp;</p><p><strong><u>Corporations are already playing the AI game:</u></strong></p><p>The animal agriculture industry is going from wanting to know very little about what is happening behind closed doors to wanting to know everything because in the game of AI, data is king.</p><ol><li><a href=\"https://www.merck-animal-health.com/animal-health-intelligence/\">Merck</a>&nbsp;Global company based in US with a department for Animal Health Intelligence that has multiple products that incorporate AI for monitoring systems in livestock farming, aquaculture, and pets.</li><li><a href=\"https://www.connecterra.io/\">Connecterra</a>&nbsp;Dutch company with global reach and many corporate partnerships that developed a collar mounted device for dairy cows for monitoring animal health and methane emissions.</li><li><a href=\"https://www.vencomaticgroup.com/\">Vencomatic Group</a>&nbsp;Global company based in The Netherlands with tech for autonomous broiler chicken housing and egg handling that has some AI integration</li><li><a href=\"https://www.ever.ag/dairy/software-solutions/cainthus/\">Cainthus</a>&nbsp;US company using AI video monitoring system for managing dairy herds</li></ol><p>&nbsp;<strong><u>Possible Directions to Help Animals Using AI:</u></strong></p><p>In the face of rapidly advancing AI capabilities, it makes sense to look for ways that we might be able to empower animal advocates to take advantage of the changing world, and use these new advances to augment our abilities. To protect animals from again becoming the victims of technological revolution, we need to get ahead of the curve.</p><ul><li>Advocates could use GPT and other AI tools to augment their existing work (imagine advocacy without internet access).</li><li>Just as AI, like ChatGPT, has learned to intepret human languages, it has the potential to help decode&nbsp;<a href=\"https://www.earthspecies.org/\"><u>animal language</u></a>, which can finally give animals their own voice to advocate for themselves.</li><li>Alternative protein companies could lean even more into AI to accelerate development of their research.</li><li>Philanthropic or impact investing groups could turn their sights into innovative AI startups/nonprofits that help animals.</li><li>Attention could be called to <a href=\"https://arxiv.org/pdf/2202.10848.pdf\">speciesist bias</a> (see below) in <a href=\"https://arxiv.org/abs/2203.05140\">language models</a> so AI developers are aware of this potential value lock-in.&nbsp;</li></ul><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/oGoP4LjSZAsYfcF3N/xexjxyfkrob65b9gtsze\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/oGoP4LjSZAsYfcF3N/bijofsilu4dgfdsvqaxs 220w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/oGoP4LjSZAsYfcF3N/cdjcf8znkma4yvtqlrlm 440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/oGoP4LjSZAsYfcF3N/f4vcoaehnejoeuba8fd5 660w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/oGoP4LjSZAsYfcF3N/yhd0232dbavvubzrr4c8 880w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/oGoP4LjSZAsYfcF3N/supexuezos2b49hx1ixx 1100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/oGoP4LjSZAsYfcF3N/gu1dvwrgdjwaxkhgeuw1 1320w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/oGoP4LjSZAsYfcF3N/hwmjlw9hptocplck0lbs 1540w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/oGoP4LjSZAsYfcF3N/abzpiyboq5ch1gauek6m 1760w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/oGoP4LjSZAsYfcF3N/cw7cdoke1ghmzcebept0 1980w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/oGoP4LjSZAsYfcF3N/v6arjfompvvog7qnrh82 2165w\"><figcaption>Humans have built AI in our own image with our own biases</figcaption></figure><p>See more examples of inconsistent morality around animals in large language models in this <a href=\"https://twitter.com/Lewis_Bollard/status/1683938947695796224?s=20\">tweet from Lewis Bollard</a>.&nbsp;</p><h1>AI and the Future for Animals</h1><p><u>If animal advocates are really serious about fighting for a kinder future for everyone, they cannot afford to ignore what is happening with AI</u>. The automation of thought is going to transform everything about our society. As with technological revolutions of the past, there\u2019s no reason to expect that this ends well for animals by default. We are already seeing ways that the longer-term future might be strongly affected by how AI is developed and deployed.</p><p>Unfortunately, there exists a&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/35bfnGmsyrZkEnkLJ/steering-ai-to-care-for-animals-and-soon\"><u>strong divide</u></a> between people who believe that AI will radically transform the future and come to determine most of what happens in the world, and people who prioritize the wellbeing of animals. Because there is so little focus from the AI community on how their work will affect animals, it can easily feel like worries about AI and worries about animals are at odds, fighting for people\u2019s attention and for philanthropic funding, but in reality they are deeply intertwined.</p><p>The AI revolution could also create the opportunity for humans to radically reconsider their relationship with other animals. When Darwin published his works, he forced many to realize that humans, rather than being inherently special, are instead one species among many, born from the same process of natural selection. Similarly, the emergence of powerful AI could help us realize that our self-defining trait, superior intelligence, might not be as unique as we once thought.&nbsp;</p><figure class=\"image image_resized\" style=\"width:52.23%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/oGoP4LjSZAsYfcF3N/nupebyvnqjdy5oglzhkk\"><figcaption>AI Learns from Us</figcaption></figure><p>Many of us already know that being worthy of moral consideration is not derived from the ability to intellectually dominate the world around us, but rather from the ability to experience pain, pleasure, fear, and fulfillment. And in this respect, AI presents the chance for humans to notice that the moral divide we\u2019ve created between ourselves and other species has always been an artificial one, and perhaps not one worth keeping around.</p><p>The next 100 years could go in a more positive or more negative trajectory for animals. Historically, the default has been negative. This is all the more reason for animal advocates to pay attention to AI now.</p><h1>Get Involved</h1><ul><li>Join the #ai-discussions channel on the&nbsp;<a href=\"https://imaa.me/3rP7GeV\"><u>Impactful Animal Advocacy (IAA) slack</u></a> to connect and collaborate</li><li>Learn more through IAA\u2019s&nbsp;<a href=\"https://imaa.me/43RJfLf\"><u>resource guide</u></a> for AI and animals&nbsp;</li><li>Try out IAA\u2019s&nbsp;<a href=\"https://imaa.me/3rR8IYc\"><u>prompt library for animal advocates</u></a> to augment existing advocacy work</li><li>Follow along for part 2 where we will discuss using AI to make ourselves more mentally capable at our work</li></ul><p><strong>Many thanks to the following people for their generous feedback and suggestions:&nbsp;</strong><br><i>Ana Bradley, Kyle Behrend, G\u00fcney Ulas Turk, Helene Kortschak, Sofia Balderson, and Cameron King</i></p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnnbivcxwqa3i\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefnbivcxwqa3i\">^</a></strong></sup></span><div class=\"footnote-content\"><p>In fact, milk spoilage was a major public health problem contributing to <a href=\"https://www.sciencedirect.com/science/article/pii/S0362028X22087610\">infant mortality</a>.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnayxsr5mcwx\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefayxsr5mcwx\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Mobilizing farmers or slaughterhouse workers to fight for better working conditions and pay could have significantly slowed the rise of factory farming, and made meat more expensive. In particular, <a href=\"https://awionline.org/awi-quarterly/summer-2022/current-state-animal-farming-us\">just 4 companies</a> now control the majority of animal agriculture in the US, and preventing this centralization could have helped slow the development of powerful economies of scale which keep the price so low.&nbsp;</p></div></li></ol>", "user": {"username": "Constance Li"}}, {"_id": "pd6m3LDYZ7tjc6WoB", "title": "2022 Effective Animal Advocacy Forum Survey: Results and analysis", "postedAt": "2023-07-25T00:31:49.566Z", "htmlBody": "<h1>Introduction</h1><p>In September 2022, the Effective Animal Advocacy (EAA) Coordination Forum (now titled the Animal Advocacy Strategy Forum) was held with the purpose of bringing together key decision-makers in the animal advocacy community to connect, coordinate, and strategize. The attendees represented approximately 20 key groups in the effective animal advocacy space.</p><p>At the end of the forum, 25 participants filled out a survey that sought to better understand the future needs of effective animal advocacy groups and the perceptions of animal advocates about the most important areas to focus on in the future. This report analyzes the results of that survey.</p><h1>Key Takeaways</h1><p>On average, respondents to the EAA Survey believe that:</p><ul><li>The largest share (29%) of effective animal advocacy resources should be spent in Asia and the Pacific, followed by Western Europe, the U.S., Canada, Australia, and New Zealand (26%).</li><li>Farmed fish and farmed invertebrates received the highest allocations of resources among respondents (16.5% and 17.1%, respectively), shortly followed by egg-laying hens and broiler chickens (12.8% and 13.1%, respectively).</li><li>The plurality of resources should be spent targeting businesses (34%), followed by government institutions (28%).</li><li>There\u2019s about a 60% chance that an area that should receive over 20% of the EAA funding currently receives less than 5% of it.</li></ul><p>In addition, a plurality of respondents believes that:</p><ul><li>EAA needs more people who are experts on the developing world/populous-yet-neglected countries (17/25 votes), government and policy (16/25), and/or figuring out what matters most and setting priorities (13/25).</li><li>Their EAA organization is sometimes (9/25 votes) or often (10/25) funding-constrained and it is sometimes hard (11/25) to find outstanding candidates for roles.</li></ul><p>When asked about issues facing the effective animal advocacy movement:</p><ul><li>The lack of a strong evidence base (11/25 votes) and ability to appeal to the people most able to contribute to EAA cause areas (10/25) were the most commonly cited problems for EAA.</li><li>Epistemic uncertainty regarding interventions (10/25 votes) and a lack of influence over the public, donors, and others with power (10/25) were generally cited as the most pressing problems in EAA.</li></ul><p><a href=\"https://rethinkpriorities.org/publications/2022-effective-animal-advocacy-forum-survey\"><strong><u>Click here</u></strong></a><strong> for the full version of this report on the Rethink Priorities website.</strong></p><h1>Acknowledgments</h1><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/c5m8vAxpJgJJ2XGFu/yyzoqjvtmgntnoqgfhww\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/c5m8vAxpJgJJ2XGFu/f1evby7siwx3pib9tlmp 100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/c5m8vAxpJgJJ2XGFu/rz0kwaujenjz6flg4wrr 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/c5m8vAxpJgJJ2XGFu/qbrd79nta2szivkkfywp 500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/c5m8vAxpJgJJ2XGFu/d8sqte1pjsxbonyppcrc 750w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/4SFgv9iSaBWikriYj/ebtlpudxvmlsflkl6uf9 1000w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/c5m8vAxpJgJJ2XGFu/m3pjks0ctmo8stxfb3jl 1500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/c5m8vAxpJgJJ2XGFu/vzp21jxqrntzmi739hgq 2500w\"></p><p>This report is a project of <a href=\"https://rethinkpriorities.org/\">Rethink Priorities</a>\u2013a think tank dedicated to informing decisions made by high-impact organizations and funders across various cause areas. It was written by Laura Duffy. Thanks to William McAuliffe for helpful feedback and to Adam Papineau for copy-editing.</p><p>If you are interested in RP\u2019s work, please visit our <a href=\"https://www.rethinkpriorities.org/research\">research database</a> and subscribe to our <a href=\"https://www.rethinkpriorities.org/newsletter\">newsletter</a>.</p>", "user": {"username": "Rachel"}}, {"_id": "c5m8vAxpJgJJ2XGFu", "title": "An overview of WHO Prequalification: Process, usage, and potential improvements", "postedAt": "2023-07-25T00:04:16.566Z", "htmlBody": "<h1>Editorial note</h1><p>This report is a \u201cshallow\u201d investigation, as described <a href=\"https://perma.cc/D85A-EKDG\">here</a>, and was commissioned by Open Philanthropy and produced by Rethink Priorities from July to August 2022. We updated and revised this report for publication. Open Philanthropy does not necessarily endorse our conclusions, nor do the organizations represented by those who were interviewed.</p><p>The primary focus of the report is to provide a review of WHO Prequalification (WHO-PQ). We focused mostly on how it works and how it\u2019s funded, as well as how it came about and how it could be improved for a greater global health impact. We reviewed the scientific and gray literature and spoke to four experts.</p><p>We don\u2019t intend this report to be Rethink Priorities\u2019 final word on WHO-PQ, and we have tried to flag major sources of uncertainty in the report. We hope this report galvanizes a productive conversation within the effective altruism community about the role of WHO-PQ in improving global health. We are open to revising our views as more information is uncovered.</p><h1>Key takeaways</h1><ul><li>WHO-PQ evaluates applications from manufacturers to determine whether their products meet its <strong>standards of quality, safety, and efficacy</strong>. If so, then the product is \u201clisted,\u201d i.e., added to the relevant <strong>prequalified list</strong>. These lists are <strong>publicly available</strong>, and are used by some countries to inform their own national authorization of products; the lists are also used as criteria for tendering and procurement. [<a href=\"https://rethinkpriorities.org/publications/an-overview-of-who-prequalification-process-usage-and-potential-improvements#who-pq-is-organized-into-four-product-streams-and-products-go-through-a-six-stage-process-to-be-prequalified\">more</a>]</li><li>There are four product streams within WHO-PQ: <strong>vaccines, medicines, diagnostics, and vector control</strong>. There is also a cross-cutting <strong>Inspection Services</strong> team. [<a href=\"https://rethinkpriorities.org/publications/an-overview-of-who-prequalification-process-usage-and-potential-improvements#there-are-four-product-streams\">more</a>]</li><li><strong>WHO program areas define which specific products fall within WHO-PQ\u2019s scope</strong>. Manufacturers can only submit applications for these products. WHO-PQ\u2019s assessment consists of both a <strong>desk audit and site inspection</strong>. After prequalification, <strong>products can be delisted</strong>. [<a href=\"https://rethinkpriorities.org/publications/an-overview-of-who-prequalification-process-usage-and-potential-improvements#at-the-simplest-level-the-streams-share-a-similar-process\">more</a>]</li><li>The program was originally created in 1987 to inform UNICEF\u2019s procurement of vaccines for immunization programs. It then expanded to medicines in 2001, and diagnostics in 2010. Vector control was added in 2017. [<a href=\"https://rethinkpriorities.org/publications/an-overview-of-who-prequalification-process-usage-and-potential-improvements#who-pq-was-initially-created-in-1987-for-vaccines-and-has-extended-its-scope-over-time\">more</a>]</li><li>WHO-PQ\u2019s estimated <strong>total budget is $30 million-$40 million per year (75% confidence)</strong>. An estimated breakdown of the major funding streams is <strong>~50% from Unitaid</strong> (focused on medicines and diagnostics for TB, malaria, and HIV/AIDS), <strong>~20% from the Bill and Melinda Gates Foundation (BMGF)</strong>, and approximately <strong>30% covered by fees </strong>paid by manufacturers. [<a href=\"https://rethinkpriorities.org/publications/an-overview-of-who-prequalification-process-usage-and-potential-improvements#we-estimate-that-the-annual-who-pq-budget-is-$30-million-to-$40-million-75%-confidence\">more</a>]</li><li>It is <strong>unclear whether WHO-PQ\u2019s fees negatively impact access</strong>, as they may deter manufacturers from pursuing prequalification, but we were unable to assess whether this is the case. [<a href=\"https://rethinkpriorities.org/publications/an-overview-of-who-prequalification-process-usage-and-potential-improvements#it%E2%80%99s-unclear-whether-who-pq-charging-fees-is-ultimately-good-for-access\">more</a>]</li><li>Prequalified products <strong>must also be authorized by the national regulatory authority (NRA) in each country</strong> where they will be used. <strong>Two years</strong> is a conservative estimate of how long this process takes. [<a href=\"https://rethinkpriorities.org/publications/an-overview-of-who-prequalification-process-usage-and-potential-improvements#prequalified-products-almost-always-also-need-to-be-registered-by-national-regulatory-authorities\">more</a>]</li><li>Prequalification most directly influences country registration via the <strong>Collaborative Registration Procedure (CRP)</strong>. This effort reduces the timeline for country registration to a <strong>median of 90 days</strong>, versus two years. However, its implementation is currently limited, primarily to medicines. [<a href=\"https://rethinkpriorities.org/publications/an-overview-of-who-prequalification-process-usage-and-potential-improvements#who-pqs-collaborative-registration-procedure-aims-to-speed-up-country\">more</a>]</li><li>Products covered by WHO-PQ are a <strong>small subset (~10%) of the products on the Essential Medicines List (EML)</strong>. Future expansions of WHO-PQ\u2019s scope will be based on the EML or perceived priority needs (e.g., COVID products). [<a href=\"https://rethinkpriorities.org/publications/an-overview-of-who-prequalification-process-usage-and-potential-improvements#who-pq-covers-a-small-subset-of-the-who-eml\">more</a>]</li><li>Most <strong>international procurement agencies use the prequalified lists as a key requirement </strong>of their tenders for product categories within PQ\u2019s scope. [<a href=\"https://rethinkpriorities.org/publications/an-overview-of-who-prequalification-process-usage-and-potential-improvements#major-procurement-agencies-use-who-pq-for-quality-assurance\">more</a>]</li><li>Our initial thinking explores <strong>four potential ways that better resourcing could have impact </strong>[<a href=\"https://rethinkpriorities.org/publications/an-overview-of-who-prequalification-process-usage-and-potential-improvements#extra-funding-might-increase-the-effectiveness-of-who-pq-in-a-number-of-ways\">more</a>]:<ul><li>by causing WHO-PQ to extend to more products or new product streams: we estimate that current scope only covers up to 48% of global DALYs, leaving room for expansion, but understand that a WHO headcount freeze may be blocking this action.</li><li>by speeding up PQ and country registration processes: we outline efforts that could help, such as increased regionalization or use of abridged assessments.</li><li>by increasing the number of applications to WHO-PQ: we briefly explore three ways that funding (rather than fees) could support more applications.</li><li>by improving the quality of products that have been prequalified.</li></ul></li></ul><p><a href=\"https://rethinkpriorities.org/publications/an-overview-of-who-prequalification-process-usage-and-potential-improvements\"><strong><u>Click here</u></strong></a><strong> for the full version of this report on the Rethink Priorities website.</strong></p><h1>Contributions and acknowledgments</h1><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/c5m8vAxpJgJJ2XGFu/yyzoqjvtmgntnoqgfhww\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/c5m8vAxpJgJJ2XGFu/f1evby7siwx3pib9tlmp 100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/c5m8vAxpJgJJ2XGFu/rz0kwaujenjz6flg4wrr 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/c5m8vAxpJgJJ2XGFu/qbrd79nta2szivkkfywp 500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/c5m8vAxpJgJJ2XGFu/d8sqte1pjsxbonyppcrc 750w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/4SFgv9iSaBWikriYj/ebtlpudxvmlsflkl6uf9 1000w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/c5m8vAxpJgJJ2XGFu/m3pjks0ctmo8stxfb3jl 1500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/c5m8vAxpJgJJ2XGFu/vzp21jxqrntzmi739hgq 2500w\"></p><p>Aisling Leow researched and wrote this report. James Hu assisted with the DALYs exercise, and edited the client-facing version to transform it into a public-facing report. Tom Hird supervised and reviewed the report. Thanks to Jenny Kudymowa, Melanie Basnak and Marcus A. Davis for helpful comments on drafts, and Adam Papineau for copyediting. Further thanks to Alex Bowles (Open Philanthropy), Christian Stillson (Clinton Health Access Initiative), Murray Lumpkin (Bill and Melinda Gates Foundation), and a senior health systems consultant in Kenya (who preferred not to be named) for taking the time to speak with us. Open Philanthropy provided funding for this project, but it does not necessarily endorse our conclusions.</p><p>If you are interested in Rethink Priorities' work, please consider subscribing to <a href=\"https://www.rethinkpriorities.org/newsletter\">our newsletter</a>. You can explore our completed public work <a href=\"https://www.rethinkpriorities.org/research\">here</a>.</p>", "user": {"username": "Rachel"}}, {"_id": "bb47TA7KyytJi3bGy", "title": "A New Resource for Effective Volunteerism & Activism in Minutes", "postedAt": "2023-07-24T17:38:31.691Z", "htmlBody": "<p>I collected the most effective volunteerism/activism opportunities (actions) I could find and built a website called<strong>&nbsp;</strong><a href=\"https://www.doinggoodnow.org\"><strong>Doing Good Now</strong></a><strong>, a one-stop shop for doing good, aiming to help people maximize their positive impact in minimized time.&nbsp;</strong></p><p>I think Effective Altruism's focus on philanthropy and careers is missing out on the room in people's free time for making a positive impact, even if that free time is constrained to only a couple of minutes.</p><p>I created Doing Good Now after learning about the Humane League's&nbsp;<a href=\"https://action.thehumaneleague.org/signin\">Fast Action Network</a>&nbsp;(FAN), which makes animal advocacy effortless.&nbsp;<strong>It shocked me how much impact people can have in a minimal amount of time IF they are properly mobilized;</strong>&nbsp;the Humane League's campaigns often receive responses from the target, earning it a spot among Animal Charity Evaluators'&nbsp;<a href=\"https://animalcharityevaluators.org/donation-advice/recommended-charities/\">recommended charities</a>.</p><p>Moreover,<strong>&nbsp;think about all of the volunteer hours people altruistically spend on relatively low-impact ventures</strong>&nbsp;and how much more good they could achieve if their time were better optimized.</p><p>For example, think of all the volunteers handing water bottles to marathon runners and contrast them with the protesters at the Sunrise Movement, who are often credited as a serious cause of the Biden administration's landmark climate legislation.</p><p>Doing Good Now's offerings include recommendations for Animal Welfare, Global Health &amp; Development, and Climate Change. It also aims to remedy EA's lack of political action, which is a problem because legislative change can yield a substantial impact. Doing Good Now includes these actions alongside charitable funds and newsletters. While Giving What We Can already offers a selection of highly-effective charitable funds, my research indicates a meaningful disparity in effectiveness between some of their recommendations. Hence, I found it worth providing a further distilled list.</p>", "user": {"username": "NicholasNicholas"}}, {"_id": "6sykvCXRC5rjgtoQt", "title": "The Productivity Fallacy", "postedAt": "2023-07-24T17:34:38.090Z", "htmlBody": "<p>When I find myself saying the same thing multiple times, it's time to write it up in an article.</p><p>Recently, in my coaching sessions primarily with EA clients, I\u2019ve found myself giving the same advice multiple times \u2013 cut down on what you\u2019re doing, spend time on yourself, and try to be unproductive for short periods of time.&nbsp;</p><p>The problem is that people want to work at their maximum capacity in order to be the most impactful. And that is the productivity fallacy. So let\u2019s take a look at what happens when you are constantly working at full capacity.</p><p>To start with, I'm going to use the analogy of a computer since most of us are pretty familiar with the basic mechanics of how it works. When a computer is going slowly, there are a few basic troubleshooting steps:</p><ol><li><strong>Check your computer\u2019s resources</strong></li></ol><p>Your computer only has a limited amount of resources to apply to the tasks set to it. When it exceeds hardware limitations, it will not be able to perform the required functions. Even worse, when it\u2019s exceeding its resource availability (running at &gt;80%) for an extended period of time, it can have unintended and negative consequences such as <strong>shortened lifespan</strong>, <strong>slower performance</strong>, and <strong>software errors.</strong></p><p>&nbsp;</p><p>I don\u2019t think anyone would argue with that \u2013 that\u2019s pretty much basic knowledge.</p><p>&nbsp;</p><p>So let\u2019s apply that to you and productivity:</p><p>We only have a limited amount of energy. You can definitely argue that it\u2019s a design flaw with humans. When we exceed that amount of energy without replenishing it properly, you start running at \u201cmax capacity\u201d. When you\u2019re running at max capacity (being highly productive and efficient with your time without the restorative components to balance it), there are 3 big problems you\u2019ll encounter:</p><ol><li>You\u2019re at a much greater risk of burnout, getting sick, and harming your long-term ability to be impactful. The stress on your system has damaging consequences for both your physical and mental health, and they\u2019re not easy to recover from.</li><li>Humans aren\u2019t built to do too much at once. If you take too much on, it will likely take necessary energy away from the things that matter most.</li><li>You\u2019re much more likely to make mistakes. Mistakes can often be prevented by having the presence, calm, and headspace to focus properly. When you have too much going on, mistakes should be expected. You\u2019re also less likely to be able to come up with creative solutions since our creativity flows much more when we\u2019re not in a stressed state.</li></ol><p>&nbsp;</p><p><strong>2. Close unnecessary applications&nbsp;</strong></p><p>If your computer is running too many applications, it slows everything else down. So you have to make a choice \u2013 which are the ones that are critical to have running, and which ones can you live without, are consuming too many resources, or you didn\u2019t even realize were consuming resources?</p><p>&nbsp;</p><p>Applying that back to you, take an honest look at the activities that consume your resources. Which ones are critical to keep going? Which ones are less essential? Letting go of something isn\u2019t a failure \u2013 it\u2019s redirecting your resources to excel in your top priorities. Sometimes it helps to use a \u201cmonitoring program\u201d like time tracking to see where your time and energy is going.</p><p>&nbsp;</p><p><strong>3. Optimize your settings</strong></p><p>Sometimes there are some applications that you need, but they consume a lot of resources. So the next recommended step is to optimize your settings. Sometimes it\u2019s deleting the backlog, or changing the refresh rate, or having it not run in the background, or run at lower intensity. There are lots of potential solutions, and they differ based on your unique set of programs, available resources, and objectives.</p><p>&nbsp;</p><p>In your life, there may be some things that are high-resource consuming. But they don\u2019t need to be that way. How can you adjust these things to consume less resources? It may require setting boundaries with friends and family, installing a time blocking app, or learning to delegate, or striving to meet a lower bar in a certain program or task. How can you accomplish the same goal, or close to it, with fewer resources? Try switching up some of your \u201csettings\u201d to see which ones help create more resource availability. It might require adding new \u201capplications\u201d that are more efficient \u2013 like task management systems and calendar scheduling tools so that you can free up some literal memory.</p><p>&nbsp;</p><p><strong>4. Restart your computer</strong></p><p>I really don\u2019t understand the technicality of why restarting your device works to solve problems, but it does (yes, I did look it up, so no need to explain it \u2013 I just personally don\u2019t understand the mechanics of how computers work; I just use them!). Things just go wrong sometimes and a good reset fixes it and refreshes everything.</p><p>&nbsp;</p><p>For you \u2013 get some sleep. Take a vacation. Get away from everything and \u201cturn yourself off\u201d. You\u2019ll wake up / come back rejuvenated, replenished, and ready with lots of resources to do your best work. That is MUCH more impactful than working during that same period of time.</p><p>&nbsp;</p><p>I\u2019m assuming that most of the people reading this at least appreciate the value of long-termism. If you want to be a true long-termist, you want to think about how you can make yourself the most impactful over the long term, not just over the short term period. That means taking care of yourself, saying no to things, not overextending yourself, and making sure you always have that extra 20% capacity built into your schedule. Yes, there will be short times when you'll need to extend yourself, but make sure that they stay short. Otherwise, you run the danger of being more impactful in the short term, but less impactful in the long term. I know it feels very counterintuitive, but it's really important to keep in mind as you optimize your life to be as high-impact as you can.</p><p>If you have any questions, please feel free to reach out via PM / <a href=\"mailto:denglander@workstreamsystems.com\">email</a>, or schedule a time to chat <a href=\"https://calendly.com/deenaenglander\">here</a>.</p>", "user": {"username": "Deena Englander"}}, {"_id": "qNKHumeLwTamkD5ED", "title": "Asterisk Magazine Issue 03: AI", "postedAt": "2023-07-24T15:53:38.797Z", "htmlBody": "<h1>All the articles from Asterisk's AI special:</h1><p><a href=\"https://asteriskmag.com/issues/03/the-great-inflection-a-debate-about-ai-and-explosive-growth\">Matt Clancy and Tamay Besiroglu</a> debate whether AI will lead to explosive economic growth</p><p><a href=\"https://asteriskmag.com/issues/03/what-we-get-wrong-about-ai-china\">Jeffrey Ding</a> argues that we overestimate China's AI capabilities&nbsp;</p><p><a href=\"https://asteriskmag.com/issues/03/crash-testing-gpt-4\">Beth Barnes</a> explans ARC Evals' work on GPT-4</p><p><a href=\"https://asteriskmag.com/issues/03/through-a-glass-darkly\">Scott Alexander </a>looks into the field of AI forecasting since 2016</p><p><a href=\"https://asteriskmag.com/issues/03/the-transistor-cliff\">Sarah Constantin</a> on what happens to AI progress if Moore's Law ends</p><p><a href=\"https://asteriskmag.com/issues/03/ai-isn-t-coming-for-tech-jobs-yet\">Jonathan Mann</a> argues that LLMs won't result in tech job losses by 2025</p><p><a href=\"https://asteriskmag.com/issues/03/the-puzzle-of-non-proliferation\">Carl Robichaud</a> on<a href=\"https://asteriskmag.com/issues/03/the-puzzle-of-non-proliferation\"> </a>the history of nuclear non-proliferation and takeaways for AI governance</p><p><a href=\"https://asteriskmag.com/issues/03/a-field-guide-to-ai-safety\">Kelsey Piper </a>offers an overview and history of the field of AI Safety</p><p><a href=\"https://asteriskmag.com/issues/03/are-we-smart-enough-to-know-how-smart-ais-are\">Rob Long</a> on the problem of how we should think about AI cognition</p><p><a href=\"https://asteriskmag.com/issues/03/how-we-can-regulate-ai\">Avital Balwit</a> gives an overview of compute governance</p><p><a href=\"https://asteriskmag.com/issues/03/how-long-until-armageddon\">Michael Gordin</a> on how American scientists underestimated how long it would take the Soviets to create an atomic bomb</p><p><a href=\"https://asteriskmag.com/issues/03/emotional-intelligence-amplification\">Jamie Wahl's</a> short story <i>Emotional Intelligence Amplification</i></p><p><a href=\"https://asteriskmag.com/issues/03/why-worry\">The Editors</a> on why they worry about AI risk</p><p><a href=\"https://asteriskmag.com/issues/03/growing-up-overnight\">Bonus: </a>the magazine offers a visualisation of LLM progress in the last 6 years<br>&nbsp;</p><p>And a reminder that if it's your thing you can buy a print subscription to the magazine <a href=\"https://store.asteriskmag.com/\">here</a>, or you can<a href=\"https://store.asteriskmag.com/\"> </a>subscribe to the newsletter by clicking the menu bar on the <a href=\"https://asteriskmag.com/\">homepage</a></p>", "user": {"username": "alejandro"}}, {"_id": "EHTynQaSN8ubjCbm9", "title": "How much is reducing catastrophic and extinction risk worth, assuming XPT forecasts?", "postedAt": "2023-07-24T15:16:50.072Z", "htmlBody": "<p><i>This is a post I drafted some months ago, in the course of analysing some XPT data and reading </i><a href=\"https://philpapers.org/archive/SHUHMS.pdf\"><i>Shulman and Thornley</i></a><i>. It\u2019s not very sophisticated, I haven\u2019t checked the workings, and I haven\u2019t polished the language; but I\u2019m posting anyway because that seems better than not posting. <strong>Note that it\u2019s a personal take and doesn\u2019t represent FRI\u2019s views.</strong></i></p><p><i>Thanks to Josh Rosenberg at FRI and Elliot Thornley for help and comments.</i></p><p>&nbsp;</p><p><strong>BLUF: if you make a bunch of assumptions, then even quite low absolute risk forecasts like the XPT ones imply quite high spending on reducing GCRs, conditional on there being sufficiently cost-effective ways to do so.</strong></p><p>In 2022, what has become the <a href=\"https://forecastingresearch.org/\"><u>Forecasting Research Institute</u></a>&nbsp;ran the Existential Risk Persuasion Tournament (XPT). Over 200 forecasters, including superforecasters and domain experts, spent 4 months making forecasts on various questions related to existential and catastrophic risk.</p><p>You can see the results from the tournament overall <a href=\"https://static1.squarespace.com/static/635693acf15a3e2a14a56a4a/t/64abffe3f024747dd0e38d71/1688993798938/XPT.pdf\"><u>here</u></a>, and a discussion of the XPT AI risk forecasts in particular <a href=\"https://forum.effectivealtruism.org/posts/K2xQrrXn5ZSgtntuT/what-do-xpt-forecasts-tell-us-about-ai-risk-1\"><u>here</u></a>.</p><p>These are the main XPT forecasts on catastrophic and extinction risk:</p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">&nbsp;</td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p><strong>2030</strong></p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p><strong>2050</strong></p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p><strong>2100</strong></p></td></tr><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"4\" rowspan=\"1\"><p><strong>Catastrophic risk (&gt;10% of humans die in 5 years)</strong></p></td></tr><tr><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>Biological</strong><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefukb7irvfql\"><sup><a href=\"#fnukb7irvfql\">[1]</a></sup></span></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>-</p></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>-</p></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>1.8%</p></td></tr><tr><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>Engineered pathogens</strong><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref8nvcv73pddd\"><sup><a href=\"#fn8nvcv73pddd\">[2]</a></sup></span></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>-</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>-</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>0.8%</p></td></tr><tr><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>Natural pathogens</strong><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref5mqtx2h8ayt\"><sup><a href=\"#fn5mqtx2h8ayt\">[3]</a></sup></span></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>-</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>-</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>1%</p></td></tr><tr><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><a href=\"https://docs.google.com/document/d/1CAmw1g_Y3siZGZaaYJjMRjEIyV4HURhCZf5rZ4a6-d8/edit\"><strong><u>AI</u></strong></a><strong>&nbsp;(superforecasters)</strong></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>0.01%</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>0.73%</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>2.13%</p></td></tr><tr><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><a href=\"https://docs.google.com/document/d/1CAmw1g_Y3siZGZaaYJjMRjEIyV4HURhCZf5rZ4a6-d8/edit\"><strong><u>AI</u></strong></a><strong>&nbsp;(domain experts)</strong></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>0.35%</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>5%</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>12%</p></td></tr><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><a href=\"https://docs.google.com/document/d/199bSOzlT5PR4TAOU3myFfdXpBfbNDAG69wESSnl_MaE/edit\"><strong><u>Nuclear</u></strong></a></td><td style=\"border-style:solid;padding:2pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p>0.50%</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p>1.83%</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p>4%</p></td></tr><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><a href=\"https://docs.google.com/document/d/1Syu1oqedSqWh1KneRH-LtV__3ZVdrYoDdL3FpG7v0eQ/edit\"><strong><u>Non-anthropogenic</u></strong></a></td><td style=\"border-style:solid;padding:2pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p>0.0026%</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p>0.015%</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p>0.05%</p></td></tr><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><a href=\"https://docs.google.com/document/d/1H11Aq_XTZkKzjyECb_qdy4cbmJWxGHkYAI2JvhrjjdY/edit\"><strong><u>Total catastrophic risk</u></strong></a><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefrpjcw4agoam\"><sup><a href=\"#fnrpjcw4agoam\">[4]</a></sup></span></td><td style=\"border-style:solid;padding:2pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p>0.85%</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p>3.85%</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p>9.05%</p></td></tr><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"4\" rowspan=\"1\"><p><strong>Extinction risk (human population &lt;5000)</strong></p></td></tr><tr><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>Biological</strong><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefjxomqgjkqr\"><sup><a href=\"#fnjxomqgjkqr\">[5]</a></sup></span></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>-</p></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>-</p></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>0.012%</p></td></tr><tr><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>Engineered pathogens</strong><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref0kt7harrciga\"><sup><a href=\"#fn0kt7harrciga\">[6]</a></sup></span></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>-</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>-</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>0.01%</p></td></tr><tr><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>Natural pathogens</strong><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefuwqkzh5jbo\"><sup><a href=\"#fnuwqkzh5jbo\">[7]</a></sup></span></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>-</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>-</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>0.0018%</p></td></tr><tr><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><a href=\"https://docs.google.com/document/d/1NMC1RV8XD0zcvVUfgcJPx7rBKqoNOk7pVJ74C9-JtLY/edit\"><strong><u>AI</u></strong></a><strong>&nbsp;(superforecasters)</strong></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>0.0001%</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>0.03%</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>0.38%</p></td></tr><tr><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><a href=\"https://docs.google.com/document/d/1NMC1RV8XD0zcvVUfgcJPx7rBKqoNOk7pVJ74C9-JtLY/edit\"><strong><u>AI</u></strong></a><strong>&nbsp;(domain experts)</strong></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>0.02%</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>1.1%</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>3%</p></td></tr><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><a href=\"https://docs.google.com/document/d/1-hkApWaPqETJLZ6Z0nXbtG0b--EihUdNTcB38fTAYI8/edit\"><strong><u>Nuclear</u></strong></a></td><td style=\"border-style:solid;padding:2pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p>0.001%</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p>0.01%</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p>0.074%</p></td></tr><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><a href=\"https://docs.google.com/document/d/1GUNJD-ogiMRaPgRmJA_4uo_U4EqBiDSnBe-lxuMo5qo/edit\"><strong><u>Non-anthropogenic</u></strong></a></td><td style=\"border-style:solid;padding:2pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p>0.0004%</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p>0.0014%</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p>0.0043%</p></td></tr><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><a href=\"https://docs.google.com/document/d/1wENxRHoCrNU4MXfusy2Txh6onO9zt5kIl-K-OLZv5FQ/edit\"><strong><u>Total extinction risk</u></strong></a><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref2cowcw8o502\"><sup><a href=\"#fn2cowcw8o502\">[8]</a></sup></span></td><td style=\"border-style:solid;padding:2pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p>0.01%</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p>0.3%</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p>1%</p></td></tr></tbody></table></figure><p>If we take these numbers at face value, how much is catastrophic and extinction risk reduction worth?</p><p>One approach is to take the XPT forecasts, convert them into deaths in expectation, then assume a value of a statistical life and a discount rate, and estimate how much averting those deaths is \u2018worth\u2019. (I\u2019m stealing this method directly from <a href=\"https://philpapers.org/archive/SHUHMS.pdf\"><u>Shulman and Thornley</u></a>.)</p><p>Using the XPT superforecasts and <a href=\"https://ourworldindata.org/grapher/un-population-projection-medium-variant\"><u>OWID population projections</u></a>&nbsp;gives us the following deaths in expectation, in millions:</p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">&nbsp;</td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"3\" rowspan=\"1\"><p><strong>Deaths in expectation (millions)</strong></p></td></tr><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">&nbsp;</td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p><strong>2030</strong></p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p><strong>2050</strong></p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p><strong>2100</strong></p></td></tr><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"4\" rowspan=\"1\"><p><strong>Catastrophic risk (&gt;10% of humans die in 5 years)</strong></p></td></tr><tr><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>Bio</strong></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>--</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>--</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>18.6</p></td></tr><tr><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>AI</strong></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>0.09</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>7.1</p></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>22.0</p></td></tr><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>Nuclear</strong></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>4.3</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>17.8</p></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>41.4</p></td></tr><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>Non-anthropogenic</strong></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>0.02</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>0.15</p></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>0.5</p></td></tr><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>Total</strong></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>7.3</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>37.4</p></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>93.7</p></td></tr><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"4\" rowspan=\"1\"><p><strong>Extinction risk (human population &lt;5000)</strong></p></td></tr><tr><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>Bio</strong></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>--</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>--</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>1.2</p></td></tr><tr><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>AI</strong></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>0.01</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>2.9</p></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>39.3</p></td></tr><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>Nuclear</strong></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>0.09</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>1.0</p></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>7.7</p></td></tr><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>Non-anthropogenic</strong></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>0.03</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>0.1</p></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>0.4</p></td></tr><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>Total</strong></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>0.9</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>29.1</p></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>103.5</p></td></tr></tbody></table></figure><p>Some notes:</p><ul><li>Workings <a href=\"https://docs.google.com/spreadsheets/d/1UI-tUWpncLoeoCBUHxMPhprBVpobLr2Dnn6L3-PBW_k/edit?pli=1#gid=0\"><u>here</u></a>.</li><li>For catastrophic risks, the deaths in expectation should be read as a lower bound, because they assume 10% deaths and the question includes scenarios with &gt;10% deaths.</li></ul><p>That\u2019s deaths in expectation worldwide. But the value of a statistical life varies by country: governments have different resources and the cost of interventions in different places varies.</p><p>So the most straightforward way to think about the worth of catastrophic and extinction risk reduction is to ask how much this would be worth in a given country. Let\u2019s take the US as an example.</p><p>First we need US deaths in expectation:</p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">&nbsp;</td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"3\" rowspan=\"1\"><p><strong>US deaths in expectation (millions)</strong></p></td></tr><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">&nbsp;</td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p><strong>2030</strong></p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p><strong>2050</strong></p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p><strong>2100</strong></p></td></tr><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"4\" rowspan=\"1\"><p><strong>Catastrophic risk (&gt;10% of humans die in 5 years)</strong></p></td></tr><tr><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>Bio</strong></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>--</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>--</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>0.7</p></td></tr><tr><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>AI</strong></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>0.004</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>0.3</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>0.8</p></td></tr><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>Nuclear</strong></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>0.2</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>0.7</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>1.6</p></td></tr><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>Non-anthropogenic</strong></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>0.001</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>0.006</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>0.02</p></td></tr><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>Total</strong></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>0.3</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>1.4</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>3.6</p></td></tr><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"4\" rowspan=\"1\"><p><strong>Extinction risk (human population &lt;5000)</strong></p></td></tr><tr><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>Bio</strong></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>--</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>--</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>0.05</p></td></tr><tr><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>AI</strong></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>0.0004</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>0.1</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>1.5</p></td></tr><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>Nuclear</strong></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>0.004</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>0.04</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>0.3</p></td></tr><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>Non-anthropogenic</strong></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>0.001</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>0.01</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>0.02</p></td></tr><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>Total</strong></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>0.04</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>1.1</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>3.9</p></td></tr></tbody></table></figure><p>Workings <a href=\"https://docs.google.com/spreadsheets/d/1UI-tUWpncLoeoCBUHxMPhprBVpobLr2Dnn6L3-PBW_k/edit?pli=1#gid=0\"><u>here</u></a>.</p><p>We can then&nbsp;assume a US value for a statistical life, and a discount rate, and use these to estimate how much averting the deaths in expectation is \u2018worth\u2019 to the US government.</p><ul><li>The primary VSL figure used by the U.S. Department of Transportation for 2021 is $11.8 million, with a range to account for various kinds of uncertainty spanning from about $7 million to $16.5 million.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefv4tsyoc1xns\"><sup><a href=\"#fnv4tsyoc1xns\">[9]</a></sup></span></li><li>The Environmental Protection Agency (EPA) uses annual discount rates of 2% and 3%; the Office of Information and Regulatory Affairs (OIRA) instructs agencies to conduct analyses using annual discount rates of 3% and 7%.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefyrqkjorjoki\"><sup><a href=\"#fnyrqkjorjoki\">[10]</a></sup></span></li><li>It\u2019s a widely held position that 7% is too high a discount rate,<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefubgi0hzvywo\"><sup><a href=\"#fnubgi0hzvywo\">[11]</a></sup></span>&nbsp;so let\u2019s go with 3% as it\u2019s closer to consensus.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefyz1d525nkqj\"><sup><a href=\"#fnyz1d525nkqj\">[12]</a></sup></span></li></ul><p>Assuming $7m as the value of a statistical life, and a 3% annual discount rate, the value&nbsp;to the US government of reducing total initial risks by 1% (not one percentage point)<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefrabivc4rr7\"><sup><a href=\"#fnrabivc4rr7\">[13]</a></sup></span>&nbsp;would be as follows:</p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>&nbsp;</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"3\" rowspan=\"1\"><p><strong>Value of a 1% reduction in risk, assuming VSL at $7m and discount rate at 3% (billions of dollars)</strong></p></td></tr><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>&nbsp;</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p><strong>2030</strong></p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p><strong>2050</strong></p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p><strong>2100</strong></p></td></tr><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"4\" rowspan=\"1\"><strong>Catastrophic risk (&gt;10% of humans die in 5 years)</strong></td></tr><tr><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>Bio</strong></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>--</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>--</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$5.0</p></td></tr><tr><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>AI</strong></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$0.2</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$8.4</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$5.9</p></td></tr><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>Nuclear</strong></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$9.7</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$21.0</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$11.0</p></td></tr><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>Non-anthropogenic</strong></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$0.05</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$0.2</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$0.1</p></td></tr><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>Total</strong></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$16.5</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$44.2</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$24.9</p></td></tr><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"4\" rowspan=\"1\"><strong>Extinction risk (human population &lt;5000)</strong></td></tr><tr><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>Bio</strong></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>--</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>--</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$0.3</p></td></tr><tr><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>AI</strong></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$0.02</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$3.4</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$10.5</p></td></tr><tr><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>Nuclear</strong></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$0.2</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$1.1</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$2.0</p></td></tr><tr><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>Non-anthropogenic</strong></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$0.1</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$0.2</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$0.12</p></td></tr><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>Total</strong></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$1.9</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$34.5</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$27.5</p></td></tr></tbody></table></figure><p>Workings <a href=\"https://docs.google.com/spreadsheets/d/1UI-tUWpncLoeoCBUHxMPhprBVpobLr2Dnn6L3-PBW_k/edit?pli=1#gid=1382612543\"><u>here</u></a>.</p><p>There are a few&nbsp;reasons to expect these numbers to underestimate the value&nbsp;of catastrophic and extinction risk reduction:</p><ul><li>When it comes to extinction risk, these numbers only concern deaths in expectation, not lives foregone in expectation</li><li>These numbers assume that all of the deaths averted are averted at the very end of the period in question (i.e. maximum discounting)</li><li>Note that this means that it doesn\u2019t make sense to sum the figures across rows: that would mean double counting deaths averted but at different discount rates</li><li>As noted above, the estimated deaths in expectation for catastrophic risks should be read as lower bounds. The corresponding dollar values are therefore also lower bounds</li></ul><h3>What if I only care about the next few decades?</h3><p>Suppose I don\u2019t take extinction risk seriously, but I am interested in the XPT forecasts on catastrophic risks. That said, I think that 2030 is so soon that catastrophe seems extremely unlikely, and I don\u2019t care much about things as far out as 2100, partly because I\u2019m sceptical that we can influence things on that timescale, and partly because I only care about current lives. I want to know how much reducing catastrophic risk by 1% by 2050 would be worth, assuming $7m VSL and a 3% discount rate.</p><p>That would give me something like this:</p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p><strong>Catastrophic risk</strong></p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p><strong>Total value of 1% risk reduction by 2050, millions* of dollar</strong></p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p><strong>Annual value, millions* of dollars**</strong></p></td></tr><tr><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>AI</strong></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$8,400</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$299.4</p></td></tr><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>Nuclear</strong></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$21,000</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$750.6</p></td></tr><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>Non-anthropogenic</strong></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$170</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$6.2</p></td></tr><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>Total</strong></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$44,000</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$1,579.2</p></td></tr></tbody></table></figure><p>* Note that this table displays millions of dollars, and the previous tables displayed billions.</p><p>**This is just a naive division of the total by 28 (the XPT tournament took place in 2022). Workings <a href=\"https://docs.google.com/spreadsheets/d/1UI-tUWpncLoeoCBUHxMPhprBVpobLr2Dnn6L3-PBW_k/edit?pli=1#gid=1509068422\"><u>here</u></a>.</p><p>How does this compare to current annual spending on these risks? There isn\u2019t good data here, but to give some ballpark ideas:</p><ul><li>Ord estimated global spending on reducing AI risk at $10-50m in 2020.</li><li>The US spent <a href=\"https://carnegieendowment.org/files/nuclear_security_spending_complete_high.pdf\"><u>$5,200m</u></a>&nbsp;on nuclear threat reduction in 2008 (about <a href=\"https://www.in2013dollars.com/us/inflation/2008?amount%3D5.20\"><u>$7,170m</u></a>&nbsp;in 2023 dollars).</li><li>NASA spent <a href=\"https://www.planetary.org/articles/nasas-planetary-defense-budget-growth\"><u>$150m</u></a>&nbsp;on its near-earth objects program in 2019.</li></ul><p>Note that it\u2019s unclear what level of risk reduction those figures correspond to, so it\u2019s not clear what the direct comparison should be between current total spending and the value of a 1% risk reduction.</p><h3>What about the value of catastrophic and extinction risk reduction worldwide?</h3><p>Most of the people potentially affected by catastrophic and extinction risks aren\u2019t US citizens. Can we say anything about how much catastrophic and extinction risk reduction is worth globally, using the VSL method?</p><p>Not very accurately, but it might be interesting to have a go anyway.</p><p>The problems with extrapolating this method worldwide are:</p><ul><li>The figure we used for US VSL was $7m. In many places in the world, the value of a statistical life is much lower: there are fewer resources, and interventions are cheaper.</li><li>In the US case, it\u2019s clear to say that using VSL, reducing catastrophic and extinction risk by 1% is worth so much <i>to the US government</i>. It\u2019s not clear which actor this reduction is worth something to in the global case.</li></ul><p>That said:</p><ul><li>Usually the US government isn\u2019t willing to pay the same amount for the lives of its citizens and those of other countries, but there are exceptions. For example, the US social cost of carbon number counts costs to non-US citizens in the same way as costs to US citizens.</li><li>We can ask how much catastrophic and extinction risk reduction would be worth to some hypothetical actor who put the same VSL on all lives that the US government puts on the lives of its citizens.</li></ul><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>&nbsp;</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"3\" rowspan=\"1\"><p><strong>Value of a 1% reduction in risk, assuming VSL at $7m and discount rate at 3% (billions of dollars)</strong></p></td></tr><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>&nbsp;</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p><strong>2030</strong></p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p><strong>2050</strong></p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p><strong>2100</strong></p></td></tr><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"4\" rowspan=\"1\"><strong>Catastrophic risk (&gt;10% of humans die in 5 years)</strong></td></tr><tr><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>Bio</strong></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>--</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>--</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$130.0</p></td></tr><tr><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>AI</strong></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$4.7</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$216.9</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$153.9</p></td></tr><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>Nuclear</strong></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$236.2</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$543.7</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$288.9</p></td></tr><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>Non-anthropogenic</strong></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$1.2</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$4.5</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$3.6</p></td></tr><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>Total</strong></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$401.6</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$1,143.8</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$653.7</p></td></tr><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"4\" rowspan=\"1\"><strong>Extinction risk (human population &lt;5000)</strong></td></tr><tr><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>Bio</strong></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>--</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>--</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$8.7</p></td></tr><tr><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>AI</strong></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$0.5</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$89.1</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$274.5</p></td></tr><tr><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>Nuclear</strong></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$4.7</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$29.7</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$53.5</p></td></tr><tr><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>Non-anthropogenic</strong></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$1.9</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$4.2</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$3.1</p></td></tr><tr><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>Total</strong></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$47.2</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$891.2</p></td><td style=\"border:1pt solid rgb(204, 204, 204);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$722.3</p></td></tr></tbody></table></figure><p>Workings <a href=\"https://docs.google.com/spreadsheets/d/1UI-tUWpncLoeoCBUHxMPhprBVpobLr2Dnn6L3-PBW_k/edit?pli=1#gid=1382612543\"><u>here</u></a>.</p><h3>Summing up</h3><ul><li>Given XPT estimates of risk and standard US CBA assumptions ($7m VSL, 3% discount rate):<ul><li>A 1% reduction in total catastrophic risk by 2050 would be worth up to $44bn to the US government.<ul><li>A 1% reduction in catastrophic nuclear risk by 2050 would be worth up to $21bn.</li><li>A 1% reduction in catastrophic AI risk by 2050 would be worth up to $8bn.</li></ul></li><li>A 1% reduction in total extinction risk by 2050 would be worth up to $35bn to the US government.</li><li>To an actor willing to spend US VSL to save the lives of citizens of any country:<ul><li>A 1% reduction in total catastrophic risk by 2050 would be worth up to $1.1tr.</li><li>A 1% reduction in total extinction risk by 2050 would be worth up to $891bn.</li></ul></li></ul></li><li>Interventions which reduce the relevant catastrophic or extinction risk by 1% by 2050 and cost less than those figures would plausibly be cost-effective for the US government to fund.<ul><li>This depends on what cost-benefit ratio the US government (or more likely its constituent parts) are aiming for.</li></ul></li><li>It seems pretty likely to me that such interventions exist.</li><li><strong>If you make the assumptions above, then</strong> <strong>even quite low absolute risk forecasts like the XPT ones imply quite high spending on reducing GCRs, conditional on there being sufficiently cost-effective ways to do so.</strong></li></ul><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnukb7irvfql\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefukb7irvfql\">^</a></strong></sup></span><div class=\"footnote-content\"><p>This row is the sum of the two following rows (catastrophic risk from engineered and from natural pathogens respectively). We did not directly ask for catastrophic biorisk forecasts.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn8nvcv73pddd\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref8nvcv73pddd\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Because of concerns among our funders about <a href=\"https://nickbostrom.com/information-hazards.pdf\"><u>information hazards</u></a>, we did not include this question in the main tournament, but we did ask about risks from engineered and natural pathogens in a one-shot separate postmortem survey to which most XPT participants responded after the tournament.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn5mqtx2h8ayt\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref5mqtx2h8ayt\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Because of concerns among our funders about <a href=\"https://nickbostrom.com/information-hazards.pdf\"><u>information hazards</u></a>, we did not include this question in the main tournament, but we did ask about risks from engineered and natural pathogens in a one-shot separate postmortem survey to which most XPT participants responded after the tournament.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnrpjcw4agoam\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefrpjcw4agoam\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;This question was asked independently, rather than inferred from questions about individual risks.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnjxomqgjkqr\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefjxomqgjkqr\">^</a></strong></sup></span><div class=\"footnote-content\"><p>This row is the sum of the two following rows (catastrophic risk from engineered and from natural pathogens respectively). We did not directly ask for catastrophic biorisk forecasts.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn0kt7harrciga\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref0kt7harrciga\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Because of concerns among our funders about <a href=\"https://nickbostrom.com/information-hazards.pdf\"><u>information hazards</u></a>, we did not include this question in the main tournament, but we did ask about risks from engineered and natural pathogens in a one-shot separate postmortem survey to which most XPT participants responded after the tournament.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnuwqkzh5jbo\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefuwqkzh5jbo\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Because of concerns among our funders about <a href=\"https://nickbostrom.com/information-hazards.pdf\"><u>information hazards</u></a>, we did not include this question in the main tournament, but we did ask about risks from engineered and natural pathogens in a one-shot separate postmortem survey to which most XPT participants responded after the tournament.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn2cowcw8o502\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref2cowcw8o502\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;This question was asked independently, rather than inferred from questions about individual risks.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnv4tsyoc1xns\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefv4tsyoc1xns\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;<a href=\"https://philpapers.org/archive/SHUHMS.pdf\"><u>Shulman and Thornley</u></a>, p. 12; from (U.S. Department of Transportation 2021a, 2021b).</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnyrqkjorjoki\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefyrqkjorjoki\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;<a href=\"https://philpapers.org/archive/SHUHMS.pdf\"><u>Shulman and Thornley</u></a>, p. 12; from (Graham 2008: 504).</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnubgi0hzvywo\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefubgi0hzvywo\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;See <a href=\"https://www.aeaweb.org/articles?id%3D10.1257/pol.20160240\"><u>here</u></a>&nbsp;and p. 504 <a href=\"https://drive.google.com/file/d/1AxbXTMBVqDK23U-hMpJ9J3e6Xa5-Md3n/view\"><u>here</u></a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnyz1d525nkqj\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefyz1d525nkqj\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;You can see what the 7% discount rate figures look like in the <a href=\"https://docs.google.com/spreadsheets/d/1UI-tUWpncLoeoCBUHxMPhprBVpobLr2Dnn6L3-PBW_k/edit?pli=1#gid=1509068422\"><u>workings</u></a>&nbsp;spreadsheet for this post.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnrabivc4rr7\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefrabivc4rr7\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;I mean a 1% reduction of the total initial risk, rather than a reduction of the total risk by 1 percentage point.</p></div></li></ol>", "user": {"username": "rosehadshar"}}, {"_id": "YGsojZYtEsj2A3PjZ", "title": "Who\u2019s right about inputs to the biological anchors model?", "postedAt": "2023-07-24T14:37:10.166Z", "htmlBody": "<p>In&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/ccw9v9giKxg8nyLhp/xpt-forecasts-on-some-biological-anchors-inputs\"><u>this</u></a> post, I compared forecasts from Ajeya Cotra and from forecasters in the Existential Risk Persuasion Tournament (XPT) relating to some of the inputs to Cotra\u2019s biological anchors model.</p><p>Here, I give my personal take on which of those forecasts seem more plausible.</p><p>Note that:</p><ul><li>I\u2019m only considering the inputs to the bio anchors model which we have XPT forecasts for. This notably excludes the 2020 training requirements distribution, which is a very important driver of model outputs.</li><li>My take is based on considering the explicit arguments that Cotra and the XPT forecasters gave, rather than on independent research.</li><li>My take is subjective.</li><li>I\u2019ve been working with the Forecasting Research Institute (who ran the XPT) since November 2022, and this is a potential source of bias.</li><li>I\u2019m publishing this post in a personal capacity and it hasn\u2019t gone through FRI\u2019s review process.</li><li>I originally wrote this early in 2023. I've tried to update it as new information came out, but I likely haven't done a comprehensive job of this.</li></ul><p>To recap, here are the relevant forecasts:</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YGsojZYtEsj2A3PjZ/t0tcqf6s2q9p2uqh3zwi\"></p><p>See workings&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1tw2B1okJUdLrTIeDzooMPP16yduxZPzgLPHafD6Q6_8/edit#gid=0\">here</a> and&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1ZW4j1DbOYnFSGj0WjzNMEBCSN6daTKAg63ZO_B2tcws/edit#gid=505210495\">here</a><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefhysgw1fmwwi\"><sup><a href=\"#fnhysgw1fmwwi\">[1]</a></sup></span>.&nbsp;<br>*The 'most aggressive' and 'most conservative' forecasts can be considered equivalent to 90% confidence intervals for the median estimate.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefbx8maz9mt6h\"><sup><a href=\"#fnbx8maz9mt6h\">[2]</a></sup></span></p><h2>Hardware</h2><ul><li>For FLOP/$ in 2025, I think both Cotra and the XPGT forecasters are wrong, but Cotra will prove more right.<ul><li>Epoch\u2019s current estimate of highest GPU price-performance is&nbsp;<a href=\"https://epochai.org/trends#hardware-trends-section\"><u>4.2e18 FLOP per $</u></a>.</li><li>They also find a trend in GPU price-performance of 0.1 OOM/year for state of the art GPUs. So I\u2019ll extrapolate 4.2e18 to 5.97E+18.</li></ul></li><li>For compute price halving time to 2100, I think it depends how likely you think it is that novel technologies like optical computing will reduce compute prices in future.<ul><li>This is the main argument Cotra puts forward for expecting such low prices.</li><li>It\u2019s an argument made in XPT too, but less weight is put on it.<ul><li>Counterarguments given in XPT: fundamental physical limits, progress getting harder, rare materials capping how much prices can drop, catastrophe/extinction, optimisation shifting to memory architectures.<ul><li>Cotra mentions some but not all of these (she doesn\u2019t mention rare materials or memory architectures).</li></ul></li></ul></li><li>Cotra flags that she thinks after 2040 her forecasts on this are pretty unreliable.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefq0x1hofivd\"><sup><a href=\"#fnq0x1hofivd\">[3]</a></sup></span></li><li>But, because of how wrong their 2024 and 2030 forecasts seem to be, I\u2019m not inclined to put much weight on XPT forecasts here either.</li><li>I\u2019ll go with the most aggressive XPT figure, which is close to Cotra\u2019s.<ul><li>I don\u2019t have an inside view on the likelihood of novel technologies causing further price drops.</li></ul></li></ul></li><li>Note that the disagreement about compute price halving times drives a lot of the difference in model output.</li></ul><h2>Willingness to spend</h2><ul><li>On the most expensive training run by 2025, I think Cotra is a bit too aggressive and XPT forecasters are much too conservative.<ul><li>In&nbsp;<a href=\"https://www.lesswrong.com/posts/AfH2oPHCApdKicM4m/two-year-update-on-my-personal-ai-timelines#Making_a_one_time_upward_adjustment_for__2020_FLOP_____\"><u>2022</u></a>, Cotra updated downwards a bit on the likelihood of a $1bn training run by 2025.<ul><li>There isn\u2019t much time left for Cotra to be right.</li></ul></li><li>Cotra was predicting $20m by the end of 2020, and $80m by the end of 2021.<ul><li>GPT-3 was&nbsp;<a href=\"https://lambdalabs.com/blog/demystifying-gpt-3/#1\"><u>$4.6m</u></a> in 2020. If you buy that unreleased proprietary models are likely to be 2-8x more expensive than public ones (which Cotra argues),<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefrprefic3dm\"><sup><a href=\"#fnrprefic3dm\">[4]</a></sup></span>&nbsp;that XPT forecasters missed this consideration,&nbsp;<i>and</i> that GPT-3 isn\u2019t proprietary and/or unreleased (flagging because I\u2019m unsure what Cotra actually means by proprietary/unreleased), then this could be consistent with Cotra\u2019s forecasts.&nbsp;</li></ul></li><li>Epoch estimates that GPT-4 cost&nbsp;<a href=\"https://colab.research.google.com/drive/1O99z9b1I5O66bT78r9ScslE_nOj5irN9?usp=sharing#scrollTo=Pqkx-E3NQocI\"><u>$50m</u></a> to train at some point in 2022.&nbsp;<ul><li>Again, this could be in line with Cotra\u2019s predictions.</li><li>More importantly, GPT-4 costs make XPT forecasters look quite wrong already - their 2024 prediction was surpassed in 2022. This is especially striking in the context of:<ul><li>XPT forecasters making their predictions three years after Cotra made hers.</li><li>The possibility that at a given time unreleased models might be 2-8x more expensive than the most expensive released model.</li></ul></li></ul></li><li>It seems to me that both Cotra and XPT forecasters will probably end up wrong, but that XPT forecasters will be much more wrong.&nbsp;<ul><li>I\u2019ll somewhat arbitrarily pick halfway between Cotra\u2019s conservative estimate ($300m) and her $1bn forecast for my best guess - so $650m.</li></ul></li></ul></li><li>On the doubling time of spending on compute, I lean towards Cotra over XPT.<ul><li>I feel a bit confused about how Cotra gets her 2.5 year doubling time, but I think it rests on:<ul><li>Assuming $1bn in 2025 and the incentive of building a transformative model.</li><li>Getting a doubling time from 2025-2040 of 2 years, by estimating how much companies would be willing to spend on a project overall, and then ratios of overall spending to spending on compute for final training runs.</li><li>Then assuming that growth slows down, hitting a cap at 1% of GDP and eventually syncing up with the GDP growth rates of the largest national economy, which Cotra estimates at 3%.</li></ul></li><li>My main reaction to this is that there are lots of assumptions here and therefore many ways that it could turn out wrong.</li><li>I feel disagreement on some specific points, though I\u2019m not sure how much of Cotra\u2019s 2.5 year doubling time is based on these things:<ul><li>$1bn in 2025 seems too high (see above).</li><li>There being a transparent incentive of building a transformative model seems like an upper bound, not a median estimate to me.</li><li>Using Manhattan/Apollo projects as anchors for 2100 also seems like an upper bound to me:<ul><li>It\u2019s possible that we\u2019d get a huge countrywide effort like this, but also possible that governments don\u2019t get involved in this way.&nbsp;</li><li>For a company to spend 1% of GDP you\u2019d need loads of concentration of wealth - which might happen, or might not.</li><li>I agree that it seems unlikely to be higher than that - but my median guess would be lower.</li></ul></li></ul></li><li>But, because of how wrong their 2024 and 2030 forecasts seem to be, I\u2019m inclined to basically ignore XPT forecasts here.</li><li>I\u2019ll extend Cotra\u2019s doubling time a bit, because I have a few arguments for slower doubling times, to 3 years.</li><li>Note that the disagreement about spending on compute doubling times drives a lot of the difference in model output (it\u2019s the single biggest driver of difference among the inputs we have XPT forecasts for).</li></ul></li></ul><h2>Algorithmic progress</h2><ul><li>I think comparability here is low ish.<ul><li>XPT forecasters were asked by what factor training efficiency on ImageNet classification would improve by 2024 and 2030. Extrapolating this to a halving time for the compute required for TAI which holds till 2100 seems like a bit of a stretch.</li><li>That said, Cotra is substantially basing her forecasts on past trends on specific benchmarks, so I still think the XPT forecasts should be viewed as somewhat indicative.</li></ul></li><li>One of the reviewers of our post on these results (Daniel Kokotajlo) pointed out that&nbsp;<a href=\"https://epochai.org/blog/revisiting-algorithmic-progress\"><u>this 2022 Erdil and Besiroglu paper</u></a> shows that efficiency has been improving faster than the&nbsp;<a href=\"https://arxiv.org/pdf/2005.04305.pdf\"><u>2020 Hernandez and Brown</u></a> paper Cotra based her forecasts on suggest - halving every 9 months, as opposed to every 13-16 months. That\u2019s a decrease in halving time by around 30%.</li><li>Cotra further bumps&nbsp;<i>up</i> the 13-16 month estimate from Hernandez and Brown, arguing that progress on narrow tasks which can be directly optimized for is likely to be faster than TAI progress.<ul><li>Kokotajlo offered an argument in the other direction: estimating algorithmic improvements using quantitative improvements on existing benchmarks only fails to take into account qualitative improvements where whole new capabilities emerge.&nbsp;</li><li>Without having looked into it, I expect the magnitude of the effect from Cotra\u2019s argument to be bigger than the effect from Kokotajlo\u2019s argument - but it still makes me want to bump down Cotra\u2019s forecasts a bit.</li></ul></li><li>My best guess is to bump Cotra\u2019s forecasts down by 35%, which gives me a halving time of 1.3-2.3 years, depending on the anchor.</li></ul><h2>My best guess</h2><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YGsojZYtEsj2A3PjZ/ichnpz65y4cwit9gtwmg\"></p><p>* See workings&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1ciz5JIFuDEg7R8EgcHcOIFiMekgOQzLQ4vWYkZLeoyE/edit#gid=505210495\"><u>here</u></a>.</p><h2>Where this leaves me</h2><ul><li>I expect that sometimes the XPT forecasts will be closer to the truth, and sometimes Cotra\u2019s will be.<ul><li>Specifically, I expect Cotra to be more right on:&nbsp;<ul><li>FLOP per $ in 2025</li><li>Compute price halving time from 2025 to 2100</li><li>Compute cost for most expensive training run to 2025</li><li>Doubling time of spending on compute for the most expensive training run to 2025 (years)</li></ul></li><li>And XPT forecasters to be more right on:<ul><li>Halving time of compute requirements from 2025 to 2100 (years)</li></ul></li></ul></li><li>The net effect of my best guess inputs is an output that\u2019s slightly more aggressive than Cotra\u2019s original model output.&nbsp;</li><li>I don\u2019t think I can conclude from this \u201853% by 2050 is roughly my TAI timeline\u2019, for a few reasons:<ul><li>I haven\u2019t considered all of the inputs to Cotra\u2019s model, most notably the 2020 training computation requirements distribution. Without forming a view on that, I can\u2019t really say that ~53% represents my overall view.</li><li>I feel pretty uncertain about this sort of modeling in general. It feels very sensitive to assumptions and inputs. If it were really hard to get the model to put any significant probability on TAI this century, I\u2019d take that as an update (similarly with the model making TAI soon look very very likely). But for most middling values I\u2019m not personally inclined to base too much on them.</li></ul></li></ul><p><br>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnhysgw1fmwwi\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefhysgw1fmwwi\">^</a></strong></sup></span><div class=\"footnote-content\"><p>This spreadsheet uses as a template Cotra's publicly available <a href=\"https://docs.google.com/spreadsheets/d/1TjNQyVHvHlC-sZbcA7CRKcCp0NxV6MkkqBvL408xrJw/edit#gid=505210495\"><u>spreadsheet</u></a>, linked to from her <a href=\"https://docs.google.com/document/d/1IJ6Sr-gPeXdSJugFulwIpvavc0atjHGM82QjIfUSBGQ/edit#heading=h.c5pt0lvk9kkw\"><u>report</u></a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnbx8maz9mt6h\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefbx8maz9mt6h\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;For the relevant questions in the XPT, forecasters were asked to provide their 5th, 25th, 50th, 75th, and 95th percentile forecasts. In this analysis we use the term, \u2018median\u2019 to refer to analyses using the group\u2019s median forecast for the 50th percentile of each question. We use the term \u2018most aggressive\u2019 to refer to analyses using the group medians for the 5th percentile estimate of the question relating to hardware costs, and the 95th percentile estimate for the questions relating to willingness to spend and algorithmic progress. (I.e., this uses the lowest plausible hardware costs and the highest plausible willingness to spend and algorithmic efficiency to give the highest plausible likelihood of TAI.) We use the term \u2018most conservative\u2019 to refer to &nbsp;analyses using the group medians for the 95th percentile estimate of the question relating to hardware costs, and the 5th percentile estimate for the questions relating to willingness to spend and algorithmic progress. (I.e., this uses the highest plausible hardware costs and the lowest plausible willingness to spend and algorithmic efficiency to give the lowest plausible likelihood of TAI.) The most aggressive and most conservative estimates can be considered equivalent to 90% confidence interval for the median estimate. See <a href=\"https://forum.effectivealtruism.org/posts/ccw9v9giKxg8nyLhp/xpt-forecasts-on-some-biological-anchors-inputs#Comparing_Cotra_and_XPT_forecasts\">here </a>for context on which XPT questions map to which biological anchors inputs.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnq0x1hofivd\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefq0x1hofivd\">^</a></strong></sup></span><div class=\"footnote-content\"><p>\u201cThis forecast feels most solid and plausible out to ~2040 or so, beyond which it feels substantially more murky and likely incorrect.\u201d&nbsp;<a href=\"https://docs.google.com/document/d/1cCJjzZaJ7ATbq8N2fvhmsDOUWdm7t3uSSXv6bD0E_GM/edit#heading=h.fmq8f6whj003\"><u>p. 4</u></a>&nbsp;</p><p>\u201cOf all the quantitative estimates in this document, I consider these forecasts the most likely to be knowably mistaken. While most of the other quantitative estimates in this document have a lot more absolute uncertainty associated with them, there is a lot more low-hanging fruit left in improving short- and medium-term hardware price forecasts. For example, my understanding is that semiconductor industry professionals regularly write highly detailed technical reports forecasting a number of hardware cost-efficiency metrics, and I have neither read any of this literature nor interviewed any hardware experts on this question.\u201d&nbsp;<a href=\"https://docs.google.com/document/d/1qjgBkoHO_kDuUYqy_Vws0fpf-dG5pTU4b8Uej6ff2Fg/edit#heading=h.xi6z3buznjb7\"><u>p. 30</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnrprefic3dm\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefrprefic3dm\">^</a></strong></sup></span><div class=\"footnote-content\"><p>\u201cI would guess that the most compute-intensive training run for an unreleased and/or proprietary model (e.g., a language model powering Google Assistant or Google Translate) is already ~2-8x larger than AlphaStar\u2019s ~1.3e23, costing ~$2-8M.\u201d&nbsp;<a href=\"https://docs.google.com/document/d/1qjgBkoHO_kDuUYqy_Vws0fpf-dG5pTU4b8Uej6ff2Fg/edit#heading=h.nc2d14p8i1pd\"><u>p. 36</u></a> \u201c[N]ote that there will probably be a non-trivial delay between the first time a training run of size X is completed and the first time such a training run is published, and my forecasts are about the former\u201d.&nbsp;<a href=\"https://docs.google.com/document/d/1qjgBkoHO_kDuUYqy_Vws0fpf-dG5pTU4b8Uej6ff2Fg/edit#heading=h.nc2d14p8i1pd\"><u>p. 37</u></a></p></div></li></ol>", "user": {"username": "rosehadshar"}}, {"_id": "kHqfZczkcp5Wp4yvW", "title": "Carl Shulman on AI takeover mechanisms (& more): Part II of Dwarkesh Patel interview for The Lunar Society", "postedAt": "2023-07-25T18:31:47.958Z", "htmlBody": "<p><a href=\"https://www.dwarkeshpatel.com/p/carl-shulman#details\">Part I</a> has been linkposted before, &nbsp;but I thought it was worth signal-boosting the second part separately.&nbsp;</p><p>The link is to a transcript, but you can watch the interview on <a href=\"https://youtu.be/KUieFuV1fuo\">Youtube</a> or listen wherever you get your podcasts (here are the <a href=\"https://spoti.fi/3S5g2YK\">Spotify</a> and <a href=\"https://apple.co/3oBack9\">Apple Podcasts</a> links)</p><p>&nbsp;</p><p>Self-recommending, and the following quotes are all from Carl.</p><p>&nbsp;</p><p>On the likelihood of forcible takeover:&nbsp;</p><blockquote><p>The answer I give will differ depending on the day. In the 2000s, before the deep learning revolution, I might have said 10% and part of it was that I expected there would be a lot more time for efforts to build movements, to prepare to better handle these problems in advance. But that was only some 15 years ago and we did not have 40 or 50 years as I might have hoped and the situation is moving very rapidly now. <strong>At this point depending on the day I might say one in four or one in five. [emphasis added]</strong></p></blockquote><p>&nbsp;</p><p>On why Carl is not more pessimistic about the likelihood of forcible takeover:</p><blockquote><p>[A] lot of that is driven by this intelligence explosion dynamic where our attempts to do alignment have to take place in a very, very short time window because if you have a safety property that emerges only when an AI has near human level intelligence, that's potentially deep into this intelligence explosion [...]</p><p>..[A]s we approach that kind of AI capability we're approaching that from weaker systems like these predictive models right now that are starting off with less situational awareness. [...]</p><p>An infinite-limit perfect-AI that can always figure out exactly when it would get caught and when it wouldn't might navigate that with a motivation of only conditional honesty or only conditional loyalties. But for systems that are limited in their ability to reliably determine when they can get away with things and when not including our efforts to actively construct those situations and including our efforts to use interpretability methods to create neural lie detectors. It's quite a challenging situation to develop those motives.&nbsp;</p><p>We don't know when in the process those motives might develop and <strong>if the really bad sorts of motivations develop relatively later in the training process at least with all our countermeasures, then by that time we may have plenty of ability to extract AI assistance on further strengthening the quality of our adversarial examples, the strength of our neural lie detectors, the experiments that we can use to reveal and elicit and distinguish between different kinds of reward hacking tendencies and motivations</strong>. <strong>[emphasis added]</strong></p></blockquote><p>&nbsp;</p><p>On why deception might be easier to detect than you'd expect:</p><blockquote><p>...[I]f the AIs know they are misaligned ... it's pretty plausible they know that and they're thinking about ... when they would [ e.g. put backdoors into the code]</p><p>&nbsp;So that means the knowledge is present in the system \u2014 Ah, here is the circumstance where I would try to do the takeover and this is how I would tell whether this is the time for the takeover or is this an elaborate test by the humans, an adversarial example.</p><p>&nbsp;If gradient descent is working fine and there's any way to slightly jiggle the weights to make it more likely to deliver a more acceptable answer, we ask the AI: can you think of any circumstances where if we put a copy of you into that situation, it would then violate some of the various constraints?&nbsp;</p><p>It would tell a lie, it would insert a backdoor into a program it wrote when it was not supposed to. If the model knows yeah, I would look for signs of consistency of the information I was being presented with, certain checksums failing could indicate that it was actually a constructed example, a simulation.&nbsp;</p><p>...We could do something called relaxed adversarial training. If we can find how those things are represented within the AI, we can induce a hallucination that it has seen that those checksums have been passed. We can then ask, well does that cause the forbidden behavior?&nbsp;</p></blockquote><p>&nbsp;</p><p>On learning from climate change:</p><blockquote><p>Why might [coordination between governments on AI] fail? ... When science pins something down absolutely overwhelmingly then you can get to a situation where most people mostly believe it. Climate change was something that was a subject of scientific study for decades and gradually over time the scientific community converged on a quite firm consensus that human activity releasing carbon dioxide and other greenhouse gases was causing the planet to warm. We've had increasing amounts of action coming out of that. Not as much as would be optimal particularly in the most effective areas like creating renewable energy technology and the like.&nbsp;</p><p>[...]</p><p>That's the kind of reason why I'm very enthusiastic about experiments and research that helps us to better evaluate the character of the problem in advance. Any resolution of that uncertainty helps us get better efforts in the possible worlds where it matters the most and hopefully we'll have that and it'll be a much easier epistemic environment. But the environment may not be that easy because deceptive alignment is pretty plausible.</p></blockquote><p>&nbsp;</p><p>On the median far-future outcome of AI:</p><blockquote><p>... I think there's a lot of reason to expect that you would have significant diversity for something coming out of our existing diverse human society.</p></blockquote><p>&nbsp;</p><p>On whether Carl expects<a href=\"https://forum.effectivealtruism.org/posts/8c7LycgtkypkgYjZx/agi-and-the-emh-markets-are-not-expecting-aligned-or\"> interest rates to rise in the coming years</a>:</p><blockquote><p>Yeah. So in the case we were talking about where this intelligence explosion happening in software to the extent that investors are noticing that, yeah they should be willing to lend money or make equity investments in these firms or demanding extremely high interest rates because if it's possible to turn capital into twice as much capital in a relatively short period and then more shortly after that, <strong>then yeah you should demand a much higher return [emphasis added].</strong> Assuming there's competition among companies or coalitions for resources, whether that's investment or ownership of cloud compute. That would happen before you have so much investor cash making purchases and sales on this basis, you would first see it in things like the valuations of the AI companies, valuations of AI chip makers, and so far there have been effects.</p></blockquote><p>&nbsp;</p><p>On the Carl Shulman production function:</p><blockquote><p>I've also had a very weird professional career that has involved a much much higher proportion than is normal of trying to build more comprehensive models of the world. That included being more of a journalist trying to get an understanding of many issues and many problems that had not yet been widely addressed but do a first pass and a second pass dive into them.&nbsp;</p><p>[...]</p><p>My approach compared to some other people in forecasting and assessing some of these things, I try to obtain and rely on any data that I can find that is relevant. I try early and often to find factual information that bears on some of the questions I've got, especially in a quantitative fashion, do the basic arithmetic and consistency checks and checksums on a hypothesis about the world. Do that early and often. And I find that's quite fruitful and that people don't do it enough.&nbsp;</p><p>Things like with the economic growth, just when someone mentions the diminishing returns, I immediately ask hmm, okay, so you have two exponential processes. What's the ratio between the doubling you get on the output versus the input? And find oh yeah, for computing and information technology and AI software it's well on the one side. There are other technologies that are closer to neutral.&nbsp;</p><p>Whenever I can go from here's a vague qualitative consideration in one direction and here's a vague qualitative consideration in the other direction, I try and find some data, do some simple Fermi calculations, back of the envelope calculations and see if I can get a consistent picture of the world being one way or the world being another.&nbsp;</p><p>I also try to be more exhaustive compared to some. I'm very interested in finding things like taxonomies of the world where I can go systematically through all of the possibilities. For example in <a href=\"https://www.openphilanthropy.org/wp-content/uploads/Carl_Shulman_08-19-16_public.pdf\">my work with Open Philanthropy</a> and previously on global catastrophic risks I wanted to make sure I'm not missing any big thing, anything that could be the biggest thing....</p><p>So I would do things like go through all of the different major scientific fields from anthropology to biology, chemistry, computer science, physics. What are the doom stories or candidates for big things associated within each of these fields... Go through all of the lists that people have made of threats of doom, search for previous literature of people who have done discussions and then yeah, have a big spreadsheet of what the candidates are.&nbsp;</p></blockquote>", "user": {"username": "alejandro"}}, {"_id": "GTYkyzF5DnXa4xwJM", "title": "Where should I donate for animal welfare?", "postedAt": "2023-07-24T13:44:11.806Z", "htmlBody": "<p>I'm a longtime GiveWell donor looking to diversify my giving somewhat. What are the best options for donating in animal welfare? I value certainty, track-record, etc. over something more speculative but potentially higher-impact.<br><br>My current sense is that my best options are <a href=\"https://funds.effectivealtruism.org/funds/animal-welfare\">https://funds.effectivealtruism.org/funds/animal-welfare</a> and <a href=\"https://animalcharityevaluators.org/donation-advice/recommended-charity-fund/.\">https://animalcharityevaluators.org/donation-advice/recommended-charity-fund/.</a> Are those reasonable options? Anything else I should consider?</p>", "user": {"username": "Jonathan Paulson"}}, {"_id": "HXoHFHCSFX7Cxn7hC", "title": "Summary of posts on XPT forecasts on AI risk and timelines", "postedAt": "2023-07-25T08:42:55.273Z", "htmlBody": "<p>In 2022, the&nbsp;<a href=\"https://forecastingresearch.org/\"><u>Forecasting Research Institute</u></a> (FRI) ran the Existential Risk Persuasion Tournament (XPT). Over the course of four months, 169 forecasters, including 80 superforecasters<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref1rq5frqp0vn\"><sup><a href=\"#fn1rq5frqp0vn\">[1]</a></sup></span>&nbsp;and 89 experts, forecasted on various questions related to existential and catastrophic risk. Forecasters moved through a four-stage deliberative process that was designed to incentivize them not only to make accurate predictions but also to provide persuasive rationales that boosted the predictive accuracy of others\u2019 forecasts.</p><p>Forecasters stopped updating their forecasts on 31st October 2022, and are not currently updating on an ongoing basis. FRI plans to run future iterations of the tournament, and open up the questions more broadly for other forecasters.</p><p>We're in the process of publishing a series of Forum posts on the the XPT results. <strong>This post summarises all of the posts in that series on AI risk and AI timelines</strong></p><p>(You can see results from the tournament overall&nbsp;<a href=\"https://forecastingresearch.org/s/XPT.pdf\"><u>here</u></a>.)</p><p>Posts in this series which relate to AI risk and timelines:</p><ul><li>Summary of posts on XPT forecasts on AI risk and timelines (this post)</li><li><a href=\"https://forum.effectivealtruism.org/posts/K2xQrrXn5ZSgtntuT/what-do-xpt-forecasts-tell-us-about-ai-risk-1\"><u>What do XPT forecasts tell us about AI risk?</u></a></li><li><a href=\"https://forum.effectivealtruism.org/posts/KGGDduXSwZQTQJ9xc/what-do-xpt-forecasts-tell-us-about-ai-timelines\"><u>What do XPT forecasts tell us about AI timelines?</u></a><ul><li><a href=\"https://forum.effectivealtruism.org/posts/ccw9v9giKxg8nyLhp/xpt-forecasts-on-some-biological-anchors-inputs\">XPT forecasts on (some) bio anchors inputs</a></li></ul></li><li>Expected shape of AI impacts on society (forthcoming) <i>[Edited to add: We decided to cut the \"Expected shape of AI impacts on society\" post from the series, and added a post on </i><a href=\"https://forum.effectivealtruism.org/posts/saAXc8zsFgZuxFM6L/xpt-forecasts-on-some-direct-approach-model-inputs\"><i>some key inputs from Epoch's direct approach model</i></a><i>]</i></li></ul><p>This post briefly summarizes the main findings across those posts.</p><h1>A summary of the main results</h1><h2>AI risk</h2><figure class=\"image image_resized\" style=\"width:90.67%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HXoHFHCSFX7Cxn7hC/do3y6wxuqs61icp1erbg\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HXoHFHCSFX7Cxn7hC/y1a1vazlrf5lcaeyf8ki 100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HXoHFHCSFX7Cxn7hC/foqun3mv0lsaetwm5drq 200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HXoHFHCSFX7Cxn7hC/skiwbzcchyhqatzbjw8g 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HXoHFHCSFX7Cxn7hC/ppjopgb8a8bgzerx1hpg 400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HXoHFHCSFX7Cxn7hC/lsovyvn6iqmwpctsjmpd 500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HXoHFHCSFX7Cxn7hC/z3ypoqb3jhq0umdtyhhv 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HXoHFHCSFX7Cxn7hC/lpbevbns3nsgs0xfgnxz 700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HXoHFHCSFX7Cxn7hC/iajsh3as2dofg9ocvadl 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HXoHFHCSFX7Cxn7hC/ex3ujmuyzqnlrri9m9d6 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HXoHFHCSFX7Cxn7hC/aez4hhejxd5r4z2xxkqm 982w\"></figure><p>*Question details and resolution criteria are available&nbsp;<a href=\"https://forecastingresearch.org/s/XPT.pdf#page=133\"><u>here</u></a>. **Question details and resolution criteria are available&nbsp;<a href=\"https://forecastingresearch.org/s/XPT.pdf#page=135\"><u>here</u></a>.</p><ul><li><strong>XPT superforecasters predicted that&nbsp;</strong><i><strong>catastrophic</strong></i><strong> and&nbsp;</strong><i><strong>extinction</strong></i><strong> risk from AI by 2030 is very low&nbsp;</strong>(0.01% catastrophic risk and 0.0001% extinction risk).</li><li><strong>XPT superforecasters predicted that&nbsp;</strong><i><strong>catastrophic</strong></i><strong> risk from nuclear weapons by 2100 is almost twice as likely as&nbsp;</strong><i><strong>catastrophic</strong></i><strong> risk from AI by 2100&nbsp;</strong>(4% vs 2.13%).</li><li><strong>XPT superforecasters predicted that&nbsp;</strong><i><strong>extinction</strong></i><strong> risk from AI by 2050 and 2100 is roughly an order of magnitude larger than extinction</strong><i><strong>&nbsp;</strong></i><strong>risk from nuclear weapons, which in turn is an order of magnitude larger than non-anthropogenic extinction</strong><i><strong>&nbsp;</strong></i><strong>risk&nbsp;</strong>(see&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/K2xQrrXn5ZSgtntuT/what-do-xpt-forecasts-tell-us-about-ai-risk-1#Forecasts_on_other_risks\">here</a> for details).</li><li><strong>XPT superforecasters more than quadruple their forecasts for AI extinction risk by 2100 if conditioned on AGI or TAI by 2070</strong> (see&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/K2xQrrXn5ZSgtntuT/what-do-xpt-forecasts-tell-us-about-ai-risk-1#How_sensitive_are_XPT_AI_risk_forecasts_to_AI_timelines_\">here</a> for details).&nbsp;</li><li><strong>XPT domain experts predicted that AI extinction risk by 2100 is far greater than XPT superforecasters do&nbsp;</strong>(3% for domain experts, and 0.38% for superforecasters by 2100).</li><li><strong>Although XPT superforecasters and experts disagreed substantially about AI risk, both superforecasters and experts still prioritized AI as an area for marginal resource allocation&nbsp;</strong>(see&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/K2xQrrXn5ZSgtntuT/what-do-xpt-forecasts-tell-us-about-ai-risk-1#Resource_allocation_to_different_risks\">here</a> for details).</li><li><strong>It\u2019s unclear how accurate these forecasts will prove, particularly as superforecasters have not been evaluated on this timeframe before.</strong><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefwakh05xt8cf\"><sup><a href=\"#fnwakh05xt8cf\">[2]</a></sup></span></li></ul><h2>AI timelines</h2><ul><li><strong>XPT superforecasters predict a 50% chance that advanced AI</strong><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefb6l8qrpt00n\"><sup><a href=\"#fnb6l8qrpt00n\">[3]</a></sup></span><strong>&nbsp;exists</strong>&nbsp;<strong>by 2060.</strong></li><li><strong>XPT superforecasters predict that very powerful AI by 2030 is very unlikely&nbsp;</strong>(1% that Nick Bostrom affirms AGI by 2030; 3% that the compute required for TAI is attainable by 2030 (taking Ajeya Cotra\u2019s biological anchors model as given, and using XPT superforecaster forecasts as some of the inputs)).</li><li><strong>In the XPT postmortem survey, superforecasters predicted:</strong><ul><li><strong>13% chance of AGI by 2070,&nbsp;</strong>defined as \u201cany scenario in which cheap AI systems are fully substitutable for human labor, or if AI systems power a comparably profound transformation (in economic terms or otherwise) as would be achieved in such a world.\u201d</li><li><strong>3.75% chance of TAI by 2070,&nbsp;</strong>defined as \u201c\u200b\u200bany scenario in which global real GDP during a year exceeds 115% of the highest GDP reported in any full prior year.\u201d</li></ul></li></ul><p>It\u2019s unclear how accurate these forecasts will prove, particularly as superforecasters have not been evaluated on this timeframe before.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref0exc7pyq2w3v\"><sup><a href=\"#fn0exc7pyq2w3v\">[4]</a></sup></span></p><h2>The bio anchors model</h2><ul><li>As part of the XPT we asked participants to forecast several questions that allowed us to infer inputs to Ajeya Cotra\u2019s&nbsp;<a href=\"https://docs.google.com/document/d/1IJ6Sr-gPeXdSJugFulwIpvavc0atjHGM82QjIfUSBGQ/edit#\"><u>biological anchors model</u></a>. XPT superforecasters\u2019 predictions differ substantially from Cotra\u2019s on hardware costs, willingness to spend and algorithmic efficiency:</li></ul><figure class=\"image image_resized\" style=\"width:88%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HXoHFHCSFX7Cxn7hC/c7rccxihys5u3tel9m3o\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HXoHFHCSFX7Cxn7hC/yvcht0pspohcb3pdrvvw 100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HXoHFHCSFX7Cxn7hC/qmtzpvwgzsnwwwbg7m7g 200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HXoHFHCSFX7Cxn7hC/am3e3esnktjl88merrxr 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HXoHFHCSFX7Cxn7hC/iojvqdfvdodxlcs92vvi 400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HXoHFHCSFX7Cxn7hC/rwkgpxcputpapfolkx8b 500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HXoHFHCSFX7Cxn7hC/yga5pas8mgzxndmso0il 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HXoHFHCSFX7Cxn7hC/qlcf4pjmw9czndqxicz5 700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HXoHFHCSFX7Cxn7hC/tolxstcselfocv6rr56p 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HXoHFHCSFX7Cxn7hC/ayedooophwqhyr1rlk9a 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HXoHFHCSFX7Cxn7hC/t5eisjg6csyf56afng9a 955w\"></figure><ul><li>There are no XPT forecasts relating to other inputs to Cotra\u2019s model, most notably the 2020 training computation requirements distribution.</li><li>Taking Cotra\u2019s model and 2020 training computation requirements distribution as given, and using relevant XPT superforecaster forecasts as inputs, leads to substantial differences in model output:</li></ul><figure class=\"image image_resized\" style=\"width:90.1%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HXoHFHCSFX7Cxn7hC/jg24m4lrregmfw5xgzq9\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HXoHFHCSFX7Cxn7hC/gglvcskfwfbnsmtu084v 100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HXoHFHCSFX7Cxn7hC/bx8egjqu1lf6enb8zd3a 200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HXoHFHCSFX7Cxn7hC/w6ipbjq7c1rymwrkfobg 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HXoHFHCSFX7Cxn7hC/ihdkdn7yugefkx3crpbm 400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HXoHFHCSFX7Cxn7hC/eqvcnobgpr4wy4ibannw 500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HXoHFHCSFX7Cxn7hC/xgq1wcydxe67ffnzr5kg 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HXoHFHCSFX7Cxn7hC/xezmy8g4bdxyqocxpau1 700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HXoHFHCSFX7Cxn7hC/f2obxilbbldlrn7ns7hb 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HXoHFHCSFX7Cxn7hC/omwlgnnvbo5gmdqqomti 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HXoHFHCSFX7Cxn7hC/psikuxet3etcn5ey8iim 979w\"></figure><p>*The most aggressive and most conservative estimates can be considered equivalent to 90% confidence interval for the median estimate.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefpcevf95631r\"><sup><a href=\"#fnpcevf95631r\">[5]</a></sup></span></p><ul><li>Using median XPT inputs implies median transformative AI (TAI) timelines of around ~2090, compared to Cotra\u2019s 2050 median timeline in 2020, and her&nbsp;<a href=\"https://www.lesswrong.com/posts/AfH2oPHCApdKicM4m/two-year-update-on-my-personal-ai-timelines#Making_a_one_time_upward_adjustment_for__2020_FLOP_____\"><u>2040 median timeline</u></a> in 2022.</li><li>Using 90% confidence interval (CI) XPT inputs:<ul><li>Even the most aggressive XPT superforecaster inputs imply a lower probability that the compute required for training TAI is available than Cotra predicts, and the most conservative XPT superforecaster inputs predict TAI by 2100 as less likely than not.</li></ul></li><li>Most of the difference in outputs comes down to differences in forecasts on:<ul><li>Compute price halving time from 2025 to 2100</li><li>Doubling time of spending on compute for the most expensive training run from 2025 onwards</li></ul></li><li>Note that:<ul><li>Both Cotra and XPT forecasts on FLOP/$ are already inaccurate. However, Cotra's will necessarily prove more accurate and the current estimate is outside the XPT 90% CI.</li><li>The XPT forecast for the most expensive training run (by 2024) is already inaccurate, but it's not yet clear whether this forecast is more or less accurate than Cotra's forecast for 2025, which remains much higher than current estimates.</li></ul></li><li>XPT superforecasters\u2019 all-things-considered TAI timelines are longer than those suggested by using Cotra\u2019s model with XPT inputs. When asked about AI timelines in a survey at the end of the XPT, the median superforecaster put a probability of 3.75% on TAI by 2070. In contrast, Cotra\u2019s model with superforecaster XPT inputs suggests a ~35%<strong>&nbsp;</strong>probability of TAI by 2070.</li><li><strong>To the extent that timeline beliefs are based on the biological anchors model,&nbsp;</strong><i><strong>and&nbsp;</strong></i><strong>to the extent that these beliefs are based on a training requirements distribution similar to Cotra\u2019s, then the actual value of the inputs on compute price halving time and doubling time of compute spending could have a significant bearing on expected timelines.</strong></li></ul><h2>Expected shape of AI impacts on society</h2><ul><li>This post will discuss in layperson terms what we might expect AI's impacts on society to be in the next decade, based on XPT forecasts.&nbsp;</li><li>We will discuss forecasters' views about both:<ul><li>AI capabilities progress (e.g. when will AI first win an&nbsp;<a href=\"https://www.imo-official.org/\"><u>IMO</u></a> gold medal? when will a New York Times bestseller be AI-written?)</li><li>the broad impacts of AI on society (e.g. what will labor force participation rates be? will the public view AI as a good or bad thing?)</li></ul></li><li>There was significantly more agreement (though still a noticeable spread) among tournament participants about nearer-term AI outcomes than there was about AI risks.&nbsp;</li><li>There were some key areas of disagreement: for example, compared to other tournament participants, AI domain experts generally predicted somewhat nearer dates for AI achieving certain capabilities benchmarks, and predicted a higher probability of large, longer-term impacts in some domains (e.g. the likelihood of very large GDP growth).</li></ul><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn1rq5frqp0vn\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref1rq5frqp0vn\">^</a></strong></sup></span><div class=\"footnote-content\"><p>By superforecasters, we mean seasoned forecasters with a track record of predictive accuracy on shorter-run questions in forecasting tournaments held by the Good Judgment Project.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnwakh05xt8cf\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefwakh05xt8cf\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;&nbsp;See&nbsp;<a href=\"https://www.openphilanthropy.org/research/how-feasible-is-long-range-forecasting/\">here</a> for a discussion of the feasibility of long-range forecasting.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnb6l8qrpt00n\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefb6l8qrpt00n\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Full question text (with details on criteria&nbsp;<a href=\"https://forecastingresearch.org/s/XPT.pdf#page=208\">here</a>):</p><p>When will the first unified AI system meeting all of the following criteria be trained, tested, and publicly known of?</p><p>1. Able to reliably pass a 2-hour adversarial Turing test.</p><p>2. High competency at answering questions across diverse fields of expertise.</p><p>3. High competency on interview-level problems in the APPS benchmark.</p><p>4. Able to learn the classic Atari game \u201cMontezuma\u2019s revenge\u201d in the equivalent of 100 hours or less of real-time play.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn0exc7pyq2w3v\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref0exc7pyq2w3v\">^</a></strong></sup></span><div class=\"footnote-content\"><p>See&nbsp;<a href=\"https://www.openphilanthropy.org/research/how-feasible-is-long-range-forecasting/\">here</a> for a discussion of the feasibility of long-range forecasting.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnpcevf95631r\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefpcevf95631r\">^</a></strong></sup></span><div class=\"footnote-content\"><p>For the relevant questions in the XPT, forecasters were asked to provide their 5th, 25th, 50th, 75th, and 95th percentile forecasts. In this analysis we use the term, \u2018median\u2019 to refer to analyses using the group\u2019s median forecast for the 50th percentile of each question. We use the term \u2018most aggressive\u2019 to refer to analyses using the group medians for the 5th percentile estimate of the question relating to hardware costs, and the 95th percentile estimate for the questions relating to willingness to spend and algorithmic progress. (I.e., this uses the lowest plausible hardware costs and the highest plausible willingness to spend and algorithmic efficiency to give the highest plausible likelihood of TAI.) We use the term \u2018most conservative\u2019 to refer to&nbsp; analyses using the group medians for the 95th percentile estimate of the question relating to hardware costs, and the 5th percentile estimate for the questions relating to willingness to spend and algorithmic progress. (I.e., this uses the highest plausible hardware costs and the lowest plausible willingness to spend and algorithmic efficiency to give the lowest plausible likelihood of TAI.) The most aggressive and most conservative estimates can be considered equivalent to 90% confidence interval for the median estimate. See&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/ccw9v9giKxg8nyLhp/xpt-forecasts-on-some-biological-anchors-inputs#Comparing_Cotra_and_XPT_forecasts\">here</a> for context on which XPT questions map to which biological anchors inputs.</p></div></li></ol>", "user": {"username": "Forecasting Research Institute"}}, {"_id": "Hyupm7mPgoXNu9PEW", "title": "Should you work at a leading AI lab? (including in non-safety roles)", "postedAt": "2023-07-25T16:28:30.324Z", "htmlBody": "<p><i>This post is a (slightly) edited cross-post of a new 80,000 Hours </i><a href=\"https://80000hours.org/career-reviews/working-at-an-ai-lab/\"><i>career review on working at a a leading AI lab</i></a><i>. </i><a href=\"https://www.lesswrong.com/posts/QZNbqWENLzmtSourT/should-you-work-at-a-leading-ai-lab-including-in-non-safety\"><i>See LessWrong comments here</i></a><i>.</i></p><h1>Summary</h1><p>Working at a leading AI lab is an important career option to consider, but the impact of any given role is complex to assess. It comes with great potential for career growth, and many roles could be (or lead to) highly impactful ways of <a href=\"https://80000hours.org/problem-profiles/artificial-intelligence/\">reducing the chances of an AI-related catastrophe</a> \u2014 one of the world\u2019s <a href=\"https://80000hours.org/problem-profiles/\">most pressing problems</a>. However, there\u2019s a risk of doing substantial harm in some cases. There are also roles you should probably avoid.</p><h3>Pros</h3><ul><li>Many roles have a high potential for impact by reducing risks from AI</li><li>Among the best and most robust ways to gain AI-specific career capital</li><li>Possibility of shaping the lab\u2019s approach to governance, security, and standards</li></ul><h3>Cons</h3><ul><li>Can be extremely competitive to enter</li><li>Risk of contributing to the development of harmful AI systems</li><li>Stress and frustration, especially because of a need to carefully and frequently assess whether your role is harmful</li></ul><h3>Key facts on fit</h3><p>Excellent understanding of the risks posed by future AI systems, and for some roles, comfort with a lot of quick and morally ambiguous decision making. You\u2019ll also need to be a good fit for the specific role you\u2019re applying for, whether you\u2019re in research, comms, policy, or something else (see our <a href=\"https://80000hours.org/career-reviews/working-at-an-ai-lab/#learn-more\">related career reviews</a>).</p><h2>Overall recommendation: it's complicated</h2><p>We think there are people in our audience for whom this is their highest impact option \u2014 but some of these roles might also be very harmful for some people. This means it's important to take real care figuring out whether you're in a harmful role, and, if not, whether the role is a good fit for you.</p><h3>Review status</h3><p>Based on a medium-depth investigation</p><p>This review is informed by two surveys of people with expertise about this path \u2014 one on whether you should be open to roles that advance AI capabilities (written up <a href=\"https://80000hours.org/articles/ai-capabilities/\">here</a>), and a second follow-up survey. We also performed an in-depth investigation into at least one of our key uncertainties concerning this path. Some of our views will be thoroughly researched, though it's likely there are still some gaps in our understanding, as many of these considerations remain highly debated.</p><h1><strong>Why </strong><i><strong>might</strong></i><strong> it be high-impact to work for a leading AI lab?</strong></h1><p>We think <a href=\"https://80000hours.org/career-guide/career-capital/#future-skills\">AI is likely to have transformative effects</a> over the coming decades. We also think that <a href=\"https://80000hours.org/problem-profiles/artificial-intelligence/\">reducing the chances of an AI-related catastrophe</a> is one of the <a href=\"https://80000hours.org/problem-profiles\">world\u2019s most pressing problems</a>.</p><p>So it\u2019s natural to wonder \u2014 if you\u2019re thinking about your career \u2014 whether it would be worth working in the labs that are doing the most to build, and shape, these future AI systems.</p><p>Working at a top AI lab, like <a href=\"https://www.deepmind.com/\">Google DeepMind</a>, <a href=\"https://openai.com/\">OpenAI</a>, or <a href=\"https://www.anthropic.com/\">Anthropic</a>, might be an excellent way to build <a href=\"https://80000hours.org/career-guide/career-capital/\">career capital</a> to work on reducing AI risk in the future. Their work is extremely relevant to solving this problem, which suggests you\u2019ll likely gain directly useful skills, connections, and credentials (more on this <a href=\"https://80000hours.org/career-reviews/working-at-an-ai-lab/#career-capital\">later</a>).</p><p>In fact, we suggest working at AI labs in many of our career reviews; it can be a great step in <a href=\"https://80000hours.org/career-reviews/ai-safety-research/\">technical AI safety</a> and <a href=\"https://80000hours.org/career-reviews/ai-policy-and-strategy/\">AI governance and coordination</a> careers. We\u2019ve also looked at working in AI labs in our career reviews on <a href=\"https://80000hours.org/career-reviews/information-security\">information security</a>, <a href=\"https://80000hours.org/career-reviews/software-engineering\">software engineering</a>, <a href=\"https://80000hours.org/career-reviews/alignment-data-expert\">data collection for AI alignment</a>, and <a href=\"https://80000hours.org/career-reviews/non-technical-roles-in-ai-labs/\">non-technical roles in AI labs</a>.</p><p>What\u2019s more, the importance of these organisations to the development of AI suggests that they could be huge forces for either good or bad (more <a href=\"https://80000hours.org/career-reviews/working-at-an-ai-lab/#force-for-good-or-bad\">below</a>). If the former, they might be high-impact places to work. And if the latter, there\u2019s still a chance that by working in a leading lab <a href=\"https://80000hours.org/career-reviews/working-at-an-ai-lab/#help-reduce-risk\">you may be able to reduce the risks</a>.</p><p>All that said, we think it\u2019s crucial to take an enormous amount of care before working at an organisation that might be a huge force for harm. Overall, it\u2019s complicated to assess whether it\u2019s good to work at a leading AI lab \u2014 and it\u2019ll vary from person to person, and role to role. But we think this is an important option to <i>consider</i> for many people who want to use their careers to reduce the chances of an existential catastrophe (or other harmful outcomes) resulting from the development of AI.</p><h1><strong>What relevant considerations are there?</strong></h1><h2><strong>Labs could be a huge force for good \u2014 or harm</strong></h2><p>We think that a leading \u2014 but careful \u2014 AI project could be a huge force for good, and crucial to <i>preventing</i> an AI-related catastrophe. Such a project could, for example:</p><ul><li>Engage in <a href=\"https://www.cold-takes.com/racing-through-a-minefield-the-ai-deployment-problem/#defensive-deployment\"><i>defensive deployment</i></a>: using early, safe, but powerful AI systems to make the situation safer \u2014 for example, by using AI systems to <a href=\"https://www.cold-takes.com/p/97d2a7b1-af2d-4dd4-b679-5ea8bb41c47d#alignment\">contribute to AI safety research</a>, <a href=\"https://www.cold-takes.com/p/97d2a7b1-af2d-4dd4-b679-5ea8bb41c47d#threat-assessment\">produce evidence and demonstrations of risks</a>, <a href=\"https://www.cold-takes.com/racing-through-a-minefield-the-ai-deployment-problem/#selective-information-sharing\">contribute to information security</a>, and <a href=\"https://www.cold-takes.com/racing-through-a-minefield-the-ai-deployment-problem/#selective-information-sharing\">help with monitoring the risks</a>. (Note that <a href=\"https://www.alignmentforum.org/posts/iy2o4nQj9DnQD7Yhj/discussion-with-nate-soares-on-a-key-alignment-difficulty#High_level_premises.\">whether this will be possible is debated</a>.)</li><li>Perform valuable empirical research into making sure that AI systems are safe, using state-of-the-art systems (possibly ones far more advanced than would be available outside a leading AI project)</li><li>Put <i>huge</i> effort into designing tests for danger, and credibly warning others if it does see designs of danger in its own systems</li><li>Set examples for other projects on governance, security, and adherence to standards.</li><li>Coordinate effectively with other AI companies and projects \u2014 for example, by sharing important safety findings and techniques, and possibly, if needed acquiring other projects or otherwise gaining visibility, influence, and control with which to prevent the deployment of any dangerous systems</li><li>Credibly and effectively lobby the government for <a href=\"https://www.openphilanthropy.org/research/12-tentative-ideas-for-us-ai-policy/\">helpful measures to reduce the risk</a></li></ul><p>(Read more about <a href=\"https://www.cold-takes.com/what-ai-companies-can-do-today-to-help-with-the-most-important-century/\">what AI companies can do today to reduce risks</a>).<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefenep3wu5kb5\"><sup><a href=\"#fnenep3wu5kb5\">[1]</a></sup></span></p><p>But a leading and <i>uncareful</i> \u2014 or just unlucky \u2014 AI project could be a huge danger to the world. It could, for example, generate hype and acceleration (which <a href=\"https://80000hours.org/career-reviews/working-at-an-ai-lab/#advancing-capabilities\">we\u2019d guess is harmful</a>), make it more likely (through hype, open-sourcing or other actions) that incautious players enter the field, normalise disregard for governance, standards and security, and ultimately it could even produce the very systems that cause a catastrophe.</p><p>So, in order to successfully be a force for good, a leading AI lab would need to balance continuing their development of powerful AI (and possibly even retaining a <i>leadership</i> position), whilst also appropriately prioritising doing things that reduce the risk overall.</p><p>This tightrope seems difficult to walk, with constant tradeoffs to make between success and caution. And it seems hard to assess from the outside which labs are doing this well. The top labs \u2014 as of 2023, <a href=\"https://openai.com/\">OpenAI</a>, <a href=\"https://www.deepmind.com/\">Google DeepMind</a>, and <a href=\"https://www.anthropic.com/\">Anthropic</a> \u2014 seem reasonably inclined towards safety, and it\u2019s plausible that any or all of these could be successfully walking the tightrope, but we\u2019re not really sure.</p><p>We don\u2019t feel confident enough to give concrete recommendations on which of these labs people should or should not work for. We can only really recommend that you put work into forming your own views about whether a company is a force for good. But the fact that labs <i>could</i> be such a huge force for good is part of why we think it\u2019s likely there are many roles at leading AI labs that are among the world\u2019s most impactful positions.</p><h2><strong>It\u2019s often excellent career capital</strong></h2><p>Top AI labs are high-performing, rapidly growing organisations. In general, one of the <a href=\"https://80000hours.org/career-guide/career-capital/#best-career-capital-steps\">best ways to gain career capital</a> is to go and work with any high-performing team \u2014 you can just learn a huge amount about <i>getting stuff done</i>. They also have excellent reputations more widely (AI is one of the world\u2019s most sought-after fields right now, and the top labs are top for a reason). So you get the credential of saying you\u2019ve worked in a leading lab, and you\u2019ll also gain lots of dynamic, impressive connections. So even if we didn\u2019t think the development of AI was a <a href=\"https://80000hours.org/problem-profiles/\">particularly pressing problem</a>, they\u2019d already seem good for career capital.</p><p>But you will also learn a huge amount about and make connections within AI in particular, and, in some roles, gain technical skills which could be much harder to learn elsewhere.</p><p>We think that, if you\u2019re early in your career, this is probably the biggest effect of working for a leading AI lab, and the career capital is (generally) a more important consideration than the direct impact of the work. You\u2019re probably not going to be having much impact at all, whether for good or for bad, when you\u2019re just getting started.</p><p>However, your <i>character</i> is also shaped and built by the jobs you take, and matters a lot for your long-run impact, so is <a href=\"https://80000hours.org/career-guide/career-capital/#career-capital-questions\">one of the components of career capital</a>. Some experts we\u2019ve spoken to warn against working at leading AI labs because you should always assume that you are psychologically affected by the environment you work in. That is, there\u2019s a risk you change your mind without ever encountering an argument that you\u2019d currently endorse (for example, you could end up thinking that it\u2019s much less important to ensure that AI systems are safe, purely because that\u2019s the view of people around you). Our impression is that leading labs <i>are</i> increasingly concerned about the risks, which makes this consideration less important \u2014 but we still think it should be taken into account in any decision you make. There are ways of mitigating this risk, <a href=\"https://80000hours.org/career-reviews/working-at-an-ai-lab/#mitigate-downsides\">which we\u2019ll discuss later</a>.</p><p>Of course, it\u2019s important to compare working at an AI lab with other ways you might gain career capital. For example, to get into <a href=\"https://80000hours.org/career-reviews/ai-safety-researcher\">technical AI safety research</a>, you may want to go do a PhD instead. Generally, the best option for career capital will depend on a number of factors, including the <a href=\"https://80000hours.org/career-reviews/working-at-an-ai-lab/career-guide/career-planning/#have-a-longer-term-vision\">path you\u2019re aiming for longer term</a> and your <a href=\"https://80000hours.org/career-guide/personal-fit/\">personal fit for the options in front of you</a>.</p><h2><strong>You might advance AI capabilities, which could be (really) harmful</strong></h2><p>We\u2019d guess that, all else equal, we\u2019d prefer that progress on AI capabilities was slower.</p><p>This is because it seems plausible that <a href=\"https://80000hours.org/problem-profiles/artificial-intelligence/#when-can-we-expect-to-develop-transformative-AI\">we could develop transformative AI fairly soon</a> (potentially in the next few decades). This suggests that we could also build potentially <a href=\"https://80000hours.org/problem-profiles/artificial-intelligence/#aps-systems\"><i>dangerous</i></a> AI systems fairly soon \u2014 and the sooner this occurs the less time society has to successfully mitigate the risks. As a broad rule of thumb, <a href=\"https://www.lesswrong.com/posts/uFNgRumrDTpBfQGrs/let-s-think-about-slowing-down-ai\">less time to mitigate risks seems <i>likely</i> to mean that the risks are higher overall</a>.</p><p>But that\u2019s not <i>necessarily</i> the case. There are reasons to think that advancing at least some kinds of AI capabilities could be beneficial. Here are a few:</p><ul><li>This distinction between \u2018capabilities\u2019 research and \u2018safety\u2019 research is extremely fuzzy, and we have a <a href=\"https://80000hours.org/articles/ai-capabilities/#expert-8-overall-i-think-there-is-a-lot-of-value-for-people-who-are-concerned-about-ai-extremeexistential-risks-to\">somewhat poor track record</a> of predicting which areas of research will be beneficial for safety work in the future. This suggests that work that advances some (and perhaps many) kinds of capabilities faster may be useful for reducing risks.</li><li>Moving faster could <a href=\"https://www.cold-takes.com/racing-through-a-minefield-the-ai-deployment-problem/\">reduce the risk that AI projects that are <i>less</i> cautious than the existing ones can enter the field</a>.</li><li>Lots of work that makes models more useful \u2014 and so could be classified as capabilities (for example, work to align existing large language models) \u2014 probably does so without increasing the risk of danger . This kind of work might allow us to use these models to <i>reduce</i> the risk overall, for example, through the kinds of defensive deployment discussed <a href=\"https://80000hours.org/career-reviews/working-at-an-ai-lab/#force-for-good-or-bad\">earlier</a>.</li><li>It\u2019s possible that the later we develop transformative AI, the faster (and therefore more dangerously) everything will play out, because other currently-constraining factors (like the amount of compute available in the world) could continue to grow independently of technical progress. Slowing down advances <i>now</i> could <i>increase</i> the rate of development in the future, when we\u2019re much closer to being able to build transformative AI systems. This would give the world less time to conduct safety research with models that are very similar to ones we should be concerned about but which aren\u2019t themselves dangerous. (When this is caused by a growth in the amount of compute, it\u2019s often referred to as a <a href=\"https://aiimpacts.org/hardware-overhang/\"><i>hardware overhang</i></a>.)</li></ul><p>Overall, we think not all capabilities research is made equal \u2014 and that many roles advancing AI capabilities (especially more junior ones) will not be harmful, and could be beneficial. That said, <strong>our best guess is that the broad rule of thumb that there will be less time to mitigate the risks is more important than these other considerations</strong> \u2014 and as a result, broadly advancing AI capabilities should be regarded overall as probably harmful.</p><p>This raises an important question. In our article on whether it\u2019s <a href=\"https://80000hours.org/articles/harmful-career/\">ever OK to take a harmful job to do more good</a>, we ask whether it might be <i>morally impermissible</i> to do a job that causes serious harm, even if you think it\u2019s a good idea on net.</p><p>It\u2019s really unclear to us how jobs that advance AI capabilities fall into the <a href=\"https://80000hours.org/articles/harmful-career/#wheres-the-line-between-permissible-and-impermissible-negative-impact-a-step-by-step-process-for-deciding\">framework proposed in that article</a>.</p><p>This is made even more complicated by our view that <a href=\"https://80000hours.org/career-reviews/working-at-an-ai-lab/#force-for-good-or-bad\">a leading AI project could be crucial to preventing an AI-related catastrophe</a> \u2014 and failing to <i>prevent</i> a catastrophe seems, in many value systems, similarly bad to causing one.</p><p>Ultimately, answering the question of moral permissibility is going to depend on ethical considerations about which we\u2019re just <a href=\"https://80000hours.org/articles/moral-uncertainty/\">hugely uncertain</a>. Our guess is that it\u2019s good for us to sometimes recommend that people work in roles that could harmfully advance AI capabilities \u2014 but we could easily change our minds on this.</p><p>For another article, we asked the 22 people we thought would be most informed about working in roles that advance AI capabilities \u2014 and who we knew had a range of views \u2014 to write a summary of their takes on the question: if you want to help prevent an AI-related catastrophe, should you be open to roles that also advance AI capabilities, or steer clear of them? There\u2019s a range of views among the 11 responses we received, which we\u2019ve <a href=\"https://80000hours.org/articles/ai-capabilities/\">published here</a>.</p><h2><strong>You may be able to help labs reduce risks</strong></h2><p>As far as we can tell, there are many roles at leading AI labs where the primary effects of the roles could be to reduce risks.</p><p>Most obviously, these include research and engineering roles focused on <a href=\"https://80000hours.org/career-reviews/ai-safety-researcher/\">AI safety</a>. Labs also often don\u2019t have enough staff in relevant teams to develop and implement good internal policies (like on evaluating and <a href=\"https://en.wikipedia.org/wiki/Red_team\">red-teaming</a> their models and wider activity), or to figure out what they should be lobbying governments for (we\u2019d guess that many of the top labs would lobby for things that reduce existential risks). We\u2019re also particularly excited about people working in <a href=\"https://80000hours.org/career-reviews/information-security/\">information security</a> at labs to reduce risks of theft and misuse.</p><p>Beyond the direct impact of your role, you may be able to help guide internal culture in a more risk-sensitive direction. You probably won\u2019t be able to influence many specific decisions, unless you\u2019re very senior (or have the potential to become very senior), but if you\u2019re a good employee you can just generally become part of the \u2018conscience\u2019 of an organisation. Just like anyone working at a powerful institution, you can also \u2014 if you see something really harmful occurring \u2014 consider organising internal complaints, whistleblowing, or even resigning. Finally, you could help foster good, cooperative working relationships with other labs as well as the public.</p><p>To do this well, you\u2019d need the sorts of social skills that let you climb the organisational ladder and bring people round to your point of view. We\u2019d also guess that you should spend almost all of your work time focused on doing your job well; criticism is usually far more powerful coming from a high performer.</p><p>There\u2019s a risk that doing this badly could <a href=\"https://80000hours.org/articles/accidental-harm\">accidentally cause harm</a>, for example, by making people think that arguments for caution are unconvincing.</p><h1><strong>How can you mitigate the downsides of this option?</strong></h1><p>There are a few things you can do to mitigate the downsides of taking a role in a leading AI lab:</p><ul><li><strong>Don\u2019t work in certain positions</strong> unless you feel <i>awesome</i> about the lab being a <a href=\"https://80000hours.org/career-reviews/working-at-an-ai-lab/#force-for-good-or-bad\">force for good</a>. This includes some technical work, like work that improves the efficiency of training very large models, whether via architectural improvements, optimiser improvements, improved reduced-precision training, or improved hardware. We\u2019d also guess that roles in marketing, commercialisation, and fundraising tend to contribute to hype and acceleration, and so are somewhat likely to be harmful.</li><li><strong>Think carefully, and take action if you need to.</strong> Take the time to think carefully about the work you\u2019re doing, and how it\u2019ll be disclosed outside the lab. For example, will publishing your research lead to <a href=\"https://80000hours.org/career-reviews/working-at-an-ai-lab/#advancing-capabilities\">harmful hype and acceleration</a>? Who should have access to any models that you build? Be an employee who pays attention to the actions of the company you\u2019re working for, and speaks up when you\u2019re unhappy or uncomfortable.</li><li><strong>Consult others.</strong> <a href=\"https://80000hours.org/articles/accidental-harm/#1-you-take-on-a-challenging-project-and-make-a-mistake-through-lack-of-expertise-or-poor-judgement\">Don\u2019t be a unilateralist</a>. It\u2019s worth discussing any role in advance with others. We can give you <a href=\"https://80000hours.org/speak-with-us/\">1-1 advice</a>, for free. If you know anyone working in the area who\u2019s concerned about the risks, discuss your options with them. You may be able to meet people through <a href=\"https://80000hours.org/community/\">our community</a>, and our <a href=\"https://80000hours.org/speak-with-us/\">advisors</a> can also help you make connections with people who can give you more nuanced and personalised advice.</li><li><strong>Continue to engage with the broader safety community.</strong> To reduce the chance that your opinions or values will drift just because of the people you\u2019re socialising with, try to find a way to spend time with people who more closely share your values. For example, if you\u2019re a researcher or engineer, you may be able to spend some of your working time with a safety-focused research group.</li><li><strong>Be ready to switch.</strong> Avoid being in a financial or psychological situation where it\u2019s just going to be really hard for you to switch jobs into something more exclusively focused on doing good. Instead, constantly ask yourself whether you\u2019d be able to make that switch, and whether you\u2019re making decisions that could make it harder to do so in the future.</li></ul><h1><strong>How to predict your fit in advance</strong></h1><p>In general, we think you\u2019ll be a better fit for working at an AI lab if you have an excellent understanding of risks from AI. If the positive impact of your role comes from being able to persuade others to make better decisions, you\u2019ll also need very good social skills. You\u2019ll probably have a better time if you\u2019re pragmatic and comfortable with making decisions that can, at times, be difficult, time-pressured, and morally ambiguous.</p><p>While a career in a leading AI lab can be rewarding and high impact for some, it\u2019s not suitable for everyone. People who should probably not work at an AI lab include:</p><ul><li>People who can\u2019t follow tight security practices: AI labs often deal with sensitive information that needs to be handled responsibly.</li><li>People who aren\u2019t able to keep their options open \u2014 that is, they aren\u2019t (for a number of possible reasons) financially or psychologically prepared to leave if it starts to seem like the right idea. (In general, <i>whatever</i> your career path, we think <a href=\"https://80000hours.org/2015/11/why-everyone-even-our-readers-should-save-enough-to-live-for-6-24-months/\">it\u2019s worth trying to build at least 6-12 months of financial runway</a>.)</li><li>People who are more sensitive than average to incentives and social pressure: you\u2019re just more likely to do things you wouldn\u2019t <i>currently</i> endorse.</li></ul><p>More specifically than that, predicting your fit will depend on the exact career path you\u2019re following, and for that you can check out our other <a href=\"https://80000hours.org/career-reviews/working-at-an-ai-lab/#learn-more\">related career reviews</a>.</p><h1><strong>How to enter</strong></h1><p>Some labs have internships (e.g. at <a href=\"https://ai-jobs.net/job/28354-research-engineer-intern-2023-london\">Google DeepMind</a>) or residency programmes (e.g. at <a href=\"https://openai.com/blog/openai-residency\">OpenAI</a>) \u2014 but the path to entering a leading AI lab can depend substantially on the specific role you\u2019re interested in. So we\u2019d suggest you look at our <a href=\"https://80000hours.org/career-reviews/working-at-an-ai-lab/#learn-more\">other career reviews</a> for more detail, as well as plenty of practical advice.</p><h2><strong>Recommended organisations</strong></h2><p>We\u2019re really not sure. It seems like <a href=\"https://openai.com/\">OpenAI</a>, <a href=\"https://www.deepmind.com/\">Google DeepMind</a>, and <a href=\"https://www.anthropic.com/\">Anthropic</a> are currently taking existential risk more seriously than other labs. Some people we spoke to have strong opinions about which of these is best, but they disagree with each other substantially.</p><p>Big tech companies like Apple, Microsoft, Meta, Amazon, and NVIDIA \u2014 which have the resources to potentially become rising stars in AI \u2014 are also worth considering, as there\u2019s a need for more people in these companies who care about AI safety and ethics. Relatedly, plenty of startups can be good places to gain career capital, especially if they\u2019re not advancing dangerous capabilities. However, the absence of teams focused on existential safety means that we\u2019d guess these are worse choices for most of our readers.</p><h1><strong>Learn more&nbsp;</strong></h1><p>Learn more about making career decisions where there\u2019s a risk of harm:</p><ul><li><a href=\"https://80000hours.org/articles/ai-capabilities/\">Anonymous advice about advancing AI capabilities</a></li><li><a href=\"https://80000hours.org/articles/harmful-career/\">Is it ever OK to take a harmful job in order to do more good?</a></li><li><a href=\"https://80000hours.org/articles/accidental-harm/\">Ways people trying to do good accidentally make things worse, and how to avoid them</a></li></ul><p>Relevant career reviews (for more specific and practical advice):</p><ul><li><a href=\"https://80000hours.org/career-reviews/ai-safety-researcher/\">AI safety technical research</a></li><li><a href=\"https://80000hours.org/career-reviews/ai-policy-and-strategy/\">AI governance and coordination</a></li><li><a href=\"https://80000hours.org/career-reviews/information-security/\">Information security</a></li><li><a href=\"https://80000hours.org/career-reviews/software-engineering/\">Software engineering</a></li><li><a href=\"https://80000hours.org/career-reviews/alignment-data-expert/\">Data collection for AI alignment</a></li><li><a href=\"https://80000hours.org/career-reviews/non-technical-roles-in-ai-labs/\">Non-technical roles in leading AI labs</a></li></ul><p>If you think you might be a good fit for this path and you\u2019re ready to start looking at job opportunities that are currently accepting applications, see our <a href=\"https://jobs.80000hours.org/?refinementList%5Btags_area%5D%5B0%5D=AI%20safety%20%26%20policy&amp;refinementList%5Bcompany_name%5D%5B0%5D=Anthropic&amp;refinementList%5Bcompany_name%5D%5B1%5D=OpenAI&amp;refinementList%5Bcompany_name%5D%5B2%5D=Deepmind\">list of opportunities for this path</a>.</p><h2><strong>Want one-on-one advice?</strong></h2><p>If you think working at a leading AI lab might be a great option for you, but you need help deciding or thinking about what to do next, the 80,000 Hours team might be able to help.</p><p>We can help you compare options, make connections, and possibly even help you find jobs or funding opportunities.&nbsp;</p><p><a href=\"https://80000hours.org/speak-with-us/?int_campaign=career-review-generic-EA-forum\">Apply to speak to the 80,000 Hours team here.</a><br>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnenep3wu5kb5\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefenep3wu5kb5\">^</a></strong></sup></span><div class=\"footnote-content\"><p>The linked article is by Holden Karnofsky. Karnofsky co-founded Open Philanthropy, 80,000 Hours\u2019 largest funder.</p></div></li></ol>", "user": {"username": "Benjamin Hilton"}}, {"_id": "ZD7KxnqfXR7cyouxP", "title": "Towards evidence gap-maps for AI safety", "postedAt": "2023-07-25T08:13:34.612Z", "htmlBody": "<p>An Evidence Gap Map (EGM) is visual tool that provides an overview of the existing evidence on a topic. They are a starting point for strategic evidence production and use. Organisations like the WHO, 3ie Impact and UNICEF produce EGMs that make evidence available in an accessible format for decision makers.<br><br>This is a post to prompt discussion about whether evidence gap-maps could and should be used by the AI safety community to inform decision-making, policy strategies, allocate resources and prioritising research efforts. They are to be interpreted cautiously. Strong recommendations can result from low confidence in effect estimates or from even low effect sizes.&nbsp;</p><p><strong>How could an AI safety evidence gap map look?</strong></p><p>This is a simplified, illustrative mockup of an EGM about interventions that alter the rate of AI progress. The shortlist of interventions and assessments of the strength of evidence has been <strong><u>made-up</u></strong> for illustrative purposes only.</p><figure class=\"table\" style=\"width:0px\"><table><tbody><tr><td style=\"padding:2px 3px;text-align:center;vertical-align:bottom\"><strong>Interventions</strong></td><td style=\"padding:2px 3px;text-align:center;vertical-align:bottom\"><strong>Data</strong></td><td style=\"padding:2px 3px;text-align:center;vertical-align:bottom\"><strong>Algorithms</strong></td><td style=\"padding:2px 3px;text-align:center;vertical-align:bottom\"><strong>Compute</strong></td></tr><tr><td style=\"padding:2px 3px;vertical-align:bottom\">A. Taxation</td><td style=\"padding:2px 3px;vertical-align:bottom\">M</td><td style=\"padding:2px 3px;vertical-align:bottom\">L</td><td style=\"padding:2px 3px;vertical-align:bottom\">L</td></tr><tr><td style=\"padding:2px 3px;vertical-align:bottom\">B. Subsidies</td><td style=\"padding:2px 3px;vertical-align:bottom\">L</td><td style=\"padding:2px 3px;vertical-align:bottom\">L</td><td style=\"padding:2px 3px;vertical-align:bottom\">M</td></tr><tr><td style=\"padding:2px 3px;vertical-align:bottom\">C. Law Enforcement</td><td style=\"padding:2px 3px;vertical-align:bottom\">M</td><td style=\"padding:2px 3px;vertical-align:bottom\">M</td><td style=\"padding:2px 3px;vertical-align:bottom\">L</td></tr><tr><td style=\"padding:2px 3px;vertical-align:bottom\">D. Education and Workforce Dev</td><td style=\"padding:2px 3px;vertical-align:bottom\">H</td><td style=\"padding:2px 3px;vertical-align:bottom\">M</td><td style=\"padding:2px 3px;vertical-align:bottom\">L</td></tr><tr><td style=\"padding:2px 3px;vertical-align:bottom\">E. Research Funding</td><td style=\"padding:2px 3px;vertical-align:bottom\">M</td><td style=\"padding:2px 3px;vertical-align:bottom\">M</td><td style=\"padding:2px 3px;vertical-align:bottom\">L</td></tr><tr><td style=\"padding:2px 3px;vertical-align:bottom\">F. Intellectual Property Rts</td><td style=\"padding:2px 3px;vertical-align:bottom\">L</td><td style=\"padding:2px 3px;vertical-align:bottom\">M</td><td style=\"padding:2px 3px;vertical-align:bottom\">L</td></tr><tr><td style=\"padding:2px 3px;vertical-align:bottom\">G. Data Privacy and Security</td><td style=\"padding:2px 3px;vertical-align:bottom\">M</td><td style=\"padding:2px 3px;vertical-align:bottom\">M</td><td style=\"padding:2px 3px;vertical-align:bottom\">L</td></tr><tr><td style=\"padding:2px 3px;vertical-align:bottom\">H. Open Data Initiatives</td><td style=\"padding:2px 3px;vertical-align:bottom\">M</td><td style=\"padding:2px 3px;vertical-align:bottom\">M</td><td style=\"padding:2px 3px;vertical-align:bottom\">L</td></tr><tr><td style=\"padding:2px 3px;vertical-align:bottom\">J. Intl Collab and Governance</td><td style=\"padding:2px 3px;vertical-align:bottom\">M</td><td style=\"padding:2px 3px;vertical-align:bottom\">M</td><td style=\"padding:2px 3px;vertical-align:bottom\">L</td></tr><tr><td style=\"padding:2px 3px;vertical-align:bottom\">K. Antitrust laws</td><td style=\"padding:2px 3px;vertical-align:bottom\">M</td><td style=\"padding:2px 3px;vertical-align:bottom\">L</td><td style=\"padding:2px 3px;vertical-align:bottom\">M</td></tr><tr><td style=\"padding:2px 3px;vertical-align:bottom\">L. Sanctions</td><td style=\"padding:2px 3px;vertical-align:bottom\">M</td><td style=\"padding:2px 3px;vertical-align:bottom\">M</td><td style=\"padding:2px 3px;vertical-align:bottom\">M</td></tr><tr><td style=\"padding:2px 3px;vertical-align:bottom\">M. Military Intervention</td><td style=\"padding:2px 3px;vertical-align:bottom\">M</td><td style=\"padding:2px 3px;vertical-align:bottom\">L</td><td style=\"padding:2px 3px;vertical-align:bottom\">M</td></tr><tr><td style=\"padding:2px 3px;vertical-align:bottom\">N. Treaties</td><td style=\"padding:2px 3px;vertical-align:bottom\">L</td><td style=\"padding:2px 3px;vertical-align:bottom\">L</td><td style=\"padding:2px 3px;vertical-align:bottom\">L</td></tr></tbody></table></figure><p>Remember, this is <strong><u>placeholder data</u></strong> for illustrative purposes, I did not review the literature.&nbsp;</p><p>As you can see, EGMs are matrices, where the rows display the interventions and the columns display the outcomes or the factors that may affect the implementation of interventions:</p><ul><li>In the rows you will see shortlisted interventions</li><li>In the columns you can see: \"compute,\" \"algorithms,\" and \"data\" which are possible indicators of AI progress.</li><li>In the cells, strength of evidence are coded under the GRADE (Grading of Recommendations, Assessment, Development, and Evaluations) framework:</li></ul><figure class=\"table\" style=\"width:0px\"><table><tbody><tr><td style=\"background-color:#ffffff;padding:2px 3px;vertical-align:bottom\"><code><strong>Certainty</strong></code></td><td style=\"background-color:#ffffff;padding:2px 3px;vertical-align:bottom\"><code><strong>What it means</strong></code></td></tr><tr><td style=\"background-color:#eeeeee;padding:2px 3px;vertical-align:bottom\"><code>Very low</code></td><td style=\"background-color:#eeeeee;padding:2px 3px;vertical-align:bottom\"><code>The true effect is probably markedly different from the estimated effect</code></td></tr><tr><td style=\"background-color:#ffffff;padding:2px 3px;vertical-align:bottom\"><code>Low</code></td><td style=\"background-color:#ffffff;padding:2px 3px;vertical-align:bottom\"><code>The true effect might be markedly different from the estimated effect</code></td></tr><tr><td style=\"background-color:#eeeeee;padding:2px 3px;vertical-align:bottom\"><code>Moderate</code></td><td style=\"background-color:#eeeeee;padding:2px 3px;vertical-align:bottom\"><code>The authors believe that the true effect is probably close to the estimated effect</code></td></tr><tr><td style=\"background-color:#ffffff;padding:2px 3px;vertical-align:bottom\"><code>High</code></td><td style=\"background-color:#ffffff;padding:2px 3px;vertical-align:bottom\"><code>The authors have a lot of confidence that the true effect is similar to the estimated effect</code></td></tr></tbody></table></figure><p>GRADE is subjective and certainty can be rated down for: risk of bias, imprecision, inconsistency, indirectness, and publication bias. Certainty can be rated up for: large magnitude of effect, exposure-response gradient and residual confounding that would decrease magnitude of effect (in situations with an effect).</p><p>In the GRADE framework you will see the term estimated effect. This is another consideration. &nbsp;Separating <i>confidence in estimates</i> or <i>quality of evidence</i> from <i>judgements about the size of effect estimates</i> (the kind you can find in a meta-analysis) is important. There can be low confidence in a high effect estimate and vice-versa.</p><p>Don't systematic reviews make these redundant? No, evidence gap maps\u2019 development can be faster, more responsive and easier for decision-makers to interpret than systematic reviews: all available studies can be included in the EGM whether or not it is complete. You can see what I mean when we move on from my simplified, illustrative example of an AI Safety EGM to an actual EBM from the Cochrane and Campbell Collaborations:</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ZD7KxnqfXR7cyouxP/tnnswxdbvgv411stz05q\"></figure>", "user": {"username": "dEAsign"}}, {"_id": "sAgExeaxCNmFSmrJT", "title": "EA Survey 2022: Geography", "postedAt": "2023-07-24T15:31:01.872Z", "htmlBody": "<h1>Summary</h1><ul><li>Although the USA (35%) and UK (14%) remain the two countries with the largest numbers of EA Survey respondents, the rest of Europe (32%) and the rest of the world (19%) account for increasingly large shares.&nbsp;</li><li>For the first time, we look at EAs\u2019 countries of origin as well as their current countries of residence, and find the largest flows are into the USA and UK.</li><li>This year, London was the city with the most respondents (7.3%), overtaking the SF Bay Area (6.2%), followed by NYC (4.5%) and DC (3.8%).</li><li>Average age differed across regions, with respondents from the USA being on average older (31.8) than those from the UK (30.2) or Europe (29.5).</li><li>Likewise, relative to the UK (25.4%) and USA (22.4%), many more respondents from Europe were students (42.0%).</li><li>The UK has significantly higher engagement levels (65.1% in the top two engagement categories) compared to Europe (56.2%), the USA (55.8%), and the rest of the world (51.5%).</li><li>Respondents from the USA (7.0 / 10) and UK (7.0 / 10) had lower average satisfaction with the EA community than respondents from Europe (7.4 / 10) or the rest of the world (7.4 / 10).</li><li>There was wide variation in the percentage of respondents who were members of local EA groups, with particularly low group membership in the USA (34.1%) and UK (34.4%).</li><li>The UK was one of the countries with the highest relative prioritization of longtermist (e.g., AI risk, nuclear- and biosecurity, existential risk) to neartermist (e.g., global poverty/health, mental health) causes, and was significantly higher on this metric than the USA.</li></ul><h1>Totals per country</h1><figure class=\"image\"><img></figure><figure class=\"image\"><img src=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/5cd41da0dfce8384d5d9f6133a8748c3e831457523d4c14e.png\" srcset=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/5cd41da0dfce8384d5d9f6133a8748c3e831457523d4c14e.png/w_720 720w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/5cd41da0dfce8384d5d9f6133a8748c3e831457523d4c14e.png/w_1440 1440w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/5cd41da0dfce8384d5d9f6133a8748c3e831457523d4c14e.png/w_2160 2160w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/5cd41da0dfce8384d5d9f6133a8748c3e831457523d4c14e.png/w_2880 2880w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/5cd41da0dfce8384d5d9f6133a8748c3e831457523d4c14e.png/w_3600 3600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/5cd41da0dfce8384d5d9f6133a8748c3e831457523d4c14e.png/w_4320 4320w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/5cd41da0dfce8384d5d9f6133a8748c3e831457523d4c14e.png/w_5040 5040w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/5cd41da0dfce8384d5d9f6133a8748c3e831457523d4c14e.png/w_5760 5760w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/5cd41da0dfce8384d5d9f6133a8748c3e831457523d4c14e.png/w_6480 6480w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/5cd41da0dfce8384d5d9f6133a8748c3e831457523d4c14e.png/w_7200 7200w\"></figure><p>Respondents to the Effective Altruism Survey (EAS) in 2022 represent countries from every continent (excluding Antarctica). The United States has, by far, the greatest number of EAS respondents, followed by the United Kingdom. Most countries with the high numbers of respondents are either predominantly native English speaking countries (USA, UK, Australia, Canada) or European. Israel somewhat bucks this trend, although English is very widely spoken in the country as a second language. Areas of the globe that stand out as having no or relatively few respondents are South East Asia, Africa, and the Middle East. In a future post, we plan to examine factors that predict higher or lower numbers of EAs and EAs per capita across different countries.<br><br><img src=\"https://lh3.googleusercontent.com/IP2h6uG4QxjDbGDqCIvKXMPjPRi9ruZoSe5MvL1bphiqAbKP8BzZcSAZWblm5AttkSZn2bgjrtb4bRtf7kRaTQiWdTgwVIn4gaMipB65TVhGm3fhlAtG7Qyu7QvR4QbfqU692IcppuFT1o6zDd3qI4o\"></p><h2>Movement between countries</h2><figure class=\"image\"><img src=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/83bb051d1422ebd53ea2ef9edf4023d24e245b79d56bf972.png\" srcset=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/83bb051d1422ebd53ea2ef9edf4023d24e245b79d56bf972.png/w_720 720w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/83bb051d1422ebd53ea2ef9edf4023d24e245b79d56bf972.png/w_1440 1440w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/83bb051d1422ebd53ea2ef9edf4023d24e245b79d56bf972.png/w_2160 2160w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/83bb051d1422ebd53ea2ef9edf4023d24e245b79d56bf972.png/w_2880 2880w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/83bb051d1422ebd53ea2ef9edf4023d24e245b79d56bf972.png/w_3600 3600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/83bb051d1422ebd53ea2ef9edf4023d24e245b79d56bf972.png/w_4320 4320w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/83bb051d1422ebd53ea2ef9edf4023d24e245b79d56bf972.png/w_5040 5040w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/83bb051d1422ebd53ea2ef9edf4023d24e245b79d56bf972.png/w_5760 5760w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/83bb051d1422ebd53ea2ef9edf4023d24e245b79d56bf972.png/w_6480 6480w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/83bb051d1422ebd53ea2ef9edf4023d24e245b79d56bf972.png/w_7200 7200w\"></figure><p>The same countries that represent the largest shares of current countries of residence are mostly also those with the largest proportions as countries of origin for respondents.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref00lu13y7i6lzm\"><sup><a href=\"#fn00lu13y7i6lzm\">[1]</a></sup></span>&nbsp;The two largest places of residence - the USA and UK - notably show a pattern consistent with an influx of respondents from other countries of origin. Switzerland, though a small country in terms of its share of respondents, also has an especially large ratio of residents to people who were born there - almost double. India also stands out as a location with substantial outflows of EAs: 1.8% of respondents reported India as a country of origin but less than half that presently reside there, with the most sizable outflow towards the USA.</p><figure class=\"image\"><img src=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/3f47db583af371558eba1a8f392ad8d996e745b815442e5d.png\" srcset=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/3f47db583af371558eba1a8f392ad8d996e745b815442e5d.png/w_720 720w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/3f47db583af371558eba1a8f392ad8d996e745b815442e5d.png/w_1440 1440w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/3f47db583af371558eba1a8f392ad8d996e745b815442e5d.png/w_2160 2160w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/3f47db583af371558eba1a8f392ad8d996e745b815442e5d.png/w_2880 2880w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/3f47db583af371558eba1a8f392ad8d996e745b815442e5d.png/w_3600 3600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/3f47db583af371558eba1a8f392ad8d996e745b815442e5d.png/w_4320 4320w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/3f47db583af371558eba1a8f392ad8d996e745b815442e5d.png/w_5040 5040w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/3f47db583af371558eba1a8f392ad8d996e745b815442e5d.png/w_5760 5760w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/3f47db583af371558eba1a8f392ad8d996e745b815442e5d.png/w_6480 6480w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/3f47db583af371558eba1a8f392ad8d996e745b815442e5d.png/w_7200 7200w\"></figure><h2>Changes across time</h2><p>Although the US and the UK still make up the largest shares of respondents, respondents who got involved in EA more recently are more likely to be from other European countries and countries outside of Europe. Based on data from 2022, the raw number of new EAs coming from the US and UK remains high, but there have been sizable and proportionally greater increases in the number of respondents coming from other countries over time.</p><p><img src=\"https://lh3.googleusercontent.com/89EwBkfcpJtXwl3LEwfUNZke7kQQJWyjM9BDskQEPygxsxNa-FsClZyadrExLRq81PNnJFrOCLY1H4jcGqY9SFtyGA1Qi22xNGZP_QPxutYg5_9VTwGUmV5Lt1hchlcJ3y9Vi4gr_l-_hwXtSF_tGGs\"><br><img src=\"https://lh4.googleusercontent.com/bMGG-3QrMdoN-GpjwQ6xvVNsXkAc0uQZYyVZWcFa4sgQCG6YUh4OZVHJQtJ4R0gOKiPjUsPTwlFRvwVHj21YE-KxV2abE-Huw74JXbWNNn-7zid0EnplTP2-e0LjtYnnRvRfxq_xMLLjHU60ltl4_4I\"></p><p>Some of these changes might of course reflect differential dropout from different locations over time. However, we see a similar pattern if we simply look at the proportion of people in these different areas across EAS survey years: in more recent years, USA and UK respondents make up a smaller relative proportion of the total, with other European countries taking up increasing proportions of the share.</p><p><img src=\"https://lh3.googleusercontent.com/W-nsSecJL9W0lDuYTD458fRp1bJDgBoSIdi-TsbVd1RQ5enCjKNWgkDuSaaLzysVA3EA6l1CsLJQpLFkaGFHZ5JQ_gMjgE-BWdnTyW1XtKb-ZXxvhdo1THX-Cc2zIq9NusSgoY1ZtAlJD6L0c5uirrQ\"></p><h1>Totals per city<br><img src=\"https://lh5.googleusercontent.com/MogCMJiRV0rJRxDxs-U0o8dlSFy5QYqqpqyDAWsgTY-tlm-cBq-iK3Qq4F5Vijjj-F7at1Bu-bH8yLdYZoHj14fjquE192_LcQeMeOQ9ROTnicTJga27sORGs8hGRlrPmjki3n76HsdDe4GLXmqdXkc\"></h1><p>As might be expected, the most prominent hubs for EAs within countries are predominantly capital cities and other major metropolitan areas, or centers of major academic activity (0r combinations of these). London was the city with the single largest share of EAs, followed by four cities/areas of the USA - most notably the Bay Area.</p><h2>Changes across time</h2><p>In the plots below, we also present how the percentages of EAS respondents coming from the top 15 hubs have changed over survey years. We would caution somewhat against using these numbers to simply infer the growth, variability/consistency, or decline of different major hubs, however. Efforts by local leaders and groups to have people&nbsp;<i>fill in&nbsp;</i>the EAS in any given year could have very large effects that might exaggerate or obscure changes in the number of community members in that location.<br><br><img src=\"https://lh3.googleusercontent.com/NqxmcFXOgiOg6o6fwsLO8G1ze4xoY8occuqPCpxvFC5QVtOttbhxIeFTWFCYUHkbVl4rOiX9GpjC-hrJMfGZBXiwtmk2dXt0WJRVm3qSlIe4COttEcCY-QNASg2_0VIPlOGnylUR_ekNDsxthwmQdLk\"></p><h1>Age<img src=\"https://lh4.googleusercontent.com/_1dXzxXAPFBpA1gMdkFBHzU49-C-_I485mqwaffAOQUNfFG8ydPRDlknUlj3jY-xWOXnZt-S-j6-twCfhM-OL8BLd3-MEf-blWpU2zKMuZ4fO0t6APKF-eynRo4apg7ML28Czbf9VgZ3zqxwPp0iZm8\"></h1><p>Across all locations, the age of EAs in the EA Survey skews quite young relative to the general population, with the bulk between 20 and 40 years of age. There is, however, some variation in age across locations. Compared with respondents in the USA, UK respondents were on average about 1.5 years younger, with respondents from the rest of Europe being younger still - on average, by over 2 years. Of countries with at least 25 respondents,<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref3zkmprzh3e3\"><sup><a href=\"#fn3zkmprzh3e3\">[2]</a></sup></span>&nbsp;respondents from Brazil had the highest average age, being nearly 13 years older than those in India on average.</p><p><img src=\"https://lh6.googleusercontent.com/HGdKsXhoDHBAKUbCs-MoI2R7hRNYj6VMQ-dz3g_i3S0XBtEtwJL1csXXu4N-z2kkiM1MjSb1pz86GE9K6LR-t3ZVF5xFHaqKs963fJCOpdvDH4wn8QqNlwedkwaLcL5x4sLvDEDu48LNH2Zx3vKvtOQ\"></p><p><img src=\"https://lh3.googleusercontent.com/MqgD2YZTgi1UQ-L5UDP73fV2t6dPVOBF5fJft8HpzqKrOAcci5jimGQlEwvACwngyvbmu2LRwpFjUl5WW3lpbCjFDDc11Z6TTSpBjWTb5JM79zDGSefjCvHOZ-rPkHPG87i4DaJPrK3nQUGtdqbVhn8\"></p><h1>Gender</h1><p>Across regions, the proportion of men (vs. women or those of other identifications) tends towards almost twice as many men as women. There appears to be substantial variation across countries and cities, although the proportions have considerable uncertainty across many locations owing to the relatively small sample sizes.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefuz4c4oe0o4e\"><sup><a href=\"#fnuz4c4oe0o4e\">[3]</a></sup></span></p><p><img src=\"https://lh3.googleusercontent.com/qqaYdrdMxKrbXGw922bd-XSd00iLxtwpW_IUnVJfMaU-Qu_LwxlZZlRj4-AUTyWcfMr4_npQyG-k9WQUgOfaQbjfYahtkKaleRVBSjXATy9N9tPbsdI_Q015Ns8xppIaJcD95dFpx_lrOdRcP-xfc80\"></p><p><img src=\"https://lh3.googleusercontent.com/EeKUlBrrY8Y6SyZBn-1vLMkpMnjKWDXYCXdytlhQqJE1kc_gtG7oV0HDPqwSzgCjIP7odQakDCSR3NpxvmXi7ROIZ4JjLynxWFVOxJUX8_sHIV3OTOm-fSXa29W_CpWZ0dhlyddU6Td4GAVjB3lfY7U\"><br>&nbsp;</p><p><img src=\"https://lh3.googleusercontent.com/flBDahg6Hw9Q7aITPLv-PEJvsqZb4U5C7kL3N_SEK9d1yIVCqVGUK4atkRzr-267MIZV-58_gJK4c5val5Prm78OV9FvYmzd-A3ORRlOn4SWdbqqSx0z0WxVK35ZiQxlFxiVi1IUSK1Dht-1W67SI0k\"></p><h1>Race</h1><p>Racial identification across locations shows substantial variability. Respondents with white racial identification make up the very highest proportions mostly in European countries. As would be expected, places such as Brazil, India, and Israel - where white is also not the most common racial or ethnic background in the general population - show much lower proportions of white respondents. Clearly, there is also substantial variation within countries regarding racial diversity of the EA community. For example, Los Angeles, Sydney, and Toronto in particular have a wider range of racial backgrounds among their respondents - considerably more than the EA make-up of the overall country they belong to.</p><p>When considering these racial identification results, at least two things should be noted. Firstly, although respondents were able to provide their own description, the default categories provided were based upon racial identifications primarily from the US, and may not translate especially well to other locations. Secondly, it may not be as informative as it would first seem to compare the racial identification of EAS respondents with the general population in the different locations. Although we can see that there is a general tendency for the racial diversity to increase with higher racial diversity in the broader population, more specific deviations from this background population level may reflect other characteristics that are over-represented in the EA community which are also associated with race, and to different degrees in different areas (for example, income and education).&nbsp;</p><p><img src=\"https://lh3.googleusercontent.com/TcQUomgl5JdTpzXaw5FQ3IUwQ7n4NeMcwTe5eqzq9YGkUxgIj1sBfWdz4hlz658xRaUg3-OUxuE_oVDbsvevbauy2wfDJ8IqVJ-yZlo2YdK9k3v0GNmalAQk9eQco8vxfviU8bphj6r3SkJ3oGa_eHY\"><br>&nbsp;</p><p><img src=\"https://lh4.googleusercontent.com/EM2VI6f2NsItNnnVgLNZMkUcfHulOa0vyNOa66z7989pv_8jywE5snE1XeN8r2zf0_aZtRLyQwRo7xwsAwm-WznHpla-rsNrk3-0jL75bh-6503eKLmVKVZB_cx5ZO1SePHpa0N_zmTv1rVV00Pw4dc\"></p><p><img src=\"https://lh3.googleusercontent.com/OoaSqeDNiGHpFXGrS9jr2KY6jZY5hbWSi4VwIU5bmplXeIOmnwwEdyfdishs3wFlqA4itndcfIyZi9oVrL8i6TOUU22B5y5l0YcGuRvwMEAVvGHYt8r27zmocz4-RUm3RKbVpKBa_hsgIoHK5ggqYTs\"></p><p><img src=\"https://lh5.googleusercontent.com/Gn6GmfRLov8iI3mdRH6q1ooJPWhd5H6RtA57uvbqQzK9uVBkk6G5bABZGULR9YS3Nr9lsw8YPZwMMJ1Y2fSYQacygmVER4EU0J9BUgix0mlNX_8HoowOduPgrmi-mtXOHJvrzZERxWJs_G6NHRw00E8\"></p><p><img src=\"https://lh4.googleusercontent.com/py1uFDqQeW1bgdxJnDKAt2mGrMrgHWNRUeLJ2_guMZKVz0wq5Hjwzw2JZ94_dF2Pmbhi8H5CZQ_Zb_LmFMVgH9WBO5AoA9VkTwAYfCOzH3NKRDe596SvUFRhvC-1_C08mE_egYzi_2RKsJKbrPlowtg\"></p><h1>Student status</h1><p>Student status varies substantially across different regions and countries. Understandably, countries with the highest proportions of students also tend to be those with younger average ages (e.g., Canada and Brazil are very low, and Hungary, India and Finland are very high - with the converse being the case for ages).&nbsp;<br>&nbsp;</p><p><img src=\"https://lh3.googleusercontent.com/fjiXlBCSThQedFwqaxpyMzroCMjYrrEOlkRyUUedSr2Ua12xA4EUMCPv7Hntwm_GTZANOmTW83RUgg_hjl05txQ_17F_J9EJWOYViFksAAE5dDfdMcHdm30x2ZDkaQSjuiJu7cQRm2UTOTqaBo_G6T4\"><br><img src=\"https://lh6.googleusercontent.com/iyJOs-5gm3hiLdqid_wsqEyOGdnMFd4lR_8sQJl_1ud1dv8bEF-rpLmb2P7snsu-R4fXfPiBYJ0bxFeb-lfh8BI1_DpT3J0yVmttmDDtYSCHEiAAWztQwvWq4OSNLHjo58AqBw9Lawp_o3ZeiOeQS3M\"><br><br><img src=\"https://lh3.googleusercontent.com/LHcw3LzZoXqUGQS6t9DoK1T7tBW297tqhDHmPgh8Z0VnZljbOiGXZJ9Kf3WsDGbPArBGtJOfIj3qeS98XNFqQEc2z-ac5IF6LxiwsjszWQuGV2CcnzKPjIJP8Kh5DVn2TsWKkXkTCC55OtAUlItx_7I\"></p><h1>Engagement</h1><p><img src=\"https://lh4.googleusercontent.com/4forAXm9BKmC6jYa_IoSqxblSBqWWRi80VfGGFbqCQjWPJ-FlYKAK4KKjLXKnwdfsEBqhGGMSj0_iuAg5Nsvdguxh69wxPcl279t6qbIawMJdibKxDtwPIOeOjVLsYGhsSZ2NKY_RXMuLTwTZmj_91w\"></p><p>Engagement is significantly higher in the UK than the USA - the two biggest countries in terms of EAS respondents. Although when treated as numeric, this amounts to an average difference of .2 on a scale of 1 to 5, the percentage of respondents falling into the highest engagement rating was over 50% higher for the UK relative to the US. This may in part be driven by the presence of Oxford, which has the highest engagement among all cities by a substantial margin, with over 90% of residents reporting being Considerably or Highly engaged. Two other major hubs, London and the Bay Area, also have very high levels of engagement on average.</p><p><img src=\"https://lh4.googleusercontent.com/nlWz77RuxPmqJZKKQ4dJEapslBmX2tJ9slvJFZuR-pWEkA2tw4KON7ZbWLNNm9E6kHOOSiB6nbei6lsDN6tp683GZTmnLsZeZ0Mbj59KIgi_e36JBNzSuM7ShmVc4MIHtJkwEeCbH5oJErNTkYScdqk\"></p><p><img src=\"https://lh4.googleusercontent.com/cHzO9as2wk0QpvkL-_3xCa8FzxthL2A2AG5VfBJJRaQpaFWaPJFDeULYRZ3k-FpxbGJFn2SJJDqvhVP5mi_qVooYMP19Fovqv-kttwvfHtRn9C7tTdPObOLfOjsQxFHjZJqX8eLboIcVhpdnYEvTwoo\"></p><h1>Satisfaction</h1><p>The two countries with the largest numbers of respondents - the USA and the UK - sit at the bottom of countries in average satisfaction with the EA community, although the average satisfaction rating is still 7 out of 10. The country with the highest satisfaction, and the only one to reach an average over 8, was Hungary. However, for most of these cases, the difference in terms of standard deviation units (i.e., Cohen\u2019s d, an indicator of effect size) from e.g., the UK and USA to Germany would typically be considered of small-to-moderate size.</p><p><img src=\"https://lh3.googleusercontent.com/B4UlniFVjyYTgRtoq-L9IoFjPSkOcGY0-JvPU93sdhrJ4dbei3TtguAN9r9TaczPs4JtBg1ON928Z2C33YDHJ1Y-hB5yiqG5KmdHqGju0ApDHJysA_zlcTAQGXyhKh81htYnt2Z-aNqUZhPCcLbI2pE\"></p><p><img src=\"https://lh4.googleusercontent.com/TVthDFnG4JwSVjbEBK_BB-wKeszBWT8LGa-4D5zzrDidqNF9rz0W_LI0v6xJpbtoh-fNwu0DbQiUB68erJ81eXAgImHibAH3E1BXFztMgMaz6UT_jqmfBAxs_EL_ZrCy3AftIiN9-Yy1GssURmvQaoE\"></p><p><img src=\"https://lh3.googleusercontent.com/Co8dZ1iIHBEcqTUXBCbo5b6yAanDeTqXC2V-K39aLGLOSL2ElcTtLgnJ66G2oeFprff0jCe-V-huFZHKG89BvtTJIltOkI3WGzjir_Nu9NojxAqkpDtwkxO0sPq9XFSDgmWZMO_cq4ewwOsf29Kqfmw\"></p><h1>Cause Prioritization</h1><p>Across regions, global poverty and health, AI risk, and biosecurity tended to be rated very highly, whereas mental health tended to be rated lowest among causes as a priority.<img src=\"https://lh6.googleusercontent.com/HPHCAI1eCK6iehddRCeyozjFbDa5OQVhIDspsDphPeyt5VscfdKDhDRCm_MkNV6D0HwBqZI10V2yORcRaCO-PNRDIpg4HRBOlOSQU6gQ8VKCqZilwxyC5vy4M0dKQmxfs1ia8kEFPo-ldzWWrRvXipQ\">One way of summarizing cause prioritization is to create indicators of leanings towards broadly \u2018longtermist\u2019 cause areas, relative to more traditional \u2018neartermist\u2019/global health and wellbeing cause areas<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref2b6w0smo1p5\"><sup><a href=\"#fn2b6w0smo1p5\">[4]</a></sup></span>&nbsp;- an approach taken when&nbsp;<a href=\"https://forum.effectivealtruism.org/s/YLudF7wvkjALvAgni/p/83tEL2sHDTiWR6nwo#Relationships_Between_Causes\"><u>analyzing EA Survey prioritization ratings in 2020</u></a>. We did this by calculating the average of cause prioritization ratings for biosecurity, nuclear security, AI risk, existential risk, and \u2018other longtermism\u2019 to indicate prioritization of \u2018Longtermist\u2019 cause areas, and the average of global poverty / global health, mental health, and \u2018other neartermism\u2019 to indicate prioritization of \u2018Neartermist\u2019 cause areas. Countries varied in the degree to which they tended to prioritize Longtermist over Neartermist cause areas (assessed by subtracting the average of ratings for Neartermist causes from the average of ratings for Longtermist causes). The Czech Republic and Sweden in particular had a high preference towards Longtermist causes. Among countries with more sizable numbers of respondents, it can be seen that the UK had a higher preference for Longtermist over Neartermist causes than did the USA - a difference that was statistically significant, but still relatively small.&nbsp;</p><figure class=\"image\"><img src=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/e2b224e49b83be281b1cfab0cadf8e4e19966a85ba7b1fb9.png\" srcset=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/e2b224e49b83be281b1cfab0cadf8e4e19966a85ba7b1fb9.png/w_720 720w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/e2b224e49b83be281b1cfab0cadf8e4e19966a85ba7b1fb9.png/w_1440 1440w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/e2b224e49b83be281b1cfab0cadf8e4e19966a85ba7b1fb9.png/w_2160 2160w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/e2b224e49b83be281b1cfab0cadf8e4e19966a85ba7b1fb9.png/w_2880 2880w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/e2b224e49b83be281b1cfab0cadf8e4e19966a85ba7b1fb9.png/w_3600 3600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/e2b224e49b83be281b1cfab0cadf8e4e19966a85ba7b1fb9.png/w_4320 4320w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/e2b224e49b83be281b1cfab0cadf8e4e19966a85ba7b1fb9.png/w_5040 5040w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/e2b224e49b83be281b1cfab0cadf8e4e19966a85ba7b1fb9.png/w_5760 5760w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/e2b224e49b83be281b1cfab0cadf8e4e19966a85ba7b1fb9.png/w_6480 6480w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/e2b224e49b83be281b1cfab0cadf8e4e19966a85ba7b1fb9.png/w_7200 7200w\"></figure><figure class=\"image\"><img src=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/4226955e95d780e67360c2c2203c13372c46d5d26a6b8021.png\" srcset=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/4226955e95d780e67360c2c2203c13372c46d5d26a6b8021.png/w_720 720w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/4226955e95d780e67360c2c2203c13372c46d5d26a6b8021.png/w_1440 1440w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/4226955e95d780e67360c2c2203c13372c46d5d26a6b8021.png/w_2160 2160w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/4226955e95d780e67360c2c2203c13372c46d5d26a6b8021.png/w_2880 2880w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/4226955e95d780e67360c2c2203c13372c46d5d26a6b8021.png/w_3600 3600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/4226955e95d780e67360c2c2203c13372c46d5d26a6b8021.png/w_4320 4320w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/4226955e95d780e67360c2c2203c13372c46d5d26a6b8021.png/w_5040 5040w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/4226955e95d780e67360c2c2203c13372c46d5d26a6b8021.png/w_5760 5760w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/4226955e95d780e67360c2c2203c13372c46d5d26a6b8021.png/w_6480 6480w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/4226955e95d780e67360c2c2203c13372c46d5d26a6b8021.png/w_7200 7200w\"></figure><p>We would caution that these scores should not be interpreted as indicating the absolute level of support for longtermism over neartermism (with scores above 0 indicating net preference for longtermism and scores below 0 indicating net preference for neartermism and 0 representing neutrality). For example, from these \u2018Longtermist - Neartermist\u2019 comparisons it may look as if longtermism is, across countries, generally superseding prioritization of more traditional EA cause areas such as Global poverty/health, which is in the \u2018neartermist\u2019 bucket of causes. However, as noted, Global poverty/health remains highly prioritized across regions. Low ratings attributed specifically to mental health - the other main item in the \u2018neartermist\u2019 average - tend to bring the average down substantially. The overall \u2018neartermist\u2019 scores could be significantly higher or lower depending on whether Mental health is included/excluded (and, likewise, if we added or removed less popular causes to the longtermist group), which would shift the relative balance of the longtermism-neartermism scores. Hence, we would not conclude that different regions all prioritize \u2018longtermist\u2019 over \u2018neartermist\u2019 causes in some absolute sense, but their relative leanings towards these different cause categories can be informative.</p><h1>EA Group Membership</h1><p>In the figures below, we present the percentages of EAS respondents who reported being members of a local EA group across different countries and cities. It is notable that the two countries with the largest and longest-established EA communities - the UK and USA - have relatively low percentages of people reporting being members of EA groups, at about one third. The same might be said for some more specific cities/areas, such as Oxford and the SF Bay Area. However, it should also be considered that numbers for several of the smaller countries and cities with very high percentages could be slightly inflated: when there are relatively few EAs overall responding to the survey from a particular country or city, effective encouragement from group leaders in those places could lead to nearly all the people who are part of an EA group answering the survey, which would generate the appearance that almost all the EAs in that area are part of a group, but it is more indicative of a selection effect into the survey via the EA group in that area.</p><p><img src=\"https://lh4.googleusercontent.com/EJFphTUeAwYSmLMvjURAHzbtX-Ggoa1g0QKx2SD3AipPKCDY2dIs_aOJv6-caUJxTYTpPiw6v7A7_8Vdkjxar60JLJjUnOnWa2NZDzSaD_j1_VdwWtZ8tYfNiqdOBC-x-BQ4FXN2DqqtPwv0HlVneHo\"></p><p><img src=\"https://lh6.googleusercontent.com/EINZovdRdvIck3FegxvbS_vGO1RmGpVGBrGXP2-QiYxuQWv5PgSuMmL8YI-Y8nlWZGoeDkHBmXWv3lkkD0ISjTDWoWrMyLic9Hr7OJxy81IBpM2sW8lyNG1lVtPB61LBXJsTTyxr135sTSGdktPKXNs\"><br>&nbsp;</p><h2>Acknowledgments</h2><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ConFiY9cRmg37fs2p/iknljsjkg9wjbzr1rlfh\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ConFiY9cRmg37fs2p/jyurkufygqkvqtvo7if7 210w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ConFiY9cRmg37fs2p/a9slgapkbeei183rf7go 420w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ConFiY9cRmg37fs2p/akgzoc3wmpkep47qwgln 630w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ConFiY9cRmg37fs2p/xfl0oizedzzu509hbabm 840w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ConFiY9cRmg37fs2p/osnhhfi7kjmbbuizkmk0 1050w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ConFiY9cRmg37fs2p/qjra1tjgvsldjjrpsocn 1260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ConFiY9cRmg37fs2p/gs8r0uiw7usyezm0ndq2 1470w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ConFiY9cRmg37fs2p/rg925cnz6gh69z2nyso1 1680w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ConFiY9cRmg37fs2p/voog6bjdjo8rh4ly3ozb 1890w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ConFiY9cRmg37fs2p/f4spg4okr8eaw5ytetpd 2048w\"></p><p><i>This research is a project of</i><a href=\"http://rethinkpriorities.org/\"><i> <u>Rethink Priorities</u></i></a><i>. This post was written by Jamie Elsey and David Moss. We would also like to thank Peter Wildeford and David Rhys Bernard for their comments.</i></p><p><i>If you like our work, please consider</i><a href=\"https://www.rethinkpriorities.org/newsletter\"><i> <u>subscribing to our newsletter</u></i></a><i>. You can see more of our work </i><a href=\"https://www.rethinkpriorities.org/research\"><i><u>here</u></i></a><i>.</i></p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn00lu13y7i6lzm\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref00lu13y7i6lzm\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Note that percentages reported in the chart below showing countries of residence vs. countries of origin may not exactly match the first chart that just show countries of residence, as data were filtered slightly differently to include only respondents answering both origin and residence questions.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn3zkmprzh3e3\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref3zkmprzh3e3\">^</a></strong></sup></span><div class=\"footnote-content\"><p>In some plots you may see that the n is in fact below 25: for the most part we have continued to plot locations that, overall, had 25 respondents or more in the 2022 EAS, but for specific outcomes there may have been missing data, bringing the respective n for that item below 25.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnuz4c4oe0o4e\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefuz4c4oe0o4e\">^</a></strong></sup></span><div class=\"footnote-content\"><p>For uncertainty around percentages, we use a Bayesian 95% Highest Density Interval (HDI), reflecting the 95% most likely values from a posterior distribution. Uncertainty around means reflects a 95% confidence interval.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn2b6w0smo1p5\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref2b6w0smo1p5\">^</a></strong></sup></span><div class=\"footnote-content\"><p>As we noted in our&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/g5uKzBLjiEuC5k46A/ftx-community-response-survey-results#Cause_prioritization\"><u>FTX Community Response Survey report</u></a>, although we refer to these groups of causes as \u201clongtermist\u201d and \u201cneartermist\u201d, which they are often referred to as in the EA community, we are not committed to the claim that support for these causes is explained by longtermism/neartermism specifically. For example, support for \u201cneartermist\u201d causes might be explained by beliefs about&nbsp;appropriate kinds of evidence rather than beliefs about the value of the future per se.</p></div></li></ol>", "user": {"username": "Jamie Elsey"}}, {"_id": "ccw9v9giKxg8nyLhp", "title": "XPT forecasts on (some) biological anchors inputs", "postedAt": "2023-07-24T13:32:39.309Z", "htmlBody": "<p><i>This post was co-authored by the Forecasting Research Institute and Rose Hadshar. Thanks to Josh Rosenberg for managing this work, Zachary Jacobs and Molly Hickman for the underlying data analysis, Bridget Williams for fact-checking and copy-editing, the whole FRI XPT team for all their work on this project, and our external reviewers.</i></p><h1>TL;DR</h1><ul><li>As part of the Existential Risk Persuasion Tournament (XPT) we asked participants to&nbsp;forecast several questions that allowed us to infer inputs to Ajeya Cotra\u2019s <a href=\"https://docs.google.com/document/d/1IJ6Sr-gPeXdSJugFulwIpvavc0atjHGM82QjIfUSBGQ/edit#\">biological anchors model</a>. The XPT superforecasters\u2019 predictions differ substantially from Cotra\u2019s on hardware costs, willingness to spend and algorithmic efficiency:</li></ul><figure class=\"image image_resized\" style=\"width:89.43%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/qyiyiidtg7pwcdcecllj\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/afwtug1y9tzlf2ciiph3 100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/o2ssdc1sep0dxcxhh2jp 200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/aqjzyhqwgum2n2ycivle 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/ve8q5z5srjqnoaixbb3b 400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/p7mglpmdkyzsm1cunpzd 500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/b9crxjkurd24zeetxzop 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/dkwpji3b5dkk3ot7wmq7 700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/zcyijaox3vmaiuz2g9jm 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/fs7ao8bykhpovt3azzpi 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/kjtgpr0xbszdfzp783zi 996w\"></figure><ul><li>There are no XPT forecasts relating to other inputs to Cotra\u2019s model, most notably the 2020 training computation requirements distribution.</li><li>Taking Cotra\u2019s model and 2020 training computation requirements distribution as given, and using relevant XPT superforecaster forecasts as inputs, leads to substantial differences in model output:</li></ul><figure class=\"image image_resized\" style=\"width:82.85%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/sttjuyrdpvhgv1v3cg8d\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/hn5aqykzmuforqiuhztm 90w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/zvnnyuccg97dzg3mdh57 180w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/ni4kvwcssvsiyr9jzgy9 270w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/xcgxbkzpljwyjdh0d1rg 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/b6jmxw7ibdt4bmmshbos 450w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/ggverhmxpridelfbacrg 540w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/ynyzuuggqsw5cu1sq7h2 630w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/un35ldlt1nue9s3rcaik 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/xdk7obxlthzkfbgk7yo0 810w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/vsav4ztwmk6zf25ncrn0 843w\"></figure><p>*The most aggressive and most conservative estimates can be considered equivalent to 90% confidence interval for the median estimate.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref736fhvw6wlo\"><sup><a href=\"#fn736fhvw6wlo\">[1]</a></sup></span></p><ul><li>&nbsp;Using median XPT inputs implies median transformative AI (TAI) timelines of around ~2090, compared to Cotra\u2019s 2050 median timeline in 2020, and her <a href=\"https://www.lesswrong.com/posts/AfH2oPHCApdKicM4m/two-year-update-on-my-personal-ai-timelines%23Making_a_one_time_upward_adjustment_for__2020_FLOP_____\"><u>2040 median timeline</u></a>&nbsp;in 2022.</li><li>Using 90% confidence interval (CI) XPT inputs:<ul><li>Even the most aggressive XPT superforecaster inputs&nbsp;imply a lower probability that the compute required for training TAI is available than Cotra predicts, but the most conservative XPT superforecaster inputs predict TAI by 2100 as less likely than not.</li></ul></li><li>Most of the difference in outputs comes down to differences in forecasts on:<ul><li>Compute price halving time from 2025 to 2100</li><li>Doubling time of spending on compute for the most expensive training run from 2025 onwards</li></ul></li><li>Note that:<ul><li>Both Cotra and XPT forecasts on FLOP/$ are already inaccurate. However, Cotra's will necessarily prove more accurate and the current estimate is outside the XPT 90% CI.</li><li>The XPT forecast for the most expensive training run (by 2024) is already inaccurate, but it's not yet clear whether this forecast is more or less accurate than Cotra's forecast for 2025, which remains much higher than current estimates.</li></ul></li><li>XPT superforecasters\u2019 all-things-considered TAI timelines are longer than those suggested by using Cotra\u2019s model with XPT inputs. When asked about AI timelines in a survey at the end of the XPT, the median superforecaster put a probability of 3.75% on TAI by 2070. In contrast, Cotra\u2019s model with superforecaster XPT inputs suggests a&nbsp;~35%<strong>&nbsp;</strong>probability of TAI by 2070.</li><li><strong>To the extent that timeline beliefs are based on the biological anchors model, </strong><i><strong>and </strong></i><strong>to the extent that these beliefs are based on a training requirements distribution similar to Cotra\u2019s, then the actual value of the inputs on compute price halving time and doubling time of compute spending could have a significant bearing on expected timelines.</strong></li></ul><h1>Introduction</h1><p>This post:</p><ul><li>Compares estimates made by Ajeya Cotra and XPT <a href=\"https://forum.effectivealtruism.org/posts/ccw9v9giKxg8nyLhp/xpt-forecasts-on-some-biological-anchors-inputs#The_forecasts\"><u>forecasts</u></a>&nbsp;on questions relating to timelines until the compute required for TAI is attainable, and shows how the differences in forecasts impact the outputs of Cotra\u2019s biological anchors model</li><li>Discusses <a href=\"https://forum.effectivealtruism.org/posts/ccw9v9giKxg8nyLhp/xpt-forecasts-on-some-biological-anchors-inputs#What_drives_the_differences_between_Cotra_and_XPT_forecasters_\"><u>why</u></a>&nbsp;Cotra and XPT forecasters disagree, and <a href=\"https://forum.effectivealtruism.org/posts/ccw9v9giKxg8nyLhp/xpt-forecasts-on-some-biological-anchors-inputs#Which_forecasts_are_more_accurate_\"><u>which forecasts are more accurate</u></a></li><li>Notes that <a href=\"https://forum.effectivealtruism.org/posts/ccw9v9giKxg8nyLhp/xpt-forecasts-on-some-biological-anchors-inputs#XPT_superforecasters__all_things_considered_view_on_TAI_timelines\"><u>XPT forecasters\u2019 all-things-considered TAI timelines</u></a>&nbsp;are longer than those implied by using XPT forecasts as inputs to Cotra\u2019s model</li><li>Includes appendices on:<ul><li>The <a href=\"https://forum.effectivealtruism.org/posts/ccw9v9giKxg8nyLhp/xpt-forecasts-on-some-biological-anchors-inputs#Appendix_A__Arguments_made_for_different_forecasts\"><u>arguments</u></a>&nbsp;given by Cotra and the XPT forecasters for their respective forecasts</li><li><a href=\"https://forum.effectivealtruism.org/posts/ccw9v9giKxg8nyLhp/xpt-forecasts-on-some-biological-anchors-inputs#Appendix_B__XPT_expert_forecasts_related_to_when_the_compute_required_for_TAI_will_be_attainable\"><u>XPT expert</u></a>&nbsp;(as opposed to superforecaster) forecasts relating to the biological anchors model</li></ul></li></ul><h2>Background on the Forecasting TAI with biological anchors report</h2><p>In 2020, Ajeya Cotra at Open Philanthropy published her <a href=\"https://docs.google.com/document/d/1IJ6Sr-gPeXdSJugFulwIpvavc0atjHGM82QjIfUSBGQ/edit#\"><u>Forecasting TAI with biological anchors report</u></a>. The report modeled the probability that the compute required for building transformative AI (TAI) would be attainable in a given year, using:</p><ul><li>An estimate of the amount of compute required to train a TAI model that uses machine learning architectures available in 2020. This was developed using various biological anchors<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefx9yquvymqx\"><sup><a href=\"#fnx9yquvymqx\">[2]</a></sup></span>&nbsp;and is referred to as the \u201c2020 training computation requirements distribution\u201d.</li><li>An estimate of when the amount of compute required for TAI would be obtainable, which was developed from forecasts on hardware prices, willingness to spend, and algorithmic efficiency.</li></ul><p>Cotra\u2019s \u2018best guess\u2019 model outputted a probability of ~46% that the compute required for TAI would be attainable by 2050. Cotra gave her overall median TAI timeline as 2050.</p><p>In August 2022, Cotra <a href=\"https://www.lesswrong.com/posts/AfH2oPHCApdKicM4m/two-year-update-on-my-personal-ai-timelines\"><u>published some updates</u></a>&nbsp;to her model, and shifted her median TAI timeline forward to 2040.</p><h2>Background on the Existential Risk Persuasion Tournament (XPT)</h2><p>In 2022, the <a href=\"https://forecastingresearch.org/\"><u>Forecasting Research Institute</u></a>&nbsp;(FRI)&nbsp;ran the Existential Risk Persuasion Tournament (XPT). From June through October 2022, 169 forecasters, including 80 superforecasters and 89 experts in topics related to existential risk, developed&nbsp;forecasts on questions related to existential and catastrophic risk.&nbsp;Forecasters stopped updating their forecasts on 31st October 2022. FRI hopes to run future iterations of the tournament.</p><p>You can see the results from the tournament overall <a href=\"https://forecastingresearch.org/s/XPT.pdf\"><u>here</u></a>, results relating to AI risk <a href=\"https://forum.effectivealtruism.org/posts/K2xQrrXn5ZSgtntuT/what-do-xpt-forecasts-tell-us-about-ai-risk-1\"><u>here</u></a>, and to AI timelines in general <a href=\"https://forum.effectivealtruism.org/posts/KGGDduXSwZQTQJ9xc/what-do-xpt-forecasts-tell-us-about-ai-timelines\"><u>here</u></a>.</p><h2>Comparing Cotra and XPT forecasts</h2><p>Some XPT questions relate directly to some of the inputs to Cotra\u2019s biological anchors model. Specifically, there are XPT questions that relate to some of Cotra\u2019s forecasts on hardware prices, willingness to spend, and algorithmic efficiency:<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefrrryf8sfjaf\"><sup><a href=\"#fnrrryf8sfjaf\">[3]</a></sup></span></p><figure class=\"table\"><table style=\"border-color:hsl(0, 0%, 0%);border-style:solid\"><tbody><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>XPT question</strong></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><strong>Comparison</strong></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt 0pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><a href=\"https://docs.google.com/spreadsheets/d/1TjNQyVHvHlC-sZbcA7CRKcCp0NxV6MkkqBvL408xrJw/edit#gid=505210495\"><strong><u>Input to Cotra's model</u></strong></a></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:top\" colspan=\"1\" rowspan=\"2\"><a href=\"https://forecastingresearch.org/s/XPT.pdf#page=217\"><u>47. What will be the lowest price, in 2021 US dollars, of 1 GFLOPS with a widely-used processor by the end of 2024, 2030, 2050?</u></a></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">Median XPT superforecaster forecast for 2024 converted from petaFLOPS-days to FLOP per $ and compared with Cotra's forecast for 2025</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">FLOP per $ at the start of period (2025)</td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">Inferred doubling time between median XPT superforecaster forecasts for 2024 and 2050, compared with Cotra's doubling time from 2025 to 2100</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Compute price halving time in this period (2025\u20132100), in years</td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:top\" colspan=\"1\" rowspan=\"2\"><p><a href=\"https://forecastingresearch.org/s/XPT.pdf#page=213\"><u>46. How much will be spent on compute in the largest AI experiment by the end of 2024, 2030, 2050?</u></a></p><p>&nbsp;</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">Comparison of median XPT superforecaster 2024 forecast with Cotra 2025 forecast</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Compute cost for the most expensive training run at the start of period (2025), in 2020 USD</td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">Inferred doubling time between median XPT superforecaster forecasts for 2024 and 2050, compared with Cotra's doubling time from 2025 to 2100</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Doubling time of spending on compute for the most expensive training run at start of period (2025), in years.</td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><a href=\"https://forecastingresearch.org/s/XPT.pdf#page=223\"><u>48. By what factor will training efficiency on ImageNet classification have improved over AlexNet by the end of 2024, 2030?</u></a></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">Inferred doubling time between median XPT superforecaster forecasts for 2024 and 2030, compared with Cotra's doubling time from 2025 to 2100</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Halving time of compute requirements per path over this period (2025\u20132100), in years</td></tr></tbody></table></figure><h2>Caveats and notes</h2><p>It is important to note that there are several limitations to this analysis:</p><ul><li><strong>Outputs from Cotra\u2019s model using some XPT inputs do not reflect the overall views of XPT forecasters on TAI timelines.</strong><ul><li>Based on commentary during the XPT, it\u2019s unlikely that XPT forecasters would accept the assumptions of Cotra\u2019s model, or agree with all of Cotra\u2019s forecasts where there were no relevant XPT forecasts (most notably, the 2020 training computation requirements distribution).</li><li>In a survey we ran at the end of the XPT, superforecasters predicted a 3.8% chance of TAI by 2070, which is much lower than the corresponding ~35% outputted by Cotra\u2019s model using relevant XPT forecasts as inputs.</li></ul></li><li><strong>Cotra\u2019s model is very sensitive to changes in the training requirements distribution, so inputs on hardware prices and willingness to spend will not be significant for all values of that distribution.</strong><ul><li>In particular, for lower estimates of training requirements, XPT inputs would remain consistent with very short timelines.</li></ul></li><li><strong>None of the XPT forecasts are of exactly the same questions that Cotra uses as inputs.</strong></li></ul><p>And some notes:</p><ul><li>In this post, we focus on the forecasts of XPT superforecasters, as opposed to experts, &nbsp;when comparing with Cotra\u2019s forecasts.<ul><li>Analysis of the XPT differentiated experts into those with expertise in the specific domain of a question (in this case, AI), those with expertise in other domains related to existential risk (biosecurity, nuclear weapons, and climate change), and those with general expertise in existential risk studies. Too few AI domain experts answered the questions relevant to Cotra\u2019s model to allow for analysis, so the expert figures provided here&nbsp;include all types of experts in the XPT.</li><li>Compared to superforecasters, XPT experts\u2019 forecasts tended to be closer to Cotra by around an order of magnitude, but when inputted into Cotra\u2019s model they produced similar outputs to those drawing on XPT&nbsp;superforecaster forecasts.<ul><li>The exception to this is that the most aggressive XPT expert forecasts produced a probability of ~51% that the compute required for TAI is available by 2050, compared with 32% using the most aggressive XPT superforecaster forecasts.</li><li>See <a href=\"https://forum.effectivealtruism.org/posts/ccw9v9giKxg8nyLhp/xpt-forecasts-on-some-biological-anchors-inputs#Appendix_B__XPT_expert_forecasts_related_to_when_the_compute_required_for_TAI_will_be_attainable\">Appendix B</a> for more details.</li></ul></li></ul></li><li>The number of superforecasters who provided forecasts for each of the three key input questions ranged from 31 to 32.</li></ul><h1>The forecasts</h1><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/mnb4bz8kisoik60lh9ik\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/awrfmosztg3jmlkz0bqk 106w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/tu8jrhqwsmtfsikcdpcu 186w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/oilpfraqs5zwqqky4sie 266w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/tqcdjtiwhqlo5w5ix9uy 346w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/orqekf44aypy6vazn6kb 426w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/phazw4ovdp6azxhwkkcr 506w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/ujpnwrnktuijvu5x7q0r 586w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/y79pynma8djeh3sp8sri 666w\"></figure><p>See&nbsp;workings <a href=\"https://docs.google.com/spreadsheets/d/1tw2B1okJUdLrTIeDzooMPP16yduxZPzgLPHafD6Q6_8/edit#gid=0\"><u>here</u></a>&nbsp;and <a href=\"https://docs.google.com/spreadsheets/d/1ZW4j1DbOYnFSGj0WjzNMEBCSN6daTKAg63ZO_B2tcws/edit#gid=505210495\"><u>here</u></a><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefzjuoyohk3ui\"><sup><a href=\"#fnzjuoyohk3ui\">[4]</a></sup></span>. *The 'most aggressive' and 'most conservative' forecasts can be considered equivalent to 90% confidence intervals for the median estimate.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefree5mvhcuue\"><sup><a href=\"#fnree5mvhcuue\">[5]</a></sup></span></p><h1>What drives the differences between Cotra and XPT forecasters?</h1><h2>Differences in inputs</h2><p>Relevant XPT forecasts differ substantially from Cotra\u2019s.</p><h3>Hardware costs</h3><p><strong>FLOP per $ in 2025</strong></p><ul><li>Cotra (<a href=\"https://www.lesswrong.com/posts/AfH2oPHCApdKicM4m/two-year-update-on-my-personal-ai-timelines\"><u>2022</u></a>): 3.8E+18</li><li>XPT: 7E+17 (for 2024)</li><li>Cotra factors in that big companies get cheaper rates on GPUs.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefzk3i3ubxvco\"><sup><a href=\"#fnzk3i3ubxvco\">[6]</a></sup></span>&nbsp;XPT forecasters were explicitly asked to forecast the initial retail price of the chip on its release.&nbsp;That would explain most of the difference, assuming rates for big companies are 2\u20133x cheaper (which is what Cotra claims).</li></ul><p><strong>Compute price halving time from 2025 to 2100 (years)</strong></p><ul><li>Cotra: 2.5</li><li>XPT: 4.1&nbsp;(for 2024\u20132050)</li><li>In the short run, this difference is driven by Cotra factoring in efficiency improvements specific to machine learning, such as increasing arithmetic-to-communication ratios via e.g. memory locality, further reductions in precision.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefq5jzsylhl6e\"><sup><a href=\"#fnq5jzsylhl6e\">[7]</a></sup></span>&nbsp;These improvements were not relevant to the question XPT forecasters were asked, so they didn\u2019t take them into account.</li><li>In the long run, this difference seems to mostly come down to the likelihood that novel technologies like optical computing substantially reduce compute prices in the future.</li><li>Cotra flags that this is her least robust forecast and that after 2040 the forecast is particularly unreliable.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref9toxsxc0mx\"><sup><a href=\"#fn9toxsxc0mx\">[8]</a></sup></span></li></ul><h3>Willingness to spend</h3><p><strong>Compute cost for most expensive training run to 2025</strong></p><ul><li>Cotra: $1bn</li><li>XPT: $35m (for 2024)</li><li>XPT forecasters are predicting spending for a year earlier than Cotra.</li><li>XPT forecasters made their predictions three years after Cotra made hers.<ul><li>An influential <a href=\"https://openai.com/research/ai-and-compute\"><u>blog post by OpenAI in 2018</u></a>&nbsp;noted rapid increases in the compute cost of the most expensive training runs, with a doubling time of 3.6 months. However, <a href=\"https://epochai.org/blog/compute-trends\"><u>more recent analysis</u></a>&nbsp;using more data suggests a longer doubling time of ~6 months.</li><li>In <a href=\"https://www.lesswrong.com/posts/AfH2oPHCApdKicM4m/two-year-update-on-my-personal-ai-timelines%23Making_a_one_time_upward_adjustment_for__2020_FLOP_____\"><u>2022</u></a>, Cotra updated downwards on the likelihood of a $1bn training run by 2025.</li></ul></li><li>Cotra expects that the most expensive training run is likely to be unreleased.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefpltlpmivcm\"><sup><a href=\"#fnpltlpmivcm\">[9]</a></sup></span>&nbsp;XPT forecasters do not highlight this possibility in their forecasts even though unreleased models are included in the relevant resolution criteria. It is unclear whether XPT forecasters disagree substantively with Cotra, missed this consideration in their analysis, or were confused about resolution criteria. If Cotra's expectation is correct, and we accept her claim that unreleased runs are likely to be 2\u20138 times more expensive, XPT forecasts would still be an order of magnitude lower than Cotra\u2019s forecast, but more comparable with her conservative forecast of $300 million.</li></ul><p><strong>Doubling time of spending on compute for the most expensive training run from 2025 onwards&nbsp;(years)</strong></p><ul><li>Cotra: 2.5<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefu9c3xxsfmwg\"><sup><a href=\"#fnu9c3xxsfmwg\">[10]</a></sup></span></li><li>XPT: 8.4&nbsp;(for 2024\u20132050)</li><li>Cotra\u2019s reasoning for her 2.5 years doubling time rests on estimating various anchors and working backwards from them:<ul><li>She assumes a compute cost of $1bn in 2025 and the incentive to build a transformative model.</li><li>She arrives at a doubling time from 2025\u20132040 of 2 years by estimating how much companies would be willing to spend on a project overall, and the ratio of overall spending to spending on compute for final training runs.</li><li>Then assuming that the doubling times lengthens, hitting a cap at 1% of GDP and eventually syncing up with the GDP growth rates of the largest national economy, which Cotra estimates at 3%.</li></ul></li><li>Many XPT forecasters approached the question differently, by estimating current costs and then adding a modest multiplier.</li></ul><h3>Algorithmic progress</h3><p><strong>Halving time of compute requirements from 2025 to 2100 (years)</strong></p><ul><li>Cotra: 2\u20133.5</li><li>XPT: 1.6 (for 2024\u20132030)</li><li>Cotra notes that she spent very little time on this forecast.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefwnozgaaqfvs\"><sup><a href=\"#fnwnozgaaqfvs\">[11]</a></sup></span></li><li>XPT forecasts tend to be more conservative than Cotra and here they are more aggressive.</li><li>Comparability of the Cotra and XPT forecasts is particularly low here:<ul><li>XPT forecasters were asked to forecast expected improvements on a specific narrow application (image classification on ImageNet). Cotra expects improvements on narrow applications to be easier than improvements on a general and poorly defined metric like TAI.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefag1a5j2ga6k\"><sup><a href=\"#fnag1a5j2ga6k\">[12]</a></sup></span>&nbsp;This likely explains much of the difference in forecasts here.<ul><li>Cotra also draws on data from narrow applications, but then applies an upwards adjustment factor. We haven\u2019t applied an adjustment factor to the XPT forecasts in our main analysis, as Cotra isn\u2019t explicit about her methodology and we didn\u2019t want to introduce more subjectivity.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefrq3znbe25wp\"><sup><a href=\"#fnrq3znbe25wp\">[13]</a></sup></span><ul><li>We did a robustness check using an estimated upwards adjustment factor, and found that adjusting XPT forecasts on compute requirement halving times does not significantly shift model outputs. (See <a href=\"https://forum.effectivealtruism.org/posts/ccw9v9giKxg8nyLhp/xpt-forecasts-on-some-biological-anchors-inputs#Appendix_C__Applying_an_upwards_adjustment_factor_to_the_XPT_compute_halving_time_forecasts\"><u>appendix</u></a>&nbsp;for details.)</li></ul></li></ul></li><li>The XPT forecasts were only for 2024 and 2030, whereas Cotra\u2019s estimate was for 2025\u20132100.</li><li>Cotra estimates different halving times for each of her six biological anchors.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefvyw066je3as\"><sup><a href=\"#fnvyw066je3as\">[14]</a></sup></span>&nbsp;We haven\u2019t attempted to extrapolate this from XPT forecasts, because Cotra\u2019s methodology isn\u2019t very transparent and we didn\u2019t want to introduce more subjectivity.</li></ul></li></ul><h2>Differences in outputs</h2><p><strong>Taking XPT forecasts as inputs to Cotra\u2019s model leads to differences in outputs.</strong></p><ul><li>Taking the median forecasts from XPT superforecasters as inputs to Cotra\u2019s model produces a probability that the compute required for TAI is attainable by 2050 of ~20%&nbsp;(~3% by 2030, ~60% by 2100).</li><li>The most aggressive<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefl84026ya6b\"><sup><a href=\"#fnl84026ya6b\">[15]</a></sup></span>&nbsp;forecasts&nbsp;from XPT superforecasters produce a probability of ~32% by 2050 (~6% by 2030, ~71% by 2100).</li><li>The most conservative<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefonnqacsxrvf\"><sup><a href=\"#fnonnqacsxrvf\">[16]</a></sup></span>&nbsp;forecasts from XPT superforecasters produce a probability of ~7% by 2050 (~1% by 2030, ~31% by 2100).</li><li>Cotra\u2019s best guess inputs produce a probability of ~46% by 2050 (~8% by 2030, ~78% by 2100).<ul><li>In 2020, Cotra gave an overall median TAI timeline of 2050.</li><li>In <a href=\"https://www.lesswrong.com/posts/AfH2oPHCApdKicM4m/two-year-update-on-my-personal-ai-timelines\"><u>2022</u></a>, she updated her overall median to 2040.</li><li>Using the XPT forecasts as inputs to the model would translate to overall median TAI timelines of:<ul><li>Median: ~2090</li><li>Most aggressive: ~2065</li><li>Most conservative: &gt;2100</li></ul></li></ul></li></ul><p><strong>Most of the difference in outputs comes down to differences in forecasts on:</strong></p><ul><li><strong>Compute price halving time from 2025 to 2100.</strong></li><li><strong>Doubling time of spending on compute for the most expensive training run from 2025 onwards.</strong><ul><li>This is the single biggest driver of difference among the inputs we have XPT forecasts for.</li></ul></li></ul><h1>Which forecasts are more accurate?</h1><p>It\u2019s not possible yet to determine which forecasts are more accurate across the board; in some cases we\u2019d need to wait until 2100 to find out, and the earliest resolution date for final comparison is 2025.</p><p>That said, since Cotra and the XPT forecasters made their predictions, relevant new data has been released which already gives some indication of accuracy on some inputs. Epoch have developed estimates of the current FLOP per $ and the compute cost for the most expensive training run to date. We can compare these to the Cotra and XPT estimates:</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/wcbspeydiud9yyspropq\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/ugymv1kvw6tpp358x6oe 90w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/psb4znxeqofzeug01hkc 180w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/i6qd827llti6e2mjld0y 270w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/eifttyzsmlx77z1i7mlq 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/djhx2if9yqdchno5gkla 450w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/jat557m7yuaxu5e0ljfp 540w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/br5xzkmbmdl6yivvirnm 630w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/ss8pxfglbv0qmx2z2rsw 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/fqjvdztblttkcgqmyrgl 810w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/zqorldsny3zfiywyzmmy 846w\"></figure><p>* The 'most aggressive' and 'most conservative' forecasts can be considered equivalent to 90% confidence intervals for the median estimate.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreftocoiurtgkl\"><sup><a href=\"#fntocoiurtgkl\">[17]</a></sup></span>&nbsp;</p><p>**Note that these Epoch estimates are not forecasts of what these inputs will be in future, but estimates of the current value of the inputs at a given point in time (dates in brackets in the table). See <a href=\"https://epochai.org/trends#hardware-trends-section\"><u>here</u></a>&nbsp;for the FLOP/$ estimate and <a href=\"https://colab.research.google.com/drive/1O99z9b1I5O66bT78r9ScslE_nOj5irN9?usp%3Dsharing%23scrollTo%3DPqkx-E3NQocI\"><u>here</u></a>&nbsp;for the estimate of compute cost for most expensive training run.</p><p>If we accept the Epoch estimates, then this suggests that as of 2023:</p><ul><li><strong>Both Cotra and XPT forecasts on FLOP/$ are already inaccurate, although Cotra's 2022 estimate will necessarily prove more accurate </strong>(and the current estimate is outside the XPT 90% CI).</li><li><strong>The XPT forecast for the most expensive training run (by 2024) is already inaccurate (though it's not yet clear whether this forecast is more or less accurate than Cotra's forecast for 2025, which remains much higher than Epoch\u2019s current estimate).</strong></li></ul><p>It remains to be seen <i>how</i>&nbsp;inaccurate the XPT (and Cotra\u2019s) forecasts will prove, but it is striking that these XPT forecasts are already inaccurate&nbsp;even though they were made after Cotra\u2019s and for an earlier resolution date.</p><p>The forecasts for which it\u2019s not yet clear whether Cotra or XPT forecasters will prove more accurate are:</p><ul><li>Halving time of compute requirements from 2025 to 2100<ul><li>There is a recent Epoch estimate of this using historical data (<a href=\"https://epochai.org/blog/revisiting-algorithmic-progress\"><u>0.75</u></a>&nbsp;years, analysis published Dec 2022), but it won\u2019t be clear until much closer to 2100 which forecasts are on track to be more accurate.</li></ul></li><li>Compute price halving time from 2025 to 2100<ul><li>Though we note that both XPT and Cotra forecasts on FLOP/$ for 2024/2025 are already inaccurate, and that our inferred XPT halving time is based on XPT forecasts on FLOP/$ for 2024 and 2050.</li></ul></li><li>Doubling time of spending on compute for the most expensive training run from 2025 onwards, though note that:<ul><li>Our inferred XPT doubling time is based on XPT forecasts on most expensive training runs by 2024 and 2050, and the 2024 forecast is already inaccurate.</li><li>There is a substantial difference (greater than one order of magnitude) between Epoch\u2019s estimate of the most expensive training run to date, and Cotra\u2019s 2025 forecast.</li></ul></li></ul><h1>XPT superforecasters\u2019 all-things-considered view on TAI timelines</h1><p>As we mentioned above, this analysis takes Cotra\u2019s model and many of her inputs as a given, and uses XPT forecasts for particular inputs. It cannot be read as a statement of XPT forecasters\u2019 all-things-considered view on TAI timelines.</p><p>In fact, from questions in a postmortem survey conducted at the end of the XPT, we know that<strong>&nbsp;XPT forecasters\u2019 all-things-considered TAI timelines are longer than this analysis of Cotra\u2019s model suggests</strong>.</p><p>Superforecasters made the following explicit predictions in the postmortem survey:</p><ul><li><strong>Probability of AGI by 2070: 13%</strong><ul><li>\u201cArtificial general intelligence is defined here as any scenario in which cheap AI systems are fully substitutable for human labor, or if AI systems power a comparably profound transformation (in economic terms or otherwise) as would be achieved in such a world.\u201d</li></ul></li><li><strong>Probability of TAI by 2070: 3.75%</strong><ul><li>\u201cTransformative AI is defined here as any scenario in which global real GDP during a year exceeds 115% of the highest GDP reported in any full prior year.\u201d</li></ul></li><li><strong>Probability of &gt;15% GWP growth by 2100: 3%</strong><ul><li>\u201cBy 2100, will the global real GDP in a year ever exceed 115% of the highest GDP reported in any full prior year?\u201d</li></ul></li></ul><p>The output of Cotra\u2019s model using superforecaster XPT inputs is more aggressive than XPT superforecasters\u2019 overall views. Using the XPT superforecaster inputs in Cotra\u2019s model outputs <strong>35% by 2070, and 60% by 2100.</strong><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefy19nkgqtdpm\"><sup><a href=\"#fny19nkgqtdpm\">[18]</a></sup></span></p><p>Note that:</p><ul><li><strong>XPT superforecasters think AGI is considerably more likely than TAI by 2070.</strong></li><li><strong>XPT forecasters' views appear inconsistent.</strong><ul><li>~26%&nbsp;of superforecasters predicted AGI by 2070 as 50% likely or more, but ~38%&nbsp;agree or strongly agree that AGI will arise by the end of 2072. ~36% of experts predicted AGI by 2070 as 50% likely or more, but ~61% agree or strongly agree that AGI will arise by the end of 2072.</li><li>Superforecasters predict a 3% chance of &gt;15%&nbsp;growth by 2100,<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefq8480uoqlbo\"><sup><a href=\"#fnq8480uoqlbo\">[19]</a></sup></span>&nbsp;and a 3.75%&nbsp;chance of TAI (defined as &gt;15% growth) by 2070.<ul><li>Experts predict a 10%&nbsp;chance of &gt;15% growth by 2100,<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref2fjhfiti01s\"><sup><a href=\"#fn2fjhfiti01s\">[20]</a></sup></span>&nbsp;and a 16%&nbsp;chance of TAI by 2070, so their views are even less coherent on this question.</li></ul></li></ul></li></ul><h1>Appendix A: Arguments made for different forecasts</h1><p>Both Cotra and the XPT forecasters gave arguments for their forecasts.</p><p>In Cotra\u2019s case, she puts forward arguments directly in the relevant <a href=\"https://docs.google.com/document/d/1cCJjzZaJ7ATbq8N2fvhmsDOUWdm7t3uSSXv6bD0E_GM/edit#\"><u>section</u></a>&nbsp;of her report and in <a href=\"https://docs.google.com/document/d/1qjgBkoHO_kDuUYqy_Vws0fpf-dG5pTU4b8Uej6ff2Fg/edit#\"><u>appendices</u></a>.</p><p>In the XPT case:</p><ul><li>During the tournament, forecasters were assigned to teams.</li><li>Within teams, forecasters discussed and exchanged arguments in writing.</li><li>Each team was asked to produce a \u2018rationale\u2019 summarizing the arguments raised in team discussion.</li><li>The rationales from different teams on each XPT question were summarized by the FRI team.</li></ul><p>This appendix contains direct quotes from:</p><ul><li>Cotra\u2019s report, appendices and 2022 update</li><li>XPT team rationales</li></ul><p>Note that we haven't made any edits to these quotes, including where there are grammatical errors.</p><h2>Hardware costs</h2><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/llgegkj3n1ud0x4tx6ky\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/xz0bjpfm7luaylut3qve 90w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/hyr3yha3i7iebackoojp 180w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/o4eclafm2q1ihzrd1uzx 270w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/drugypnewain9kw0t4j0 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/woupfviogwzlvecy7afc 450w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/i5rlmothnmt70qfjum8i 540w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/ugkxei36z5s3aqudv7zm 630w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/z769fhtspkhczkdd12ju 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/dwhahsawdpfuvra0kxti 810w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/vdoyf9ow3hu07bp7n4ea 835w\"></figure><h3>Meta points</h3><ul><li>Cotra thinks these numbers are the least robust in her report.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref7l90xxd3ls9\"><sup><a href=\"#fn7l90xxd3ls9\">[21]</a></sup></span></li><li>She also thinks the forecast is more reliable till 2040 and then less reliable.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefb7yik8au95a\"><sup><a href=\"#fnb7yik8au95a\">[22]</a></sup></span></li></ul><h3>Cotra\u2019s arguments</h3><p><strong>In 2020:</strong></p><ul><li>Recent trends have been slower, are probably more informative, and probably reflect diminishing returns.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreftcd9uv850ye\"><sup><a href=\"#fntcd9uv850ye\">[23]</a></sup></span></li><li>The older, faster trend held for a long time and over multiple hardware transitions. Extrapolating the recent trend for several times longer than the older trend seems wrong.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefqiimvg78byi\"><sup><a href=\"#fnqiimvg78byi\">[24]</a></sup></span></li><li>NVIDIA A100 is a big improvement on the V100.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefwa98esiuxr\"><sup><a href=\"#fnwa98esiuxr\">[25]</a></sup></span></li><li>Specializing chips for deep learning applications will create a one off improvement in the next 5\u201310 years.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref6dof7uvxcbj\"><sup><a href=\"#fn6dof7uvxcbj\">[26]</a></sup></span></li><li>In the longer term, unknown unknowns and new technologies will probably lead to further improvements.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefk4d4a3477mi\"><sup><a href=\"#fnk4d4a3477mi\">[27]</a></sup></span><ul><li>Technologies noted: optical computing, three-dimensional circuits, reversible computing, quantum computing.</li></ul></li></ul><p><strong>In 2022:</strong></p><ul><li>The 2020 forecast used V100 as its reference machine, but the A100 was 2\u20133x more powerful.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefbw2j45fu8aa\"><sup><a href=\"#fnbw2j45fu8aa\">[28]</a></sup></span></li><li>The 2020 forecast was based on rental prices, but big companies get 2\u20133x cheaper prices.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefs4agwzqg6wi\"><sup><a href=\"#fns4agwzqg6wi\">[29]</a></sup></span></li><li>The 2020 forecast assumes \u2153 utilization of FLOP/s, but utilization then improved to around 50%.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefc26a00cvb37\"><sup><a href=\"#fnc26a00cvb37\">[30]</a></sup></span></li></ul><h3>XPT arguments</h3><p><strong>Arguments for&nbsp;lower hardware costs (closer to Cotra\u2019s forecasts):</strong></p><ul><li>Some XPT forecasters used outdated data to form their base rates, and so unknowingly predicted future lowest costs as being higher than present costs.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefi6f273fqkr\"><sup><a href=\"#fni6f273fqkr\">[31]</a></sup></span>&nbsp;This is an argument for lower forecasts than Cotra or XPT.</li><li>Covid inflated costs of electricity and hardware, but efficiencies in development and falling energy prices will drive costs down again.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefl38f8tktkq\"><sup><a href=\"#fnl38f8tktkq\">[32]</a></sup></span></li><li>Recent price-performance trends have been slower than usual, and there could be a return to the older order of magnitude improvements every 8 or 4 years.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefk9tchtr0bp\"><sup><a href=\"#fnk9tchtr0bp\">[33]</a></sup></span></li><li>Novel technologies might lead to a discontinuous drop in prices.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefm319n7vve2\"><sup><a href=\"#fnm319n7vve2\">[34]</a></sup></span>&nbsp;<ul><li>Possible technologies cited are optical computing, quantum computing, reversible and three-dimensional circuits, and unknown advances.</li></ul></li><li>Historical trends show an order of magnitude improvement in price-performance every decade.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefgi0yeduewvm\"><sup><a href=\"#fngi0yeduewvm\">[35]</a></sup></span></li></ul><p><strong>Arguments for higher hardware costs than Cotra forecasts:</strong></p><ul><li>Since 2010 the rate of price decline has slowed.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefieunsj2qvqr\"><sup><a href=\"#fnieunsj2qvqr\">[36]</a></sup></span>&nbsp;One team cited the IEEE report, \u2018<a href=\"https://irds.ieee.org/images/files/pdf/2021/2021IRDS_MM.pdf\"><u>More Moore</u></a>\u2019.</li><li>War, particularly over Taiwan, could raise prices.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefr54exi4l6nl\"><sup><a href=\"#fnr54exi4l6nl\">[37]</a></sup></span></li><li>Global economic decline could slow technological advances.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefuuntszjpqoh\"><sup><a href=\"#fnuuntszjpqoh\">[38]</a></sup></span></li><li>Progress may be getting harder.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefvvqi9u1adji\"><sup><a href=\"#fnvvqi9u1adji\">[39]</a></sup></span></li><li>We may reach fundamental physical limits.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefakupzs8hdho\"><sup><a href=\"#fnakupzs8hdho\">[40]</a></sup></span></li><li>Demand for more efficient chips may be low.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefqpu8rjdnwkn\"><sup><a href=\"#fnqpu8rjdnwkn\">[41]</a></sup></span></li><li>Future technological developments are uncertain and could raise prices.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefgxsk2ag6pkp\"><sup><a href=\"#fngxsk2ag6pkp\">[42]</a></sup></span></li><li>FLOP rates might stabilize in the future and optimization might shift to memory architectures.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefb9yab4mx67q\"><sup><a href=\"#fnb9yab4mx67q\">[43]</a></sup></span></li><li>Materials for chips are rare and have other uses.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefwstb6iaj9fk\"><sup><a href=\"#fnwstb6iaj9fk\">[44]</a></sup></span></li><li>A catastrophe or extinction event could halt price decreases.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref4w6519lrusw\"><sup><a href=\"#fn4w6519lrusw\">[45]</a></sup></span></li></ul><h2>Willingness to spend</h2><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/xprxfbhij6qwwssb2364\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/easefovg4wpx7qq8id62 90w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/ciwmqxfkxu5aighl0ynu 180w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/zmq1vda5pjhc4zhud8c2 270w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/nibgwtp0l0tjpr2moyfb 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/jcbbu7nf84mt7om8ufal 450w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/lzqxifmx7o0q3ld7qume 540w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/deboggyamx2nczlggr3j 630w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/w41zreejuoxibsqborol 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/eioyjtanuir7qq0gplw3 810w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/g0garytuzfks6tzws5vq 845w\"></figure><h3>Cotra\u2019s arguments</h3><ul><li>On compute cost for most expensive training run to 2025:<ul><li>$1bn by 2025 is consistent with recent spending scaling according to <a href=\"https://openai.com/blog/ai-and-compute/\"><u>this</u></a>&nbsp;2018 OpenAI blog.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefjcg29m30g\"><sup><a href=\"#fnjcg29m30g\">[46]</a></sup></span></li><li>It is also consistent with the existing resources of AI companies like Google.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref3igsee5vlnx\"><sup><a href=\"#fn3igsee5vlnx\">[47]</a></sup></span></li><li>Excitement around deep learning is sufficient such that several companies will be willing to spend a few hundred million dollars on experiments which don\u2019t generate much revenue at the moment.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefd8pml2evi6e\"><sup><a href=\"#fnd8pml2evi6e\">[48]</a></sup></span></li><li>Spending on the most compute intensive unreleased/proprietary model is likely 2\u20138x larger than AlphaStar already.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefjji9p2haoy\"><sup><a href=\"#fnjji9p2haoy\">[49]</a></sup></span></li><li>\u201cIt also seems quite likely that by the end of 2020, a single ML training run costing at least $20M will have been completed, and that by the end of 2021, a single training run costing at least $80M will have been completed.\u201d<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefiit8rlrsmh\"><sup><a href=\"#fniit8rlrsmh\">[50]</a></sup></span></li></ul></li><li>On doubling time of spending on compute 2025\u20132040:<ul><li>[Note that for these arguments Cotra assumes that a company has spent $1bn on a training run in 2025 and has the incentive of building a transformative model.]<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefoz8765uouig\"><sup><a href=\"#fnoz8765uouig\">[51]</a></sup></span></li><li>By 2040 an AI company could spend hundreds of billions on a project to train a transformative model.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefp42zmh193s\"><sup><a href=\"#fnp42zmh193s\">[52]</a></sup></span><ul><li>Current cash in hand of relevant companies is ~$50\u2013100bn.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefza495v8sl4g\"><sup><a href=\"#fnza495v8sl4g\">[53]</a></sup></span></li><li>These companies\u2019 market capitalization tends to be 10x as large as cash in hand, close to $1 trillion.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefpswcyp1u5e8\"><sup><a href=\"#fnpswcyp1u5e8\">[54]</a></sup></span><ul><li>They could probably borrow up to 50% of this.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefscpkxkjecf\"><sup><a href=\"#fnscpkxkjecf\">[55]</a></sup></span></li></ul></li><li>If AI progress continues, these companies\u2019 share of the economy will grow.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefhcedwnmdkbb\"><sup><a href=\"#fnhcedwnmdkbb\">[56]</a></sup></span></li></ul></li><li>The ratio of overall project spend to spend on compute for final training runs may be 2\u201310x.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref9z035kl63u4\"><sup><a href=\"#fn9z035kl63u4\">[57]</a></sup></span></li><li>This suggests that in 2040 an AI project would be willing to spend $100bn on compute for a final training run.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefsq4ytfzcjjg\"><sup><a href=\"#fnsq4ytfzcjjg\">[58]</a></sup></span></li><li>This implies a doubling time of 2 years.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefmuqvnvxj50o\"><sup><a href=\"#fnmuqvnvxj50o\">[59]</a></sup></span></li></ul></li><li>On long-run willingness to spend:<ul><li>Eventually growth in spending on compute will keep pace with the GDP growth of the largest national economy.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefiujw8p1ugwb\"><sup><a href=\"#fniujw8p1ugwb\">[60]</a></sup></span><ul><li>3% is in keeping with average US growth over the past few decades.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefoocwg4lvde\"><sup><a href=\"#fnoocwg4lvde\">[61]</a></sup></span></li></ul></li><li>Anchoring to the Manhattan and Apollo projects would suggest that the maximum spend would be around 1% of the GDP of the largest country.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefrjcs2p9hg6\"><sup><a href=\"#fnrjcs2p9hg6\">[62]</a></sup></span></li></ul></li><li><a href=\"https://www.lesswrong.com/posts/AfH2oPHCApdKicM4m/two-year-update-on-my-personal-ai-timelines%23Making_a_one_time_upward_adjustment_for__2020_FLOP_____\"><u>2022 update</u></a>: \u201c<a href=\"https://www.cbsnews.com/news/tech-companies-layoffs-stock-market-cryptocurrency/\">There\u2019s been a major market downturn that hit tech companies especially hard</a>; it seems a little less likely to me now than it did when writing the report that there will be a billion dollar training run by 2025.\u201d</li></ul><h3>XPT arguments</h3><p><strong>General comments:</strong></p><ul><li>Low forecasts are derived from applying a modest multiplier to current costs. Higher forecasts identify anchors (such as company budgets or costs of previous mega-projects) and assume fast scaling up to those anchors.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefmhiw3fnxyta\"><sup><a href=\"#fnmhiw3fnxyta\">[63]</a></sup></span></li><li>Lower forecasts assume current manufacturing processes will continue. Higher forecasts imagine novel technology.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefl9b1tv6dqun\"><sup><a href=\"#fnl9b1tv6dqun\">[64]</a></sup></span></li></ul><p><strong>Arguments for lower spending than Cotra forecasts:</strong></p><ul><li>Training costs have been stable at around $10m for the last few years.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefetmsawbnk8\"><sup><a href=\"#fnetmsawbnk8\">[65]</a></sup></span></li><li>Current trend increases are not sustainable for many more years.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefizgiixeqjsm\"><sup><a href=\"#fnizgiixeqjsm\">[66]</a></sup></span>&nbsp;One team cited <a href=\"https://aiimpacts.org/trends-in-the-cost-of-computing/\"><u>this</u></a>&nbsp;AI Impacts blog post.</li><li>Major companies are cutting costs.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefz53jukboly\"><sup><a href=\"#fnz53jukboly\">[67]</a></sup></span></li><li>Increases in model size and complexity will be offset by a combination of falling compute costs, pre-training, and algorithmic improvements.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefejfq54kjbyf\"><sup><a href=\"#fnejfq54kjbyf\">[68]</a></sup></span></li><li>Large language models will probably see most attention in the near future, and these are bottlenecked by availability of data, which will lead to smaller models and lower compute requirements.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreffvkqh3q6u3\"><sup><a href=\"#fnfvkqh3q6u3\">[69]</a></sup></span></li><li>Growth may already be slowing down.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefl9mc89we9kn\"><sup><a href=\"#fnl9mc89we9kn\">[70]</a></sup></span></li><li>In the future, AI systems may be more modular, such that single experiments remain small even if total spending on compute increases drastically.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefamxjodiun8\"><sup><a href=\"#fnamxjodiun8\">[71]</a></sup></span></li><li>Recent spending on compute may have been status driven.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref0ix7mtmb6mlg\"><sup><a href=\"#fn0ix7mtmb6mlg\">[72]</a></sup></span></li><li>There seems to be general agreement that experiments of more than a few months are unwise, which might place an upper bound on how much compute can cost for a single experiment.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefgysbfx3oe5k\"><sup><a href=\"#fngysbfx3oe5k\">[73]</a></sup></span></li></ul><p><strong>Arguments for higher spending (closer to Cotra\u2019s forecasts):</strong></p><ul><li>As AI creates more value, more money will be spent on development.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreffafjllwoial\"><sup><a href=\"#fnfafjllwoial\">[74]</a></sup></span></li><li>A mega-project could be launched nationally or internationally which leads to this level of spending.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefsqw8i6ormgq\"><sup><a href=\"#fnsqw8i6ormgq\">[75]</a></sup></span></li><li>There is strong competition between actors with lots of resources and incentives to develop AI.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefo2a7vpo5uh\"><sup><a href=\"#fno2a7vpo5uh\">[76]</a></sup></span></li><li>The impact of AI on AI development or the economy at large might raise the spending ceiling arbitrarily high.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreffwql072onar\"><sup><a href=\"#fnfwql072onar\">[77]</a></sup></span></li></ul><h2>Algorithmic progress</h2><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/x0ngjafdjtl0c2duwtx7\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/dej1j5fiisdgluscxm1s 90w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/h0mcsbpp2xsz6z2oizmz 180w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/ffv9of5dcwveft9eod0f 270w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/i6smqnxlxinfkthrxzki 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/xxrkf4yr2x7bb3iogvew 450w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/xspt5k92f7cufgvnwsht 540w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/pkzxbsfw9nzrpmebnlck 630w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/cktr8frll1vflrw5mcsp 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/r6blp7rumq0davpxvhfq 810w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/ztelwwnwfbfp5elm7teb 812w\"></figure><h3>Meta points</h3><ul><li>Cotra says she\u2019s spent very little time on this: the least time of any of the major components of her model.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefew8ze3kr47\"><sup><a href=\"#fnew8ze3kr47\">[78]</a></sup></span></li><li>The comparability is low:<ul><li>The XPT question only covers 2024 and 2030, which is a small part of the time from 2025 to 2100.</li><li>The XPT question was specifically about efficiency improvements on ImageNet, and the relationship between that and the most relevant kinds of algorithmic progress for TAI is unclear.<ul><li>Cotra notes that we should expect efficiency improvements on narrow, well-defined tasks to be faster than those most relevant to TAI.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefamojubiv4t\"><sup><a href=\"#fnamojubiv4t\">[79]</a></sup></span></li></ul></li><li>Cotra breaks her forecasts down for each of the biological anchors she considers; the XPT question generates only one overall number.</li></ul></li></ul><h3>Cotra\u2019s arguments</h3><ul><li><a href=\"https://arxiv.org/pdf/2005.04305.pdf\"><u>Hernandez and Brown 2020</u></a>&nbsp;show halving every 13-16 months.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefmo2eyygb6aq\"><sup><a href=\"#fnmo2eyygb6aq\">[80]</a></sup></span></li><li>But these are on narrow well-defined tasks which researchers can directly optimize for, so forecasts should be adjusted up.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref8ct49j3vr5d\"><sup><a href=\"#fn8ct49j3vr5d\">[81]</a></sup></span></li><li>There might also be breakthrough progress at some point.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefofy638opskn\"><sup><a href=\"#fnofy638opskn\">[82]</a></sup></span></li></ul><h3>XPT arguments</h3><p><strong>General comments:</strong></p><ul><li>Extrapolating current growth rates leads to above median forecasts, and median and below median forecasts assume that current growth rates will slow.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref7z8f6ze1278\"><sup><a href=\"#fn7z8f6ze1278\">[83]</a></sup></span></li></ul><p><strong>Arguments for slower algorithmic progress (closer to Cotra\u2019s forecast):</strong></p><ul><li>It\u2019s possible no further work will be done in this area such that no further improvements are made.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref8uypddzxh5s\"><sup><a href=\"#fn8uypddzxh5s\">[84]</a></sup></span></li><li>Recently the focus has been on building very large models rather than increasing efficiency.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref7w68fm2va6j\"><sup><a href=\"#fn7w68fm2va6j\">[85]</a></sup></span></li><li>There may be hard limits on how much computation is required to train a strong image classifier.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreft02npjjf2zi\"><sup><a href=\"#fnt02npjjf2zi\">[86]</a></sup></span></li><li>Accuracy may be more important for models given what AI is used for, such that leading researchers target accuracy rather than efficiency gains.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref3gcw5wtj1ry\"><sup><a href=\"#fn3gcw5wtj1ry\">[87]</a></sup></span></li><li>If there is a shift towards explainable AI, this may require more compute&nbsp;and so slow efficiency growth rates.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefu5lg1oldi9\"><sup><a href=\"#fnu5lg1oldi9\">[88]</a></sup></span></li><li>Improvements may not be linear, especially as past improvements have been \u201clumpy\u201d (i.e. improvements have come inconsistently) and the reference source is only rarely updated.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefefls1wfvo5f\"><sup><a href=\"#fnefls1wfvo5f\">[89]</a></sup></span></li><li>Very high growth rates are hard to sustain and tend to revert to the mean.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref7vs2ikh3xl3\"><sup><a href=\"#fn7vs2ikh3xl3\">[90]</a></sup></span></li></ul><p><strong>Arguments for faster algorithmic progress:</strong></p><ul><li>Pure extrapolation of improvements to date would result in fast progress.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefaygwmerb4wf\"><sup><a href=\"#fnaygwmerb4wf\">[91]</a></sup></span></li><li>Quantum computing might increase compute power and speed.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefsl68iqurcv\"><sup><a href=\"#fnsl68iqurcv\">[92]</a></sup></span></li><li>As AI models grow and become limited by available compute, efficiency will become increasingly important and necessary for improving accuracy.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefevo36u0up86\"><sup><a href=\"#fnevo36u0up86\">[93]</a></sup></span></li><li>\u201cThe <a href=\"https://paperswithcode.com/sota/image-classification-on-imagenet?metric%3DTop%25205%2520Accuracy%26dimension%3DGFLOPs\"><u>Papers with Code ImageNet benchmark sorted by GFLOPs</u></a>&nbsp;shows several more recent models with good top 5 accuracy and a much lower GFLOPs used than the current leader, EfficientNet.\u201d If GFLOPS is a good indicator of training efficiency, then large efficiency increases may already have been made.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref38gxe0yakea\"><sup><a href=\"#fn38gxe0yakea\">[94]</a></sup></span></li><li>This technology is in its infancy so there may still be great improvements to be made.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefq5gtiwextll\"><sup><a href=\"#fnq5gtiwextll\">[95]</a></sup></span></li></ul><h1>Appendix B: XPT expert forecasts related to when the compute required for TAI will be attainable</h1><figure class=\"image image_resized\" style=\"width:100%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/e88nk4qwxunw4nfpehqb\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/wm8ewtakpql7hq608uzg 130w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/bnibulfsl41k2dak9sve 210w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/nzeh77z02dzfb9iq9kof 290w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/qk0zlijapjfjjsennlse 370w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/k4oo6bhn2xzudhloc7s9 450w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/nw0pp1oqvbewnzwmycw8 530w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/trrjts4ohoepy5g7rhw4 610w\"></figure><p>* The 'most aggressive' and 'most conservative' forecasts can be considered equivalent to 90% confidence intervals for the median estimate.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefpi55hwql9bo\"><sup><a href=\"#fnpi55hwql9bo\">[96]</a></sup></span></p><p>Notes:</p><ul><li>Here, experts includes&nbsp;all experts in the XPT, including experts in fields other than AI which are relevant to existential risk.<ul><li>We chose to present results for all experts because the sample sizes were bigger than those of domain experts (14-21 compared to 5-6 domain experts). However, we expect readers will vary in how much weight they want to put on the forecasts of domain experts vs. general x-risk experts vs. non-domain experts on these questions. For details on each subgroup's forecasts on these questions, see Appendix 5 <a href=\"https://static1.squarespace.com/static/635693acf15a3e2a14a56a4a/t/64abffe3f024747dd0e38d71/1688993798938/XPT.pdf\"><u>here</u></a>, where you can navigate to each question to see each subgroup's forecast.</li></ul></li><li>The range in expert inputs tends to be larger than the range in superforecaster inputs.</li><li>The most aggressive expert inputs are the only XPT inputs which produce probabilities higher than Cotra\u2019s.</li></ul><h1>Appendix C: Applying an upwards adjustment factor&nbsp;to the XPT compute halving time forecasts</h1><p>Cotra bases her forecast for compute requirement halving times on data about algorithmic progress on narrow applications, but then applies an upwards adjustment factor, to account for her belief that algorithmic progress will be slower for general applications, than it is for narrow applications.</p><p>We didn\u2019t apply an adjustment factor to the XPT forecasts in our main analysis, as Cotra isn\u2019t explicit about her methodology and we didn\u2019t want to introduce more subjectivity.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefwhj1pui5tyc\"><sup><a href=\"#fnwhj1pui5tyc\">[97]</a></sup></span></p><p>But it is possible to do a robustness check using an estimated upwards adjustment factor, as follows:</p><ul><li>The Hernandez and Brown paper Cotra cites shows halving times of 13\u201316 months.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref9u7wlabe4oc\"><sup><a href=\"#fn9u7wlabe4oc\">[98]</a></sup></span></li><li>Christiano\u2019s summary of Grace\u2019s paper has halving times of 13\u201336 months.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref6bmtulxqjiv\"><sup><a href=\"#fn6bmtulxqjiv\">[99]</a></sup></span>&nbsp;</li><li>Let's guess that the bottom of Cotra\u2019s unadjusted range is a halving time of 14 months.</li><li>Her final estimates range from 24\u201336 months, which is an adjustment of 1.7 at the bottom end.</li><li>This would mean the top of her unadjusted range is 21, which is consistent with Cotra putting more weight on Hernandez and Brown.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefaoyi4t53r0g\"><sup><a href=\"#fnaoyi4t53r0g\">[100]</a></sup></span>&nbsp;</li><li>If we apply an upward adjustment factor of 1.7 to all of the XPT figures, we end up with a median halving time of 2.72 years (90% CI: 2.55 years to 5.78 years).</li><li>If we input this adjusted figure into the model, we get the following outputs:</li></ul><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/qh3dhotyfunwn6a3szzm\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/tesp4h8b4ncksysyg0h4 88w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/xl3cbrcxyv13xnxhrpyb 168w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/ovad7ifm0nfyfnjln0ta 248w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/se8dnywr2rahav4a6mhy 328w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/sicv4hohcli8wmuozbwv 408w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/n2u7guqowviufeyaxj2n 488w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/futqp9wm342hpit1wct2 568w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/gaue1eaftxlvg22fwveu 648w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ccw9v9giKxg8nyLhp/yq7vn1flwobroaav3szn 728w\"></figure><p>Workings <a href=\"https://docs.google.com/spreadsheets/d/1tw2B1okJUdLrTIeDzooMPP16yduxZPzgLPHafD6Q6_8/edit#gid=610909524\"><u>here</u></a>. *The 'most aggressive' and 'most conservative' forecasts can be considered equivalent to 90% confidence intervals for the median estimate.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref05naqbi3hvgi\"><sup><a href=\"#fn05naqbi3hvgi\">[101]</a></sup></span></p><p>So applying a rough upwards adjustment factor to the XPT forecasts on compute requirement halving times does not significantly shift model outputs.</p><p>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn736fhvw6wlo\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref736fhvw6wlo\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;For the relevant questions in the XPT, forecasters were asked to provide their 5th, 25th, 50th, 75th, and 95th percentile forecasts. In this analysis we use the term, \u2018median\u2019 to refer to analyses using the group\u2019s median forecast for the 50th percentile of each question. We use the term \u2018most aggressive\u2019 to refer to analyses using the group medians for the 5th percentile estimate of the question relating to hardware costs, and the 95th percentile estimate for the questions relating to willingness to spend and algorithmic progress. (I.e., this uses the lowest plausible hardware costs and the highest plausible willingness to spend and algorithmic efficiency to give the highest plausible likelihood of TAI.) We use the term \u2018most conservative\u2019 to refer to &nbsp;analyses using the group medians for the 95th percentile estimate of the question relating to hardware costs, and the 5th percentile estimate for the questions relating to willingness to spend and algorithmic progress. (I.e., this uses the highest plausible hardware costs and the lowest plausible willingness to spend and algorithmic efficiency to give the lowest plausible likelihood of TAI.) The most aggressive and most conservative estimates can be considered equivalent to 90% confidence interval for the median estimate. See <a href=\"https://forum.effectivealtruism.org/posts/ccw9v9giKxg8nyLhp/xpt-forecasts-on-some-biological-anchors-inputs#Comparing_Cotra_and_XPT_forecasts\"><u>here</u></a>&nbsp;for context on which XPT questions map to which biological anchors inputs.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnx9yquvymqx\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefx9yquvymqx\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Biological anchors refers to four hypotheses for the amount of computation that would be required to train a transformative model using 2020 architectures and algorithms: total computation done over evolution, total computation done over a human lifetime, the computational power of the human brain, and the amount of information in the human genome. All four anchors rely on an estimate of the amount of computation performed by the human brain, measured in floating point operations per second (FLOP/s). &nbsp;See <a href=\"https://docs.google.com/document/d/1IJ6Sr-gPeXdSJugFulwIpvavc0atjHGM82QjIfUSBGQ/edit%23heading%3Dh.yrpq5m3bxdvh\">here</a>&nbsp;for an introduction to the framework.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnrrryf8sfjaf\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefrrryf8sfjaf\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;More detail on the XPT forecasts on these questions can be found in pages 657 to 678 of the <a href=\"https://forecastingresearch.org/s/XPT.pdf#page=658\">XPT report</a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnzjuoyohk3ui\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefzjuoyohk3ui\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;This spreadsheet uses as a template Cotra's publicly available <a href=\"https://docs.google.com/spreadsheets/d/1TjNQyVHvHlC-sZbcA7CRKcCp0NxV6MkkqBvL408xrJw/edit#gid=505210495\"><u>spreadsheet</u></a>, linked to from her <a href=\"https://docs.google.com/document/d/1IJ6Sr-gPeXdSJugFulwIpvavc0atjHGM82QjIfUSBGQ/edit#heading=h.c5pt0lvk9kkw\"><u>report</u></a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnree5mvhcuue\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefree5mvhcuue\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;For the relevant questions in the XPT, forecasters were asked to provide their 5th, 25th, 50th, 75th, and 95th percentile forecasts. In this analysis we use the term, \u2018median\u2019 to refer to analyses using the group\u2019s median forecast for the 50th percentile of each question. We use the term \u2018most aggressive\u2019 to refer to analyses using the group medians for the 5th percentile estimate of the question relating to hardware costs, and the 95th percentile estimate for the questions relating to willingness to spend and algorithmic progress. (I.e., this uses the lowest plausible hardware costs and the highest plausible willingness to spend and algorithmic efficiency to give the highest plausible likelihood of TAI.) We use the term \u2018most conservative\u2019 to refer to &nbsp;analyses using the group medians for the 95th percentile estimate of the question relating to hardware costs, and the 5th percentile estimate for the questions relating to willingness to spend and algorithmic progress. (I.e., this uses the highest plausible hardware costs and the lowest plausible willingness to spend and algorithmic efficiency to give the lowest plausible likelihood of TAI.) The most aggressive and most conservative estimates can be considered equivalent to 90% confidence interval for the median estimate. See <a href=\"https://forum.effectivealtruism.org/posts/ccw9v9giKxg8nyLhp/xpt-forecasts-on-some-biological-anchors-inputs#Comparing_Cotra_and_XPT_forecasts\">here </a>for context on which XPT questions map to which biological anchors inputs.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnzk3i3ubxvco\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefzk3i3ubxvco\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cI was using the rental price of a V100 (~$1/hour), but big companies get better deals on compute&nbsp;than that, by about another 2-3x.\u201d <a href=\"https://www.lesswrong.com/posts/AfH2oPHCApdKicM4m/two-year-update-on-my-personal-ai-timelines%23Making_a_one_time_upward_adjustment_for__2020_FLOP_____\"><u>here</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnq5jzsylhl6e\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefq5jzsylhl6e\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cCommunication costs currently account for roughly ~70%-80% of the cost of a GPU, and Paul\u2019s understanding is that the recent trend in ML chips has been toward increasing arithmetic-to-communication ratios. Pushing further in that direction (e.g. switching to chips with more localized memory) could bring communication costs more in-line with arithmetic costs and reduce total costs by a factor of ~3.</p><p>Deep learning applications could also gain a factor of ~2 from switching to 8-bit precision computations (rather than 16-bit).\u201d <a href=\"https://docs.google.com/document/d/1qjgBkoHO_kDuUYqy_Vws0fpf-dG5pTU4b8Uej6ff2Fg/edit#\"><u>p. 30</u></a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn9toxsxc0mx\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref9toxsxc0mx\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cBecause they have not been the primary focus of my research, I consider these estimates unusually unstable, and expect that talking to a hardware expert could easily change my mind.\u201d <a href=\"https://docs.google.com/document/d/1qjgBkoHO_kDuUYqy_Vws0fpf-dG5pTU4b8Uej6ff2Fg/edit#heading=h.nmcod2jynsy4\"><u>p. 26</u></a>. \u201cThis forecast feels most solid and plausible out to ~2040 or so, beyond which it feels substantially more murky and likely incorrect.\u201d <a href=\"https://docs.google.com/document/d/1cCJjzZaJ7ATbq8N2fvhmsDOUWdm7t3uSSXv6bD0E_GM/edit#heading=h.fmq8f6whj003\"><u>p. 4</u></a>.&nbsp;\u201cOf all the quantitative estimates in this document, I consider these forecasts the most likely to be knowably mistaken. While most of the other quantitative estimates in this document have a lot more absolute uncertainty associated with them, there is a lot more low-hanging fruit left in improving short- and medium-term hardware price forecasts. For example, my understanding is that semiconductor industry professionals regularly write highly detailed technical reports forecasting a number of hardware cost-efficiency metrics, and I have neither read any of this literature nor interviewed any hardware experts on this question.\u201d <a href=\"https://docs.google.com/document/d/1qjgBkoHO_kDuUYqy_Vws0fpf-dG5pTU4b8Uej6ff2Fg/edit#heading=h.xi6z3buznjb7\"><u>p. 30</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnpltlpmivcm\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefpltlpmivcm\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cI would guess that the most compute-intensive training run for an unreleased and/or proprietary model (e.g., a language model powering Google Assistant or Google Translate) is already ~2-8x larger than AlphaStar\u2019s ~1.3e23, costing ~$2-8M.\u201d <a href=\"https://docs.google.com/document/d/1qjgBkoHO_kDuUYqy_Vws0fpf-dG5pTU4b8Uej6ff2Fg/edit#heading=h.nc2d14p8i1pd\"><u>p. 36</u></a>&nbsp;\u201c[N]ote that there will probably be a non-trivial delay between the first time a training run of size X is completed and the first time such a training run is published, and my forecasts are about the former\u201d. <a href=\"https://docs.google.com/document/d/1qjgBkoHO_kDuUYqy_Vws0fpf-dG5pTU4b8Uej6ff2Fg/edit#heading=h.nc2d14p8i1pd\"><u>p. 37</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnu9c3xxsfmwg\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefu9c3xxsfmwg\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;In Cotra\u2019s model, this number is a point estimate for \u2018Doubling time of spending on compute&nbsp;for the most expensive training run at start of period (2025)\u2019. When she reviewed this post, Cotra confirmed that it made sense to treat this as the doubling time from 2025 onwards.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnwnozgaaqfvs\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefwnozgaaqfvs\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cI have done very little research into algorithmic progress trends. Of the four main components of my model (2020 compute requirements, algorithmic progress, compute price trends, and spending on computation) I have spent the least time thinking about algorithmic progress.\u201d <a href=\"https://docs.google.com/document/d/1cCJjzZaJ7ATbq8N2fvhmsDOUWdm7t3uSSXv6bD0E_GM/edit#heading=h.epn531rebzyy\"><u>p. 5</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnag1a5j2ga6k\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefag1a5j2ga6k\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cAdditionally, it seems plausible to me that both sets of results would overestimate the pace of algorithmic progress on a transformative task, because they are both focusing on relatively narrow problems with simple, well-defined benchmarks that large groups of researchers could directly optimize.[] Because no one has trained a transformative model yet, to the extent that the computation required to train one is falling over time, it would have to happen via proxies rather than researchers directly optimizing that metric (e.g. perhaps architectural innovations that improve training efficiency for image classifiers or language models would translate to a transformative model). Additionally, it may be that halving the amount of computation required to train a transformative model would require making progress on multiple partially-independent sub-problems (e.g. vision <i>and </i>language <i>and </i>motor control).\u201d <a href=\"https://docs.google.com/document/d/1cCJjzZaJ7ATbq8N2fvhmsDOUWdm7t3uSSXv6bD0E_GM/edit#heading=h.epn531rebzyy\"><u>p. 6</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnrq3znbe25wp\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefrq3znbe25wp\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cI have attempted to take the Hernandez and Brown 2020 halving times (and Paul\u2019s summary of the Grace 2013 halving times) as anchoring points and shade them upward to account for the considerations raised above. There is massive room for judgment in whether and how much to shade upward; I expect many readers will want to change my assumptions here, and some will believe it is more reasonable to shade downward.\" <a href=\"https://docs.google.com/document/d/1cCJjzZaJ7ATbq8N2fvhmsDOUWdm7t3uSSXv6bD0E_GM/edit#heading=h.epn531rebzyy\"><u>p. 6</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnvyw066je3as\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefvyw066je3as\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cI chose to break down the algorithmic progress forecast by hypothesis rather than use a single value describing how the 2020 compute requirements distribution shifts to the left in future years. This is because hypotheses which predict that the amount of computation required to train a transformative model is already very low (such as the Lifetime Anchor hypothesis) seems like they should also predict that further algorithmic progress would be difficult and there is not as much room to reduce compute requirements even further.\u201d <a href=\"https://docs.google.com/document/d/1cCJjzZaJ7ATbq8N2fvhmsDOUWdm7t3uSSXv6bD0E_GM/edit#\"><u>p. 7</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnl84026ya6b\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefl84026ya6b\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;For the relevant questions in the XPT, forecasters were asked to provide their 5th, 25th, 50th, 75th, and 95th percentile forecasts. In this analysis we use the term, \u2018median\u2019 to refer to analyses using the group\u2019s median forecast for the 50th percentile of each question. We use the term \u2018most aggressive\u2019 to refer to analyses using the group medians for the 5th percentile estimate of the question relating to hardware costs, and the 95th percentile estimate for the questions relating to willingness to spend and algorithmic progress. (I.e., this uses the lowest plausible hardware costs and the highest plausible willingness to spend and algorithmic efficiency to give the highest plausible likelihood of TAI.) We use the term \u2018most conservative\u2019 to refer to &nbsp;analyses using the group medians for the 95th percentile estimate of the question relating to hardware costs, and the 5th percentile estimate for the questions relating to willingness to spend and algorithmic progress. (I.e., this uses the highest plausible hardware costs and the lowest plausible willingness to spend and algorithmic efficiency to give the lowest plausible likelihood of TAI.) The most aggressive and most conservative estimates can be considered equivalent to 90% confidence interval for the median estimate. See <a href=\"https://forum.effectivealtruism.org/posts/ccw9v9giKxg8nyLhp/xpt-forecasts-on-some-biological-anchors-inputs#Comparing_Cotra_and_XPT_forecasts\"><u>here</u></a>&nbsp;for context on which XPT questions map to which biological anchors inputs.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnonnqacsxrvf\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefonnqacsxrvf\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;For the relevant questions in the XPT, forecasters were asked to provide their 5th, 25th, 50th, 75th, and 95th percentile forecasts. In this analysis we use the term, \u2018median\u2019 to refer to analyses using the group\u2019s median forecast for the 50th percentile of each question. We use the term \u2018most aggressive\u2019 to refer to analyses using the group medians for the 5th percentile estimate of the question relating to hardware costs, and the 95th percentile estimate for the questions relating to willingness to spend and algorithmic progress. (I.e., this uses the lowest plausible hardware costs and the highest plausible willingness to spend and algorithmic efficiency to give the highest plausible likelihood of TAI.) We use the term \u2018most conservative\u2019 to refer to &nbsp;analyses using the group medians for the 95th percentile estimate of the question relating to hardware costs, and the 5th percentile estimate for the questions relating to willingness to spend and algorithmic progress. (I.e., this uses the highest plausible hardware costs and the lowest plausible willingness to spend and algorithmic efficiency to give the lowest plausible likelihood of TAI.) The most aggressive and most conservative estimates can be considered equivalent to 90% confidence interval for the median estimate. See <a href=\"https://forum.effectivealtruism.org/posts/ccw9v9giKxg8nyLhp/xpt-forecasts-on-some-biological-anchors-inputs#Comparing_Cotra_and_XPT_forecasts\"><u>here</u></a>&nbsp;for context on which XPT questions map to which biological anchors inputs.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fntocoiurtgkl\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreftocoiurtgkl\">^</a></strong></sup></span><div class=\"footnote-content\"><p>For the relevant questions in the XPT, forecasters were asked to provide their 5th, 25th, 50th, 75th, and 95th percentile forecasts. In this analysis we use the term, \u2018median\u2019 to refer to analyses using the group\u2019s median forecast for the 50th percentile of each question. We use the term \u2018most aggressive\u2019 to refer to analyses using the group medians for the 5th percentile estimate of the question relating to hardware costs, and the 95th percentile estimate for the questions relating to willingness to spend and algorithmic progress. (I.e., this uses the lowest plausible hardware costs and the highest plausible willingness to spend and algorithmic efficiency to give the highest plausible likelihood of TAI.) We use the term \u2018most conservative\u2019 to refer to &nbsp;analyses using the group medians for the 95th percentile estimate of the question relating to hardware costs, and the 5th percentile estimate for the questions relating to willingness to spend and algorithmic progress. (I.e., this uses the highest plausible hardware costs and the lowest plausible willingness to spend and algorithmic efficiency to give the lowest plausible likelihood of TAI.) The most aggressive and most conservative estimates can be considered equivalent to 90% confidence interval for the median estimate. See <a href=\"https://forum.effectivealtruism.org/posts/ccw9v9giKxg8nyLhp/xpt-forecasts-on-some-biological-anchors-inputs#Comparing_Cotra_and_XPT_forecasts\">here </a>for context on which XPT questions map to which biological anchors inputs.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fny19nkgqtdpm\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefy19nkgqtdpm\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Not all superforecasters completed the end-of-tournament survey. However, using the forecasts from only the subset of superforecasters who did complete the survey does not change the results. Using this subset\u2019s forecasts as inputs to Cotra\u2019s model outputs the same probability of TAI by 2070 and 2100 (35% and 60%, respectively).</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnq8480uoqlbo\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefq8480uoqlbo\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;The probability of &gt;15% growth by 2100 was asked about in both the main component of the XPT and the postmortem survey. The results here are from the postmortem survey. The superforecaster median estimate for this question in the main component of the XPT was 2.75% (for all superforecaster participants and the subset that completed the postmortem survey).</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn2fjhfiti01s\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref2fjhfiti01s\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;The probability of &gt;15% growth by 2100 was asked about in both the main component of the XPT and the postmortem survey. The results here are from the postmortem survey. The experts median estimate for this question in the main component of the XPT was 19% for all expert participants and 16.9% for the subset that completed the postmortem survey.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn7l90xxd3ls9\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref7l90xxd3ls9\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cBecause they have not been the primary focus of my research, I consider these estimates unusually unstable, and expect that talking to a hardware expert could easily change my mind.\u201d <a href=\"https://docs.google.com/document/d/1qjgBkoHO_kDuUYqy_Vws0fpf-dG5pTU4b8Uej6ff2Fg/edit#heading=h.nmcod2jynsy4\"><u>p. 26</u></a></p><p>\u201cOf all the quantitative estimates in this document, I consider these forecasts the most likely to be knowably&nbsp;mistaken. While most of the other quantitative estimates in this document have a lot more absolute uncertainty associated with them, there is a lot more low-hanging fruit left in improving short- and medium-term hardware price forecasts. For example, my understanding is that semiconductor industry professionals regularly write highly detailed technical reports forecasting a number of hardware cost-efficiency metrics, and I have neither read any of this literature nor interviewed any hardware experts on this question.\u201d <a href=\"https://docs.google.com/document/d/1qjgBkoHO_kDuUYqy_Vws0fpf-dG5pTU4b8Uej6ff2Fg/edit#heading=h.xi6z3buznjb7\"><u>p. 30</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnb7yik8au95a\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefb7yik8au95a\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cThis forecast feels most solid and plausible out to ~2040 or so, beyond which it feels substantially more murky and likely incorrect.\u201d <a href=\"https://docs.google.com/document/d/1cCJjzZaJ7ATbq8N2fvhmsDOUWdm7t3uSSXv6bD0E_GM/edit#heading=h.fmq8f6whj003\"><u>p. 4</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fntcd9uv850ye\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreftcd9uv850ye\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cOther things being equal, the recent slower trend is probably more informative than older data, and is fairly likely to reflect diminishing returns in the silicon chip manufacturing industry.\u201d <a href=\"https://docs.google.com/document/d/1cCJjzZaJ7ATbq8N2fvhmsDOUWdm7t3uSSXv6bD0E_GM/edit#heading=h.96w8mskhfp5l\"><u>p. 2</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnqiimvg78byi\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefqiimvg78byi\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cHowever, the older trend of faster growth has held for a much longer period of time and through more than one change in \u201chardware paradigms.\u201d I don\u2019t think it makes sense to extrapolate the relatively slower growth from 2008 to 2018 over a period of time several times longer than that\u201d <a href=\"https://docs.google.com/document/d/1cCJjzZaJ7ATbq8N2fvhmsDOUWdm7t3uSSXv6bD0E_GM/edit%23heading%3Dh.96w8mskhfp5l\"><u>p. 2</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnwa98esiuxr\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefwa98esiuxr\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cAdditionally, a technical advisor informs me that the <a href=\"https://www.nvidia.com/en-us/data-center/a100/\"><u>NVIDIA A100 GPU</u></a>&nbsp;(released in 2020) is substantially more powerful than the V100 that it replaced, which could be more consistent with a ~2-2.5 year doubling time than a ~3.5 year doubling time.\u201d <a href=\"https://docs.google.com/document/d/1cCJjzZaJ7ATbq8N2fvhmsDOUWdm7t3uSSXv6bD0E_GM/edit#heading=h.96w8mskhfp5l\"><u>p. 3</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn6dof7uvxcbj\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref6dof7uvxcbj\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cOn top of that, it seems that we can expect a one-time ~6x improvement in the next ~5-10 years from specializing chips for deep learning applications.\u201d <a href=\"https://docs.google.com/document/d/1qjgBkoHO_kDuUYqy_Vws0fpf-dG5pTU4b8Uej6ff2Fg/edit#heading=h.xi6z3buznjb7\"><u>p. 29</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnk4d4a3477mi\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefk4d4a3477mi\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cThe above reasoning was focused on listing all the foreseeable improvements on the horizon for silicon-based chips, but I believe there is substantial possibility for both a) \u201cunknown unknown\u201d sources of improvements to silicon chips and b) transition to an exotic form of hardware. For example, at least some companies are actively working on <a href=\"https://en.wikipedia.org/wiki/Optical_computing\"><u>optical computing</u></a>&nbsp;in particular -- I would bet that effective FLOP per dollar will eventually move past the plateau, potentially reaching values multiple orders of magnitude higher. Possibilities that seem somewhat more distant include <a href=\"https://en.wikipedia.org/wiki/Three-dimensional_integrated_circuit\"><u>three-dimensional circuits</u></a>, <a href=\"https://en.wikipedia.org/wiki/Reversible_computing\"><u>reversible computing</u></a>, and <a href=\"https://en.wikipedia.org/wiki/Quantum_computing%23:~:text%3DQuantum%2520computing%2520is%2520the%2520use,are%2520known%2520as%2520quantum%2520computers.\"><u>quantum computing</u></a>.\u201d <a href=\"https://docs.google.com/document/d/1qjgBkoHO_kDuUYqy_Vws0fpf-dG5pTU4b8Uej6ff2Fg/edit#heading=h.jx25381jyv09\"><u>p. 32</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnbw2j45fu8aa\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefbw2j45fu8aa\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cI was using <a href=\"https://www.nvidia.com/en-us/data-center/v100/\">the V100</a>&nbsp;as my reference machine; this was in fact the most advanced publicly available chip on the market as of 2020, but it was released in 2018 and on its way out, so it was better as an estimate for 2018 or 2019 compute than 2020 compute. The more advanced <a href=\"https://www.nvidia.com/en-us/data-center/a100/\">A100</a>&nbsp;was 2-3x more powerful per dollar and released in late 2020 almost immediately after my report was published.\u201d <a href=\"https://www.lesswrong.com/posts/AfH2oPHCApdKicM4m/two-year-update-on-my-personal-ai-timelines%23Making_a_one_time_upward_adjustment_for__2020_FLOP_____\"><u>here</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fns4agwzqg6wi\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefs4agwzqg6wi\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cI was using the rental price of a V100 (~$1/hour), but big companies get better deals on compute&nbsp;than that, by about another 2-3x.\u201d <a href=\"https://www.lesswrong.com/posts/AfH2oPHCApdKicM4m/two-year-update-on-my-personal-ai-timelines%23Making_a_one_time_upward_adjustment_for__2020_FLOP_____\"><u>here</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnc26a00cvb37\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefc26a00cvb37\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cI was assuming ~\u2153 utilization of FLOP/s, which was in line with what people were achieving then, but utilization seems to have improved, maybe to ~50% or so.\u201d <a href=\"https://www.lesswrong.com/posts/AfH2oPHCApdKicM4m/two-year-update-on-my-personal-ai-timelines%23Making_a_one_time_upward_adjustment_for__2020_FLOP_____\"><u>here</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fni6f273fqkr\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefi6f273fqkr\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Question 47: 337, \u201cGiven that five out of eight team forecasters used faulty data, we should conclude that the team forecast is also faulty for all dates and percentiles\u201d, \u201cmany forecasters only used the outdated Wikipedia article referenced in the question description. That article was specifically the price/performance data for the more recent models of GPUs. (The article was updated recently, though it still doesn't cover the dedicated AI infrastructure hardware sold by Nvidia like their new H100 line.) This led to most forecasters using obsolete data for their baselines and predicting future GFLOPS prices that are worse than the already achieved results. The difference in the source data quality fully explains the widely divergent forecasts for 2024, which should normally be simple - and numerically similar - extrapolations of the status quo.\u201d 344, \u201cThis question has a shallow pool of forecasters with limited arguments given for the estimates and erroneous inputs.\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnl38f8tktkq\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefl38f8tktkq\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Question 47: 336, \u201c\u2018The biggest price is not hardware itself but electricity, data-center usage and human AI-scientists salaries.\u2019 The COVID pandemic inflated costs for electricity and hardware but efficiencies in development, and energy costs, will drive this down again.\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnk9tchtr0bp\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefk9tchtr0bp\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Question 47: 336, \u201crecent performance/$ trend is slower than long-run (there could be a return to the longer run trends of OOM every 8 or 4 years.)\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnm319n7vve2\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefm319n7vve2\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Question 47: 336, \u201cuncertainty regarding future technological improvements\u201d; \u201cpotential for discovering new modes of computing leading to discontinuous improvements\u201d. 340, \u201cThe strongest argument for lower extreme forecasts is that some novel technology precipitates discontinuous progress in the trend of the cost of computation for training AI models. Optical neural networks are a promising technology with the potential to improve AI model training in this way.\u201d See also 341, \u201cPotential prospects for a revolutionary technology (e.g. optical computing, quantum computing, reversible and three-dimensional circuits) as per Cotra's report. This could break the foreseen plateau and lead to continued doubling every 3-4 years past 2040 and go back to a 1-2 year doubling.\u201d See also 343, \u201cApplication of advanced AI or AGI to the problem could transformatively decrease prices in an unpredictable way.\u201d See also 344, \u201cQuantum computing seems to be accelerating progress - it's going to get much cheaper much quicker imho\u201d.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fngi0yeduewvm\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefgi0yeduewvm\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Question 47: 336, \u201ctrend of order of magnitude improvement in price-performance every 10 years\u201d.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnieunsj2qvqr\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefieunsj2qvqr\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Question 47: 336, \u201cadvancement may have been slowing since 2010 and rate of decline in prices could continue to slow\u201d. 341, \u201cFaltering of Moore's Law. See the IEEE's 2021 IRDS report, More Moore, Table MM for challenges.\u201d See also 339, \u201cUnstable world and a decline in Moore's law limit the factors that drove down costs in previous years.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnr54exi4l6nl\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefr54exi4l6nl\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Question 47: 336, \u201cwar, especially over Taiwan, could raise prices and/or slow advancement\u201d. See also 339, \u201cUnstable world and a decline in Moore's law limit the factors that drove down costs in previous years. It could take decades for the US to reshore semiconductor manufacturing to the US (and to China). This means Taiwan tensions could throw wrenches into cost dropping.\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnuuntszjpqoh\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefuuntszjpqoh\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Question 47: 336, \u201cglobal economic decline could lead to slower advancement\u201d.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnvvqi9u1adji\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefvvqi9u1adji\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Question 47: 341, \u201cIf early technological progress can be seen as a low-hanging fruit, further progress inherently becomes harder. Many experts (as quoted in Cotra, 2020) expect much less improvement over the next century than we have seen in the past century.\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnakupzs8hdho\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefakupzs8hdho\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Question 47: 336, \u201cpotential for hard/impossible to surpass fundamental physical limits\u201d. 340, \u201cThe strongest argument for higher extreme forecasts is that Moore\u2019s law slows due to physical limitations in manufacturing, GPU cost per compute&nbsp;slows because of limits to parallelization, and there is are&nbsp;no new technologies to pick up the flattening S-curve and continue the trend.\u201d 341, \u201cKnown limitations of specific technologies. The existence of fundamental physical limits.\u201d &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnqpu8rjdnwkn\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefqpu8rjdnwkn\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Question 47: 341, \u201c Lack of high demand (or diminished urgency) for ever more efficient chips.\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fngxsk2ag6pkp\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefgxsk2ag6pkp\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Question 47: 336, \u201cuncertainty regarding future technological development - potential for new tech to lead to higher prices.\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnb9yab4mx67q\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefb9yab4mx67q\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Question 47: 339, \u201cProcessors in the future may not necessarily have greater FLOP rates, which hit limits of Moore's law, but superior memory architecture (e.g. Apple's M1/m2 chips did this by being better suited to scientific computing workloads). Apple's success: access a distributed RAM with almost no latency: <a href=\"https://www.techradar.com/news/apple-m1-destroys-intel-and-amd-in-newly-released-benchmarks%23:~:text%3DApple%2520M1%2520destroys%2520Intel%2520and%2520AMD%2520in%2520newly%252Dreleased%2520benchmarks,-By%2520Jess%2520Weatherbed%26text%3DIt%2527s%2520now%2520been%2520revealed%2520through,the%2520Intel%2520Core%2520i9%252D11900K\"><u>Apple M1 destroys Intel and AMD in newly-released benchmarks | TechRadar</u></a>. FLOP rate may become static at one point, meaning memory optimisations will rule. There may be another metric, such as effective FLOP rate, that might emerge instead.\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnwstb6iaj9fk\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefwstb6iaj9fk\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Question 47: 339, \u201cBuilding processors requires rare earth minerals that will not be as abundant and have other uses (solar cells, Li-ion batteries)\u201d.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn4w6519lrusw\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref4w6519lrusw\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Question 47: 343, \u201cRealization of catastrophic or existential risks could halt or reverse price decreases (or otherwise make them irrelevant).\u201d See also 337, \u201cThe effect of catastrophic risk could be important for 2050 (as per questions 1 to 12): a few of the scenarios could imply a temporal reversion to previous and more expensive forms of computing, such as mechanical computing or paper and pen. This could increase the price of one GFLOPS to values not seen in decades. However, since the forecasters' predictions of such catastrophes are relatively low (around 5%), only the 95th percentile forecasts should be affected by this consideration.\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnjcg29m30g\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefjcg29m30g\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cThis would require doubling spending on the most expensive training run about once every 6 months, which is consistent with what I understand of <a href=\"https://openai.com/blog/ai-and-compute/\"><u>the recent pace of spending scaleup</u></a>&nbsp;and the existing resources of AI companies such as Google.\u201d <a href=\"https://docs.google.com/document/d/1cCJjzZaJ7ATbq8N2fvhmsDOUWdm7t3uSSXv6bD0E_GM/edit#heading=h.z7u133pzed6k\"><u>pp. 4-5</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn3igsee5vlnx\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref3igsee5vlnx\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cThis would require doubling spending on the most expensive training run about once every 6 months, which is consistent with what I understand of <a href=\"https://openai.com/blog/ai-and-compute/\"><u>the recent pace of spending scaleup</u></a>&nbsp;and the existing resources of AI companies such as Google.\u201d <a href=\"https://docs.google.com/document/d/1cCJjzZaJ7ATbq8N2fvhmsDOUWdm7t3uSSXv6bD0E_GM/edit#heading=h.z7u133pzed6k\"><u>pp. 4-5</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnd8pml2evi6e\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefd8pml2evi6e\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cHowever, it does appear that there is enough short-term excitement about deep learning that several companies will have the budget to scale up to training runs costing a few hundred million dollars while only having to demonstrate promising research results and/or very modest value-added for now.\u201d <a href=\"https://docs.google.com/document/d/1qjgBkoHO_kDuUYqy_Vws0fpf-dG5pTU4b8Uej6ff2Fg/edit#heading=h.nc2d14p8i1pd\"><u>p. 36</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnjji9p2haoy\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefjji9p2haoy\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cI would guess that the most compute-intensive training run for an unreleased and/or proprietary model (e.g., a language model powering Google Assistant or Google Translate) is already ~2-8x larger than AlphaStar\u2019s ~1.3e23, costing ~$2-8M.\u201d <a href=\"https://docs.google.com/document/d/1qjgBkoHO_kDuUYqy_Vws0fpf-dG5pTU4b8Uej6ff2Fg/edit#heading=h.nc2d14p8i1pd\"><u>p. 36</u></a>&nbsp;\u201c[N]ote that there will probably be a non-trivial delay between the first time a training run of size X is completed and the first time such a training run is published, and my forecasts are about the former\u201d. <a href=\"https://docs.google.com/document/d/1qjgBkoHO_kDuUYqy_Vws0fpf-dG5pTU4b8Uej6ff2Fg/edit#heading=h.nc2d14p8i1pd\"><u>p. 37</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fniit8rlrsmh\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefiit8rlrsmh\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;<a href=\"https://docs.google.com/document/d/1qjgBkoHO_kDuUYqy_Vws0fpf-dG5pTU4b8Uej6ff2Fg/edit#heading=h.nc2d14p8i1pd\"><u>P. 36</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnoz8765uouig\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefoz8765uouig\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cThe possibility of training a transformative model would provide an enormous incentive. Given this incentive, how much additional money would an AI company be willing and able to spend on a training run over the next couple of decades (if they had already ramped up to ~$1B training runs)?\u201d <a href=\"https://docs.google.com/document/d/1qjgBkoHO_kDuUYqy_Vws0fpf-dG5pTU4b8Uej6ff2Fg/edit#heading=h.ce0olvo3jfpb\"><u>p. 37</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnp42zmh193s\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefp42zmh193s\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cI would guess that an AI company could spend hundreds of billions on a project to train a transformative model by ~2040.\u201d <a href=\"https://docs.google.com/document/d/1qjgBkoHO_kDuUYqy_Vws0fpf-dG5pTU4b8Uej6ff2Fg/edit#heading=h.ce0olvo3jfpb\"><u>p. 38</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnza495v8sl4g\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefza495v8sl4g\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cThe largest AI companies already have enough <a href=\"https://www.upcounsel.com/cash-on-hand\"><u>cash on hand</u></a>&nbsp;that they could relatively quickly deploy tens of billions for a lucrative enough project. As of Q4 2019, both <a href=\"https://www.microsoft.com/\"><u>Microsoft</u></a>&nbsp;and <a href=\"https://abc.xyz/\"><u>Alphabet</u></a>&nbsp;(the parent company of Google and <a href=\"https://deepmind.com/\"><u>DeepMind</u></a>) had more than $100B in cash on hand, and Facebook and Amazon each have more than $50B;[] this&nbsp;could theoretically be spent given buy-in from only a small number of people in leadership positions at each of those companies. Those four companies have already invested heavily in AI research and relevant infrastructure such as data centers; other large tech companies have not made a large investment into AI but also have large amounts of cash on hand (e.g. Apple has over $100B)[] and could imaginably make that transition over ~5-10 years if AI continues to look like a lucrative field.\u201d <a href=\"https://docs.google.com/document/d/1qjgBkoHO_kDuUYqy_Vws0fpf-dG5pTU4b8Uej6ff2Fg/edit#heading=h.ce0olvo3jfpb\"><u>p. 38</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnpswcyp1u5e8\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefpswcyp1u5e8\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cLarge tech companies\u2019 <a href=\"https://en.wikipedia.org/wiki/Market_capitalization\"><u>market capitalization</u></a>&nbsp;tends to be ~10x as large as their cash on hand (close to $1 trillion).\u201d <a href=\"https://docs.google.com/document/d/1qjgBkoHO_kDuUYqy_Vws0fpf-dG5pTU4b8Uej6ff2Fg/edit#heading=h.ce0olvo3jfpb\"><u>p. 38</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnscpkxkjecf\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefscpkxkjecf\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cIt seems unlikely that a company could borrow money much past its market capitalization -- particularly for a single risky venture -- but seems possible that it could borrow something in the range of ~10%-50% of market cap for a project like training a potentially transformative model; this could make $100-500B in additional funds available.\u201d <a href=\"https://docs.google.com/document/d/1qjgBkoHO_kDuUYqy_Vws0fpf-dG5pTU4b8Uej6ff2Fg/edit#heading=h.ce0olvo3jfpb\"><u>p. 38</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnhcedwnmdkbb\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefhcedwnmdkbb\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cI would expect such companies to grow significantly as a share of the economy over the next 20 years in the worlds where AI progress continues, and increase in their borrowing power and ability to attract investment.\u201d <a href=\"https://docs.google.com/document/d/1qjgBkoHO_kDuUYqy_Vws0fpf-dG5pTU4b8Uej6ff2Fg/edit#heading=h.ce0olvo3jfpb\"><u>p. 38</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn9z035kl63u4\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref9z035kl63u4\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;See <a href=\"https://docs.google.com/document/d/1qjgBkoHO_kDuUYqy_Vws0fpf-dG5pTU4b8Uej6ff2Fg/edit#heading=h.1iu8tiytml42\"><u>here</u></a>, particularly, \u201cMy overall intuition based on the above information is that all-in costs for a large project to train an ML model -- including the cost of salaries, data and environments, and all the compute used to experiment at smaller scales -- could get to within ~2-10x the cost of the compute for the single final training run in the medium term.\u201d <a href=\"https://docs.google.com/document/d/1qjgBkoHO_kDuUYqy_Vws0fpf-dG5pTU4b8Uej6ff2Fg/edit#heading=h.1iu8tiytml42\"><u>p. 42</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnsq4ytfzcjjg\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefsq4ytfzcjjg\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cThis suggests that by 2040, an AI project would be willing and able to spend about $100B on computation to train a transformative model.\u201d <a href=\"https://docs.google.com/document/d/1qjgBkoHO_kDuUYqy_Vws0fpf-dG5pTU4b8Uej6ff2Fg/edit#heading=h.1iu8tiytml42\"><u>p. 42</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnmuqvnvxj50o\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefmuqvnvxj50o\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cIf willingness to spend in 2040 is $100B and willingness to spend in 2025 is $1B, this suggests a doubling time of about two years in that period.\u201d <a href=\"https://docs.google.com/document/d/1qjgBkoHO_kDuUYqy_Vws0fpf-dG5pTU4b8Uej6ff2Fg/edit#heading=h.1iu8tiytml42\"><u>p. 42</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fniujw8p1ugwb\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefiujw8p1ugwb\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cEventually, I expect that growth in spending on computation will keep pace with growth in the GDP of the largest national economy.\u201d <a href=\"https://docs.google.com/document/d/1qjgBkoHO_kDuUYqy_Vws0fpf-dG5pTU4b8Uej6ff2Fg/edit#heading=h.d3f6hblbagva\"><u>p. 44</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnoocwg4lvde\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefoocwg4lvde\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cI will assume that the GDP of the largest national economy will grow at ~3% annually, which is similar to the average growth rate of the United States (the current largest national economy) over the last few decades.\u201d <a href=\"https://docs.google.com/document/d/1qjgBkoHO_kDuUYqy_Vws0fpf-dG5pTU4b8Uej6ff2Fg/edit#heading=h.d3f6hblbagva\"><u>p. 44</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnrjcs2p9hg6\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefrjcs2p9hg6\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cAnchoring to the costs of major technological megaprojects such as the Manhattan Project (which cost about ~1.7% of a year of GDP over five years) and the Apollo Project (which cost about ~3.6% of a year of GDP over its four peak years), I assumed that the maximum level of spending on computation for a single training run that could be reached is ~1% of the GDP of the largest country.\u201d <a href=\"https://docs.google.com/document/d/1cCJjzZaJ7ATbq8N2fvhmsDOUWdm7t3uSSXv6bD0E_GM/edit#heading=h.z7u133pzed6k\"><u>p. 5</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnmhiw3fnxyta\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefmhiw3fnxyta\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Question 46: 338, \u201cThe main split between predictions is between lower estimates (including the team median) that anchor on present project costs with a modest multiplier, and higher estimates that follow Cotra in predicting pretty fast scaling will continue up to anchors set by demonstrated value-added, tech company budgets, and megaproject percentages of GDP.\"</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnl9b1tv6dqun\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefl9b1tv6dqun\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Question 46: 340, \u201cPresumably much of these disagreement[s] stem from different ways of looking at recent AI progress. &nbsp;Some see the growth of computing power as range&nbsp;bound by current manufacturing processes and others expect dramatic changes in the very basis of how processors function leading to continued price decreases.\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnetmsawbnk8\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefetmsawbnk8\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Question 46: 337, \u201ctraining cost seems to have been stuck in the $10M figure for the last few years.\u201d; \u201cwe have not seen such a large increase in the estimated training cost of the largest AI model during the last few years: AlphaZero and PALM are on the same ballpark.\u201d 341, \u201cFor 2024, the costs seem to have flattened out and will be similar to now. To be on trend in 2021, the largest experiment would need to be at $0.2-1.5bn. GPT-3 was only $4.6mn\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnizgiixeqjsm\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefizgiixeqjsm\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Question 46: 341, \u201cThe AI impacts note also states that the trend would only be sustainable for a few more years. 5-6 years from 2018, i.e. 2023-24, we would be at $200bn, where we are already past the total budgets for even the biggest companies.\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnz53jukboly\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefz53jukboly\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Question 46: 336, \u201cThe days of 'easy money' may be over. There's some serious belt-tightening going on in the industry (Meta, Google) that could have a negative impact on money spent.\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnejfq54kjbyf\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefejfq54kjbyf\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Question 46: 337, \u201cIt also puts more weight on the reduced cost of compute and maybe even in the improved efficiency of minimization algorithms, see question 48 for instance.\u201d 336, \u201cAfter 2030, we expect increased size and complexity to be offset by falling cost of compute, better pre-trained models and better algorithms. This will lead to a plateau and possible even a reduction in costs.\u201d; \u201cIn the near term, falling cost of compute, pre-trained models, and better algorithms will reduce the expense of training a large language model (which is the architecture which will likely see the most attention and investment in the short term).\u201d See also 343, \u201c$/FLOPs is likely to be driven down by new technologies and better chips. Better algorithm design may also improve project performance without requiring as much spend on raw compute.\u201d See also 339, \u201cThe low end scenarios could happen if we were to discover more efficient training methods (eg take&nbsp;a trained model from today and somehow augment it incrementally each year rather than a single batch retrain or perhaps some new research paradigm which makes training much cheaper).\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnfvkqh3q6u3\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreffvkqh3q6u3\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Question 46: 336, \u201cAdditionally, large language models are currently bottlenecked by available data. Recent results from DeepMind suggest that models over ~100 billion parameters would not have enough data to optimally train. This will lead to smaller models and less compute used in the near term. For example, GPT-4 will likely not be significantly larger than Chinchilla. <a href=\"https://arxiv.org/abs/2203.15556\"><u>https://arxiv.org/abs/2203.15556</u></a>\u201d. 341, \u201cThe data availability is limited.\u201d See also 340, \u201cThe evidence from Chinchilla says that researchers overestimated the value of adding parameters (see <a href=\"https://www.lesswrong.com/posts/6Fpvch8RR29qLEWNH/chinchilla-s-wild-implications\"><u>https://www.lesswrong.com/posts/6Fpvch8RR29qLEWNH/chinchilla-s-wild-implications</u></a>). That is probably discouraging researchers from adding more parameters for a while. Combined with the difficulty of getting bigger text datasets, that might mean text-oriented systems are hitting a wall. (I'm unsure why this lasts long - I think other datasets such as video are able to expand more).\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnl9mc89we9kn\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefl9mc89we9kn\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Question 46: 340, \u201cThe growth might be slowing down now.\u201d; \u201cOr maybe companies were foolishly spending too little a few years ago, but are now reaching diminishing returns, with the result that declining hardware costs mostly offset the desire for bigger models.\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnamxjodiun8\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefamxjodiun8\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Question 46: 340, \u201cLater on, growth might slow a lot due to a shift to modular systems. I.e. total spending on AI training might increase a good deal. Each single experiment could stay small, producing parts that are coordinated to produce increasingly powerful results.\u201d See also 339, \u201c2050 At this point I'm not sure it will be coherent to talk about a single AI experiment, models will probably be long lived things which are improved incrementally rather than in a single massive go. But they'll also be responsible for a large fraction of the global GDP so large expenditures will make sense, either at the state level or corporation.\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn0ix7mtmb6mlg\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref0ix7mtmb6mlg\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Question 46: 340, :Some forecasters don't expect much profit from increased spending on AI training. Maybe the recent spending spree was just researchers showing mpanies&nbsp;are about to come to their senses and stop spending so much money.\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fngysbfx3oe5k\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefgysbfx3oe5k\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Question 46: 340; \u201cThere may some&nbsp;limits resulting from training time. There seems to be agreement that it's unwise to attempt experiments that take more than a few months. Maybe that translates into a limit on overall spending on a single experiment, due to limits on how much can be done in parallel, or datacenter size, or supercomputer size?\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnfafjllwoial\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreffafjllwoial\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Question 46: 343, \u201cMonetization of AGI is in its early stages. As AI creates new value, it's likely that additional money will be spent on increasingly more complex projects.\u201d Note that this argument refers to forecasts higher than the team median forecasts, and the team median for 2024 was $25m.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnsqw8i6ormgq\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefsqw8i6ormgq\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Question 46: 337, \u201cThis will make very much sense in the event that a great public project or international collaboration will be assembled for researching a particular aspect of AI (a bit in the line of project Manhattan for the atomic bomb, the LHC for collider physics or ITER for fusion). The probability of such a collaboration eventually appearing is not small. Other&nbsp;scenario is great power competition between China and the US, with a focus on AI capabilities.\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fno2a7vpo5uh\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefo2a7vpo5uh\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Question 46: 336, \u201cThere is strong competition between players with deep pockets and strong incentives to develop and commercialize 'AI-solutions'.\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnfwql072onar\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreffwql072onar\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Question 46: 344, \u201cAutomatic experiments run by AI are beyond valuation\u201d. 337, \u201cOne forecast suggest&nbsp;astronomical numbers for the largest project in the future, where the basis of this particular forecast is the possibility of an AI-driven economic explosion (allowing for the allocation of arbitrarily large resources in AI).\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnew8ze3kr47\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefew8ze3kr47\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cI have done very little research into algorithmic progress trends. Of the four main components of my model (2020 compute requirements, algorithmic progress, compute price trends, and spending on computation) I have spent the least time thinking about algorithmic progress.\u201d <a href=\"https://docs.google.com/document/d/1cCJjzZaJ7ATbq8N2fvhmsDOUWdm7t3uSSXv6bD0E_GM/edit#heading=h.epn531rebzyy\"><u>p. 5</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnamojubiv4t\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefamojubiv4t\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cAdditionally, it seems plausible to me that both sets of results would overestimate the pace of algorithmic progress on a transformative task, because they are both focusing on relatively narrow problems with simple, well-defined benchmarks that large groups of researchers could directly optimize.# Because no one has trained a transformative model yet, to the extent that the computation required to train one is falling over time, it would have to happen via proxies rather than researchers directly optimizing that metric (e.g. perhaps architectural innovations that improve training efficiency for image classifiers or language models would translate to a transformative model). Additionally, it may be that halving the amount of computation required to train a transformative model would require making progress on multiple partially-independent sub-problems (e.g. vision <i>and </i>language <i>and </i>motor control).</p><p>I have attempted to take the Hernandez and Brown 2020 halving times (and Paul\u2019s summary of the Grace 2013 halving times) as anchoring points and shade them upward to account for the considerations raised above.\u201d <a href=\"https://docs.google.com/document/d/1cCJjzZaJ7ATbq8N2fvhmsDOUWdm7t3uSSXv6bD0E_GM/edit#heading=h.epn531rebzyy\"><u>p. 6</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnmo2eyygb6aq\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefmo2eyygb6aq\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cFor <strong>incremental progress</strong>,<strong>&nbsp;</strong>the main source I used was <a href=\"https://arxiv.org/pdf/2005.04305.pdf\"><u>Hernandez and Brown 2020</u></a>, \u201cMeasuring the Algorithmic Efficiency of Neural Networks.\u201d The authors reimplemented open source state-of-the-art (SOTA) ImageNet models between 2012 and 2019 (six models in total). They trained each model up to the point that it achieved the same performance as AlexNet achieved in 2012, and recorded the total FLOP that required. They found that the SOTA model in 2019, <a href=\"https://arxiv.org/pdf/1905.11946.pdf\"><u>EfficientNet B0</u></a>, required ~44 times fewer training FLOP to achieve AlexNet performance than AlexNet did; the six data points fit a power law curve with the amount of computation required to match AlexNet halving every ~16 months over the seven years in the dataset.# They also show that <a href=\"https://en.wikipedia.org/wiki/Linear_programming\"><u>linear programming</u></a>&nbsp;displayed a similar trend over a longer period of time: when hardware is held fixed, the time in seconds taken to solve a standard basket of mixed integer programs by SOTA commercial software packages halved every ~13 months over the 21 years from 1996 to 2017.\u201d <a href=\"https://docs.google.com/document/d/1cCJjzZaJ7ATbq8N2fvhmsDOUWdm7t3uSSXv6bD0E_GM/edit#heading=h.epn531rebzyy\"><u>p. 6</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn8ct49j3vr5d\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref8ct49j3vr5d\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cAdditionally, it seems plausible to me that both sets of results would overestimate the pace of algorithmic progress on a transformative task, because they are both focusing on relatively narrow problems with simple, well-defined benchmarks that large groups of researchers could directly optimize.# Because no one has trained a transformative model yet, to the extent that the computation required to train one is falling over time, it would have to happen via proxies rather than researchers directly optimizing that metric (e.g. perhaps architectural innovations that improve training efficiency for image classifiers or language models would translate to a transformative model). Additionally, it may be that halving the amount of computation required to train a transformative model would require making progress on multiple partially-independent sub-problems (e.g. vision <i>and </i>language <i>and </i>motor control).</p><p>I have attempted to take the Hernandez and Brown 2020 halving times (and Paul\u2019s summary of the Grace 2013 halving times) as anchoring points and shade them upward to account for the considerations raised above.\u201d <a href=\"https://docs.google.com/document/d/1cCJjzZaJ7ATbq8N2fvhmsDOUWdm7t3uSSXv6bD0E_GM/edit#heading=h.epn531rebzyy\"><u>p. 6</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnofy638opskn\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefofy638opskn\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cI consider two types of algorithmic progress: relatively incremental and steady progress from iteratively improving architectures and learning algorithms, and the chance of \u201cbreakthrough\u201d progress which brings the <a href=\"https://docs.google.com/document/d/1IJ6Sr-gPeXdSJugFulwIpvavc0atjHGM82QjIfUSBGQ/edit#heading=h.5butqad6sph5\"><u>technical difficulty</u></a>&nbsp;of training a transformative model down from \u201castronomically large\u201d / \u201cimpossible\u201d to \u201cbroadly feasible.\u201d\u201d <a href=\"https://docs.google.com/document/d/1cCJjzZaJ7ATbq8N2fvhmsDOUWdm7t3uSSXv6bD0E_GM/edit#heading=h.epn531rebzyy\"><u>p. 5</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn7z8f6ze1278\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref7z8f6ze1278\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Question 48: See 339, \u201c\"On the other hand, an economist would say that one day, the improvement will stagnate as models become \"\"good enough\"\" for efficient use, and it's not worth it to become even better at image classification. Arguably, this day seems not too far off. So growth may either level off or continue on its exponential path. Base rate thinking does not help much with this question\u2026 It eluded the team to find reasonable and plausible answers... stagnation may be just as plausible as further exponential growth. No one seems to know.\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn8uypddzxh5s\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref8uypddzxh5s\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Question 48: 340, \u201cLow range forecasts assume that nobody does any further work on this area, hence no improvement in efficiency.\u201d 341, \u201cThe Github page for people to submit entries to the leaderboard created by OpenAI hasn't received any submissions (based on pull requests), which could indicate a lack of interest in targeting efficiency. <a href=\"https://github.com/openai/ai-and-efficiency\"><u>https://github.com/openai/ai-and-efficiency</u></a>\u201d.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn7w68fm2va6j\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref7w68fm2va6j\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Question 48: 340, \u201cIn addition, it seems pretty unclear, whether this metric would keep improving incidentally with further progress in ML, especially given the recent focus on extremely large-scale models rather than making things more efficient.\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnt02npjjf2zi\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreft02npjjf2zi\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Question 48: 340, \u201cthere seem to bem&nbsp;some hard limits on how much computation would be needed to learn a strong image classifier\u201d.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn3gcw5wtj1ry\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref3gcw5wtj1ry\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Question 48: 341, \u201cThe use cases for AI may demand accuracy instead of efficiency, leading researchers to target continued accuracy gains instead of focusing on increased efficiency.\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnu5lg1oldi9\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefu5lg1oldi9\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Question 48: 341, \u201cA shift toward explainable AI (which could require more computing power to enable the AI to provide explanations) could depress growth in performance.\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnefls1wfvo5f\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefefls1wfvo5f\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Question 48: 336, \u201cLower end forecasts generally focused on the fact that improvements may not happen in a linear fashion and may not be able to keep pace with past trends, especially given the \"lumpiness\" of algorithmic improvement and infrequent updates to the source data.\u201d 338, \u201cThe lowest forecasts come from a member that attempted to account for long periods with no improvement. &nbsp;The reference table is rarely updated and it only includes a few data points. &nbsp;So progress does look sporadic.\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn7vs2ikh3xl3\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref7vs2ikh3xl3\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Question 48: 337, \u201cThe most significant disagreements involved whether very rapid improvement observed in historical numbers would continue for the next eight years. &nbsp;A rate of 44X is often very hard to sustain and such levels usually revert to the mean.\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnaygwmerb4wf\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefaygwmerb4wf\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Question 48: 340, \u201cThe higher range forecasts simply stem from the extrapolation detailed above.</p><p>Pure extrapolation of the 44x in 7 years would yield a factor 8.7 for the 4 years from 2020 to 2024 and a factor of 222 for the years until 2030. =&gt; 382 and 9768.\u201d 336, \u201cBase rate has been roughly a doubling&nbsp;in efficiency every 16 months, with a status quo of 44 as of May 2019, when the last update was published. Most team members seem to have extrapolated that pace out in order to generate estimates for the end of 2024 and 2030, with general assumption being progress will continue at roughly the same pace as it has previously.\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnsl68iqurcv\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefsl68iqurcv\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Question 48: 336, \u201cThe high end seems to assume that progress will continue and possibly increase if things like quantum computing allow for a higher than anticipated increase in computing power and speed.\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnevo36u0up86\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefevo36u0up86\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Question 48: 341, \u201cAI efficiency will be increasingly important and necessary to achieve greater accuracy as AI models grow and become limited by available compute.\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn38gxe0yakea\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref38gxe0yakea\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Question 48: 341.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnq5gtiwextll\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefq5gtiwextll\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Question 48: 337, \u201cThe most significant disagreements involved whether very rapid improvement observed in historical numbers would continue for the next eight years. &nbsp;A rate of 44X is often very hard to sustain and such levels usually revert to the mean. &nbsp;However, it seems relatively early days for this tech, so this is plausible.\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnpi55hwql9bo\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefpi55hwql9bo\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;For the relevant questions in the XPT, forecasters were asked to provide their 5th, 25th, 50th, 75th, and 95th percentile forecasts. In this analysis we use the term, \u2018median\u2019 to refer to analyses using the group\u2019s median forecast for the 50th percentile of each question. We use the term \u2018most aggressive\u2019 to refer to analyses using the group medians for the 5th percentile estimate of the question relating to hardware costs, and the 95th percentile estimate for the questions relating to willingness to spend and algorithmic progress. (I.e., this uses the lowest plausible hardware costs and the highest plausible willingness to spend and algorithmic efficiency to give the highest plausible likelihood of TAI.) We use the term \u2018most conservative\u2019 to refer to &nbsp;analyses using the group medians for the 95th percentile estimate of the question relating to hardware costs, and the 5th percentile estimate for the questions relating to willingness to spend and algorithmic progress. (I.e., this uses the highest plausible hardware costs and the lowest plausible willingness to spend and algorithmic efficiency to give the lowest plausible likelihood of TAI.) The most aggressive and most conservative estimates can be considered equivalent to 90% confidence interval for the median estimate. See <a href=\"https://forum.effectivealtruism.org/posts/ccw9v9giKxg8nyLhp/xpt-forecasts-on-some-biological-anchors-inputs#Comparing_Cotra_and_XPT_forecasts\"><u>here</u></a>&nbsp;for context on which XPT questions map to which biological anchors inputs.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnwhj1pui5tyc\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefwhj1pui5tyc\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cI have attempted to take the Hernandez and Brown 2020 halving times (and Paul\u2019s summary of the Grace 2013 halving times) as anchoring points and shade them upward to account for the considerations raised above. There is massive room for judgment in whether and how much to shade upward; I expect many readers will want to change my assumptions here, and some will believe it is more reasonable to shade downward.\" <a href=\"https://docs.google.com/document/d/1cCJjzZaJ7ATbq8N2fvhmsDOUWdm7t3uSSXv6bD0E_GM/edit#heading=h.epn531rebzyy\"><u>p. 6</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn9u7wlabe4oc\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref9u7wlabe4oc\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cThey found that the SOTA model in 2019, <a href=\"https://arxiv.org/pdf/1905.11946.pdf\"><u>EfficientNet B0</u></a>, required ~44 times fewer training FLOP to achieve AlexNet performance than AlexNet did; the six data points fit a power law curve with the amount of computation required to match AlexNet halving every ~16 months over the seven years in the dataset. They also show that <a href=\"https://en.wikipedia.org/wiki/Linear_programming\"><u>linear programming</u></a>&nbsp;displayed a similar trend over a longer period of time: when hardware is held fixed, the time in seconds taken to solve a standard basket of mixed integer programs by SOTA commercial software packages halved every ~13 months over the 21 years from 1996 to 2017.\u201d <a href=\"https://docs.google.com/document/d/1cCJjzZaJ7ATbq8N2fvhmsDOUWdm7t3uSSXv6bD0E_GM/edit#heading=h.epn531rebzyy\"><u>p. 6</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn6bmtulxqjiv\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref6bmtulxqjiv\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cPaul is familiar with the results, and he believes that algorithmic progress across the six domains studied in Grace 2013 is consistent with a similar but slightly slower rate of progress, ranging from 13 to 36 months to halve the computation required to reach a fixed level of performance.\u201d <a href=\"https://docs.google.com/document/d/1cCJjzZaJ7ATbq8N2fvhmsDOUWdm7t3uSSXv6bD0E_GM/edit#heading=h.epn531rebzyy\"><u>p. 6</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnaoyi4t53r0g\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefaoyi4t53r0g\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cthe&nbsp;main source I used was <a href=\"https://arxiv.org/pdf/2005.04305.pdf\"><u>Hernandez and Brown 2020</u></a>\u2026<a href=\"https://intelligence.org/files/AlgorithmicProgress.pdf\"><u>Grace 2013</u></a>&nbsp;(\u201cAlgorithmic Progress in Six Domains\u201d) is the only other paper attempting to systematically quantify algorithmic progress that I am currently aware of\u2026 I have chosen not to examine it in detail because a) it was written largely before the deep learning boom and mostly does not focus on ML tasks, and b) it is less straightforward to translate Grace\u2019s results into the format that I am most interested in (\u201cHow has the amount of computation required to solve a fixed <a href=\"https://docs.google.com/document/d/1KsItCUEYR4_yGKF2ehyHiUYWWrPo28_rqp0oIq0BRqA/edit#heading=h.oy8zfrwjlptx\"><u>task</u></a>&nbsp;decreased over time?\u201d)\u201d. <a href=\"https://docs.google.com/document/d/1cCJjzZaJ7ATbq8N2fvhmsDOUWdm7t3uSSXv6bD0E_GM/edit#heading=h.epn531rebzyy\"><u>p. 6</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn05naqbi3hvgi\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref05naqbi3hvgi\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;For the relevant questions in the XPT, forecasters were asked to provide their 5th, 25th, 50th, 75th, and 95th percentile forecasts. In this analysis we use the term, \u2018median\u2019 to refer to analyses using the group\u2019s median forecast for the 50th percentile of each question. We use the term \u2018most aggressive\u2019 to refer to analyses using the group medians for the 5th percentile estimate of the question relating to hardware costs, and the 95th percentile estimate for the questions relating to willingness to spend and algorithmic progress. (I.e., this uses the lowest plausible hardware costs and the highest plausible willingness to spend and algorithmic efficiency to give the highest plausible likelihood of TAI.) We use the term \u2018most conservative\u2019 to refer to &nbsp;analyses using the group medians for the 95th percentile estimate of the question relating to hardware costs, and the 5th percentile estimate for the questions relating to willingness to spend and algorithmic progress. (I.e., this uses the highest plausible hardware costs and the lowest plausible willingness to spend and algorithmic efficiency to give the lowest plausible likelihood of TAI.) The most aggressive and most conservative estimates can be considered equivalent to 90% confidence interval for the median estimate. See <a href=\"https://forum.effectivealtruism.org/posts/ccw9v9giKxg8nyLhp/xpt-forecasts-on-some-biological-anchors-inputs#Comparing_Cotra_and_XPT_forecasts\">here</a> for context on which XPT questions map to which biological anchors inputs.</p></div></li></ol>", "user": {"username": "Forecasting Research Institute"}}, {"_id": "NM6Qpg5MfSZfs5Gh7", "title": "Investigating the Long Reflection", "postedAt": "2023-07-24T16:26:48.817Z", "htmlBody": "<h2>Summary</h2><p>The&nbsp;<i>Long Reflection</i> is a period in which humanity tries to minimize the number of irreversible actions and focuses on moral reflection and working out a macrostrategy for its future.&nbsp;</p><p>This post discusses the concept in more detail than done before and collects arguments for and against the Long Reflection.</p><p>Claims</p><ul><li>beyond a time for philosophy, the LR is also a period in which we need to negotiate a framework for space expansion that minimizes its risks</li><li>there is a fundamental paradox at the heart of the Long Reflection: in order to preserve option-value for the future, humanity might have to take measures that themselves risk value lock-in&nbsp;</li><li>one of the central challenges will be how to reconcile an atmosphere of open debate and open-mindedness with the enforcement mechanisms that make sure no one defects</li><li>the Long Reflection is not likely to happen but it might nevertheless be valuable to investigate it further</li></ul><h2>&nbsp;</h2><h2>Introduction</h2><p>For a few years now the most prominent answer to \u2018What if we successfully avoid existential risk?\u2019 has been Will MacAskill\u2019s concept of the Long Reflection - also restated in Toby Ord\u2019s book The Precipice.[4,5]&nbsp;</p><p>The concept has been discussed in several places, but there has not been a deeper investigation of the concept so far. This is the role this post is seeking to fulfil.&nbsp;</p><h2><br>Structure of the Long Reflection</h2><h3>Definition</h3><p>We shall define the Long Reflection here as a period in which humanity tries to minimize the number of irreversible actions and focuses on&nbsp;<i>moral reflection</i> and&nbsp;<i>working out a macrostrategy for its future</i>.&nbsp;</p><p>Having reached the state of existential security, humanity will almost certainly be in possession of Transformative Artificial Intelligence (TAI), since it\u2019s hard to imagine reaching that state if TAI is still in the future. &nbsp;This means that solving empirical and scientific questions will be comparatively easy. We can expect that <strong>the key obstacle to a coherent macrostrategy will be the negotiation between different interest groups</strong></p><h3><strong>When</strong> to start</h3><p>The right point to start the Long Reflection is when humanity has reached existential security. Here we define existential security as the state in which existential risk across all time is very low.&nbsp;</p><p>Given that the universe will probably be inhabitable for a very long time, this might necessitate reducing existential risk to an extremely low level. If we conservatively assume that humanity only could survive until the end of the last stars in approximately 10^14 years, this would require us to reduce existential risk to 10^(-17) annually to reach a total risk of 0.1%.[1]&nbsp;</p><p>A more realistic goal may be to get to a state in which we can be sure existential risk will decline with time in the future and total existential risk will converge to a finite value. This way we can establish a lower bound for total existential risk going forward.&nbsp;&nbsp;</p><p>An open question is how high the existential risks stemming from&nbsp;<strong>unknown unknowns</strong> are. It is of course very hard to give examples for risks from unknown unknowns, but an interesting one is how the risk of power outages caused by solar flares would look like to someone from 1500 that doesn\u2019t understand the concept of electricity. Another place where risks from unknown unknowns might be situated is in the realm of complex risks stemming from interactions of many separate agents.&nbsp;</p><p>It may be the best option to first attempt to minimize known existential risks, then start a process to explore fundamental science and social science in a way that can identify risk from unknown unknowns. This would likely require humanity to conduct this process while taking appropriate care to handle the possible information hazards that might be encountered.</p><p>Another question is how confident we are in our estimate. As estimating total existential risk - especially going forward - will be a challenging task even with advanced AI, there should be continuing investigation of the issue with plans to quickly refocus on x-risk reduction if it is deemed necessary again.</p><h3><br>Hard to reverse changes</h3><p>There are some changes that seem to be truly irreversible, but there is a much broader category of changes that seem reversible in theory, but only at significant cost.</p><p>One clear source of irreversibility are the laws of physics. Catastrophes stemming from accidental or deliberate manipulation of them should already be accounted for by our mechanism for ensuring a continued state of existential security.&nbsp;</p><p>The most relevant potential irreversible change stemming directly from the laws of physics are mechanisms associated with the cosmic speed limit of the speed of light - contained in the theory of special relativity and confirmed experimentally ever since their discovery.&nbsp;</p><p>Due to the cosmic speed limit combined with the expansion of the universe it is possible to send objects at sufficient speed to make them unreachable from earth after a certain period of time.[2] Using self-replicating probes this could give certain actors access to large amounts of matter, space and energy without a possibility of influence by other human descendent actors.&nbsp;</p><p>Another thing that is truly irreversible is active&nbsp;<a href=\"https://en.wikipedia.org/wiki/METI_(Messaging_Extraterrestrial_Intelligence)\"><u>Messaging Extraterrestrial Intelligence (METI)</u></a>. This threatens to take away option value in potential future encounters if previous messages have already revealed crucial information or entrenched a certain view of humanity.&nbsp;</p><p>Beyond that, powerful agentic AGIs might also be a source of irreversibility. Deployed by choice or by accident, we must assume incorrigible superintelligence has the ability to maintain their internal goals and power against all future attempts to modify them. It is possible to imagine scenarios in which humanity might want to choose this path despite its risk, like if AI sovereigns proves necessary to ensure the absence of military confrontation after space expansion, but this is a choice that should only be made after the Long Reflection.&nbsp;&nbsp;&nbsp;&nbsp;</p><p>Another place we might expect irreversibility is consciousness, although this doesn\u2019t rise to the same level of&nbsp;<i>physical&nbsp;</i>impossibility as the previous example. It\u2019s likely that at a certain level of technological progress humanity will have the ability and want to directly modify its consciousness. There may be certain places in mind space that are powerful attractor states that actors will find impossible to leave. This is related to concerns about wireheading in the literature.&nbsp;[9] In general this era is more speculative, as the laws of consciousness are barely known at all compared to our current knowledge of physics.&nbsp;</p><p>The danger of self-replicating probes is that even a small object escaping the solar system has the possibility to harness the energy from a galaxy or star system it reaches at exponential speed. If the target system then optimizes for defense, the actor that initiated the processes might be very hard to dislodge. Wars utilizing self-replicating probes on such scale run the risk of converting a significant amount of the universe into more warmachines.[7] If this process is initiated by a malevolent actor this could result in significant amounts of suffering.&nbsp;&nbsp;</p><h3>Goals</h3><p><strong>Figure out what is of value</strong>: If moral realism is true this may have a single correct answer that we could hope to confirm with a reasonable level of confidence. If morality turns out to be more subjective, we could still imagine humanity gradually converging on a narrower and narrower set of ethical beliefs and reach a reflective equilibrium.&nbsp;</p><p><strong>Negotiate a framework to minimize the risks of space expansion</strong>: We are currently unsure of how high the risks of space expansion and other wide-ranging, irreversible changes are. Obviously a goal for the Long Reflection would be to answer these questions and design a framework to minimize them going forward.&nbsp;</p><p><strong>Learn as much as needed about basic science and technological possibilities</strong>: To figure out its moral priorities and design a framework for its future, humanity will probably need an almost complete understanding of basic science and all the technological possibilities.</p><h3>Important Questions</h3><p>In this paragraph I want to give a few examples of the questions that we might want to resolve during the Long Reflection. This list is obviously not comprehensive and some of the questions may turn out to resolve itself even before we begin it.&nbsp;</p><h3>Philosophical Questions</h3><ul><li>What things are of intrinsic value? Is value in the universe bounded or unbounded?</li><li>What are our moral obligations? Do we have an obligation to maximize value in the universe?</li><li>If digital consciousness is possible, is there a reason to not prefer this to maintaining human consciousness in a biological substrate?</li><li>What does the space of possible minds and consciousness look like and which points are most preferable?</li><li>If coordination on crucial issues is not possible, when and by whom should violence be used?</li><li>What are the ethics of interacting with Extraterrestrial Intelligence?</li></ul><h3>Political Questions</h3><ul><li>What framework can the relevant actors agree on for<ul><li>space expansion and use of the cosmic commons</li><li>self-replicating probes</li><li>control of digital consciousness</li><li>potentially dangerous physics experiments</li></ul></li><li>What are desirable cosmic projects and how can we best coordinate to achieve them?</li><li>What should our response to contact with Extraterrestrial Intelligence look like?</li></ul><h3><br>When to stop reflecting</h3><p>This is a hard point to establish in advance because future knowledge is hard to predict and we don\u2019t know what further problems we will encounter as we learn more.&nbsp;</p><p>The most clear endpoint is when humanity has discoverd&nbsp;<strong>a certain moral view or a set of compatible moral views</strong> and has attained a high level of confidence in their truth and how to implement them. This may be because moral realism is true and we are confident we figured out all knowable moral facts. Another option is that, while not ontologically \u201ctrue\u201d, certain views are so intuitive to most humans after a lot of reflection that there is very strong convergence.&nbsp;</p><p>If there is no set of compatible views that we converge on, another natural endpoint is when we reach a&nbsp;<a href=\"https://plato.stanford.edu/entries/reflective-equilibrium/\"><strong><u>reflective equilibrium</u></strong></a>, meaning individuals or coalition do not converge on a moral view, but the different views are compatible. The most obvious next step then is to negotiate for a common framework in which different conceptions of the good can be pursued. It is likely that towards the end of the Long Reflection, humanity will have a better idea how this could be achieved, but in case there is no agreement, there should be a fall back option that all agents have agreed to in advance.&nbsp;</p><p>It is of course possible (perhaps even the most likely outcome) that we neither converge on a clear moral truth nor reach reflective equilibrium. This outcome is &nbsp;the one we should prepare for most. Given the fact that for certain value-systems delaying space expansion has a very high cost, we should ensure in advance that the Long Reflection is temporary.&nbsp;</p><p>This could of course be done by simply setting a certain time limit in advance, but it seems almost impossible to foresee how long a reflection time is actually appropriate. A superior option could be to supplement this with a metric that measures how much people are updating on new information and the arguments of others - as long as people are still updating it makes sense to continue the reflection period. Another measure could be the amount and type of future expected technological process. We should also make sure some of the key questions (e.g. regarding cosmology, consciousness) are answered.</p><p>We could do this by agreeing in advance to compromise in a certain framework. This may either mean dividing the resources between groups according to a certain mechanism or giving control to a coalition that comes out as the winner of a previously agreed voting system.&nbsp;</p><h3><br>Who will oppose the Long Reflection</h3><p>It is likely that some actors or groups will oppose a period of reflection. This may include egoistic actors that only care about their own preferences or potentially fanatical actors that assign a very small probability to them changing their values upon reflection. Some actors may also aim to violently enforce their values, even against the wishes of most others.&nbsp;</p><p>There will also likely be opportunist actors that will try to defect before or during the reflection period in hope of gaining access to more resources than they could in a direct competition or after the reflection period. Others may defect at the point where they realize that the process isn\u2019t going the way they had hoped.&nbsp;</p><p>Some people may also assign intrinsic value to war and competition and believe that it\u2019s better to decide the future of the universe in that way rather than by reflection and cooperation.&nbsp;</p><p>&nbsp;</p><h3>Coordinating the Long Reflection</h3><p>Given the high probability of opposition and defection, one of the central challenges will be how to&nbsp;<strong>reconcile an atmosphere of open debate and open-mindedness with the enforcement mechanisms that make sure no one defects</strong>.&nbsp;</p><p>An intensive exploration of fundamental science might also bring to light knowledge that could constitute an existential risk if it were to get into the wrong hands. Here we encounter another trade-off between control and freedom.&nbsp;</p><p>Actors that believe we will air too far towards enforcement are likely to defect, while actors that think we will lean too far into freedom may seek to unilaterally disempower possibly harmful groups.&nbsp;</p><h2><br>Arguments for the Long Reflection</h2><p>Some argue that our moral values have improved significantly over the past centuries and we have reason to expect that trend to continue. So many actions we take may later be viewed as morally wrong or even catastrophic. This becomes more important the more impactful and harder to reverse our actions get, so it\u2019s necessary to engage in a long period of moral reflection if one wants to minimize that risk.&nbsp;</p><p>But even if we expand beyond Earth in a manner that is reversible at a limited cost and start to modify our biology on a fundamental level we may lose for humanity wide reflection and bargaining. If a lot of cooperation is necessary to avoid bad outcomes of space expansion it will be important to ensure that before it is too late.&nbsp;</p><p>From this angle we can add a practical argument for a Long Reflection: Space Expansion on a large scale entails&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/z5cSbt8DaRuAu5Xsb/risks-from-bad-space-governance\"><u>risks</u></a> that could be avoided if we deliberately steer the process in an advantageous direction. But space expansion might no longer be steerable beyond a certain point due to the long distances involved. So we want to make sure we have reflected on the issue sufficiently and ideally have reached some sort of technological maturity, so we know against which technical background we should design our space governance framework.</p><p>Surveying s-risks and the risk from bad space governance, it seems like the risks from not engaging in a long reflection are significantly bigger than doing so.<br>&nbsp;</p><h2>Arguments against the Long Reflection</h2><p>By blocking all changes that might be irreversible or very hard to reverse, we might severely limit fundamental goals of some individuals. Stopping this change would potentially require a &nbsp;very intrusive \u2018world government\u2019 that might not be desirable and might itself carry very large risks.[3] The higher we believe the incentives for defection are, the more severe the enforcement mechanisms have to be and the higher the risks.&nbsp;&nbsp;&nbsp;</p><p>The society engaging in a Long Reflection might have to adopt significantly different values and it may come to see this new state as ideal. If a strong majority is required to leave it, the society may continue forever, which for certain value systems constitutes a huge risk.[3]&nbsp;</p><p>Others argue that it might be unethical to subject individuals to live during the Long Reflection. Even if it makes the total future better, it might mean people during the Long Reflection are not allowed to do certain things, for instance modife their consciousness in certain ways.&nbsp;[8]&nbsp;&nbsp;</p><p>Perhaps the most simple argument against the Long Reflection is that it has an opportunity cost. If you think that the most likely outcome after existential security is reached is not very far from the ideal outcome reached after a longer period of reflection, holding off on important actions may simply not be worth the energy and matter that is lost during the period.&nbsp;&nbsp;</p><h2><br>Is the long reflection likely to happen?</h2><p>The Long Reflection is a coordination problem on a level that has not been seen in any other situation. As humanity is currently struggling with coordination problems, even on much smaller scale, our prior should probably be that something like the Long Reflection is unlikely to happen.&nbsp;</p><p>However, there are reasons to think that the probability is not extremely low. Human history until now has been a non-continuous but steady process of increasing coordination. Compared to a 1000 years ago, modern states allow for cooperation on a level that is extremely impressive. If this process continues, the level of global cooperation required for something like the Long Reflection is at least in the realm of possibility.&nbsp;</p><p>The world on the verge of humanity reaching existential security would also be radically different from what we have today. Since reaching existential security will very likely entail the possession of TAI that is aligned with human preferences, we might expect that this time will also mark the end of material abundance. Such a world has been described as&nbsp;<a href=\"https://www.effectivealtruism.org/articles/ea-global-2018-paretotopian-goal-alignment\"><u>\u201cParetotopia\u201d</u></a>. All agents suddenly have a lot more to gain since there are so many resources to divide up.&nbsp;</p><p>While those arguments don\u2019t strike me as strong enough towards the view that the Long Reflection is a likely outcome, they do seem strong enough to not dismiss the possibility of the scenario completely.&nbsp;</p><h2><br>Why it\u2019s worth thinking about this now</h2><p>It may seem to some like the ability to make irreversible changes to the universe is a long way off, but there is a significant chance that this is possible in the next 100 years.</p><p>In a recent survey of ML researchers conducted by AI Impacts, the average result was a 50% chance of Human Level AI in 37 years. Additionally, \"The median respondent thinks there is an \u201cabout even chance\u201d that an argument given for an intelligence explosion is broadly correct.\" The forecasting website Metaculus&nbsp;<a href=\"https://www.metaculus.com/questions/5121/date-of-artificial-general-intelligence/\"><u>predicts</u></a> a median occurance of Artificial General Intelligence for the year 2034. This leads to the conclusion that a significant speedup of technological progress in the next few decades is a realistic possibility, which would allow for some of the irreversible changes listed in the relevant section above.&nbsp;</p><p>If we want policymakers to be sensible to issues addressed here we might want to start advocacy and research in this field as early as possible. Making a well thought out case for the Long Reflection or similar proposals can help contribute to increased awareness of this kind of macrostrategic reasoning. The Long Reflection is a good example of a concrete proposal in this field that can be argued over which is likely to contribute to its growth.&nbsp;</p><p>&nbsp;</p><h2>Conclusion</h2><p>There is a fundamental paradox at the heart of the Long Reflection: in order to preserve option-value for the future humanity might have to take measures that themselves risk value lock-in. This means the whole concept is fraught with risk.</p><p>However, uncontrolled space expansion itself comes with risk and it seems likely that something like a Long Reflection could help to go about space expansion in a coordinated and controlled way.&nbsp;</p><h3>&nbsp;</h3><h2>Bibliography</h2><p>[1] Fred Adams and Greg Laughlin. 2000.&nbsp;<i>The five ages of the universe: inside the physics of eternity</i>. Touchstone, London.</p><p>[2] Stuart Armstrong, Anders Sandberg, and Se\u00e1n \u00d3h\u00c9igeartaigh. 2015. Outrunning the Law: Extraterrestrial Liberty and Universal Colonisation. In&nbsp;<i>The Meaning of Liberty Beyond Earth</i>, Charles S. Cockell (ed.). Springer International Publishing, Cham, 165\u2013186. DOI:https://doi.org/10.1007/978-3-319-09567-7_11 @</p><p>[3] Hanson, Robin. 2021. \u2018Long Reflection\u2019 Is Crazy Bad Idea.&nbsp;<i>Overcoming Bias</i>. Retrieved August 24, 2022 from https://www.overcomingbias.com/2021/10/long-reflection-is-crazy-bad-idea.html</p><p>[4] WILLIAM MACASKILL. 2022.&nbsp;<i>What we owe the future: the million-year view.</i> ONEWORLD PUBLICATIONS, S.l.</p><p>[5] Toby Ord. 2020.&nbsp;<i>The precipice: existential risk and the future of humanity</i>. Bloomsbury academic, london New York (N.Y.).</p><p>[6] Sandberg, Anders and Stuart Armstrong. 2013. Hunters in the dark: Game theory analysis of the deadly probes scenario.&nbsp;<i>Poster Present. Natl. Astron. Meet. R. Astonomical Soc. NAM2013</i> (2013).</p><p>[7] Stocker, Felix. 2021. Reflecting on the Long Reflection.&nbsp;<i>felixstocker.com</i>. Retrieved August 24, 2022 from https://www.felixstocker.com/blog/reflecting-on-the-long-reflection</p><p>[8] Turchin, Alexey. Wireheading as a Possible Contributor to Civilizational Decline. 2018 .<br>&nbsp;</p><p><br><i>This is one of the pieces written as part of the CHERI Summer Research Program 2022. I whole-heartedly thank the organisers for giving me this opportunity and Joseph Levin for being my mentor. Joseph was especially helpful working on this piece in supplying a draft of his.</i></p><p><i>A significant proportion of work during that time went into the Space Futures Initiative research agenda. I am planning to publish the rest of my work going forward.&nbsp;</i></p><p><i>Originally this was meant to be part of a larger sequence I planned to write. Since then I have decided against continuing that work and am publishing the drafts as they are.&nbsp; I might write about my view on Space Governance as a cause area in the future.</i></p><p><i><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NM6Qpg5MfSZfs5Gh7/msdfqif0guxdzukdby0p\"></i></p><p><br>&nbsp;</p>", "user": {"username": "Yannick_Muehlhaeuser"}}, {"_id": "3pEdtm2DfAzPftojw", "title": "A tool to compare the ease of operating in different countries", "postedAt": "2023-07-28T05:58:48.632Z", "htmlBody": "<p><strong>TLDR:</strong> <a href=\"https://docs.google.com/spreadsheets/d/1-kiHE6UYviyOJfyBcP6-FflgvQlqBC7NRrxnpmQzefo/edit?usp=sharing\">I present a linear model</a> for comparing the ease of operating a philanthropic organization in different countries. Make a copy and adjust the weights to your needs.</p><p><i>I am a researcher at the Center for Exploratory Altruism Research (CEARCH), but I created this tool in my own time as a personal project.</i></p><p><strong>Why use it? </strong>Deciding which country to operate a charity in depends on lots of factors, some of which are fairly universal: the costs of operating, the availability of talent, and the risks of crime and corruption. This tool provides a quick way of assessing countries on these factors.</p><p>It won't be much use with more cause-specific factors like the global distribution of the problem you are trying to solve, your personal experience, or where your intervention is proven to work.</p><p><strong>How to use it? </strong><a href=\"https://docs.google.com/spreadsheets/d/1-kiHE6UYviyOJfyBcP6-FflgvQlqBC7NRrxnpmQzefo/edit?usp=sharing\">Open the spreadsheet</a>, make a copy and start experimenting! Some key information:</p><ul><li><i>Lower scores are better</i>. Each indicator is between 0 and 1</li><li>The total score is calculated by multiplying each indicator in the row by the relevant weight at the top of the column. You should change the weights according to your needs</li><li>If you find the scaling of the indicators too subjective, use the \"ranking\" version on the second tab</li><li>The \"intervention effectiveness\" indicators are proxies for how easy it is to help people (by tackling poverty, improving health) in the country. I leave these weights at zero by default.</li></ul><p><strong>What are the limitations?</strong></p><ul><li>The indicators are derived from hard data, but most of them are subjectively scaled</li><li>The hard data can be quite crap: the education data ranks Singapore's education level alongside Kyrgyzstan and Bulgaria.</li><li>The model provides very limited information on health/welfare outcomes in each country: if you are starting a malaria charity, you will need to find extra data on the incidence of malaria!</li><li>The weights are subjec<strong>t</strong>ive</li><li>Some countries are missing (missing countries with population above 2 million are: Qatar, Eritrea, Kuwait, Palestine, Oman, Singapore, Libya, Hong Kong, Cuba, Cambodia, North Korea, Saudi Arabia)</li></ul><p><strong>Could this be better? </strong>Let me know if you think the tool could be upgraded. Double credit if you can link to a data source that could be added.</p><p><strong>Some trends I noticed: </strong>In the comments I'll add some of my findings from playing around with the tool for an hour or so.</p>", "user": {"username": "Stan Pinsent"}}, {"_id": "vqPy7TkBbzrAkxCf7", "title": "Updates to the flow of funding in EA movement building post", "postedAt": "2023-07-25T00:44:48.771Z", "htmlBody": "<p><i>This is an summary of updates made to my previous post, </i><a href=\"https://forum.effectivealtruism.org/posts/nnTQaLpBfy2znG5vm/the-flow-of-funding-in-ea-movement-building\"><i><u>The flow of funding in EA movement building</u></i></a><i>.&nbsp;</i></p><h2>Overall Changes</h2><p>Total funding tracked in the data increased to $290M (from $245M). New data is from:</p><ul><li>Several private donors and Longview Philanthropy who shared (previously non-public) donation &amp; grant recommendation data</li><li>Global health &amp; wellbeing spending e.g. GiveWell, ACE and some animal orgs (at a discounted rate since these organizations aren\u2019t explicitly focused on EA movement building but did contribute to the growth of the EA movement)</li><li>The inclusion of some longtermist research organizations such as FHI which have helped do field building (also at a discounted rate)</li></ul><p><strong><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/vqPy7TkBbzrAkxCf7/nqnwvcxiws8rjugd72ox\"></strong></p><h2>Changes to proportions and funding over time</h2><p>During the 2012-2016 period, funding tracked in my data roughly doubled from ~$4M to ~$8.9M (quick estimate) including $4M in funding to GiveWell and $0.5M from other donors. During 2017-2023 period, funding tracked roughly increased from $241 to $281M, from other donors and the inclusion of some cause-area specific organizations that contributed to movement building.</p><p>The table below summarizes the changes to the proportions of funding coming from different sources:&nbsp;</p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:150px\"><strong>Funder Category</strong></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:200px\"><strong>Change in %&nbsp;</strong></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><strong>New %</strong></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><strong>Original %</strong></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Other donors</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Up ~8%&nbsp;</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">9.6%</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">1.5%</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">FTX Future Fund</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Down ~3%</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">14.8%</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">17.5%</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">EAIF (non-OP donors), LTFF &amp; Jaan Tallinn (incl. SFF)</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Down ~1%</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">&nbsp;</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">&nbsp;</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">EA Animal Fund</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Up ~1%</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">1.1%</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">0%</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Open Philanthropy</p><p><br>&nbsp;</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>OP LT: Down 9.5%<br>(~10.1% w. EAIF)</p><p>OP GH&amp;W: Down 0.4%</p><p>OP Other: Up 5.9%</p><p>Overall: Down ~3%</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>OP LT: 50.4% (~54.5% w. EAIF)</p><p>OP GH&amp;W: 2.6%</p><p>OP Other: 5.9%</p><p>Overall: 63%</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>OP LT: 59.8% (~64.6% w. EAIF)</p><p>OP GH&amp;W: 2.2%</p><p>OP Other: 0%</p><p>Overall: 66%</p></td></tr></tbody></table></figure><p><br>&nbsp;Here's the new % data in a pie chart:&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/nnTQaLpBfy2znG5vm/kgel3irrx1qbmua6iy9x\"></p><h2>What data is still missing?</h2><ul><li><strong>Total funding</strong>: I estimate total funding from 2012 to June 2023 is likely $300-350M (medium confidence). I previously estimated $250-280M (significant underestimate).&nbsp;&nbsp;</li><li><strong>Individual donors</strong>: I estimate that $1-20M since 2012 is probably still missing, since I haven\u2019t included donors who work with Effective Giving, Generation Pledge or Founders\u2019 Pledge.&nbsp;</li><li><strong>Allocation of cause-specific efforts:&nbsp;</strong>You may disagree with the discounting I\u2019ve done towards different cause-specific projects (in either direction). If you think I\u2019m underweighting those efforts, then you could consider that \u201cmissing\u201d data.&nbsp;</li></ul><p>The most accurate way to do these estimates would be to ask movement building&nbsp; organizations for their annual expenses and to break down the sources of their funding. This information is not publicly available, and some organizations do not publish annual expenses publicly from where you might make initial guesses. I\u2019d encourage organizations to share their numbers to give us a fuller picture of the landscape.&nbsp;</p><h2>Mistakes &amp; reflections</h2><ul><li>I didn\u2019t expect this post to be read by as many people as it was. If I\u2019d known this in advance, I think it\u2019s likely I would have delayed publication and seeked more external feedback because concrete numbers can be sticky and hard to update people\u2019s views on.&nbsp;</li><li>I noted that this was a preliminary analysis in the opening, but the data may have been seen as more final than it was. In the future I would spend more time hedging numbers and stating ranges of possible values and encourage people to cite those instead of exact numbers.&nbsp;</li><li>I didn\u2019t add enough uncertainty estimates to the numbers throughout the post. For example, I mentioned that the data was incomplete, and provided an estimate on the total amount of funding ($250-280M) - this was a moderately large underestimate (the total new total tracked data now stands at $290M).</li><li>I missed several sources of global health &amp; wellbeing spending, which significantly increased total spend between 2012-2016. This was an easy fix that I would have caught fairly early with more time / feedback. H/T to Michael St Jules &amp; Devon Fritz for raising this and prompting me to spend time looking into it.&nbsp;</li></ul><p><i>Thanks to Luke Ding for several helpful comments and help procuring relevant data, and to donors who shared their data with me.&nbsp;</i></p>", "user": {"username": "vaidehi_agarwalla"}}, {"_id": "Lv6LzeC4SfdyPy6uM", "title": "Quadratic Funding with Incomplete Information (Luis V. M. Freitas and Wilfredo L. Maldonado)", "postedAt": "2023-07-28T11:56:42.023Z", "htmlBody": "<p>This working paper was published in August 2022. You might also be interested in <a href=\"https://forum.effectivealtruism.org/posts/kHDjtqSiSohZAQyjG/some-thoughts-on-quadratic-funding\">this more recent post</a> by one of the authors on a similar topic.</p><h2>Abstract</h2><p>Quadratic funding is a public good provision mechanism that satisfies desirable theoretical properties, such as efficiency under complete information, and has been gaining popularity in practical applications. We evaluate this mechanism in a setting of incomplete information regarding individual preferences, and show that this result only holds under knife-edge conditions. We also estimate the inefficiency of the mechanism in a variety of settings and show, in particular, that inefficiency increases in population size and in the variance of expected contribution to the public good. We show how these findings can be used to estimate the mechanism\u2019s inefficiency in a wide range of situations under incomplete information.</p><h2>Introduction</h2><p>The non-excludability and non-rivalry of public goods poses a challenge for public good provision that has long received considerable attention in both the theoretical and the applied economic literature (Samuelson 1954; Lindahl 1958). Several mechanisms for providing efficient levels of a public good have been proposed (Clarke 1971; Groves and Ledyard 1977; Hylland and Zeckhauser 1979; Walker 1981), and while these mechanisms are of considerable theoretical importance, there has been to date limited practical application of these solutions, resulting at least in part from undesirable properties they were shown to possess (Walker 1981; Healy 2006; Rothkopf 2007). On the other hand, there are various solutions commonly used in practice, such as majority voting, 1:1 donation matching, and private provision of public goods, all of which lead to inefficient outcomes in the general case (Bergstrom 1981; Bergstrom et al. 1986).</p><p>The quadratic funding (QF) mechanism, proposed by Buterin et al. (2019), appears to be promising in both a theoretical and a practical sense. This mechanism provides a public good level that is equal to the square of the sum of the square roots of individual contributions. That is, if every individual&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"i\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span><style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}\n.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}\n.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}\n.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}\n.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}\n.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}\n.mjx-numerator {display: block; text-align: center}\n.mjx-denominator {display: block; text-align: center}\n.MJXc-stacked {height: 0; position: relative}\n.MJXc-stacked > * {position: absolute}\n.MJXc-bevelled > * {display: inline-block}\n.mjx-stack {display: inline-block}\n.mjx-op {display: block}\n.mjx-under {display: table-cell}\n.mjx-over {display: block}\n.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-stack > .mjx-sup {display: block}\n.mjx-stack > .mjx-sub {display: block}\n.mjx-prestack > .mjx-presup {display: block}\n.mjx-prestack > .mjx-presub {display: block}\n.mjx-delim-h > .mjx-char {display: inline-block}\n.mjx-surd {vertical-align: top}\n.mjx-surd + .mjx-box {display: inline-flex}\n.mjx-mphantom * {visibility: hidden}\n.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}\n.mjx-annotation-xml {line-height: normal}\n.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}\n.mjx-mtr {display: table-row}\n.mjx-mlabeledtr {display: table-row}\n.mjx-mtd {display: table-cell; text-align: center}\n.mjx-label {display: table-row}\n.mjx-box {display: inline-block}\n.mjx-block {display: block}\n.mjx-span {display: inline}\n.mjx-char {display: block; white-space: pre}\n.mjx-itable {display: inline-table; width: auto}\n.mjx-row {display: table-row}\n.mjx-cell {display: table-cell}\n.mjx-table {display: table; width: 100%}\n.mjx-line {display: block; height: 0}\n.mjx-strut {width: 0; padding-top: 1em}\n.mjx-vsize {width: 0}\n.MJXc-space1 {margin-left: .167em}\n.MJXc-space2 {margin-left: .222em}\n.MJXc-space3 {margin-left: .278em}\n.mjx-test.mjx-test-display {display: table!important}\n.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}\n.mjx-test.mjx-test-default {display: block!important; clear: both}\n.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}\n.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}\n.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}\n.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}\n.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}\n.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}\n.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}\n.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}\n.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}\n.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}\n.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}\n.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}\n.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}\n.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}\n.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}\n.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}\n.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}\n.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}\n.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}\n.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}\n.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}\n.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}\n.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}\n.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}\n.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}\n.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}\n.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}\n.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}\n.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}\n@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}\n@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}\n@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}\n@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}\n@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}\n@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}\n@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}\n@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}\n@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}\n@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}\n@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}\n@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}\n@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}\n@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}\n@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}\n@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}\n@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}\n@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}\n@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}\n@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}\n@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}\n@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}\n@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}\n@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}\n@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}\n@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}\n</style></span></span></span>&nbsp;contributes some quantity&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"c\u1d62\u22650\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\"><span class=\"mjx-charbox MJXc-TeX-unknown-R\" style=\"padding-bottom: 0.3em; width: 0.5em;\">\u1d62</span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.446em;\">\u2265</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span></span></span>&nbsp;for funding a public good, then the resulting funding for the public good through QF is&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"(\u03a3\u1d62\u221ac\u1d62)\u00b2.\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u03a3</span></span></span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\"><span class=\"mjx-charbox MJXc-TeX-unknown-R\" style=\"padding-bottom: 0.3em; width: 0.5em;\">\u1d62</span></span></span></span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.519em; padding-bottom: 0.519em;\">\u221a</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\"><span class=\"mjx-charbox MJXc-TeX-unknown-R\" style=\"padding-bottom: 0.3em; width: 0.5em;\">\u1d62</span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\"><span class=\"mjx-charbox MJXc-TeX-unknown-R\" style=\"padding-bottom: 0.3em; width: 0.5em;\">\u00b2</span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span></span></span></span></span></span>Besides efficiency under complete information, one characteristic that distinguishes this mechanism from previously proposed ones is that it does not require any assumptions about the set of public goods to be funded, making it particularly well-suited to cases in which it is important that individuals be able to propose new public goods. It also stands out for its simplicity, and satisfies other desirable properties such as individual rationality and homogeneity of degree one. These characteristics make QF particularly promising for usage in a broad range of situations. In fact, QF has been employed to allocate significant sums of money for funding open-source software projects and matching donations to charity.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefl98l9v97uo\"><sup><a href=\"#fnl98l9v97uo\">[1]</a></sup></span></p><p>This paper aims to analyze the efficiency of the quadratic funding mechanism in a more general informational context, and we do so in two main ways. First, we adapt the framework introduced by Buterin et al. (2019) to allow for the possibility of incomplete information regarding individual preferences. Besides showing the existence of equilibria, we present necessary and sufficient conditions for efficiency, and show that QF is only efficient under knife-edge conditions, which stands in contrast with the efficiency of the mechanism under complete information. In particular, we show that QF is inefficient whenever an individual is uncertain about whether the efficient provision is positive, and that QF is efficient for individuals with isoelastic utility functions for the public good if and only if the elasticity coefficient of these functions is equal to 1/2. We show that the latter condition can be interpreted as saying that QF is efficient when the optimal individual contributions is a dominant strategy, i.e., do not depend on the contribution by others, thus presenting an easily verifiable test for efficiency in applications of this mechanism.</p><p>Second, and motivated by the large class of models in which the private provision of the public good is inefficient, we use numerical estimations to quantify the inefficiency of QF under incomplete information. We define two measures of inefficiency, and then analyze how these measures respond to changes to parameters of our setup. We show that inefficiency is increasing in the number of players and in the variance of the expected value of the fund, and we characterize conditions under which this response is more or less intense. The results presented in our analysis can be used to assess how QF would perform even when it does not lead to efficient public good provision.</p><p>Besides the importance of these findings to quadratic funding, our results also bring implications to quadratic voting (Lalley and Weyl 2019), and more broadly to the growing literature on quadratic pricing (Tideman and Plassmann 2017). Quadratic voting is a voting mechanism that has gained attention both from academia (Kaplow and Kominers 2017; Park and Rivest 2017; Quarfoot et al. 2017; Weyl 2017) and from policymakers, having been applied by the Democratic Party of the United States for political decision-making.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref5nqjbzkpg4x\"><sup><a href=\"#fn5nqjbzkpg4x\">[2]</a></sup></span>&nbsp;Quadratic funding can be understood as an adaptation of quadratic voting to a context of continuous public good provision, which makes our findings particularly surprising, given that Lalley and Weyl (2019) showed that the outcome chosen through quadratic voting under incomplete information converges to efficiency as the population grows. Therefore, our results suggest that incomplete information might pose an important challenge to other quadratic pricing mechanisms, despite the efficiency result for quadratic voting, and, more generally, the properties pertaining to one mechanism may fail to be held by the other.</p><p>The paper is divided into seven sections. Section 2 presents the setting used in the paper, and shows the existence of equilibria for quadratic funding. Section 3 presents efficiency results under complete information, and section 4 analyzes efficiency under incomplete information. Section 5 gives an economic intuition and an efficiency result for the special case where individuals have isoelastic utility functions for the public good, and section 6 employs this class of utility function to develop quantitative estimates of inefficiency under incomplete information. Section 7 summarizes some conclusions of the paper. The Appendix provides the proofs of the stated propositions.</p><h3><a href=\"https://globalprioritiesinstitute.org/luis-m-v-freitas-wildredo-l-maldonado-quadratic-funding-with-incomplete-information/\">Read the rest of the paper</a></h3>", "user": {"username": "Global Priorities Institute"}}]