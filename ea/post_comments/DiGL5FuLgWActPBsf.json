[{"_id": "2duxco6Myc37BsgHt", "postedAt": "2023-03-20T13:11:51.169Z", "postId": "DiGL5FuLgWActPBsf", "htmlBody": "<p>Thank you (again) for this.</p>\n<p>I think this message should be emphasized much more in many EA and LT contexts, e.g. introductory materials on <a href=\"http://effectivealtruism.org\">effectivealtruism.org</a> and <a href=\"http://80000hours.org\">80000hours.org</a>.</p>\n<p>As your paper points out: longtermist axiology probably changes the ranking between x-risk and catastrophic risk interventions in some cases. But there's lots of convergence, and in practice your ranked list of interventions won't change much (even if the diff between them does... after you adjust for cluelessness, Pascal's mugging, etc).</p>\n<p>Some worry that if you're a fan of longtermist axiology then this approach to comms is disingenous. I strongly disagree: it's normal to start your comms by finding common ground, and elaborate on your full reasoning later on.</p>\n<p>Andrew Leigh MP seems to agree. Here's the blurb from his recent book, \"What's The Worst That Could Happen?\":</p>\n<blockquote>\n<p>Did you know that you\u2019re more likely to die from a catastrophe than in a car crash? The odds that a typical US resident will die from a catastrophic event\u2014for example, nuclear war, bioterrorism, or out-of-control artificial intelligence\u2014have been estimated at 1 in 6. That\u2019s fifteen times more likely than a fatal car crash and thirty-one times more likely than being murdered. In What\u2019s the Worst That Could Happen?, Andrew Leigh looks at catastrophic risks and how to mitigate them, arguing provocatively that the rise of populist politics makes catastrophe more likely.</p>\n</blockquote>\n", "parentCommentId": null, "user": {"username": "Peter_Hartree"}}, {"_id": "dKfSqyynaqWygZbHh", "postedAt": "2023-03-20T22:59:43.232Z", "postId": "DiGL5FuLgWActPBsf", "htmlBody": "<p>Thanks for this, great paper.&nbsp;</p><ol><li>I 100% agree on the point that longtermism is not a necessary argument to achieve investment in existential/GCR risk reduction (and indeed might be a distraction). We have recently published on this (<a href=\"https://onlinelibrary.wiley.com/doi/epdf/10.1111/risa.14123\">here</a>). The paper focuses on the process of National Risk Assessment (NRA). We argue: \"If one takes standard government cost-effectiveness analysis (CEA) as the starting point, especially the domain of healthcare where cost-per-quality-adjusted-life-year is typically the currency and discount rates of around 3% are typically used, then existential risk just looks like a limiting case for CEA. The population at risk is simply all those alive at the time and the clear salience of existential risks emerges in simple consequence calculations (such as those demonstrated above) coupled with standard cost-utility metrics.\u201d (look for my post on this paper in the Forum, as I'm about to publish it (next 1-2 days probably &gt;&gt; update, here's the <a href=\"https://forum.effectivealtruism.org/posts/GYK7aMHAWhjm7davL/revolutionising-national-risk-assessment-nra-improved\">link</a>).&nbsp;</li><li>We then turn to the question of <i>why</i> governments don't see things this way, and note: \"The real question then becomes, why do government NRAs and CEAs not account for the probabilities and impacts of GCRs and existential risk? Possibilities include unfamiliarity (i.e., a knowledge gap, to be solved by wider consultation), apparent intractability (i.e., a lack of policy response options, to be solved by wider consultation), conscious neglect (due to low probability or for political purposes, but surely to be authorized by wider consultation), or seeing some issues as global rather than national (typically requiring a global coordination mechanism). Most paths point toward the need for informed public and stakeholder dialog.\"</li><li>We then ask how wider consultation might be effected and propose a two-way communication approach between governments and experts/populations. Noting that NRAs are based on somewhat arbitrary assumptions we propose letting the public explore alternative outcomes of the NRA process by altering assumptions. This is where the AWTP line of your argument could be included, as discount rate and time-horizon are two of the assumptions that could be explored, and seeing the magnitude of benefit/cost people might be persuaded that a little WTP for altruistic outcomes might be good.&nbsp;</li><li>Overall, CEA/CBA is a good approach, and NRA is a method by which it could be formalized in government processes around catastrophe (provided current shortcomings where NRA is often not connected to a capabilities analysis (solutions) are overcome).&nbsp;</li><li>Refuges: sometimes the interests in securing a refuge and protecting the whole population align, as in the case of island refuges, where investment in the refuge is also protecting the entire currently alive population. So refuges may not always be left of the blue box in your figure.&nbsp;</li></ol>", "parentCommentId": null, "user": {"username": "Matt Boyd"}}, {"_id": "iWEKp9mEoDcgNRNQs", "postedAt": "2023-03-20T23:52:42.612Z", "postId": "DiGL5FuLgWActPBsf", "htmlBody": "<p>I like the central points that (i) even weak assumptions suffice to support catastrophic risk reduction as a public policy priority, and (ii) it's generally better (more effective) to argue from widely-accepted assumptions than from widely-rejected ones.</p><p>But I worry about the following claim:</p><blockquote><p>There are clear moral objections against pursuing democratically unacceptable policies</p></blockquote><p>This seems objectionably conservative, and would seem to preclude any sort of \"systemic change\" that is not <i>already</i> popular. Closing down factory farms, for example, is clearly \"democratically unacceptable\" to the current electorate. But it would be ridiculous to claim that there are \"clear moral objections\" to vegan abolitionist political activism.</p><p>Obviously the point of such advocacy is to <i>change</i> what is (currently) regarded as \"democratically (un)acceptable\". If the advocacy succeeds, then the result is no longer democratically unacceptable. &nbsp;If the advocacy fails, then it isn't implemented. &nbsp;In neither case is there any obvious moral objection to advocating, within a democracy, for what you think is true and good.</p>", "parentCommentId": null, "user": {"username": "RYC"}}, {"_id": "mH3bYMDBit9kZ9aND", "postedAt": "2023-03-21T11:34:55.282Z", "postId": "DiGL5FuLgWActPBsf", "htmlBody": "<p>Thanks for writing this! I'm curating it.</p><p>There are roughly <strong>two parts to the post</strong>:&nbsp;</p><ol><li>a sketch cost-benefit analysis (CBA) for whether the US should fund interventions reducing global catastrophic risk (roughly sections 2-4)</li><li><a href=\"https://forum.effectivealtruism.org/posts/DiGL5FuLgWActPBsf/how-much-should-governments-pay-to-prevent-catastrophes#5__Longtermists_should_advocate_for_a_CBA_driven_catastrophe_policy\">an argument</a> for why longtermists should push for a policy of funding all those GCR-reducing interventions that pass a cost-benefit analysis test and no more (except to the extent that a government should account for its citizens' altruistic preferences, which in turn can be influenced by longtermism)<ol><li>\"That is because (1) unlike a strong longtermist policy, a CBA-driven policy would be democratically acceptable and feasible to implement, and (2) a CBA-driven policy would reduce existential risk by almost as much as a strong longtermist policy.\"</li></ol></li></ol><p>I think the second part presents more novel arguments for readers of the Forum, but the first part is an interesting exercise, and important to sketch out to make the argument in part two.&nbsp;</p><p>Assorted thoughts below.&nbsp;</p><h3>1. A graph</h3><p>I want to flag a graph from further into the post that some people might miss (\"The x-axis represents U.S. lives saved (discounted by how far in the future the life is saved) in expectation per dollar. The y-axis represents existential-risk-reduction per dollar. Interventions to the right of the blue line would be funded by a CBA-driven catastrophe policy. The exact position of each intervention is provisional and unimportant, and the graph is not to scale in any case... \"):&nbsp;</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/v1677273514/mirroredImages/DiGL5FuLgWActPBsf/wb1ktpomro91f8q2lixz.png\" alt=\"A picture containing graphical user interface\n\nDescription automatically generated\"></figure><h3>2. Outlining the cost-benefit analysis</h3><p>I do feel like a lot of the numbers used for the sketch CBA are hard to defend, but I get the sense that you're approaching those as givens, and then asking what e.g. people in the US government should do if they find the assumptions reasonable. At a brief skim, the support for \"how much the interventions in question would reduce risk\" seems to be the weakest (and I am a little worried about how this is approached \u2014 flagged below).&nbsp;</p><p>I've pulled out some fragments that produce a ~BOTEC for the cost-effectiveness of a set of interventions from the US government's perspective (bold mine): &nbsp;</p><ol><li>A \"global catastrophe\" is an event that kills at least 5 billion people. The model assumes that each person\u2019s risk of dying in a global catastrophe is equal.</li><li>Overall risk of a global catastrophe: \"Assuming independence and combining Ord\u2019s risk-estimates of 10% for AI, 3% for engineered pandemics, and 5% for nuclear war gives us at least a <strong>17% risk of global catastrophe from these sources over the next 100 years</strong>.<a href=\"https://forum.effectivealtruism.org/posts/DiGL5FuLgWActPBsf/how-much-should-governments-pay-to-prevent-catastrophes#fno23uvsfqw5\"><sup>[8]</sup></a><sup>&nbsp;</sup>If we assume that the risk per decade is constant, the risk over the next decade is about 1.85%.<a href=\"https://forum.effectivealtruism.org/posts/DiGL5FuLgWActPBsf/how-much-should-governments-pay-to-prevent-catastrophes#fnmekx3nzs16\"><sup>[9]</sup></a>&nbsp;If we assume also that every person\u2019s risk of dying in this kind of catastrophe is equal, then (conditional on not dying in other ways) each U.S. citizen\u2019s risk of dying in this kind of catastrophe in the next decade is at least&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"5/9\u00d71.85\\%\u22481.03\\%\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">5</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">9</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u00d7</span></span><span class=\"mjx-mn MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1.85</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">%</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u2248</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1.03</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">%</span></span></span></span><style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}\n.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}\n.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}\n.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}\n.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}\n.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}\n.mjx-numerator {display: block; text-align: center}\n.mjx-denominator {display: block; text-align: center}\n.MJXc-stacked {height: 0; position: relative}\n.MJXc-stacked > * {position: absolute}\n.MJXc-bevelled > * {display: inline-block}\n.mjx-stack {display: inline-block}\n.mjx-op {display: block}\n.mjx-under {display: table-cell}\n.mjx-over {display: block}\n.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-stack > .mjx-sup {display: block}\n.mjx-stack > .mjx-sub {display: block}\n.mjx-prestack > .mjx-presup {display: block}\n.mjx-prestack > .mjx-presub {display: block}\n.mjx-delim-h > .mjx-char {display: inline-block}\n.mjx-surd {vertical-align: top}\n.mjx-surd + .mjx-box {display: inline-flex}\n.mjx-mphantom * {visibility: hidden}\n.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}\n.mjx-annotation-xml {line-height: normal}\n.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}\n.mjx-mtr {display: table-row}\n.mjx-mlabeledtr {display: table-row}\n.mjx-mtd {display: table-cell; text-align: center}\n.mjx-label {display: table-row}\n.mjx-box {display: inline-block}\n.mjx-block {display: block}\n.mjx-span {display: inline}\n.mjx-char {display: block; white-space: pre}\n.mjx-itable {display: inline-table; width: auto}\n.mjx-row {display: table-row}\n.mjx-cell {display: table-cell}\n.mjx-table {display: table; width: 100%}\n.mjx-line {display: block; height: 0}\n.mjx-strut {width: 0; padding-top: 1em}\n.mjx-vsize {width: 0}\n.MJXc-space1 {margin-left: .167em}\n.MJXc-space2 {margin-left: .222em}\n.MJXc-space3 {margin-left: .278em}\n.mjx-test.mjx-test-display {display: table!important}\n.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}\n.mjx-test.mjx-test-default {display: block!important; clear: both}\n.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}\n.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}\n.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}\n.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}\n.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}\n.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}\n.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}\n.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}\n.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}\n.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}\n.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}\n.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}\n.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}\n.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}\n.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}\n.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}\n.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}\n.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}\n.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}\n.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}\n.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}\n.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}\n.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}\n.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}\n.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}\n.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}\n.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}\n.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}\n.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}\n@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}\n@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}\n@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}\n@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}\n@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}\n@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}\n@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}\n@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}\n@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}\n@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}\n@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}\n@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}\n@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}\n@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}\n@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}\n@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}\n@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}\n@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}\n@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}\n@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}\n@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}\n@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}\n@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}\n@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}\n@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}\n@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}\n</style></span></span></span>&nbsp;(since, by our definition, a global catastrophe would kill at least 5 billion people, and the world population is projected to remain under 9 billion until 2033). According to projections of the U.S. population pyramid, 6.88% of U.S. citizens alive today will die in other ways over the course of the next decade.<a href=\"https://forum.effectivealtruism.org/posts/DiGL5FuLgWActPBsf/how-much-should-governments-pay-to-prevent-catastrophes#fnk0isr41eoxl\"><sup>[10]</sup></a>&nbsp;That suggests that U.S. citizens alive today have on average about a 1% risk of being killed in a nuclear war, engineered pandemic, or AI disaster in the next decade. That is about ten times their risk of being killed in a car accident.<a href=\"https://forum.effectivealtruism.org/posts/DiGL5FuLgWActPBsf/how-much-should-governments-pay-to-prevent-catastrophes#fnhz139osjyd\"><sup>[11]</sup></a><sup>\"</sup><ol><li>A lot of ink has been spilled on this, but I don't get the sense that there's a lot of agreement.&nbsp;</li></ol></li><li>How much would a set of interventions cost: \"We project that funding <strong>this suite of interventions for the next decade would cost less than $400 billion</strong>.<a href=\"https://forum.effectivealtruism.org/posts/DiGL5FuLgWActPBsf/how-much-should-governments-pay-to-prevent-catastrophes#fnu76fcclx80r\"><sup>[16]</sup></a>\" \u2014 the footnote reads \"The Biden administration\u2019s 2023 Budget requests $88.2 billion over five years (The White House 2022c; U.S. Office of Management and Budget 2022). We can suppose that another five years of funding would require that much again. A Nucleic Acid Observatory covering the U.S. is estimated to cost $18.4 billion to establish and $10.4 billion per year to run (The Nucleic Acid Observatory Consortium 2021: 18). Ord (2020: 202\u20133) recommends increasing the budget of the Biological Weapons Convention to $80 million per year. Our listed interventions to reduce nuclear risk are unlikely to cost more than $10 billion for the decade. AI safety and governance might cost up to $10 billion as well. The total cost of these interventions for the decade would then be $319.6 billion.\"</li><li>How much would the interventions reduce risk: \"We also&nbsp;expect <strong>this suite of interventions to reduce the risk of global catastrophe over the next decade by at least 0.1pp (percentage points)</strong>. A full defence of this claim would require more detail than we can fit in this chapter, but here is one way to illustrate the claim\u2019s plausibility. Imagine an enormous set of worlds like our world in 2023. ... We claim that <i>in at least 1-in-1,000 of these worlds</i>&nbsp;the interventions we recommend above would prevent a global catastrophe this decade. That is a low bar, and it seems plausible to us that the interventions above meet it.\"<ol><li><strong>This seems under-argued. Without thinking too long about this, it's probably the point in the model that I'd want to see more work on.&nbsp;</strong></li><li>I also worry a bit that collecting interventions like this (and estimating cost-effectiveness for the whole bunch instead of individually) leads to issues like: funding interventions that aren't cost-effective because they're part of the group, <i>not</i> funding interventions that account for the bulk of the risk reduction because a group that's advocating for funding these interventions gets a partial success that drops some particularly useful intervention (e.g. funding AI safety research), etc.</li></ol></li><li>The value of a statistical life (VSL) (the value of saving one life in expectation via small reductions in mortality risks for many people): \"The primary VSL figure used by the U.S. Department of Transportation for 2021 is $11.8 million, with a range to account for various kinds of uncertainty spanning from about $7 million to $16.5 million (U.S. Department of Transportation 2021a, 2021b).\" (With a constant annual discount rate.) (Discussed <a href=\"https://forum.effectivealtruism.org/posts/DiGL5FuLgWActPBsf/how-much-should-governments-pay-to-prevent-catastrophes#4__Cost_benefit_analysis_of_catastrophe_preventing_interventions\">here</a>.)</li><li>Should the US fund these interventions? (Yes)<ol><li>\"given a world population of less than 9 billion and conditional on a global catastrophe occurring, each American\u2019s risk of dying in that catastrophe is at least 5/9. Reducing GCR this decade by 0.1pp then reduces each American\u2019s risk of death this decade by at least 0.055pp. Multiplying that figure by the U.S. population of 330 million, we get the result that reducing GCR this decade by 0.1pp saves at least 181,500 American lives in expectation. If that GCR-reduction were to occur this year, it would be worth at least $1.27 trillion on the Department of Transportation\u2019s lowest VSL figure of $7 million. But since the GCR-reduction would occur over the course of a decade, cost-benefit analysis requires that we discount. If we use OIRA\u2019s highest annual discount rate of 7% and suppose (conservatively) that all the costs of our interventions are paid up front while the GCR-reduction comes only at the end of the decade, we get the result that reducing GCR this decade by 0.1pp is worth at least $1.27 trillion /&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"1.07^{10}=\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1.07</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.605em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">10</span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span></span></span></span></span></span>&nbsp;$646 billion. So, at a cost of $400 billion, these interventions comfortably pass a standard cost-benefit analysis test.<a href=\"https://forum.effectivealtruism.org/posts/DiGL5FuLgWActPBsf/how-much-should-governments-pay-to-prevent-catastrophes#fn83dcbq1lmmf\"><sup>[20]</sup></a>&nbsp;That in turn suggests that the U.S. government should fund these interventions. Doing so would save American lives more cost-effectively than many other forms of government spending on life-saving, such as transportation and environmental regulations. In fact, we can make a stronger argument. Using a projected U.S. population pyramid and some life-expectancy statistics, we can calculate that approximately 79% of the American life-years saved by preventing a global catastrophe in 2033 would accrue to Americans alive today in 2023 (<a href=\"https://docs.google.com/spreadsheets/d/1mguFYc06mw2Bdv85Viw6CQq4mt-mqPdiU4mQRi1s0Yo/edit#gid=135523877\">Thornley 2022</a>). 79% of $646 billion is approximately $510 billion. That means that funding this suite of GCR-reducing interventions is well worth it, even considering only the benefits to Americans alive today.<a href=\"https://forum.effectivealtruism.org/posts/DiGL5FuLgWActPBsf/how-much-should-governments-pay-to-prevent-catastrophes#fnm482lc9rpwg\"><sup>[21]</sup></a>\"</li><li>(The authors also flag that this pretty significantly underrates the cost-effectiveness of the interventions, etc. by not accounting for the fact that the interventions also decrease the risks from smaller catastrophes and by not accounting for the deaths of non-US citizens.)</li></ol></li></ol><h3>3. Some excerpts from the argument about what longtermists should advocate for that I found insightful or important&nbsp;</h3><ol><li>\"getting governments to adopt a CBA-driven catastrophe policy is not trivial. One barrier is psychological (Wiener 2016). Many of us find it hard to appreciate the likelihood and magnitude&nbsp;of a global catastrophe. Another is that GCR-reduction is a collective action problem for individuals. Although a safer world is in many people\u2019s self-interest, <i>working</i>&nbsp;for a safer world is in few people\u2019s self-interest. Doing so means bearing a large portion of the costs and gaining just a small portion of the benefits.<a href=\"https://forum.effectivealtruism.org/posts/DiGL5FuLgWActPBsf/how-much-should-governments-pay-to-prevent-catastrophes#fnx54p04qc4q\"><sup>[28]</sup></a>&nbsp;Politicians and regulators likewise lack incentives to advocate for GCR-reducing interventions (as they did with climate interventions in earlier decades). Given widespread ignorance of the risks, calls for such interventions are unlikely to win much public favour. / However, these barriers can be overcome.\"</li><li>\"getting the U.S. government to adopt a CBA-driven catastrophe policy would reduce existential risk by almost as much as getting them to adopt a strong longtermist policy. This is for two reasons. The first is that, at the current margin, the primary goals of a CBA-driven policy and a strong longtermist policy are substantially aligned. The second is that increased spending on preventing catastrophes yields steeply diminishing returns in terms of existential-risk-reduction.\" (I appreciated the explanations given for the reasons.)</li><li>\"At the moment, the world is spending very little on preventing global catastrophes. The U.S. spent approximately $3 billion on biosecurity in 2019 (Watson et al. 2018), and (in spite of the wake-up call provided by COVID-19) funding for preventing future pandemics has not increased much since then.<a href=\"https://forum.effectivealtruism.org/posts/DiGL5FuLgWActPBsf/how-much-should-governments-pay-to-prevent-catastrophes#fnyx75t39r0w\"><sup>[32]</sup></a>&nbsp;Much of this spending is ill-suited to combatting the most extreme biological threats. Spending on reducing GCR from AI is less than $100 million per year.<a href=\"https://forum.effectivealtruism.org/posts/DiGL5FuLgWActPBsf/how-much-should-governments-pay-to-prevent-catastrophes#fna7t0jphf8mu\"><sup>[33]</sup></a>\"</li><li>\"here, we believe, is where longtermism should enter into government catastrophe policy. Longtermists should make the case for their view, and thereby increase citizens\u2019 AWTP [<i>altruistic willingness to pay</i>] for pure longtermist goods like refuges.<a href=\"https://forum.effectivealtruism.org/posts/DiGL5FuLgWActPBsf/how-much-should-governments-pay-to-prevent-catastrophes#fnvnvpypgizy\"><sup>[38]</sup></a>&nbsp;When citizens are willing to pay for these goods, governments should fund them.\"</li><li>\"One might think that it is true only <i>on the current margin </i>and <i>in public </i>that longtermists should push governments to adopt a catastrophe policy guided by cost-benefit analysis and altruistic willingness to pay. [...] We disagree. Longtermists can try to increase government funding for catastrophe-prevention by making longtermist arguments and thereby increasing citizens\u2019 AWTP, but they should not urge governments to depart from a CBA-plus-AWTP catastrophe policy. On the contrary, longtermists should as far as possible commit themselves to acting in accordance with a CBA-plus-AWTP policy in the political sphere. One reason why is simple: longtermists have moral reasons to respect the preferences of their fellow citizens. [Another reason why is that] the present generation may worry that longtermists would go too far. If granted imperfectly accountable power, longtermists might try to use the machinery of government to place burdens on the present generation for the sake of further benefits to future generations. These worries may lead to the marginalisation of longtermism, and thus an outcome that is worse for both present and future generations.\"</li></ol>", "parentCommentId": null, "user": {"username": "Lizka"}}, {"_id": "C2TMJ5ttiDXYFBsCt", "postedAt": "2023-03-21T23:16:03.655Z", "postId": "DiGL5FuLgWActPBsf", "htmlBody": "<p>Thanks for the comment!</p><blockquote><p>There are clear moral objections against pursuing democratically unacceptable policies</p></blockquote><p>What we mean with this sentence is that there are clear moral objections against <i>governments</i> pursuing [perhaps we should have said 'instituting'] democratically unacceptable policies. We don't mean to suggest that there's anything wrong with citizens advocating for policies that are currently democratically unacceptable with the aim of making them democratically acceptable.</p>", "parentCommentId": "iWEKp9mEoDcgNRNQs", "user": {"username": "elliottthornley"}}, {"_id": "M7fyGgeJovnJSaLFu", "postedAt": "2023-03-21T23:21:34.587Z", "postId": "DiGL5FuLgWActPBsf", "htmlBody": "<p>Thanks for the tip! Looking forward to reading your paper.</p><blockquote><p>but surely to be authorized by wider consultation</p></blockquote><p>What do you mean by this?</p>", "parentCommentId": "dKfSqyynaqWygZbHh", "user": {"username": "elliottthornley"}}, {"_id": "LkJWn2nRdwZSPjtyY", "postedAt": "2023-03-22T00:46:37.436Z", "postId": "DiGL5FuLgWActPBsf", "htmlBody": "<p>OK, thanks for clarifying! I guess there's a bit of ambiguity surrounding talk of \"the goal of longtermists in the political sphere\", so maybe worth distinguishing immediate policy goals that could be implemented right away, vs. external (e.g. \"consciousness-raising\") advocacy aimed at shifting values.</p><p>It's actually an interesting question when policymakers can reasonably go against public opinion. It doesn't seem necessarily objectionable (e.g. to push climate protection measures that most voters are too selfish or short-sighted to want to pay for). There's a reason we have representative rather than direct democracy. But the key thing about your definition of \"democratically unacceptable\" is that it specifies the policy could not possibly be <i>maintained</i>, which more naturally suggests a feasibility objection than a moral one, anyhow.<br><br>But I'm musing a bit far afield now. &nbsp;Thanks for the thought-provoking paper!</p>", "parentCommentId": "C2TMJ5ttiDXYFBsCt", "user": {"username": "RYC"}}, {"_id": "8njybvqn6hes5uupj", "postedAt": "2023-03-22T01:00:58.101Z", "postId": "DiGL5FuLgWActPBsf", "htmlBody": "<p>Thanks. I guess this relates to your point about democratically acceptable decisions of governments. If a government is choosing to neglect something (eg because its probability is low, or because they have political motivations for doing so, vested interests etc), then they should only do so if they have information suggesting the electorate has/would authorize this. Otherwise it is an undemocratic decision.&nbsp;</p>", "parentCommentId": "M7fyGgeJovnJSaLFu", "user": {"username": "Matt Boyd"}}, {"_id": "uhxFa3qLzWdmprCnH", "postedAt": "2023-03-22T11:34:40.281Z", "postId": "DiGL5FuLgWActPBsf", "htmlBody": "<p>Thanks so much for writing this thought-provoking piece and for cross-posting it here to the forum for discussion. It is a long piece with lots of subtly different arguments that piece together in complex ways. Indeed, by the end of it, I'm not sure if I agree with the overall thrust or not. But there are many strands on which I do strongly agree or disagree and so I'll try to break them out into different comments here to make the discussion easier.</p><p>Overall:</p><ul><li>I\u2019m enthusiastic about your work towards creating CBA for existential risks.</li><li>I\u2019m sympathetic to the argument that concern about presently existing people is sufficient to warrant substantial government spending on existential risk (though I don't think it quite gets there).</li><li>I\u2019m also sympathetic to the idea that one should lead with this in policy circles (though I favour the view that one should sometimes lead with it and sometimes with future generations).</li><li>I strongly agree that we shouldn't try to implement policies that are democratically infeasible (though it should be uncontroversial that it is sometimes correct to <i>propose</i> policies that go somewhat beyond current democratic feasibility, since feasibility is not fixed).</li><li>I strongly disagree with the idea that it is in some way undemocratic to argue that the effects on future generations give an especially strong reason to be concerned about existential risks (which I think your paper sometimes suggests).</li></ul>", "parentCommentId": null, "user": {"username": "Toby_Ord"}}, {"_id": "HPmhMJP6Bhfb6qMfd", "postedAt": "2023-03-22T11:53:19.044Z", "postId": "DiGL5FuLgWActPBsf", "htmlBody": "<p>'Democratically unacceptable'</p><p>Like Richard, I was quite confused while reading the piece about the use of this term. I agree with him that if you are trying to get normative mileage out of this idea, then it doesn't work. In representative democracies like the US, we elect people to represent us in the highest levels of national decision-making. They are allowed to act in our narrow self-interest, but also in furtherance of our ideals. Indeed, they are aren\u2019t constrained to leading from the back \u2014 to leading people to where they already want to go. They are also allowed to to lead from the front \u2014 to use good judgment to see things the public hadn\u2019t yet seen, to show why it is an attractive course of action and to take it. Indeed, when we think of great Presidents or Prime Ministers it is often this quality that we most admire. So it seems entirely fine to me to appeal to people in government on moral grounds \u2014 including on longtermist grounds such as the effects on future generations. To say otherwise would involve some surprising judgments about other acts of moral leadership that are widely celebrated (such as in the ending of slavery).</p><p>I think the best version of this argument about democratic acceptability is not a moral or political philosophy argument (that it is wrong or unjust or undemocratic for governments to implement policies on these grounds) because there is little evidence it would be any of those things. Before a funding allocation reached those levels it would likely become politically unacceptable \u2014 i.e. it couldn\u2019t practically be implemented and you would get less in the long run than if you asked for a more modest amount. I think there is broad agreement among longtermists that political feasibility is a key constraint, so the question is then about where it kicks in and what we can do to loosen the constraint by raising moral awareness.</p><p>At times it sounds like you agree with this, such as when you explicitly say \"<i>democratically unacceptable</i>, by which we mean it could not be adopted and maintained by a democratic government\", but at other times you seem to trade on the idea that there is something democratically tainted about political advocacy on behalf of the people of the future \u2014 this is something I strongly reject. I think the paper would be better if it were clearer on this. I think using the term 'democratically infeasible' would have been more apposite and would dispel the confusion.</p><p>(I should add that part of this is the question of whether you mean infeasible vs normatively problematic, and part of it is the question of whether you are critiquing use of longtermist considerations (over and above CBA considerations) vs whether you are critiquing attempts to impose the policies one would come up with on <i>strong</i> longtermism + ignoring feasibility. I'll address that more in another comment, but the short version is that I agree that imposing wildly unpopular policies on voters might be normatively problematic as well as infeasible, but think that comparison is a straw man.)</p>", "parentCommentId": "uhxFa3qLzWdmprCnH", "user": {"username": "Toby_Ord"}}, {"_id": "aFsbHfEjyN9JXraoW", "postedAt": "2023-03-22T12:09:36.702Z", "postId": "DiGL5FuLgWActPBsf", "htmlBody": "<p>The target of your comparisons:</p><p>At times it seems like you are comparing <i>traditional CBA justifications</i> for government work on existential risk vs <i>longtermist justifications</i>. At other times it seems like you are comparing the policy prescriptions and funding that would pass a traditional CBA vs the policy prescriptions and funding that would come out of strong longtermist reasoning (deliberately setting aside political feasibility). I have different views on each of these comparisons.&nbsp;</p><p>On the first, I think we should use both traditional CBA justifications as well as longtermist considerations and don\u2019t think the piece really offers much argument against including the latter at all (for one thing, it doesn\u2019t seem to recognise that they can actually be popular and motivating with the public and with policy makers in a way that CBA isn\u2019t, widening the feasibility window).&nbsp;</p><p>On the second, I agree that we should generally not use <i>strong</i> longtermist justifications (though the piece usually frames itself as arguing against <i>regular</i> longtermist justifications). For one thing, I don't actually endorse strong longtermism anyway. I also agree that we shouldn\u2019t set aside political feasibility in our policy recommendations. But it seems something of a straw man to suggest that the choice under discussion is to ignore effects on future generations or to consider all such effects on a total utilitarian basis and ignore the political feasibility. Are there any serious advocates of that position? The inadequacy of the second of these options doesn\u2019t really help you conclude that we should deliberately restrict ourselves to the CBA option, as there are so many other options that were not considered.</p>", "parentCommentId": "uhxFa3qLzWdmprCnH", "user": {"username": "Toby_Ord"}}, {"_id": "GZHonAJ9KTev3DXKE", "postedAt": "2023-03-22T12:27:11.881Z", "postId": "DiGL5FuLgWActPBsf", "htmlBody": "<p>Regarding your CBA:</p><p>I worry that your stated estimates, aren't really enough to secure adequate funding on traditional CBA grounds.</p><p>For example, it doesn't work in many countries. There are only a fifth as many people living in the UK, so only a fifth as many beneficiaries. Thus the benefits internalised by the UK are a fifth as high, so the cost-benefit ratio is only a fifth as good. Moreover, the UK is poorer, so people are less willing to pay to avoid risk and the VSLs used by the government are substantially lower (I think about a fifth your stated figure \u2014 \u00a32M), such that the package you list would dramatically fail the CBA by a factor of 25 or so in the UK. Many other countries are poorer or smaller than the US in some combination and will have trouble meeting this cost-benefit bar on the estimates you gave.</p><p>Even in the US, your estimates for the cost-benefit calculation aren\u2019t really enough to make it go through. It would be if all these interventions were inextricably bound up as a package, or if all funding on them had equal effect. But CBA cares about marginal cost effectiveness and presumably the package can be broken into chunks of differing ex-ante cost-effectiveness (e.g. by intervention type, or by tranches of funding in each intervention). Indeed you suggest this later in the piece. Since the average only just meets the bar, if there is much variation, the marginal work won\u2019t meet the bar, so government funding would cap out at something less than this, perhaps substantially so.</p><p>Moreover, your analysis suggests the package only marginally meets the cost-benefit threshold and requires some educated guesswork to do so (the amounts it would lower existential risk). Such speculative estimates that drive a large funding choice are usually frowned on in CBA. So even if it is marginally worth funding if government attention and capacity were free, it wouldn\u2019t be a high priority.</p><p>My guess is therefore that a national package of interventions by the US would need to be notably more modest than this one to get funded purely on traditional CBA grounds, and much more modest to get funded in the UK or elsewhere, widening the gap between what traditional CBA gets us and what the addition of longtermist considerations could achieve.</p>", "parentCommentId": "uhxFa3qLzWdmprCnH", "user": {"username": "Toby_Ord"}}, {"_id": "MdaxyFPADdghohqgp", "postedAt": "2023-03-22T17:15:06.884Z", "postId": "DiGL5FuLgWActPBsf", "htmlBody": "<p>Overshooting:</p><blockquote><p>Second, the argument overshoots. Given other plausible claims, building policy on this premise would not only lead governments to increase their efforts to prevent catastrophes. It would also lead them to impose extreme costs on the present generation for the sake of miniscule reductions in the risk of existential catastrophe.</p></blockquote><p>I disagree with this.&nbsp;</p><p>First, I think that many moral views are compelled to find the possibility that their generation permanently eradicates all humans from the world to be especially bad and worthy of much extra effort to avoid. As I detailed in Chapter 2 of the Precipice, this can be based on considerations about the past or about the future. While longtermism is often associated with the future-directed reasons, I favour a broader definition. If someone is deeply moved by the Burkean partnership of the generations over an unbroken chain stretching back 10,000 generations and thinks this gives additional reason not to be the generation who breaks it, then I\u2019m inclined to say they are a longtermist too. But whether it counts or doesn\u2019t, my arguments in Chapter 2 still imply that many moral views are already committed to a special badness of extinction (and often other existential risks). This means there is a wide set of views that go beyond traditional CBA and I can't see a good argument why they should all overshoot.</p><p>And what about for a longtermist view that is more typical of our community? Suppose we are committed to the idea that each person matters equally no matter when they would live. It doesn't follow from this that the best policy is one that demands vast sacrifices from the current generation, anymore than this follows from the widely held view that all people matter equally regardless of race or place of birth. One could still have places in ethics or political philosophy where there are limits placed on the sacrifices that can be demanded of you, and <i>especially</i> limits placed on the sacrifices you can force others to endure in order to produce a larger amount of benefits for others. Theories with such limits could still be impartial in time and could definitely qualify as longtermist.</p><p>One could also have things tempered by moral uncertainty or political beliefs about pluralism or non-coercion.</p><p>And that is before we get to the fact that longtermist policy drafters don't have to ignore the feasibility of their proposals \u2014 another clear way to stop before you overshoot.&nbsp;</p><p>I really don't think it is clear that there are any serious policy suggestions from longtermists that do overshoot here. e.g. in The Precipice (p. 186) my advice on budget is:</p><blockquote><p>We currently spend less than a thousandth of a percent of gross world product on them. Earlier, I suggested bringing this up by at least a factor of 100, to reach a point where the world is spending more on securing its potential than on ice cream, and perhaps a good longer-term target may be a full 1 percent.</p></blockquote><p>And this doesn't seem too different from your own advice ($400B spending by the US is 2% of a year's GDP).</p><p>A different take might be that I and others could be commended for not going too far, but that in doing so we are being inconsistent with our stated principles. That is an interesting angle, and one raised by Jim Holt in his very good NYT book review. But I ultimately don't think it works either: I can't see any strong arguments that longtermism lacks the theoretical resources to consistently avoid overshooting.</p>", "parentCommentId": "uhxFa3qLzWdmprCnH", "user": {"username": "Toby_Ord"}}, {"_id": "cEcaSLLg4KKK3nTu9", "postedAt": "2023-03-22T23:25:02.024Z", "postId": "DiGL5FuLgWActPBsf", "htmlBody": "<p>Thanks, these comments are great! I'm planning to work through them later this week.&nbsp;</p><p>I agree with pretty much all of your bulletpoints. With regards to the last one, we didn't mean to suggest that arguing for greater concern about existential risks is undemocratic. Instead, we meant to suggest that (in the world as it is today) it would be undemocratic for governments to implement polices that place heavy burdens on the present generation for the sake of small reductions in existential risk.</p>", "parentCommentId": "uhxFa3qLzWdmprCnH", "user": {"username": "elliottthornley"}}, {"_id": "5nwxMWz2Q73p9r6PD", "postedAt": "2023-03-23T10:57:16.199Z", "postId": "DiGL5FuLgWActPBsf", "htmlBody": "<p>The message I take is that there's potentially a big difference between these two questions:</p><ol><li>Which government policies should one advocate for?</li><li>For an impartial individual, what are the best causes and interventions to work on?</li></ol><p>Most of effective altruism, including 80,000 Hours, has focused on the second question.</p><p>This paper makes a good case for an answer to the first, but doesn't tell us much about the second.</p><p>If you only value the lives of the present generation, it's not-at-all obvious that marginal investment in reducing catastrophic risk beats funding GiveWell-recommended charities (or if animal lives are included, fighting factory farming). And this paper doesn't make that case.</p><p>I think the mistake people have made is not to distinguish more clearly between these two questions, both in discussion of what's best and in choice of strategy.</p><p>People often criticise effective altruism because they interpret the suggestions aimed at individuals as policy proposals (\"but if everyone did this...\"). But if community members are not clearly distinguishing the two perspectives, to some degree that's fair \u2013 you can see from this paper why you would not want to turn over control of the government to strong longtermists. If the community is going to expand from philanthropy to policy, it needs to rethink what proposals it advocates for and how they are justified.&nbsp;</p>", "parentCommentId": "2duxco6Myc37BsgHt", "user": {"username": "Benjamin_Todd"}}, {"_id": "56MTTwbAnjDcFJztZ", "postedAt": "2023-03-23T11:02:27.454Z", "postId": "DiGL5FuLgWActPBsf", "htmlBody": "<p>A third question is:<br><br>3. What values should one morally advocate for?<br><br>The answers to this could be different yet again.</p><p>Much past longtermist advocacy arguably fits into the framework of trying to get people to increase their altruistic willingness to pay to help future generations, and I think make sense on those grounds. Though again perhaps could be clearer that the question of what governments should do all-considered given people's <i>current</i> willingnesses to pay is a different question.</p>", "parentCommentId": "5nwxMWz2Q73p9r6PD", "user": {"username": "Benjamin_Todd"}}, {"_id": "fzqNC2W4CzHXj84mZ", "postedAt": "2023-03-23T11:39:54.213Z", "postId": "DiGL5FuLgWActPBsf", "htmlBody": "<p>Maybe an obvious point, but I think we shouldn't lose sight of the importance of providing EA funding for catastrophe-preventing interventions, alongside attempts to influence government. Attempts to influence government may fail / fall short of what is needed / take too long given the urgency of action.</p><p>Especially in the case of pure longtermist goods, we need to ensure the EA/longtermist movement has enough money to fund things that governments won't. Should we just get on with developing refuges ourselves?</p>", "parentCommentId": null, "user": {"username": "jackmalde"}}, {"_id": "bf9jcb4bagJBHibF8", "postedAt": "2023-03-24T06:46:22.186Z", "postId": "DiGL5FuLgWActPBsf", "htmlBody": "<p>I agree that much more GCR mitigation could be funded through CBA.</p><blockquote><p>There are suites of existential-risk-reducing interventions that governments could implement only at extreme cost to those alive today. \u2026 Governments could also build extensive, self-sustaining colonies (in remote locations or perhaps far underground) in which residents are permanently cut off from the rest of the world and trained to rebuild civilization in the event of a catastrophe....More generally, governments could heavily subsidise investment, research, and development in ways that incentivise the present generation to increase civilization\u2019s resilience and decrease existential risk.</p></blockquote><p>Though I agree that refuges would not pass a CBA, I don't think they are an example of something that would be extreme cost to those alive today-I suspect significant value could be obtained with $1 billion. And while storing up food for the US population for a five year nuclear winter might cost around $1 trillion, preparing to scale <a href=\"https://doi.org/10.3390/nu14030492\">resilient foods</a> quickly in a catastrophe is more like hundreds of millions of dollars and <a href=\"https://allfed.info/images/pdfs/cost_effective.pdf\">passes a CBA</a>.</p><blockquote><p>kill at least 5 billion people and hence qualify as a global catastrophe</p></blockquote><p>This is higher than other thresholds for GCR I've seen - can you explain why?</p><blockquote><p>And the Biden administration already includes costs to non-U.S. citizens in its <i>social cost of carbon</i>&nbsp;(SCC): its estimate of the harm caused by carbon dioxide emissions (The White House 2022a). The SCC is a key input to the U.S. government\u2019s climate policy, and counting costs to non-U.S. citizens in the SCC changes the cost-benefit balance of important decisions like regulating power plant emissions, setting standards for vehicle fuel efficiency, and signing on to international climate agreements.</p></blockquote><p>I'm pretty sure this includes effects on future generations, which you appear to be against for GCR mitigation. Interestingly, energy efficiency rules calculate the benefits of saved SCC, but they are forbidden to actually take this information into account in deciding what efficiency level to choose at this point.</p><p>It's probably too late, but I would mention the <a href=\"https://www.congress.gov/bill/117th-congress/senate-bill/4488/text\">Global Catastrophic Risk Management Act</a> that recently became law in the US. This provides hope that the US will do more on GCR.</p>", "parentCommentId": null, "user": {"username": "Denkenberger"}}, {"_id": "xEAP89EhLcsPtkdkt", "postedAt": "2023-03-24T12:52:56.445Z", "postId": "DiGL5FuLgWActPBsf", "htmlBody": "<p>Thank so much you for writing this I think it is an excellent piece and makes a really strong case for how longtermists should consider approaching policy. I agree with most of your conclusions here.</p><p>I have been working in the space for a number of years advocating (with some limited <a href=\"https://forum.effectivealtruism.org/posts/xX2JKae8GyzdY98Zn/appg-for-future-generations-impact-report-2020-2021\">successes</a>) for a cost effectiveness approach to government policy making on risks in the UK (and am a contributing author to the <a href=\"https://www.longtermresilience.org/futureproof\">Future Proof</a> report your cite). Interestingly despite having made progress in the area I am over time leaning more towards work on specific advocacy focused on known risks (e.g. on pandemic preparedness) than more general work on improve government spending on risks as a whole. I have a number of unpublished notes on how to assess the value of such work that might be useful so thought I would share below.</p><p>I think there is three points my notes might helpfully add to your work</p><ol><li>Some more depth about how to think about cost benefit analysis and in particular what the threshold is for government to take action. I think the cost benefit you describe is below the threshold for government action.</li><li>An independent literature review type analysis on what the benefit cost ratio is for on the margin additional funds going into disaster prevention. (Literature list in Annex section).</li><li>Some vague reflections as a practitioner in this space on the paths to impact</li></ol><p>&nbsp;</p><p><i>Note: Some of this research was carried out for Charity Entrepreneurship and should be considered Charity Entrepreneurship work. This post is in an independent capacity and does not represent views of any employer</i><br><br>&nbsp;</p><h3><strong>1. The cost benefit analysis here is not enough to suggests government action</strong></h3><p>I think it is worth putting some though into how to interpret cost benefit analyses and how a government policy maker might interpret and use them. Your conservative estimate suggests a benefit $646 billion to a cost of $400 billion \u2013 this is a benefit cost ratio (BCR) of 1.6 to 1.&nbsp;</p><p>Naively a benefit cost ratio of &gt;1 to 1 suggests that a project is worth funding. However given the overhead costs of government policy, to governments propensity to make even cost effective projects go wrong and public preferences for money in hand it may be more appropriate to apply a higher bar for cost-effective government spending. I remember I used to have a 3 to 1 ratio, perhaps picked up when I worked in Government although I cannot find a source for this now.</p><p>According to https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5537512/ the average cost benefit ratio of government investment into health programs is 8.3 to 1. I highly expect there are many actions the US government could take to improve citizens healthcare with a CBA in the 5-10 to 1 range. In comparison on a 1.6 to 1 does not look like a priority.</p><p>Some Copenhagen Consensus analysis I read considers robust evidence for benefits between 5 to 15 times higher than costs as \"good\" interventions.</p><p>So overall if making the case to government or the public I think making the case that there is a 1.6 to 1 BCR is not sufficient to suggest action. I would consider 3 to 1 to be a reasonable bar and 5 to 1 to be a good case for action.</p><p>&nbsp;</p><h2><strong>2. On the other hand the benefit cost ratio is probably higher than your analysis suggests</strong></h2><p>As mentioned you directly calculate a benefit cost ratio of 1.6 to 1 (i.e. $646 billion to $400 billion).</p><p>Firstly I note that reading your workings this is clearly a conservative estimate. I would be interested to see a midline estimate of the BCR too.</p><p>I made a separate estimate that I thought I would share. It was a bit more optimistic than this. It suggested that the benefit costs ratios (BCR) for disaster prevention are that, on the margin, additional spending on disaster preparedness to be in the region of 10 to 1, maybe a bit below that. I copy my sources into an annex section below.</p><p>(That said, spending $400 billion is arguably more than \u201con the margin\u201d and is a big jump in spending so we might expect that spending at that level to have a somewhat lower value. Of course in practice I don\u2019t think advocates are going to get government to spend $400bn tomorrow and that a gradual ramp up in spending is likely justified.)</p><p>&nbsp;</p><h2><strong>3. A few reflections on political tractability and value&nbsp;</strong></h2><p>My experience (based on the UK) is that I expect governments to be relatively open to change and improvement in this area. I expect the technocratic elements of government respond well to highlighting inconsistencies in process and decision making and the UK government has committed to improvements to how they asses risks. I expect governments to be a bit more reticent to make changes that necessitate significant spending or to put in place mechanisms and oversight that can hold them to account for not spending sufficiently on high-impact risks that might ensure future spending.</p><p>I am also becoming a bit more sceptical of the value of this kind of general longtermist work when put in comparison to work focusing on known risks. Based on my analysis to date I believe some of the more specific policy change ideas about preventing dangerous research or developing new technology to tackle pandemics (or AI regulation) to be a bit more tractable and a bit higher benefit to cost than then this more general work to increase spending on risks. That said in policy you may want to have many avenues you are working on at once so as to capitalise on key opportunities so these approaches should not be seen as mutually exclusive. Additionally there is a case for more general system improvements from a more patient longtermist view or from a higher focus on unknown unknown risks being critical.<br>&nbsp;</p><p>&nbsp;</p><h1><strong>ANNEX: My estimate&nbsp;</strong></h1><p><strong><u>On the value of general disaster preparedness</u></strong></p><p>We can set a prior for the value of pandemic preparedness by looking at other disaster preparedness spending.</p><p><strong>Real-world evidence.</strong> Most of the evidence for this comes from assessments of the value of physical infrastructure preparation for natural disasters, such as building buildings that can withstand floods. See table below.</p><figure class=\"table\"><table><tbody><tr><td style=\"background-color:#E8E8FF;border:1.0pt solid black;padding:5.0pt;vertical-align:top\"><strong>Source</strong></td><td style=\"background-color:#E8E8FF;border-color:black;padding:5.0pt;vertical-align:top\"><strong>Summary</strong></td><td style=\"background-color:#E8E8FF;border-color:black;padding:5.0pt;vertical-align:top\"><strong>BCR</strong></td></tr><tr><td style=\"border-color:black;padding:5.0pt;vertical-align:top\"><p>Natural Hazard Mitigation Saves: 2019 Report</p><p><a href=\"https://www.nibs.org/projects/natural-hazard-mitigation-saves-2019-report\">Link</a></p></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><ul><li>Looks at the BCR for different disaster mitigation prevention. For example:<ul><li>Adopting building codes 11:1</li><li>Changing buildings 4:1</li></ul></li><li>(We think this source has some risk of bias, although it does appear to be high quality.)</li></ul></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>11:1</p><p>&nbsp;</p><p>4:1</p></td></tr><tr><td style=\"border-color:black;padding:5.0pt;vertical-align:top\"><p><i>If Mitigation Saves $6 Per Every $1 \u2026</i><br>(Gall and Friedland, 2020)</p><p><a href=\"https://ascelibrary.org/doi/full/10.1061/%28ASCE%29NH.1527-6996.0000342\">Link</a></p></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><ul><li>\u201cThe value of hazard mitigation is well known: the Multihazard Mitigation Council (MMC) upped their initial estimate of $4 (<a href=\"https://ascelibrary.org/doi/full/10.1061/%28ASCE%29NH.1527-6996.0000342\">MMC 2005</a>) saved for every $1 spent on hazard mitigation to $6, and $7 with regard to flood mitigation (<a href=\"https://ascelibrary.org/doi/full/10.1061/%28ASCE%29NH.1527-6996.0000342\">MMC 2017</a>).\u201d</li></ul></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>4:1</p><p>&nbsp;</p><p>6\u00bd:1</p></td></tr></tbody></table></figure><p><strong>Other estimates.</strong> There are also a number of estimates of benefit cost ratios:</p><figure class=\"table\"><table><tbody><tr><td style=\"background-color:#E8E8FF;border:1.0pt solid black;padding:5.0pt;vertical-align:top\"><strong>Source</strong></td><td style=\"background-color:#E8E8FF;border-color:black;padding:5.0pt;vertical-align:top\"><strong>Summary</strong></td><td style=\"background-color:#E8E8FF;border-color:black;padding:5.0pt;vertical-align:top\"><strong>BCR</strong></td></tr><tr><td style=\"border-color:black;padding:5.0pt;vertical-align:top\"><p><i>Does mitigation save? Reviewing cost-benefit analyses of disaster risk reduction</i></p><p>(Shreve and Kelman, 2014)</p><p><a href=\"https://www.sciencedirect.com/science/article/pii/S2212420914000661\">Link</a></p></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><ul><li>Suggest that disaster relief saves money but at what ratio is unclear and is highly dependent on situation location and kind of disaster.</li><li>BCR estimates tend to be less than 10 with a few going into the 10s and a very few much higher (largest was 1800)</li><li>BCRs may underestimate by putting a high discount rate</li></ul></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\">~10:1</td></tr><tr><td style=\"border-color:black;padding:5.0pt;vertical-align:top\"><p><i>Natural disasters challenge paper</i></p><p>(Copenhagen Consensus, 2015)</p></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><ul><li>There are growing economic costs from natural disasters in recent years. This is especially true in developing countries where there may be limited insurance, higher risks and looser building codes.&nbsp;</li><li>Looks at retrofitting schools to be earthquake resistant in seismically active countries, suggests this has a BCR close to 1:1</li><li>Looks at constructing a one-metre high wall to protect homes or elevating houses by one metre to reduce flooding. Suggests this has a BCR of 60:1.</li></ul></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>1:1</p><p>&nbsp;</p><p>60:1</p></td></tr><tr><td style=\"border-color:black;padding:5.0pt;vertical-align:top\">IFRC&nbsp;<br><a href=\"https://www.ifrc.org/fr/nouvelles/nouvelles/common/disasters-preparedness-saves-lives-and-saves-money-61204/\">Link</a></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><ul><li>\u201c\u201cWe estimate that for each dollar spent on disaster preparedness, an average of four dollars is saved on disaster response and recovery\u201d says Alberto Monguzzi, Disaster Management Coordinator in the IFRC Europe Zone Office.\u201d</li></ul></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\">4:1</td></tr></tbody></table></figure><p><strong><u>Pandemic preparedness estimates</u></strong></p><p><strong>Other estimates.</strong> We found one example of estimates of the value of preparing better for future pandemics.&nbsp;</p><figure class=\"table\"><table><tbody><tr><td style=\"background-color:#E8E8FF;border:1.0pt solid black;padding:5.0pt;vertical-align:top\"><strong>Source</strong></td><td style=\"background-color:#E8E8FF;border-color:black;padding:5.0pt;vertical-align:top\"><strong>Summary</strong></td><td style=\"background-color:#E8E8FF;border-color:black;padding:5.0pt;vertical-align:top\"><strong>BCR</strong></td></tr><tr><td style=\"border-color:black;padding:5.0pt;vertical-align:top\"><p><i>Not the last pandemic: \u2026&nbsp;</i>(Craven et al., 2021)</p><p><a href=\"https://www.mckinsey.com/industries/public-and-social-sector/our-insights/not-the-last-pandemic-investing-now-to-reimagine-public-health-systems\">Link</a></p></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><ul><li>Suggests a cost over 10 years of $285bn-$430bn would partially mitigate a damage $16,000bn every 50 years.</li><li>This roughly implies a BCR of &lt;9:1<ul><li>(16000/50) / (((285+430)/2)/10) = 8.95</li></ul></li></ul></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\">&lt;9:1</td></tr></tbody></table></figure><p>We also found three examples of estimates of the value stockpiling for future pandemics.&nbsp;</p><figure class=\"table\"><table><tbody><tr><td style=\"background-color:#E8E8FF;border:1.0pt solid black;padding:5.0pt;vertical-align:top\"><strong>Source</strong></td><td style=\"background-color:#E8E8FF;border-color:black;padding:5.0pt;vertical-align:top\"><strong>Summary</strong></td><td style=\"background-color:#E8E8FF;border-color:black;padding:5.0pt;vertical-align:top\"><strong>BCR</strong></td></tr><tr><td style=\"border-color:black;padding:5.0pt;vertical-align:top\"><p><i>The Cost Efectiveness of Stockpiling Drugs, Vaccines and Other Health Resources for Pandemic \u2026&nbsp;</i></p><p>(Plans\u2011Rubi\u00f3, 2020)</p><p><a href=\"https://link.springer.com/content/pdf/10.1007/s41669-020-00222-x.pdf\">Link</a><i>&nbsp;</i></p></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><ul><li>Looked at estimates for the cost effectiveness of stockpiling drugs for a pandemic. Example estimates:<ul><li>\u201cUS$8550 per LYS in very high severity pandemics and US$13,447 per LYS in moderate severity pandemics\u201d</li><li>\u201c\u20a43800 per QALY and \u20a428,000 per QALY for the 1918 and 1957/69 pandemic scenarios\u201d&nbsp;</li></ul></li><li>Very roughly if we place a value of $50-100k per year of life this suggests a BCR of roughly 5:1 - 10:1.</li></ul></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\">~8:1</td></tr><tr><td style=\"border-color:black;padding:5.0pt;vertical-align:top\"><p><i>Cost-Benefit of Stockpiling Drugs \u2026</i></p><p>(Balicer et al, 2005)</p><p><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3320484/\">Link</a></p></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><ul><li>Suggest various options for stockpiling in Israel for an influenza pandemic have a cost benefit ratios of 0.37, 0.38, 2.49, 2.44, 3.68</li><li>\u201cinvestments in antiviral agents can be expected to yield a substantial economic return of &gt;$3.68 per $1 invested, while saving many lives\u201d</li></ul></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\">4:1</td></tr><tr><td style=\"border-color:black;padding:5.0pt;vertical-align:top\"><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2600182/\">Link</a></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><ul><li>\u201cexpanding the stockpile of AV drugs to encompass the whole UK population (\u224860 million) might even be acceptable (\u2248\u00a36,500 per QALY gained over a no intervention strategy for the 1918 scenario under base-case assumptions).\u201d</li><li>Very roughly if we place a value of $50-100k per year of life this suggests a BCR of roughly 10:1.</li></ul></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\">~10:1</td></tr><tr><td style=\"border-color:black;padding:5.0pt;vertical-align:top\"><p>()</p><p><a href=\"https://laborcenter.berkeley.edu/economic-and-health-benefits-of-a-ppe-stockpile/\">Link</a></p></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><ul><li>\u201cProcuring an adequate PPE stockpile in advance at non-pandemic prices would cost only 17% of the projected amount needed to procure it at current pandemic-inflated prices\u201d</li></ul></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\">6:1</td></tr></tbody></table></figure><p>&nbsp;</p><p>Historical data and estimates suggest the value of increasing preparedness is decent but not very high, with estimated benefit cost ratios (BCR) often around or just below 1:10.&nbsp;</p><p>&nbsp;</p><p><strong><u>How this changes with scale of the disaster</u></strong></p><p>There is some reason to think that disaster preparedness is more cost effective when targeted at worse disasters. Theoretically this makes sense as disasters are heavy-tailed and most of the impact of preventing and mitigating disasters will be in preventing and mitigating the very worst disasters. This is also supported by models estimating the effect of pandemic preparedness, such as those discussed in <a href=\"https://www.cgdev.org/event/what-return-investment-pandemic-preparedness\">this talk</a>. (Doohan and Hauck, 202?)</p><p>Pandemics affect more people than natural disasters so we could expect a higher than average BCR. This is more relevant if we pick preparedness interventions that scale with the size of the disaster (an example of an intervention that does not have this effect might be stockpiling, for which the impact is capped by the size of the stockpile, not by the size of the disaster).</p><p>However overall I did not find much solid evidence to suggest that the BCR ratio is higher for higher scale disasters.</p>", "parentCommentId": null, "user": {"username": "weeatquince"}}, {"_id": "SqxziSxzGcnob2Pc9", "postedAt": "2023-03-27T18:46:56.924Z", "postId": "DiGL5FuLgWActPBsf", "htmlBody": "<blockquote><p>at other times you seem to trade on the idea that there is something democratically tainted about political advocacy on behalf of the people of the future \u2014 this is something I strongly reject.</p></blockquote><p>I reject that too. We don\u2019t mean to suggest that there is anything democratically tainted about that kind of advocacy. Indeed, we say that longtermists should advocate on behalf of future generations, in order to increase the present generation\u2019s altruistic willingness to pay for benefits to future generations.</p><p>What we think would be democratically unacceptable is governments implementing policies that go significantly beyond the present generation\u2019s altruistic willingness to pay. Getting governments to adopt such policies is infeasible, but we chose \u2018unacceptable\u2019 because we also think there would be something normatively problematic about it.</p><p>So I think we are addressing your strawman here. Certainly, we don\u2019t take ourselves to be arguing against anyone in particular in saying that there would be something wrong with governments placing heavy burdens on the present generation for the sake of small reductions in existential risk. But it seems worth saying in any case, because I think it helps ward off misunderstandings from people not so familiar with longtermism (and we're hoping to reach such people - especially policymakers - with this paper). For suppose that someone knows only of the following argument for longtermism: the expected future population is enormous, the lives of future people are good in expectation, and it is better if the future contains more good lives. Then that person might mistakenly think that the goal of longtermists in the political sphere must be something like a strong longtermist policy.</p>", "parentCommentId": "HPmhMJP6Bhfb6qMfd", "user": {"username": "elliottthornley"}}, {"_id": "ZWJ9gNEZJt7b5jCG4", "postedAt": "2023-03-27T19:02:52.518Z", "postId": "DiGL5FuLgWActPBsf", "htmlBody": "<blockquote><p>On the first, I think we should use both traditional CBA justifications as well as longtermist considerations</p></blockquote><p>I agree with this. What we\u2019re arguing for is a criterion: governments should fund all those catastrophe-preventing interventions that clear the bar set by cost-benefit analysis and altruistic willingness to pay. One justification for funding these interventions is the justification provided by CBA itself, but it need not be the only one. If longtermist justifications help us get to the place where all the catastrophe-preventing interventions that clear the CBA-plus-AWTP bar are funded, then there\u2019s a case for employing those justifications too.</p><blockquote><p>But it seems something of a straw man to suggest that the choice under discussion is to ignore effects on future generations or to consider all such effects on a total utilitarian basis and ignore the political feasibility. Are there any serious advocates of that position?</p></blockquote><p>We think that longtermists in the political sphere should (as far as they can) commit themselves to only pushing for policies that can be justified on CBA-plus-AWTP grounds (which need not entirely ignore effects on future generations). We think that, in the absence of such a commitment, the present generation may worry that longtermists would go too far. From the paper:</p><blockquote><p>&nbsp;Longtermists can try to increase government funding for catastrophe-prevention by making longtermist arguments and thereby increasing citizens\u2019 AWTP, but they should not urge governments to depart from a CBA-plus-AWTP catastrophe policy. On the contrary, longtermists should as far as possible commit themselves to acting in accordance with a CBA-plus-AWTP policy in the political sphere. One reason why is simple: longtermists have moral reasons to respect the preferences of their fellow citizens.</p><p>To see another reason why, note first that longtermists working to improve government catastrophe policy could be a win-win. The present generation benefits because longtermists solve the collective action problem: they work to implement interventions that cost-effectively reduce everyone\u2019s risk of dying in a catastrophe. Future generations benefit because these interventions also reduce existential risk. But as it stands the present generation may worry that longtermists would go too far. If granted imperfectly accountable power, longtermists might try to use the machinery of government to place burdens on the present generation for the sake of further benefits to future generations. These worries may lead to the marginalisation of longtermism, and thus an outcome that is worse for both present and future generations.</p><p>The best solution is compromise and commitment.<a href=\"https://forum.effectivealtruism.org/posts/DiGL5FuLgWActPBsf/how-much-should-governments-pay-to-prevent-catastrophes#fn0ko16dwc14o\"><sup>[39]</sup></a>&nbsp;A CBA-plus-AWTP policy \u2013 founded as it is on citizens\u2019 preferences \u2013 is acceptable to a broad coalition of people. As a result, longtermists committing to act in accordance with a CBA-plus-AWTP policy makes possible an arrangement that is significantly better than the status quo, both by longtermist lights and by the lights of the present generation. It also gives rise to other benefits of cooperation. For example, it helps to avoid needless conflicts in which groups lobby for opposing policies, with some substantial portion of the resources that they spend cancelling each other out (see Ord 2015: 120\u201321, 135). With a CBA-plus-AWTP policy in place, those resources can instead be spent on interventions that are appealing to all sides.</p></blockquote>", "parentCommentId": "aFsbHfEjyN9JXraoW", "user": {"username": "elliottthornley"}}, {"_id": "ujPDdcetqPxLjZ5Fo", "postedAt": "2023-03-27T19:34:15.184Z", "postId": "DiGL5FuLgWActPBsf", "htmlBody": "<blockquote><p>But CBA cares about marginal cost effectiveness and presumably the package can be broken into chunks of differing ex-ante cost-effectiveness (e.g. by intervention type, or by tranches of funding in each intervention). Indeed you suggest this later in the piece. Since the average only just meets the bar, if there is much variation, the marginal work won\u2019t meet the bar, so government funding would cap out at something less than this, perhaps substantially so.</p></blockquote><p>Yes, this is an important point. If we were to do a more detailed cost-benefit analysis of catastrophe-preventing interventions, we\u2019d want to address it more comprehensively (especially since we also mention how different interventions can undermine each other elsewhere in the paper).</p><p>On the point about the average only just meeting the bar, though, I think it\u2019s worth noting that our mainline calculation uses very conservative assumptions. In particular, we assume:</p><ul><li>A total cost of $400b rounded up from $319.6b</li><li>That all the costs of the interventions are paid upfront and that the risk-reduction occurs only at the end of the decade</li><li>The lowest VSL figure used by the DoT</li><li>The highest discount rate recommended by OIRA</li><li>A 1-in-1,000 GCR-reduction from the whole suite</li></ul><p>And we count only these interventions benefits in terms of GCR-reduction. We don\u2019t count any of the benefits arising from these interventions reducing the risk of smaller catastrophes.</p><p>I think that, once you replace these conservative assumptions with more reasonable ones, it\u2019s plausible that each intervention we propose would pass a CBA test.</p><p>I think that these points also help our conclusions apply to other countries, even though all other countries are either smaller than the US or employ a lower VSL. And even though reasonable assumptions will still imply that some GCR-reducing interventions are too expensive for some countries, it could be worthwhile for these countries to participate in a coalition that agrees to share the costs of the interventions.</p><p>I agree that speculative estimates are a major problem. Making these estimates less speculative \u2013 insofar as that can be done \u2013 seems to me like a high priority. In the meantime, I wonder if it would help to emphasise that a speculative-but-unbiased estimate of the risk is just as likely to be too low as to be too high.</p>", "parentCommentId": "GZHonAJ9KTev3DXKE", "user": {"username": "elliottthornley"}}, {"_id": "L5TJevzkND4ErhYC2", "postedAt": "2023-03-27T19:39:22.672Z", "postId": "DiGL5FuLgWActPBsf", "htmlBody": "<blockquote><p>Second, the argument overshoots.</p></blockquote><p>The argument we mean to refer to here is the one that we call the \u2018best-known argument\u2019 elsewhere: the one that says that the non-existence of future generations would be an overwhelming moral loss because the expected future population is enormous, the lives of future people are good in expectation, and it is better if the future contains more good lives. We think that this argument is liable to overshoot.</p><p>I agree that there are other compelling longtermist arguments that don\u2019t overshoot. But my concern is that governments can\u2019t use these arguments to guide their catastrophe policy. That\u2019s because these arguments don\u2019t give governments much guidance in deciding where to set the bar for funding catastrophe-preventing interventions. They don\u2019t answer the question, \u2018By how much does an intervention need to reduce risks per $1 billion of cost in order to be worth funding?\u2019.</p><blockquote><p>We currently spend less than a thousandth of a percent of gross world product on them. Earlier, I suggested bringing this up by at least a factor of 100, to reach a point where the world is spending more on securing its potential than on ice cream, and perhaps a good longer-term target may be a full 1 percent.</p><p>And this doesn't seem too different from your own advice ($400B spending by the US is 2% of a year's GDP).</p></blockquote><p>This seems like a good target to me, although note that $400b is our estimate for how much it would cost to fund our suite of interventions for a decade, rather than for a year.</p>", "parentCommentId": "MdaxyFPADdghohqgp", "user": {"username": "elliottthornley"}}, {"_id": "XusgmWyAY8TnPRwFy", "postedAt": "2023-03-27T19:42:55.417Z", "postId": "DiGL5FuLgWActPBsf", "htmlBody": "<blockquote><p>Maybe an obvious point, but I think we shouldn't lose sight of the importance of providing EA funding for catastrophe-preventing interventions, alongside attempts to influence government. Attempts to influence government may fail / fall short of what is needed / take too long given the urgency of action.</p></blockquote><p>Yep, agreed!&nbsp;</p><blockquote><p>Should we just get on with developing refuges ourselves?</p></blockquote><p>My impression is that this is being explored. See, e.g., <a href=\"https://forum.effectivealtruism.org/posts/DArtSnDxRH5AsE5RF/sheltering-humanity-against-x-risk-report-from-the-shelter\">here</a>.</p>", "parentCommentId": "fzqNC2W4CzHXj84mZ", "user": {"username": "elliottthornley"}}, {"_id": "HvdhspFpgqc29rSAa", "postedAt": "2023-03-27T19:58:49.649Z", "postId": "DiGL5FuLgWActPBsf", "htmlBody": "<blockquote><p>Though I agree that refuges would not pass a CBA, I don't think they are an example of something that would be extreme cost to those alive today-I suspect significant value could be obtained with $1 billion.</p></blockquote><p>I think this is right. Our claim is that a strong longtermist policy <i>as a whole</i> would place extreme burdens on the present generation. We expect that a strong longtermist policy would call for particularly extensive refuges (and lots of them) as well as the other things that we mention in that paragraph.</p><blockquote><p>We also focus on the risk of <i>global catastrophes</i>, which we define as events that kill at least 5 billion people.</p><p>This is higher than other thresholds for GCR I've seen - can you explain why?</p></blockquote><p>We use that threshold because we think that focusing on that threshold <i>by itself</i> makes the benefit-cost ratio come out greater than 1. I\u2019m not so sure that\u2019s the case for the more common thresholds of killing at least 1 billion people or at least 10% of the population in order to qualify as a global catastrophe.</p><blockquote><p>I'm pretty sure this includes effects on future generations, which you appear to be against for GCR mitigation.&nbsp;</p></blockquote><p>We're not opposed to including effects on future generations in cost-benefit calculations. We do the calculation that excludes benefits to future generations to show that, even if one totally ignores benefits to future generations, our suite of interventions still looks like it's worth funding.</p><blockquote><p>Interestingly, energy efficiency rules calculate the benefits of saved SCC, but they are forbidden to actually take this information into account in deciding what efficiency level to choose at this point.</p></blockquote><p>Oh interesting! Thanks.</p><blockquote><p>It's probably too late, but I would mention the&nbsp;<a href=\"https://www.congress.gov/bill/117th-congress/senate-bill/4488/text\">Global Catastrophic Risk Management Act</a>&nbsp;that recently became law in the US. This provides hope that the US will do more on GCR.</p></blockquote><p>And thanks very much for this! I think we will still be able to mention this in the published version.</p>", "parentCommentId": "bf9jcb4bagJBHibF8", "user": {"username": "elliottthornley"}}, {"_id": "4bwpb6va4anSWqHBp", "postedAt": "2023-03-27T20:18:17.369Z", "postId": "DiGL5FuLgWActPBsf", "htmlBody": "<p>Thanks for this! All extremely helpful info.</p><blockquote><p>Naively a benefit cost ratio of &gt;1 to 1 suggests that a project is worth funding. However given the overhead costs of government policy, to governments propensity to make even cost effective projects go wrong and public preferences for money in hand it may be more appropriate to apply a higher bar for cost-effective government spending. I remember I used to have a 3 to 1 ratio, perhaps picked up when I worked in Government although I cannot find a source for this now.</p></blockquote><p>This is good to know. Our BCR of 1.6 is based on very conservative assumptions. We were basically seeing how conservative we could go while still getting a BCR of over 1. I think Carl and I agree that, on more reasonable estimates, the BCR of the suite is over 5 and maybe even over 10 (certainly I think that's the case for some of the interventions within the suite). If, as you say, many people in government are looking for interventions with BCRs significantly higher than 1, then I think we should place more emphasis on our less conservative estimates going forward.</p><blockquote><p>I made a separate estimate that I thought I would share. It was a bit more optimistic than this. It suggested that the benefit costs ratios (BCR) for disaster prevention are that, on the margin, additional spending on disaster preparedness to be in the region of 10 to 1, maybe a bit below that. I copy my sources into an annex section below.</p></blockquote><p>Thanks very much for this! I might try to get some of these references into the final paper.</p><blockquote><p>I am also becoming a bit more sceptical of the value of this kind of general longtermist work when put in comparison to work focusing on known risks. Based on my analysis to date I believe some of the more specific policy change ideas about preventing dangerous research or developing new technology to tackle pandemics (or AI regulation) to be a bit more tractable and a bit higher benefit to cost than then this more general work to increase spending on risks.&nbsp;</p></blockquote><p>This is really good to know as well.</p>", "parentCommentId": "xEAP89EhLcsPtkdkt", "user": {"username": "elliottthornley"}}, {"_id": "AbBhAgBkayxBqqzXu", "postedAt": "2023-03-29T12:33:42.844Z", "postId": "DiGL5FuLgWActPBsf", "htmlBody": "<p>Thanks Elliott,</p><p>I guess this shows that the case won't get through with the conservative rounding off that you applied here, so future developments of this CBA would want to go straight for the more precise approximations in order to secure a higher evaluation.</p><p>Re the possibility of international agreements, I agree that they can make it easier to meet various CBA thresholds, but I also note that they are notoriously hard to achieve, even when in the interests of both parties. That doesn't mean that we shouldn't try, but if the CBA case relies on them then the claim that one doesn't need to go beyond it (or beyond CBA-plus-AWTP) becomes weaker.</p><p>That said, I think some of our residual disagreement may be to do with me still not quite understanding what your paper is claiming. One of my concerns is that I'm worried that CBA-plus-AWTP is a weak <i>style</i> of argument \u2014 especially with elected politicians. That is, arguing for new policies (or treaties) on grounds of CBA-plus-AWTP has some sway for fairly routine choices made by civil servants who need to apply government cost-effectiveness tests, but little sway with voters or politicians. Indeed, many people who would be benefited by such cost-effectiveness tests are either bored by \u2014 or actively repelled by \u2014 such a methodology. But if you are arguing that we should only campaign for policies that would pass such a test, then I'm more sympathetic. In that case, we could still make the case for them in terms that will resonate more broadly.</p>", "parentCommentId": "ujPDdcetqPxLjZ5Fo", "user": {"username": "Toby_Ord"}}, {"_id": "bxKzyyspqidcLX5g8", "postedAt": "2023-03-29T12:58:43.865Z", "postId": "DiGL5FuLgWActPBsf", "htmlBody": "<blockquote><p>we chose \u2018unacceptable\u2019 because we also think there would be something normatively problematic about it.</p></blockquote><p>I'm not so sure about that. I agree with you that it would be normatively problematic in the paradigm case of a policy that imposed extreme costs on current society for very slight reduction in total existential risk \u2014 let's say, reducing incomes by 50% in order to lower risk by 1 part in 1 million.</p><p>But I don't know that it is true in general.</p><p>First, consider a policy that was inefficient but small \u2014 e.g. one that cost $10 million to the US govt, but reduced the number of statistical lives lost in the US by only 0.1, I don't think I'd say that this was democratically unacceptable. Policies like this are enacted all the time in safety contexts and are often inefficient and ill-thought-out, and I'm not generally in favour of them, but I don't find them to be <i>undemocratic</i>. I suppose one could argue that all US policy that doesn't pass a CBA is undemocratic (or democratically unacceptable), but that seems a stretch to me. So I wonder whether it is correct to count our intuitions on the extreme example as counting against all policies that are inefficient in traditional CBA terms or just against those that impose severe costs.</p>", "parentCommentId": "SqxziSxzGcnob2Pc9", "user": {"username": "Toby_Ord"}}, {"_id": "FZxHoyYndZCcpezGA", "postedAt": "2023-03-29T13:00:17.060Z", "postId": "DiGL5FuLgWActPBsf", "htmlBody": "<p>Thanks for the clarifications!</p>", "parentCommentId": "L5TJevzkND4ErhYC2", "user": {"username": "Toby_Ord"}}, {"_id": "u5eqBr4BEeemHZev2", "postedAt": "2023-03-29T13:03:41.181Z", "postId": "DiGL5FuLgWActPBsf", "htmlBody": "<p>I've just seen your comment further down:</p><blockquote><p>What we\u2019re arguing for is a criterion: governments should fund all those catastrophe-preventing interventions that clear the bar set by cost-benefit analysis and altruistic willingness to pay. One justification for funding these interventions is the justification provided by CBA itself, but it need not be the only one. If longtermist justifications help us get to the place where all the catastrophe-preventing interventions that clear the CBA-plus-AWTP bar are funded, then there\u2019s a case for employing those justifications too.</p></blockquote><p>which answers my final paragraph in the parent comment, and suggests that we are not too far apart.</p>", "parentCommentId": "AbBhAgBkayxBqqzXu", "user": {"username": "Toby_Ord"}}, {"_id": "BEmpqii7tStd52op3", "postedAt": "2023-03-30T00:12:16.990Z", "postId": "DiGL5FuLgWActPBsf", "htmlBody": "<blockquote><p>suggests that we are not too far apart.</p></blockquote><p>Yes, I think so!</p><blockquote><p>I guess this shows that the case won't get through with the conservative rounding off that you applied here, so future developments of this CBA would want to go straight for the more precise approximations in order to secure a higher evaluation.</p></blockquote><p>And thanks again for making this point (and to weeatquince as well). I've written a new paragraph emphasising a more reasonable, less conservative estimate of benefit-cost ratios. I expect it'll probably go in the final draft, and I'll edit the post here to include it as well (just waiting on Carl's approval).</p><blockquote><p>&nbsp;Re the possibility of international agreements, I agree that they can make it easier to meet various CBA thresholds, but I also note that they are notoriously hard to achieve, even when in the interests of both parties. That doesn't mean that we shouldn't try, but if the CBA case relies on them then the claim that one doesn't need to go beyond it (or beyond CBA-plus-AWTP) becomes weaker.</p></blockquote><p>I think this is right (and I must admit that I don't know that much about the mechanics and success-rates of international agreements) but one cause for optimism here is Cass Sunstein's view about why the Montreal Protocol was such a success (see <a href=\"https://drive.google.com/file/d/1IUmS6tv91-v_kvWEJxIFkkEqPJ66dmYF/view?usp=sharing\">Chapter 2</a>): cost-benefit analysis suggested that it would be in the US's interest to implement unilaterally and that the benefit-cost ratio would be even more favourable if other countries signed on as well. In that respect, the Montreal Protocol seems akin to prospective international agreements to share the cost of GCR-reducing interventions.</p>", "parentCommentId": "u5eqBr4BEeemHZev2", "user": {"username": "elliottthornley"}}, {"_id": "5JqnkyFcegvbpNtJy", "postedAt": "2023-03-30T00:32:36.040Z", "postId": "DiGL5FuLgWActPBsf", "htmlBody": "<p>I wouldn't call a small policy like that 'democratically unacceptable' either. I guess the key thing is whether a policy goes significantly beyond citizens' willingness to pay not only by a large factor but also by a large absolute value. It seems likely to be the latter kinds of policies that couldn't be adopted and maintained by a democratic government, in which case it's those policies that qualify as democratically unacceptable on our definition.</p>", "parentCommentId": "bxKzyyspqidcLX5g8", "user": {"username": "elliottthornley"}}, {"_id": "nhEzL4BRwKHJwPeD7", "postedAt": "2023-04-12T08:48:41.774Z", "postId": "DiGL5FuLgWActPBsf", "htmlBody": "<p>I agree that governments should prioritize spending on preventing catastrophic events like nuclear war, engineered pandemics, and AI risks based on cost-benefit analysis. As longtermists, we should push for a policy guided by cost-benefit analysis and citizens' willingness to pay, and commit to acting accordingly in politics. This would significantly reduce existential risks for both the present and future generations.</p>", "parentCommentId": null, "user": {"username": "DenisOkalani"}}, {"_id": "pZNHhRcoDkkoraXhF", "postedAt": "2023-05-19T01:03:34.540Z", "postId": "DiGL5FuLgWActPBsf", "htmlBody": "<p>I'm pretty late to the party here, but I want to say I really enjoyed the piece! Your piece came out only three weeks before the <a href=\"https://forum.effectivealtruism.org/posts/yWRJFAmEzofnsuHNK/u-s-regulatory-updates-to-benefit-cost-analysis-highlights#Break_Even_Analysis\">big draft overhaul to the way that the U.S. does benefit-cost analysis came out</a>, which is in a document called Circular A-4. I think there is a lot I'd change around the choices in the analysis, particularly in light of the new draft A-4 Guidance (most of which goes in favor of putting more weight on catastrophes):</p><ul><li>The old A-4's use of a 7% discount rate on capital didn't make sense because the 7% includes other factors outside of time preference (in particular risk aversion). The new A-4 has a much better treatment of discounting capital: which is applying a<a href=\"https://www.whitehouse.gov/wp-content/uploads/2023/04/DraftCircularA-4.pdf#page=79\"> shadow price of capital adjustment</a>, which is somewhere between a factor of 1-1.2 (so it's <a href=\"https://www.whitehouse.gov/wp-content/uploads/2023/04/DraftCircularA-4.pdf#page=80\">not too much of an adjustment in any case</a>). The upshot of all of this is that, based on the new A-4, you should be using a 1.7% discount rate for impacts out to 30 years, which is drastically different than the 7% discount rate that you were using and which will put more weight on the future (and appropriately so from the descriptive point of view to reflect people's tradeoffs between <a href=\"https://forum.effectivealtruism.org/posts/yWRJFAmEzofnsuHNK/u-s-regulatory-updates-to-benefit-cost-analysis-highlights#Short_Term_Discount_Rate\">money now and money in the future in capital markets</a>).&nbsp;</li><li>For impacts beyond 30 years, standard economic theory and the new A-4 suggest that you should be using a declining discount rate to account for future interest rate uncertainty (see my brief description <a href=\"https://forum.effectivealtruism.org/posts/yWRJFAmEzofnsuHNK/u-s-regulatory-updates-to-benefit-cost-analysis-highlights#Break_Even_Analysis\">here</a>). The A-4 preamble has a<a href=\"https://www.whitehouse.gov/wp-content/uploads/2023/04/DraftCircularA-4Preamble.pdf#page=30\"> proposed schedule</a> of declining discount rates, which goes down to 1% 140 years in the future. This will also place more value on the future.&nbsp;</li><li>President <a href=\"https://www.whitehouse.gov/briefing-room/presidential-actions/2021/01/20/modernizing-regulatory-review/\">Biden's Presidential Memorandum</a> and the new A-4 are quite clear (see s<a href=\"https://forum.effectivealtruism.org/posts/yWRJFAmEzofnsuHNK/u-s-regulatory-updates-to-benefit-cost-analysis-highlights#Temporal_Scope_of_Analysis\">ummary of A-4's temporal scope of analysis section</a>) that the interest of future generations should be taken into account when they will be impacted by important benefits and costs from some policy. In fact, the U.S. had previously been accounting for the<a href=\"https://www.whitehouse.gov/wp-content/uploads/2021/02/TechnicalSupportDocument_SocialCostofCarbonMethaneNitrousOxide.pdf\"> impacts of climate change</a> out to 500 years in BCA (in the Obama, Trump, and Biden administrations) through the use of the Social Cost of Greenhouse Gases, so impacts on future generations had been taken into account in that context, and should be taken into account in these other contexts as well, as discussed in the new draft A-4.</li><li>Much of your analysis seems to only look at the direct impacts on Americans. However, A-4 has a robust&nbsp;<a href=\"https://www.whitehouse.gov/wp-content/uploads/2023/04/DraftCircularA-4.pdf#page=9\">discussion</a> around the conditions under which it is important for analysts to include global impacts, such as \"regulating an externality on the basis of its global effects supports a cooperative international approach to the regulation of the externality by potentially inducing other countries to follow suit or maintain existing efforts.\" This recognizes that global externalities/risks like pandemics, biosecurity, climate change, etc. require international regulatory cooperation. If, e.g., a new global pandemic is caused by poor biosecurity regulatory oversight in other countries, this harms Americans. Both because Americans will get sick and die, but also because disruptions in other countries will cause significant harm to the global economy, global trade, and global stability that will in turn harm Americans. Just as poor biosecurity regulatory oversight in the U.S. causing a pandemic will cause harm in other countries for the same reasons. Note that this is also the approach that the U.S. Government has taken to account for climate change in BCA through the&nbsp;<a href=\"https://www.epa.gov/system/files/documents/2022-11/epa_scghg_report_draft_0.pdf#page=16\">Social Cost of Greenhouse Gases by considering global damages</a> from climate change and not just domestic damages. As that document states, global externalities like greenhouse gas emissions and biosecurity policy imply that the whole world enjoys the benefit of one country\u2019s decisions to reduce the harm from the global externality, and therefore \u201cthe only way to achieve an efficient allocation of resources for emissions reduction on a global basis\u2014and so benefit the U.S. and its citizens and residents\u2014is for all countries to consider estimates of global marginal damages\u201d from the externality as well as the global marginal benefits of taking actions to reduce the externality.</li><li>Although your post is about risks, I didn't see mention of accounting for Risk Aversion, which is one of the most consistent features of human preferences and should be reflected in BCA. The&nbsp;<a href=\"https://www.whitehouse.gov/wp-content/uploads/2023/04/DraftCircularA-4.pdf#page=71\">draft A-4 instructs</a> BCA practitioners to explicitly account for&nbsp;uncertainty<strong>&nbsp;</strong>when doing BCA as well as&nbsp;<strong>risk aversion</strong>&nbsp;across that uncertainty. This ends up placing more weight on the benefits that help to avoid catastrophes, and thus would tend to favor policies that reduce the probability of catastrophes (e.g.&nbsp;<a href=\"https://twitter.com/jasonfurman/status/1644086694600409088?s=20\">pandemic preparedness</a>).</li><li>And finally, much of your analysis seems to hinge on probabilities for catastrophes that come from e.g. the EA community or Prediction Markets. Because you choose to account for a very limited scope of impacts across time and space at a very high discount rate, those probabilities end up having to do a lot of work for the analysis to yield net benefits. My sense is for the purposes of BCA for U.S. regulatory impact assessments, these probabilities may be viewed as too speculative (at least for anthropogenic risks) and may be challenged in getting through the various processes that BCAs for regulations must go through including public comment, OIRA review, and then ultimately litigation in court where <a href=\"https://heep.hks.harvard.edu/sites/projects.iq.harvard.edu/files/heep/files/revesz_podcast_transcript_1.5.2021_post.pdf\">most rules are inevitably challenged</a>. &nbsp;Fortunately, A-4 <a href=\"https://forum.effectivealtruism.org/posts/yWRJFAmEzofnsuHNK/u-s-regulatory-updates-to-benefit-cost-analysis-highlights#Break_Even_Analysis\">has a tool</a> that provides a way forward in this situation: Break Even Analysis. Break-even analysis provides a way forward when there is a high degree of uncertainty/ambiguity in important parameters, and you need to determine what those parameters would need to be for the policy to still yield positive net benefits. This is particularly relevant <a href=\"https://www.whitehouse.gov/wp-content/uploads/2023/04/DraftCircularA-4.pdf#page=46\">for catastrophic events</a>: \u201cFor example, there may be instances where you have estimates of the expected outcome of a type of catastrophic event, but assessing the change in the probability of such an event may be difficult. Your break-even analysis could demonstrate how much a regulatory alternative would need to reduce the probability of a catastrophic event occurring in order to yield positive net benefits or change which regulatory alternative is most net beneficial.\u201d</li></ul><p>To Summarize, I think U.S. BCA practice actually offers a much wider variety of tools for assessing catastrophic risks, which benefits the interest and welfare of Americans, and those tools should be utilized.&nbsp;</p>", "parentCommentId": null, "user": {"username": "DannyBressler"}}, {"_id": "CfnKS3niWyTMemXxe", "postedAt": "2023-05-26T15:51:04.303Z", "postId": "DiGL5FuLgWActPBsf", "htmlBody": "<p>Thanks, Danny! This is all super helpful. I'm planning to work through this comment and your BCA update post next week.</p>", "parentCommentId": "pZNHhRcoDkkoraXhF", "user": {"username": "elliottthornley"}}]