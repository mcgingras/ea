[{"_id": "3H4sq5rb8aprBL5B8", "postedAt": "2023-02-17T18:51:10.215Z", "postId": "S2HvxiBHhaGYs2BYs", "htmlBody": "<blockquote>\n<p>It\u2019s always possible for a decent moral view to be self-effacing, because having true beliefs isn\u2019t the most important thing in the world. If an evil demon said \u201cAgree to moral brainwashing or I\u2019ll torture everyone for eternity,\u201d then you\u2019d obviously better agree to the brainwashing.</p>\n</blockquote>\n<p>What about the deontologist who says \"I can't agree to moral brainwashing because that would involve being complicit in an objective wrong\"? I don't see how this position reduces to or implies the belief that \"having true beliefs [is] the most important thing in the world\".</p>\n<p>Or by \"decent moral view\" did you mean \"decent consequentialist moral view\"?</p>\n", "parentCommentId": null, "user": {"username": "Dacyn"}}, {"_id": "uwvqxfuqLkLpDXHLF", "postedAt": "2023-02-17T20:50:14.283Z", "postId": "S2HvxiBHhaGYs2BYs", "htmlBody": "<p>Avoiding complicity (whatever that amounts to) also isn't literally the most important thing in the world. Note that even most deontologists reject \"though the heavens fall\" absolutism.</p>\n", "parentCommentId": "3H4sq5rb8aprBL5B8", "user": {"username": "RYC"}}, {"_id": "6z5fikboqKJ9nZrLB", "postedAt": "2023-02-18T19:11:49.520Z", "postId": "S2HvxiBHhaGYs2BYs", "htmlBody": "<p>Simple and useful, thanks.</p>\n", "parentCommentId": null, "user": {"username": "Noah Scales"}}, {"_id": "YaEET9G6xb4kjgKew", "postedAt": "2023-02-23T14:57:16.346Z", "postId": "S2HvxiBHhaGYs2BYs", "htmlBody": "<p>I love this piece - super well argued. Your argument applies to virtue ethics too if you replace \u201cRIGHTS\u201d with any virtue claimed to be intrinsically valuable by the virtue ethicist.</p>\n", "parentCommentId": null, "user": {"username": "Jasper Meyer"}}, {"_id": "GZokd6EfoZEemd8bv", "postedAt": "2023-02-23T16:07:24.999Z", "postId": "S2HvxiBHhaGYs2BYs", "htmlBody": "<p>Good point, and a nice addition to the fictionalist reasoning. I would love to see a 'fictionalist virtue ethics' in addition to a fictionalist deontology.</p>", "parentCommentId": "YaEET9G6xb4kjgKew", "user": {"username": "geoffreymiller"}}, {"_id": "oXb8jkycrwCnGQuNR", "postedAt": "2023-02-23T16:25:23.611Z", "postId": "S2HvxiBHhaGYs2BYs", "htmlBody": "<p>Richard -- excellent post -- it's clear, compelling, reasonable, and actionable.&nbsp;</p><p>A key question concerning your three options is more psychological than philosophical: which kinds of people, with which cognitive, personality, and moral traits, should adopt options 1, 2, or 3, in terms of keeping them from using bad utilitarian reasoning (e.g. self-serving, biased, unempirical, convenient moral reasoning) that violates other people's 'rights' or deters them from pursuing 'virtues'? (Just to be clear, I endorse utilitarianism as a a normative ethical theory; the question here is just how to weave some good norms and rules into our prescriptive morality that we use ourselves in day-to-day life, and promote to others.)</p><p>I suspect that many deontologists assume that most people can't handle options 1 or 2, in the sense that those options wouldn't reliably protect us against rights-violating faulty-utilitarian reasoning of the sort that humans evolved to be very good at (according to the '<a href=\"https://www.sciencedirect.com/science/article/pii/S1364661316300973\">argumentative theory of reasoning</a>' from Huge Mercier). So these deontologists see it as their job to promote option 3 as if it's true -- even though they might, in their heart of hearts, know that they're really promoting option 2. &nbsp;However, I suspect that, following science, Nietzsche, &nbsp;secularism, and the collapse of traditional theological and metaphysical bases for deontology, lots of intelligent people simply can't buy into option 3 any more. So, option-3-style arguments just can't carry as much weight as they used to, and can't motivate rule-like constraints on faulty-utilitarian reasoning.</p><p>Conversely, if most people &nbsp;adopt option 1 (prudent two-level consequentialism), I think they might be too tempted to engage in self-serving faulty-utilitarian reasoning. (Arguably this is what we saw with the FTX debacle -- 'it's OK to steal clients' crypto deposits if it's for the greater good'). However, that's an empirical question, and I'm open to updating.</p><p>My hunch is that for most people most of the time, option 2 (deontic fictionalism) strikes the best balance between evidence-based consequentialism and fairly strong guide-rails against self-serving faulty-utilitarian reasoning. So, I think it's worth developing further as a sort of psychologically pragmatic meta-ethics that could work pretty well for our species, given human nature.</p>", "parentCommentId": null, "user": {"username": "geoffreymiller"}}, {"_id": "fgXLxe7FMbHztT3SN", "postedAt": "2023-02-23T16:49:26.801Z", "postId": "S2HvxiBHhaGYs2BYs", "htmlBody": "<p>Thanks! &nbsp;Yes, agreed it's an open empirical question how well people (in general, or particular individuals) can pull off the specified options.</p><p>I wouldn't be terribly surprised if something like (2) turned out to be best for most people most of the time. But I guess I'm sufficiently Aristotelian to think that if we're raised since childhood to abide by good norms, later learning that they're instrumentally justified shouldn't really undermine them that much. (They certainly haven't for me--my wife finds it funny how strongly averse I am to any kind of dishonesty, \"despite\" my utilitarian beliefs!)</p>", "parentCommentId": "oXb8jkycrwCnGQuNR", "user": {"username": "RYC"}}]