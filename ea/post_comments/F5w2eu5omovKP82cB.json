[{"_id": "Csgfr3d2m67FiPe5t", "postedAt": "2024-03-18T05:24:49.310Z", "postId": "F5w2eu5omovKP82cB", "htmlBody": "<p>I probably agree but this is really really hard to do when you have spent most or all your adult life being passionate about one cause or topic. Many would disagree with me, but my first step here would be encouraging them to maximize their impact in the path someone is passionate about, while encouraging them to be part of the EA community/thinking in some way.</p>\n<p>I think keeping someone engaged with thinking about good maximization is more important than trying to push them hard towards cause neutrality.</p>\n", "parentCommentId": null, "user": {"username": "NickLaing"}}, {"_id": "sWBREgh6naeLiBG8e", "postedAt": "2024-03-18T10:17:25.564Z", "postId": "F5w2eu5omovKP82cB", "htmlBody": "<p>I think this is a version of a more general form of motivated reasoning where one seeks out a variable in an argument which is:&nbsp;</p><ol><li>imprecise,&nbsp;</li><li>ambiguous,&nbsp;</li><li>dependent on multiple other hard-to-track variables, or</li><li>a variable over which they can claim unique knowledge (here, 'what I am good at personally and how good at it I am')</li></ol><p>which they can then ratchet up to the maximum value for things they want to believe and the minimum value for things they don't want to believe.&nbsp;</p><p>I noticed this acutely in the comments on the <a href=\"https://www.youtube.com/watch?v=ll9myMeFU3g\">80k/Rational Animations crossover video</a>, namely things like \"If you become a doctor, you don't know how many life-saving situations you run into\" (imprecision about likelihoods) or \"Dr. Nalin couldn't have achieved what he did without the help of many others, down to the bricklayers and garbagemen who provided the essentials he needed to focus\" (ambiguity/dependencies about credit).</p><p>Finding low-confrontation ways to point such things out seems valuable. Maybe the Scout Mindset remains the best work here.</p><p>It is scary and painful for people to admit they were mistaken, especially about their basic narratives concerning what's valuable or what they intended to do with their lives. I'd guess highlighting that truth-seeking is a broader, more-endorsed narrative \u2013 that also implies lots of changing your mind \u2013 is one way to shake people out of these more contingent narratives.&nbsp;</p>", "parentCommentId": null, "user": {"username": "Mjreard"}}, {"_id": "evWeKCqxp46Eaxukt", "postedAt": "2024-03-18T13:43:00.248Z", "postId": "F5w2eu5omovKP82cB", "htmlBody": "<p>I like this post and also worry about this phenomenon.</p>\n<p>When I talk about personal fit (and when we do so at 80k) it's basically about how good you are at a thing/the chance that you can excel.</p>\n<p>It does increase your personal fit for something to be intuitively motivated by the issue it focuses on, but I agree that it seems way too quick to conclude then that your personal fit with that is higher than other things (since there are tons of factors and there are also lots of different jobs for each problem area), let alone that that means you should work on that issue all things considered (since personal fit is not the only factor).</p>\n", "parentCommentId": null, "user": {"username": "Ardenlk"}}, {"_id": "hqqqjdqGSApFbaFGw", "postedAt": "2024-03-18T20:15:42.593Z", "postId": "F5w2eu5omovKP82cB", "htmlBody": "<p>I agree narrowly with the idea that the option people could have the most impact in isn't necessarily the thing they like.&nbsp;</p><p>But the option a person could have the most early career impact in isn't necessarily what's on EA-recommended lists either:</p><ul><li>The fact climate change is not \"neglected\" <i>from a funding and organizations working on it perspective</i> actually means more good opportunities for the median nonspecialist graduate to find impactful early career work in that field,. Whereas EA orgs are famously not easy to get into. &nbsp;</li><li>Individual impact is not the same as organization-level or dollar spend impact. So a graduate with quantitative research skills probably won't produce very different output to anyone else GiveWell could have hired for that role instead, but they might radically change the impactfulness of a charity focused on gender-equality interventions. And there can be potentially very impactful interventions in QALY/WELLBY terms in gender equality, and low-impact or even negative interventions in x-risk or health fields. (Effective organizations probably aren't improved by hiring less engaged candidates either)</li></ul><p>And they're not entirely wrong that doing stuff they're already engaged with is a \"fit\" even if they don't have any specialist skills in that field because</p><ul><li>There's an opportunity cost to investing time into learning about new fields rather than just doing.</li><li>People generally perform better for longer at things they like, and comparative advantage is a thing.</li><li>Some fields are much more accepting of \"generalists\" than others, especially some of the most-recommended EA fields</li></ul><p>So whilst it's entirely possible that people are engaging in motivated reasoning, there's also reason to be cautious about going the other way, and deferring too much to impactful cause area recommendations, or assuming that people can't be more impactful in cause areas the likes of OpenPhil think are not neglected.</p>", "parentCommentId": null, "user": {"username": "David T"}}, {"_id": "zhabKjJqtEsTbwZcD", "postedAt": "2024-03-19T09:46:54.980Z", "postId": "F5w2eu5omovKP82cB", "htmlBody": "<p>I guess I weakly disagree: I think that motivation and already having roots in an issue really are a big part of personal fit - especially now that lots of \"classic EA jobs\" seem highly oversubscribed, even if the cause areas are more neglected than they should be.&nbsp;<br><br>Like to make this more concrete, if your climate-change-motivated young EA was like 'well, now that I've learnt about AI risk, I guess I should pursue that career, ?', but they don't feel excited about it. Even if they have the innate ability to excel in AI safety, they will still have to outcompete people who have already built up expertize there, many of whom will find it easier to motivate themselves to work hard because they are interested in AI.&nbsp;<br><br>(On the object level, I assume that many roles in climate change and gender equality stuff are in fact more impactful than many roles in more canonical EA cause areas).&nbsp;<br><br><br>&nbsp;</p>", "parentCommentId": null, "user": {"username": "Amber"}}, {"_id": "CdfiRtkeNj9gtFans", "postedAt": "2024-03-19T17:11:27.739Z", "postId": "F5w2eu5omovKP82cB", "htmlBody": "<p>See Holden Karnofsky's <a href=\"https://80000hours.org/podcast/episodes/holden-karnofsky-building-aptitudes-kicking-ass/\">aptitudes-based perspective</a>.&nbsp;</p><blockquote><p><a href=\"https://forum.effectivealtruism.org/posts/bud2ssJLQ33pSemKH/my-current-impressions-on-career-choice-for-longtermists\">80,000 Hours tends to emphasize \"<strong>paths</strong>\" to particular roles working on particular causes; by contrast, I emphasize \"<strong>aptitudes</strong>\" one can build in a wide variety of roles and causes (including non-effective-altruist organizations) and then apply to a wide variety of longtermist-relevant jobs (often with options working on more than one cause)</a></p></blockquote><p>I definitely agree that \"some people scoping out their career options could benefit from first identifying high-impact career options, and only second thinking about which ones they might have a great personal fit for\". But others could benefit from the opposite consideration, especially when taking into account moral and epistemic uncertainty about the relative value of different cause areas, and replaceability in areas where they would be limited to less specialized roles.</p><p>I think there's a real tension between \"it's best for everyone to just work on their favourite thing\" and \"it's best for everyone to go work <s>at OpenAI</s> on AI Policy,\" and people make mistakes in both directions, both in their own careers and when giving advice to others. I personally believe that there are enough high-impact opportunities in<a href=\"https://forum.effectivealtruism.org/posts/zuqpqqFoue5LyutTv/the-ea-community-does-not-own-its-donors-money?commentId=D8kgatLTtLhGPtksf#D8kgatLTtLhGPtksf\"> climate change</a> (esp. considering air quality) and <a href=\"https://forum.effectivealtruism.org/posts/ydH6xFXTpcRca6gw7/a-fund-to-help-prevent-violence-against-women-and-girls\">gender equality</a> (esp. in a global sense) for them to be great areas in which to build aptitudes and do the most good, but it's definitely not a given.</p><p>To be clear, I don't think this post says anything wrong, and I agree with it; although I don't see the same recommendation often made to people who work on mechanistic interpretability or cause-prioritization because they already liked it. (It's usually people criticizing the EA movement that say things like: \"<a href=\"https://mathbabe.org/2024/03/16/an-interview-with-someone-who-left-effective-altruism/\">There are a lot of people in EA who just wanted a legitimate reason or excuse to sit around and talk about these big questions. But that made it feel like it\u2019s a real job and they\u2019re doing something good in the world instead of just sitting in a room and talking about philosophy.</a>\")</p>", "parentCommentId": "zhabKjJqtEsTbwZcD", "user": {"username": "Lorenzo Buonanno"}}, {"_id": "smCvoMpBmyiixL3xe", "postedAt": "2024-03-20T15:40:58.592Z", "postId": "F5w2eu5omovKP82cB", "htmlBody": "<p>Nice point, Joris! Relatedly, readers may want to check <a href=\"https://80000hours.org/2024/02/skills-pages-launch/\">80,000 Hours' new series on building skills</a>.</p><blockquote><p>If we were going to summarise all our advice on how to get career capital in three words, we\u2019d say: <i>build useful skills</i>.</p><p>In other words, gain abilities that are valued in the job market \u2014 which makes your work more useful and makes it easier to bargain for the ingredients of a <a href=\"https://80000hours.org/career-guide/job-satisfaction/\">fulfilling job</a> \u2014 as well as those that are specifically needed in tackling the <a href=\"http://80000hours.org/problem-profiles/\">world\u2019s most pressing problems</a>.</p><p>So today, we\u2019re launching our series on <strong>the most useful skills for making a difference</strong> \u2014 <a href=\"http://80000hours.org/skills/\">which you can find here</a>. It covers why we recommend each skill, how to get started learning them, and how to work out which is the best fit for you.</p></blockquote>", "parentCommentId": null, "user": {"username": "vascoamaralgrilo"}}]