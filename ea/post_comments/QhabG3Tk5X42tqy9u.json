[{"_id": "Yzi9jdbEZbfmhhuuJ", "postedAt": "2017-11-26T22:53:12.017Z", "postId": "QhabG3Tk5X42tqy9u", "htmlBody": "<p>Thanks very much for this. I just want to add a twist to this:</p>\n<blockquote>\n<p>Counterintuitively, this suggests that you should stay away from new technologies: it is very likely that someone will try \u201cmachine learning for X\u201d relatively soon, so it is unlikely to be neglected.</p>\n</blockquote>\n<p>EAs don't have stay away from new tech. You could plan to have impact by getting rich via being the first to build cutting edge tech and then giving your money away; basically doing a variant of 'earn to give'. In this case your company wouldn't have done much good directly - because what you call the 'time advantage' would be so tiny - and the value would come from your donations. This presumes the owners of the company you beat wouldn't have given their money away.</p>\n", "parentCommentId": null, "user": {"username": "MichaelPlant"}}, {"_id": "riqXXtCNr389uLB93", "postedAt": "2017-11-27T01:14:08.617Z", "postId": "QhabG3Tk5X42tqy9u", "htmlBody": "<p>Yes, there are other instrumental reasons to be involved in new tech. It's not only the money, but it also means you'll learn about the tech, which might help you spot new opportunities for impact, or new risks.</p>\n<p>I also think I disagree with the reasoning. If you consider neglectedness over all time, then new tech <em>is</em> far more neglected since people have only just started using it. With tech that has been around for decades, people have already had a chance to find all its best applications. e.g. when we interviewed biomedical researchers, several mentioned that breakthroughs often come when people apply new tech to a research question.</p>\n<p>My guess is that there are good reasons for EAs to aim to be on the cutting edge of technology.</p>\n", "parentCommentId": "Yzi9jdbEZbfmhhuuJ", "user": {"username": "Benjamin_Todd"}}, {"_id": "GjikC8K2CFmFERKeK", "postedAt": "2017-11-27T18:20:34.704Z", "postId": "QhabG3Tk5X42tqy9u", "htmlBody": "<p>One of the things I find hard is the externalities, because often there are tons of things that a company is influencing. For example, with Heroes &amp; Friends (our company) we try to built a platform for social movements (NGOs, social enterprises, etc.) and we don't control who is using it. So it can be used for ineffective movements but also highly effective ones. However, in our view we see a new society emerging where people take action themselves and take responsibility to improve their own community and help other people too. So on the surface it might have less direct impact (depending on the users) but on the long-term we want to be the market place of the 'informal economy' where people can 'harvest goodwill'. In order for this bottom-up economy to self-organize it needs a system or marketplace that provides the technology to do so, and we are basically building the best software for social movements to grow. But how would you include or exclude externalities? Which ones do you count and which ones do you leave out? </p>\n<p>Is it a positive externality that more than 1 million people read good news stories and opportunities to act in their social media because of our platform or not? Is it a negative externality that many projects are not optimalized for 'doing the most good'? I'm just wondering how we could measure this for our own company but also for many others because I think there should be a lot of data points included.</p>\n", "parentCommentId": null, "user": {"username": "Michiel"}}, {"_id": "vKfA27FRmksM8B9sC", "postedAt": "2017-11-27T19:54:56.528Z", "postId": "QhabG3Tk5X42tqy9u", "htmlBody": "<p>I think it's worth trying to have a toy model of this, even if it's mostly big boxes full of question marks. Going down to the <a href=\"http://lesswrong.com/lw/ozz/gears_in_understanding/\">gears level</a> can be very helpful.</p>\n<p>For example, it can help you answer questions like &quot;how much good does doing X for one person have to do for this to be worth it?&quot;, or &quot;how many people do we need to reach for this to be worth it?&quot;. You might also realise that all your expected impact comes from a certain class of thing, and then try and do more of that or measure it more carefully.</p>\n<p>Which externalities to include is a tough question! In most examples I think there are a few that are &quot;obviously&quot; the most important, but that's just pumping my intuition and probably missing some things. I think often this is a case of building out your &quot;informal model&quot; of the project: presumably you think it will be good, but <em>why</em>? What is it about the project that could be good (or bad)? If you can answer those questions you have at least a starting point.</p>\n<p>One final thing: when I say &quot;negative externality&quot; I mean something that's actively <em>bad</em>. It seems unlikely that people using your platform for ineffective projects is bad, but rather neutral (since we think they're not very effective). What might be bad could be e.g. reputational damage from being associated with such things.</p>\n", "parentCommentId": "GjikC8K2CFmFERKeK", "user": {"username": "Michael_PJ"}}, {"_id": "XWZr7G2AEvLyiJRAs", "postedAt": "2017-11-27T19:58:02.231Z", "postId": "QhabG3Tk5X42tqy9u", "htmlBody": "<p>Yes - I should have clarified but this is deliberately not addressing the &quot;earning to give through entrepreneurship&quot; route. I <em>should</em> have mentioned it because it's quite important: I think for a lot of people it's going to be the best route.</p>\n<p>Aside: if I think earning to give is so great, why have I been spending so much time talking about direct work? Because I think we need to do <a href=\"http://effective-altruism.com/ea/170/ea_should_invest_more_in_exploration/\">more exploration</a>.</p>\n", "parentCommentId": "Yzi9jdbEZbfmhhuuJ", "user": {"username": "Michael_PJ"}}, {"_id": "w3xdcKc5rwohQgyg6", "postedAt": "2017-11-27T20:05:17.998Z", "postId": "QhabG3Tk5X42tqy9u", "htmlBody": "<p>Let me illustrate my argument. Suppose there are two opportunities, X and Y. Each of them contributes some value at each time step after they've been taken.</p>\n<p>In the base timeline, A is never taken, and B is taken at time 2.</p>\n<p>Now, it is time 1 and you have the option of taking A or B. Which should you pick?</p>\n<p>In one sense, both are equally neglected, but in fact taking A is much better, because B will be taken very soon, whereas A will not.</p>\n<p>The argument is that new technology is more likely to be like B, and any remaining opportunities in old technology is more likely to be like A (simply because if it were easy to do, we would have expected someone to do it already).</p>\n<p>So even if most breakthroughs occur at the cutting edge, so long as we expect other people to do them soon, and they are not <em>so</em> big that we really want even a small speedup, then it can be better to find things that are more &quot;persistently&quot; neglected. (I used to use &quot;persistent neglectedness&quot; and &quot;temporary neglectedness&quot; for these concepts, but I thought it was confusing)</p>\n", "parentCommentId": "riqXXtCNr389uLB93", "user": {"username": "Michael_PJ"}}, {"_id": "z62DK4mw5b27WM4xx", "postedAt": "2017-11-28T04:31:31.665Z", "postId": "QhabG3Tk5X42tqy9u", "htmlBody": "<p>OK, I agree that makes sense as well - it now seems unclear which way it goes.</p>\n<p>However, if you're thinking from a career capital or more long-term future perspective (where transformative technologies are often the key lever), my guess is that EAs should still focus on learning about cutting-edge technologies.</p>\n", "parentCommentId": "w3xdcKc5rwohQgyg6", "user": {"username": "Benjamin_Todd"}}, {"_id": "Yf3aBJK6fcvrvNF6X", "postedAt": "2022-01-01T17:53:23.265Z", "postId": "QhabG3Tk5X42tqy9u", "htmlBody": "<p>Hi Michael,</p><p>I am also familiar with Peter Thiel's idea about secrets. In Zero to One, &nbsp;he also talks about building and maintaining a monopoly using defenses to entry. He talks about building network effects, economies of scale, intellectual property, and brand. Do any or all of these hurt the overall good?&nbsp;</p><p>This is focused on the consumer side of things, not the third party benefactors. Though if you do find any of these often negatively affect third parties, please say so.</p><p>Economies of scale and network effects of a market makes it economical to have the large majority of production in a small number of hands. So long as the consumer sees some of that benefit either through lower prices or a better product, there is an increase in the overall good for the consumer to have a monopoly.&nbsp;</p><p>With intellectual property, you mentioned Tesla's innovation being a public good due to their open patents. To my knowledge Tesla is still protected by generally a high level of innovation, economies of scale, and brand. Could one justify having closed patents if the patents drive higher profits which helps the company &nbsp;grow and innovate further?</p><p>I know Nike has patents for their green material for shoes, but licenses their patents to non-competitors to not stop their creation. What situations would the Nike method or Tesla method best benefit the public good?</p><p>Brand is a little more subjective, but things like fashion brands which have value because they are known to be expensive may be a public loss. A brand built on reliability, quality, or trust, if accurate, allows consumers to more reliably select the best product for them by providing more accurate information to the public.&nbsp;</p><p>As Peter Thiel says, if we don't have a monopoly, the profits will be driven to effectively zero and the ability to innovate decreases (look at legacy car makers). In an efficient market, maximizing profits will maximize total well-being. In reality, there is corporate responsibility and this post covered some of it. &nbsp;How should we think about barriers to entry using EA? Thanks alot for the original post!</p>", "parentCommentId": null, "user": {"username": "Isaac Benson"}}]