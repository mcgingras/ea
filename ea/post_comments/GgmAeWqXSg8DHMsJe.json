[{"_id": "7oddaudPggccWvBo8", "postedAt": "2023-05-11T17:43:20.768Z", "postId": "GgmAeWqXSg8DHMsJe", "htmlBody": "<p>Larger charities also tend to have more room for more funding, e.g. the big corporate campaign ones, and I think ACE (for Top Charities, at least) and Open Phil both leave room for more funding in them even after taking into account other funding the funders expect the charities to get. But I suppose there could still be funging; the funders may have specific total funding targets below filling their near term RFMF, and the closer to those targets, the less they give.</p>\n", "parentCommentId": null, "user": {"username": "MichaelStJules"}}, {"_id": "JWazkBqhfaRHmxKhr", "postedAt": "2023-05-11T17:53:43.098Z", "postId": "GgmAeWqXSg8DHMsJe", "htmlBody": "<p>To be clear, I don't think ACE does this except crudely between recommendation statuses, because they regrant evenly to their Top Charities, and evenly to their other Recommended Charities. You'd have to donate enough to reduce the recommendation status of an org, which seems unlikely for their Top Charities, at least, unless you're donating (much?) more than $100K, and probably also unlikely for their Recommended Charities. So, it may be worth looking more into Open Phil in particular.</p>\n", "parentCommentId": "7oddaudPggccWvBo8", "user": {"username": "MichaelStJules"}}, {"_id": "bXQiesrdYd7vmBy6E", "postedAt": "2023-05-11T18:09:40.407Z", "postId": "GgmAeWqXSg8DHMsJe", "htmlBody": "<p>THL also regrants through the Open Wing Alliance to small orgs that the EA Animal Welfare Fund and ACE Movement Grants sometimes support, and is expanding internationally to neglected regions where it might (speculating here) crowd out other small charities, so there might be some funging there, too. But they're still doing substantial corporate welfare work concentrated in specific countries, like the US and the UK. I would guess other large charities working on corporate animal welfare reform are more concentrated in a few regions, so would funge less this way.</p>\n<p>I suppose there could also be some funging on the corporate animal welfare work, because the next targets could be relatively less important and orgs would shift to other work, now or in the future. But this seems much less important as a concern.</p>\n", "parentCommentId": "7oddaudPggccWvBo8", "user": {"username": "MichaelStJules"}}, {"_id": "Kbt4GLTRZL6NbZLcf", "postedAt": "2023-05-11T19:47:02.153Z", "postId": "GgmAeWqXSg8DHMsJe", "htmlBody": "<p>Given that EA seems to be taking invertebrate welfare more seriously lately and seems likely to do so increasingly, it may be worth specifically promoting research on the wild animal effects of diet change (I guess this post does that a bit), and possibly supporting more research on it and the welfare of populous wild animals, especially if you think wild animals are likely to have bad lives even according to classical utilitarianism, and the movement is miscalibrated and/or often ignores this. This could shift the movement's funding as a whole in a better direction.</p>\n", "parentCommentId": null, "user": {"username": "MichaelStJules"}}, {"_id": "FeFMaE4F4BJnHtB7F", "postedAt": "2023-05-11T23:14:08.122Z", "postId": "GgmAeWqXSg8DHMsJe", "htmlBody": "<p>Also, Open Phil mostly seems to spend on corporate animal welfare campaigns, so I'd expect around or less than half of your donations to big corporate campaign charities to be funged towards things other than corporate campaigns.</p>\n<p><a href=\"https://forum.effectivealtruism.org/posts/6H9QGZkdMzDEdKNCX/analysis-of-ea-funding-within-animal-welfare-from-2019-2021-1\">https://forum.effectivealtruism.org/posts/6H9QGZkdMzDEdKNCX/analysis-of-ea-funding-within-animal-welfare-from-2019-2021-1</a></p>\n", "parentCommentId": "JWazkBqhfaRHmxKhr", "user": {"username": "MichaelStJules"}}, {"_id": "Nf2AgCut4exAmH4f7", "postedAt": "2023-05-12T02:36:46.993Z", "postId": "GgmAeWqXSg8DHMsJe", "htmlBody": "<blockquote>\n<p>But I suppose there could still be funging; the funders may have specific total funding targets below filling their near term RFMF, and the closer to those targets, the less they give.</p>\n</blockquote>\n<p>Yeah. Or it could work in reverse: if they commit to giving only, say, 50% of an org's budget, then if individual donors give more, this \"unlocks\" the ability for the big donors to give more also. However, Karnofsky <a href=\"https://forum.effectivealtruism.org/posts/cjH2puDzAFrtrrThQ/despite-billions-of-extra-funding-small-donors-can-still?commentId=mY5cDtY7uH3q6HX6Z\">says</a> it's a myth that Open Phil has a hard rule like this. Also, as I noted in the post, I wouldn't <em>want</em> them to have a hard rule like this, because it could leave really valuable orgs significantly underfunded, which seems bad.</p>\n<p>Probably the answer of how it actually works varies depending on the specific case. For example, I imagine that an org that everything thinks is outstanding would be more likely to get fully topped up, while an org that seems average wouldn't be. But as an outsider, I can only speculate about how these decisions are made, which is why I posted this question.</p>\n", "parentCommentId": "7oddaudPggccWvBo8", "user": {"username": "Brian_Tomasik"}}, {"_id": "jDYk6uyzdZTiHZfka", "postedAt": "2023-05-12T02:44:49.644Z", "postId": "GgmAeWqXSg8DHMsJe", "htmlBody": "<blockquote>\n<p>You'd have to donate enough to reduce the recommendation status of an org, which seems unlikely for their Top Charities, at least</p>\n</blockquote>\n<p>It's unlikely, but if it did happen, it would be a huge negative impact, so in expectation it could still be nontrivial funging? For example, if I think one of ACE's four top charities is way better than the others, then if I donate a small amount to it, there's a tiny chance this leads to it becoming unrecommended, but if so, that would result in a ton less future funding to the org.</p>\n", "parentCommentId": "JWazkBqhfaRHmxKhr", "user": {"username": "Brian_Tomasik"}}, {"_id": "AYtNGnMvG5wTTuQPr", "postedAt": "2023-05-12T03:03:23.372Z", "postId": "GgmAeWqXSg8DHMsJe", "htmlBody": "<p>That's a useful post! It's an interesting idea. There could be some funging between Open Phil and other EA animal donors -- like, if Open Phil is handling the welfare reforms, then other donors don't have to and can donate more to non-welfare stuff. OTOH, the fact that a high-status funder like Open Phil does welfare reforms makes it more likely that other EAs follow suit.</p>\n<p>Another thing I'd worry about is that if Open Phil's preferred animal charities have less RFMF, then maybe Open Phil would allocate less of its funds to animal welfare in general, leaving more available for other cause areas. Some of those cause areas, like biorisk reduction, plausibly increase expected suffering. From the perspective of this worry, it may be safest to give to small charities that Open Phil would be unlikely to consider or charities that Open Phil doesn't find promising enough for some reason.</p>\n", "parentCommentId": "FeFMaE4F4BJnHtB7F", "user": {"username": "Brian_Tomasik"}}, {"_id": "HyNjtqaN6n4nRa6Gf", "postedAt": "2023-05-12T03:26:57.186Z", "postId": "GgmAeWqXSg8DHMsJe", "htmlBody": "<p>Yeah, more research on questions like whether beef reduces net suffering would be extremely useful, both for my personal donation decisions and more importantly for potentially shifting the priorities of the animal movement overall. My worries about funging here ultimately derive from my thinking that the movement is missing some crucial considerations (or else just has different values from me), and the best way to fix that would be for more people to highlight those considerations.</p>\n<p>I'm unsure how more research on the welfare of populous wild animals would shift people's views. I guess relative to mainstream animal-rights ideology that says more wildlife is good, there's only really room to move in a more pessimistic direction. But for people already thinking about wild-animal welfare, it's less clear. To me it's obvious that I would be horrified to be born as a random wild animal, but I'm often surprised by how little some classical utilitarians care about suffering relative to happiness.</p>\n<p>This is one reason I'm more inclined these days to promote suffering-focused philosophy rather than generic antispeciesism. However, there aren't that many ways to donate to suffering-focused philosophy at the moment, and depending on who is funded, that approach has its own possible downside risks. For example, I've considered whether the antinatalism movement could benefit from funding (because it's people-rich and money-poor), but a lot of antinatalists are abrasive and may give suffering-focused ethics a bad name. Picking the right antinatalists (and other advocates of suffering-focused ethics) to fund would be a lot of work (but might be worth it). Also, this philosophy work doesn't scratch my itch to have some amount of concrete suffering-reduction impact in the near term.</p>\n", "parentCommentId": "Kbt4GLTRZL6NbZLcf", "user": {"username": "Brian_Tomasik"}}, {"_id": "fv8CFxBSyFuTez3Nt", "postedAt": "2023-05-12T05:10:58.375Z", "postId": "GgmAeWqXSg8DHMsJe", "htmlBody": "<p>I'd guess the funging or reduced funding this way would be small in expectation, like less than 5%? If you split your donations across multiple of these charities, you can reduce the total risk.</p>\n<p>But again, I think these orgs systematically have extra RFMF (and you could check ACE's reports to see how much), and they tend not to lose status because of reduced RFMF. Like THL and GFI have been Top Charities continuously (except GFI missing one year for culture issues). I think other orgs dropped in status usually because of culture/harassment issues or revisions to expectations of their cost-effectiveness or promisingness of their work.</p>\n<p>Also, I suppose donating could even increase their RFMF in the longer run instead of dropping the recommendation status, by addressing bottlenecks for growth.</p>\n", "parentCommentId": "jDYk6uyzdZTiHZfka", "user": {"username": "MichaelStJules"}}, {"_id": "JSnKvCYixtACqdCC9", "postedAt": "2023-05-12T12:42:17.159Z", "postId": "GgmAeWqXSg8DHMsJe", "htmlBody": "<p>This isn't about the main question you raise in this post, but I'm curious why you think biorisk reduction would increase expected future suffering.</p>\n", "parentCommentId": null, "user": {"username": "Jeroen_W"}}, {"_id": "t2SimzBcGAGjeBB9t", "postedAt": "2023-05-12T18:26:13.349Z", "postId": "GgmAeWqXSg8DHMsJe", "htmlBody": "<p>Not speaking for Brian, but biorisk reduction increases the probability humanity reaches the stars, which is object-level bad from a negative utilitarian perspective unless you think we're counterfactually likely to encounter worse-than-humans aliens.&nbsp;</p>", "parentCommentId": "JSnKvCYixtACqdCC9", "user": {"username": "Linch"}}, {"_id": "TkhnoPhvBPFfz4hCD", "postedAt": "2023-05-12T19:13:51.520Z", "postId": "GgmAeWqXSg8DHMsJe", "htmlBody": "<p>And even if we encounter worse-than-humans aliens, that could be bad due to conflict with them.</p>\n", "parentCommentId": "t2SimzBcGAGjeBB9t", "user": {"username": "MichaelStJules"}}, {"_id": "c5feWdgh2WTTgA85e", "postedAt": "2023-05-12T19:26:11.492Z", "postId": "GgmAeWqXSg8DHMsJe", "htmlBody": "<blockquote>\n<p>The Humane Slaughter Association (HSA) is another option that not many EAs seem interested in. HSA received two large grants from Open Philanthropy, in 2017 and 2019, but those were earmarked for specific projects, so general HSA funding may not be funged by them.</p>\n</blockquote>\n<p>That is already a while ago. It might be worthwhile to check what they did after they received this grant and whether they have good follow-up work to do. Maybe they have room for more funding again, but Open Philanthropy downprioritized re-evaluating them? Or they aren't as promising as Open Philanthropy thought in 2019.</p>\n<p>I briefly looked at their <a href=\"https://www.hsa.org.uk/publications/newsletters-annual-reports\">2022 Annual Report</a>. They were still working on fish and invertebrates, or funding research by others.</p>\n", "parentCommentId": null, "user": {"username": "Imma Six"}}, {"_id": "KTsMNckfMjF2zz59G", "postedAt": "2023-05-12T20:07:24.238Z", "postId": "GgmAeWqXSg8DHMsJe", "htmlBody": "<p>FWIW, I have a note from a Q&amp;A with Leah Edgerton in 2021 mentioning that the funding gaps that Animal Charity Evaluators assigns to a charity typically does not get filled. The charities still don't receive enough money.\nOne could verify that by comparing the funding gap with the actual money moved a year later. (I did not do that work so far, but could imagine myself doing that if I'm interested enough in the charity).</p>\n<p>If true, I would not be very concerned about funging in ACE-recommended charities.</p>\n", "parentCommentId": null, "user": {"username": "Imma Six"}}, {"_id": "9hMjsCf7kmLyvynuA", "postedAt": "2023-05-13T01:56:59.310Z", "postId": "GgmAeWqXSg8DHMsJe", "htmlBody": "<p>I'm a bit confused about why the fact that most organizations have funding gaps would be highly relevant here.</p>\n<p>It's clear that if you donate $100K to X, and it has no good use for more than $1MM, other rational donors won't give more than $900K. That seems simple enough. But it would seem too strong to say there's no meaningful funging unless the other donors were going to give more than $900K counterfactually.</p>\n<p>Rather, it seems likely that RFMF isn't a binary cliff -- a funder may assess the hypothetical organization as producing 4 utilons per dollar for the first 300k (because of fixed overhead / diseconomies of non-scale), 10 utilons per $ for the next 300k (which would go to the highest-value programs), 7 per $ with the next 200k, 5 per $ with the next 200k, then 0 thereafter.</p>\n<p>So the effect of your donation on the funder's action would seem to depend on where the funder would be putting their last marginal dollar. Even assuming the organization would have RFMF in the binary sense in all scenarios, the other funder may be evaluating a different marginal tranche than it would have absent your $100K donation.</p>\n", "parentCommentId": null, "user": {"username": "Jason"}}, {"_id": "4a5LSMo9FPPrXFn4v", "postedAt": "2023-05-13T06:26:44.907Z", "postId": "GgmAeWqXSg8DHMsJe", "htmlBody": "<p>Great point! Michael said something similar:</p>\n<blockquote>\n<p>the funders may have specific total funding targets below filling their near term RFMF, and the closer to those targets, the less they give.</p>\n</blockquote>\n<p>For example, the funders might aim for a marginal utility of 6 utilons per dollar, so using your example numbers, they would only want to fund the org up to $800K. And if someone else is already giving $100K, they would only want to give $700K.</p>\n<p>My guess would be that in practice, funders probably aren't thinking too much about a curve of marginal utility per dollar but are more thinking something like: Is this org working on an important problem? Do they need more money to continue/expand this particular work? What percent of that funding gap do we want to fill?</p>\n<p>But this is just my speculation about how I imagine people would make grants when they have lots of charities to review and lots of money to disburse, with limited time to investigate each one in depth. If they have time to review more detailed plans about what each incremental chunk of money would be spent on, they might get closer to the marginal-utility approach you mention.</p>\n", "parentCommentId": "9hMjsCf7kmLyvynuA", "user": {"username": "Brian_Tomasik"}}, {"_id": "v4BcvKkLXPA5DuQCC", "postedAt": "2023-05-13T06:38:34.704Z", "postId": "GgmAeWqXSg8DHMsJe", "htmlBody": "<p>Thanks! That's encouraging to hear (although it would be better for animals if the charities did fill their funding gaps).</p>\n<p>There could still be some funging if a smaller remaining funding gap discourages other donors, such as the Animal Welfare Fund, from giving more, but at least the effect is probably less drastic than if the org hits its target RFMF fully.</p>\n", "parentCommentId": "KTsMNckfMjF2zz59G", "user": {"username": "Brian_Tomasik"}}, {"_id": "uHEJzrTMXiLXLb66D", "postedAt": "2023-05-13T06:43:49.286Z", "postId": "GgmAeWqXSg8DHMsJe", "htmlBody": "<p>Good points! I'd be curious to hear what Lewis thought of those two HSA grants and why Open Phil hasn't done more since then.</p>\n", "parentCommentId": "c5feWdgh2WTTgA85e", "user": {"username": "Brian_Tomasik"}}, {"_id": "WMZcGLhh4NzYiqu2d", "postedAt": "2023-05-13T07:15:24.508Z", "postId": "GgmAeWqXSg8DHMsJe", "htmlBody": "<p>That's right. :) There are various additional details to consider, but that's the main idea.</p>\n<p>Catastrophic risks have other side effects in scenarios where humanity does survive, and in most cases, humanity would survive. My impression is that apart from AI risk, biorisk is the most likely form of x-risk to cause actual extinction rather than just disruption. Nuclear winter and especially climate change seem to have a higher ratio of (probability of disruption but still survival)/(probability of complete extinction). AI extinction risk would presumably still involve intelligent agents reaching the stars, so it still may lead to astronomical amounts of suffering.</p>\n<p>There are also considerations about cooperation. For example, if one has enough credence in <a href=\"https://longtermrisk.org/msr\">Evidential Cooperation in Large Worlds</a> (ECL), then even a negative utilitarian should support reaching the stars because many other value systems want it (though some don't, even for reasons besides reducing suffering). Even ignoring ECL, it seems like a bad idea to actively increase biorisk because of the backlash it would provoke. However, due to the act/omission distinction, it's probably ok to encourage others to omit funding for biorisk-safety work, or at least to try to avoid increasing such funding yourself. Given that work on reducing AI risk isn't necessarily bad from a suffering-reduction standpoint, shifting biorisk funding to AI risk (or other EA cause areas) is a way to do this omission in a way that may not be that objectionable to most EAs, because the risk of human extinction is still being reduced in either case.</p>\n", "parentCommentId": "t2SimzBcGAGjeBB9t", "user": {"username": "Brian_Tomasik"}}, {"_id": "sJmtM2Ddw2tgBfTDK", "postedAt": "2023-05-13T11:39:25.027Z", "postId": "GgmAeWqXSg8DHMsJe", "htmlBody": "<p>Also, <i>If</i> there's sentient life on reachable planets or a chance of it emerging in the future, some NUs might also argue that the chance of human descendants ending/preventing suffering on such planets might be worth the risk of spreading suffering. (Cf. <a href=\"https://forum.effectivealtruism.org/topics/david-pearce-1\">David Pearce</a>'s <a href=\"https://www.hedweb.com/object32.htm\">\"cosmic rescue mission\"</a>.)</p>", "parentCommentId": "t2SimzBcGAGjeBB9t", "user": {"username": "eFish"}}, {"_id": "uGuYhhMjhT2DiN6cu", "postedAt": "2023-05-13T23:23:24.339Z", "postId": "GgmAeWqXSg8DHMsJe", "htmlBody": "<p>Right, this is what I was alluding to with&nbsp;</p><blockquote><p>unless you think we're counterfactually likely to encounter worse-than-humans aliens.&nbsp;</p></blockquote><p>but I agree that in theory we can reduce suffering for aliens who are morally better than humans but less technologically capable.&nbsp;<br><br>That said, the NU case for it doesn't necessarily seem very strong because natural suffering isn't as astronomical in scale as s-risks.</p>", "parentCommentId": "sJmtM2Ddw2tgBfTDK", "user": {"username": "Linch"}}, {"_id": "635TFvtCbPZZc2yjh", "postedAt": "2023-05-14T00:12:52.041Z", "postId": "GgmAeWqXSg8DHMsJe", "htmlBody": "<blockquote>\n<p>they tend not to lose status because of reduced RFMF</p>\n</blockquote>\n<p>Great point! That makes them different from GiveWell charities, where, e.g., AMF was dropped at least once due to RFMF concerns.</p>\n<blockquote>\n<p>I suppose donating could even increase their RFMF in the longer run</p>\n</blockquote>\n<p>Yeah, it's not obvious to me that it's right to think about RFMF decreasing as a charity gets more money. It may well be the opposite: more money means faster growth, which means more ability to use money.</p>\n<p>OTOH, if <em>other donors</em> believe that RFMF is limited, then there's a possibility of them funging away any extra donations you might make. For example, if you donate $25K in an effort to help the charity grow faster and increase its long-term RFMF, if someone else sees that and immediately shrinks their grant size by $25K, then you don't succeed in helping the charity grow any faster, its long-term RFMF remains unchanged, and you still get funged.</p>\n", "parentCommentId": "fv8CFxBSyFuTez3Nt", "user": {"username": "Brian_Tomasik"}}, {"_id": "hqd596rnqnAqL5bnR", "postedAt": "2023-05-14T00:43:35.124Z", "postId": "GgmAeWqXSg8DHMsJe", "htmlBody": "<p>Hey Brian, I think it's too early to judge both of the HSA grants we funded because they're for long research projects, which have also gotten delayed. We'd like to fund more similar work for HSA but there have been capacity constraints on both sides. We also tend to weigh prolonged chronic suffering more highly than shorter acute suffering, so slaughter isn't as obvious a focus for us. So I think funding HSA or similar slaughter-focused groups is a good idea for EAs like you who prioritize acute suffering. On slaughter, you might like to also look into the Shrimp Welfare Project (OP-funded, but with RFMF).</p>", "parentCommentId": "uHEJzrTMXiLXLb66D", "user": {"username": "LewisBollard"}}, {"_id": "xCwcaNkHdsreJvEif", "postedAt": "2023-05-14T01:39:25.295Z", "postId": "GgmAeWqXSg8DHMsJe", "htmlBody": "<p>Good to know! Are there any other slaughter-focused groups besides HSA? Maybe you mean groups for which one of their major priorities is slaughter, like Shrimp Welfare Project and various other charities working on chickens and fish?</p>\n<p>I saw a <a href=\"https://www.openphilanthropy.org/grants/animal-protection-denmark-wild-caught-fish-welfare/\">2021 Open Phil grant</a> \"to Animal Protection Denmark to support research on ways to improve the welfare of wild-caught fish.\" But that organization itself does lots of stuff (including non-farm-animal work).</p>\n<p>Off topic: There's <a href=\"https://transcripts.foreverdreaming.org/viewtopic.php?f=150&amp;t=35480\">a line</a> in the movie <em>A Cinderella Story: Christmas Wish</em> that might be applicable to you: \"was also credited with helping shift the Animal Rights movement to a more utilitarian focus including a focus on chicken.\"</p>\n", "parentCommentId": "hqd596rnqnAqL5bnR", "user": {"username": "Brian_Tomasik"}}, {"_id": "itCEYLHW7J23REZ5M", "postedAt": "2023-05-14T10:05:33.522Z", "postId": "GgmAeWqXSg8DHMsJe", "htmlBody": "<p>In reading more about this topic, I discovered that there has already been a lot of discussion about <a href=\"https://forum.effectivealtruism.org/topics/philanthropic-coordination\">donor coordination</a> on the EA Forum that I missed. (I don't read the Forum very actively.) EAs generally think it's bad to engage in a game of chicken where you try to let other people fund something first, at least within the EA community -- e.g., <a href=\"https://forum.effectivealtruism.org/posts/NpruaYQxW7NmaaxzT/forget-replaceability-for-community-projects\">Cotton-Barratt (2021)</a>.</p>\n<p>My original thought behind making this post was that the extent of funging for animal donations seemed like a useful thing for various animal donors to be aware of, to be more informed about their giving choices. However, I can imagine that some people see it as a net-negative topic to bring up, because it may encourage more games of donation chicken among donors. My post also mentioned my criticisms of some existing EA animal charities, but I could have done that separately from the discussion of donation funging. I still think it's reasonable for people to be more informed about how funging works, but I also see the downside of broadcasting that discussion.</p>\n", "parentCommentId": null, "user": {"username": "Brian_Tomasik"}}, {"_id": "yXRhuhskyu4moMfkh", "postedAt": "2023-05-14T16:03:09.442Z", "postId": "GgmAeWqXSg8DHMsJe", "htmlBody": "<blockquote>\n<p>Off topic: There's a line in the movie A Cinderella Story: Christmas Wish that might be applicable to you: \"was also credited with helping shift the Animal Rights movement to a more utilitarian focus including a focus on chicken.\"</p>\n</blockquote>\n<p>This is an amazing thing to learn.</p>\n", "parentCommentId": "xCwcaNkHdsreJvEif", "user": {"username": "reallyeli"}}, {"_id": "b5pQnGMXXP22GL7yo", "postedAt": "2023-05-14T18:59:42.253Z", "postId": "GgmAeWqXSg8DHMsJe", "htmlBody": "<p>[Epistemic status: confused stuff that I haven't thought about that much. That said I do think this consideration is quite real and I've talked to suffering focused people about this sort of thing (I'm not currently suffering focused)]</p>\n<p>Beyond ECL-style cooperation with values which want to reach the stars and causally reaching aliens, I think the strongest remaining case is post singularity acausal trade.</p>\n<p>I think this consideration is actually quite strong in expectation if you think that suffering focused ethics is common on reflection among humans (or human originating AIs which took over) and less common among other powerful civilizations. Though this depends heavily on the relative probabilities of S-risk from different sources. My guess would be that this consideration out weighs cooperation and encountering technologically immature aliens. I normally think causal trade with technologically mature aliens/AIs from aliens and acaual trade are basically the same.</p>\n<p>I'd guess that this consideration is probably not sufficent to think that reaching the stars is good from a negative utiliarian perspective, but I'm only like 60/40 on this (and very confused overall).</p>\n<p>By 'on reflection' I mean something like 'after the great reflection' or what you get from indirect normativity: <a href=\"https://ordinaryideas.wordpress.com/2012/04/21/indirect-normativity-write-up/\">https://ordinaryideas.wordpress.com/2012/04/21/indirect-normativity-write-up/</a></p>\n<p>My guess would be that negative utilitarians should think that at least <em>they</em> would likely remain negative utilitarian on reflection (or that the residual is unpredictable). So probably negative utilitarians should also think negative utilitarianism is common on reflection?</p>\n", "parentCommentId": "WMZcGLhh4NzYiqu2d", "user": {"username": "ryan-greenblatt"}}, {"_id": "fRKoS3pbj3tChLhaP", "postedAt": "2023-05-15T07:15:43.617Z", "postId": "GgmAeWqXSg8DHMsJe", "htmlBody": "<p>Thanks! I'm confused about the acausal issue as well :) , and it's not my specialty. I agree that acausal trade (if it's possible in practice, which I'm uncertain about) could add a lot of weird dynamics to the mix. If someone was currently almost certain that Earth-originating space colonization was net bad, then this extra variance should make such a person less certain. (But it should also make people less certain who think space colonization is definitely good.) My own probabilities for Earth-originating space colonization being net bad vs good from a negative-utilitarian (NU) perspective are like 65% vs 35% or something, mostly because it's very hard to have much confidence in the sign of almost anything. (I think my own work is less than 65% likely to reduce net suffering rather than increase it.) Since you said your probabilities are like 60% vs 40%, maybe we're almost in agreement? (That said, the main reason I think Earth-originating space colonization might be good is that there may be a decent chance of grabby aliens within our future light cone whom we could prevent from colonizing, and it seems maybe ~50% likely an NU would prefer for human descendants to colonize than for the aliens to do so.)</p>\n<p>My impression (which could be wrong) is that ECL, if it works, can only be a good thing for one's values, but generic acausal trade can cause harm as well as benefit. So I don't think the possibility of future acausal trade is necessarily a reason to favor Earth-originating intelligence (even a fully NU intelligence) from reaching the stars, but I haven't studied this issue in depth.</p>\n<p>I suspect that preserving one's goals across multiple rounds of building smarter successors is extremely hard, especially in a world as chaotic and multipolar as ours, so I think the most likely intelligence to originate from Earth will be pretty weird relative to human values -- some kind of Moloch creature. Even if something like human values does retain control, I expect NUs to represent a small faction. The current popularity of a value system (especially among intelligent young people) seems to me like a good prior for how popular it will be in the future.</p>\n<p>I think people's values are mostly shaped by emotions and intuitions, with rational arguments playing some role but not a determining role. If rational arguments were decisive, I would expect more convergence among intellectuals about morality than we in fact see. I'm mostly NU based on my hard wiring and life experiences, rather than based on abstract reasons. People sometimes become more or less suffering-focused over time due to a combination of social influence, life events, and philosophical reflection, but I don't think philosophy alone could ever be enough to create agreement one way or the other. Many people who are suffering-focused came to that view after experiencing significant life trauma, such as depression or a painful medical condition (and sometimes people stop being NU after their depression goes away). Experiencing such life events could be part of a reflection process, but experiencing other things that would reduce the salience of suffering would also be part of the reflection process, and I don't think there's any obvious attractor here. It seems to me more like causing random changes of values in random directions. The output distribution of values from a reflection process is probably sensitive to the input distribution of values and the choice of parameters regarding what kinds of thinking and life experiences would happen in what ways.</p>\n<p>In any case, I don't think ideal notions of \"values on reflection\" are that relevant to what actually ends up happening on Earth. Even if human values control the future, I assume it will be in a similar way as they control the present, with powerful and often self-interested actors fighting for control, mostly in the economic and political spheres rather than by sophisticated philosophical argumentation. The idea that a world that can't stop nuclear weapons, climate change, AI races, or wars of aggression could somehow agree to undertake and be bound by the results of a Long Reflection seems <em>prima facie</em> absurd to me. :) Philosophy will play some role in the ongoing evolution of values, but so will lots of other random factors. (To the extent that \"Long Reflection\" just means an ideal that a small number of philosophically inclined people try to crudely approximate, it seems reasonable. Indeed, we already have a community of such people.)</p>\n", "parentCommentId": "b5pQnGMXXP22GL7yo", "user": {"username": "Brian_Tomasik"}}, {"_id": "j5YkFRf8sfGmLxnLR", "postedAt": "2023-05-16T01:15:57.309Z", "postId": "GgmAeWqXSg8DHMsJe", "htmlBody": "<p>If you did find an organization that could use more funding that wasn't already receiving funding from major EA grantmakers, you should recommend it apply to the EA Animal Welfare Fund and ACE Movement Grants (and Open Phil?). If it has already, but it was rejected, it may be worth finding out why, in case the grantmakers found it unpromising for reasons you'd agree with. If it does get funding, all the better, and you could still top it up if it has more RFMF or donate elsewhere.</p>\n", "parentCommentId": null, "user": {"username": "MichaelStJules"}}, {"_id": "qmeqooKmzbxG8eakM", "postedAt": "2023-05-16T07:41:30.698Z", "postId": "GgmAeWqXSg8DHMsJe", "htmlBody": "<p>This is only somewhat related but I would be keen to get your thoughts Brian on <a href=\"https://www.youtube.com/watch?v=W-59mwoYm54\">this talk</a> and <a href=\"http://philsci-archive.pitt.edu/19608/\">related paper</a> on positive wild animal welfare? They argue that wild animal welfare isn't necessarily so clear cut to be negative and there are some positive elements as well that we often don't discuss. I'm no expert and you've probably thought about wild animal suffering more than most people so I would be very curious to hear what you think.</p><p>There's a lot in the talk but I found the slides below particularly interesting to think about (timestamp: 30:13) as it implies that even with heavily r-selected species, the deaths and suffering of juveniles may not dominate overall suffering.</p><figure class=\"image image_resized\" style=\"width:77.83%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qmeqooKmzbxG8eakM/outfcski9zzx0hr3zkfq\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qmeqooKmzbxG8eakM/mcf9s7xgsn1vamzfbc1q 180w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qmeqooKmzbxG8eakM/opjbugavak3uybjtggka 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qmeqooKmzbxG8eakM/farmsnf3q6gyjipfe1dr 540w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qmeqooKmzbxG8eakM/mysbuiqccvzncampdw2e 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qmeqooKmzbxG8eakM/relsbb78jcpfcpnfrkmi 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qmeqooKmzbxG8eakM/mbkd45ewlnf0z2jlbvjk 1080w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qmeqooKmzbxG8eakM/pkwkhnul83fzhberd4go 1260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qmeqooKmzbxG8eakM/v6madxywmg2ivcqgl0di 1440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qmeqooKmzbxG8eakM/b6kf1hn6ettcisocccd2 1620w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qmeqooKmzbxG8eakM/szwm8wowtsxmbvzkltqb 1744w\"></figure><figure class=\"image image_resized\" style=\"width:74.98%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qmeqooKmzbxG8eakM/rfm8diixlxn3nrgzqzyb\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qmeqooKmzbxG8eakM/aqd2jefhgxz3hbmtxibx 180w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qmeqooKmzbxG8eakM/cvdo0emo2lodni33n5qy 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qmeqooKmzbxG8eakM/q8ztoy4pv1l3bwiuak15 540w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qmeqooKmzbxG8eakM/zhefb89obtvcywhuptms 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qmeqooKmzbxG8eakM/bnams1eu482om0yxlnem 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qmeqooKmzbxG8eakM/htotazg52micgwth4slt 1080w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qmeqooKmzbxG8eakM/iogh1uyvk7y2ghswi1o7 1260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qmeqooKmzbxG8eakM/mw1n6thoibtfz8tu8j4h 1440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qmeqooKmzbxG8eakM/rorr5xx54gxky1ucx1bn 1620w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qmeqooKmzbxG8eakM/hn1jeuet8gfmbmifli4g 1752w\"></figure>", "parentCommentId": null, "user": {"username": "JamesOz"}}, {"_id": "e2ofrvXYC7DyAye2o", "postedAt": "2023-05-16T10:27:19.924Z", "postId": "GgmAeWqXSg8DHMsJe", "htmlBody": "<p>Your question is fairly relevant to the discussion because if I thought there was net positive value in the lives of wild animals, then I would have a lot fewer concerns about non-welfare-reform animal charities.</p>\n<p>I've had it on my todo list to check out that video and paper, but I probably won't get to it any time soon, so for now I'll just reply to the slides you asked about. :)</p>\n<p>Personally I would not want to live even as the two surviving adult fish, because they probably experience a number of moments of extreme suffering, at least during death if not earlier. They may be fearful of predators, they face unpleasant temperatures or other bad environmental conditions without being able to control them the way humans do with air conditioning and heating, they may face long periods of low food, there might be intraspecific aggression and sexual harassment (I don't know if those behaviors apply to Atlantic cod, but they are common in some fish species), and there would be many other hardships. Most of these moments of suffering probably wouldn't feel that bad, but a few of them might be unbearably awful.</p>\n<p>I said that I \"personally\" wouldn't want to live as one of these surviving fish, but you might say that the real question is whether <em>they</em> would want to have these lives rather than not existing. We can't ask fish that question, but if we imagine humans having similar lives as these fish, we could ask such humans that question. Maybe many of those humans would say during many moments of their lives that they were on balance glad to exist. However, I suspect that during some moments, such as the peak pain of dying, they would often change their minds and wish they hadn't existed. Therefore, there's no single individual whom we can ask whether his/her life was net positive; there are multiple \"individuals\" within the animal's life, some of whom are glad to exist and some of whom are horrified to exist. How we weigh up these conflicting opinions is ultimately a judgment call, and no amount of further empirical data on wild-animal welfare will resolve it. I take a suffering-focused approach to this dilemma and say that it's not acceptable for the happier moments of the animal's life to impose unbearable suffering on some other moments of the animal's life. So for any animal that has moments of unmitigated, unbearable agony (as most animals do, if only when dying), its life is net negative in my view.</p>\n<p>But most people don't take this suffering-focused approach. Many people think enough happy moments of life can outweigh something as awful as being eaten alive. So next I'll discuss the specific numbers in those slides.</p>\n<p>If a baby fish is only enduring 10 seconds of agony when dying, as the first slide suggests, then it's presumably dying from predation (or maybe a severe physical injury like being crushed or something). The next slide suggests that maybe the pain of predation is 100/100, compared against a presumed positive welfare of 0.1/100 for ordinary life. So getting eaten alive is only 1000 times worse than the goodness of a typical moment of life. That might seem plausible if we only glance at the numbers, but it's not at all plausible if we actually think about what it implies. Imagine that you endure getting eaten alive for 1 minute. These numbers say that a mere 1000 minutes of ordinary life could compensate for that. 1000 minutes is 16.7 hours, slightly more than the amount of time a typical person is awake in a day. So this ratio says that even if you spend a minute <em>every day</em> experiencing what it's like to be eaten alive, then your life can still be welfare-neutral. I wonder if anyone would actually sign up for that. One of the least suffering-averse trade ratios I've heard someone endorse was that he'd be willing to experience being eaten alive for an extra week of life (IIRC; that conversation was a long time ago). (I guess there are also a few people who say even more extreme things like \"I'd rather be alive and tortured forever than not exist\", though I expect they'd change their minds pretty quickly when the torture started.)</p>\n<p>One possible argument is that it's illegitimate to rely on our human intuitions about this tradeoff, because r-strategists may have evolved different pain-pleasure trade ratios based on the situation they face. For example, almost all fish babies will die by default, so if there's an opportunity to take a dangerous risk in order to gain some slight advantage, they should probably take it, since they have almost no chance of winning otherwise. Therefore, maybe they need to be less averse to suffering (or at least less <em>afraid</em> of suffering) than we would be. This might be the case, but it's a very theoretical argument, so I'm wary of putting too much stock in it. Of course, any estimate we have of how much suffering and pleasure exist in nature will be very speculative, so if I were a classical utilitarian who thought a minute of extreme suffering might be outweighable by a few days, weeks, or months of ordinary life in the wild, then I would have some uncertainty about the net hedonic balance of nature. But in my own case, I don't think it's ok to force extreme suffering on one for the pleasure of another -- much less imposing extreme suffering on 1,999,998 for the pleasure of 2. (If we assume a 10% hatch rate and a 10% chance of sentience, then this comparison is actually 19,999.98 vs 2. And if we look at individual organism-moments of experience, the 2 surviving fish have a lot of organism-moments.)</p>\n<p>As I mentioned, the slides seem to be assuming deaths by predation given how short the duration of suffering is. Death by almost anything else would probably take hours, days, weeks, etc, although the intensity of pain during that time would usually be a lot lower than the intensity of pain during predation. <a href=\"https://www.sciencedaily.com/releases/2014/06/140625132449.htm\">This article</a> says:</p>\n<blockquote>\n<p>A new study has uncovered the reason why 90 percent of fish larvae are biologically doomed to die mere days after hatching. This understanding of the mechanism that kills off the majority of the world's fish larvae may help find a solution to the looming fish crisis in the world. The research suggests that \"hydrodynamic starvation,\" or the physical inability to feed due to environmental incompatibility, is the reason so many fish larvae perish.</p>\n</blockquote>\n<p>So maybe rather than 10 seconds, the period of pain while dying should be measured in hours or days? 1 day = 86,400 seconds. Of course, the badness of most of those seconds would be a lot less than 100/100.</p>\n<p>See also: \"<a href=\"https://reducing-suffering.org/net-suffering-nature-reply-michael-plant/\">Is There More Suffering Than Happiness in Nature? A Reply to Michael Plant</a>\".</p>\n", "parentCommentId": "qmeqooKmzbxG8eakM", "user": {"username": "Brian_Tomasik"}}, {"_id": "Wu8sccp368Y5wsjLm", "postedAt": "2023-05-16T23:11:21.045Z", "postId": "GgmAeWqXSg8DHMsJe", "htmlBody": "<p>I think it's a fair topic to bring up in general, as long as the questioner isn't seeking more than their \"fair share\" (as it were) of control over global allocation.</p><p>I think it's important that overall funding levels reflect the collective wisdom of all donors, rather than larger donors \"funding last\" and setting global funding levels to their own individual judgment. Stated differently, suppose Big Fund thinks that funding should be allocated 50:50 between strategies A and B. But 80% of small/medium independent donors in the community think strategy A is better and donate to it exclusively. To me, that's evidence that 50:50 isn't the correct overall allocation, and it would be suboptimal for Big Fund to use its economic firepower to totally \"correct\" what the smaller donors have done. (That is not to say I think Big Fund needs to totally disregard the effects of other funders and allocate 50:50 in this circumstance. Nor am I confident in any specific mathematical construct, such as quadratic funding, to set the global funding level in this hypothetical.)</p><p>So in my example, Big Fund needs to take steps to ensure that its views are not <strong>over</strong>weighted in the global allocation of funds. It should then assure independent donors (those not giving through Big Fund) that they are exerting an appropriate amount of influence on global allocation (i.e., that they are not being practically forced to delegate their decisionmaking to Big Fund). Not doing that may suppress independent giving, as independent donors who feel they are being 100% funged by Big Fund will give based on their perception of the cost-effectiveness of Big Fund's entire portfolio without weighing the cost-effectiveness of their preferred organization.</p><p>All that is to say that your post makes me think that communication on this topic to independent donors could be improved.</p>", "parentCommentId": "itCEYLHW7J23REZ5M", "user": {"username": "Jason"}}, {"_id": "SkDszZGb7ZtfkANBk", "postedAt": "2023-05-17T07:43:14.581Z", "postId": "GgmAeWqXSg8DHMsJe", "htmlBody": "<p>Makes sense. :) There are at least two different reasons why one might discourage taking more than one's fair share:</p>\n<ol>\n<li>Epistemic: As you said, there may be \"collective wisdom\" that an individual donor is missing.</li>\n<li>Game theoretic: If multiple donors who have different values compete in a game of chicken, this could be worse for all of them than if they can agree to cooperate.</li>\n</ol>\n<p>Point #1 may be a reason to not try to outcompete others purely for its own sake. However, reason #2 depends on whether other donors are in fact playing chicken and whether it's feasible to achieve cooperation. If you genuinely have different values from other donors, you should try to do the best you can by your own values, which could include taking advantage of opportunities to donate less than your \"fair\" share.</p>\n<p>It's easy to feel warm fuzzies toward being \"fair\", but we can imagine scenarios where those fuzzies don't apply. For example, imagine that the USA and Russia are both contributing development aid to an international organization, and with any funds left over, Russia will buy attack drones from Iran. If there's an opportunity to get Russia to contribute more than its \"fair share\" to the development aid, leaving less money left over for drones, the USA should try to do that.</p>\n<p>Maybe being the kind of person who would never even consider aiming to gain some advantage for one's own values is more effective at making cooperation actually happen, but being such a person could also lead to getting exploited. It seems non-obvious how exactly to best ensure that each party gives its fair share, especially when there are so many different possible donors to keep track of, and we have no way of knowing how much each entity would have contributed on its own.</p>\n", "parentCommentId": "Wu8sccp368Y5wsjLm", "user": {"username": "Brian_Tomasik"}}, {"_id": "EnQ8rPD3LG2zqot4H", "postedAt": "2023-05-18T04:21:12.231Z", "postId": "GgmAeWqXSg8DHMsJe", "htmlBody": "<p>It seems as though I'm more optimistic about a 'simple' picture of reflection and enlightenment.</p>\n<p>When providing the 60/40 numbers, I was imagining something like 'probability that it's ex-ante good, as opposed to ex-post good'. This distinction is pretty unclear and I certainly didn't make this clear in my comment.</p>\n", "parentCommentId": "fRKoS3pbj3tChLhaP", "user": {"username": "ryan-greenblatt"}}, {"_id": "LPxwvaCHupNcKGEx5", "postedAt": "2023-05-18T11:00:01.414Z", "postId": "GgmAeWqXSg8DHMsJe", "htmlBody": "<p>Makes sense about ex ante vs ex post. :)</p>\n<p>Are you more optimistic that various different kinds of reflection would tend to yield a fair amount of convergence? Or that our descendants will in fact undertake reflection on human values to a significant degree?</p>\n", "parentCommentId": "EnQ8rPD3LG2zqot4H", "user": {"username": "Brian_Tomasik"}}, {"_id": "bEpxB9S4KaBDfviAi", "postedAt": "2023-05-18T18:52:28.035Z", "postId": "GgmAeWqXSg8DHMsJe", "htmlBody": "<p>More optimistic on both.</p>\n", "parentCommentId": "LPxwvaCHupNcKGEx5", "user": {"username": "ryan-greenblatt"}}]