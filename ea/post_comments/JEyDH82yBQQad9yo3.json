[{"_id": "Kn54PEmfLjqRRnRuW", "postedAt": "2015-06-12T19:41:49.017Z", "postId": "JEyDH82yBQQad9yo3", "htmlBody": "<p>This piece is a simplified version of an academic article Joao Fabiano and I are writing on the future of evolutionary forces, similar in spirit to <a href=\"http://www.nickbostrom.com/fut/evolution.html\">this one</a>. It will also be the basis of one of the early chapters of my book Altruism: past, present, propagation. We welcome criticism and suggestions of other forces/constraints/conventions that may be operating to interfere or accelerate the long term evolution of coalitions, cooperation, and global altruistic coordination.  </p>\n", "parentCommentId": null, "user": {"username": "Diego_Caleiro"}}, {"_id": "fFauiDRExBGrxdRL8", "postedAt": "2015-06-14T15:34:08.759Z", "postId": "JEyDH82yBQQad9yo3", "htmlBody": "<blockquote>\n<p>freewheeling evolution will not lead to satisfactory levels of global human cooperation in time to prevent severe risks . Nor it will lead to the preservation of human values in the long run ; humans, human values, and human cooperation are in no way the end-point of evolutionary processes. </p>\n</blockquote>\n<p>Excellent point; this is something I've considered many times myself.  Humans post-1850 are the first species in the history of the world that has been able to reflect on the evolutionary processes that brought it here.  As such, we are the first species with an opportunity to play an intentional, direct role in affecting those processes.  Evolution doesn't select for morality per se, or values per se, but we will potentially have the capability of incorporating such considerations into the evolutionary process.  As we continue to grow our ability to genetically modify humans, however, there is a possibility that we can intervene on a biological basis to improve the morality of the human species.  It sounds very sci-fi, but also very realistic.</p>\n", "parentCommentId": null, "user": {"username": "zackrobinson"}}, {"_id": "8qXW68d6L9C6vrknX", "postedAt": "2015-06-15T04:46:55.932Z", "postId": "JEyDH82yBQQad9yo3", "htmlBody": "<p>This essay seems heavier with jargon than most posts here. I'm guessing that's in part because it's primarily written for and from an academic perspective. This made it difficult for me to understand all parts of it at first. I'm not sure how much of a problem that might be, and Diego might consider changes how he words his ideas in his forthcoming book, depending on who it's intended for.</p>\n<p>That stated, I don't mean it's poorly written. I learned some from it. It also covers an abstract field without enough research already done yet, so it must be difficult to write about at all.</p>\n", "parentCommentId": null, "user": {"username": "Evan_Gaensbauer"}}, {"_id": "P9MuhB833CLD5ePyz", "postedAt": "2015-06-16T17:44:00.043Z", "postId": "JEyDH82yBQQad9yo3", "htmlBody": "<p>&quot;From single-celled to pluricellular to multicellular organisms or from hunter-gatherers to the EU, the history of evolutionary forces that resulted in human society is a history where cooperation has emerged at increasingly large scales.&quot;</p>\n<p>I often hear claims like this, but I'm not sure these things are really all that analogous beyond the superficial 'smaller -&gt; bigger' aspect. For instance, there is no intentionality with the single-celled organisms, only chance and natural selection, whereas there seems to be intentionality in the latter example.</p>\n<p>While I tend to agree that this is the overall trend, there are numerous counterexamples, such as empires decolonizing, the cession of individual rights by Leviathans, and perhaps even entropy on a physical level. So the deck may be even more stacked against us than we think.</p>\n", "parentCommentId": null, "user": {"username": "zdgroff"}}, {"_id": "rWDp6zXWASeZTurJG", "postedAt": "2015-06-17T13:06:12.005Z", "postId": "JEyDH82yBQQad9yo3", "htmlBody": "<blockquote>\n<p>Each individual could be packed with an emergency survival strategy. Just like or reptilian brain kicks in when we sense danger, our in-group favouritism and specificity would kick in when we sense existential catastrophe. Like an ant colony that produces more queens every time it senses danger. Society would become some metamorphic superorganism with local fluctuations that would rapidly turn into divergent groups when existential risk increases, only to merge again whenever the risk lowers.</p>\n</blockquote>\n<p>Wait, I thought the entire point of enforcing global altruism was to guard against existential risks?  Maybe depending on the nature of the risk we either do or don't want global altruism?</p>\n<p>Anyway, I had a hard time understanding much of this post... simpler language and more concrete examples might have been helpful.  I was reminded of <a href=\"http://chronicle.com/article/Why-Academics-Writing-Stinks/148989/\">this recent article</a> by Steven Pinker on problems with academic writing in general.  I recently took the time to <a href=\"http://pastebin.com/XksZSWxh\">gather some thoughts</a> on clear writing if you're interested.  Pinker also recently <a href=\"http://smile.amazon.com/Sense-Style-Thinking-Persons-Writing/dp/0670025852/\">wrote a book</a> about how to write well which might be good.  I suspect that writing clearly and simply could be an easy way to get noticed in academia where most writing is terrible.</p>\n", "parentCommentId": null, "user": {"username": "John_Maxwell_IV"}}]