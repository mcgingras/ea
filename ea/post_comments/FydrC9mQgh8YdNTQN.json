[{"_id": "HGiqABxMC59p4H32x", "postedAt": "2022-12-01T09:03:51.037Z", "postId": "FydrC9mQgh8YdNTQN", "htmlBody": "<p>Trying to \"do as the virtuous agent would do\" (or maybe \"do things for the sake of being a good person\") seems to be a &nbsp;really common problem for people.</p><p>Ruthless consequentialist reasoning totally short-circuits this, which I think is a large part of its appeal. You can be sitting around in this paralyzed fog, agonizing over whether you're \"really\" good or merely trying to fake being good for subconscious selfish reasons, feeling guilty for not being eudaimonic enough -- and then somebody comes along and says \"stop worrying and get up and buy some bednets\", and you're free.</p><p>I'm not philosophically sophisticated enough to have views on metaethics, but it does seem sometimes that the main value of ethical theories is therapeutic, so different contradictory ethical theories could be best for different people and at different times of life.</p>", "parentCommentId": null, "user": {"username": "anonymous6"}}, {"_id": "ymJ7o8HvA538bdwkT", "postedAt": "2022-12-01T10:32:20.717Z", "postId": "FydrC9mQgh8YdNTQN", "htmlBody": "<p>I think there's something to be said for the value of self-interest in your thought experiment about the person saving their partner over a stranger. A broader understanding of self-interest is one that reflects a rational and emotionally  aligned decision to serve oneself through serving another.  Some people are important in one's life, and instrumental reasoning applies to altruistic consequences of your actions toward them. Through your actions to benefit them, you also benefit yourself.</p>\n<p>With respect to love, trust, and especially in romance, where loyalty is important, self-interest is prevalent. A person falls \"out of love\" when that loyalty is betrayed, typically. Work against someone's self-interest enough, and their emotional feelings and attachment to you will fade.</p>\n<p>All to say that consequentialism plays a role in serving self-interest as well as the interests of others. With regard to the dissonance it creates, in the case of manifesting virtues toward those who we depend on to manifest those virtues in return, the dissonance eases because those people serve our interests as we serve their interests.</p>\n", "parentCommentId": null, "user": {"username": "Noah Scales"}}, {"_id": "9AJGvahnwDaTnvaqv", "postedAt": "2022-12-01T12:01:31.245Z", "postId": "FydrC9mQgh8YdNTQN", "htmlBody": "<p>I'm quite skeptical of post-hoc articles with titles like 'X was no surprise', they're usually full of hindsight bias. Like, if it was no surprise, did you predict it coming?&nbsp;</p><p>Although there's almost nothing about SBF here, is this part 1 of a series?</p>", "parentCommentId": null, "user": {"username": "Matt g"}}, {"_id": "9ntnHYdAbRboZJgdM", "postedAt": "2022-12-01T13:18:36.040Z", "postId": "FydrC9mQgh8YdNTQN", "htmlBody": "<p>I\u2019m confused about how you\u2019re dividing up the three ethical paradigms. I know you said your categories were excessively simplistic. But I\u2019m not sure they even roughly approximate my background knowledge of the three systems, and they don\u2019t seem like places you\u2019d want to draw the boundaries in any case.</p>\n<p>For example, my reading of Kant, a major deontological thinker, is that one identifies a maxim by asking about the effect on society if that maxim were universalized. That seems to be looking at an action at time T1, and evaluating the effects at times after T1 should that action be considered morally permissible and therefore repeated. That doesn\u2019t seem to be a process of looking \u201ccausally upstream\u201d of the act.</p>\n<p>When I\u2019ve seen references to virtue ethics, they usually seem to involve arbitrating the morality of the act via some sort of organic discussion within one\u2019s moral community. I don\u2019t think most virtue ethicists would think that if we could hook somebody up to a brain scrambler that changed their psychological state to something more or less tasteful immediately before the act, that this could somehow make the act more or less moral. I don\u2019t buy that virtue ethicists judge actions based on how you were feeling right before you did it.</p>\n<p>And of course, we do have rule utilitarianism, which doesn\u2019t judge individual actions by their downstream consequences, but rules for actions.</p>\n<p>Honestly, I\u2019ve never quite understood the idea that consequentialism, deontology, and virtue ethics are carving morality at the joints. That\u2019s a strong assertion to make, and it seems like you have to bend these moral traditions to the categorization scheme. I haven\u2019t seen a natural categorization scheme that fits them like a glove and yet beating distinguishes one from the other.</p>\n", "parentCommentId": null, "user": {"username": "AllAmericanBreakfast"}}, {"_id": "4NNmeHpstEse4mDBv", "postedAt": "2022-12-01T14:44:01.749Z", "postId": "FydrC9mQgh8YdNTQN", "htmlBody": "<p>You're right that post-hoc articles are usually full of hindsight bias, making them a lot less valuable. <strong>That's why I tried </strong><i><strong>not </strong></i><strong>to make the article about SBF too much </strong>(no this is not part 1 of a series). I laid that out from the beginning:</p><blockquote><p>Please don't read too much into the armchair psychological diagnosis from a complete amateur \u2013 that isn't the point.&nbsp;</p></blockquote><p>If you want a prediction I give one right after this:</p><blockquote><p>The point, to lay my cards on the table, is this: virtue ethicists would not be surprised if many EAs suffer (in varying degrees) from \"moral schizophrenia\"</p></blockquote><p>I reiterate this when I say \"I fear it is widespread in this community\" where \"it\" is a certain coldness toward ethical choices (and other choices that would normally be full of affect).&nbsp;</p><p>SBF is topical and I thought this was a good opportunity to highlight this lesson about not engaging in excessive reasoning. But I agree my title isn't great. Suggestions?</p>", "parentCommentId": "9AJGvahnwDaTnvaqv", "user": {"username": "c.trout"}}, {"_id": "kqKkniSXcmzrCXAwh", "postedAt": "2022-12-01T15:00:21.347Z", "postId": "FydrC9mQgh8YdNTQN", "htmlBody": "<p>So I feel like your comment misses the point I was trying to make there (which means I didn't make it well enough \u2013 my apologies!) The point is not that consequentialists can't justify saving their spouse, as if they don't have the theoretical resources to do so. They absolutely can, as you demonstrate. The point is that in the heat of the moment, when actually taking action, <i>you shouldn't be engaging in any consequentialist reasoning </i>in order to decide what to do or motivate yourself to do it.<br><br>Or maybe you did understand all this, and you're just describing how consequentialism self-effaces? Because it recommends we adopt a certain amount of self-care/self-interest in our character and then operate on that (among other things)?</p>", "parentCommentId": "ymJ7o8HvA538bdwkT", "user": {"username": "c.trout"}}, {"_id": "G7k9vswqDddAPicez", "postedAt": "2022-12-01T15:44:49.693Z", "postId": "FydrC9mQgh8YdNTQN", "htmlBody": "<p>You're absolutely right to criticize that section! It's just not good. I will add more warning labels/caveats to it ASAP. This is always the pitfall of doing YAABINE.</p><p>That said, I do think the three families <i>can </i>be divided up based on <i>what they take to be explanatorily fundamental. </i>That's what I was trying to do (even though I probably failed). The slogan goes like this: VE is \"all about\" what kind of person we should be, DE is \"all about\" what duties we have, and Consequentialism is \"all about\" the consequences of our actions. Character, duty, consequences \u2013 three key moral terms. (And natural joints? Who knows). Theories from each family will have something to say about all three terms, but each family of theory takes a different term to be explanatorily fundamental.</p><p>So you're absolutely right that, in their judgments of particular cases, they can all appeal to facts up and down the causal stream (e.g. there is no reason consequentialists can't refer to promises made earlier when trying to determine the consequences of an action). Maybe another way to put this: the decision procedures proposed by the various theories take all sorts of facts as inputs. You give a number of examples of this. But ultimately, what sorts of facts <i>unify </i>those various judgments under a <i>common explanation </i>according to each family of theory? That's what I was trying to point at. I thought one way to divvy those explanatorily fundamental facts was by there position along the causal stream but maybe I was wrong. I'm really not sure!</p><p>Unrelated reply:</p><blockquote><p>I don\u2019t buy that virtue ethicists judge actions based on how you were feeling right before you did it.</p></blockquote><p>I completely agree that <i>actual virtue ethicists </i>would not do so, but the <i>theory </i>many of them are implicitly attached to (\"do as the virtuous agent would do, for all the reasons the virtuous agent would do it\") <i>does </i>seem to judge people based on how you were feeling/what you were thinking right before you did it.</p>", "parentCommentId": "9ntnHYdAbRboZJgdM", "user": {"username": "c.trout"}}, {"_id": "NZqtgYYcBkRmNJYfZ", "postedAt": "2022-12-01T17:50:22.360Z", "postId": "FydrC9mQgh8YdNTQN", "htmlBody": "<p>Thanks for clarifying!</p>\n<p>The big distinction I think needs to be made is between offering a guide to extant consensus on moral paradigms, and proposing your own view on how moral paradigms ought to be divided up. It might not really be possible to give an appropriate summary of moral paradigms in the space you\u2019ve allotted to yourself, just as I wouldn\u2019t want to try and sum up, say, \u201cindigenous vs Western environmentalist paradigms\u201d in the space of a couple paragraphs.</p>\n", "parentCommentId": "G7k9vswqDddAPicez", "user": {"username": "AllAmericanBreakfast"}}, {"_id": "b2GFg8mTnarL5judm", "postedAt": "2022-12-01T17:53:19.840Z", "postId": "FydrC9mQgh8YdNTQN", "htmlBody": "<p>The Mayo Clinic says of schizophrenia:</p>\n<p>\u201c Schizophrenia is characterized by thoughts or experiences that seem out of touch with reality, disorganized speech or behavior, and decreased participation in daily activities. Difficulty with concentration and memory may also be present.\u201d</p>\n<p>I don\u2019t see the analogy between schizophrenia and \u201ca certain coldness toward ethical choices,\u201d and if it were me, I\u2019d avoid using mental health problems as analogies, unless the analogy is exact.</p>\n", "parentCommentId": "4NNmeHpstEse4mDBv", "user": {"username": "AllAmericanBreakfast"}}, {"_id": "ziWqp8wr2DEDRtCLu", "postedAt": "2022-12-01T18:02:32.881Z", "postId": "FydrC9mQgh8YdNTQN", "htmlBody": "<p>Ok, I didn't pick up that was where the prediction was in the article. I think of (good) predictions as having a clear, falsifiable hypothesis. &nbsp;Whereas this seems to be predicting ... that virtue ethicists continue believing whatever they already believed about EAs?</p><p>The reason I downvoted this article is the use of the term 'moral schizophrenia'. Even if it's not your term originally, I think using it is:</p><p>a) Super unclear as a descriptive term. I understand in mainstream culture it's seen as a kind of Jeckyll/Hyde split personality thing, so maybe it's meant to describe that. But I'm pretty sure that's an inaccurate description &nbsp;of actual schizophrenia.&nbsp;</p><p>b) Harmful to those who have schizophrenia when used in this kind of negative fashion. Especially as &nbsp;it seems to be propagating the Jeckyll/Hyde false belief about the condition.</p><p>Lastly, the 'moral schizophrenia'/coldness described here seems much more like a straw-man of EAs than an accurate description of an EAs I've met. The EAs I know IRL are warm and generous towards their families and friends, and don't seem to associate being that way as at all incompatible with EA kind of reasoning. Sure, online and even irl discussions can seem dry, but it <a href=\"https://mindingourway.com/on-caring/\">would be hard to have any discussions if we had to express, with our emotions, the magnitude of what was being discussed.</a></p>", "parentCommentId": "4NNmeHpstEse4mDBv", "user": {"username": "Matt g"}}, {"_id": "jxo4myWMt7NkxQnD5", "postedAt": "2022-12-01T18:19:12.225Z", "postId": "FydrC9mQgh8YdNTQN", "htmlBody": "<p>The term is certainly outdated and an inaccurate analogy, hence the scare quotes and the caveat I put in the heading of the same name. It's the term that Stocker uses though and I haven't seen another one (but maybe I missed it). The description \"tendency to suffer cognitive dissonance in moral thinking\" is much more accurate but not exactly succinct enough to make for a good name. I'm open &nbsp;to suggestions!</p>", "parentCommentId": "b2GFg8mTnarL5judm", "user": {"username": "c.trout"}}, {"_id": "asgTt48v5e9R68GNN", "postedAt": "2022-12-01T19:21:17.776Z", "postId": "FydrC9mQgh8YdNTQN", "htmlBody": "<p><u>Regarding the term \"moral schizophrenia\":</u><br>As I said to AllAmericanBreakfast, I wholeheartedly agree the term is outdated and inaccurate! Hence the scare quotes and the caveat I put in the heading of the same name. But obviously I underestimated how bad the term was since everyone is telling to change it. I'm open to suggestions! EDIT: I replaced it with \"internal moral disharmony.\" Kind of a mouthful but good enough for a blog post.&nbsp;</p><p><u>Regarding predictions:</u><br>You're right, that wasn't a very exact prediction (mostly because internal moral disharmony is going to be hard to measure). Here is a falsifiable claim that I stand by and that, if true, is evidence of internal moral disharmony:</p><blockquote><p>I claim that one's level of engagement with the LW/EA rationalist community can weakly predict the degree to which one adopts a maximizer's mindset when confronted with moral/normative scenarios in life, the degree to which one suffers cognitive dissonance in such scenarios, and the degree to which one expresses positive affective attachment to one's decision (or the object at the center of their decision) in such scenarios.</p><p>More specifically I predict that, above a certain threshold of engagement with the community,&nbsp;increased engagement with the LW/EA community correlates with an increase in the maximizer's mindset, increase in cognitive dissonance, and decrease in positive affective attachment in the aforementioned scenarios.</p></blockquote><p>The hypothesis for why I think this correlation exists is mostly at the end of <a href=\"https://forum.effectivealtruism.org/posts/FydrC9mQgh8YdNTQN/sbf-s-comments-on-ethics-are-no-surprise-to-virtue-ethicists#Internal_Moral_Disharmony\">here </a>and <a href=\"https://forum.effectivealtruism.org/posts/FydrC9mQgh8YdNTQN/sbf-s-comments-on-ethics-are-no-surprise-to-virtue-ethicists#___but_especially__casual__consequentialists_\">here.</a></p><p>But more generally, must a criticism of/concern for the EA community come in the form of a prediction? I'm really just trying to point out a hazard for those who go in for Rationalism/Consequentialism. If everyone has avoided it, that's great! But there seems to be evidence that some have failed to avoid it, and that we might want to take further precautions. SBF was very much one of EA's own: his comments therefore merit some EA introspection. I'm just throwing in my two cents.</p><p><u>Regarding actual EAs:</u><br>I would be happy to learn few EAs actually have thoughts too many! But I do know it's a thing, that some have suffered it (personally I've struggled with it at times, and it's literally in <a href=\"https://www.gutenberg.org/cache/epub/10378/pg10378-images.html#link2HCH0005\">Mill's autobiography</a>). More generally, the ills of adopting a maximizer's mindset too often are well documented (see references in footnotes). I thought it was in the community's interest to raise awareness about it. I'm certainly not trying to demonize anyone: if someone in this community does suffer it, my first suspect would be <i>the culture surrounding/theory of Consequentialism</i>,<i> </i>not some particular weakness on the individual's part.</p><p><u>Regarding dry discussion on topics of incredible magnitude:</u><br>That's fair. I'm not saying being dry and calculating is always wrong. I'm just saying one should be careful about getting too comfortable with that mindset lest one start slipping into it when one shouldn't. That seems like something rationalists need to be especially mindful of.</p>", "parentCommentId": "ziWqp8wr2DEDRtCLu", "user": {"username": "c.trout"}}, {"_id": "uZJyzPv6QJskscyGg", "postedAt": "2022-12-01T20:38:32.367Z", "postId": "FydrC9mQgh8YdNTQN", "htmlBody": "<p>The term I'd probably use is hypocrisy. Usually, we say that hypocrisy is when one's behaviors don't match one's moral standards. But it can also take on other meanings. The film The Big Short has <a href=\"https://www.youtube.com/watch?v=mwdo17GT6sg\">a great scene</a> in which one hypocrite, whose behavior doesn't match her stated moral standards, accuses FrontPoint partners of being hypocrites, because their true motivations (making money by convincing her to rate the mortgage bonds they are shorting appropriately) don't match their stated ethical rationales (combating fraud).</p><p>On Wikipedia, I also found definitions from David Runciman and Michael Gerson showing that hypocrisy can go beyond a behavior/ethical standards mismatch:</p><blockquote><p>According to British political philosopher <a href=\"https://en.wikipedia.org/wiki/David_Runciman\">David Runciman</a>, \"Other kinds of hypocritical deception include claims to knowledge that one lacks, claims to a consistency that one cannot sustain, claims to a loyalty that one does not possess, claims to an identity that one does not hold\".<a href=\"https://en.wikipedia.org/wiki/Hypocrisy#cite_note-2\"><sup>[2]</sup></a> American political journalist <a href=\"https://en.wikipedia.org/wiki/Michael_Gerson\">Michael Gerson</a> says that <a href=\"https://en.wikipedia.org/wiki/Political_hypocrisy\">political hypocrisy</a> is \"the conscious use of a mask to fool the public and gain political benefit\".<a href=\"https://en.wikipedia.org/wiki/Hypocrisy#cite_note-Gerson_Trump-3\"><sup>[3]</sup></a></p></blockquote><p>I think \"motivational hypocrisy\" might be a more clear term than \"moral schizophrenia\" for indicating a motives/ethical rationale mismatch.</p>", "parentCommentId": "jxo4myWMt7NkxQnD5", "user": {"username": "AllAmericanBreakfast"}}, {"_id": "pEHCfKiAHwKKSiQwc", "postedAt": "2022-12-01T21:25:31.003Z", "postId": "FydrC9mQgh8YdNTQN", "htmlBody": "<p>Well, I think my mistake was to use the word \"consequentialism\" as if referring to the ethical theory. All I mean by consequentialism is thinking in terms of consequences, and having feelings about them. So, drawn by feelings to save one's spouse, that's very different than calculating the altruistic ideal of maximum benefit through the consequences of one's actions.</p>\n<p>I'm not sure that concern about conscious effort toward thinking or overthinking is really moral schizophrenia. If you mean it's preferable to engage one's feelings or acting through instinct in ways that you identify as demonstrating character traits, well, I get it, but it's ... just about how the conscious mind should or should not work, or how the unconscious (system 1) should or should not work, and those are tricky things to navigate in the first place.  I would settle for just doing the right thing, as I see it, whether that reflects an ethical system or not, or happens with sureness and swiftness or not, not because it shows virtue, but because, that means I didn't freeze up when I was supposed to be a hero.</p>\n<p>People in tense situations freeze up, or talk to themselves, or think thoughts that feel disociated, and labeling that is less helpful than simply noting whether they were able to react in time to prevent a disaster, ie, saving someone's life. If they could, kudos. If they couldn't, how to help them do better next time?  Sometimes being heroic or brave or loyal or whatever takes practice and some reassurance rather than judgment. Not all the time, though.</p>\n", "parentCommentId": "kqKkniSXcmzrCXAwh", "user": {"username": "Noah Scales"}}, {"_id": "9jYdfQLtcYTBfLD4Q", "postedAt": "2022-12-01T21:33:45.412Z", "postId": "FydrC9mQgh8YdNTQN", "htmlBody": "<p>Thanks for the suggestion. I ended up going with \"internal moral disharmony\" since it's innocuous and accurate enough. I think \"hypocrisy\" is too strong and too narrow: it's a species of internal moral disharmony (closely related to the \"extreme case\" in Stocker's terms), one which seems to imply no feelings of remorse or frustration with oneself regarding the disharmony. I wanted to focus on the more \"moderate case\" in which the disharmony is not too strong, one feels a cognitive dissonance, and one attempts to resolve the disharmony so as <i>not </i>to be a hypocrite.</p>", "parentCommentId": "uZJyzPv6QJskscyGg", "user": {"username": "c.trout"}}, {"_id": "zaPY8CPpqSpebJMvW", "postedAt": "2022-12-01T21:38:23.819Z", "postId": "FydrC9mQgh8YdNTQN", "htmlBody": "<p>Based on this comment, I think I understand your original point better. In most situations, a conscious chain of ethical reasoning held in the mind is not what should be motivating our actions from moment to moment. That would be crazy. I don\u2019t need to consider the ethics of whether to take one more sip of my cup of tea.</p>\n<p>But I think the way we resolve this is a common sense and practical form of consequentialism: a directive to apply moral thought in a manner  that will have the most good consequences.</p>\n<p>One way that might look is outsourcing our charity evaluations to specialists. I don\u2019t have to decide if bednets or direct donations is better: GiveWell does it for me with their wonderful spreadsheets.</p>\n<p>And I don\u2019t have to consider every moment whether deontology or consequentialism is better: the EA movement and my identity as an EA does a lot of that work for me. It also licenses me to defer to habit almost 100% of the time, and invites applying modest limits to my obligation to give of my resources - time, money, and by extension thought.</p>\n<p>So I think EA is already doing a pretty darn good job of limiting our need to think about ethics all the time. It\u2019s just that when people do EA stuff, that\u2019s what they think about. My personal EA involvement is only a tiny fraction of my waking hours, but if you thought of my EA posting as 100% of who I am, it would certainly look like I\u2019m obsessed.</p>\n", "parentCommentId": "kqKkniSXcmzrCXAwh", "user": {"username": "AllAmericanBreakfast"}}, {"_id": "XqPx46oqy3AmBaMHy", "postedAt": "2022-12-01T22:17:08.124Z", "postId": "FydrC9mQgh8YdNTQN", "htmlBody": "<blockquote><p>I think \"hypocrisy\" is too strong and too narrow</p></blockquote><p>Fwiw I consider \"hypocrisy\" to be a much weaker accusation than \"schizophrenia\"</p>", "parentCommentId": "9jYdfQLtcYTBfLD4Q", "user": {"username": "Linch"}}, {"_id": "7unZTQJ9dLjwnqsCF", "postedAt": "2022-12-01T22:56:55.047Z", "postId": "FydrC9mQgh8YdNTQN", "htmlBody": "<p>I think that's fine too.</p>", "parentCommentId": "9jYdfQLtcYTBfLD4Q", "user": {"username": "AllAmericanBreakfast"}}, {"_id": "tzKxXW7CBWeDfc4aR", "postedAt": "2022-12-02T00:13:32.888Z", "postId": "FydrC9mQgh8YdNTQN", "htmlBody": "<p>I meant strong relative to \"internal moral disharmony.\" But also, am I to understand people are reading the label of \"schizophrenia\" as an <i>accusation</i>? It's a disorder that one gets through no choice of one's own: you can't be <i>blamed </i>for having it. Hypocrisy, as I understand it, is something we have control over and therefore are responsible for avoiding or getting rid of in ourselves.</p><p>At most Stocker is blaming Consequentialism and DE for being moral schizophrenia <i>inducing. </i>But it's the theory that's at fault, not the person who suffers it!</p>", "parentCommentId": "XqPx46oqy3AmBaMHy", "user": {"username": "c.trout"}}, {"_id": "CAnCiWZ4mMqzMCfwK", "postedAt": "2022-12-02T00:54:17.039Z", "postId": "FydrC9mQgh8YdNTQN", "htmlBody": "<p>Yeah I think this is fair. I probably didn't read you very carefully or fairly. However, it is hard to control connotations of words, and I have to admit I had a slightly negative visceral reaction for what I believed to be my sincerely held moral views (that I tried pretty hard to live up to, and I made large sacrifices for) medicalized and dismissed so casually.&nbsp;</p>", "parentCommentId": "tzKxXW7CBWeDfc4aR", "user": {"username": "Linch"}}, {"_id": "fu5Gy4i4Nf5cXrAj4", "postedAt": "2022-12-02T01:50:35.534Z", "postId": "FydrC9mQgh8YdNTQN", "htmlBody": "<blockquote><p>...outsourcing our charity evaluations to specialists. I don\u2019t have to decide if bednets or direct donations is better: GiveWell does it for me with their wonderful spreadsheets.</p><p>And I don\u2019t have to consider every moment whether deontology or consequentialism is better: the EA movement and my identity as an EA does a lot of that work for me. It also licenses me to defer to habit almost 100% of the time</p></blockquote><p>These are good things, and you're right to point them out! I certainly don't expect to find that every EA is a walking utility calculator \u2013 I expect that to be extremely rare. I also don't expect to find internal moral disharmony in every EA, though I expect it to be much less rare than walking utility calculators.</p><p>I just want to add one thing, just to be sure everything is clear. I'm glad you see how \"a conscious chain of ethical reasoning held in the mind is not what should be motivating our actions\" (i.e. we should not be walking utility calculators). But that was just my starting point. Ultimately I want to claim that, whether you're in a \"heat of the moment\" situation or not, getting too used to applying a calculating maximizer's mindset in realms typically governed by affect can result in the following:</p><ol><li>Worst case extreme scenario: you become a walking utility calculator, and are perfectly at peace with yourself about being one. You could be accused of being cold, calculating, uncaring.</li><li>More likely scenario: you start adopting a calculating maximizer's mindset when you shouldn't (e.g. when trying to decide whether to go see a sick friend or not) <i>even though you know you shouldn't, or you didn't mean to adopt that mindset</i>. You could be accused of being <i>inadvertently </i>cold and calculating \u2013 someone who, sadly, tends to overthink things.<ol><li>In such situations, because you've adopted that mindset, you will dampen your positive affective attachment to the decision you make (or the object at the center of that decision), <i>even though you started with strong affect toward that decision/object</i>. E.g. when you first heard your friend was in the hospital, you got a pit in your stomach, but it eventually wore away as you evaluated the pros and cons of going to see them or doing something else with your time (as you began comparing friends maybe, to decide who to spend time with). Whatever you do end up deciding to do, you feel ambivalent about it.</li><li>Any cognitive dissonance you might have (e.g. your internal monologue sounds like this: \"Why am I thinking so hard about this? I should have just gone with my gut\"), and the struggle to resolve that dissonance only worsens 2.a.&nbsp;</li></ol></li><li>Either way: in general, considerations that once engendered an emotional response now start leaving you cold (or colder). This in turn can result in:<ol><li>A more general struggle to motivate oneself to do what one believes one should do.</li><li>Seeing ethics as \"just a game.\"</li></ol></li></ol><p>Was that clear? Since it's getting clearer for me, I fear it wasn't clear in the post... It seems it needed to go through one more draft!</p>", "parentCommentId": "zaPY8CPpqSpebJMvW", "user": {"username": "c.trout"}}, {"_id": "ZrMutjwCyMniymqE5", "postedAt": "2022-12-02T01:56:49.030Z", "postId": "FydrC9mQgh8YdNTQN", "htmlBody": "<p>Yikes! Thank you for letting me know! Clearly a very poor choice of words: that was not at all my intent!</p><p>To be clear, I agree with EAs on many many issues. I just fear they suffer from \"overthinking ethical stuff too often\" if you will.</p>", "parentCommentId": "CAnCiWZ4mMqzMCfwK", "user": {"username": "c.trout"}}, {"_id": "6z4fcG2pGnuqiR9zZ", "postedAt": "2022-12-02T02:20:01.285Z", "postId": "FydrC9mQgh8YdNTQN", "htmlBody": "<p>No worries!</p><p>I understand your concern. It seems like your model is that you assume most people start with a sort of organic, healthy gut-level caring and sense of fellow-feeling, which moral calculation tends to distort.</p><p>My model is the reverse. Most people are somewhere between cold and unfeeling, and aggressively egocentric. Moral reflection builds into them some capacity for paying attention to others and cultivating empathy, which at first starts as an intellectual exercise and eventually becomes a deeply ingrained and felt habit that feels natural.</p><p>By analogy, you seem to see that moral reflection turns humans into robots. By contrast, I see moral reflection as turning animals into humans. Or think of it like acting. If you've ever acted, or read lines for a play in school, you might have experienced that at first, it's hard to even understand what your character is saying or identify their objectives. After time with the script, actors understand the goal and develop an intellectual understanding of their character and the actions they use to convey emotion. The greatest actors are perhaps method actors, who spend so much time with their character that they actually feel and think naturally like their character. But this takes a lot of time and effort, and seems like it requires starting with a more intellectualized relationship with their character.</p><p>As I see it, this is pretty much how we develop our adult personalities and figure out how to fit into the social world. Maybe I'm wrong - maybe most people have a nice well-adjusted sense of fellow feeling and empathy from the jump, and I'm the weird one who's had to work on it. If so, I think that my approach has been successful, because I think most people I know see me as an unusually empathic and emotionally aware person.</p><p>I can think of examples of people with all four combinations of moral systematization and emapthy: high/high, high/low, low/high, and low/low. I'm really not sure how the correlations run.</p><p>Overall, this seems like a question for psychology rather than a question for philosophy, and if you're really concerned that consequentialism will turn us into calculators, I'd be most interested to see that argument referring to the psych literature rather than the philosophy literature.</p>", "parentCommentId": "fu5Gy4i4Nf5cXrAj4", "user": {"username": "AllAmericanBreakfast"}}, {"_id": "wsRAiRHp97MXsBJvT", "postedAt": "2022-12-02T04:12:45.615Z", "postId": "FydrC9mQgh8YdNTQN", "htmlBody": "<blockquote><p>It seems like your model is that you assume most people start with a sort of organic, healthy gut-level caring and sense of fellow-feeling, which moral calculation tends to distort.</p></blockquote><p>Moral calculation (and faking it 'til you make it) can be helpful in becoming more virtuous, but to a limited extent \u2013 you can push it too far. And anyway, its not the only way to become a better person. I think more helpful is what I mentioned at the end of my post:</p><blockquote><p>Encourage your friends to call out your vices. (In turn, steer your friends away from vice and try to be a good role model for the impressionable). Engage with good books, movies, plays etc. <a href=\"https://www.jstor.org/stable/2026358\">Virtue ethicists note</a> that art has a great potential for exercising and training moral awareness...</p></blockquote><p>If you want to see how the psych literature intersects on a related topic (romantic relationships instead of ethics in general) see Eva Illouz's <i>Why love hurts: A sociological explanation </i>(2012), Chapter 3. Search for the heading \"The New Architecture of Romantic Choice or the Disorganization of the Will\" (p 90 in my edition) if you want to skip right to it. You might be able to read the entire section through Google books preview? I recommend the book though, if you're interested.</p>", "parentCommentId": "6z4fcG2pGnuqiR9zZ", "user": {"username": "c.trout"}}, {"_id": "8mdMzcobYoJjwni2N", "postedAt": "2022-12-02T05:26:34.226Z", "postId": "FydrC9mQgh8YdNTQN", "htmlBody": "<p>I am really specifically interested in the claim you promote that moral calculation interferes on empathic development, rather than contributes to it or is neutral, on net. I don\u2019t expect there\u2019s much lit studying that, but that\u2019s kind of my point. Why would we fee so confident that this or that morality has that or this psychological effect? I have a sense of how my morality has affected me,  and we can speculate, but can we really claim to be going beyond that?</p>\n", "parentCommentId": "wsRAiRHp97MXsBJvT", "user": {"username": "AllAmericanBreakfast"}}, {"_id": "72bPuqPDjhcG33grR", "postedAt": "2022-12-02T05:53:57.861Z", "postId": "FydrC9mQgh8YdNTQN", "htmlBody": "<p>I claim that there is a healthy amount of moral calculation one should do, but doing too much of it has harmful side-effects. I claim, for <a href=\"https://forum.effectivealtruism.org/posts/FydrC9mQgh8YdNTQN/sbf-s-comments-on-ethics-are-no-surprise-to-virtue-ethicists#___but_especially__casual__consequentialists_\">these reasons</a>, that Consequentialism (and the culture surrounding it) tends to result in abuse of moral calculation more so than VE. I don't expect abuse to arise in the <i>majority </i>of people who engage with/follow Consequentialism or something \u2013 just more than among those who engage with/follow VE. I also claim, for reasons <a href=\"https://forum.effectivealtruism.org/posts/FydrC9mQgh8YdNTQN/sbf-s-comments-on-ethics-are-no-surprise-to-virtue-ethicists#Internal_Moral_Disharmony\">at the end of this section</a>, that abuse will be more prevalent among those who engage with rationalism than those who don't.</p><p>If I'm right about this flaw in the community culture around here, and this flaw in anyway contributed to SBF talking the way he did, shouldn't the community consider taking some steps to curb that problematic tendency?</p>", "parentCommentId": "8mdMzcobYoJjwni2N", "user": {"username": "c.trout"}}, {"_id": "fzGkmLmo8o2aYzoAz", "postedAt": "2022-12-02T06:10:51.119Z", "postId": "FydrC9mQgh8YdNTQN", "htmlBody": "<p>What you have is a hypothesis. You could gather data to test it. But we should not take any significant action on the basis of your hypothesis.</p>\n", "parentCommentId": "72bPuqPDjhcG33grR", "user": {"username": "AllAmericanBreakfast"}}, {"_id": "fWkJynHRERgAihuZ7", "postedAt": "2022-12-02T07:12:20.408Z", "postId": "FydrC9mQgh8YdNTQN", "htmlBody": "<p>Fair enough!</p><p>But also: if the EA community will only correct the flaws in itself <i>that it can measure </i>then... good luck. Seems short-sighted to me.</p><p>I may not have the data to back up my hypothesis, but it's also not as if I pulled this out of thin air. And I'm not the first to find this hypothesis plausible.</p>", "parentCommentId": "fzGkmLmo8o2aYzoAz", "user": {"username": "c.trout"}}, {"_id": "aKYgWdecuzzWWSCjE", "postedAt": "2022-12-03T02:16:03.357Z", "postId": "FydrC9mQgh8YdNTQN", "htmlBody": "<p>Thanks for responding! (upvoted)<br><br>On my end, I'm sorry if my words sounded too strong or emotive.</p><p>Separately, I strongly disagree that we suffer from overthinking ethical stuff too much. I don't think SBF's problems with ethics came from careful debate in business ethics and then missing a decimal point in the relevant calculations. I would guess that if he actually consulted senior EA leaders or researchers on the morality of his actions, this would predictably have resulted in less fraud.</p>", "parentCommentId": "ZrMutjwCyMniymqE5", "user": {"username": "Linch"}}, {"_id": "ppZkQjAjAsdd9wyfi", "postedAt": "2022-12-03T17:20:58.341Z", "postId": "FydrC9mQgh8YdNTQN", "htmlBody": "<p>No worries about the strong response \u2013 I misjudged how my words would be interpreted. I'm glad we sorted that out.</p><p><u>Regarding overthinking ethical stuff and SBF:&nbsp;</u><br>Unfortunately I fear you've missed my point. First of all, I wasn't really talking about any fraud/negligence that he may have committed. As I said in the 2nd paragraph:</p><blockquote><p>Regarding his ignorance and his intentions, he might be telling the truth. Suppose he is: suppose he never condoned doing sketchy things as a means he could justify by some expected greater good. Where then is the borderline moral nihilism coming from? Note that it's <i>saying \"all the right shibboleths\" </i>that he spoke of as mere means to an end, <i>not the doing of sketchy things.&nbsp;</i></p></blockquote><p>My subject was <i>his attitude/comments towards ethics</i>. Second, my diagnosis was not that:</p><blockquote><p>SBF's problems with ethics came from careful debate in business ethics and then missing a decimal point in the relevant calculations.</p></blockquote><p>My point was that it's <i>getting too comfortable approaching ethics like a careful calculation </i>that can be dangerous in the first place \u2013 no matter how accurate the calculation is. It's not about missing some decimal points. Please reread <a href=\"https://forum.effectivealtruism.org/posts/FydrC9mQgh8YdNTQN/sbf-s-comments-on-ethics-are-no-surprise-to-virtue-ethicists#Internal_Moral_Disharmony\">this section</a> if you're interested. I updated the end of it with a reference to a <a href=\"https://forum.effectivealtruism.org/posts/FydrC9mQgh8YdNTQN/sbf-s-comments-on-ethics-are-no-surprise-to-virtue-ethicists?commentId=asgTt48v5e9R68GNN\">clear falsifiable claim</a>.</p>", "parentCommentId": "aKYgWdecuzzWWSCjE", "user": {"username": "c.trout"}}, {"_id": "Z7bZupjw44hzRYSZ9", "postedAt": "2022-12-04T01:27:32.660Z", "postId": "FydrC9mQgh8YdNTQN", "htmlBody": "<p>Meta: I couldn't figure out why the first chart renders with so much whitespace.</p>", "parentCommentId": "aKYgWdecuzzWWSCjE", "user": {"username": "Linch"}}]